digraph {
	graph [size="21.599999999999998,21.599999999999998"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140340497698488 [label=AddmmBackward fillcolor=darkolivegreen1]
	140340372943312 -> 140340497698488
	140340372943312 [label="module_list.21.bias
 (10)" fillcolor=lightblue]
	140340372943424 -> 140340497698488
	140340372943424 [label=ViewBackward]
	140340372943928 -> 140340372943424
	140340372943928 [label=ViewBackward]
	140340497712240 -> 140340372943928
	140340497712240 [label=MeanBackward1]
	140340497712296 -> 140340497712240
	140340497712296 [label=ViewBackward]
	140340497712464 -> 140340497712296
	140340497712464 [label=ReluBackward1]
	140340497712576 -> 140340497712464
	140340497712576 [label=AddBackward0]
	140340497712688 -> 140340497712576
	140340497712688 [label=ReluBackward1]
	140340497712856 -> 140340497712688
	140340497712856 [label=AddBackward0]
	140340497713024 -> 140340497712856
	140340497713024 [label=ReluBackward1]
	140340497713192 -> 140340497713024
	140340497713192 [label=AddBackward0]
	140340497713360 -> 140340497713192
	140340497713360 [label=ReluBackward1]
	140340497713528 -> 140340497713360
	140340497713528 [label=CudnnBatchNormBackward]
	140340497713696 -> 140340497713528
	140340497713696 [label=CudnnConvolutionBackward]
	140340497696416 -> 140340497713696
	140340497696416 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140340497696248 -> 140340497713528
	140340497696248 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140340497696304 -> 140340497713528
	140340497696304 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140340497713416 -> 140340497713192
	140340497713416 [label=CudnnBatchNormBackward]
	140340497713584 -> 140340497713416
	140340497713584 [label=CudnnConvolutionBackward]
	140340497713808 -> 140340497713584
	140340497713808 [label=ReluBackward1]
	140340497713864 -> 140340497713808
	140340497713864 [label=CudnnBatchNormBackward]
	140340497714032 -> 140340497713864
	140340497714032 [label=CudnnConvolutionBackward]
	140340497714144 -> 140340497714032
	140340497714144 [label=ReluBackward1]
	140340497714256 -> 140340497714144
	140340497714256 [label=CudnnBatchNormBackward]
	140340497714424 -> 140340497714256
	140340497714424 [label=CudnnConvolutionBackward]
	140340497713360 -> 140340497714424
	140340497697648 -> 140340497714424
	140340497697648 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497697480 -> 140340497714256
	140340497697480 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140340497697536 -> 140340497714256
	140340497697536 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140340497697144 -> 140340497714032
	140340497697144 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497696920 -> 140340497713864
	140340497696920 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140340497696976 -> 140340497713864
	140340497696976 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140340497696640 -> 140340497713584
	140340497696640 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497696360 -> 140340497713416
	140340497696360 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140340497696472 -> 140340497713416
	140340497696472 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140340497713080 -> 140340497712856
	140340497713080 [label=CudnnBatchNormBackward]
	140340497713248 -> 140340497713080
	140340497713248 [label=CudnnConvolutionBackward]
	140340497713752 -> 140340497713248
	140340497713752 [label=ReluBackward1]
	140340497714088 -> 140340497713752
	140340497714088 [label=CudnnBatchNormBackward]
	140340497713976 -> 140340497714088
	140340497713976 [label=CudnnConvolutionBackward]
	140340497714536 -> 140340497713976
	140340497714536 [label=ReluBackward1]
	140340497714648 -> 140340497714536
	140340497714648 [label=CudnnBatchNormBackward]
	140340497714592 -> 140340497714648
	140340497714592 [label=CudnnConvolutionBackward]
	140340497713024 -> 140340497714592
	140340497698432 -> 140340497714592
	140340497698432 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497698264 -> 140340497714648
	140340497698264 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140340497698320 -> 140340497714648
	140340497698320 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140340497697984 -> 140340497713976
	140340497697984 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497697816 -> 140340497714088
	140340497697816 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140340497697872 -> 140340497714088
	140340497697872 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140340497697200 -> 140340497713248
	140340497697200 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497695968 -> 140340497713080
	140340497695968 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140340497696584 -> 140340497713080
	140340497696584 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140340497712744 -> 140340497712576
	140340497712744 [label=CudnnBatchNormBackward]
	140340497712912 -> 140340497712744
	140340497712912 [label=CudnnConvolutionBackward]
	140340497713472 -> 140340497712912
	140340497713472 [label=ReluBackward1]
	140340497714480 -> 140340497713472
	140340497714480 [label=CudnnBatchNormBackward]
	140340497714200 -> 140340497714480
	140340497714200 [label=CudnnConvolutionBackward]
	140340497714816 -> 140340497714200
	140340497714816 [label=ReluBackward1]
	140340497714928 -> 140340497714816
	140340497714928 [label=CudnnBatchNormBackward]
	140340497714872 -> 140340497714928
	140340497714872 [label=CudnnConvolutionBackward]
	140340497712688 -> 140340497714872
	140340497711568 -> 140340497714872
	140340497711568 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497711400 -> 140340497714928
	140340497711400 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140340497711456 -> 140340497714928
	140340497711456 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140340497698768 -> 140340497714200
	140340497698768 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497698600 -> 140340497714480
	140340497698600 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140340497698656 -> 140340497714480
	140340497698656 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140340497698040 -> 140340497712912
	140340497698040 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140340497695632 -> 140340497712744
	140340497695632 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140340497696696 -> 140340497712744
	140340497696696 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140340372942976 -> 140340497698488
	140340372942976 [label=TBackward]
	140340372946840 -> 140340372942976
	140340372946840 [label="module_list.21.weight
 (10, 16)" fillcolor=lightblue]
}
