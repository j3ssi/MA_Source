no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
Pytorch Training main.py; workers: 6; numOfStages: 3; layerinBlock: 2;widthofFirstLayer: 16; Epochen: 2; reset: False; start epoche: 1; test: True pathtoModell: None; checkpoint: ./output/experimente4/wider; saveModell: False; LR: 0.1
random number: 8517
Files already downloaded and verified
width: 16

Arch Num:  [[2, 2, 2, 2, 2], [3, 2, 2, 2, 2], [3, 2, 2, 2, 2]]
conv0: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0
bn1: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
Relu; i: 2
i : 2; block: 0
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 2; block: 0
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 2
i : 3; block: 1
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 3; block: 1
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 3
i : 4; block: 2
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 4; block: 2
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 4
i : 5; block: 3
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 5; block: 3
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 5
i : 6; block: 4
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 6; block: 4
Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 6
i : 7; block: 0
Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False); i=0; if 1
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i=0
relu: 0
i : 7; block: 0
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
i : 7; block: 0
Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False); i: 2 if 2
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 2
seq: Sequential(
  (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 7
seq1: Sequential(
  (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 8
i : 8; block: 1
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 8; block: 1
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 8
i : 9; block: 2
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 9; block: 2
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 9
i : 10; block: 3
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 10; block: 3
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 10
i : 11; block: 4
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 11; block: 4
Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 11
i : 12; block: 0
Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False); i=0; if 1
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i=0
relu: 0
i : 12; block: 0
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
i : 12; block: 0
Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False); i: 2 if 2
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 2
seq: Sequential(
  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 12
seq1: Sequential(
  (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 13
i : 13; block: 1
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 13; block: 1
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 13
i : 14; block: 2
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 14; block: 2
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 14
i : 15; block: 3
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 15; block: 3
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 15
i : 16; block: 4
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 0 if 4
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 0
relu; i: 0
i : 16; block: 4
Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); i: 1 if 3
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); i: 1
seq: Sequential(
  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (2): ReLU(inplace=True)
  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
); i: 16
avgpoll: AdaptiveAvgPool2d(output_size=(1, 1))
linear: Linear(in_features=64, out_features=10, bias=True)
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 4
Startepoche: 1
deeper epoch: 0
Epoche: [1/2]; Lr: 0.1
batch Size 256
befor train
test -4
test -3.5
test -3
test -2
test -1
Epoch: [1][0/196]	Time 0.187 (0.187)	Data 0.277 (0.277)	Loss 2.5009 (2.5009)	Acc@1 9.375 (9.375)	Acc@5 46.094 (46.094)
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
Epoch: [1][64/196]	Time 0.099 (0.102)	Data 0.000 (0.004)	Loss 1.7615 (1.9590)	Acc@1 37.109 (26.322)	Acc@5 87.500 (79.495)
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
Epoch: [1][128/196]	Time 0.104 (0.101)	Data 0.000 (0.002)	Loss 1.5134 (1.7839)	Acc@1 42.188 (32.610)	Acc@5 89.844 (84.614)
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
Epoch: [1][192/196]	Time 0.099 (0.101)	Data 0.000 (0.002)	Loss 1.2031 (1.6652)	Acc@1 61.328 (37.423)	Acc@5 94.141 (87.261)
test -3
test -2
test -1
test -3
test -2
test -1
test -3
test -2
test -1
after train
Prune Train:
[INFO] Force the sparse filters to zero...
altList: [(0, None), (3, 0), (3, 3), (4, 0), (4, 3), (5, 0), (5, 3), (6, 0), (6, 3), (7, 0), (7, 3), (8, 0), (8, 3), (9, 0), (10, 0), (10, 3), (11, 0), (11, 3), (12, 0), (12, 3), (13, 0), (13, 3), (14, 0), (14, 3), (15, 0), (16, 0), (16, 3), (17, 0), (17, 3), (18, 0), (18, 3), (19, 0), (19, 3), (21, None)]


 Reconf: 
[(0, None)]: [16, 3, 3, 3]


 Reconf: 
[(3, 0)]: [16, 16, 3, 3]


 Reconf: 
[(3, 3)]: [16, 16, 3, 3]


 Reconf: 
[(4, 0)]: [16, 16, 3, 3]


 Reconf: 
[(4, 3)]: [16, 16, 3, 3]


 Reconf: 
[(5, 0)]: [16, 16, 3, 3]


 Reconf: 
[(5, 3)]: [16, 16, 3, 3]


 Reconf: 
[(6, 0)]: [16, 16, 3, 3]


 Reconf: 
[(6, 3)]: [16, 16, 3, 3]


 Reconf: 
[(7, 0)]: [16, 16, 3, 3]


 Reconf: 
[(7, 3)]: [16, 16, 3, 3]


 Reconf: 
[(8, 0)]: [32, 16, 3, 3]


 Reconf: 
[(8, 3)]: [32, 32, 3, 3]


 Reconf: 
[(9, 0)]: [32, 16, 1, 1]


 Reconf: 
[(10, 0)]: [32, 32, 3, 3]


 Reconf: 
[(10, 3)]: [32, 32, 3, 3]


 Reconf: 
[(11, 0)]: [32, 32, 3, 3]


 Reconf: 
[(11, 3)]: [32, 32, 3, 3]


 Reconf: 
[(12, 0)]: [32, 32, 3, 3]


 Reconf: 
[(12, 3)]: [32, 32, 3, 3]


 Reconf: 
[(13, 0)]: [32, 32, 3, 3]


 Reconf: 
[(13, 3)]: [32, 32, 3, 3]


 Reconf: 
[(14, 0)]: [64, 32, 3, 3]


 Reconf: 
[(14, 3)]: [64, 64, 3, 3]


 Reconf: 
[(15, 0)]: [64, 32, 1, 1]


 Reconf: 
[(16, 0)]: [64, 64, 3, 3]


 Reconf: 
[(16, 3)]: [64, 64, 3, 3]


 Reconf: 
[(17, 0)]: [64, 64, 3, 3]


 Reconf: 
[(17, 3)]: [64, 64, 3, 3]


 Reconf: 
[(18, 0)]: [64, 64, 3, 3]


 Reconf: 
[(18, 3)]: [64, 64, 3, 3]


 Reconf: 
[(19, 0)]: [64, 64, 3, 3]


 Reconf: 
[(19, 3)]: [64, 64, 3, 3]


 Reconf: 
[(21, None)]: [10, 64]
Start width: 16
Append O : (0, None)
Traceback (most recent call last):
  File "main.py", line 883, in <module>
    main()
  File "main.py", line 377, in main
    dense_chs, chs_map = makeSparse(optimizer, model, args.threshold)
  File "/home/jessica.buehler/MA_Source/src/checkpoint_utils.py", line 185, in makeSparse
    layerWidth = module.weight.size(0)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 580, in __getattr__
    def __getattr__(self, name):
KeyboardInterrupt
