no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 0
total    : 11018
free     : 11008
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  100
  71.76
 155.067s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  200
  77.96
 84.436s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  300
  64.12
 68.241s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  400
  70.02
 58.563s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  500
  60.36
 52.423s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  600
  74.2
 50.663s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  700
  75.3
 41.362s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  800
  82.89
 40.057s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified

Epoch: [1 | 50] LR: 0.100000

Epoch: [2 | 50] LR: 0.100000

Epoch: [3 | 50] LR: 0.100000

Epoch: [4 | 50] LR: 0.100000

Epoch: [5 | 50] LR: 0.100000

Epoch: [6 | 50] LR: 0.100000

Epoch: [7 | 50] LR: 0.100000

Epoch: [8 | 50] LR: 0.100000

Epoch: [9 | 50] LR: 0.100000

Epoch: [10 | 50] LR: 0.100000

Epoch: [11 | 50] LR: 0.100000

Epoch: [12 | 50] LR: 0.100000

Epoch: [13 | 50] LR: 0.100000

Epoch: [14 | 50] LR: 0.100000

Epoch: [15 | 50] LR: 0.100000

Epoch: [16 | 50] LR: 0.100000

Epoch: [17 | 50] LR: 0.100000

Epoch: [18 | 50] LR: 0.100000

Epoch: [19 | 50] LR: 0.100000

Epoch: [20 | 50] LR: 0.100000

Epoch: [21 | 50] LR: 0.100000

Epoch: [22 | 50] LR: 0.100000

Epoch: [23 | 50] LR: 0.100000

Epoch: [24 | 50] LR: 0.100000

Epoch: [25 | 50] LR: 0.100000

Epoch: [26 | 50] LR: 0.100000

Epoch: [27 | 50] LR: 0.100000

Epoch: [28 | 50] LR: 0.100000

Epoch: [29 | 50] LR: 0.100000

Epoch: [30 | 50] LR: 0.100000

Epoch: [31 | 50] LR: 0.100000

Epoch: [32 | 50] LR: 0.100000

Epoch: [33 | 50] LR: 0.100000

Epoch: [34 | 50] LR: 0.100000

Epoch: [35 | 50] LR: 0.100000

Epoch: [36 | 50] LR: 0.100000

Epoch: [37 | 50] LR: 0.100000

Epoch: [38 | 50] LR: 0.100000

Epoch: [39 | 50] LR: 0.100000

Epoch: [40 | 50] LR: 0.100000

Epoch: [41 | 50] LR: 0.100000

Epoch: [42 | 50] LR: 0.100000

Epoch: [43 | 50] LR: 0.100000

Epoch: [44 | 50] LR: 0.100000

Epoch: [45 | 50] LR: 0.100000

Epoch: [46 | 50] LR: 0.100000

Epoch: [47 | 50] LR: 0.100000

Epoch: [48 | 50] LR: 0.100000

Epoch: [49 | 50] LR: 0.100000

Epoch: [50 | 50] LR: 0.100000

  900
  75.62
 39.429s  no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
no display found. Using non-interactive Agg backend
gpu id:0
Device Name: GeForce RTX 2080 Ti
GPU id:2
Device Name: GeForce RTX 2080 Ti
This Gpu is free
GPU Id: 2
total    : 11019
free     : 11009
used     : 10


Files already downloaded and verified
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic

Epoch: [1 | 50] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 742, in <module>
    main()
  File "main.py", line 502, in main
    use_gpu_num)
  File "main.py", line 656, in train
    scaled_loss.backward()
  File "/usr/lib/python3.6/contextlib.py", line 88, in __exit__
    next(self.gen)
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/handle.py", line 127, in scale_loss
    should_skip = False if delay_overflow_check else loss_scaler.update_scale()
  File "/home/jessica.buehler/env/local/lib/python3.6/site-packages/apex/amp/scaler.py", line 200, in update_scale
    self._has_overflow = self._overflow_buf.item()
RuntimeError: CUDA error: an illegal memory access was encountered
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 100 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 200 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 300 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 400 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 500 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 600 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 700 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 800 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --test --learning-rate 0.1 --batchTrue --batch_size 900 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 100 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 200 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 300 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 400 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 500 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 600 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 700 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 800 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 900 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1000 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1100 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1200 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1300 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1400 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1500 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1600 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1700 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1800 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O1 --test  --learning-rate 0.1 --batchTrue --batch_size 1900 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 100 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 200 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 300 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 400 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 500 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 600 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 700 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 800 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 900 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1000 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1100 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1200 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1300 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1400 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1500 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1600 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1700 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1800 --test_batch 100 -s 3 -n 3 -l 3
python3 main.py --workers 4 --epochs 50 --O2 --learning-rate 0.1 --batchTrue --batch_size 1900 --test_batch 100 -s 3 -n 3 -l 3
