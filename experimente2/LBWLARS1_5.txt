j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
stage: 0; sizeof Layers: 3
stage: 1; sizeof Layers: 6
stage: 2; sizeof Layers: 12
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv21.weight', 'module.conv22.weight'], ['module.conv23.weight', 'module.conv24.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight'], ['module.conv30.weight', 'module.conv31.weight'], ['module.conv32.weight', 'module.conv33.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv21.weight', 'module.conv22.weight'], ['module.conv23.weight', 'module.conv24.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight'], ['module.conv30.weight', 'module.conv31.weight'], ['module.conv32.weight', 'module.conv33.weight']]
device count: 1
Startepoche: 1
count0: 17683

Epoch: [1 | 5] LR: 1.585938
Epoch: [1][0/13]	Time 0.672 (0.672)	Data 1.242 (1.242)	Loss 3.2516 (3.2516)	Acc@1 10.714 (10.714)	Acc@5 50.074 (50.074)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [2 | 5] LR: 1.585938
Epoch: [2][0/13]	Time 0.468 (0.468)	Data 1.233 (1.233)	Loss 13.4545 (13.4545)	Acc@1 10.813 (10.813)	Acc@5 50.172 (50.172)
[INFO] Storing checkpoint...

Epoch: [3 | 5] LR: 1.585938
Epoch: [3][0/13]	Time 0.413 (0.413)	Data 1.691 (1.691)	Loss 36.0613 (36.0613)	Acc@1 8.842 (8.842)	Acc@5 50.099 (50.099)
[INFO] Storing checkpoint...

Epoch: [4 | 5] LR: 1.585938
Epoch: [4][0/13]	Time 0.386 (0.386)	Data 1.249 (1.249)	Loss 2694.9895 (2694.9895)	Acc@1 10.764 (10.764)	Acc@5 50.961 (50.961)
[INFO] Storing checkpoint...

Epoch: [5 | 5] LR: 1.585938
Epoch: [5][0/13]	Time 0.436 (0.436)	Data 1.175 (1.175)	Loss 11745764.0000 (11745764.0000)	Acc@1 12.167 (12.167)	Acc@5 53.498 (53.498)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  10.28
Max memory: 241.7924608
 5.635s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
count0: 17683

Epoch: [6 | 10] LR: 1.585938
Epoch: [6][0/13]	Time 0.750 (0.750)	Data 1.386 (1.386)	Loss 26329964544.0000 (26329964544.0000)	Acc@1 7.808 (7.808)	Acc@5 44.606 (44.606)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [7 | 10] LR: 1.585938
Epoch: [7][0/13]	Time 0.484 (0.484)	Data 1.179 (1.179)	Loss 8763179794432.0000 (8763179794432.0000)	Acc@1 9.975 (9.975)	Acc@5 49.261 (49.261)
[INFO] Storing checkpoint...

Epoch: [8 | 10] LR: 1.585938
Epoch: [8][0/13]	Time 0.431 (0.431)	Data 1.499 (1.499)	Loss 15600772918018048.0000 (15600772918018048.0000)	Acc@1 9.655 (9.655)	Acc@5 50.197 (50.197)
[INFO] Storing checkpoint...

Epoch: [9 | 10] LR: 1.585938
Epoch: [9][0/13]	Time 0.370 (0.370)	Data 1.218 (1.218)	Loss 532359134754897920.0000 (532359134754897920.0000)	Acc@1 9.631 (9.631)	Acc@5 50.246 (50.246)
[INFO] Storing checkpoint...

Epoch: [10 | 10] LR: 1.585938
Epoch: [10][0/13]	Time 0.402 (0.402)	Data 1.442 (1.442)	Loss 29605187584.0000 (29605187584.0000)	Acc@1 9.433 (9.433)	Acc@5 49.187 (49.187)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  10.0
Max memory: 241.7923584
 5.446s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
count0: 17683

Epoch: [11 | 15] LR: 1.585938
Epoch: [11][0/13]	Time 0.630 (0.630)	Data 1.316 (1.316)	Loss 69729107968.0000 (69729107968.0000)	Acc@1 10.419 (10.419)	Acc@5 50.296 (50.296)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [12 | 15] LR: 1.585938
Epoch: [12][0/13]	Time 0.459 (0.459)	Data 1.342 (1.342)	Loss 2819448373248.0000 (2819448373248.0000)	Acc@1 9.704 (9.704)	Acc@5 48.768 (48.768)
[INFO] Storing checkpoint...

Epoch: [13 | 15] LR: 1.585938
Epoch: [13][0/13]	Time 0.434 (0.434)	Data 1.172 (1.172)	Loss 281594626048.0000 (281594626048.0000)	Acc@1 10.296 (10.296)	Acc@5 50.000 (50.000)
[INFO] Storing checkpoint...

Epoch: [14 | 15] LR: 1.585938
Epoch: [14][0/13]	Time 0.387 (0.387)	Data 1.320 (1.320)	Loss 860117794816.0000 (860117794816.0000)	Acc@1 9.532 (9.532)	Acc@5 49.409 (49.409)
[INFO] Storing checkpoint...

Epoch: [15 | 15] LR: 1.585938
Epoch: [15][0/13]	Time 0.439 (0.439)	Data 1.221 (1.221)	Loss 123029252294574080.0000 (123029252294574080.0000)	Acc@1 10.468 (10.468)	Acc@5 50.271 (50.271)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  10.0
Max memory: 241.7923584
 5.249s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
count0: 17683

Epoch: [16 | 20] LR: 1.585938
Epoch: [16][0/13]	Time 0.838 (0.838)	Data 1.267 (1.267)	Loss 10229169258496.0000 (10229169258496.0000)	Acc@1 10.764 (10.764)	Acc@5 49.606 (49.606)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [17 | 20] LR: 1.585938
Epoch: [17][0/13]	Time 0.390 (0.390)	Data 1.215 (1.215)	Loss 1270317449216.0000 (1270317449216.0000)	Acc@1 10.443 (10.443)	Acc@5 50.517 (50.517)
[INFO] Storing checkpoint...

Epoch: [18 | 20] LR: 1.585938
Epoch: [18][0/13]	Time 0.376 (0.376)	Data 1.263 (1.263)	Loss 1952981188608.0000 (1952981188608.0000)	Acc@1 9.975 (9.975)	Acc@5 51.724 (51.724)
[INFO] Storing checkpoint...

Epoch: [19 | 20] LR: 1.585938
Epoch: [19][0/13]	Time 0.432 (0.432)	Data 1.268 (1.268)	Loss 1317801295872.0000 (1317801295872.0000)	Acc@1 10.320 (10.320)	Acc@5 49.458 (49.458)
[INFO] Storing checkpoint...

Epoch: [20 | 20] LR: 1.585938
Epoch: [20][0/13]	Time 0.446 (0.446)	Data 1.263 (1.263)	Loss 174903672832.0000 (174903672832.0000)	Acc@1 10.345 (10.345)	Acc@5 50.542 (50.542)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  10.0
Max memory: 241.7923584
 5.680s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
count0: 17683

Epoch: [21 | 25] LR: 1.585938
Epoch: [21][0/13]	Time 0.697 (0.697)	Data 1.358 (1.358)	Loss 245866430464.0000 (245866430464.0000)	Acc@1 10.222 (10.222)	Acc@5 49.778 (49.778)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [22 | 25] LR: 1.585938
Epoch: [22][0/13]	Time 0.414 (0.414)	Data 1.231 (1.231)	Loss 30533107712.0000 (30533107712.0000)	Acc@1 10.862 (10.862)	Acc@5 50.862 (50.862)
[INFO] Storing checkpoint...

Epoch: [23 | 25] LR: 1.585938
Epoch: [23][0/13]	Time 0.408 (0.408)	Data 1.346 (1.346)	Loss 46941495296.0000 (46941495296.0000)	Acc@1 10.493 (10.493)	Acc@5 51.650 (51.650)
[INFO] Storing checkpoint...

Epoch: [24 | 25] LR: 1.585938
Epoch: [24][0/13]	Time 0.414 (0.414)	Data 1.359 (1.359)	Loss 31674423296.0000 (31674423296.0000)	Acc@1 11.010 (11.010)	Acc@5 50.567 (50.567)
[INFO] Storing checkpoint...

Epoch: [25 | 25] LR: 1.585938
Epoch: [25][0/13]	Time 0.389 (0.389)	Data 1.504 (1.504)	Loss 89905763981476233216.0000 (89905763981476233216.0000)	Acc@1 9.803 (9.803)	Acc@5 50.394 (50.394)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  10.0
Max memory: 241.7923584
 5.721s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
count0: 17683

Epoch: [26 | 30] LR: 1.585938
Epoch: [26][0/13]	Time 0.690 (0.690)	Data 1.366 (1.366)	Loss 4083524042752.0000 (4083524042752.0000)	Acc@1 9.458 (9.458)	Acc@5 50.320 (50.320)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [27 | 30] LR: 1.585938
Epoch: [27][0/13]	Time 0.418 (0.418)	Data 1.619 (1.619)	Loss 507115536384.0000 (507115536384.0000)	Acc@1 9.803 (9.803)	Acc@5 50.517 (50.517)
[INFO] Storing checkpoint...

Epoch: [28 | 30] LR: 1.585938
Epoch: [28][0/13]	Time 0.369 (0.369)	Data 1.246 (1.246)	Loss 779637555200.0000 (779637555200.0000)	Acc@1 9.089 (9.089)	Acc@5 49.015 (49.015)
[INFO] Storing checkpoint...

Epoch: [29 | 30] LR: 1.585938
Epoch: [29][0/13]	Time 0.381 (0.381)	Data 1.167 (1.167)	Loss 526071365632.0000 (526071365632.0000)	Acc@1 10.197 (10.197)	Acc@5 49.655 (49.655)
[INFO] Storing checkpoint...

Epoch: [30 | 30] LR: 1.585938
Epoch: [30][0/13]	Time 0.387 (0.387)	Data 1.463 (1.463)	Loss 69822251008.0000 (69822251008.0000)	Acc@1 10.739 (10.739)	Acc@5 50.320 (50.320)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  10.0
Max memory: 241.7923584
 5.648s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.775 (0.775)	Data 1.231 (1.231)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.000 (10.000)	Acc@5 48.892 (48.892)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.829 (0.829)	Data 1.825 (1.825)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.369 (10.369)	Acc@5 49.606 (49.606)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.841 (0.841)	Data 1.245 (1.245)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.099 (10.099)	Acc@5 51.478 (51.478)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.735 (0.735)	Data 1.355 (1.355)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.690 (10.690)	Acc@5 50.887 (50.887)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.690 (0.690)	Data 1.228 (1.228)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.803 (9.803)	Acc@5 49.384 (49.384)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.669 (0.669)	Data 1.279 (1.279)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.926 (9.926)	Acc@5 49.606 (49.606)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.684 (0.684)	Data 1.548 (1.548)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.138 (9.138)	Acc@5 48.941 (48.941)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.836 (0.836)	Data 1.500 (1.500)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.310 (9.310)	Acc@5 49.778 (49.778)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.725 (0.725)	Data 1.457 (1.457)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.163 (9.163)	Acc@5 48.522 (48.522)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.969 (0.969)	Data 1.786 (1.786)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.655 (9.655)	Acc@5 50.222 (50.222)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.739 (0.739)	Data 1.333 (1.333)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.557 (9.557)	Acc@5 47.759 (47.759)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.650 (0.650)	Data 1.886 (1.886)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.172 (10.172)	Acc@5 50.665 (50.665)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 1.160 (1.160)	Data 1.644 (1.644)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.631 (9.631)	Acc@5 49.384 (49.384)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.839 (0.839)	Data 1.124 (1.124)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.384 (9.384)	Acc@5 49.803 (49.803)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.792 (0.792)	Data 1.852 (1.852)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.591 (10.591)	Acc@5 50.369 (50.369)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.699 (0.699)	Data 1.661 (1.661)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.335 (9.335)	Acc@5 50.099 (50.099)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.811 (0.811)	Data 1.277 (1.277)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.468 (10.468)	Acc@5 50.640 (50.640)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.735 (0.735)	Data 1.315 (1.315)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.828 (9.828)	Acc@5 49.483 (49.483)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.672 (0.672)	Data 1.256 (1.256)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.739 (10.739)	Acc@5 49.655 (49.655)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.751 (0.751)	Data 1.288 (1.288)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.704 (9.704)	Acc@5 49.310 (49.310)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.815 (0.815)	Data 1.313 (1.313)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.222 (10.222)	Acc@5 50.911 (50.911)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.805 (0.805)	Data 1.223 (1.223)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.567 (10.567)	Acc@5 49.852 (49.852)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.837 (0.837)	Data 1.728 (1.728)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.764 (10.764)	Acc@5 50.567 (50.567)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.667 (0.667)	Data 1.332 (1.332)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.828 (9.828)	Acc@5 50.369 (50.369)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.761 (0.761)	Data 2.035 (2.035)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.074 (10.074)	Acc@5 50.419 (50.419)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.817 (0.817)	Data 1.271 (1.271)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 10.025 (10.025)	Acc@5 50.862 (50.862)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.763 (0.763)	Data 1.370 (1.370)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.483 (9.483)	Acc@5 48.793 (48.793)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.741 (0.741)	Data 1.249 (1.249)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.631 (9.631)	Acc@5 49.286 (49.286)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.759 (0.759)	Data 1.895 (1.895)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.729 (9.729)	Acc@5 50.172 (50.172)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 17683

Epoch: [31 | 35] LR: 1.585938
Warning: Error detected in LogSoftmaxBackward. Traceback of forward call that caused the error:
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 526, in train
    loss = criterion(outputs, targets)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 932, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2317, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1535, in log_softmax
    ret = input.log_softmax(dim)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
Epoch: [31][0/13]	Time 0.763 (0.763)	Data 1.289 (1.289)	Loss 98150817792.0000 (98150817792.0000)	Acc@1 9.754 (9.754)	Acc@5 48.990 (48.990)
Traceback (most recent call last):
  File "main.py", line 839, in <module>
    main()
  File "main.py", line 392, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 583, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'LogSoftmaxBackward' returned nan values in its 0th output.
