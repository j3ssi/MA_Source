j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
stage: 0; sizeof Layers: 3
stage: 1; sizeof Layers: 6
stage: 2; sizeof Layers: 12
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv21.weight', 'module.conv22.weight'], ['module.conv23.weight', 'module.conv24.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight'], ['module.conv30.weight', 'module.conv31.weight'], ['module.conv32.weight', 'module.conv33.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv21.weight', 'module.conv22.weight'], ['module.conv23.weight', 'module.conv24.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight'], ['module.conv30.weight', 'module.conv31.weight'], ['module.conv32.weight', 'module.conv33.weight']]
device count: 1
Startepoche: 1
count0: 17683

Epoch: [1 | 5] LR: 1.585938
Epoch: [1][0/13]	Time 0.664 (0.664)	Data 1.334 (1.334)	Loss 3.1570 (3.1570)	Acc@1 9.458 (9.458)	Acc@5 49.138 (49.138)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [2 | 5] LR: 1.585938
Epoch: [2][0/13]	Time 0.370 (0.370)	Data 1.296 (1.296)	Loss 2.6558 (2.6558)	Acc@1 20.517 (20.517)	Acc@5 72.512 (72.512)
[INFO] Storing checkpoint...

Epoch: [3 | 5] LR: 1.585938
Epoch: [3][0/13]	Time 0.384 (0.384)	Data 1.269 (1.269)	Loss 2.4719 (2.4719)	Acc@1 22.020 (22.020)	Acc@5 77.808 (77.808)
[INFO] Storing checkpoint...

Epoch: [4 | 5] LR: 1.585938
Epoch: [4][0/13]	Time 0.439 (0.439)	Data 1.233 (1.233)	Loss 2.4084 (2.4084)	Acc@1 25.493 (25.493)	Acc@5 79.852 (79.852)
[INFO] Storing checkpoint...

Epoch: [5 | 5] LR: 1.585938
Epoch: [5][0/13]	Time 0.444 (0.444)	Data 1.273 (1.273)	Loss 2.4664 (2.4664)	Acc@1 23.153 (23.153)	Acc@5 75.246 (75.246)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 11515 ; 17683 ; 0.6511904088672736
[INFO] Storing checkpoint...

  4060
  10.96
Max memory: 241.7924608
 5.523s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
count0: 11515

Epoch: [6 | 10] LR: 1.585938
Epoch: [6][0/13]	Time 1.316 (1.316)	Data 1.979 (1.979)	Loss 2.3330 (2.3330)	Acc@1 26.576 (26.576)	Acc@5 77.808 (77.808)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [7 | 10] LR: 1.585938
Epoch: [7][0/13]	Time 0.423 (0.423)	Data 1.305 (1.305)	Loss 2.2027 (2.2027)	Acc@1 29.532 (29.532)	Acc@5 81.897 (81.897)
[INFO] Storing checkpoint...

Epoch: [8 | 10] LR: 1.585938
Epoch: [8][0/13]	Time 0.372 (0.372)	Data 1.233 (1.233)	Loss 2.1084 (2.1084)	Acc@1 32.118 (32.118)	Acc@5 83.177 (83.177)
[INFO] Storing checkpoint...

Epoch: [9 | 10] LR: 1.585938
Epoch: [9][0/13]	Time 0.354 (0.354)	Data 1.291 (1.291)	Loss 2.0958 (2.0958)	Acc@1 28.941 (28.941)	Acc@5 82.956 (82.956)
[INFO] Storing checkpoint...

Epoch: [10 | 10] LR: 1.585938
Epoch: [10][0/13]	Time 0.440 (0.440)	Data 1.139 (1.139)	Loss 2.0351 (2.0351)	Acc@1 31.921 (31.921)	Acc@5 84.852 (84.852)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 8290 ; 11515 ; 0.71993052540165
[INFO] Storing checkpoint...

  4060
  19.61
Max memory: 220.2797568
 5.295s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
count0: 8290

Epoch: [11 | 15] LR: 1.585938
Epoch: [11][0/13]	Time 1.413 (1.413)	Data 1.435 (1.435)	Loss 2.0649 (2.0649)	Acc@1 30.887 (30.887)	Acc@5 83.498 (83.498)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [12 | 15] LR: 1.585938
Epoch: [12][0/13]	Time 0.377 (0.377)	Data 1.240 (1.240)	Loss 2.0239 (2.0239)	Acc@1 32.980 (32.980)	Acc@5 83.744 (83.744)
[INFO] Storing checkpoint...

Epoch: [13 | 15] LR: 1.585938
Epoch: [13][0/13]	Time 0.343 (0.343)	Data 1.311 (1.311)	Loss 2.0222 (2.0222)	Acc@1 31.059 (31.059)	Acc@5 84.236 (84.236)
[INFO] Storing checkpoint...

Epoch: [14 | 15] LR: 1.585938
Epoch: [14][0/13]	Time 0.446 (0.446)	Data 1.288 (1.288)	Loss 1.9509 (1.9509)	Acc@1 34.680 (34.680)	Acc@5 86.921 (86.921)
[INFO] Storing checkpoint...

Epoch: [15 | 15] LR: 1.585938
Epoch: [15][0/13]	Time 0.439 (0.439)	Data 1.188 (1.188)	Loss 2.1256 (2.1256)	Acc@1 30.517 (30.517)	Acc@5 81.330 (81.330)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 7320 ; 8290 ; 0.8829915560916767
[INFO] Storing checkpoint...

  4060
  25.46
Max memory: 202.1602816
 5.580s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
count0: 7320

Epoch: [16 | 20] LR: 1.585938
Epoch: [16][0/13]	Time 1.437 (1.437)	Data 1.381 (1.381)	Loss 1.9682 (1.9682)	Acc@1 33.054 (33.054)	Acc@5 86.601 (86.601)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [17 | 20] LR: 1.585938
Epoch: [17][0/13]	Time 0.474 (0.474)	Data 1.277 (1.277)	Loss 1.8736 (1.8736)	Acc@1 37.044 (37.044)	Acc@5 88.399 (88.399)
[INFO] Storing checkpoint...

Epoch: [18 | 20] LR: 1.585938
Epoch: [18][0/13]	Time 0.461 (0.461)	Data 1.280 (1.280)	Loss 1.8145 (1.8145)	Acc@1 39.310 (39.310)	Acc@5 88.498 (88.498)
[INFO] Storing checkpoint...

Epoch: [19 | 20] LR: 1.585938
Epoch: [19][0/13]	Time 0.417 (0.417)	Data 1.371 (1.371)	Loss 1.7547 (1.7547)	Acc@1 41.429 (41.429)	Acc@5 89.926 (89.926)
[INFO] Storing checkpoint...

Epoch: [20 | 20] LR: 1.585938
Epoch: [20][0/13]	Time 0.540 (0.540)	Data 1.711 (1.711)	Loss 1.7468 (1.7468)	Acc@1 39.532 (39.532)	Acc@5 90.074 (90.074)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv17.weight

 RM:  module.conv18.weight

 RM:  module.conv19.weight

 RM:  module.conv20.weight

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv21.weight', 'module.conv22.weight'], ['module.conv24.weight', 'module.conv25.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight'], ['module.conv30.weight', 'module.conv31.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv21.weight', 'module.conv22.weight'], ['module.conv24.weight', 'module.conv25.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight'], ['module.conv30.weight', 'module.conv31.weight']]
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(3, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(5, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(5, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(12, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv22.weight', 'module.conv23.weight'], ['module.conv24.weight', 'module.conv25.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv12.weight', 'module.conv13.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv19.weight', 'module.conv20.weight'], ['module.conv22.weight', 'module.conv23.weight'], ['module.conv24.weight', 'module.conv25.weight'], ['module.conv26.weight', 'module.conv27.weight'], ['module.conv28.weight', 'module.conv29.weight']]
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(3, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(5, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(5, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(5, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(12, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Count: 6764 ; 7320 ; 0.9240437158469945
[INFO] Storing checkpoint...

  4060
  22.98
Max memory: 196.8394752
 6.019s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
count0: 6764

Epoch: [21 | 25] LR: 1.585938
Epoch: [21][0/13]	Time 1.530 (1.530)	Data 1.419 (1.419)	Loss 1.6771 (1.6771)	Acc@1 43.818 (43.818)	Acc@5 90.837 (90.837)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [22 | 25] LR: 1.585938
Epoch: [22][0/13]	Time 0.396 (0.396)	Data 1.292 (1.292)	Loss 1.5994 (1.5994)	Acc@1 46.010 (46.010)	Acc@5 91.921 (91.921)
[INFO] Storing checkpoint...

Epoch: [23 | 25] LR: 1.585938
Epoch: [23][0/13]	Time 0.413 (0.413)	Data 1.221 (1.221)	Loss 1.5876 (1.5876)	Acc@1 45.493 (45.493)	Acc@5 92.611 (92.611)
[INFO] Storing checkpoint...

Epoch: [24 | 25] LR: 1.585938
Epoch: [24][0/13]	Time 0.404 (0.404)	Data 1.226 (1.226)	Loss 1.6067 (1.6067)	Acc@1 45.764 (45.764)	Acc@5 92.241 (92.241)
[INFO] Storing checkpoint...

Epoch: [25 | 25] LR: 1.585938
Epoch: [25][0/13]	Time 0.388 (0.388)	Data 1.135 (1.135)	Loss 1.5745 (1.5745)	Acc@1 46.675 (46.675)	Acc@5 92.586 (92.586)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 6490 ; 6764 ; 0.959491425192194
[INFO] Storing checkpoint...

  4060
  38.89
Max memory: 174.8845056
 5.209s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
count0: 6490

Epoch: [26 | 30] LR: 1.585938
Epoch: [26][0/13]	Time 1.595 (1.595)	Data 1.958 (1.958)	Loss 1.5384 (1.5384)	Acc@1 48.842 (48.842)	Acc@5 93.547 (93.547)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [27 | 30] LR: 1.585938
Epoch: [27][0/13]	Time 0.445 (0.445)	Data 1.206 (1.206)	Loss 1.5407 (1.5407)	Acc@1 47.808 (47.808)	Acc@5 93.596 (93.596)
[INFO] Storing checkpoint...

Epoch: [28 | 30] LR: 1.585938
Epoch: [28][0/13]	Time 0.392 (0.392)	Data 1.276 (1.276)	Loss 1.5196 (1.5196)	Acc@1 49.557 (49.557)	Acc@5 93.399 (93.399)
[INFO] Storing checkpoint...

Epoch: [29 | 30] LR: 1.585938
Epoch: [29][0/13]	Time 0.384 (0.384)	Data 1.201 (1.201)	Loss 1.4679 (1.4679)	Acc@1 50.493 (50.493)	Acc@5 93.966 (93.966)
[INFO] Storing checkpoint...

Epoch: [30 | 30] LR: 1.585938
Epoch: [30][0/13]	Time 0.390 (0.390)	Data 1.390 (1.390)	Loss 1.5863 (1.5863)	Acc@1 47.488 (47.488)	Acc@5 92.463 (92.463)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 6378 ; 6490 ; 0.9827426810477657
[INFO] Storing checkpoint...

  4060
  28.83
Max memory: 169.2132864
 5.089s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
count0: 6378

Epoch: [31 | 35] LR: 1.585938
Epoch: [31][0/13]	Time 1.776 (1.776)	Data 2.110 (2.110)	Loss 1.4627 (1.4627)	Acc@1 51.798 (51.798)	Acc@5 93.966 (93.966)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [32 | 35] LR: 1.585938
Epoch: [32][0/13]	Time 0.407 (0.407)	Data 1.242 (1.242)	Loss 1.4311 (1.4311)	Acc@1 52.882 (52.882)	Acc@5 94.483 (94.483)
[INFO] Storing checkpoint...

Epoch: [33 | 35] LR: 1.585938
Epoch: [33][0/13]	Time 0.352 (0.352)	Data 1.350 (1.350)	Loss 1.4582 (1.4582)	Acc@1 51.626 (51.626)	Acc@5 93.818 (93.818)
[INFO] Storing checkpoint...

Epoch: [34 | 35] LR: 1.585938
Epoch: [34][0/13]	Time 0.386 (0.386)	Data 1.264 (1.264)	Loss 1.4715 (1.4715)	Acc@1 50.887 (50.887)	Acc@5 93.719 (93.719)
[INFO] Storing checkpoint...

Epoch: [35 | 35] LR: 1.585938
Epoch: [35][0/13]	Time 0.361 (0.361)	Data 1.132 (1.132)	Loss 1.3700 (1.3700)	Acc@1 55.665 (55.665)	Acc@5 94.557 (94.557)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 6223 ; 6378 ; 0.975697710881154
[INFO] Storing checkpoint...

  4060
  27.68
Max memory: 162.5024
 4.787s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
count0: 6223

Epoch: [36 | 40] LR: 1.585938
Epoch: [36][0/13]	Time 1.651 (1.651)	Data 1.438 (1.438)	Loss 1.4394 (1.4394)	Acc@1 53.621 (53.621)	Acc@5 93.473 (93.473)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [37 | 40] LR: 1.585938
Epoch: [37][0/13]	Time 0.381 (0.381)	Data 1.316 (1.316)	Loss 1.4703 (1.4703)	Acc@1 50.148 (50.148)	Acc@5 94.113 (94.113)
[INFO] Storing checkpoint...

Epoch: [38 | 40] LR: 1.585938
Epoch: [38][0/13]	Time 0.354 (0.354)	Data 1.235 (1.235)	Loss 1.4707 (1.4707)	Acc@1 51.970 (51.970)	Acc@5 93.670 (93.670)
[INFO] Storing checkpoint...

Epoch: [39 | 40] LR: 1.585938
Epoch: [39][0/13]	Time 0.351 (0.351)	Data 1.294 (1.294)	Loss 1.4380 (1.4380)	Acc@1 52.315 (52.315)	Acc@5 94.039 (94.039)
[INFO] Storing checkpoint...

Epoch: [40 | 40] LR: 1.585938
Epoch: [40][0/13]	Time 0.385 (0.385)	Data 1.313 (1.313)	Loss 1.3861 (1.3861)	Acc@1 54.852 (54.852)	Acc@5 94.754 (94.754)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  36.9
Max memory: 162.2943232
 4.837s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
count0: 6223

Epoch: [41 | 45] LR: 1.585938
Epoch: [41][0/13]	Time 1.394 (1.394)	Data 1.679 (1.679)	Loss 1.3235 (1.3235)	Acc@1 57.660 (57.660)	Acc@5 95.813 (95.813)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [42 | 45] LR: 1.585938
Epoch: [42][0/13]	Time 0.331 (0.331)	Data 1.319 (1.319)	Loss 1.3496 (1.3496)	Acc@1 56.675 (56.675)	Acc@5 94.433 (94.433)
[INFO] Storing checkpoint...

Epoch: [43 | 45] LR: 1.585938
Epoch: [43][0/13]	Time 0.373 (0.373)	Data 1.344 (1.344)	Loss 1.3447 (1.3447)	Acc@1 55.862 (55.862)	Acc@5 95.493 (95.493)
[INFO] Storing checkpoint...

Epoch: [44 | 45] LR: 1.585938
Epoch: [44][0/13]	Time 0.375 (0.375)	Data 1.324 (1.324)	Loss 1.3683 (1.3683)	Acc@1 56.847 (56.847)	Acc@5 94.532 (94.532)
[INFO] Storing checkpoint...

Epoch: [45 | 45] LR: 1.585938
Epoch: [45][0/13]	Time 0.337 (0.337)	Data 1.336 (1.336)	Loss 1.3376 (1.3376)	Acc@1 57.882 (57.882)	Acc@5 94.877 (94.877)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  29.61
Max memory: 162.2943232
 4.851s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
count0: 6223

Epoch: [46 | 50] LR: 1.585938
Epoch: [46][0/13]	Time 1.432 (1.432)	Data 1.628 (1.628)	Loss 1.3641 (1.3641)	Acc@1 55.197 (55.197)	Acc@5 95.074 (95.074)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [47 | 50] LR: 1.585938
Epoch: [47][0/13]	Time 0.327 (0.327)	Data 1.274 (1.274)	Loss 1.3777 (1.3777)	Acc@1 54.606 (54.606)	Acc@5 94.606 (94.606)
[INFO] Storing checkpoint...

Epoch: [48 | 50] LR: 1.585938
Epoch: [48][0/13]	Time 0.366 (0.366)	Data 1.296 (1.296)	Loss 1.3451 (1.3451)	Acc@1 57.167 (57.167)	Acc@5 94.828 (94.828)
[INFO] Storing checkpoint...

Epoch: [49 | 50] LR: 1.585938
Epoch: [49][0/13]	Time 0.306 (0.306)	Data 1.385 (1.385)	Loss 1.3260 (1.3260)	Acc@1 57.611 (57.611)	Acc@5 95.517 (95.517)
[INFO] Storing checkpoint...

Epoch: [50 | 50] LR: 1.585938
Epoch: [50][0/13]	Time 0.330 (0.330)	Data 1.256 (1.256)	Loss 1.3545 (1.3545)	Acc@1 58.103 (58.103)	Acc@5 94.631 (94.631)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 6005 ; 6223 ; 0.9649686646312068
[INFO] Storing checkpoint...

  4060
  38.98
Max memory: 162.2943232
 4.660s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
count0: 6005

Epoch: [51 | 55] LR: 1.585938
Epoch: [51][0/13]	Time 1.359 (1.359)	Data 1.514 (1.514)	Loss 1.3216 (1.3216)	Acc@1 58.424 (58.424)	Acc@5 94.926 (94.926)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [52 | 55] LR: 1.585938
Epoch: [52][0/13]	Time 0.325 (0.325)	Data 1.252 (1.252)	Loss 1.3174 (1.3174)	Acc@1 56.601 (56.601)	Acc@5 95.542 (95.542)
[INFO] Storing checkpoint...

Epoch: [53 | 55] LR: 1.585938
Epoch: [53][0/13]	Time 0.369 (0.369)	Data 1.251 (1.251)	Loss 1.3409 (1.3409)	Acc@1 57.340 (57.340)	Acc@5 95.222 (95.222)
[INFO] Storing checkpoint...

Epoch: [54 | 55] LR: 1.585938
Epoch: [54][0/13]	Time 0.372 (0.372)	Data 1.299 (1.299)	Loss 1.3183 (1.3183)	Acc@1 58.325 (58.325)	Acc@5 95.517 (95.517)
[INFO] Storing checkpoint...

Epoch: [55 | 55] LR: 1.585938
Epoch: [55][0/13]	Time 0.386 (0.386)	Data 1.230 (1.230)	Loss 1.2949 (1.2949)	Acc@1 59.532 (59.532)	Acc@5 95.419 (95.419)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  32.2
Max memory: 162.0862464
 4.710s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
count0: 6005

Epoch: [56 | 60] LR: 1.585938
Epoch: [56][0/13]	Time 1.416 (1.416)	Data 1.246 (1.246)	Loss 1.2849 (1.2849)	Acc@1 58.842 (58.842)	Acc@5 95.640 (95.640)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [57 | 60] LR: 1.585938
Epoch: [57][0/13]	Time 0.477 (0.477)	Data 1.713 (1.713)	Loss 1.3075 (1.3075)	Acc@1 57.709 (57.709)	Acc@5 95.271 (95.271)
[INFO] Storing checkpoint...

Epoch: [58 | 60] LR: 1.585938
Epoch: [58][0/13]	Time 0.402 (0.402)	Data 1.214 (1.214)	Loss 1.2884 (1.2884)	Acc@1 59.163 (59.163)	Acc@5 95.099 (95.099)
[INFO] Storing checkpoint...

Epoch: [59 | 60] LR: 1.585938
Epoch: [59][0/13]	Time 0.366 (0.366)	Data 1.283 (1.283)	Loss 1.2540 (1.2540)	Acc@1 60.493 (60.493)	Acc@5 95.640 (95.640)
[INFO] Storing checkpoint...

Epoch: [60 | 60] LR: 1.585938
Epoch: [60][0/13]	Time 0.362 (0.362)	Data 1.205 (1.205)	Loss 1.3033 (1.3033)	Acc@1 58.867 (58.867)	Acc@5 94.975 (94.975)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  38.54
Max memory: 162.0862464
 4.586s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
count0: 6005

Epoch: [61 | 65] LR: 1.585938
Epoch: [61][0/13]	Time 1.342 (1.342)	Data 1.416 (1.416)	Loss 1.2275 (1.2275)	Acc@1 61.034 (61.034)	Acc@5 95.985 (95.985)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [62 | 65] LR: 1.585938
Epoch: [62][0/13]	Time 0.527 (0.527)	Data 1.659 (1.659)	Loss 1.3497 (1.3497)	Acc@1 56.823 (56.823)	Acc@5 94.680 (94.680)
[INFO] Storing checkpoint...

Epoch: [63 | 65] LR: 1.585938
Epoch: [63][0/13]	Time 0.313 (0.313)	Data 1.240 (1.240)	Loss 1.3647 (1.3647)	Acc@1 58.448 (58.448)	Acc@5 94.113 (94.113)
[INFO] Storing checkpoint...

Epoch: [64 | 65] LR: 1.585938
Epoch: [64][0/13]	Time 0.376 (0.376)	Data 1.280 (1.280)	Loss 1.3051 (1.3051)	Acc@1 60.000 (60.000)	Acc@5 95.369 (95.369)
[INFO] Storing checkpoint...

Epoch: [65 | 65] LR: 1.585938
Epoch: [65][0/13]	Time 0.313 (0.313)	Data 1.262 (1.262)	Loss 1.2655 (1.2655)	Acc@1 60.714 (60.714)	Acc@5 95.566 (95.566)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  35.74
Max memory: 162.0862464
 4.716s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
count0: 6005

Epoch: [66 | 70] LR: 1.585938
Epoch: [66][0/13]	Time 1.286 (1.286)	Data 1.404 (1.404)	Loss 1.2732 (1.2732)	Acc@1 59.901 (59.901)	Acc@5 95.665 (95.665)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [67 | 70] LR: 1.585938
Epoch: [67][0/13]	Time 0.380 (0.380)	Data 1.224 (1.224)	Loss 1.2621 (1.2621)	Acc@1 59.778 (59.778)	Acc@5 95.640 (95.640)
[INFO] Storing checkpoint...

Epoch: [68 | 70] LR: 1.585938
Epoch: [68][0/13]	Time 0.365 (0.365)	Data 1.305 (1.305)	Loss 1.2710 (1.2710)	Acc@1 59.655 (59.655)	Acc@5 95.665 (95.665)
[INFO] Storing checkpoint...

Epoch: [69 | 70] LR: 1.585938
Epoch: [69][0/13]	Time 0.316 (0.316)	Data 1.306 (1.306)	Loss 1.2435 (1.2435)	Acc@1 61.601 (61.601)	Acc@5 95.862 (95.862)
[INFO] Storing checkpoint...

Epoch: [70 | 70] LR: 1.585938
Epoch: [70][0/13]	Time 0.332 (0.332)	Data 1.295 (1.295)	Loss 1.2606 (1.2606)	Acc@1 59.606 (59.606)	Acc@5 95.788 (95.788)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv6.weight

 RM:  module.conv7.weight

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv13.weight', 'module.conv14.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv20.weight', 'module.conv21.weight'], ['module.conv22.weight', 'module.conv23.weight'], ['module.conv24.weight', 'module.conv25.weight'], ['module.conv26.weight', 'module.conv27.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv10.weight', 'module.conv11.weight'], ['module.conv13.weight', 'module.conv14.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv17.weight', 'module.conv18.weight'], ['module.conv20.weight', 'module.conv21.weight'], ['module.conv22.weight', 'module.conv23.weight'], ['module.conv24.weight', 'module.conv25.weight'], ['module.conv26.weight', 'module.conv27.weight']]
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (19): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(3, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(5, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(5, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(12, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(12, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(12, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): AdaptiveAvgPool2d(output_size=(1, 1))
    (55): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Count: 5943 ; 6005 ; 0.9896752706078268
[INFO] Storing checkpoint...

  4060
  52.32
Max memory: 162.0862464
 4.736s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
count0: 5943

Epoch: [71 | 75] LR: 1.585938
Epoch: [71][0/13]	Time 1.452 (1.452)	Data 1.217 (1.217)	Loss 1.2502 (1.2502)	Acc@1 59.975 (59.975)	Acc@5 95.640 (95.640)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [72 | 75] LR: 1.585938
Epoch: [72][0/13]	Time 0.378 (0.378)	Data 1.207 (1.207)	Loss 1.2793 (1.2793)	Acc@1 58.177 (58.177)	Acc@5 95.443 (95.443)
[INFO] Storing checkpoint...

Epoch: [73 | 75] LR: 1.585938
Epoch: [73][0/13]	Time 0.331 (0.331)	Data 1.660 (1.660)	Loss 1.2555 (1.2555)	Acc@1 60.493 (60.493)	Acc@5 95.739 (95.739)
[INFO] Storing checkpoint...

Epoch: [74 | 75] LR: 1.585938
Epoch: [74][0/13]	Time 0.347 (0.347)	Data 1.232 (1.232)	Loss 1.2299 (1.2299)	Acc@1 61.108 (61.108)	Acc@5 95.961 (95.961)
[INFO] Storing checkpoint...

Epoch: [75 | 75] LR: 1.585938
Epoch: [75][0/13]	Time 0.340 (0.340)	Data 1.302 (1.302)	Loss 1.2191 (1.2191)	Acc@1 61.700 (61.700)	Acc@5 96.010 (96.010)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  52.22
Max memory: 148.7815168
 4.432s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
count0: 5943

Epoch: [76 | 80] LR: 1.585938
Epoch: [76][0/13]	Time 1.233 (1.233)	Data 1.345 (1.345)	Loss 1.2883 (1.2883)	Acc@1 59.187 (59.187)	Acc@5 94.926 (94.926)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [77 | 80] LR: 1.585938
Epoch: [77][0/13]	Time 0.361 (0.361)	Data 1.225 (1.225)	Loss 1.2793 (1.2793)	Acc@1 59.680 (59.680)	Acc@5 95.788 (95.788)
[INFO] Storing checkpoint...

Epoch: [78 | 80] LR: 1.585938
Epoch: [78][0/13]	Time 0.373 (0.373)	Data 1.567 (1.567)	Loss 1.2364 (1.2364)	Acc@1 62.020 (62.020)	Acc@5 96.034 (96.034)
[INFO] Storing checkpoint...

Epoch: [79 | 80] LR: 1.585938
Epoch: [79][0/13]	Time 0.323 (0.323)	Data 1.245 (1.245)	Loss 1.1981 (1.1981)	Acc@1 62.020 (62.020)	Acc@5 96.527 (96.527)
[INFO] Storing checkpoint...

Epoch: [80 | 80] LR: 1.585938
Epoch: [80][0/13]	Time 0.355 (0.355)	Data 1.237 (1.237)	Loss 1.2404 (1.2404)	Acc@1 61.330 (61.330)	Acc@5 95.394 (95.394)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  29.49
Max memory: 148.7815168
 4.443s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
count0: 5943

Epoch: [81 | 85] LR: 1.585938
Epoch: [81][0/13]	Time 1.323 (1.323)	Data 1.355 (1.355)	Loss 1.2528 (1.2528)	Acc@1 61.108 (61.108)	Acc@5 95.394 (95.394)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [82 | 85] LR: 1.585938
Epoch: [82][0/13]	Time 0.329 (0.329)	Data 1.225 (1.225)	Loss 1.4753 (1.4753)	Acc@1 52.709 (52.709)	Acc@5 93.941 (93.941)
[INFO] Storing checkpoint...

Epoch: [83 | 85] LR: 1.585938
Epoch: [83][0/13]	Time 0.324 (0.324)	Data 1.290 (1.290)	Loss 1.3345 (1.3345)	Acc@1 58.522 (58.522)	Acc@5 95.296 (95.296)
[INFO] Storing checkpoint...

Epoch: [84 | 85] LR: 1.585938
Epoch: [84][0/13]	Time 0.374 (0.374)	Data 1.932 (1.932)	Loss 1.2600 (1.2600)	Acc@1 60.837 (60.837)	Acc@5 96.207 (96.207)
[INFO] Storing checkpoint...

Epoch: [85 | 85] LR: 1.585938
Epoch: [85][0/13]	Time 0.342 (0.342)	Data 1.284 (1.284)	Loss 1.2583 (1.2583)	Acc@1 61.034 (61.034)	Acc@5 95.665 (95.665)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  40.72
Max memory: 148.7815168
 4.512s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
count0: 5943

Epoch: [86 | 90] LR: 1.585938
Epoch: [86][0/13]	Time 1.299 (1.299)	Data 1.331 (1.331)	Loss 1.1798 (1.1798)	Acc@1 63.079 (63.079)	Acc@5 96.700 (96.700)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [87 | 90] LR: 1.585938
Epoch: [87][0/13]	Time 0.344 (0.344)	Data 1.304 (1.304)	Loss 1.2066 (1.2066)	Acc@1 61.897 (61.897)	Acc@5 96.650 (96.650)
[INFO] Storing checkpoint...

Epoch: [88 | 90] LR: 1.585938
Epoch: [88][0/13]	Time 0.367 (0.367)	Data 1.262 (1.262)	Loss 1.1985 (1.1985)	Acc@1 62.217 (62.217)	Acc@5 96.576 (96.576)
[INFO] Storing checkpoint...

Epoch: [89 | 90] LR: 1.585938
Epoch: [89][0/13]	Time 0.336 (0.336)	Data 1.538 (1.538)	Loss 1.1711 (1.1711)	Acc@1 63.448 (63.448)	Acc@5 96.724 (96.724)
[INFO] Storing checkpoint...

Epoch: [90 | 90] LR: 1.585938
Epoch: [90][0/13]	Time 0.366 (0.366)	Data 1.259 (1.259)	Loss 1.2060 (1.2060)	Acc@1 61.847 (61.847)	Acc@5 96.355 (96.355)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  38.73
Max memory: 148.7815168
 4.479s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
count0: 5943

Epoch: [91 | 95] LR: 1.585938
Epoch: [91][0/13]	Time 1.426 (1.426)	Data 1.284 (1.284)	Loss 1.2027 (1.2027)	Acc@1 62.020 (62.020)	Acc@5 96.305 (96.305)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [92 | 95] LR: 1.585938
Epoch: [92][0/13]	Time 0.360 (0.360)	Data 1.254 (1.254)	Loss 1.3738 (1.3738)	Acc@1 56.133 (56.133)	Acc@5 94.507 (94.507)
[INFO] Storing checkpoint...

Epoch: [93 | 95] LR: 1.585938
Epoch: [93][0/13]	Time 0.366 (0.366)	Data 1.262 (1.262)	Loss 1.3175 (1.3175)	Acc@1 58.990 (58.990)	Acc@5 95.172 (95.172)
[INFO] Storing checkpoint...

Epoch: [94 | 95] LR: 1.585938
Epoch: [94][0/13]	Time 0.337 (0.337)	Data 1.350 (1.350)	Loss 1.2244 (1.2244)	Acc@1 61.749 (61.749)	Acc@5 96.552 (96.552)
[INFO] Storing checkpoint...

Epoch: [95 | 95] LR: 1.585938
Epoch: [95][0/13]	Time 0.513 (0.513)	Data 1.886 (1.886)	Loss 1.3254 (1.3254)	Acc@1 58.350 (58.350)	Acc@5 95.123 (95.123)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  23.8
Max memory: 148.7815168
 5.261s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
count0: 5943

Epoch: [96 | 100] LR: 1.585938
Epoch: [96][0/13]	Time 1.451 (1.451)	Data 1.339 (1.339)	Loss 1.2775 (1.2775)	Acc@1 60.222 (60.222)	Acc@5 95.542 (95.542)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [97 | 100] LR: 1.585938
Epoch: [97][0/13]	Time 0.368 (0.368)	Data 1.228 (1.228)	Loss 1.3652 (1.3652)	Acc@1 57.241 (57.241)	Acc@5 95.049 (95.049)
[INFO] Storing checkpoint...

Epoch: [98 | 100] LR: 1.585938
Epoch: [98][0/13]	Time 0.302 (0.302)	Data 1.310 (1.310)	Loss 1.2620 (1.2620)	Acc@1 61.182 (61.182)	Acc@5 95.911 (95.911)
[INFO] Storing checkpoint...

Epoch: [99 | 100] LR: 1.585938
Epoch: [99][0/13]	Time 0.342 (0.342)	Data 1.219 (1.219)	Loss 1.2792 (1.2792)	Acc@1 60.222 (60.222)	Acc@5 95.911 (95.911)
[INFO] Storing checkpoint...

Epoch: [100 | 100] LR: 1.585938
Epoch: [100][0/13]	Time 0.322 (0.322)	Data 1.166 (1.166)	Loss 1.2666 (1.2666)	Acc@1 61.084 (61.084)	Acc@5 95.813 (95.813)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 5887 ; 5943 ; 0.9905771495877503
[INFO] Storing checkpoint...

  4060
  36.67
Max memory: 148.7815168
 4.371s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
count0: 5887

Epoch: [101 | 105] LR: 1.585938
Epoch: [101][0/13]	Time 1.341 (1.341)	Data 1.594 (1.594)	Loss 1.2237 (1.2237)	Acc@1 61.675 (61.675)	Acc@5 95.788 (95.788)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [102 | 105] LR: 1.585938
Epoch: [102][0/13]	Time 0.342 (0.342)	Data 1.327 (1.327)	Loss 1.3428 (1.3428)	Acc@1 57.857 (57.857)	Acc@5 94.310 (94.310)
[INFO] Storing checkpoint...

Epoch: [103 | 105] LR: 1.585938
Epoch: [103][0/13]	Time 0.331 (0.331)	Data 1.303 (1.303)	Loss 1.3174 (1.3174)	Acc@1 58.645 (58.645)	Acc@5 95.813 (95.813)
[INFO] Storing checkpoint...

Epoch: [104 | 105] LR: 1.585938
Epoch: [104][0/13]	Time 0.313 (0.313)	Data 1.235 (1.235)	Loss 1.2689 (1.2689)	Acc@1 60.862 (60.862)	Acc@5 96.059 (96.059)
[INFO] Storing checkpoint...

Epoch: [105 | 105] LR: 1.585938
Epoch: [105][0/13]	Time 0.349 (0.349)	Data 1.264 (1.264)	Loss 1.2885 (1.2885)	Acc@1 60.246 (60.246)	Acc@5 95.788 (95.788)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  38.97
Max memory: 145.4555648
 4.432s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
count0: 5887

Epoch: [106 | 110] LR: 1.585938
Epoch: [106][0/13]	Time 1.167 (1.167)	Data 1.257 (1.257)	Loss 1.2474 (1.2474)	Acc@1 62.069 (62.069)	Acc@5 95.714 (95.714)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [107 | 110] LR: 1.585938
Epoch: [107][0/13]	Time 0.320 (0.320)	Data 1.267 (1.267)	Loss 1.2201 (1.2201)	Acc@1 62.882 (62.882)	Acc@5 96.256 (96.256)
[INFO] Storing checkpoint...

Epoch: [108 | 110] LR: 1.585938
Epoch: [108][0/13]	Time 0.286 (0.286)	Data 1.337 (1.337)	Loss 1.2298 (1.2298)	Acc@1 62.709 (62.709)	Acc@5 95.837 (95.837)
[INFO] Storing checkpoint...

Epoch: [109 | 110] LR: 1.585938
Epoch: [109][0/13]	Time 0.338 (0.338)	Data 1.368 (1.368)	Loss 1.2116 (1.2116)	Acc@1 63.744 (63.744)	Acc@5 95.936 (95.936)
[INFO] Storing checkpoint...

Epoch: [110 | 110] LR: 1.585938
Epoch: [110][0/13]	Time 0.271 (0.271)	Data 1.297 (1.297)	Loss 1.2572 (1.2572)	Acc@1 61.552 (61.552)	Acc@5 95.690 (95.690)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  26.58
Max memory: 145.4555648
 4.251s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
count0: 5887

Epoch: [111 | 115] LR: 1.585938
Epoch: [111][0/13]	Time 1.199 (1.199)	Data 1.310 (1.310)	Loss 1.3506 (1.3506)	Acc@1 58.300 (58.300)	Acc@5 95.197 (95.197)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [112 | 115] LR: 1.585938
Epoch: [112][0/13]	Time 0.376 (0.376)	Data 1.261 (1.261)	Loss 1.3115 (1.3115)	Acc@1 58.793 (58.793)	Acc@5 95.443 (95.443)
[INFO] Storing checkpoint...

Epoch: [113 | 115] LR: 1.585938
Epoch: [113][0/13]	Time 0.382 (0.382)	Data 1.261 (1.261)	Loss 1.3066 (1.3066)	Acc@1 59.261 (59.261)	Acc@5 95.616 (95.616)
[INFO] Storing checkpoint...

Epoch: [114 | 115] LR: 1.585938
Epoch: [114][0/13]	Time 0.374 (0.374)	Data 1.266 (1.266)	Loss 1.2795 (1.2795)	Acc@1 60.640 (60.640)	Acc@5 95.813 (95.813)
[INFO] Storing checkpoint...

Epoch: [115 | 115] LR: 1.585938
Epoch: [115][0/13]	Time 0.346 (0.346)	Data 1.263 (1.263)	Loss 1.3084 (1.3084)	Acc@1 59.433 (59.433)	Acc@5 95.468 (95.468)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  40.26
Max memory: 145.4555648
 4.541s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
count0: 5887

Epoch: [116 | 120] LR: 1.585938
Epoch: [116][0/13]	Time 1.202 (1.202)	Data 1.276 (1.276)	Loss 1.3172 (1.3172)	Acc@1 58.941 (58.941)	Acc@5 95.690 (95.690)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [117 | 120] LR: 1.585938
Epoch: [117][0/13]	Time 0.388 (0.388)	Data 1.290 (1.290)	Loss 1.4845 (1.4845)	Acc@1 53.621 (53.621)	Acc@5 93.030 (93.030)
[INFO] Storing checkpoint...

Epoch: [118 | 120] LR: 1.585938
Epoch: [118][0/13]	Time 0.277 (0.277)	Data 1.344 (1.344)	Loss 1.4106 (1.4106)	Acc@1 55.739 (55.739)	Acc@5 94.458 (94.458)
[INFO] Storing checkpoint...

Epoch: [119 | 120] LR: 1.585938
Epoch: [119][0/13]	Time 0.329 (0.329)	Data 1.380 (1.380)	Loss 1.3329 (1.3329)	Acc@1 59.236 (59.236)	Acc@5 95.419 (95.419)
[INFO] Storing checkpoint...

Epoch: [120 | 120] LR: 1.585938
Epoch: [120][0/13]	Time 0.354 (0.354)	Data 1.323 (1.323)	Loss 1.2537 (1.2537)	Acc@1 62.438 (62.438)	Acc@5 96.305 (96.305)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  40.01
Max memory: 145.4555648
 4.481s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
count0: 5887

Epoch: [121 | 125] LR: 1.585938
Epoch: [121][0/13]	Time 1.149 (1.149)	Data 1.235 (1.235)	Loss 1.2796 (1.2796)	Acc@1 60.961 (60.961)	Acc@5 95.394 (95.394)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [122 | 125] LR: 1.585938
Epoch: [122][0/13]	Time 0.317 (0.317)	Data 1.249 (1.249)	Loss 1.3712 (1.3712)	Acc@1 57.365 (57.365)	Acc@5 94.680 (94.680)
[INFO] Storing checkpoint...

Epoch: [123 | 125] LR: 1.585938
Epoch: [123][0/13]	Time 0.262 (0.262)	Data 1.268 (1.268)	Loss 1.3155 (1.3155)	Acc@1 59.606 (59.606)	Acc@5 95.665 (95.665)
[INFO] Storing checkpoint...

Epoch: [124 | 125] LR: 1.585938
Epoch: [124][0/13]	Time 0.329 (0.329)	Data 1.207 (1.207)	Loss 1.3274 (1.3274)	Acc@1 59.360 (59.360)	Acc@5 95.468 (95.468)
[INFO] Storing checkpoint...

Epoch: [125 | 125] LR: 1.585938
Epoch: [125][0/13]	Time 0.292 (0.292)	Data 1.238 (1.238)	Loss 1.4039 (1.4039)	Acc@1 57.512 (57.512)	Acc@5 94.507 (94.507)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  21.15
Max memory: 145.4555648
 4.339s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
count0: 5887

Epoch: [126 | 130] LR: 1.585938
Epoch: [126][0/13]	Time 1.167 (1.167)	Data 1.368 (1.368)	Loss 1.3362 (1.3362)	Acc@1 60.049 (60.049)	Acc@5 94.951 (94.951)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [127 | 130] LR: 1.585938
Epoch: [127][0/13]	Time 0.353 (0.353)	Data 1.250 (1.250)	Loss 1.3036 (1.3036)	Acc@1 60.764 (60.764)	Acc@5 94.803 (94.803)
[INFO] Storing checkpoint...

Epoch: [128 | 130] LR: 1.585938
Epoch: [128][0/13]	Time 0.347 (0.347)	Data 1.321 (1.321)	Loss 1.4034 (1.4034)	Acc@1 57.266 (57.266)	Acc@5 94.754 (94.754)
[INFO] Storing checkpoint...

Epoch: [129 | 130] LR: 1.585938
Epoch: [129][0/13]	Time 0.315 (0.315)	Data 1.259 (1.259)	Loss 1.3296 (1.3296)	Acc@1 59.138 (59.138)	Acc@5 95.394 (95.394)
[INFO] Storing checkpoint...

Epoch: [130 | 130] LR: 1.585938
Epoch: [130][0/13]	Time 0.347 (0.347)	Data 1.319 (1.319)	Loss 1.3342 (1.3342)	Acc@1 59.606 (59.606)	Acc@5 95.443 (95.443)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  22.29
Max memory: 145.4555648
 4.497s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
count0: 5887

Epoch: [131 | 135] LR: 1.585938
Epoch: [131][0/13]	Time 1.168 (1.168)	Data 1.309 (1.309)	Loss 1.3081 (1.3081)	Acc@1 59.828 (59.828)	Acc@5 95.542 (95.542)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [132 | 135] LR: 1.585938
Epoch: [132][0/13]	Time 0.340 (0.340)	Data 1.245 (1.245)	Loss 1.2554 (1.2554)	Acc@1 62.759 (62.759)	Acc@5 95.985 (95.985)
[INFO] Storing checkpoint...

Epoch: [133 | 135] LR: 1.585938
Epoch: [133][0/13]	Time 0.273 (0.273)	Data 1.306 (1.306)	Loss 1.2719 (1.2719)	Acc@1 61.847 (61.847)	Acc@5 96.133 (96.133)
[INFO] Storing checkpoint...

Epoch: [134 | 135] LR: 1.585938
Epoch: [134][0/13]	Time 0.327 (0.327)	Data 1.288 (1.288)	Loss 1.2698 (1.2698)	Acc@1 61.379 (61.379)	Acc@5 95.837 (95.837)
[INFO] Storing checkpoint...

Epoch: [135 | 135] LR: 1.585938
Epoch: [135][0/13]	Time 0.319 (0.319)	Data 1.245 (1.245)	Loss 1.3656 (1.3656)	Acc@1 57.537 (57.537)	Acc@5 95.320 (95.320)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  28.71
Max memory: 145.4555648
 4.315s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
count0: 5887

Epoch: [136 | 140] LR: 1.585938
Epoch: [136][0/13]	Time 1.097 (1.097)	Data 1.445 (1.445)	Loss 1.3029 (1.3029)	Acc@1 59.877 (59.877)	Acc@5 95.862 (95.862)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [137 | 140] LR: 1.585938
Epoch: [137][0/13]	Time 0.350 (0.350)	Data 1.296 (1.296)	Loss 1.2763 (1.2763)	Acc@1 61.650 (61.650)	Acc@5 95.764 (95.764)
[INFO] Storing checkpoint...

Epoch: [138 | 140] LR: 1.585938
Epoch: [138][0/13]	Time 0.346 (0.346)	Data 1.301 (1.301)	Loss 1.2385 (1.2385)	Acc@1 62.094 (62.094)	Acc@5 96.453 (96.453)
[INFO] Storing checkpoint...

Epoch: [139 | 140] LR: 1.585938
Epoch: [139][0/13]	Time 0.330 (0.330)	Data 1.329 (1.329)	Loss 1.2553 (1.2553)	Acc@1 62.414 (62.414)	Acc@5 96.182 (96.182)
[INFO] Storing checkpoint...

Epoch: [140 | 140] LR: 1.585938
Epoch: [140][0/13]	Time 0.372 (0.372)	Data 1.218 (1.218)	Loss 1.2591 (1.2591)	Acc@1 61.256 (61.256)	Acc@5 96.330 (96.330)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
Count: 5831 ; 5887 ; 0.990487514863258
[INFO] Storing checkpoint...

  4060
  25.38
Max memory: 145.4555648
 4.435s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
count0: 5831

Epoch: [141 | 145] LR: 1.585938
Epoch: [141][0/13]	Time 1.293 (1.293)	Data 1.341 (1.341)	Loss 1.2444 (1.2444)	Acc@1 62.734 (62.734)	Acc@5 96.601 (96.601)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [142 | 145] LR: 1.585938
Epoch: [142][0/13]	Time 0.347 (0.347)	Data 1.327 (1.327)	Loss 1.3201 (1.3201)	Acc@1 60.000 (60.000)	Acc@5 95.493 (95.493)
[INFO] Storing checkpoint...

Epoch: [143 | 145] LR: 1.585938
Epoch: [143][0/13]	Time 0.285 (0.285)	Data 1.306 (1.306)	Loss 1.3552 (1.3552)	Acc@1 58.448 (58.448)	Acc@5 95.197 (95.197)
[INFO] Storing checkpoint...

Epoch: [144 | 145] LR: 1.585938
Epoch: [144][0/13]	Time 0.370 (0.370)	Data 1.226 (1.226)	Loss 1.3067 (1.3067)	Acc@1 59.236 (59.236)	Acc@5 95.837 (95.837)
[INFO] Storing checkpoint...

Epoch: [145 | 145] LR: 1.585938
Epoch: [145][0/13]	Time 0.304 (0.304)	Data 1.276 (1.276)	Loss 1.4416 (1.4416)	Acc@1 55.246 (55.246)	Acc@5 94.507 (94.507)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  14.04
Max memory: 142.2140928
 4.376s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
count0: 5831

Epoch: [146 | 150] LR: 1.585938
Epoch: [146][0/13]	Time 1.327 (1.327)	Data 1.323 (1.323)	Loss 1.3428 (1.3428)	Acc@1 59.852 (59.852)	Acc@5 94.778 (94.778)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [147 | 150] LR: 1.585938
Epoch: [147][0/13]	Time 0.343 (0.343)	Data 1.267 (1.267)	Loss 1.2657 (1.2657)	Acc@1 62.192 (62.192)	Acc@5 95.690 (95.690)
[INFO] Storing checkpoint...

Epoch: [148 | 150] LR: 1.585938
Epoch: [148][0/13]	Time 0.365 (0.365)	Data 1.213 (1.213)	Loss 1.5366 (1.5366)	Acc@1 52.488 (52.488)	Acc@5 93.030 (93.030)
[INFO] Storing checkpoint...

Epoch: [149 | 150] LR: 1.585938
Epoch: [149][0/13]	Time 0.346 (0.346)	Data 1.186 (1.186)	Loss 1.7645 (1.7645)	Acc@1 46.182 (46.182)	Acc@5 89.483 (89.483)
[INFO] Storing checkpoint...

Epoch: [150 | 150] LR: 1.585938
Epoch: [150][0/13]	Time 0.315 (0.315)	Data 1.209 (1.209)	Loss 1.6525 (1.6525)	Acc@1 49.384 (49.384)	Acc@5 91.675 (91.675)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv4.weight

 RM:  module.conv5.weight

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv11.weight', 'module.conv12.weight'], ['module.conv13.weight', 'module.conv14.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv18.weight', 'module.conv19.weight'], ['module.conv20.weight', 'module.conv21.weight'], ['module.conv22.weight', 'module.conv23.weight'], ['module.conv24.weight', 'module.conv25.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv8.weight', 'module.conv9.weight'], ['module.conv11.weight', 'module.conv12.weight'], ['module.conv13.weight', 'module.conv14.weight'], ['module.conv15.weight', 'module.conv16.weight'], ['module.conv18.weight', 'module.conv19.weight'], ['module.conv20.weight', 'module.conv21.weight'], ['module.conv22.weight', 'module.conv23.weight'], ['module.conv24.weight', 'module.conv25.weight']]
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(3, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (19): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(5, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (29): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(5, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(12, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(12, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(12, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): AdaptiveAvgPool2d(output_size=(1, 1))
    (51): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Count: 5769 ; 5831 ; 0.9893671754416052
[INFO] Storing checkpoint...

  4060
  29.87
Max memory: 142.2140928
 4.300s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
count0: 5769

Epoch: [151 | 155] LR: 1.585938
Epoch: [151][0/13]	Time 1.305 (1.305)	Data 1.303 (1.303)	Loss 1.6415 (1.6415)	Acc@1 50.616 (50.616)	Acc@5 91.847 (91.847)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [152 | 155] LR: 1.585938
Epoch: [152][0/13]	Time 0.256 (0.256)	Data 1.260 (1.260)	Loss 1.5329 (1.5329)	Acc@1 54.163 (54.163)	Acc@5 93.547 (93.547)
[INFO] Storing checkpoint...

Epoch: [153 | 155] LR: 1.585938
Epoch: [153][0/13]	Time 0.317 (0.317)	Data 1.293 (1.293)	Loss 1.4248 (1.4248)	Acc@1 56.527 (56.527)	Acc@5 94.310 (94.310)
[INFO] Storing checkpoint...

Epoch: [154 | 155] LR: 1.585938
Epoch: [154][0/13]	Time 0.293 (0.293)	Data 1.292 (1.292)	Loss 1.4299 (1.4299)	Acc@1 56.502 (56.502)	Acc@5 94.507 (94.507)
[INFO] Storing checkpoint...

Epoch: [155 | 155] LR: 1.585938
Epoch: [155][0/13]	Time 0.298 (0.298)	Data 1.307 (1.307)	Loss 1.3324 (1.3324)	Acc@1 60.837 (60.837)	Acc@5 95.222 (95.222)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv6.weight

 RM:  module.conv7.weight

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv9.weight', 'module.conv10.weight'], ['module.conv11.weight', 'module.conv12.weight'], ['module.conv13.weight', 'module.conv14.weight'], ['module.conv16.weight', 'module.conv17.weight'], ['module.conv18.weight', 'module.conv19.weight'], ['module.conv20.weight', 'module.conv21.weight'], ['module.conv22.weight', 'module.conv23.weight']]

Same Node:  [['module.conv2.weight', 'module.conv3.weight'], ['module.conv4.weight', 'module.conv5.weight'], ['module.conv6.weight', 'module.conv7.weight'], ['module.conv9.weight', 'module.conv10.weight'], ['module.conv11.weight', 'module.conv12.weight'], ['module.conv13.weight', 'module.conv14.weight'], ['module.conv16.weight', 'module.conv17.weight'], ['module.conv18.weight', 'module.conv19.weight'], ['module.conv20.weight', 'module.conv21.weight'], ['module.conv22.weight', 'module.conv23.weight']]
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(2, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (11): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(3, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(5, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(5, 5, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (25): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(5, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (29): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(12, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(12, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(12, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(5, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): AdaptiveAvgPool2d(output_size=(1, 1))
    (47): Linear(in_features=12, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Count: 5707 ; 5769 ; 0.9892529034494714
[INFO] Storing checkpoint...

  4060
  45.34
Max memory: 128.9288192
 4.070s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
count0: 5707

Epoch: [156 | 160] LR: 1.585938
Epoch: [156][0/13]	Time 1.294 (1.294)	Data 1.215 (1.215)	Loss 1.3029 (1.3029)	Acc@1 61.084 (61.084)	Acc@5 95.788 (95.788)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [157 | 160] LR: 1.585938
Epoch: [157][0/13]	Time 0.278 (0.278)	Data 1.258 (1.258)	Loss 1.4579 (1.4579)	Acc@1 56.330 (56.330)	Acc@5 94.212 (94.212)
[INFO] Storing checkpoint...

Epoch: [158 | 160] LR: 1.585938
Epoch: [158][0/13]	Time 0.255 (0.255)	Data 1.305 (1.305)	Loss 1.3287 (1.3287)	Acc@1 60.837 (60.837)	Acc@5 95.468 (95.468)
[INFO] Storing checkpoint...

Epoch: [159 | 160] LR: 1.585938
Epoch: [159][0/13]	Time 0.266 (0.266)	Data 1.192 (1.192)	Loss 1.4015 (1.4015)	Acc@1 56.552 (56.552)	Acc@5 95.197 (95.197)
[INFO] Storing checkpoint...

Epoch: [160 | 160] LR: 1.585938
Epoch: [160][0/13]	Time 0.262 (0.262)	Data 1.310 (1.310)	Loss 1.3393 (1.3393)	Acc@1 60.246 (60.246)	Acc@5 95.197 (95.197)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  42.52
Max memory: 115.6240896
 3.794s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
count0: 5707

Epoch: [161 | 165] LR: 1.585938
Epoch: [161][0/13]	Time 1.225 (1.225)	Data 1.383 (1.383)	Loss 1.3643 (1.3643)	Acc@1 59.483 (59.483)	Acc@5 94.360 (94.360)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [162 | 165] LR: 1.585938
Epoch: [162][0/13]	Time 0.261 (0.261)	Data 1.234 (1.234)	Loss 1.3631 (1.3631)	Acc@1 58.325 (58.325)	Acc@5 95.271 (95.271)
[INFO] Storing checkpoint...

Epoch: [163 | 165] LR: 1.585938
Epoch: [163][0/13]	Time 0.281 (0.281)	Data 1.277 (1.277)	Loss 1.3594 (1.3594)	Acc@1 58.818 (58.818)	Acc@5 94.828 (94.828)
[INFO] Storing checkpoint...

Epoch: [164 | 165] LR: 1.585938
Epoch: [164][0/13]	Time 0.277 (0.277)	Data 1.230 (1.230)	Loss 1.3092 (1.3092)	Acc@1 61.108 (61.108)	Acc@5 95.665 (95.665)
[INFO] Storing checkpoint...

Epoch: [165 | 165] LR: 1.585938
Epoch: [165][0/13]	Time 0.271 (0.271)	Data 1.270 (1.270)	Loss 1.3272 (1.3272)	Acc@1 60.369 (60.369)	Acc@5 95.222 (95.222)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  36.79
Max memory: 115.6240896
 3.784s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
count0: 5707

Epoch: [166 | 170] LR: 1.585938
Epoch: [166][0/13]	Time 1.183 (1.183)	Data 1.239 (1.239)	Loss 1.2934 (1.2934)	Acc@1 61.281 (61.281)	Acc@5 95.419 (95.419)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [167 | 170] LR: 1.585938
Epoch: [167][0/13]	Time 0.268 (0.268)	Data 1.315 (1.315)	Loss 1.3083 (1.3083)	Acc@1 60.123 (60.123)	Acc@5 95.837 (95.837)
[INFO] Storing checkpoint...

Epoch: [168 | 170] LR: 1.585938
Epoch: [168][0/13]	Time 0.258 (0.258)	Data 1.323 (1.323)	Loss 1.2644 (1.2644)	Acc@1 62.685 (62.685)	Acc@5 95.862 (95.862)
[INFO] Storing checkpoint...

Epoch: [169 | 170] LR: 1.585938
Epoch: [169][0/13]	Time 0.264 (0.264)	Data 1.270 (1.270)	Loss 1.2382 (1.2382)	Acc@1 63.153 (63.153)	Acc@5 96.330 (96.330)
[INFO] Storing checkpoint...

Epoch: [170 | 170] LR: 1.585938
Epoch: [170][0/13]	Time 0.221 (0.221)	Data 1.251 (1.251)	Loss 1.3149 (1.3149)	Acc@1 60.000 (60.000)	Acc@5 94.754 (94.754)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  18.9
Max memory: 115.6240896
 3.665s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
count0: 5707

Epoch: [171 | 175] LR: 1.585938
Epoch: [171][0/13]	Time 1.328 (1.328)	Data 1.212 (1.212)	Loss 1.2569 (1.2569)	Acc@1 62.833 (62.833)	Acc@5 95.862 (95.862)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [172 | 175] LR: 1.585938
Epoch: [172][0/13]	Time 0.245 (0.245)	Data 1.285 (1.285)	Loss 1.3374 (1.3374)	Acc@1 59.261 (59.261)	Acc@5 95.911 (95.911)
[INFO] Storing checkpoint...

Epoch: [173 | 175] LR: 1.585938
Epoch: [173][0/13]	Time 0.263 (0.263)	Data 1.301 (1.301)	Loss 1.2911 (1.2911)	Acc@1 61.601 (61.601)	Acc@5 95.887 (95.887)
[INFO] Storing checkpoint...

Epoch: [174 | 175] LR: 1.585938
Epoch: [174][0/13]	Time 0.216 (0.216)	Data 1.296 (1.296)	Loss 1.2728 (1.2728)	Acc@1 61.626 (61.626)	Acc@5 95.936 (95.936)
[INFO] Storing checkpoint...

Epoch: [175 | 175] LR: 1.585938
Epoch: [175][0/13]	Time 0.263 (0.263)	Data 1.273 (1.273)	Loss 1.3065 (1.3065)	Acc@1 60.074 (60.074)	Acc@5 95.862 (95.862)
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
[INFO] Storing checkpoint...

  4060
  52.09
Max memory: 115.6240896
 3.751s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
count0: 5707

Epoch: [176 | 180] LR: 1.585938
Epoch: [176][0/13]	Time 1.317 (1.317)	Data 1.270 (1.270)	Loss 1.2412 (1.2412)	Acc@1 63.596 (63.596)	Acc@5 96.108 (96.108)
/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha)
[INFO] Storing checkpoint...

Epoch: [177 | 180] LR: 1.585938
Epoch: [177][0/13]	Time 0.277 (0.277)	Data 1.287 (1.287)	Loss 1.2686 (1.2686)	Acc@1 61.379 (61.379)	Acc@5 96.182 (96.182)
[INFO] Storing checkpoint...

Epoch: [178 | 180] LR: 1.585938
Epoch: [178][0/13]	Time 0.279 (0.279)	Data 1.254 (1.254)	Loss 1.2808 (1.2808)	Acc@1 61.305 (61.305)	Acc@5 95.665 (95.665)
[INFO] Storing checkpoint...

Epoch: [179 | 180] LR: 1.585938
Epoch: [179][0/13]	Time 0.273 (0.273)	Data 1.272 (1.272)	Loss 1.2135 (1.2135)	Acc@1 63.350 (63.350)	Acc@5 96.576 (96.576)
[INFO] Storing checkpoint...

Epoch: [180 | 180] LR: 1.585938
Epoch: [180][0/13]	Time 0.302 (0.302)	Data 1.235 (1.235)	Loss 1.2528 (1.2528)	Acc@1 62.488 (62.488)	Acc@5 96.478 (96.478)
[INFO] Storing checkpoint...

  4060
  30.69
Max memory: 115.6240896
 3.808s  