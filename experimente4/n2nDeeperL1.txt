Net2Net Deeper 1
j: 1 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 8121
Files already downloaded and verified
width: 8

Arch Num:  [[1, 1, 1, 1, 1], [2, 1, 1, 1, 1], [2, 1, 1, 1, 1]]
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): AdaptiveAvgPool2d(output_size=(1, 1))
    (37): Linear(in_features=32, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.0292352
lr: 0.1
lr: 0.1
1
Epoche:1/5; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.074 (0.074)	Data 0.285 (0.285)	Loss 2.4551 (2.4551)	Acc@1 8.594 (8.594)	Acc@5 48.047 (48.047)
Epoch: [1][64/196]	Time 0.033 (0.036)	Data 0.000 (0.005)	Loss 1.7947 (1.9856)	Acc@1 32.422 (25.054)	Acc@5 85.938 (77.867)
Epoch: [1][128/196]	Time 0.040 (0.037)	Data 0.000 (0.002)	Loss 1.7117 (1.8720)	Acc@1 34.375 (28.737)	Acc@5 87.109 (82.401)
Epoch: [1][192/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 1.6761 (1.8138)	Acc@1 37.500 (31.005)	Acc@5 87.891 (84.363)
Max memory in training epoch: 5.2850176
lr: 0.1
lr: 0.1
1
Epoche:2/5; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.037 (0.037)	Data 0.302 (0.302)	Loss 1.6711 (1.6711)	Acc@1 33.594 (33.594)	Acc@5 89.062 (89.062)
Epoch: [2][64/196]	Time 0.036 (0.036)	Data 0.000 (0.005)	Loss 1.5942 (1.6421)	Acc@1 39.062 (38.029)	Acc@5 89.453 (89.237)
Epoch: [2][128/196]	Time 0.036 (0.035)	Data 0.000 (0.003)	Loss 1.5632 (1.6250)	Acc@1 39.453 (39.314)	Acc@5 92.188 (89.453)
Epoch: [2][192/196]	Time 0.032 (0.035)	Data 0.000 (0.002)	Loss 1.5285 (1.5981)	Acc@1 43.359 (40.382)	Acc@5 91.797 (90.048)
Max memory in training epoch: 5.2850176
lr: 0.1
lr: 0.1
1
Epoche:3/5; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.047 (0.047)	Data 0.279 (0.279)	Loss 1.4687 (1.4687)	Acc@1 46.094 (46.094)	Acc@5 91.797 (91.797)
Epoch: [3][64/196]	Time 0.036 (0.036)	Data 0.000 (0.004)	Loss 1.5342 (1.5192)	Acc@1 44.922 (43.750)	Acc@5 90.625 (91.520)
Epoch: [3][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 1.4326 (1.4929)	Acc@1 46.094 (44.734)	Acc@5 91.797 (91.888)
Epoch: [3][192/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 1.3843 (1.4811)	Acc@1 49.609 (45.282)	Acc@5 94.922 (92.121)
Max memory in training epoch: 5.2850176
lr: 0.1
lr: 0.1
1
Epoche:4/5; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.056 (0.056)	Data 0.290 (0.290)	Loss 1.3372 (1.3372)	Acc@1 52.344 (52.344)	Acc@5 92.578 (92.578)
Epoch: [4][64/196]	Time 0.038 (0.036)	Data 0.000 (0.005)	Loss 1.5297 (1.4302)	Acc@1 40.625 (47.776)	Acc@5 91.016 (92.734)
Epoch: [4][128/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 1.4077 (1.4134)	Acc@1 44.141 (48.604)	Acc@5 93.750 (92.969)
Epoch: [4][192/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 1.2832 (1.4019)	Acc@1 54.297 (49.041)	Acc@5 94.531 (93.114)
Max memory in training epoch: 5.2850176
lr: 0.1
lr: 0.1
1
Epoche:5/5; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.046 (0.046)	Data 0.272 (0.272)	Loss 1.2709 (1.2709)	Acc@1 52.734 (52.734)	Acc@5 95.312 (95.312)
Epoch: [5][64/196]	Time 0.040 (0.037)	Data 0.000 (0.004)	Loss 1.3383 (1.3488)	Acc@1 53.906 (50.986)	Acc@5 91.016 (93.786)
Epoch: [5][128/196]	Time 0.047 (0.036)	Data 0.000 (0.002)	Loss 1.3541 (1.3597)	Acc@1 47.266 (50.621)	Acc@5 93.750 (93.680)
Epoch: [5][192/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 1.3334 (1.3546)	Acc@1 50.000 (50.909)	Acc@5 97.266 (93.744)
Max memory in training epoch: 5.2850176


now deeper1


Stage:  0


	Block:  0
size:8, 8, 3, 3; j: 2
conv: 5
layerin This Block: 2
bn: 7
Länge der ModuleListe: 40
j: 8; i: 3


	Block:  1
size:8, 8, 3, 3; j: 10
conv: 13
layerin This Block: 2
bn: 15
Länge der ModuleListe: 42
j: 16; i: 3


	Block:  2
size:16, 8, 3, 3; j: 18
conv: 21
layerin This Block: 2
bn: 23
Länge der ModuleListe: 44
j: 24; i: 3


	Block:  3
size:16, 16, 3, 3; j: 26
conv: 29
layerin This Block: 2
bn: 31
Länge der ModuleListe: 46
j: 32; i: 3


	Block:  4
size:32, 16, 3, 3; j: 34
conv: 37
layerin This Block: 2
bn: 39
Länge der ModuleListe: 48
j: 40; i: 3


Stage:  1


	Block:  0
size:32, 32, 3, 3; j: 42
conv: 45
layerin This Block: 3
bn: 47
Länge der ModuleListe: 50
j: 48; i: 3


	Block:  1
Traceback (most recent call last):
  File "main.py", line 965, in <module>
    main()
  File "main.py", line 545, in main
    model = model.deeper()
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 1027, in deeper
    module = self.module_list[j]
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/container.py", line 147, in __getitem__
    return self._modules[self._get_abs_string_index(idx)]
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/container.py", line 137, in _get_abs_string_index
    raise IndexError('index {} is out of range'.format(idx))
IndexError: index 50 is out of range
j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 4900
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 521
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:521/525; Lr: 0.0010000000000000002
batch Size 256
/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'src.n2n.N2N' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
Epoch: [521][0/196]	Time 0.087 (0.087)	Data 0.225 (0.225)	Loss 0.9152 (0.9152)	Acc@1 67.188 (67.188)	Acc@5 95.312 (95.312)
Epoch: [521][64/196]	Time 0.040 (0.039)	Data 0.000 (0.004)	Loss 0.9319 (0.8891)	Acc@1 66.797 (69.020)	Acc@5 98.828 (97.440)
Epoch: [521][128/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.9190 (0.8973)	Acc@1 70.312 (69.023)	Acc@5 96.875 (97.423)
Epoch: [521][192/196]	Time 0.033 (0.037)	Data 0.000 (0.001)	Loss 0.7751 (0.8987)	Acc@1 73.828 (68.772)	Acc@5 98.438 (97.500)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:522/525; Lr: 0.0010000000000000002
batch Size 256
Epoch: [522][0/196]	Time 0.050 (0.050)	Data 0.247 (0.247)	Loss 0.8970 (0.8970)	Acc@1 68.359 (68.359)	Acc@5 97.656 (97.656)
Epoch: [522][64/196]	Time 0.033 (0.037)	Data 0.000 (0.004)	Loss 0.8717 (0.8918)	Acc@1 69.922 (69.081)	Acc@5 98.047 (97.614)
Epoch: [522][128/196]	Time 0.036 (0.037)	Data 0.000 (0.002)	Loss 0.9563 (0.8950)	Acc@1 67.188 (68.995)	Acc@5 98.047 (97.668)
Epoch: [522][192/196]	Time 0.031 (0.037)	Data 0.000 (0.001)	Loss 0.8103 (0.8965)	Acc@1 75.781 (69.007)	Acc@5 97.266 (97.626)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:523/525; Lr: 0.0010000000000000002
batch Size 256
Epoch: [523][0/196]	Time 0.057 (0.057)	Data 0.269 (0.269)	Loss 0.8500 (0.8500)	Acc@1 71.875 (71.875)	Acc@5 98.047 (98.047)
Epoch: [523][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.8178 (0.9042)	Acc@1 69.922 (68.431)	Acc@5 98.828 (97.488)
Epoch: [523][128/196]	Time 0.039 (0.037)	Data 0.000 (0.002)	Loss 0.9054 (0.9008)	Acc@1 70.312 (68.423)	Acc@5 97.656 (97.562)
Epoch: [523][192/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.8702 (0.9016)	Acc@1 70.312 (68.384)	Acc@5 96.875 (97.543)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:524/525; Lr: 0.0010000000000000002
batch Size 256
Epoch: [524][0/196]	Time 0.061 (0.061)	Data 0.248 (0.248)	Loss 0.9348 (0.9348)	Acc@1 67.188 (67.188)	Acc@5 98.047 (98.047)
Epoch: [524][64/196]	Time 0.030 (0.034)	Data 0.000 (0.004)	Loss 0.9258 (0.9020)	Acc@1 65.625 (68.870)	Acc@5 98.438 (97.620)
Epoch: [524][128/196]	Time 0.030 (0.035)	Data 0.000 (0.002)	Loss 1.0535 (0.9041)	Acc@1 67.578 (68.768)	Acc@5 96.484 (97.599)
Epoch: [524][192/196]	Time 0.031 (0.035)	Data 0.000 (0.001)	Loss 0.8852 (0.9001)	Acc@1 67.969 (68.845)	Acc@5 98.047 (97.630)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:525/525; Lr: 0.0010000000000000002
batch Size 256
Epoch: [525][0/196]	Time 0.067 (0.067)	Data 0.272 (0.272)	Loss 0.8815 (0.8815)	Acc@1 73.438 (73.438)	Acc@5 98.047 (98.047)
Epoch: [525][64/196]	Time 0.037 (0.038)	Data 0.000 (0.004)	Loss 0.9096 (0.9027)	Acc@1 68.750 (68.834)	Acc@5 97.656 (97.506)
Epoch: [525][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.8108 (0.8985)	Acc@1 74.219 (68.980)	Acc@5 98.438 (97.526)
Epoch: [525][192/196]	Time 0.046 (0.037)	Data 0.000 (0.002)	Loss 0.8929 (0.8986)	Acc@1 71.484 (69.048)	Acc@5 97.656 (97.549)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.95
Max memory: 7.7508608
 7.511s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 4427
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 526
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:526/530; Lr: 0.0010000000000000002
batch Size 256
Epoch: [526][0/196]	Time 0.070 (0.070)	Data 0.226 (0.226)	Loss 0.9227 (0.9227)	Acc@1 67.969 (67.969)	Acc@5 95.703 (95.703)
Epoch: [526][64/196]	Time 0.046 (0.038)	Data 0.000 (0.004)	Loss 0.8576 (0.8915)	Acc@1 71.875 (69.339)	Acc@5 98.828 (97.704)
Epoch: [526][128/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.8786 (0.8956)	Acc@1 69.141 (68.889)	Acc@5 97.266 (97.611)
Epoch: [526][192/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 0.9477 (0.8993)	Acc@1 67.969 (68.712)	Acc@5 96.484 (97.620)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:527/530; Lr: 0.0010000000000000002
batch Size 256
Epoch: [527][0/196]	Time 0.041 (0.041)	Data 0.263 (0.263)	Loss 0.8460 (0.8460)	Acc@1 68.750 (68.750)	Acc@5 98.828 (98.828)
Epoch: [527][64/196]	Time 0.030 (0.037)	Data 0.000 (0.004)	Loss 0.8943 (0.8996)	Acc@1 67.969 (68.528)	Acc@5 98.438 (97.668)
Epoch: [527][128/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 0.9026 (0.9012)	Acc@1 67.578 (68.414)	Acc@5 97.266 (97.472)
Epoch: [527][192/196]	Time 0.055 (0.037)	Data 0.000 (0.002)	Loss 0.7929 (0.8997)	Acc@1 71.875 (68.663)	Acc@5 99.219 (97.527)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:528/530; Lr: 0.0010000000000000002
batch Size 256
Epoch: [528][0/196]	Time 0.044 (0.044)	Data 0.288 (0.288)	Loss 0.8913 (0.8913)	Acc@1 70.703 (70.703)	Acc@5 96.875 (96.875)
Epoch: [528][64/196]	Time 0.049 (0.036)	Data 0.000 (0.005)	Loss 0.8477 (0.8962)	Acc@1 71.094 (69.056)	Acc@5 96.484 (97.668)
Epoch: [528][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8650 (0.8959)	Acc@1 70.312 (69.253)	Acc@5 97.266 (97.599)
Epoch: [528][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.8234 (0.8978)	Acc@1 73.438 (68.987)	Acc@5 98.828 (97.571)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:529/530; Lr: 0.0010000000000000002
batch Size 256
Epoch: [529][0/196]	Time 0.053 (0.053)	Data 0.322 (0.322)	Loss 0.9378 (0.9378)	Acc@1 66.016 (66.016)	Acc@5 98.438 (98.438)
Epoch: [529][64/196]	Time 0.043 (0.036)	Data 0.000 (0.005)	Loss 0.9628 (0.8991)	Acc@1 67.969 (68.840)	Acc@5 96.875 (97.644)
Epoch: [529][128/196]	Time 0.047 (0.036)	Data 0.000 (0.003)	Loss 0.8922 (0.8992)	Acc@1 68.750 (68.938)	Acc@5 96.875 (97.584)
Epoch: [529][192/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.8971 (0.8977)	Acc@1 68.750 (68.977)	Acc@5 99.219 (97.561)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:530/530; Lr: 0.0010000000000000002
batch Size 256
Epoch: [530][0/196]	Time 0.053 (0.053)	Data 0.336 (0.336)	Loss 0.8837 (0.8837)	Acc@1 69.922 (69.922)	Acc@5 96.094 (96.094)
Epoch: [530][64/196]	Time 0.037 (0.037)	Data 0.000 (0.005)	Loss 0.8050 (0.9070)	Acc@1 69.922 (68.293)	Acc@5 97.656 (97.560)
Epoch: [530][128/196]	Time 0.031 (0.037)	Data 0.000 (0.003)	Loss 0.9689 (0.8977)	Acc@1 67.969 (68.856)	Acc@5 98.047 (97.578)
Epoch: [530][192/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 1.0252 (0.8966)	Acc@1 66.016 (68.839)	Acc@5 96.484 (97.575)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.26
Max memory: 7.7508608
 7.611s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 1544
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 531
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:531/535; Lr: 0.0010000000000000002
batch Size 256
Epoch: [531][0/196]	Time 0.074 (0.074)	Data 0.244 (0.244)	Loss 0.9472 (0.9472)	Acc@1 67.188 (67.188)	Acc@5 96.094 (96.094)
Epoch: [531][64/196]	Time 0.036 (0.038)	Data 0.000 (0.004)	Loss 0.9316 (0.9087)	Acc@1 69.141 (68.113)	Acc@5 96.484 (97.638)
Epoch: [531][128/196]	Time 0.039 (0.037)	Data 0.000 (0.002)	Loss 0.8783 (0.9003)	Acc@1 70.312 (68.699)	Acc@5 97.656 (97.602)
Epoch: [531][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9224 (0.8998)	Acc@1 70.312 (68.730)	Acc@5 97.266 (97.589)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:532/535; Lr: 0.0010000000000000002
batch Size 256
Epoch: [532][0/196]	Time 0.054 (0.054)	Data 0.302 (0.302)	Loss 1.0136 (1.0136)	Acc@1 64.062 (64.062)	Acc@5 97.266 (97.266)
Epoch: [532][64/196]	Time 0.042 (0.037)	Data 0.000 (0.005)	Loss 0.7477 (0.9068)	Acc@1 73.047 (68.606)	Acc@5 98.828 (97.476)
Epoch: [532][128/196]	Time 0.037 (0.037)	Data 0.000 (0.003)	Loss 0.8270 (0.9020)	Acc@1 68.359 (68.847)	Acc@5 98.047 (97.502)
Epoch: [532][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8641 (0.8980)	Acc@1 70.703 (68.912)	Acc@5 97.656 (97.616)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:533/535; Lr: 0.0010000000000000002
batch Size 256
Epoch: [533][0/196]	Time 0.066 (0.066)	Data 0.274 (0.274)	Loss 0.8166 (0.8166)	Acc@1 67.578 (67.578)	Acc@5 98.438 (98.438)
Epoch: [533][64/196]	Time 0.034 (0.036)	Data 0.000 (0.004)	Loss 0.8522 (0.8964)	Acc@1 69.922 (68.858)	Acc@5 100.000 (97.590)
Epoch: [533][128/196]	Time 0.040 (0.036)	Data 0.000 (0.002)	Loss 0.9747 (0.8959)	Acc@1 67.188 (68.971)	Acc@5 98.438 (97.638)
Epoch: [533][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8965 (0.8975)	Acc@1 70.312 (68.894)	Acc@5 98.047 (97.614)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:534/535; Lr: 0.0010000000000000002
batch Size 256
Epoch: [534][0/196]	Time 0.043 (0.043)	Data 0.296 (0.296)	Loss 0.9104 (0.9104)	Acc@1 69.141 (69.141)	Acc@5 96.094 (96.094)
Epoch: [534][64/196]	Time 0.042 (0.037)	Data 0.000 (0.005)	Loss 0.9791 (0.9013)	Acc@1 68.750 (69.069)	Acc@5 97.266 (97.398)
Epoch: [534][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8769 (0.8975)	Acc@1 71.875 (68.895)	Acc@5 96.875 (97.559)
Epoch: [534][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 1.0238 (0.8961)	Acc@1 66.406 (68.928)	Acc@5 96.094 (97.624)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:535/535; Lr: 0.0010000000000000002
batch Size 256
Epoch: [535][0/196]	Time 0.050 (0.050)	Data 0.297 (0.297)	Loss 0.8718 (0.8718)	Acc@1 71.094 (71.094)	Acc@5 98.047 (98.047)
Epoch: [535][64/196]	Time 0.033 (0.036)	Data 0.000 (0.005)	Loss 0.9182 (0.8914)	Acc@1 73.438 (68.996)	Acc@5 96.094 (97.740)
Epoch: [535][128/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.8297 (0.9019)	Acc@1 68.359 (68.580)	Acc@5 99.219 (97.623)
Epoch: [535][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.9481 (0.9018)	Acc@1 67.969 (68.588)	Acc@5 95.312 (97.577)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.77
Max memory: 7.7508608
 7.346s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 357
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 536
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:536/540; Lr: 0.0010000000000000002
batch Size 256
Epoch: [536][0/196]	Time 0.061 (0.061)	Data 0.337 (0.337)	Loss 0.8528 (0.8528)	Acc@1 66.797 (66.797)	Acc@5 98.438 (98.438)
Epoch: [536][64/196]	Time 0.041 (0.036)	Data 0.000 (0.005)	Loss 0.9280 (0.8921)	Acc@1 67.188 (69.056)	Acc@5 98.828 (97.788)
Epoch: [536][128/196]	Time 0.040 (0.037)	Data 0.000 (0.003)	Loss 0.9244 (0.8936)	Acc@1 67.188 (69.016)	Acc@5 97.266 (97.705)
Epoch: [536][192/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.8678 (0.8984)	Acc@1 68.359 (68.825)	Acc@5 98.828 (97.608)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:537/540; Lr: 0.0010000000000000002
batch Size 256
Epoch: [537][0/196]	Time 0.046 (0.046)	Data 0.283 (0.283)	Loss 0.9109 (0.9109)	Acc@1 67.969 (67.969)	Acc@5 97.656 (97.656)
Epoch: [537][64/196]	Time 0.029 (0.037)	Data 0.000 (0.005)	Loss 0.8905 (0.8952)	Acc@1 71.484 (69.111)	Acc@5 96.875 (97.512)
Epoch: [537][128/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.9698 (0.9044)	Acc@1 67.188 (68.683)	Acc@5 96.875 (97.505)
Epoch: [537][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9039 (0.8995)	Acc@1 66.797 (68.898)	Acc@5 97.656 (97.587)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:538/540; Lr: 0.0010000000000000002
batch Size 256
Epoch: [538][0/196]	Time 0.033 (0.033)	Data 0.236 (0.236)	Loss 0.8899 (0.8899)	Acc@1 71.484 (71.484)	Acc@5 97.266 (97.266)
Epoch: [538][64/196]	Time 0.036 (0.036)	Data 0.000 (0.004)	Loss 0.9295 (0.8971)	Acc@1 66.797 (68.852)	Acc@5 96.875 (97.338)
Epoch: [538][128/196]	Time 0.029 (0.035)	Data 0.000 (0.002)	Loss 0.9435 (0.9025)	Acc@1 64.062 (68.844)	Acc@5 96.875 (97.475)
Epoch: [538][192/196]	Time 0.033 (0.035)	Data 0.000 (0.001)	Loss 0.8314 (0.8971)	Acc@1 73.438 (69.021)	Acc@5 97.266 (97.531)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:539/540; Lr: 0.0010000000000000002
batch Size 256
Epoch: [539][0/196]	Time 0.047 (0.047)	Data 0.305 (0.305)	Loss 0.9282 (0.9282)	Acc@1 65.625 (65.625)	Acc@5 98.047 (98.047)
Epoch: [539][64/196]	Time 0.038 (0.037)	Data 0.000 (0.005)	Loss 1.0190 (0.8982)	Acc@1 67.969 (69.147)	Acc@5 94.922 (97.692)
Epoch: [539][128/196]	Time 0.038 (0.037)	Data 0.000 (0.003)	Loss 0.9072 (0.8992)	Acc@1 68.750 (69.119)	Acc@5 98.047 (97.647)
Epoch: [539][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9514 (0.8999)	Acc@1 64.453 (68.963)	Acc@5 98.047 (97.557)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:540/540; Lr: 0.0010000000000000002
batch Size 256
Epoch: [540][0/196]	Time 0.061 (0.061)	Data 0.303 (0.303)	Loss 0.7858 (0.7858)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [540][64/196]	Time 0.035 (0.036)	Data 0.000 (0.005)	Loss 0.9282 (0.8878)	Acc@1 64.453 (69.255)	Acc@5 97.266 (97.764)
Epoch: [540][128/196]	Time 0.055 (0.036)	Data 0.000 (0.003)	Loss 1.0208 (0.8972)	Acc@1 65.234 (68.723)	Acc@5 94.922 (97.665)
Epoch: [540][192/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.8286 (0.8986)	Acc@1 72.266 (68.752)	Acc@5 97.266 (97.636)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.01
Max memory: 7.7508608
 7.401s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 1855
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 541
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:541/545; Lr: 0.0010000000000000002
batch Size 256
Epoch: [541][0/196]	Time 0.093 (0.093)	Data 0.291 (0.291)	Loss 0.9064 (0.9064)	Acc@1 69.141 (69.141)	Acc@5 98.828 (98.828)
Epoch: [541][64/196]	Time 0.035 (0.037)	Data 0.000 (0.005)	Loss 0.8321 (0.8964)	Acc@1 73.438 (69.267)	Acc@5 98.047 (97.566)
Epoch: [541][128/196]	Time 0.040 (0.037)	Data 0.000 (0.002)	Loss 0.8829 (0.8951)	Acc@1 69.922 (68.820)	Acc@5 96.875 (97.653)
Epoch: [541][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.9512 (0.8967)	Acc@1 64.453 (68.774)	Acc@5 96.875 (97.624)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:542/545; Lr: 0.0010000000000000002
batch Size 256
Epoch: [542][0/196]	Time 0.048 (0.048)	Data 0.312 (0.312)	Loss 0.8359 (0.8359)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [542][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.9518 (0.9065)	Acc@1 69.531 (68.780)	Acc@5 96.484 (97.488)
Epoch: [542][128/196]	Time 0.037 (0.037)	Data 0.000 (0.003)	Loss 0.9379 (0.8966)	Acc@1 62.109 (69.110)	Acc@5 98.828 (97.562)
Epoch: [542][192/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.9737 (0.9009)	Acc@1 66.406 (68.835)	Acc@5 96.484 (97.531)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:543/545; Lr: 0.0010000000000000002
batch Size 256
Epoch: [543][0/196]	Time 0.045 (0.045)	Data 0.206 (0.206)	Loss 0.8748 (0.8748)	Acc@1 67.969 (67.969)	Acc@5 97.656 (97.656)
Epoch: [543][64/196]	Time 0.038 (0.034)	Data 0.000 (0.003)	Loss 0.8545 (0.8954)	Acc@1 69.531 (69.020)	Acc@5 98.047 (97.698)
Epoch: [543][128/196]	Time 0.039 (0.035)	Data 0.000 (0.002)	Loss 1.0302 (0.8968)	Acc@1 62.500 (69.074)	Acc@5 94.922 (97.620)
Epoch: [543][192/196]	Time 0.038 (0.035)	Data 0.000 (0.001)	Loss 0.9430 (0.8985)	Acc@1 69.141 (68.934)	Acc@5 96.875 (97.559)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:544/545; Lr: 0.0010000000000000002
batch Size 256
Epoch: [544][0/196]	Time 0.043 (0.043)	Data 0.284 (0.284)	Loss 0.9711 (0.9711)	Acc@1 67.578 (67.578)	Acc@5 97.266 (97.266)
Epoch: [544][64/196]	Time 0.034 (0.036)	Data 0.000 (0.005)	Loss 0.8663 (0.8992)	Acc@1 69.141 (68.756)	Acc@5 97.266 (97.524)
Epoch: [544][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8762 (0.9003)	Acc@1 71.875 (68.914)	Acc@5 97.266 (97.559)
Epoch: [544][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 1.0093 (0.8984)	Acc@1 62.109 (68.987)	Acc@5 97.656 (97.579)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:545/545; Lr: 0.0010000000000000002
batch Size 256
Epoch: [545][0/196]	Time 0.045 (0.045)	Data 0.300 (0.300)	Loss 0.9293 (0.9293)	Acc@1 69.922 (69.922)	Acc@5 96.484 (96.484)
Epoch: [545][64/196]	Time 0.041 (0.037)	Data 0.000 (0.005)	Loss 0.9016 (0.8982)	Acc@1 68.359 (69.020)	Acc@5 96.875 (97.662)
Epoch: [545][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.9006 (0.8922)	Acc@1 70.312 (69.380)	Acc@5 96.875 (97.620)
Epoch: [545][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9053 (0.8958)	Acc@1 69.922 (69.151)	Acc@5 95.703 (97.573)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.76
Max memory: 7.7508608
 7.448s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3123
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 546
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:546/550; Lr: 0.0010000000000000002
batch Size 256
Epoch: [546][0/196]	Time 0.057 (0.057)	Data 0.254 (0.254)	Loss 0.9310 (0.9310)	Acc@1 67.578 (67.578)	Acc@5 96.094 (96.094)
Epoch: [546][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.8265 (0.9007)	Acc@1 72.656 (68.960)	Acc@5 98.047 (97.560)
Epoch: [546][128/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 1.0168 (0.8989)	Acc@1 63.281 (68.977)	Acc@5 96.484 (97.538)
Epoch: [546][192/196]	Time 0.037 (0.037)	Data 0.000 (0.001)	Loss 1.0072 (0.8978)	Acc@1 68.750 (68.936)	Acc@5 95.703 (97.555)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:547/550; Lr: 0.0010000000000000002
batch Size 256
Epoch: [547][0/196]	Time 0.044 (0.044)	Data 0.290 (0.290)	Loss 0.8981 (0.8981)	Acc@1 69.922 (69.922)	Acc@5 97.266 (97.266)
Epoch: [547][64/196]	Time 0.033 (0.039)	Data 0.000 (0.005)	Loss 1.0110 (0.8920)	Acc@1 64.062 (69.014)	Acc@5 98.047 (97.698)
Epoch: [547][128/196]	Time 0.040 (0.039)	Data 0.000 (0.002)	Loss 0.8102 (0.8934)	Acc@1 72.656 (69.023)	Acc@5 98.438 (97.599)
Epoch: [547][192/196]	Time 0.035 (0.038)	Data 0.000 (0.002)	Loss 0.8550 (0.8971)	Acc@1 70.703 (68.914)	Acc@5 97.656 (97.579)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:548/550; Lr: 0.0010000000000000002
batch Size 256
Epoch: [548][0/196]	Time 0.051 (0.051)	Data 0.291 (0.291)	Loss 1.0349 (1.0349)	Acc@1 65.234 (65.234)	Acc@5 95.312 (95.312)
Epoch: [548][64/196]	Time 0.034 (0.036)	Data 0.000 (0.005)	Loss 0.8909 (0.8959)	Acc@1 66.406 (68.858)	Acc@5 97.266 (97.620)
Epoch: [548][128/196]	Time 0.038 (0.037)	Data 0.000 (0.002)	Loss 0.9219 (0.8960)	Acc@1 65.625 (68.868)	Acc@5 98.438 (97.547)
Epoch: [548][192/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 0.8564 (0.8975)	Acc@1 73.438 (68.841)	Acc@5 98.828 (97.513)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:549/550; Lr: 0.0010000000000000002
batch Size 256
Epoch: [549][0/196]	Time 0.042 (0.042)	Data 0.279 (0.279)	Loss 0.8229 (0.8229)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [549][64/196]	Time 0.035 (0.035)	Data 0.000 (0.004)	Loss 1.0141 (0.8950)	Acc@1 66.406 (68.996)	Acc@5 97.266 (97.764)
Epoch: [549][128/196]	Time 0.038 (0.035)	Data 0.000 (0.002)	Loss 0.8836 (0.8952)	Acc@1 72.266 (68.968)	Acc@5 97.266 (97.662)
Epoch: [549][192/196]	Time 0.031 (0.035)	Data 0.000 (0.002)	Loss 0.8281 (0.8990)	Acc@1 70.703 (68.825)	Acc@5 97.266 (97.594)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:550/550; Lr: 0.0010000000000000002
batch Size 256
Epoch: [550][0/196]	Time 0.043 (0.043)	Data 0.271 (0.271)	Loss 1.0795 (1.0795)	Acc@1 62.891 (62.891)	Acc@5 95.312 (95.312)
Epoch: [550][64/196]	Time 0.029 (0.036)	Data 0.000 (0.004)	Loss 0.9867 (0.8878)	Acc@1 65.234 (69.038)	Acc@5 94.922 (97.903)
Epoch: [550][128/196]	Time 0.040 (0.037)	Data 0.000 (0.002)	Loss 0.9535 (0.8992)	Acc@1 66.797 (68.671)	Acc@5 98.047 (97.653)
Epoch: [550][192/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.8650 (0.8971)	Acc@1 69.141 (68.786)	Acc@5 98.828 (97.648)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.14
Max memory: 7.7508608
 7.400s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5894
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 551
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:551/555; Lr: 0.0010000000000000002
batch Size 256
Epoch: [551][0/196]	Time 0.078 (0.078)	Data 0.283 (0.283)	Loss 0.9843 (0.9843)	Acc@1 64.453 (64.453)	Acc@5 96.484 (96.484)
Epoch: [551][64/196]	Time 0.037 (0.037)	Data 0.000 (0.005)	Loss 0.8572 (0.9013)	Acc@1 69.531 (68.750)	Acc@5 97.656 (97.518)
Epoch: [551][128/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 0.8324 (0.9011)	Acc@1 71.094 (68.605)	Acc@5 97.266 (97.602)
Epoch: [551][192/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 0.8468 (0.8981)	Acc@1 74.219 (68.837)	Acc@5 98.828 (97.596)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:552/555; Lr: 0.0010000000000000002
batch Size 256
Epoch: [552][0/196]	Time 0.052 (0.052)	Data 0.323 (0.323)	Loss 0.9269 (0.9269)	Acc@1 67.969 (67.969)	Acc@5 98.047 (98.047)
Epoch: [552][64/196]	Time 0.040 (0.037)	Data 0.000 (0.005)	Loss 0.9974 (0.9023)	Acc@1 64.062 (68.774)	Acc@5 97.266 (97.686)
Epoch: [552][128/196]	Time 0.033 (0.036)	Data 0.000 (0.003)	Loss 0.9650 (0.9021)	Acc@1 69.922 (68.653)	Acc@5 96.094 (97.623)
Epoch: [552][192/196]	Time 0.030 (0.035)	Data 0.000 (0.002)	Loss 0.9455 (0.8984)	Acc@1 67.188 (68.677)	Acc@5 98.438 (97.670)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:553/555; Lr: 0.0010000000000000002
batch Size 256
Epoch: [553][0/196]	Time 0.046 (0.046)	Data 0.258 (0.258)	Loss 0.9219 (0.9219)	Acc@1 67.969 (67.969)	Acc@5 96.484 (96.484)
Epoch: [553][64/196]	Time 0.043 (0.038)	Data 0.000 (0.004)	Loss 0.9511 (0.8984)	Acc@1 65.234 (68.738)	Acc@5 97.266 (97.662)
Epoch: [553][128/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.9529 (0.9007)	Acc@1 64.062 (68.786)	Acc@5 96.484 (97.590)
Epoch: [553][192/196]	Time 0.036 (0.037)	Data 0.000 (0.001)	Loss 1.0050 (0.8976)	Acc@1 65.625 (68.918)	Acc@5 96.484 (97.612)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:554/555; Lr: 0.0010000000000000002
batch Size 256
Epoch: [554][0/196]	Time 0.042 (0.042)	Data 0.301 (0.301)	Loss 0.8999 (0.8999)	Acc@1 68.359 (68.359)	Acc@5 98.438 (98.438)
Epoch: [554][64/196]	Time 0.033 (0.036)	Data 0.000 (0.005)	Loss 0.8766 (0.8956)	Acc@1 69.141 (68.930)	Acc@5 97.656 (97.506)
Epoch: [554][128/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 1.0060 (0.8989)	Acc@1 64.844 (68.747)	Acc@5 96.094 (97.444)
Epoch: [554][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.9208 (0.8997)	Acc@1 62.891 (68.784)	Acc@5 97.266 (97.462)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:555/555; Lr: 0.0010000000000000002
batch Size 256
Epoch: [555][0/196]	Time 0.064 (0.064)	Data 0.255 (0.255)	Loss 0.9905 (0.9905)	Acc@1 63.672 (63.672)	Acc@5 98.047 (98.047)
Epoch: [555][64/196]	Time 0.030 (0.036)	Data 0.000 (0.004)	Loss 0.8727 (0.9005)	Acc@1 71.484 (68.335)	Acc@5 97.656 (97.632)
Epoch: [555][128/196]	Time 0.050 (0.036)	Data 0.000 (0.002)	Loss 0.9455 (0.9005)	Acc@1 66.016 (68.665)	Acc@5 98.047 (97.605)
Epoch: [555][192/196]	Time 0.035 (0.036)	Data 0.000 (0.001)	Loss 0.9232 (0.8981)	Acc@1 65.234 (68.801)	Acc@5 98.047 (97.577)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.35
Max memory: 7.7508608
 7.407s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6883
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 556
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:556/560; Lr: 0.0010000000000000002
batch Size 256
Epoch: [556][0/196]	Time 0.090 (0.090)	Data 0.260 (0.260)	Loss 0.8902 (0.8902)	Acc@1 68.359 (68.359)	Acc@5 98.438 (98.438)
Epoch: [556][64/196]	Time 0.036 (0.036)	Data 0.000 (0.004)	Loss 0.9547 (0.9044)	Acc@1 67.188 (68.780)	Acc@5 96.875 (97.464)
Epoch: [556][128/196]	Time 0.036 (0.037)	Data 0.000 (0.002)	Loss 0.8686 (0.8973)	Acc@1 69.922 (68.910)	Acc@5 96.875 (97.632)
Epoch: [556][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8862 (0.8981)	Acc@1 69.531 (68.942)	Acc@5 97.656 (97.612)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:557/560; Lr: 0.0010000000000000002
batch Size 256
Epoch: [557][0/196]	Time 0.042 (0.042)	Data 0.250 (0.250)	Loss 0.7829 (0.7829)	Acc@1 72.266 (72.266)	Acc@5 98.047 (98.047)
Epoch: [557][64/196]	Time 0.032 (0.036)	Data 0.000 (0.004)	Loss 0.8865 (0.8858)	Acc@1 69.531 (69.129)	Acc@5 99.219 (97.764)
Epoch: [557][128/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8807 (0.9003)	Acc@1 69.922 (68.729)	Acc@5 97.656 (97.644)
Epoch: [557][192/196]	Time 0.032 (0.036)	Data 0.000 (0.001)	Loss 0.9238 (0.8982)	Acc@1 68.359 (68.770)	Acc@5 96.094 (97.604)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:558/560; Lr: 0.0010000000000000002
batch Size 256
Epoch: [558][0/196]	Time 0.046 (0.046)	Data 0.260 (0.260)	Loss 0.9214 (0.9214)	Acc@1 66.797 (66.797)	Acc@5 97.656 (97.656)
Epoch: [558][64/196]	Time 0.040 (0.037)	Data 0.000 (0.004)	Loss 0.7851 (0.8954)	Acc@1 73.438 (68.966)	Acc@5 99.219 (97.644)
Epoch: [558][128/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.8899 (0.8968)	Acc@1 72.656 (68.871)	Acc@5 97.656 (97.581)
Epoch: [558][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9836 (0.8992)	Acc@1 67.969 (68.647)	Acc@5 97.656 (97.553)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:559/560; Lr: 0.0010000000000000002
batch Size 256
Epoch: [559][0/196]	Time 0.050 (0.050)	Data 0.294 (0.294)	Loss 0.8761 (0.8761)	Acc@1 72.266 (72.266)	Acc@5 97.266 (97.266)
Epoch: [559][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8698 (0.9060)	Acc@1 67.578 (68.684)	Acc@5 98.828 (97.410)
Epoch: [559][128/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8721 (0.9027)	Acc@1 71.875 (68.647)	Acc@5 98.828 (97.511)
Epoch: [559][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 1.0480 (0.8986)	Acc@1 63.281 (68.750)	Acc@5 96.875 (97.563)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:560/560; Lr: 0.0010000000000000002
batch Size 256
Epoch: [560][0/196]	Time 0.046 (0.046)	Data 0.258 (0.258)	Loss 0.9627 (0.9627)	Acc@1 66.016 (66.016)	Acc@5 96.484 (96.484)
Epoch: [560][64/196]	Time 0.031 (0.035)	Data 0.000 (0.004)	Loss 0.9418 (0.8924)	Acc@1 67.969 (68.744)	Acc@5 96.875 (97.674)
Epoch: [560][128/196]	Time 0.037 (0.035)	Data 0.000 (0.002)	Loss 0.8837 (0.8966)	Acc@1 70.312 (68.929)	Acc@5 98.828 (97.553)
Epoch: [560][192/196]	Time 0.032 (0.035)	Data 0.000 (0.001)	Loss 0.8290 (0.8970)	Acc@1 71.484 (69.003)	Acc@5 97.266 (97.545)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.97
Max memory: 7.7508608
 7.119s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 984
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 561
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:561/565; Lr: 0.0010000000000000002
batch Size 256
Epoch: [561][0/196]	Time 0.078 (0.078)	Data 0.286 (0.286)	Loss 0.8658 (0.8658)	Acc@1 71.484 (71.484)	Acc@5 97.266 (97.266)
Epoch: [561][64/196]	Time 0.036 (0.036)	Data 0.000 (0.005)	Loss 0.8381 (0.8844)	Acc@1 69.922 (69.615)	Acc@5 98.438 (97.620)
Epoch: [561][128/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.8270 (0.8898)	Acc@1 73.828 (69.244)	Acc@5 98.828 (97.614)
Epoch: [561][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.9100 (0.8941)	Acc@1 67.188 (69.068)	Acc@5 97.656 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:562/565; Lr: 0.0010000000000000002
batch Size 256
Epoch: [562][0/196]	Time 0.050 (0.050)	Data 0.233 (0.233)	Loss 0.9337 (0.9337)	Acc@1 70.703 (70.703)	Acc@5 97.266 (97.266)
Epoch: [562][64/196]	Time 0.031 (0.037)	Data 0.000 (0.004)	Loss 0.8975 (0.8963)	Acc@1 72.656 (68.954)	Acc@5 96.875 (97.452)
Epoch: [562][128/196]	Time 0.036 (0.035)	Data 0.000 (0.002)	Loss 0.8683 (0.8935)	Acc@1 68.359 (69.107)	Acc@5 98.828 (97.623)
Epoch: [562][192/196]	Time 0.037 (0.035)	Data 0.000 (0.001)	Loss 0.9615 (0.8938)	Acc@1 64.062 (69.080)	Acc@5 98.047 (97.658)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:563/565; Lr: 0.0010000000000000002
batch Size 256
Epoch: [563][0/196]	Time 0.076 (0.076)	Data 0.257 (0.257)	Loss 0.9150 (0.9150)	Acc@1 66.016 (66.016)	Acc@5 96.875 (96.875)
Epoch: [563][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.9140 (0.9005)	Acc@1 69.141 (68.948)	Acc@5 96.094 (97.602)
Epoch: [563][128/196]	Time 0.036 (0.037)	Data 0.000 (0.002)	Loss 0.8972 (0.9016)	Acc@1 69.922 (68.756)	Acc@5 97.266 (97.644)
Epoch: [563][192/196]	Time 0.031 (0.036)	Data 0.000 (0.001)	Loss 0.8397 (0.8989)	Acc@1 73.047 (68.780)	Acc@5 97.656 (97.658)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:564/565; Lr: 0.0010000000000000002
batch Size 256
Epoch: [564][0/196]	Time 0.048 (0.048)	Data 0.279 (0.279)	Loss 0.9503 (0.9503)	Acc@1 64.062 (64.062)	Acc@5 98.047 (98.047)
Epoch: [564][64/196]	Time 0.034 (0.036)	Data 0.000 (0.004)	Loss 0.9366 (0.9014)	Acc@1 66.406 (68.966)	Acc@5 99.219 (97.578)
Epoch: [564][128/196]	Time 0.043 (0.036)	Data 0.000 (0.002)	Loss 0.9554 (0.8947)	Acc@1 64.844 (68.941)	Acc@5 96.875 (97.553)
Epoch: [564][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8560 (0.8968)	Acc@1 66.797 (68.958)	Acc@5 99.219 (97.509)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:565/565; Lr: 0.0010000000000000002
batch Size 256
Epoch: [565][0/196]	Time 0.058 (0.058)	Data 0.271 (0.271)	Loss 0.9019 (0.9019)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [565][64/196]	Time 0.035 (0.037)	Data 0.000 (0.004)	Loss 0.8866 (0.8939)	Acc@1 71.484 (68.966)	Acc@5 97.656 (97.746)
Epoch: [565][128/196]	Time 0.038 (0.037)	Data 0.000 (0.002)	Loss 0.8435 (0.8937)	Acc@1 70.312 (69.071)	Acc@5 97.656 (97.696)
Epoch: [565][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8769 (0.8980)	Acc@1 67.969 (68.819)	Acc@5 99.219 (97.604)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.75
Max memory: 7.7508608
 7.520s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 7489
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 566
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:566/570; Lr: 0.0010000000000000002
batch Size 256
Epoch: [566][0/196]	Time 0.039 (0.039)	Data 0.309 (0.309)	Loss 0.9504 (0.9504)	Acc@1 67.969 (67.969)	Acc@5 96.875 (96.875)
Epoch: [566][64/196]	Time 0.038 (0.036)	Data 0.000 (0.005)	Loss 0.8584 (0.8990)	Acc@1 67.969 (69.075)	Acc@5 98.047 (97.578)
Epoch: [566][128/196]	Time 0.036 (0.036)	Data 0.000 (0.003)	Loss 0.9108 (0.9008)	Acc@1 69.922 (68.786)	Acc@5 97.266 (97.644)
Epoch: [566][192/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8155 (0.8975)	Acc@1 72.656 (68.863)	Acc@5 96.484 (97.596)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:567/570; Lr: 0.0010000000000000002
batch Size 256
Epoch: [567][0/196]	Time 0.047 (0.047)	Data 0.273 (0.273)	Loss 0.9462 (0.9462)	Acc@1 66.406 (66.406)	Acc@5 97.266 (97.266)
Epoch: [567][64/196]	Time 0.036 (0.037)	Data 0.000 (0.004)	Loss 0.8718 (0.9040)	Acc@1 69.141 (68.816)	Acc@5 98.438 (97.614)
Epoch: [567][128/196]	Time 0.042 (0.037)	Data 0.000 (0.002)	Loss 0.9724 (0.8985)	Acc@1 64.062 (68.808)	Acc@5 96.875 (97.629)
Epoch: [567][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.7834 (0.8995)	Acc@1 75.000 (68.766)	Acc@5 97.656 (97.591)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:568/570; Lr: 0.0010000000000000002
batch Size 256
Epoch: [568][0/196]	Time 0.044 (0.044)	Data 0.256 (0.256)	Loss 0.8914 (0.8914)	Acc@1 70.703 (70.703)	Acc@5 96.484 (96.484)
Epoch: [568][64/196]	Time 0.036 (0.037)	Data 0.000 (0.004)	Loss 0.9402 (0.9031)	Acc@1 66.797 (68.636)	Acc@5 96.875 (97.638)
Epoch: [568][128/196]	Time 0.039 (0.037)	Data 0.000 (0.002)	Loss 0.9336 (0.8962)	Acc@1 65.625 (68.944)	Acc@5 96.094 (97.626)
Epoch: [568][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.9414 (0.8976)	Acc@1 65.234 (68.910)	Acc@5 95.312 (97.612)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:569/570; Lr: 0.0010000000000000002
batch Size 256
Epoch: [569][0/196]	Time 0.038 (0.038)	Data 0.275 (0.275)	Loss 0.8485 (0.8485)	Acc@1 68.359 (68.359)	Acc@5 98.047 (98.047)
Epoch: [569][64/196]	Time 0.043 (0.037)	Data 0.000 (0.004)	Loss 0.9217 (0.9060)	Acc@1 67.188 (68.606)	Acc@5 98.438 (97.548)
Epoch: [569][128/196]	Time 0.027 (0.037)	Data 0.000 (0.002)	Loss 0.8804 (0.9027)	Acc@1 68.750 (68.523)	Acc@5 97.656 (97.453)
Epoch: [569][192/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.8969 (0.9000)	Acc@1 69.141 (68.673)	Acc@5 97.266 (97.529)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:570/570; Lr: 0.0010000000000000002
batch Size 256
Epoch: [570][0/196]	Time 0.062 (0.062)	Data 0.247 (0.247)	Loss 0.9133 (0.9133)	Acc@1 66.797 (66.797)	Acc@5 98.047 (98.047)
Epoch: [570][64/196]	Time 0.040 (0.038)	Data 0.000 (0.004)	Loss 0.8825 (0.9141)	Acc@1 69.922 (68.353)	Acc@5 97.656 (97.410)
Epoch: [570][128/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 0.9011 (0.9024)	Acc@1 72.266 (68.708)	Acc@5 96.875 (97.562)
Epoch: [570][192/196]	Time 0.028 (0.037)	Data 0.000 (0.001)	Loss 0.8952 (0.8973)	Acc@1 68.359 (68.837)	Acc@5 98.438 (97.594)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.9
Max memory: 7.7508608
 7.456s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3764
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 571
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:571/575; Lr: 0.0010000000000000002
batch Size 256
Epoch: [571][0/196]	Time 0.086 (0.086)	Data 0.224 (0.224)	Loss 0.8706 (0.8706)	Acc@1 73.047 (73.047)	Acc@5 97.266 (97.266)
Epoch: [571][64/196]	Time 0.042 (0.037)	Data 0.000 (0.004)	Loss 0.8928 (0.8932)	Acc@1 65.234 (68.395)	Acc@5 96.875 (97.704)
Epoch: [571][128/196]	Time 0.030 (0.037)	Data 0.000 (0.002)	Loss 0.8651 (0.8964)	Acc@1 70.703 (68.623)	Acc@5 97.266 (97.605)
Epoch: [571][192/196]	Time 0.031 (0.037)	Data 0.000 (0.001)	Loss 0.8570 (0.8973)	Acc@1 73.438 (68.835)	Acc@5 98.047 (97.577)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:572/575; Lr: 0.0010000000000000002
batch Size 256
Epoch: [572][0/196]	Time 0.044 (0.044)	Data 0.191 (0.191)	Loss 0.9296 (0.9296)	Acc@1 67.188 (67.188)	Acc@5 97.656 (97.656)
Epoch: [572][64/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 0.8602 (0.8934)	Acc@1 71.094 (68.792)	Acc@5 97.266 (97.812)
Epoch: [572][128/196]	Time 0.040 (0.036)	Data 0.000 (0.002)	Loss 0.9067 (0.8919)	Acc@1 67.969 (69.032)	Acc@5 97.656 (97.696)
Epoch: [572][192/196]	Time 0.035 (0.036)	Data 0.000 (0.001)	Loss 0.8889 (0.8957)	Acc@1 71.094 (68.776)	Acc@5 97.656 (97.664)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:573/575; Lr: 0.0010000000000000002
batch Size 256
Epoch: [573][0/196]	Time 0.050 (0.050)	Data 0.298 (0.298)	Loss 0.9500 (0.9500)	Acc@1 67.969 (67.969)	Acc@5 96.094 (96.094)
Epoch: [573][64/196]	Time 0.032 (0.038)	Data 0.000 (0.005)	Loss 0.9637 (0.8981)	Acc@1 65.625 (68.570)	Acc@5 98.047 (97.458)
Epoch: [573][128/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 0.9454 (0.8918)	Acc@1 71.484 (69.044)	Acc@5 97.266 (97.568)
Epoch: [573][192/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.8902 (0.8963)	Acc@1 68.750 (69.015)	Acc@5 98.047 (97.569)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:574/575; Lr: 0.0010000000000000002
batch Size 256
Epoch: [574][0/196]	Time 0.036 (0.036)	Data 0.250 (0.250)	Loss 0.9218 (0.9218)	Acc@1 65.234 (65.234)	Acc@5 97.656 (97.656)
Epoch: [574][64/196]	Time 0.039 (0.037)	Data 0.000 (0.004)	Loss 0.8019 (0.8976)	Acc@1 74.219 (68.822)	Acc@5 97.656 (97.494)
Epoch: [574][128/196]	Time 0.040 (0.036)	Data 0.000 (0.002)	Loss 0.9189 (0.8997)	Acc@1 69.141 (68.874)	Acc@5 98.438 (97.590)
Epoch: [574][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.9327 (0.8962)	Acc@1 69.141 (68.989)	Acc@5 97.266 (97.587)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:575/575; Lr: 0.0010000000000000002
batch Size 256
Epoch: [575][0/196]	Time 0.057 (0.057)	Data 0.280 (0.280)	Loss 0.9149 (0.9149)	Acc@1 69.531 (69.531)	Acc@5 97.266 (97.266)
Epoch: [575][64/196]	Time 0.032 (0.036)	Data 0.000 (0.004)	Loss 0.9984 (0.8913)	Acc@1 67.188 (69.321)	Acc@5 94.531 (97.674)
Epoch: [575][128/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.8881 (0.8922)	Acc@1 69.922 (69.410)	Acc@5 96.875 (97.629)
Epoch: [575][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9122 (0.8973)	Acc@1 65.625 (69.062)	Acc@5 98.438 (97.608)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.11
Max memory: 7.7508608
 7.411s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3057
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 576
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:576/580; Lr: 0.0010000000000000002
batch Size 256
Epoch: [576][0/196]	Time 0.055 (0.055)	Data 0.256 (0.256)	Loss 0.9315 (0.9315)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [576][64/196]	Time 0.041 (0.037)	Data 0.000 (0.004)	Loss 1.0763 (0.8907)	Acc@1 63.672 (69.062)	Acc@5 96.484 (97.608)
Epoch: [576][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8554 (0.8955)	Acc@1 74.219 (68.980)	Acc@5 95.703 (97.584)
Epoch: [576][192/196]	Time 0.027 (0.036)	Data 0.000 (0.001)	Loss 0.9849 (0.8946)	Acc@1 66.797 (68.981)	Acc@5 97.266 (97.587)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:577/580; Lr: 0.0010000000000000002
batch Size 256
Epoch: [577][0/196]	Time 0.054 (0.054)	Data 0.304 (0.304)	Loss 0.9129 (0.9129)	Acc@1 70.312 (70.312)	Acc@5 97.266 (97.266)
Epoch: [577][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8681 (0.8916)	Acc@1 68.750 (69.044)	Acc@5 98.828 (97.698)
Epoch: [577][128/196]	Time 0.031 (0.036)	Data 0.000 (0.003)	Loss 1.0093 (0.8928)	Acc@1 64.453 (69.113)	Acc@5 96.094 (97.596)
Epoch: [577][192/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 0.9874 (0.8953)	Acc@1 65.625 (68.920)	Acc@5 96.875 (97.636)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:578/580; Lr: 0.0010000000000000002
batch Size 256
Epoch: [578][0/196]	Time 0.044 (0.044)	Data 0.269 (0.269)	Loss 0.9147 (0.9147)	Acc@1 66.016 (66.016)	Acc@5 97.266 (97.266)
Epoch: [578][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.8338 (0.8909)	Acc@1 73.438 (69.237)	Acc@5 96.875 (97.662)
Epoch: [578][128/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.9801 (0.8936)	Acc@1 66.797 (68.977)	Acc@5 95.703 (97.611)
Epoch: [578][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8280 (0.8967)	Acc@1 71.484 (68.801)	Acc@5 97.656 (97.664)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:579/580; Lr: 0.0010000000000000002
batch Size 256
Epoch: [579][0/196]	Time 0.043 (0.043)	Data 0.304 (0.304)	Loss 0.9189 (0.9189)	Acc@1 68.359 (68.359)	Acc@5 98.047 (98.047)
Epoch: [579][64/196]	Time 0.031 (0.036)	Data 0.000 (0.005)	Loss 0.9298 (0.9009)	Acc@1 66.406 (68.618)	Acc@5 98.047 (97.626)
Epoch: [579][128/196]	Time 0.036 (0.037)	Data 0.000 (0.003)	Loss 0.8241 (0.8931)	Acc@1 73.047 (69.132)	Acc@5 97.656 (97.644)
Epoch: [579][192/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.9022 (0.8941)	Acc@1 70.312 (69.250)	Acc@5 96.094 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:580/580; Lr: 0.0010000000000000002
batch Size 256
Epoch: [580][0/196]	Time 0.043 (0.043)	Data 0.246 (0.246)	Loss 0.9476 (0.9476)	Acc@1 68.359 (68.359)	Acc@5 98.047 (98.047)
Epoch: [580][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.9257 (0.8904)	Acc@1 66.406 (68.858)	Acc@5 98.438 (97.614)
Epoch: [580][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8746 (0.8967)	Acc@1 69.141 (68.689)	Acc@5 98.047 (97.659)
Epoch: [580][192/196]	Time 0.036 (0.036)	Data 0.000 (0.001)	Loss 0.8656 (0.8959)	Acc@1 69.141 (68.801)	Acc@5 98.047 (97.608)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.62
Max memory: 7.7508608
 7.361s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 204
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 581
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:581/585; Lr: 0.0010000000000000002
batch Size 256
Epoch: [581][0/196]	Time 0.052 (0.052)	Data 0.257 (0.257)	Loss 0.9037 (0.9037)	Acc@1 69.531 (69.531)	Acc@5 98.047 (98.047)
Epoch: [581][64/196]	Time 0.035 (0.035)	Data 0.000 (0.004)	Loss 0.8961 (0.9015)	Acc@1 65.625 (68.966)	Acc@5 98.828 (97.572)
Epoch: [581][128/196]	Time 0.033 (0.034)	Data 0.000 (0.002)	Loss 0.9423 (0.9004)	Acc@1 65.625 (68.865)	Acc@5 96.875 (97.593)
Epoch: [581][192/196]	Time 0.030 (0.034)	Data 0.000 (0.001)	Loss 0.9398 (0.8990)	Acc@1 64.844 (68.833)	Acc@5 94.922 (97.600)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:582/585; Lr: 0.0010000000000000002
batch Size 256
Epoch: [582][0/196]	Time 0.042 (0.042)	Data 0.265 (0.265)	Loss 0.8749 (0.8749)	Acc@1 69.531 (69.531)	Acc@5 97.656 (97.656)
Epoch: [582][64/196]	Time 0.037 (0.037)	Data 0.000 (0.004)	Loss 0.9240 (0.8923)	Acc@1 67.578 (69.081)	Acc@5 98.047 (97.776)
Epoch: [582][128/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.9135 (0.9020)	Acc@1 69.922 (68.647)	Acc@5 98.047 (97.635)
Epoch: [582][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8425 (0.8959)	Acc@1 74.609 (68.851)	Acc@5 97.656 (97.689)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:583/585; Lr: 0.0010000000000000002
batch Size 256
Epoch: [583][0/196]	Time 0.049 (0.049)	Data 0.269 (0.269)	Loss 0.8701 (0.8701)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [583][64/196]	Time 0.035 (0.037)	Data 0.000 (0.004)	Loss 0.8525 (0.9053)	Acc@1 69.531 (68.684)	Acc@5 98.828 (97.368)
Epoch: [583][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8353 (0.8935)	Acc@1 69.922 (69.129)	Acc@5 98.047 (97.508)
Epoch: [583][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.9481 (0.8959)	Acc@1 69.141 (69.011)	Acc@5 96.484 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:584/585; Lr: 0.0010000000000000002
batch Size 256
Epoch: [584][0/196]	Time 0.043 (0.043)	Data 0.224 (0.224)	Loss 0.8927 (0.8927)	Acc@1 69.531 (69.531)	Acc@5 98.828 (98.828)
Epoch: [584][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.8600 (0.9014)	Acc@1 70.312 (68.924)	Acc@5 98.047 (97.596)
Epoch: [584][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8189 (0.8988)	Acc@1 70.703 (68.835)	Acc@5 96.875 (97.587)
Epoch: [584][192/196]	Time 0.030 (0.037)	Data 0.000 (0.001)	Loss 0.8633 (0.8984)	Acc@1 67.578 (68.784)	Acc@5 98.828 (97.624)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:585/585; Lr: 0.0010000000000000002
batch Size 256
Epoch: [585][0/196]	Time 0.057 (0.057)	Data 0.269 (0.269)	Loss 0.8432 (0.8432)	Acc@1 72.266 (72.266)	Acc@5 97.656 (97.656)
Epoch: [585][64/196]	Time 0.028 (0.038)	Data 0.000 (0.004)	Loss 0.9472 (0.9005)	Acc@1 66.016 (68.822)	Acc@5 97.266 (97.662)
Epoch: [585][128/196]	Time 0.040 (0.037)	Data 0.000 (0.002)	Loss 0.8647 (0.8959)	Acc@1 68.359 (68.904)	Acc@5 98.438 (97.677)
Epoch: [585][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8965 (0.8965)	Acc@1 67.969 (68.930)	Acc@5 98.047 (97.654)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.75
Max memory: 7.7508608
 7.537s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3837
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 586
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:586/590; Lr: 0.0010000000000000002
batch Size 256
Epoch: [586][0/196]	Time 0.060 (0.060)	Data 0.274 (0.274)	Loss 0.9214 (0.9214)	Acc@1 66.016 (66.016)	Acc@5 98.047 (98.047)
Epoch: [586][64/196]	Time 0.031 (0.036)	Data 0.000 (0.004)	Loss 0.9344 (0.8974)	Acc@1 66.016 (68.804)	Acc@5 96.875 (97.686)
Epoch: [586][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8033 (0.8992)	Acc@1 73.438 (68.871)	Acc@5 98.438 (97.596)
Epoch: [586][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.8855 (0.8977)	Acc@1 68.359 (68.825)	Acc@5 98.828 (97.589)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:587/590; Lr: 0.0010000000000000002
batch Size 256
Epoch: [587][0/196]	Time 0.042 (0.042)	Data 0.272 (0.272)	Loss 0.8155 (0.8155)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Epoch: [587][64/196]	Time 0.031 (0.036)	Data 0.000 (0.004)	Loss 0.9204 (0.8959)	Acc@1 67.969 (69.327)	Acc@5 98.438 (97.422)
Epoch: [587][128/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8137 (0.8951)	Acc@1 71.484 (69.095)	Acc@5 98.828 (97.571)
Epoch: [587][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.9707 (0.8961)	Acc@1 65.625 (69.037)	Acc@5 96.875 (97.589)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:588/590; Lr: 0.0010000000000000002
batch Size 256
Epoch: [588][0/196]	Time 0.048 (0.048)	Data 0.283 (0.283)	Loss 0.8539 (0.8539)	Acc@1 74.609 (74.609)	Acc@5 98.047 (98.047)
Epoch: [588][64/196]	Time 0.038 (0.037)	Data 0.000 (0.005)	Loss 0.8744 (0.9017)	Acc@1 67.188 (68.666)	Acc@5 97.656 (97.542)
Epoch: [588][128/196]	Time 0.038 (0.037)	Data 0.000 (0.002)	Loss 0.9672 (0.9019)	Acc@1 63.672 (68.599)	Acc@5 98.047 (97.523)
Epoch: [588][192/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8615 (0.8988)	Acc@1 71.875 (68.679)	Acc@5 95.703 (97.559)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:589/590; Lr: 0.0010000000000000002
batch Size 256
Epoch: [589][0/196]	Time 0.043 (0.043)	Data 0.322 (0.322)	Loss 0.9453 (0.9453)	Acc@1 66.797 (66.797)	Acc@5 96.484 (96.484)
Epoch: [589][64/196]	Time 0.038 (0.037)	Data 0.000 (0.005)	Loss 0.9089 (0.8962)	Acc@1 68.359 (68.852)	Acc@5 98.438 (97.668)
Epoch: [589][128/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 0.9258 (0.8985)	Acc@1 67.188 (68.850)	Acc@5 98.047 (97.602)
Epoch: [589][192/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.9183 (0.8955)	Acc@1 68.359 (68.904)	Acc@5 96.484 (97.585)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:590/590; Lr: 0.0010000000000000002
batch Size 256
Epoch: [590][0/196]	Time 0.058 (0.058)	Data 0.236 (0.236)	Loss 1.0326 (1.0326)	Acc@1 61.719 (61.719)	Acc@5 96.875 (96.875)
Epoch: [590][64/196]	Time 0.037 (0.037)	Data 0.000 (0.004)	Loss 0.9988 (0.8974)	Acc@1 62.109 (69.020)	Acc@5 96.094 (97.626)
Epoch: [590][128/196]	Time 0.042 (0.037)	Data 0.000 (0.002)	Loss 0.8762 (0.8959)	Acc@1 66.797 (68.989)	Acc@5 97.656 (97.632)
Epoch: [590][192/196]	Time 0.036 (0.037)	Data 0.000 (0.001)	Loss 0.8668 (0.8986)	Acc@1 69.141 (68.971)	Acc@5 97.656 (97.557)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.15
Max memory: 7.7508608
 7.520s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 176
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 591
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:591/595; Lr: 0.0010000000000000002
batch Size 256
Epoch: [591][0/196]	Time 0.065 (0.065)	Data 0.271 (0.271)	Loss 0.9375 (0.9375)	Acc@1 68.359 (68.359)	Acc@5 97.266 (97.266)
Epoch: [591][64/196]	Time 0.031 (0.033)	Data 0.000 (0.004)	Loss 0.8838 (0.8947)	Acc@1 69.922 (68.942)	Acc@5 96.484 (97.482)
Epoch: [591][128/196]	Time 0.029 (0.034)	Data 0.000 (0.002)	Loss 0.9431 (0.8997)	Acc@1 69.531 (68.768)	Acc@5 97.266 (97.562)
Epoch: [591][192/196]	Time 0.037 (0.034)	Data 0.000 (0.002)	Loss 0.8598 (0.8960)	Acc@1 70.312 (68.880)	Acc@5 98.438 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:592/595; Lr: 0.0010000000000000002
batch Size 256
Epoch: [592][0/196]	Time 0.045 (0.045)	Data 0.265 (0.265)	Loss 0.8095 (0.8095)	Acc@1 70.703 (70.703)	Acc@5 99.219 (99.219)
Epoch: [592][64/196]	Time 0.034 (0.035)	Data 0.000 (0.004)	Loss 0.9188 (0.9137)	Acc@1 67.188 (68.071)	Acc@5 97.656 (97.620)
Epoch: [592][128/196]	Time 0.039 (0.034)	Data 0.000 (0.002)	Loss 0.9816 (0.9005)	Acc@1 67.969 (68.568)	Acc@5 96.484 (97.674)
Epoch: [592][192/196]	Time 0.029 (0.034)	Data 0.000 (0.002)	Loss 0.9879 (0.8984)	Acc@1 67.188 (68.813)	Acc@5 94.922 (97.598)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:593/595; Lr: 0.0010000000000000002
batch Size 256
Epoch: [593][0/196]	Time 0.049 (0.049)	Data 0.276 (0.276)	Loss 1.0027 (1.0027)	Acc@1 65.625 (65.625)	Acc@5 97.656 (97.656)
Epoch: [593][64/196]	Time 0.035 (0.038)	Data 0.000 (0.004)	Loss 0.8955 (0.8988)	Acc@1 69.922 (68.816)	Acc@5 98.438 (97.572)
Epoch: [593][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.9697 (0.9000)	Acc@1 67.578 (68.814)	Acc@5 96.484 (97.499)
Epoch: [593][192/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.7984 (0.8975)	Acc@1 68.750 (68.871)	Acc@5 99.609 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:594/595; Lr: 0.0010000000000000002
batch Size 256
Epoch: [594][0/196]	Time 0.046 (0.046)	Data 0.297 (0.297)	Loss 0.8328 (0.8328)	Acc@1 69.922 (69.922)	Acc@5 98.438 (98.438)
Epoch: [594][64/196]	Time 0.028 (0.037)	Data 0.000 (0.005)	Loss 0.8112 (0.8842)	Acc@1 71.094 (68.882)	Acc@5 98.828 (97.794)
Epoch: [594][128/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.8578 (0.8913)	Acc@1 69.531 (68.753)	Acc@5 98.438 (97.684)
Epoch: [594][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8372 (0.8937)	Acc@1 74.219 (68.873)	Acc@5 97.656 (97.577)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:595/595; Lr: 0.0010000000000000002
batch Size 256
Epoch: [595][0/196]	Time 0.055 (0.055)	Data 0.326 (0.326)	Loss 0.9512 (0.9512)	Acc@1 65.625 (65.625)	Acc@5 98.438 (98.438)
Epoch: [595][64/196]	Time 0.030 (0.036)	Data 0.000 (0.005)	Loss 0.8724 (0.8926)	Acc@1 70.312 (69.044)	Acc@5 97.656 (97.542)
Epoch: [595][128/196]	Time 0.029 (0.036)	Data 0.000 (0.003)	Loss 0.8728 (0.8962)	Acc@1 69.922 (68.980)	Acc@5 96.875 (97.514)
Epoch: [595][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.8838 (0.8950)	Acc@1 68.750 (69.031)	Acc@5 97.656 (97.628)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.07
Max memory: 7.7508608
 7.455s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2600
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 596
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:596/600; Lr: 0.0010000000000000002
batch Size 256
Epoch: [596][0/196]	Time 0.087 (0.087)	Data 0.278 (0.278)	Loss 0.8745 (0.8745)	Acc@1 69.922 (69.922)	Acc@5 96.875 (96.875)
Epoch: [596][64/196]	Time 0.039 (0.037)	Data 0.000 (0.004)	Loss 0.9399 (0.8901)	Acc@1 69.141 (69.429)	Acc@5 98.047 (97.572)
Epoch: [596][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8476 (0.8926)	Acc@1 71.875 (69.077)	Acc@5 98.828 (97.608)
Epoch: [596][192/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8980 (0.8940)	Acc@1 67.578 (69.027)	Acc@5 97.266 (97.571)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:597/600; Lr: 0.0010000000000000002
batch Size 256
Epoch: [597][0/196]	Time 0.055 (0.055)	Data 0.384 (0.384)	Loss 0.7877 (0.7877)	Acc@1 73.047 (73.047)	Acc@5 98.047 (98.047)
Epoch: [597][64/196]	Time 0.030 (0.036)	Data 0.000 (0.006)	Loss 0.8520 (0.9027)	Acc@1 70.312 (68.846)	Acc@5 98.047 (97.530)
Epoch: [597][128/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 0.9188 (0.8985)	Acc@1 65.625 (68.717)	Acc@5 97.656 (97.596)
Epoch: [597][192/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.9046 (0.8959)	Acc@1 69.531 (68.878)	Acc@5 97.656 (97.608)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:598/600; Lr: 0.0010000000000000002
batch Size 256
Epoch: [598][0/196]	Time 0.042 (0.042)	Data 0.295 (0.295)	Loss 0.8730 (0.8730)	Acc@1 70.703 (70.703)	Acc@5 98.047 (98.047)
Epoch: [598][64/196]	Time 0.041 (0.035)	Data 0.000 (0.005)	Loss 0.7881 (0.8963)	Acc@1 73.438 (68.882)	Acc@5 98.828 (97.644)
Epoch: [598][128/196]	Time 0.039 (0.035)	Data 0.000 (0.002)	Loss 0.8592 (0.9037)	Acc@1 71.484 (68.590)	Acc@5 97.656 (97.581)
Epoch: [598][192/196]	Time 0.034 (0.035)	Data 0.000 (0.002)	Loss 0.8504 (0.9010)	Acc@1 70.312 (68.720)	Acc@5 98.828 (97.618)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:599/600; Lr: 0.0010000000000000002
batch Size 256
Epoch: [599][0/196]	Time 0.062 (0.062)	Data 0.300 (0.300)	Loss 0.8810 (0.8810)	Acc@1 69.922 (69.922)	Acc@5 97.266 (97.266)
Epoch: [599][64/196]	Time 0.032 (0.036)	Data 0.000 (0.005)	Loss 0.8319 (0.9072)	Acc@1 72.656 (68.353)	Acc@5 96.484 (97.440)
Epoch: [599][128/196]	Time 0.041 (0.037)	Data 0.000 (0.002)	Loss 0.9639 (0.9048)	Acc@1 69.922 (68.590)	Acc@5 95.703 (97.462)
Epoch: [599][192/196]	Time 0.030 (0.037)	Data 0.000 (0.002)	Loss 0.9087 (0.8984)	Acc@1 67.188 (68.639)	Acc@5 98.438 (97.579)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:600/600; Lr: 0.0010000000000000002
batch Size 256
Epoch: [600][0/196]	Time 0.054 (0.054)	Data 0.276 (0.276)	Loss 0.9685 (0.9685)	Acc@1 64.844 (64.844)	Acc@5 98.047 (98.047)
Epoch: [600][64/196]	Time 0.039 (0.036)	Data 0.000 (0.004)	Loss 0.8080 (0.9027)	Acc@1 74.609 (68.299)	Acc@5 98.438 (97.620)
Epoch: [600][128/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8641 (0.9005)	Acc@1 69.922 (68.450)	Acc@5 97.656 (97.653)
Epoch: [600][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.8282 (0.8963)	Acc@1 71.484 (68.875)	Acc@5 98.438 (97.628)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.09
Max memory: 7.7508608
 7.351s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5913
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 601
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:601/605; Lr: 0.0010000000000000002
batch Size 256
Epoch: [601][0/196]	Time 0.052 (0.052)	Data 0.224 (0.224)	Loss 0.8435 (0.8435)	Acc@1 71.875 (71.875)	Acc@5 98.828 (98.828)
Epoch: [601][64/196]	Time 0.041 (0.036)	Data 0.000 (0.004)	Loss 0.9247 (0.8922)	Acc@1 66.016 (68.876)	Acc@5 95.312 (97.602)
Epoch: [601][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.9450 (0.8933)	Acc@1 69.531 (68.953)	Acc@5 97.266 (97.717)
Epoch: [601][192/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 0.8916 (0.8940)	Acc@1 67.188 (68.940)	Acc@5 98.438 (97.695)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:602/605; Lr: 0.0010000000000000002
batch Size 256
Epoch: [602][0/196]	Time 0.048 (0.048)	Data 0.272 (0.272)	Loss 0.8064 (0.8064)	Acc@1 71.094 (71.094)	Acc@5 98.828 (98.828)
Epoch: [602][64/196]	Time 0.041 (0.036)	Data 0.000 (0.004)	Loss 0.9544 (0.8915)	Acc@1 67.188 (68.918)	Acc@5 97.656 (97.548)
Epoch: [602][128/196]	Time 0.040 (0.037)	Data 0.000 (0.002)	Loss 0.8998 (0.8921)	Acc@1 71.484 (68.865)	Acc@5 97.266 (97.608)
Epoch: [602][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8451 (0.8954)	Acc@1 71.094 (68.829)	Acc@5 98.047 (97.537)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:603/605; Lr: 0.0010000000000000002
batch Size 256
Epoch: [603][0/196]	Time 0.033 (0.033)	Data 0.283 (0.283)	Loss 0.9920 (0.9920)	Acc@1 65.234 (65.234)	Acc@5 97.656 (97.656)
Epoch: [603][64/196]	Time 0.035 (0.037)	Data 0.000 (0.005)	Loss 0.9159 (0.8932)	Acc@1 65.234 (69.129)	Acc@5 97.656 (97.746)
Epoch: [603][128/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.8881 (0.8946)	Acc@1 69.531 (69.032)	Acc@5 97.266 (97.677)
Epoch: [603][192/196]	Time 0.032 (0.035)	Data 0.000 (0.002)	Loss 0.9696 (0.8978)	Acc@1 67.969 (68.997)	Acc@5 96.484 (97.634)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:604/605; Lr: 0.0010000000000000002
batch Size 256
Epoch: [604][0/196]	Time 0.043 (0.043)	Data 0.261 (0.261)	Loss 0.9438 (0.9438)	Acc@1 66.016 (66.016)	Acc@5 96.484 (96.484)
Epoch: [604][64/196]	Time 0.034 (0.036)	Data 0.000 (0.004)	Loss 0.8537 (0.8936)	Acc@1 68.359 (69.111)	Acc@5 97.656 (97.536)
Epoch: [604][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8585 (0.8999)	Acc@1 67.578 (68.826)	Acc@5 97.656 (97.453)
Epoch: [604][192/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 0.8932 (0.8977)	Acc@1 71.484 (68.853)	Acc@5 97.656 (97.482)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:605/605; Lr: 0.0010000000000000002
batch Size 256
Epoch: [605][0/196]	Time 0.048 (0.048)	Data 0.248 (0.248)	Loss 0.8917 (0.8917)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [605][64/196]	Time 0.032 (0.036)	Data 0.000 (0.004)	Loss 0.9075 (0.8954)	Acc@1 70.703 (68.972)	Acc@5 96.094 (97.506)
Epoch: [605][128/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8493 (0.8944)	Acc@1 70.312 (69.029)	Acc@5 95.703 (97.559)
Epoch: [605][192/196]	Time 0.033 (0.036)	Data 0.000 (0.001)	Loss 0.9959 (0.8961)	Acc@1 68.750 (68.902)	Acc@5 96.875 (97.616)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.79
Max memory: 7.7508608
 7.342s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2683
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 606
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:606/610; Lr: 0.0010000000000000002
batch Size 256
Epoch: [606][0/196]	Time 0.062 (0.062)	Data 0.311 (0.311)	Loss 0.8640 (0.8640)	Acc@1 70.703 (70.703)	Acc@5 98.047 (98.047)
Epoch: [606][64/196]	Time 0.038 (0.037)	Data 0.000 (0.005)	Loss 0.8246 (0.8864)	Acc@1 69.531 (69.423)	Acc@5 98.828 (97.752)
Epoch: [606][128/196]	Time 0.042 (0.036)	Data 0.000 (0.003)	Loss 0.9203 (0.8957)	Acc@1 68.359 (68.844)	Acc@5 96.094 (97.693)
Epoch: [606][192/196]	Time 0.033 (0.035)	Data 0.000 (0.002)	Loss 0.8217 (0.8966)	Acc@1 73.047 (68.922)	Acc@5 97.656 (97.640)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:607/610; Lr: 0.0010000000000000002
batch Size 256
Epoch: [607][0/196]	Time 0.051 (0.051)	Data 0.301 (0.301)	Loss 0.9105 (0.9105)	Acc@1 70.703 (70.703)	Acc@5 98.438 (98.438)
Epoch: [607][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8748 (0.8957)	Acc@1 70.703 (69.303)	Acc@5 98.047 (97.674)
Epoch: [607][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.8890 (0.8978)	Acc@1 69.922 (68.995)	Acc@5 97.656 (97.568)
Epoch: [607][192/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 0.9383 (0.8955)	Acc@1 66.016 (69.043)	Acc@5 98.828 (97.624)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:608/610; Lr: 0.0010000000000000002
batch Size 256
Epoch: [608][0/196]	Time 0.046 (0.046)	Data 0.267 (0.267)	Loss 0.8345 (0.8345)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [608][64/196]	Time 0.039 (0.037)	Data 0.000 (0.004)	Loss 0.8811 (0.9021)	Acc@1 67.188 (69.062)	Acc@5 98.828 (97.542)
Epoch: [608][128/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.8298 (0.8921)	Acc@1 73.047 (69.280)	Acc@5 96.875 (97.587)
Epoch: [608][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8630 (0.8954)	Acc@1 69.531 (69.126)	Acc@5 98.828 (97.608)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:609/610; Lr: 0.0010000000000000002
batch Size 256
Epoch: [609][0/196]	Time 0.044 (0.044)	Data 0.306 (0.306)	Loss 0.9125 (0.9125)	Acc@1 63.672 (63.672)	Acc@5 98.047 (98.047)
Epoch: [609][64/196]	Time 0.031 (0.037)	Data 0.000 (0.005)	Loss 0.8706 (0.8982)	Acc@1 71.484 (68.906)	Acc@5 97.656 (97.602)
Epoch: [609][128/196]	Time 0.048 (0.037)	Data 0.000 (0.003)	Loss 0.9132 (0.8955)	Acc@1 71.094 (68.829)	Acc@5 98.047 (97.641)
Epoch: [609][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.8286 (0.8969)	Acc@1 74.609 (68.861)	Acc@5 98.438 (97.660)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:610/610; Lr: 0.0010000000000000002
batch Size 256
Epoch: [610][0/196]	Time 0.053 (0.053)	Data 0.311 (0.311)	Loss 0.9306 (0.9306)	Acc@1 66.016 (66.016)	Acc@5 97.656 (97.656)
Epoch: [610][64/196]	Time 0.035 (0.037)	Data 0.000 (0.005)	Loss 0.8856 (0.8848)	Acc@1 70.703 (68.792)	Acc@5 97.656 (97.975)
Epoch: [610][128/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 0.9476 (0.8920)	Acc@1 65.234 (68.832)	Acc@5 98.047 (97.805)
Epoch: [610][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9744 (0.8957)	Acc@1 62.109 (68.847)	Acc@5 97.266 (97.668)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.03
Max memory: 7.7508608
 7.493s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2703
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 611
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:611/615; Lr: 0.0010000000000000002
batch Size 256
Epoch: [611][0/196]	Time 0.067 (0.067)	Data 0.271 (0.271)	Loss 0.8900 (0.8900)	Acc@1 68.750 (68.750)	Acc@5 96.875 (96.875)
Epoch: [611][64/196]	Time 0.028 (0.037)	Data 0.000 (0.004)	Loss 0.9562 (0.8939)	Acc@1 63.672 (68.606)	Acc@5 97.266 (97.680)
Epoch: [611][128/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.9323 (0.9009)	Acc@1 66.406 (68.550)	Acc@5 98.828 (97.650)
Epoch: [611][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.9554 (0.8964)	Acc@1 64.844 (68.754)	Acc@5 95.312 (97.721)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:612/615; Lr: 0.0010000000000000002
batch Size 256
Epoch: [612][0/196]	Time 0.048 (0.048)	Data 0.295 (0.295)	Loss 0.8692 (0.8692)	Acc@1 69.922 (69.922)	Acc@5 97.656 (97.656)
Epoch: [612][64/196]	Time 0.035 (0.037)	Data 0.000 (0.005)	Loss 0.9329 (0.8907)	Acc@1 68.359 (69.441)	Acc@5 96.875 (97.620)
Epoch: [612][128/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 0.9277 (0.8955)	Acc@1 65.234 (68.938)	Acc@5 97.266 (97.553)
Epoch: [612][192/196]	Time 0.045 (0.036)	Data 0.000 (0.002)	Loss 0.9315 (0.8974)	Acc@1 64.453 (68.936)	Acc@5 96.484 (97.541)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:613/615; Lr: 0.0010000000000000002
batch Size 256
Epoch: [613][0/196]	Time 0.056 (0.056)	Data 0.255 (0.255)	Loss 0.8745 (0.8745)	Acc@1 67.969 (67.969)	Acc@5 98.047 (98.047)
Epoch: [613][64/196]	Time 0.037 (0.036)	Data 0.000 (0.004)	Loss 0.9559 (0.9044)	Acc@1 67.188 (68.431)	Acc@5 97.656 (97.578)
Epoch: [613][128/196]	Time 0.045 (0.036)	Data 0.000 (0.002)	Loss 0.8987 (0.8975)	Acc@1 66.797 (68.777)	Acc@5 97.656 (97.617)
Epoch: [613][192/196]	Time 0.034 (0.036)	Data 0.000 (0.001)	Loss 0.8895 (0.8971)	Acc@1 67.188 (68.829)	Acc@5 98.438 (97.612)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:614/615; Lr: 0.0010000000000000002
batch Size 256
Epoch: [614][0/196]	Time 0.053 (0.053)	Data 0.327 (0.327)	Loss 0.9040 (0.9040)	Acc@1 66.797 (66.797)	Acc@5 98.828 (98.828)
Epoch: [614][64/196]	Time 0.038 (0.036)	Data 0.000 (0.005)	Loss 0.9496 (0.9012)	Acc@1 65.234 (68.594)	Acc@5 97.656 (97.692)
Epoch: [614][128/196]	Time 0.031 (0.036)	Data 0.000 (0.003)	Loss 0.7826 (0.8965)	Acc@1 71.875 (68.826)	Acc@5 98.438 (97.650)
Epoch: [614][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9475 (0.8963)	Acc@1 64.844 (68.756)	Acc@5 97.266 (97.674)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:615/615; Lr: 0.0010000000000000002
batch Size 256
Epoch: [615][0/196]	Time 0.052 (0.052)	Data 0.225 (0.225)	Loss 0.7972 (0.7972)	Acc@1 70.312 (70.312)	Acc@5 99.609 (99.609)
Epoch: [615][64/196]	Time 0.030 (0.035)	Data 0.000 (0.004)	Loss 0.9851 (0.8918)	Acc@1 65.234 (69.393)	Acc@5 98.438 (97.554)
Epoch: [615][128/196]	Time 0.042 (0.035)	Data 0.000 (0.002)	Loss 0.9407 (0.8919)	Acc@1 67.578 (69.283)	Acc@5 97.266 (97.596)
Epoch: [615][192/196]	Time 0.027 (0.035)	Data 0.000 (0.001)	Loss 0.8882 (0.8962)	Acc@1 65.625 (69.080)	Acc@5 98.438 (97.575)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.74
Max memory: 7.7508608
 7.181s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6133
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 616
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:616/620; Lr: 0.0010000000000000002
batch Size 256
Epoch: [616][0/196]	Time 0.063 (0.063)	Data 0.226 (0.226)	Loss 0.9489 (0.9489)	Acc@1 64.844 (64.844)	Acc@5 96.484 (96.484)
Epoch: [616][64/196]	Time 0.031 (0.036)	Data 0.000 (0.004)	Loss 0.9315 (0.9007)	Acc@1 68.359 (68.720)	Acc@5 98.438 (97.632)
Epoch: [616][128/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8636 (0.9011)	Acc@1 71.875 (68.650)	Acc@5 98.047 (97.599)
Epoch: [616][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.8765 (0.8959)	Acc@1 66.406 (68.886)	Acc@5 97.656 (97.620)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:617/620; Lr: 0.0010000000000000002
batch Size 256
Epoch: [617][0/196]	Time 0.053 (0.053)	Data 0.272 (0.272)	Loss 0.8890 (0.8890)	Acc@1 67.578 (67.578)	Acc@5 97.656 (97.656)
Epoch: [617][64/196]	Time 0.039 (0.037)	Data 0.000 (0.004)	Loss 1.0156 (0.9064)	Acc@1 64.062 (68.456)	Acc@5 98.438 (97.386)
Epoch: [617][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.9504 (0.8947)	Acc@1 65.625 (68.974)	Acc@5 96.875 (97.553)
Epoch: [617][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8982 (0.8924)	Acc@1 64.453 (69.052)	Acc@5 98.438 (97.575)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:618/620; Lr: 0.0010000000000000002
batch Size 256
Epoch: [618][0/196]	Time 0.044 (0.044)	Data 0.310 (0.310)	Loss 0.8629 (0.8629)	Acc@1 68.750 (68.750)	Acc@5 98.438 (98.438)
Epoch: [618][64/196]	Time 0.040 (0.036)	Data 0.000 (0.005)	Loss 0.8332 (0.8994)	Acc@1 70.703 (68.618)	Acc@5 98.438 (97.500)
Epoch: [618][128/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 0.8195 (0.8975)	Acc@1 69.922 (68.765)	Acc@5 100.000 (97.502)
Epoch: [618][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9146 (0.8999)	Acc@1 68.750 (68.707)	Acc@5 96.875 (97.517)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:619/620; Lr: 0.0010000000000000002
batch Size 256
Epoch: [619][0/196]	Time 0.045 (0.045)	Data 0.298 (0.298)	Loss 1.0098 (1.0098)	Acc@1 64.062 (64.062)	Acc@5 96.875 (96.875)
Epoch: [619][64/196]	Time 0.039 (0.036)	Data 0.000 (0.005)	Loss 0.9047 (0.8886)	Acc@1 66.406 (69.243)	Acc@5 99.219 (97.662)
Epoch: [619][128/196]	Time 0.034 (0.037)	Data 0.000 (0.003)	Loss 0.8867 (0.8953)	Acc@1 67.578 (68.883)	Acc@5 98.047 (97.620)
Epoch: [619][192/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 0.8760 (0.8965)	Acc@1 69.141 (68.898)	Acc@5 96.875 (97.604)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:620/620; Lr: 0.0010000000000000002
batch Size 256
Epoch: [620][0/196]	Time 0.044 (0.044)	Data 0.313 (0.313)	Loss 0.8162 (0.8162)	Acc@1 72.656 (72.656)	Acc@5 97.656 (97.656)
Epoch: [620][64/196]	Time 0.036 (0.036)	Data 0.000 (0.005)	Loss 0.8793 (0.9004)	Acc@1 69.531 (68.948)	Acc@5 96.875 (97.728)
Epoch: [620][128/196]	Time 0.028 (0.036)	Data 0.000 (0.003)	Loss 0.8866 (0.8996)	Acc@1 70.312 (68.856)	Acc@5 98.828 (97.668)
Epoch: [620][192/196]	Time 0.040 (0.036)	Data 0.000 (0.002)	Loss 0.9474 (0.8970)	Acc@1 66.406 (68.912)	Acc@5 97.266 (97.640)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.21
Max memory: 7.7508608
 7.414s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5408
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 621
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:621/625; Lr: 0.0010000000000000002
batch Size 256
Epoch: [621][0/196]	Time 0.083 (0.083)	Data 0.268 (0.268)	Loss 0.8520 (0.8520)	Acc@1 72.266 (72.266)	Acc@5 96.875 (96.875)
Epoch: [621][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.8526 (0.8927)	Acc@1 69.141 (68.600)	Acc@5 98.047 (97.548)
Epoch: [621][128/196]	Time 0.036 (0.037)	Data 0.000 (0.002)	Loss 0.8670 (0.8961)	Acc@1 67.969 (68.611)	Acc@5 96.875 (97.541)
Epoch: [621][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.7956 (0.8943)	Acc@1 74.609 (68.691)	Acc@5 98.828 (97.573)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:622/625; Lr: 0.0010000000000000002
batch Size 256
Epoch: [622][0/196]	Time 0.052 (0.052)	Data 0.281 (0.281)	Loss 0.8411 (0.8411)	Acc@1 71.094 (71.094)	Acc@5 97.266 (97.266)
Epoch: [622][64/196]	Time 0.040 (0.037)	Data 0.000 (0.004)	Loss 0.8851 (0.9044)	Acc@1 73.047 (68.395)	Acc@5 98.438 (97.668)
Epoch: [622][128/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.9163 (0.8959)	Acc@1 68.750 (68.953)	Acc@5 96.094 (97.644)
Epoch: [622][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8986 (0.8952)	Acc@1 67.969 (69.052)	Acc@5 97.656 (97.691)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:623/625; Lr: 0.0010000000000000002
batch Size 256
Epoch: [623][0/196]	Time 0.071 (0.071)	Data 0.279 (0.279)	Loss 0.8608 (0.8608)	Acc@1 69.141 (69.141)	Acc@5 98.047 (98.047)
Epoch: [623][64/196]	Time 0.046 (0.039)	Data 0.000 (0.004)	Loss 0.9893 (0.9016)	Acc@1 63.672 (68.900)	Acc@5 96.484 (97.584)
Epoch: [623][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.8510 (0.8947)	Acc@1 70.703 (68.980)	Acc@5 98.047 (97.662)
Epoch: [623][192/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.9285 (0.8957)	Acc@1 64.844 (68.833)	Acc@5 98.047 (97.662)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:624/625; Lr: 0.0010000000000000002
batch Size 256
Epoch: [624][0/196]	Time 0.050 (0.050)	Data 0.237 (0.237)	Loss 0.8917 (0.8917)	Acc@1 71.484 (71.484)	Acc@5 97.656 (97.656)
Epoch: [624][64/196]	Time 0.035 (0.036)	Data 0.000 (0.004)	Loss 0.9005 (0.8947)	Acc@1 67.188 (69.141)	Acc@5 97.656 (97.590)
Epoch: [624][128/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.7806 (0.8945)	Acc@1 70.312 (68.859)	Acc@5 98.438 (97.599)
Epoch: [624][192/196]	Time 0.034 (0.036)	Data 0.000 (0.001)	Loss 0.9556 (0.8941)	Acc@1 66.016 (69.023)	Acc@5 95.703 (97.634)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:625/625; Lr: 0.0010000000000000002
batch Size 256
Epoch: [625][0/196]	Time 0.047 (0.047)	Data 0.280 (0.280)	Loss 0.9681 (0.9681)	Acc@1 63.281 (63.281)	Acc@5 98.828 (98.828)
Epoch: [625][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.8909 (0.8928)	Acc@1 67.969 (69.075)	Acc@5 96.875 (97.638)
Epoch: [625][128/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 0.9226 (0.8937)	Acc@1 69.141 (68.977)	Acc@5 96.484 (97.647)
Epoch: [625][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9046 (0.8926)	Acc@1 66.797 (69.114)	Acc@5 98.047 (97.640)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.58
Max memory: 7.7508608
 7.344s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 9562
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 626
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:626/630; Lr: 0.0010000000000000002
batch Size 256
Epoch: [626][0/196]	Time 0.084 (0.084)	Data 0.250 (0.250)	Loss 0.9382 (0.9382)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [626][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.9941 (0.8988)	Acc@1 66.016 (68.714)	Acc@5 95.703 (97.596)
Epoch: [626][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8547 (0.8948)	Acc@1 69.922 (68.877)	Acc@5 97.266 (97.647)
Epoch: [626][192/196]	Time 0.036 (0.036)	Data 0.000 (0.001)	Loss 0.9748 (0.8958)	Acc@1 66.016 (68.882)	Acc@5 96.875 (97.666)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:627/630; Lr: 0.0010000000000000002
batch Size 256
Epoch: [627][0/196]	Time 0.051 (0.051)	Data 0.242 (0.242)	Loss 0.9410 (0.9410)	Acc@1 65.625 (65.625)	Acc@5 96.875 (96.875)
Epoch: [627][64/196]	Time 0.034 (0.037)	Data 0.000 (0.004)	Loss 0.8424 (0.8803)	Acc@1 69.141 (69.453)	Acc@5 96.875 (97.800)
Epoch: [627][128/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.9840 (0.8931)	Acc@1 68.359 (69.035)	Acc@5 96.875 (97.650)
Epoch: [627][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.9355 (0.8955)	Acc@1 67.969 (68.950)	Acc@5 97.656 (97.616)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:628/630; Lr: 0.0010000000000000002
batch Size 256
Epoch: [628][0/196]	Time 0.047 (0.047)	Data 0.293 (0.293)	Loss 0.9241 (0.9241)	Acc@1 70.312 (70.312)	Acc@5 95.703 (95.703)
Epoch: [628][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8454 (0.8954)	Acc@1 69.922 (68.600)	Acc@5 98.438 (97.488)
Epoch: [628][128/196]	Time 0.044 (0.037)	Data 0.000 (0.002)	Loss 0.9035 (0.8968)	Acc@1 65.625 (68.674)	Acc@5 98.047 (97.611)
Epoch: [628][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8615 (0.8971)	Acc@1 69.922 (68.843)	Acc@5 97.656 (97.571)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:629/630; Lr: 0.0010000000000000002
batch Size 256
Epoch: [629][0/196]	Time 0.066 (0.066)	Data 0.218 (0.218)	Loss 0.8598 (0.8598)	Acc@1 71.875 (71.875)	Acc@5 98.047 (98.047)
Epoch: [629][64/196]	Time 0.037 (0.037)	Data 0.000 (0.004)	Loss 0.8703 (0.8922)	Acc@1 68.750 (68.648)	Acc@5 98.047 (97.716)
Epoch: [629][128/196]	Time 0.030 (0.037)	Data 0.000 (0.002)	Loss 0.8203 (0.8975)	Acc@1 71.094 (68.735)	Acc@5 100.000 (97.650)
Epoch: [629][192/196]	Time 0.034 (0.037)	Data 0.000 (0.001)	Loss 0.8572 (0.8966)	Acc@1 70.703 (68.847)	Acc@5 96.484 (97.577)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:630/630; Lr: 0.0010000000000000002
batch Size 256
Epoch: [630][0/196]	Time 0.043 (0.043)	Data 0.247 (0.247)	Loss 0.8125 (0.8125)	Acc@1 72.656 (72.656)	Acc@5 98.438 (98.438)
Epoch: [630][64/196]	Time 0.040 (0.037)	Data 0.000 (0.004)	Loss 0.7914 (0.8833)	Acc@1 73.828 (69.141)	Acc@5 98.828 (97.788)
Epoch: [630][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.8808 (0.8917)	Acc@1 69.141 (69.180)	Acc@5 98.047 (97.605)
Epoch: [630][192/196]	Time 0.036 (0.037)	Data 0.000 (0.001)	Loss 0.9181 (0.8965)	Acc@1 69.531 (68.851)	Acc@5 97.266 (97.529)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.13
Max memory: 7.7508608
 7.572s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5673
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 631
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:631/635; Lr: 0.0010000000000000002
batch Size 256
Epoch: [631][0/196]	Time 0.086 (0.086)	Data 0.282 (0.282)	Loss 0.8479 (0.8479)	Acc@1 72.266 (72.266)	Acc@5 97.656 (97.656)
Epoch: [631][64/196]	Time 0.038 (0.037)	Data 0.000 (0.005)	Loss 0.8176 (0.8898)	Acc@1 70.703 (69.231)	Acc@5 96.875 (97.668)
Epoch: [631][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.7833 (0.8900)	Acc@1 71.875 (69.231)	Acc@5 98.438 (97.581)
Epoch: [631][192/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 1.0073 (0.8932)	Acc@1 66.406 (69.082)	Acc@5 95.703 (97.594)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:632/635; Lr: 0.0010000000000000002
batch Size 256
Epoch: [632][0/196]	Time 0.050 (0.050)	Data 0.249 (0.249)	Loss 0.9087 (0.9087)	Acc@1 69.141 (69.141)	Acc@5 98.438 (98.438)
Epoch: [632][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.9259 (0.9000)	Acc@1 66.797 (69.069)	Acc@5 98.047 (97.452)
Epoch: [632][128/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8088 (0.9023)	Acc@1 71.875 (68.904)	Acc@5 98.438 (97.502)
Epoch: [632][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.8375 (0.8940)	Acc@1 69.531 (69.080)	Acc@5 98.828 (97.531)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:633/635; Lr: 0.0010000000000000002
batch Size 256
Epoch: [633][0/196]	Time 0.045 (0.045)	Data 0.278 (0.278)	Loss 0.8251 (0.8251)	Acc@1 71.484 (71.484)	Acc@5 97.266 (97.266)
Epoch: [633][64/196]	Time 0.035 (0.036)	Data 0.000 (0.004)	Loss 0.8288 (0.8988)	Acc@1 71.484 (68.864)	Acc@5 97.656 (97.674)
Epoch: [633][128/196]	Time 0.040 (0.036)	Data 0.000 (0.002)	Loss 0.8985 (0.8962)	Acc@1 69.922 (68.959)	Acc@5 97.266 (97.690)
Epoch: [633][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8385 (0.8947)	Acc@1 69.141 (68.993)	Acc@5 98.828 (97.681)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:634/635; Lr: 0.0010000000000000002
batch Size 256
Epoch: [634][0/196]	Time 0.048 (0.048)	Data 0.253 (0.253)	Loss 0.8480 (0.8480)	Acc@1 71.484 (71.484)	Acc@5 98.828 (98.828)
Epoch: [634][64/196]	Time 0.041 (0.038)	Data 0.000 (0.004)	Loss 0.8574 (0.9000)	Acc@1 68.359 (68.726)	Acc@5 96.875 (97.566)
Epoch: [634][128/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8795 (0.8931)	Acc@1 67.969 (69.020)	Acc@5 98.047 (97.599)
Epoch: [634][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8809 (0.8968)	Acc@1 65.234 (68.823)	Acc@5 98.438 (97.606)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:635/635; Lr: 0.0010000000000000002
batch Size 256
Epoch: [635][0/196]	Time 0.048 (0.048)	Data 0.240 (0.240)	Loss 0.8558 (0.8558)	Acc@1 73.828 (73.828)	Acc@5 98.438 (98.438)
Epoch: [635][64/196]	Time 0.040 (0.037)	Data 0.000 (0.004)	Loss 0.9177 (0.8949)	Acc@1 70.312 (69.171)	Acc@5 96.484 (97.566)
Epoch: [635][128/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8932 (0.8975)	Acc@1 70.703 (69.059)	Acc@5 98.828 (97.547)
Epoch: [635][192/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 0.8725 (0.8961)	Acc@1 70.312 (68.956)	Acc@5 97.656 (97.565)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.25
Max memory: 7.7508608
 7.450s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 4848
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 636
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:636/640; Lr: 0.0010000000000000002
batch Size 256
Epoch: [636][0/196]	Time 0.055 (0.055)	Data 0.257 (0.257)	Loss 0.9290 (0.9290)	Acc@1 69.531 (69.531)	Acc@5 97.656 (97.656)
Epoch: [636][64/196]	Time 0.031 (0.036)	Data 0.000 (0.004)	Loss 0.8306 (0.9131)	Acc@1 71.094 (68.702)	Acc@5 98.438 (97.284)
Epoch: [636][128/196]	Time 0.039 (0.035)	Data 0.000 (0.002)	Loss 0.7897 (0.8971)	Acc@1 72.656 (69.068)	Acc@5 98.828 (97.520)
Epoch: [636][192/196]	Time 0.032 (0.035)	Data 0.000 (0.001)	Loss 0.8806 (0.8964)	Acc@1 70.312 (69.052)	Acc@5 97.266 (97.579)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:637/640; Lr: 0.0010000000000000002
batch Size 256
Epoch: [637][0/196]	Time 0.041 (0.041)	Data 0.227 (0.227)	Loss 0.8625 (0.8625)	Acc@1 69.531 (69.531)	Acc@5 98.047 (98.047)
Epoch: [637][64/196]	Time 0.042 (0.037)	Data 0.000 (0.004)	Loss 0.9337 (0.8865)	Acc@1 72.266 (69.399)	Acc@5 96.484 (97.596)
Epoch: [637][128/196]	Time 0.042 (0.037)	Data 0.000 (0.002)	Loss 0.8020 (0.8890)	Acc@1 75.391 (69.350)	Acc@5 99.219 (97.517)
Epoch: [637][192/196]	Time 0.034 (0.037)	Data 0.000 (0.001)	Loss 0.8313 (0.8945)	Acc@1 71.094 (69.023)	Acc@5 98.438 (97.577)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:638/640; Lr: 0.0010000000000000002
batch Size 256
Epoch: [638][0/196]	Time 0.044 (0.044)	Data 0.270 (0.270)	Loss 0.9464 (0.9464)	Acc@1 64.844 (64.844)	Acc@5 98.047 (98.047)
Epoch: [638][64/196]	Time 0.037 (0.036)	Data 0.000 (0.004)	Loss 0.8477 (0.9011)	Acc@1 69.922 (68.852)	Acc@5 97.266 (97.446)
Epoch: [638][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.9099 (0.8971)	Acc@1 67.969 (68.971)	Acc@5 97.266 (97.462)
Epoch: [638][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9702 (0.8955)	Acc@1 66.016 (68.989)	Acc@5 97.266 (97.494)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:639/640; Lr: 0.0010000000000000002
batch Size 256
Epoch: [639][0/196]	Time 0.053 (0.053)	Data 0.257 (0.257)	Loss 0.9048 (0.9048)	Acc@1 69.922 (69.922)	Acc@5 96.875 (96.875)
Epoch: [639][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.8591 (0.8974)	Acc@1 67.188 (68.852)	Acc@5 98.047 (97.626)
Epoch: [639][128/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8397 (0.8928)	Acc@1 73.828 (69.101)	Acc@5 97.656 (97.641)
Epoch: [639][192/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.8576 (0.8940)	Acc@1 74.609 (69.080)	Acc@5 97.266 (97.632)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:640/640; Lr: 0.0010000000000000002
batch Size 256
Epoch: [640][0/196]	Time 0.041 (0.041)	Data 0.271 (0.271)	Loss 0.9736 (0.9736)	Acc@1 63.672 (63.672)	Acc@5 97.266 (97.266)
Epoch: [640][64/196]	Time 0.031 (0.037)	Data 0.000 (0.004)	Loss 0.9265 (0.8993)	Acc@1 68.750 (68.738)	Acc@5 96.875 (97.674)
Epoch: [640][128/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.8791 (0.8974)	Acc@1 68.359 (68.914)	Acc@5 98.828 (97.611)
Epoch: [640][192/196]	Time 0.032 (0.035)	Data 0.000 (0.002)	Loss 0.8407 (0.8930)	Acc@1 69.531 (68.930)	Acc@5 99.219 (97.658)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.67
Max memory: 7.7508608
 7.265s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6848
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 641
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:641/645; Lr: 0.0010000000000000002
batch Size 256
Epoch: [641][0/196]	Time 0.067 (0.067)	Data 0.307 (0.307)	Loss 0.8830 (0.8830)	Acc@1 69.141 (69.141)	Acc@5 98.438 (98.438)
Epoch: [641][64/196]	Time 0.035 (0.037)	Data 0.000 (0.005)	Loss 0.8218 (0.8974)	Acc@1 72.656 (68.792)	Acc@5 98.047 (97.590)
Epoch: [641][128/196]	Time 0.038 (0.037)	Data 0.000 (0.003)	Loss 0.9296 (0.9054)	Acc@1 67.969 (68.629)	Acc@5 98.438 (97.505)
Epoch: [641][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.9046 (0.8989)	Acc@1 68.750 (68.847)	Acc@5 97.266 (97.553)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:642/645; Lr: 0.0010000000000000002
batch Size 256
Epoch: [642][0/196]	Time 0.053 (0.053)	Data 0.287 (0.287)	Loss 0.9268 (0.9268)	Acc@1 68.750 (68.750)	Acc@5 94.922 (94.922)
Epoch: [642][64/196]	Time 0.032 (0.037)	Data 0.000 (0.005)	Loss 0.8902 (0.8972)	Acc@1 69.922 (68.996)	Acc@5 96.875 (97.518)
Epoch: [642][128/196]	Time 0.040 (0.037)	Data 0.000 (0.002)	Loss 0.8278 (0.8923)	Acc@1 69.922 (69.213)	Acc@5 99.219 (97.568)
Epoch: [642][192/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.8448 (0.8918)	Acc@1 69.922 (69.303)	Acc@5 98.828 (97.604)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:643/645; Lr: 0.0010000000000000002
batch Size 256
Epoch: [643][0/196]	Time 0.044 (0.044)	Data 0.310 (0.310)	Loss 0.8538 (0.8538)	Acc@1 68.359 (68.359)	Acc@5 98.828 (98.828)
Epoch: [643][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8449 (0.9025)	Acc@1 73.828 (68.834)	Acc@5 96.875 (97.548)
Epoch: [643][128/196]	Time 0.033 (0.036)	Data 0.000 (0.003)	Loss 0.9730 (0.8953)	Acc@1 67.969 (68.750)	Acc@5 96.875 (97.623)
Epoch: [643][192/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 0.8431 (0.8945)	Acc@1 69.922 (68.857)	Acc@5 98.047 (97.662)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:644/645; Lr: 0.0010000000000000002
batch Size 256
Epoch: [644][0/196]	Time 0.050 (0.050)	Data 0.268 (0.268)	Loss 0.8990 (0.8990)	Acc@1 69.141 (69.141)	Acc@5 97.656 (97.656)
Epoch: [644][64/196]	Time 0.040 (0.036)	Data 0.000 (0.004)	Loss 0.7771 (0.8872)	Acc@1 74.609 (69.014)	Acc@5 97.656 (97.686)
Epoch: [644][128/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.9512 (0.8919)	Acc@1 66.016 (69.107)	Acc@5 97.266 (97.629)
Epoch: [644][192/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.9352 (0.8926)	Acc@1 67.969 (69.052)	Acc@5 96.484 (97.630)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:645/645; Lr: 0.0010000000000000002
batch Size 256
Epoch: [645][0/196]	Time 0.053 (0.053)	Data 0.246 (0.246)	Loss 0.9123 (0.9123)	Acc@1 65.234 (65.234)	Acc@5 97.656 (97.656)
Epoch: [645][64/196]	Time 0.034 (0.037)	Data 0.000 (0.004)	Loss 0.8950 (0.8874)	Acc@1 71.875 (69.339)	Acc@5 98.438 (97.602)
Epoch: [645][128/196]	Time 0.044 (0.037)	Data 0.000 (0.002)	Loss 0.9377 (0.8926)	Acc@1 67.578 (69.147)	Acc@5 96.875 (97.559)
Epoch: [645][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.8610 (0.8942)	Acc@1 73.047 (68.977)	Acc@5 97.266 (97.557)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.3
Max memory: 7.7508608
 7.347s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3062
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 646
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:646/650; Lr: 0.0010000000000000002
batch Size 256
Epoch: [646][0/196]	Time 0.065 (0.065)	Data 0.245 (0.245)	Loss 0.8717 (0.8717)	Acc@1 72.266 (72.266)	Acc@5 98.438 (98.438)
Epoch: [646][64/196]	Time 0.030 (0.037)	Data 0.000 (0.004)	Loss 0.9608 (0.9038)	Acc@1 64.844 (68.690)	Acc@5 98.828 (97.416)
Epoch: [646][128/196]	Time 0.043 (0.036)	Data 0.000 (0.002)	Loss 0.8805 (0.8956)	Acc@1 69.141 (68.986)	Acc@5 98.047 (97.499)
Epoch: [646][192/196]	Time 0.031 (0.036)	Data 0.000 (0.001)	Loss 0.8512 (0.8980)	Acc@1 73.047 (68.839)	Acc@5 97.266 (97.478)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:647/650; Lr: 0.0010000000000000002
batch Size 256
Epoch: [647][0/196]	Time 0.046 (0.046)	Data 0.266 (0.266)	Loss 0.8720 (0.8720)	Acc@1 70.703 (70.703)	Acc@5 97.656 (97.656)
Epoch: [647][64/196]	Time 0.037 (0.035)	Data 0.000 (0.004)	Loss 1.0332 (0.8998)	Acc@1 66.016 (68.960)	Acc@5 96.484 (97.638)
Epoch: [647][128/196]	Time 0.038 (0.035)	Data 0.000 (0.002)	Loss 0.9111 (0.8959)	Acc@1 68.359 (68.962)	Acc@5 97.266 (97.547)
Epoch: [647][192/196]	Time 0.029 (0.035)	Data 0.000 (0.002)	Loss 0.9200 (0.8928)	Acc@1 65.625 (69.050)	Acc@5 98.047 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:648/650; Lr: 0.0010000000000000002
batch Size 256
Epoch: [648][0/196]	Time 0.035 (0.035)	Data 0.376 (0.376)	Loss 0.9159 (0.9159)	Acc@1 69.531 (69.531)	Acc@5 96.484 (96.484)
Epoch: [648][64/196]	Time 0.038 (0.036)	Data 0.000 (0.006)	Loss 0.8130 (0.8980)	Acc@1 70.703 (69.056)	Acc@5 98.047 (97.470)
Epoch: [648][128/196]	Time 0.038 (0.036)	Data 0.000 (0.003)	Loss 0.9183 (0.8927)	Acc@1 68.750 (69.053)	Acc@5 98.047 (97.596)
Epoch: [648][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9968 (0.8941)	Acc@1 67.969 (68.896)	Acc@5 96.484 (97.658)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:649/650; Lr: 0.0010000000000000002
batch Size 256
Epoch: [649][0/196]	Time 0.042 (0.042)	Data 0.346 (0.346)	Loss 0.8709 (0.8709)	Acc@1 70.703 (70.703)	Acc@5 96.094 (96.094)
Epoch: [649][64/196]	Time 0.038 (0.036)	Data 0.000 (0.005)	Loss 0.8771 (0.8936)	Acc@1 68.359 (69.099)	Acc@5 97.656 (97.548)
Epoch: [649][128/196]	Time 0.032 (0.036)	Data 0.000 (0.003)	Loss 0.9560 (0.8943)	Acc@1 69.531 (68.935)	Acc@5 98.047 (97.565)
Epoch: [649][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.9203 (0.8945)	Acc@1 68.359 (68.932)	Acc@5 96.875 (97.573)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:650/650; Lr: 0.0010000000000000002
batch Size 256
Epoch: [650][0/196]	Time 0.046 (0.046)	Data 0.238 (0.238)	Loss 0.9345 (0.9345)	Acc@1 67.969 (67.969)	Acc@5 96.094 (96.094)
Epoch: [650][64/196]	Time 0.035 (0.036)	Data 0.000 (0.004)	Loss 0.8792 (0.9056)	Acc@1 68.359 (69.171)	Acc@5 98.047 (97.302)
Epoch: [650][128/196]	Time 0.032 (0.035)	Data 0.000 (0.002)	Loss 0.9219 (0.8993)	Acc@1 68.750 (69.032)	Acc@5 97.266 (97.511)
Epoch: [650][192/196]	Time 0.028 (0.035)	Data 0.000 (0.001)	Loss 0.8209 (0.8947)	Acc@1 69.531 (69.041)	Acc@5 97.266 (97.531)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.42
Max memory: 7.7508608
 7.114s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2625
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 651
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:651/655; Lr: 0.0010000000000000002
batch Size 256
Epoch: [651][0/196]	Time 0.063 (0.063)	Data 0.290 (0.290)	Loss 0.9284 (0.9284)	Acc@1 67.578 (67.578)	Acc@5 96.484 (96.484)
Epoch: [651][64/196]	Time 0.031 (0.036)	Data 0.000 (0.005)	Loss 0.8643 (0.8880)	Acc@1 70.312 (69.327)	Acc@5 97.266 (97.632)
Epoch: [651][128/196]	Time 0.042 (0.036)	Data 0.000 (0.002)	Loss 0.9438 (0.8923)	Acc@1 67.188 (68.995)	Acc@5 96.094 (97.562)
Epoch: [651][192/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.9343 (0.8935)	Acc@1 65.625 (68.948)	Acc@5 96.875 (97.551)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:652/655; Lr: 0.0010000000000000002
batch Size 256
Epoch: [652][0/196]	Time 0.069 (0.069)	Data 0.333 (0.333)	Loss 0.9219 (0.9219)	Acc@1 67.969 (67.969)	Acc@5 98.047 (98.047)
Epoch: [652][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8614 (0.8886)	Acc@1 73.047 (68.984)	Acc@5 98.047 (97.806)
Epoch: [652][128/196]	Time 0.041 (0.037)	Data 0.000 (0.003)	Loss 0.9115 (0.8951)	Acc@1 64.844 (69.035)	Acc@5 99.609 (97.641)
Epoch: [652][192/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 0.9026 (0.8953)	Acc@1 70.312 (68.956)	Acc@5 97.656 (97.608)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:653/655; Lr: 0.0010000000000000002
batch Size 256
Epoch: [653][0/196]	Time 0.047 (0.047)	Data 0.253 (0.253)	Loss 0.9383 (0.9383)	Acc@1 67.578 (67.578)	Acc@5 98.047 (98.047)
Epoch: [653][64/196]	Time 0.037 (0.036)	Data 0.000 (0.004)	Loss 0.8844 (0.8934)	Acc@1 70.703 (68.828)	Acc@5 97.656 (97.578)
Epoch: [653][128/196]	Time 0.041 (0.036)	Data 0.000 (0.002)	Loss 0.8913 (0.8925)	Acc@1 70.312 (68.977)	Acc@5 98.047 (97.578)
Epoch: [653][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.8538 (0.8911)	Acc@1 69.922 (69.021)	Acc@5 98.438 (97.630)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:654/655; Lr: 0.0010000000000000002
batch Size 256
Epoch: [654][0/196]	Time 0.053 (0.053)	Data 0.329 (0.329)	Loss 0.7897 (0.7897)	Acc@1 74.609 (74.609)	Acc@5 97.656 (97.656)
Epoch: [654][64/196]	Time 0.036 (0.037)	Data 0.000 (0.005)	Loss 0.8859 (0.8917)	Acc@1 71.094 (69.093)	Acc@5 98.438 (97.692)
Epoch: [654][128/196]	Time 0.037 (0.037)	Data 0.000 (0.003)	Loss 0.8167 (0.8974)	Acc@1 72.656 (69.065)	Acc@5 96.875 (97.574)
Epoch: [654][192/196]	Time 0.039 (0.037)	Data 0.000 (0.002)	Loss 0.8462 (0.8950)	Acc@1 70.703 (69.005)	Acc@5 98.047 (97.608)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:655/655; Lr: 0.0010000000000000002
batch Size 256
Epoch: [655][0/196]	Time 0.042 (0.042)	Data 0.283 (0.283)	Loss 0.9273 (0.9273)	Acc@1 67.578 (67.578)	Acc@5 97.266 (97.266)
Epoch: [655][64/196]	Time 0.031 (0.036)	Data 0.000 (0.005)	Loss 0.8628 (0.8963)	Acc@1 66.797 (68.894)	Acc@5 98.047 (97.476)
Epoch: [655][128/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.8338 (0.8951)	Acc@1 69.531 (68.998)	Acc@5 97.656 (97.520)
Epoch: [655][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.7671 (0.8944)	Acc@1 73.438 (68.956)	Acc@5 99.609 (97.604)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.61
Max memory: 7.7508608
 7.382s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3538
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 656
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:656/660; Lr: 0.0010000000000000002
batch Size 256
Epoch: [656][0/196]	Time 0.096 (0.096)	Data 0.279 (0.279)	Loss 0.9574 (0.9574)	Acc@1 69.531 (69.531)	Acc@5 97.656 (97.656)
Epoch: [656][64/196]	Time 0.034 (0.037)	Data 0.000 (0.004)	Loss 0.8511 (0.8943)	Acc@1 69.922 (69.153)	Acc@5 98.047 (97.698)
Epoch: [656][128/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8584 (0.8926)	Acc@1 71.094 (69.056)	Acc@5 96.875 (97.608)
Epoch: [656][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9288 (0.8926)	Acc@1 65.625 (69.137)	Acc@5 97.656 (97.622)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:657/660; Lr: 0.0010000000000000002
batch Size 256
Epoch: [657][0/196]	Time 0.079 (0.079)	Data 0.288 (0.288)	Loss 0.8810 (0.8810)	Acc@1 73.438 (73.438)	Acc@5 97.656 (97.656)
Epoch: [657][64/196]	Time 0.038 (0.037)	Data 0.000 (0.005)	Loss 0.9772 (0.8857)	Acc@1 67.578 (69.303)	Acc@5 96.875 (97.650)
Epoch: [657][128/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.9804 (0.8930)	Acc@1 67.188 (69.265)	Acc@5 96.484 (97.617)
Epoch: [657][192/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8336 (0.8955)	Acc@1 69.141 (69.118)	Acc@5 98.438 (97.632)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:658/660; Lr: 0.0010000000000000002
batch Size 256
Epoch: [658][0/196]	Time 0.047 (0.047)	Data 0.256 (0.256)	Loss 0.8810 (0.8810)	Acc@1 70.312 (70.312)	Acc@5 97.266 (97.266)
Epoch: [658][64/196]	Time 0.032 (0.035)	Data 0.000 (0.004)	Loss 0.7958 (0.8877)	Acc@1 72.266 (69.213)	Acc@5 96.094 (97.614)
Epoch: [658][128/196]	Time 0.033 (0.034)	Data 0.000 (0.002)	Loss 0.9911 (0.8892)	Acc@1 61.719 (69.180)	Acc@5 97.656 (97.632)
Epoch: [658][192/196]	Time 0.031 (0.034)	Data 0.000 (0.001)	Loss 0.9273 (0.8964)	Acc@1 65.625 (68.873)	Acc@5 98.047 (97.616)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:659/660; Lr: 0.0010000000000000002
batch Size 256
Epoch: [659][0/196]	Time 0.039 (0.039)	Data 0.266 (0.266)	Loss 1.0185 (1.0185)	Acc@1 64.844 (64.844)	Acc@5 96.094 (96.094)
Epoch: [659][64/196]	Time 0.035 (0.036)	Data 0.000 (0.004)	Loss 0.8302 (0.8971)	Acc@1 70.703 (68.504)	Acc@5 99.219 (97.512)
Epoch: [659][128/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8752 (0.8992)	Acc@1 66.406 (68.777)	Acc@5 97.266 (97.493)
Epoch: [659][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.9345 (0.8951)	Acc@1 66.797 (68.997)	Acc@5 97.656 (97.559)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:660/660; Lr: 0.0010000000000000002
batch Size 256
Epoch: [660][0/196]	Time 0.048 (0.048)	Data 0.229 (0.229)	Loss 1.0641 (1.0641)	Acc@1 62.109 (62.109)	Acc@5 95.312 (95.312)
Epoch: [660][64/196]	Time 0.039 (0.033)	Data 0.000 (0.004)	Loss 1.0057 (0.8995)	Acc@1 66.016 (68.924)	Acc@5 96.484 (97.518)
Epoch: [660][128/196]	Time 0.035 (0.034)	Data 0.000 (0.002)	Loss 0.9698 (0.8949)	Acc@1 65.234 (68.962)	Acc@5 96.484 (97.574)
Epoch: [660][192/196]	Time 0.032 (0.035)	Data 0.000 (0.001)	Loss 0.9530 (0.8958)	Acc@1 63.672 (69.043)	Acc@5 97.266 (97.571)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.55
Max memory: 7.7508608
 7.104s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 4539
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 661
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:661/665; Lr: 0.0010000000000000002
batch Size 256
Epoch: [661][0/196]	Time 0.094 (0.094)	Data 0.249 (0.249)	Loss 0.8974 (0.8974)	Acc@1 71.875 (71.875)	Acc@5 98.047 (98.047)
Epoch: [661][64/196]	Time 0.033 (0.037)	Data 0.000 (0.004)	Loss 0.8210 (0.8895)	Acc@1 70.703 (68.738)	Acc@5 98.438 (97.764)
Epoch: [661][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8029 (0.8911)	Acc@1 71.094 (68.692)	Acc@5 97.266 (97.717)
Epoch: [661][192/196]	Time 0.035 (0.036)	Data 0.000 (0.001)	Loss 1.0546 (0.8945)	Acc@1 63.672 (68.695)	Acc@5 96.875 (97.594)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:662/665; Lr: 0.0010000000000000002
batch Size 256
Epoch: [662][0/196]	Time 0.052 (0.052)	Data 0.288 (0.288)	Loss 0.8280 (0.8280)	Acc@1 70.703 (70.703)	Acc@5 98.438 (98.438)
Epoch: [662][64/196]	Time 0.038 (0.036)	Data 0.000 (0.005)	Loss 0.9260 (0.8929)	Acc@1 67.188 (69.573)	Acc@5 96.484 (97.452)
Epoch: [662][128/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8286 (0.8993)	Acc@1 68.750 (69.174)	Acc@5 98.828 (97.456)
Epoch: [662][192/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.8571 (0.8972)	Acc@1 70.703 (69.112)	Acc@5 96.875 (97.587)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:663/665; Lr: 0.0010000000000000002
batch Size 256
Epoch: [663][0/196]	Time 0.043 (0.043)	Data 0.328 (0.328)	Loss 0.8859 (0.8859)	Acc@1 69.141 (69.141)	Acc@5 98.047 (98.047)
Epoch: [663][64/196]	Time 0.032 (0.036)	Data 0.000 (0.005)	Loss 0.8220 (0.8881)	Acc@1 71.094 (69.465)	Acc@5 96.875 (97.392)
Epoch: [663][128/196]	Time 0.037 (0.036)	Data 0.005 (0.003)	Loss 0.9183 (0.8922)	Acc@1 64.453 (69.113)	Acc@5 98.047 (97.514)
Epoch: [663][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8688 (0.8949)	Acc@1 69.531 (68.975)	Acc@5 99.219 (97.462)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:664/665; Lr: 0.0010000000000000002
batch Size 256
Epoch: [664][0/196]	Time 0.048 (0.048)	Data 0.289 (0.289)	Loss 0.9076 (0.9076)	Acc@1 67.578 (67.578)	Acc@5 96.484 (96.484)
Epoch: [664][64/196]	Time 0.032 (0.037)	Data 0.000 (0.005)	Loss 0.7308 (0.8876)	Acc@1 78.125 (69.219)	Acc@5 98.047 (97.632)
Epoch: [664][128/196]	Time 0.047 (0.037)	Data 0.000 (0.002)	Loss 0.9560 (0.8958)	Acc@1 64.844 (69.001)	Acc@5 97.656 (97.665)
Epoch: [664][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8930 (0.8940)	Acc@1 69.531 (69.108)	Acc@5 98.828 (97.660)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:665/665; Lr: 0.0010000000000000002
batch Size 256
Epoch: [665][0/196]	Time 0.043 (0.043)	Data 0.236 (0.236)	Loss 0.9110 (0.9110)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [665][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.8544 (0.8962)	Acc@1 72.266 (69.075)	Acc@5 98.047 (97.476)
Epoch: [665][128/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 0.9572 (0.8973)	Acc@1 67.188 (68.998)	Acc@5 96.094 (97.571)
Epoch: [665][192/196]	Time 0.030 (0.037)	Data 0.000 (0.001)	Loss 0.9019 (0.8982)	Acc@1 67.188 (68.823)	Acc@5 98.438 (97.531)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.04
Max memory: 7.7508608
 7.457s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3646
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 666
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:666/670; Lr: 0.0010000000000000002
batch Size 256
Epoch: [666][0/196]	Time 0.079 (0.079)	Data 0.288 (0.288)	Loss 0.8104 (0.8104)	Acc@1 73.047 (73.047)	Acc@5 97.656 (97.656)
Epoch: [666][64/196]	Time 0.032 (0.037)	Data 0.000 (0.005)	Loss 0.9041 (0.8955)	Acc@1 67.969 (69.147)	Acc@5 96.094 (97.536)
Epoch: [666][128/196]	Time 0.041 (0.037)	Data 0.000 (0.002)	Loss 0.9721 (0.8966)	Acc@1 62.109 (69.026)	Acc@5 96.484 (97.605)
Epoch: [666][192/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.8431 (0.8927)	Acc@1 72.656 (69.068)	Acc@5 98.438 (97.579)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:667/670; Lr: 0.0010000000000000002
batch Size 256
Epoch: [667][0/196]	Time 0.046 (0.046)	Data 0.302 (0.302)	Loss 0.7436 (0.7436)	Acc@1 76.953 (76.953)	Acc@5 98.047 (98.047)
Epoch: [667][64/196]	Time 0.037 (0.036)	Data 0.000 (0.005)	Loss 0.8345 (0.8975)	Acc@1 71.094 (69.135)	Acc@5 98.828 (97.542)
Epoch: [667][128/196]	Time 0.028 (0.036)	Data 0.000 (0.003)	Loss 0.8020 (0.8963)	Acc@1 73.047 (69.044)	Acc@5 98.438 (97.574)
Epoch: [667][192/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.8505 (0.8964)	Acc@1 71.094 (68.912)	Acc@5 98.047 (97.632)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:668/670; Lr: 0.0010000000000000002
batch Size 256
Epoch: [668][0/196]	Time 0.043 (0.043)	Data 0.248 (0.248)	Loss 0.8873 (0.8873)	Acc@1 69.531 (69.531)	Acc@5 98.438 (98.438)
Epoch: [668][64/196]	Time 0.040 (0.036)	Data 0.000 (0.004)	Loss 0.8486 (0.8965)	Acc@1 69.922 (68.780)	Acc@5 98.438 (97.602)
Epoch: [668][128/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.8956 (0.9007)	Acc@1 66.797 (68.711)	Acc@5 96.094 (97.447)
Epoch: [668][192/196]	Time 0.031 (0.036)	Data 0.000 (0.001)	Loss 0.8876 (0.8987)	Acc@1 71.875 (68.716)	Acc@5 94.922 (97.519)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:669/670; Lr: 0.0010000000000000002
batch Size 256
Epoch: [669][0/196]	Time 0.041 (0.041)	Data 0.290 (0.290)	Loss 0.8483 (0.8483)	Acc@1 70.703 (70.703)	Acc@5 98.438 (98.438)
Epoch: [669][64/196]	Time 0.033 (0.035)	Data 0.000 (0.005)	Loss 0.9164 (0.8849)	Acc@1 66.406 (69.369)	Acc@5 98.438 (97.740)
Epoch: [669][128/196]	Time 0.031 (0.034)	Data 0.000 (0.002)	Loss 0.8686 (0.8901)	Acc@1 67.578 (69.165)	Acc@5 96.875 (97.535)
Epoch: [669][192/196]	Time 0.031 (0.034)	Data 0.000 (0.002)	Loss 0.8094 (0.8908)	Acc@1 70.312 (69.048)	Acc@5 99.219 (97.600)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:670/670; Lr: 0.0010000000000000002
batch Size 256
Epoch: [670][0/196]	Time 0.048 (0.048)	Data 0.269 (0.269)	Loss 0.9113 (0.9113)	Acc@1 67.578 (67.578)	Acc@5 97.266 (97.266)
Epoch: [670][64/196]	Time 0.040 (0.036)	Data 0.000 (0.004)	Loss 0.8177 (0.9030)	Acc@1 71.484 (68.972)	Acc@5 98.438 (97.410)
Epoch: [670][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8681 (0.8987)	Acc@1 69.531 (68.947)	Acc@5 97.266 (97.535)
Epoch: [670][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8612 (0.8965)	Acc@1 71.484 (68.965)	Acc@5 96.875 (97.587)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.08
Max memory: 7.7508608
 7.430s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 1660
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 671
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:671/675; Lr: 0.0010000000000000002
batch Size 256
Epoch: [671][0/196]	Time 0.070 (0.070)	Data 0.282 (0.282)	Loss 0.8465 (0.8465)	Acc@1 69.922 (69.922)	Acc@5 98.438 (98.438)
Epoch: [671][64/196]	Time 0.034 (0.037)	Data 0.000 (0.005)	Loss 0.8369 (0.8785)	Acc@1 73.047 (70.018)	Acc@5 96.875 (97.458)
Epoch: [671][128/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.8892 (0.8848)	Acc@1 68.359 (69.574)	Acc@5 96.875 (97.562)
Epoch: [671][192/196]	Time 0.027 (0.036)	Data 0.000 (0.002)	Loss 0.9820 (0.8930)	Acc@1 65.234 (69.199)	Acc@5 96.094 (97.587)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:672/675; Lr: 0.0010000000000000002
batch Size 256
Epoch: [672][0/196]	Time 0.045 (0.045)	Data 0.302 (0.302)	Loss 0.8525 (0.8525)	Acc@1 70.703 (70.703)	Acc@5 97.656 (97.656)
Epoch: [672][64/196]	Time 0.040 (0.037)	Data 0.000 (0.005)	Loss 1.0078 (0.8862)	Acc@1 64.062 (69.237)	Acc@5 96.875 (97.608)
Epoch: [672][128/196]	Time 0.037 (0.037)	Data 0.000 (0.003)	Loss 0.9289 (0.8934)	Acc@1 66.016 (69.277)	Acc@5 97.656 (97.668)
Epoch: [672][192/196]	Time 0.032 (0.037)	Data 0.000 (0.002)	Loss 0.9896 (0.8943)	Acc@1 62.500 (69.145)	Acc@5 98.828 (97.654)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:673/675; Lr: 0.0010000000000000002
batch Size 256
Epoch: [673][0/196]	Time 0.042 (0.042)	Data 0.294 (0.294)	Loss 0.8228 (0.8228)	Acc@1 72.656 (72.656)	Acc@5 98.438 (98.438)
Epoch: [673][64/196]	Time 0.049 (0.037)	Data 0.000 (0.005)	Loss 1.0008 (0.8917)	Acc@1 64.062 (69.201)	Acc@5 95.703 (97.512)
Epoch: [673][128/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 0.9055 (0.8960)	Acc@1 69.922 (69.062)	Acc@5 98.438 (97.505)
Epoch: [673][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.9124 (0.8942)	Acc@1 67.578 (69.090)	Acc@5 96.094 (97.531)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:674/675; Lr: 0.0010000000000000002
batch Size 256
Epoch: [674][0/196]	Time 0.056 (0.056)	Data 0.356 (0.356)	Loss 0.8164 (0.8164)	Acc@1 73.047 (73.047)	Acc@5 98.438 (98.438)
Epoch: [674][64/196]	Time 0.038 (0.037)	Data 0.000 (0.006)	Loss 0.9137 (0.8888)	Acc@1 64.062 (68.942)	Acc@5 97.266 (97.837)
Epoch: [674][128/196]	Time 0.033 (0.036)	Data 0.000 (0.003)	Loss 0.8984 (0.8958)	Acc@1 68.359 (68.938)	Acc@5 98.047 (97.614)
Epoch: [674][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8404 (0.8963)	Acc@1 68.359 (68.930)	Acc@5 97.656 (97.606)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:675/675; Lr: 0.0010000000000000002
batch Size 256
Epoch: [675][0/196]	Time 0.051 (0.051)	Data 0.273 (0.273)	Loss 0.9010 (0.9010)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [675][64/196]	Time 0.036 (0.036)	Data 0.000 (0.004)	Loss 0.8635 (0.8961)	Acc@1 70.703 (68.528)	Acc@5 98.047 (97.542)
Epoch: [675][128/196]	Time 0.029 (0.036)	Data 0.000 (0.002)	Loss 1.0010 (0.8981)	Acc@1 64.062 (68.665)	Acc@5 96.875 (97.547)
Epoch: [675][192/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.8465 (0.8974)	Acc@1 73.828 (68.811)	Acc@5 98.438 (97.555)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.13
Max memory: 7.7508608
 7.436s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 8422
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 676
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:676/680; Lr: 0.0010000000000000002
batch Size 256
Epoch: [676][0/196]	Time 0.072 (0.072)	Data 0.308 (0.308)	Loss 0.9756 (0.9756)	Acc@1 66.406 (66.406)	Acc@5 96.875 (96.875)
Epoch: [676][64/196]	Time 0.033 (0.036)	Data 0.000 (0.005)	Loss 0.9185 (0.8948)	Acc@1 67.578 (69.249)	Acc@5 96.484 (97.578)
Epoch: [676][128/196]	Time 0.032 (0.036)	Data 0.000 (0.003)	Loss 0.8756 (0.8954)	Acc@1 69.531 (69.216)	Acc@5 98.438 (97.472)
Epoch: [676][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9269 (0.8965)	Acc@1 70.312 (68.975)	Acc@5 95.703 (97.490)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:677/680; Lr: 0.0010000000000000002
batch Size 256
Epoch: [677][0/196]	Time 0.047 (0.047)	Data 0.228 (0.228)	Loss 0.7830 (0.7830)	Acc@1 75.391 (75.391)	Acc@5 97.266 (97.266)
Epoch: [677][64/196]	Time 0.038 (0.037)	Data 0.000 (0.004)	Loss 0.9120 (0.8875)	Acc@1 67.578 (69.423)	Acc@5 97.266 (97.794)
Epoch: [677][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8691 (0.8884)	Acc@1 70.703 (69.289)	Acc@5 97.266 (97.668)
Epoch: [677][192/196]	Time 0.038 (0.036)	Data 0.000 (0.001)	Loss 0.9893 (0.8917)	Acc@1 62.891 (69.228)	Acc@5 95.703 (97.602)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:678/680; Lr: 0.0010000000000000002
batch Size 256
Epoch: [678][0/196]	Time 0.056 (0.056)	Data 0.331 (0.331)	Loss 0.8449 (0.8449)	Acc@1 71.484 (71.484)	Acc@5 97.656 (97.656)
Epoch: [678][64/196]	Time 0.033 (0.036)	Data 0.000 (0.005)	Loss 0.9394 (0.9012)	Acc@1 67.188 (68.792)	Acc@5 96.875 (97.602)
Epoch: [678][128/196]	Time 0.039 (0.036)	Data 0.000 (0.003)	Loss 0.8578 (0.8961)	Acc@1 68.359 (68.871)	Acc@5 98.047 (97.584)
Epoch: [678][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.8260 (0.8938)	Acc@1 73.047 (68.973)	Acc@5 98.438 (97.616)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:679/680; Lr: 0.0010000000000000002
batch Size 256
Epoch: [679][0/196]	Time 0.047 (0.047)	Data 0.249 (0.249)	Loss 0.8538 (0.8538)	Acc@1 69.922 (69.922)	Acc@5 98.047 (98.047)
Epoch: [679][64/196]	Time 0.030 (0.036)	Data 0.000 (0.004)	Loss 0.9063 (0.8935)	Acc@1 68.359 (69.387)	Acc@5 98.047 (97.548)
Epoch: [679][128/196]	Time 0.028 (0.034)	Data 0.000 (0.002)	Loss 0.7696 (0.8948)	Acc@1 73.047 (69.001)	Acc@5 98.828 (97.559)
Epoch: [679][192/196]	Time 0.034 (0.034)	Data 0.000 (0.001)	Loss 0.8947 (0.8935)	Acc@1 69.141 (69.131)	Acc@5 98.047 (97.604)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:680/680; Lr: 0.0010000000000000002
batch Size 256
Epoch: [680][0/196]	Time 0.040 (0.040)	Data 0.339 (0.339)	Loss 0.8000 (0.8000)	Acc@1 74.609 (74.609)	Acc@5 98.047 (98.047)
Epoch: [680][64/196]	Time 0.038 (0.036)	Data 0.000 (0.005)	Loss 0.8999 (0.8878)	Acc@1 70.312 (69.243)	Acc@5 96.875 (97.692)
Epoch: [680][128/196]	Time 0.032 (0.035)	Data 0.000 (0.003)	Loss 0.9413 (0.8923)	Acc@1 66.406 (68.953)	Acc@5 98.438 (97.680)
Epoch: [680][192/196]	Time 0.031 (0.035)	Data 0.000 (0.002)	Loss 0.8691 (0.8932)	Acc@1 70.312 (68.922)	Acc@5 97.656 (97.650)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.54
Max memory: 7.7508608
 7.207s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5686
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 681
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:681/685; Lr: 0.0010000000000000002
batch Size 256
Epoch: [681][0/196]	Time 0.087 (0.087)	Data 0.254 (0.254)	Loss 0.8342 (0.8342)	Acc@1 75.000 (75.000)	Acc@5 97.266 (97.266)
Epoch: [681][64/196]	Time 0.035 (0.036)	Data 0.000 (0.004)	Loss 0.8473 (0.8961)	Acc@1 67.188 (68.870)	Acc@5 98.828 (97.488)
Epoch: [681][128/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.8727 (0.8941)	Acc@1 69.531 (68.932)	Acc@5 98.047 (97.568)
Epoch: [681][192/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 0.9193 (0.8941)	Acc@1 69.141 (69.009)	Acc@5 99.219 (97.575)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:682/685; Lr: 0.0010000000000000002
batch Size 256
Epoch: [682][0/196]	Time 0.051 (0.051)	Data 0.320 (0.320)	Loss 0.8716 (0.8716)	Acc@1 68.750 (68.750)	Acc@5 97.266 (97.266)
Epoch: [682][64/196]	Time 0.040 (0.036)	Data 0.000 (0.005)	Loss 0.8495 (0.9056)	Acc@1 69.141 (68.456)	Acc@5 98.047 (97.446)
Epoch: [682][128/196]	Time 0.038 (0.036)	Data 0.000 (0.003)	Loss 0.7759 (0.8944)	Acc@1 71.484 (69.004)	Acc@5 98.438 (97.550)
Epoch: [682][192/196]	Time 0.045 (0.037)	Data 0.000 (0.002)	Loss 1.0438 (0.8949)	Acc@1 64.453 (68.928)	Acc@5 95.312 (97.486)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:683/685; Lr: 0.0010000000000000002
batch Size 256
Epoch: [683][0/196]	Time 0.049 (0.049)	Data 0.268 (0.268)	Loss 0.8931 (0.8931)	Acc@1 67.969 (67.969)	Acc@5 96.875 (96.875)
Epoch: [683][64/196]	Time 0.033 (0.036)	Data 0.000 (0.004)	Loss 0.8932 (0.8951)	Acc@1 67.188 (69.183)	Acc@5 98.438 (97.566)
Epoch: [683][128/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.9352 (0.8979)	Acc@1 69.141 (69.071)	Acc@5 96.094 (97.605)
Epoch: [683][192/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.8762 (0.8926)	Acc@1 69.922 (69.232)	Acc@5 97.266 (97.555)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:684/685; Lr: 0.0010000000000000002
batch Size 256
Epoch: [684][0/196]	Time 0.032 (0.032)	Data 0.309 (0.309)	Loss 1.0024 (1.0024)	Acc@1 64.062 (64.062)	Acc@5 96.094 (96.094)
Epoch: [684][64/196]	Time 0.033 (0.035)	Data 0.000 (0.005)	Loss 0.8981 (0.8935)	Acc@1 65.234 (69.117)	Acc@5 98.047 (97.548)
Epoch: [684][128/196]	Time 0.034 (0.035)	Data 0.000 (0.003)	Loss 0.9203 (0.8915)	Acc@1 69.141 (69.150)	Acc@5 97.656 (97.568)
Epoch: [684][192/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.9364 (0.8890)	Acc@1 65.234 (69.159)	Acc@5 96.875 (97.628)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:685/685; Lr: 0.0010000000000000002
batch Size 256
Epoch: [685][0/196]	Time 0.055 (0.055)	Data 0.243 (0.243)	Loss 0.8521 (0.8521)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [685][64/196]	Time 0.033 (0.037)	Data 0.000 (0.004)	Loss 0.9031 (0.8887)	Acc@1 71.094 (69.014)	Acc@5 97.656 (97.620)
Epoch: [685][128/196]	Time 0.039 (0.036)	Data 0.000 (0.002)	Loss 0.8787 (0.8899)	Acc@1 69.141 (69.065)	Acc@5 99.219 (97.644)
Epoch: [685][192/196]	Time 0.029 (0.036)	Data 0.000 (0.001)	Loss 0.9481 (0.8926)	Acc@1 67.188 (68.918)	Acc@5 96.875 (97.620)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.46
Max memory: 7.7508608
 7.354s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5119
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 686
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:686/690; Lr: 0.0010000000000000002
batch Size 256
Epoch: [686][0/196]	Time 0.079 (0.079)	Data 0.228 (0.228)	Loss 0.9460 (0.9460)	Acc@1 65.625 (65.625)	Acc@5 98.828 (98.828)
Epoch: [686][64/196]	Time 0.036 (0.037)	Data 0.000 (0.004)	Loss 0.8716 (0.8886)	Acc@1 70.312 (69.525)	Acc@5 98.438 (97.686)
Epoch: [686][128/196]	Time 0.055 (0.038)	Data 0.000 (0.002)	Loss 0.7928 (0.8910)	Acc@1 70.703 (69.404)	Acc@5 98.438 (97.599)
Epoch: [686][192/196]	Time 0.031 (0.037)	Data 0.000 (0.001)	Loss 0.9207 (0.8905)	Acc@1 65.234 (69.280)	Acc@5 97.266 (97.620)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:687/690; Lr: 0.0010000000000000002
batch Size 256
Epoch: [687][0/196]	Time 0.057 (0.057)	Data 0.218 (0.218)	Loss 0.9581 (0.9581)	Acc@1 67.188 (67.188)	Acc@5 95.703 (95.703)
Epoch: [687][64/196]	Time 0.032 (0.038)	Data 0.000 (0.004)	Loss 0.8893 (0.9016)	Acc@1 68.750 (68.648)	Acc@5 97.656 (97.536)
Epoch: [687][128/196]	Time 0.036 (0.037)	Data 0.000 (0.002)	Loss 0.9355 (0.8984)	Acc@1 69.531 (68.856)	Acc@5 96.875 (97.578)
Epoch: [687][192/196]	Time 0.035 (0.037)	Data 0.000 (0.001)	Loss 0.9664 (0.8946)	Acc@1 66.406 (69.009)	Acc@5 98.438 (97.622)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:688/690; Lr: 0.0010000000000000002
batch Size 256
Epoch: [688][0/196]	Time 0.047 (0.047)	Data 0.239 (0.239)	Loss 0.8292 (0.8292)	Acc@1 68.750 (68.750)	Acc@5 98.828 (98.828)
Epoch: [688][64/196]	Time 0.037 (0.037)	Data 0.000 (0.004)	Loss 0.8625 (0.9023)	Acc@1 72.656 (68.786)	Acc@5 97.266 (97.512)
Epoch: [688][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.7953 (0.8964)	Acc@1 73.438 (68.789)	Acc@5 98.828 (97.611)
Epoch: [688][192/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 0.8754 (0.8967)	Acc@1 68.359 (68.813)	Acc@5 98.828 (97.622)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:689/690; Lr: 0.0010000000000000002
batch Size 256
Epoch: [689][0/196]	Time 0.042 (0.042)	Data 0.237 (0.237)	Loss 0.9232 (0.9232)	Acc@1 67.969 (67.969)	Acc@5 96.484 (96.484)
Epoch: [689][64/196]	Time 0.032 (0.032)	Data 0.000 (0.004)	Loss 0.8709 (0.8938)	Acc@1 69.141 (69.093)	Acc@5 98.438 (97.620)
Epoch: [689][128/196]	Time 0.033 (0.034)	Data 0.000 (0.002)	Loss 0.8668 (0.8933)	Acc@1 69.922 (69.107)	Acc@5 97.266 (97.617)
Epoch: [689][192/196]	Time 0.034 (0.035)	Data 0.000 (0.001)	Loss 0.8827 (0.8922)	Acc@1 66.406 (69.090)	Acc@5 96.484 (97.626)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:690/690; Lr: 0.0010000000000000002
batch Size 256
Epoch: [690][0/196]	Time 0.047 (0.047)	Data 0.298 (0.298)	Loss 0.8534 (0.8534)	Acc@1 69.531 (69.531)	Acc@5 97.656 (97.656)
Epoch: [690][64/196]	Time 0.032 (0.036)	Data 0.000 (0.005)	Loss 0.8173 (0.8858)	Acc@1 71.484 (68.876)	Acc@5 98.438 (97.698)
Epoch: [690][128/196]	Time 0.034 (0.037)	Data 0.000 (0.002)	Loss 0.8403 (0.8879)	Acc@1 68.750 (68.995)	Acc@5 98.828 (97.599)
Epoch: [690][192/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.9367 (0.8952)	Acc@1 66.797 (68.829)	Acc@5 97.656 (97.612)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.7
Max memory: 7.7508608
 7.495s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6987
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 691
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:691/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [691][0/196]	Time 0.064 (0.064)	Data 0.270 (0.270)	Loss 0.9311 (0.9311)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [691][64/196]	Time 0.038 (0.036)	Data 0.000 (0.004)	Loss 0.8622 (0.8861)	Acc@1 69.141 (69.363)	Acc@5 98.438 (97.843)
Epoch: [691][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8316 (0.8931)	Acc@1 69.922 (69.222)	Acc@5 97.656 (97.614)
Epoch: [691][192/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 1.0068 (0.8944)	Acc@1 66.016 (69.094)	Acc@5 97.266 (97.594)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:692/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [692][0/196]	Time 0.045 (0.045)	Data 0.298 (0.298)	Loss 0.9171 (0.9171)	Acc@1 69.141 (69.141)	Acc@5 96.094 (96.094)
Epoch: [692][64/196]	Time 0.035 (0.036)	Data 0.000 (0.005)	Loss 0.9552 (0.8967)	Acc@1 66.016 (68.498)	Acc@5 96.094 (97.632)
Epoch: [692][128/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.9492 (0.9010)	Acc@1 68.359 (68.562)	Acc@5 94.531 (97.520)
Epoch: [692][192/196]	Time 0.030 (0.036)	Data 0.000 (0.002)	Loss 0.9716 (0.8974)	Acc@1 66.016 (68.764)	Acc@5 99.219 (97.529)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:693/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [693][0/196]	Time 0.046 (0.046)	Data 0.202 (0.202)	Loss 1.0319 (1.0319)	Acc@1 64.453 (64.453)	Acc@5 98.047 (98.047)
Epoch: [693][64/196]	Time 0.031 (0.036)	Data 0.000 (0.003)	Loss 0.9390 (0.8934)	Acc@1 70.312 (69.483)	Acc@5 96.875 (97.572)
Epoch: [693][128/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.8029 (0.8910)	Acc@1 75.000 (69.256)	Acc@5 97.266 (97.656)
Epoch: [693][192/196]	Time 0.032 (0.036)	Data 0.000 (0.001)	Loss 0.9521 (0.8941)	Acc@1 63.281 (68.967)	Acc@5 97.266 (97.642)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:694/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [694][0/196]	Time 0.048 (0.048)	Data 0.277 (0.277)	Loss 0.8081 (0.8081)	Acc@1 70.703 (70.703)	Acc@5 98.438 (98.438)
Epoch: [694][64/196]	Time 0.031 (0.036)	Data 0.000 (0.004)	Loss 0.8595 (0.8724)	Acc@1 68.359 (69.615)	Acc@5 98.047 (97.800)
Epoch: [694][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8482 (0.8889)	Acc@1 69.531 (69.280)	Acc@5 98.047 (97.699)
Epoch: [694][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.8858 (0.8925)	Acc@1 68.750 (69.124)	Acc@5 96.875 (97.660)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:695/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [695][0/196]	Time 0.045 (0.045)	Data 0.270 (0.270)	Loss 0.9838 (0.9838)	Acc@1 64.844 (64.844)	Acc@5 98.438 (98.438)
Epoch: [695][64/196]	Time 0.034 (0.036)	Data 0.000 (0.004)	Loss 0.8796 (0.9011)	Acc@1 71.484 (68.744)	Acc@5 97.656 (97.686)
Epoch: [695][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.9967 (0.8993)	Acc@1 62.891 (68.935)	Acc@5 96.875 (97.665)
Epoch: [695][192/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.9118 (0.8967)	Acc@1 69.141 (68.908)	Acc@5 97.656 (97.616)
Max memory in training epoch: 5.2904448


now deeper1


Stage:  0


	Block:  0
size:8, 8, 3, 3; j: 2
conv: 5
layerin This Block: 2
bn: 7
Länge der ModuleListe: 40
j: 8; i: 3


	Block:  1
size:8, 8, 3, 3; j: 10
conv: 13
layerin This Block: 2
bn: 15
Länge der ModuleListe: 42
j: 16; i: 3


	Block:  2
size:16, 8, 3, 3; j: 18
conv: 21
layerin This Block: 2
bn: 23
Länge der ModuleListe: 44
j: 24; i: 3


	Block:  3
size:16, 16, 3, 3; j: 26
conv: 29
layerin This Block: 2
bn: 31
Länge der ModuleListe: 46
j: 32; i: 3


	Block:  4
size:32, 16, 3, 3; j: 34
conv: 37
layerin This Block: 2
bn: 39
Länge der ModuleListe: 48
j: 40; i: 3


Stage:  1


	Block:  0
size:32, 32, 3, 3; j: 42
conv: 45
layerin This Block: 3
bn: 47
Länge der ModuleListe: 50
j: 48; i: 3


	Block:  1
Traceback (most recent call last):
  File "main.py", line 965, in <module>
    main()
  File "main.py", line 545, in main
    model = model.deeper()
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 1027, in deeper
    module = self.module_list[j]
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/container.py", line 147, in __getitem__
    return self._modules[self._get_abs_string_index(idx)]
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/container.py", line 137, in _get_abs_string_index
    raise IndexError('index {} is out of range'.format(idx))
IndexError: index 50 is out of range
j: 181 bis 185
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2080
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 691
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:691/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [691][0/196]	Time 0.086 (0.086)	Data 0.266 (0.266)	Loss 0.8872 (0.8872)	Acc@1 69.922 (69.922)	Acc@5 98.438 (98.438)
Epoch: [691][64/196]	Time 0.031 (0.036)	Data 0.000 (0.004)	Loss 0.9188 (0.8926)	Acc@1 66.016 (68.810)	Acc@5 96.484 (97.746)
Epoch: [691][128/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.8939 (0.8980)	Acc@1 70.312 (68.838)	Acc@5 96.875 (97.687)
Epoch: [691][192/196]	Time 0.036 (0.036)	Data 0.000 (0.002)	Loss 0.8482 (0.8953)	Acc@1 71.094 (68.977)	Acc@5 98.438 (97.652)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:692/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [692][0/196]	Time 0.045 (0.045)	Data 0.246 (0.246)	Loss 0.9575 (0.9575)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [692][64/196]	Time 0.032 (0.037)	Data 0.000 (0.004)	Loss 0.8290 (0.8843)	Acc@1 72.656 (69.387)	Acc@5 98.047 (97.626)
Epoch: [692][128/196]	Time 0.041 (0.036)	Data 0.000 (0.002)	Loss 0.9467 (0.8904)	Acc@1 66.016 (68.989)	Acc@5 97.656 (97.602)
Epoch: [692][192/196]	Time 0.031 (0.036)	Data 0.000 (0.001)	Loss 0.9706 (0.8966)	Acc@1 66.406 (68.867)	Acc@5 98.047 (97.549)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:693/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [693][0/196]	Time 0.040 (0.040)	Data 0.263 (0.263)	Loss 0.9693 (0.9693)	Acc@1 69.141 (69.141)	Acc@5 97.266 (97.266)
Epoch: [693][64/196]	Time 0.039 (0.036)	Data 0.000 (0.004)	Loss 0.9361 (0.8931)	Acc@1 65.234 (69.423)	Acc@5 98.438 (97.686)
Epoch: [693][128/196]	Time 0.028 (0.036)	Data 0.000 (0.002)	Loss 0.9966 (0.8972)	Acc@1 66.797 (68.941)	Acc@5 96.484 (97.626)
Epoch: [693][192/196]	Time 0.041 (0.036)	Data 0.000 (0.002)	Loss 0.9958 (0.8953)	Acc@1 61.328 (69.035)	Acc@5 97.656 (97.656)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:694/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [694][0/196]	Time 0.047 (0.047)	Data 0.257 (0.257)	Loss 0.7824 (0.7824)	Acc@1 70.703 (70.703)	Acc@5 99.609 (99.609)
Epoch: [694][64/196]	Time 0.036 (0.036)	Data 0.000 (0.004)	Loss 0.8570 (0.8983)	Acc@1 71.875 (68.768)	Acc@5 96.484 (97.536)
Epoch: [694][128/196]	Time 0.038 (0.036)	Data 0.000 (0.002)	Loss 0.8727 (0.8980)	Acc@1 73.438 (68.808)	Acc@5 97.266 (97.665)
Epoch: [694][192/196]	Time 0.032 (0.036)	Data 0.000 (0.001)	Loss 0.8938 (0.8930)	Acc@1 66.016 (69.086)	Acc@5 97.656 (97.612)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:695/695; Lr: 0.0010000000000000002
batch Size 256
Epoch: [695][0/196]	Time 0.046 (0.046)	Data 0.231 (0.231)	Loss 0.8015 (0.8015)	Acc@1 74.219 (74.219)	Acc@5 97.656 (97.656)
Epoch: [695][64/196]	Time 0.036 (0.034)	Data 0.000 (0.004)	Loss 0.9428 (0.8997)	Acc@1 67.969 (68.726)	Acc@5 98.047 (97.596)
Epoch: [695][128/196]	Time 0.037 (0.035)	Data 0.000 (0.002)	Loss 0.8507 (0.8953)	Acc@1 71.875 (68.995)	Acc@5 98.047 (97.665)
Epoch: [695][192/196]	Time 0.036 (0.035)	Data 0.000 (0.001)	Loss 0.8959 (0.8953)	Acc@1 69.141 (69.019)	Acc@5 96.484 (97.650)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.88
Max memory: 7.7508608
 7.163s  j: 186 bis 190
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6113
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 696
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:696/700; Lr: 0.0010000000000000002
batch Size 256
Epoch: [696][0/196]	Time 0.052 (0.052)	Data 0.267 (0.267)	Loss 1.0296 (1.0296)	Acc@1 61.328 (61.328)	Acc@5 97.656 (97.656)
Epoch: [696][64/196]	Time 0.039 (0.036)	Data 0.000 (0.004)	Loss 0.9169 (0.8867)	Acc@1 68.359 (69.399)	Acc@5 96.484 (97.734)
Epoch: [696][128/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8803 (0.8878)	Acc@1 71.484 (69.319)	Acc@5 95.703 (97.659)
Epoch: [696][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.9091 (0.8937)	Acc@1 69.531 (69.112)	Acc@5 97.266 (97.567)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:697/700; Lr: 0.0010000000000000002
batch Size 256
Epoch: [697][0/196]	Time 0.060 (0.060)	Data 0.329 (0.329)	Loss 0.8368 (0.8368)	Acc@1 70.703 (70.703)	Acc@5 98.828 (98.828)
Epoch: [697][64/196]	Time 0.029 (0.037)	Data 0.000 (0.005)	Loss 0.8157 (0.8938)	Acc@1 73.047 (69.309)	Acc@5 96.484 (97.530)
Epoch: [697][128/196]	Time 0.037 (0.036)	Data 0.000 (0.003)	Loss 0.8641 (0.8957)	Acc@1 70.703 (69.010)	Acc@5 96.875 (97.641)
Epoch: [697][192/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.8309 (0.8965)	Acc@1 73.047 (68.977)	Acc@5 98.828 (97.583)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:698/700; Lr: 0.0010000000000000002
batch Size 256
Epoch: [698][0/196]	Time 0.050 (0.050)	Data 0.300 (0.300)	Loss 0.8858 (0.8858)	Acc@1 71.875 (71.875)	Acc@5 96.484 (96.484)
Epoch: [698][64/196]	Time 0.039 (0.038)	Data 0.000 (0.005)	Loss 0.9535 (0.8933)	Acc@1 68.750 (69.123)	Acc@5 96.484 (97.494)
Epoch: [698][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.9122 (0.8910)	Acc@1 66.797 (69.107)	Acc@5 97.266 (97.550)
Epoch: [698][192/196]	Time 0.038 (0.037)	Data 0.000 (0.002)	Loss 0.9354 (0.8950)	Acc@1 64.062 (69.045)	Acc@5 97.656 (97.569)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:699/700; Lr: 0.0010000000000000002
batch Size 256
Epoch: [699][0/196]	Time 0.064 (0.064)	Data 0.294 (0.294)	Loss 0.7925 (0.7925)	Acc@1 69.531 (69.531)	Acc@5 98.438 (98.438)
Epoch: [699][64/196]	Time 0.039 (0.037)	Data 0.000 (0.005)	Loss 0.8220 (0.8815)	Acc@1 72.266 (69.513)	Acc@5 98.438 (97.626)
Epoch: [699][128/196]	Time 0.035 (0.037)	Data 0.000 (0.002)	Loss 0.8214 (0.8849)	Acc@1 72.266 (69.468)	Acc@5 98.828 (97.620)
Epoch: [699][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9431 (0.8888)	Acc@1 66.406 (69.341)	Acc@5 94.922 (97.654)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:700/700; Lr: 0.0010000000000000002
batch Size 256
Epoch: [700][0/196]	Time 0.049 (0.049)	Data 0.265 (0.265)	Loss 0.9383 (0.9383)	Acc@1 66.406 (66.406)	Acc@5 99.219 (99.219)
Epoch: [700][64/196]	Time 0.029 (0.038)	Data 0.000 (0.004)	Loss 0.8725 (0.8878)	Acc@1 69.922 (69.020)	Acc@5 97.656 (97.584)
Epoch: [700][128/196]	Time 0.039 (0.037)	Data 0.000 (0.002)	Loss 0.8227 (0.8915)	Acc@1 73.047 (69.138)	Acc@5 98.047 (97.553)
Epoch: [700][192/196]	Time 0.027 (0.036)	Data 0.000 (0.002)	Loss 0.9190 (0.8927)	Acc@1 72.656 (69.120)	Acc@5 96.484 (97.616)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.44
Max memory: 7.7508608
 7.454s  j: 191 bis 195
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 4952
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 701
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:701/705; Lr: 0.0010000000000000002
batch Size 256
Epoch: [701][0/196]	Time 0.054 (0.054)	Data 0.255 (0.255)	Loss 0.9515 (0.9515)	Acc@1 65.234 (65.234)	Acc@5 98.047 (98.047)
Epoch: [701][64/196]	Time 0.034 (0.036)	Data 0.000 (0.004)	Loss 0.8237 (0.9000)	Acc@1 70.312 (68.660)	Acc@5 98.438 (97.704)
Epoch: [701][128/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.9327 (0.8982)	Acc@1 65.625 (68.747)	Acc@5 98.047 (97.632)
Epoch: [701][192/196]	Time 0.029 (0.037)	Data 0.000 (0.002)	Loss 0.9080 (0.8924)	Acc@1 67.188 (68.942)	Acc@5 97.656 (97.691)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:702/705; Lr: 0.0010000000000000002
batch Size 256
Epoch: [702][0/196]	Time 0.042 (0.042)	Data 0.255 (0.255)	Loss 0.9006 (0.9006)	Acc@1 67.969 (67.969)	Acc@5 98.438 (98.438)
Epoch: [702][64/196]	Time 0.042 (0.037)	Data 0.000 (0.004)	Loss 1.0087 (0.8986)	Acc@1 66.406 (68.852)	Acc@5 97.656 (97.530)
Epoch: [702][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.9042 (0.8893)	Acc@1 69.531 (69.265)	Acc@5 97.266 (97.614)
Epoch: [702][192/196]	Time 0.032 (0.037)	Data 0.000 (0.001)	Loss 0.8931 (0.8917)	Acc@1 70.312 (69.060)	Acc@5 97.656 (97.642)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:703/705; Lr: 0.0010000000000000002
batch Size 256
Epoch: [703][0/196]	Time 0.051 (0.051)	Data 0.306 (0.306)	Loss 0.8233 (0.8233)	Acc@1 71.875 (71.875)	Acc@5 98.828 (98.828)
Epoch: [703][64/196]	Time 0.033 (0.037)	Data 0.000 (0.005)	Loss 0.8509 (0.8982)	Acc@1 70.703 (68.984)	Acc@5 96.875 (97.638)
Epoch: [703][128/196]	Time 0.035 (0.037)	Data 0.000 (0.003)	Loss 0.8647 (0.8908)	Acc@1 70.312 (69.289)	Acc@5 98.047 (97.632)
Epoch: [703][192/196]	Time 0.039 (0.037)	Data 0.000 (0.002)	Loss 0.9610 (0.8958)	Acc@1 67.969 (69.019)	Acc@5 96.094 (97.583)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:704/705; Lr: 0.0010000000000000002
batch Size 256
Epoch: [704][0/196]	Time 0.050 (0.050)	Data 0.277 (0.277)	Loss 0.7994 (0.7994)	Acc@1 73.047 (73.047)	Acc@5 99.219 (99.219)
Epoch: [704][64/196]	Time 0.041 (0.036)	Data 0.000 (0.004)	Loss 0.9095 (0.8918)	Acc@1 71.875 (69.231)	Acc@5 98.438 (97.668)
Epoch: [704][128/196]	Time 0.032 (0.034)	Data 0.000 (0.002)	Loss 0.8277 (0.8959)	Acc@1 71.484 (69.023)	Acc@5 97.656 (97.571)
Epoch: [704][192/196]	Time 0.030 (0.034)	Data 0.000 (0.002)	Loss 0.8738 (0.8943)	Acc@1 67.969 (68.969)	Acc@5 98.047 (97.628)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:705/705; Lr: 0.0010000000000000002
batch Size 256
Epoch: [705][0/196]	Time 0.052 (0.052)	Data 0.224 (0.224)	Loss 0.8652 (0.8652)	Acc@1 68.359 (68.359)	Acc@5 98.047 (98.047)
Epoch: [705][64/196]	Time 0.040 (0.037)	Data 0.000 (0.004)	Loss 0.9788 (0.8999)	Acc@1 65.625 (68.972)	Acc@5 96.484 (97.500)
Epoch: [705][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 1.0667 (0.8995)	Acc@1 64.062 (69.056)	Acc@5 94.922 (97.514)
Epoch: [705][192/196]	Time 0.037 (0.036)	Data 0.000 (0.001)	Loss 0.8857 (0.8981)	Acc@1 70.312 (68.999)	Acc@5 98.438 (97.551)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.17
Max memory: 7.7508608
 7.433s  j: 196 bis 200
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6001
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 706
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:706/710; Lr: 0.0010000000000000002
batch Size 256
Epoch: [706][0/196]	Time 0.073 (0.073)	Data 0.233 (0.233)	Loss 0.9087 (0.9087)	Acc@1 68.359 (68.359)	Acc@5 98.047 (98.047)
Epoch: [706][64/196]	Time 0.033 (0.037)	Data 0.000 (0.004)	Loss 0.8949 (0.8857)	Acc@1 70.703 (69.303)	Acc@5 97.656 (97.692)
Epoch: [706][128/196]	Time 0.031 (0.037)	Data 0.000 (0.002)	Loss 0.8605 (0.8903)	Acc@1 71.875 (69.035)	Acc@5 97.656 (97.668)
Epoch: [706][192/196]	Time 0.035 (0.036)	Data 0.000 (0.001)	Loss 0.8173 (0.8913)	Acc@1 70.312 (69.161)	Acc@5 98.047 (97.630)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:707/710; Lr: 0.0010000000000000002
batch Size 256
Epoch: [707][0/196]	Time 0.035 (0.035)	Data 0.272 (0.272)	Loss 0.9378 (0.9378)	Acc@1 69.141 (69.141)	Acc@5 95.703 (95.703)
Epoch: [707][64/196]	Time 0.039 (0.037)	Data 0.000 (0.004)	Loss 0.8693 (0.8932)	Acc@1 69.531 (68.864)	Acc@5 98.438 (97.590)
Epoch: [707][128/196]	Time 0.033 (0.036)	Data 0.000 (0.002)	Loss 0.8862 (0.8927)	Acc@1 71.094 (69.107)	Acc@5 96.875 (97.568)
Epoch: [707][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.8915 (0.8935)	Acc@1 68.359 (69.084)	Acc@5 96.875 (97.585)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:708/710; Lr: 0.0010000000000000002
batch Size 256
Epoch: [708][0/196]	Time 0.047 (0.047)	Data 0.237 (0.237)	Loss 0.8686 (0.8686)	Acc@1 69.922 (69.922)	Acc@5 98.438 (98.438)
Epoch: [708][64/196]	Time 0.035 (0.034)	Data 0.000 (0.004)	Loss 0.8917 (0.8927)	Acc@1 67.969 (68.798)	Acc@5 96.484 (97.680)
Epoch: [708][128/196]	Time 0.036 (0.035)	Data 0.000 (0.002)	Loss 0.8482 (0.8882)	Acc@1 69.922 (69.122)	Acc@5 98.047 (97.796)
Epoch: [708][192/196]	Time 0.035 (0.035)	Data 0.000 (0.001)	Loss 0.8714 (0.8925)	Acc@1 71.094 (68.965)	Acc@5 97.266 (97.753)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:709/710; Lr: 0.0010000000000000002
batch Size 256
Epoch: [709][0/196]	Time 0.052 (0.052)	Data 0.261 (0.261)	Loss 0.8557 (0.8557)	Acc@1 70.703 (70.703)	Acc@5 97.656 (97.656)
Epoch: [709][64/196]	Time 0.036 (0.038)	Data 0.000 (0.004)	Loss 0.9545 (0.8967)	Acc@1 62.500 (68.678)	Acc@5 98.047 (97.704)
Epoch: [709][128/196]	Time 0.041 (0.036)	Data 0.000 (0.002)	Loss 0.8446 (0.8910)	Acc@1 72.266 (69.165)	Acc@5 98.438 (97.641)
Epoch: [709][192/196]	Time 0.034 (0.036)	Data 0.000 (0.002)	Loss 0.9114 (0.8948)	Acc@1 69.922 (68.928)	Acc@5 97.656 (97.658)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:710/710; Lr: 0.0010000000000000002
batch Size 256
Epoch: [710][0/196]	Time 0.046 (0.046)	Data 0.261 (0.261)	Loss 0.8327 (0.8327)	Acc@1 67.188 (67.188)	Acc@5 99.219 (99.219)
Epoch: [710][64/196]	Time 0.038 (0.036)	Data 0.000 (0.004)	Loss 0.8948 (0.8990)	Acc@1 71.484 (68.365)	Acc@5 96.875 (97.680)
Epoch: [710][128/196]	Time 0.035 (0.036)	Data 0.000 (0.002)	Loss 0.8787 (0.8972)	Acc@1 68.750 (68.656)	Acc@5 98.047 (97.611)
Epoch: [710][192/196]	Time 0.032 (0.036)	Data 0.000 (0.002)	Loss 0.9364 (0.8959)	Acc@1 66.797 (68.724)	Acc@5 97.656 (97.575)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  68.04
Max memory: 7.7508608
 7.355s  j: 201 bis 205
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2525
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 711
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:711/715; Lr: 0.0010000000000000002
batch Size 256
Epoch: [711][0/196]	Time 0.058 (0.058)	Data 0.231 (0.231)	Loss 0.9264 (0.9264)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [711][64/196]	Time 0.041 (0.037)	Data 0.000 (0.004)	Loss 0.8283 (0.8973)	Acc@1 71.875 (68.912)	Acc@5 97.656 (97.476)
Epoch: [711][128/196]	Time 0.038 (0.037)	Data 0.000 (0.002)	Loss 0.8749 (0.8896)	Acc@1 70.312 (69.038)	Acc@5 98.047 (97.620)
Epoch: [711][192/196]	Time 0.032 (0.036)	Data 0.000 (0.001)	Loss 0.9286 (0.8923)	Acc@1 69.141 (68.888)	Acc@5 97.266 (97.600)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:712/715; Lr: 0.0010000000000000002
batch Size 256
Epoch: [712][0/196]	Time 0.046 (0.046)	Data 0.221 (0.221)	Loss 0.8538 (0.8538)	Acc@1 69.531 (69.531)	Acc@5 98.047 (98.047)
Epoch: [712][64/196]	Time 0.039 (0.037)	Data 0.000 (0.004)	Loss 0.9934 (0.8920)	Acc@1 65.234 (68.786)	Acc@5 96.484 (97.572)
Epoch: [712][128/196]	Time 0.036 (0.037)	Data 0.000 (0.002)	Loss 0.8730 (0.8896)	Acc@1 69.531 (68.995)	Acc@5 97.656 (97.668)
Epoch: [712][192/196]	Time 0.030 (0.037)	Data 0.000 (0.001)	Loss 0.7951 (0.8912)	Acc@1 73.438 (69.025)	Acc@5 98.828 (97.638)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:713/715; Lr: 0.0010000000000000002
batch Size 256
Epoch: [713][0/196]	Time 0.062 (0.062)	Data 0.268 (0.268)	Loss 0.9124 (0.9124)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [713][64/196]	Time 0.033 (0.037)	Data 0.000 (0.005)	Loss 0.9155 (0.8901)	Acc@1 67.969 (69.147)	Acc@5 97.266 (97.530)
Epoch: [713][128/196]	Time 0.037 (0.036)	Data 0.000 (0.002)	Loss 0.8702 (0.8930)	Acc@1 71.875 (69.053)	Acc@5 97.656 (97.617)
Epoch: [713][192/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.8162 (0.8927)	Acc@1 69.922 (69.029)	Acc@5 97.656 (97.626)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:714/715; Lr: 0.0010000000000000002
batch Size 256
Epoch: [714][0/196]	Time 0.042 (0.042)	Data 0.288 (0.288)	Loss 0.8223 (0.8223)	Acc@1 68.359 (68.359)	Acc@5 98.047 (98.047)
Epoch: [714][64/196]	Time 0.031 (0.033)	Data 0.000 (0.005)	Loss 0.8900 (0.9030)	Acc@1 70.312 (68.762)	Acc@5 97.656 (97.476)
Epoch: [714][128/196]	Time 0.035 (0.034)	Data 0.000 (0.002)	Loss 0.9878 (0.8957)	Acc@1 67.969 (68.907)	Acc@5 96.875 (97.593)
Epoch: [714][192/196]	Time 0.036 (0.034)	Data 0.000 (0.002)	Loss 0.8582 (0.8940)	Acc@1 69.141 (69.039)	Acc@5 96.484 (97.622)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:715/715; Lr: 0.0010000000000000002
batch Size 256
Epoch: [715][0/196]	Time 0.081 (0.081)	Data 0.255 (0.255)	Loss 0.9320 (0.9320)	Acc@1 68.359 (68.359)	Acc@5 96.875 (96.875)
Epoch: [715][64/196]	Time 0.038 (0.038)	Data 0.000 (0.004)	Loss 0.8118 (0.8884)	Acc@1 71.875 (69.507)	Acc@5 98.438 (97.614)
Epoch: [715][128/196]	Time 0.037 (0.037)	Data 0.000 (0.002)	Loss 0.9881 (0.8945)	Acc@1 66.016 (69.141)	Acc@5 96.484 (97.620)
Epoch: [715][192/196]	Time 0.030 (0.037)	Data 0.000 (0.001)	Loss 0.8789 (0.8944)	Acc@1 67.969 (69.072)	Acc@5 97.656 (97.620)
Max memory in training epoch: 5.2904448
[INFO] Storing checkpoint...
  67.38
Max memory: 7.7508608
 7.548s  j: 206 bis 210
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3707
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 716
Max memory: 0.0346624
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:716/720; Lr: 0.0010000000000000002
batch Size 256
Epoch: [716][0/196]	Time 0.068 (0.068)	Data 0.247 (0.247)	Loss 1.0094 (1.0094)	Acc@1 66.406 (66.406)	Acc@5 96.484 (96.484)
Epoch: [716][64/196]	Time 0.043 (0.037)	Data 0.000 (0.004)	Loss 0.8427 (0.8891)	Acc@1 70.703 (69.621)	Acc@5 97.656 (97.698)
Epoch: [716][128/196]	Time 0.031 (0.036)	Data 0.000 (0.002)	Loss 0.9481 (0.8927)	Acc@1 66.797 (69.419)	Acc@5 98.047 (97.608)
Epoch: [716][192/196]	Time 0.034 (0.036)	Data 0.000 (0.001)	Loss 1.0351 (0.8942)	Acc@1 62.891 (69.240)	Acc@5 98.438 (97.616)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:717/720; Lr: 0.0010000000000000002
batch Size 256
Epoch: [717][0/196]	Time 0.048 (0.048)	Data 0.228 (0.228)	Loss 0.8369 (0.8369)	Acc@1 69.922 (69.922)	Acc@5 98.828 (98.828)
Epoch: [717][64/196]	Time 0.042 (0.037)	Data 0.000 (0.004)	Loss 0.8334 (0.8943)	Acc@1 74.219 (69.165)	Acc@5 97.266 (97.602)
Epoch: [717][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.7795 (0.8959)	Acc@1 74.609 (69.086)	Acc@5 98.438 (97.611)
Epoch: [717][192/196]	Time 0.028 (0.036)	Data 0.000 (0.001)	Loss 0.8929 (0.8953)	Acc@1 68.359 (68.912)	Acc@5 98.047 (97.596)
Max memory in training epoch: 5.2904448
lr: 0.0010000000000000002
lr: 0.0010000000000000002
1
Epoche:718/720; Lr: 0.0010000000000000002
batch Size 256
Epoch: [718][0/196]	Time 0.045 (0.045)	Data 0.275 (0.275)	Loss 0.8662 (0.8662)	Acc@1 70.312 (70.312)	Acc@5 96.875 (96.875)
Epoch: [718][64/196]	Time 0.033 (0.037)	Data 0.000 (0.004)	Loss 0.8502 (0.8943)	Acc@1 71.094 (69.044)	Acc@5 96.875 (97.662)
Epoch: [718][128/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.8710 (0.8940)	Acc@1 68.359 (68.992)	Acc@5 98.828 (97.680)
Epoch: [718][192/196]	Time 0.033 (0.037)	Data 0.000 (0.002)	Loss 0.7913 (0.8938)	Acc@1 71.094 (69.039)	Acc@5 98.438 (97.628)
Max memory in training epoch: 5.2904448
