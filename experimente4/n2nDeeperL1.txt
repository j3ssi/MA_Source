Net2Net Deeper 1
j: 1 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 2868
Files already downloaded and verified
device count: 1
Startepoche: 1
Max memory: 0.101888
1
Epoche: [1/5]; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 1.620 (1.620)	Data 1.145 (1.145)	Loss 3.1042 (3.1042)	Acc@1 11.719 (11.719)	Acc@5 46.094 (46.094)
Epoch: [1][64/196]	Time 1.094 (1.190)	Data 0.000 (0.025)	Loss 2.2724 (2.8977)	Acc@1 16.406 (11.791)	Acc@5 60.547 (52.650)
Epoch: [1][128/196]	Time 1.492 (1.278)	Data 0.000 (0.016)	Loss 1.9949 (2.5141)	Acc@1 20.312 (15.413)	Acc@5 80.469 (61.352)
Epoch: [1][192/196]	Time 1.857 (1.377)	Data 0.000 (0.012)	Loss 1.7497 (2.3014)	Acc@1 32.812 (19.347)	Acc@5 88.672 (68.819)
1
Epoche: [2/5]; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 1.372 (1.372)	Data 1.030 (1.030)	Loss 1.8065 (1.8065)	Acc@1 29.297 (29.297)	Acc@5 87.891 (87.891)
Epoch: [2][64/196]	Time 1.996 (1.794)	Data 0.005 (0.023)	Loss 1.6799 (1.7275)	Acc@1 30.859 (34.225)	Acc@5 91.406 (87.290)
Epoch: [2][128/196]	Time 2.189 (1.926)	Data 0.015 (0.014)	Loss 1.5521 (1.6616)	Acc@1 42.578 (36.767)	Acc@5 91.016 (88.790)
Epoch: [2][192/196]	Time 1.601 (1.998)	Data 0.000 (0.012)	Loss 1.4031 (1.5918)	Acc@1 47.266 (39.728)	Acc@5 94.922 (90.046)
1
Epoche: [3/5]; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 2.036 (2.036)	Data 0.922 (0.922)	Loss 1.2714 (1.2714)	Acc@1 51.953 (51.953)	Acc@5 94.531 (94.531)
Epoch: [3][64/196]	Time 2.473 (2.340)	Data 0.005 (0.019)	Loss 1.2176 (1.3081)	Acc@1 55.078 (52.356)	Acc@5 93.750 (94.050)
Epoch: [3][128/196]	Time 2.508 (2.523)	Data 0.000 (0.013)	Loss 1.2533 (1.2483)	Acc@1 50.000 (54.385)	Acc@5 93.359 (94.677)
Epoch: [3][192/196]	Time 3.057 (2.613)	Data 0.000 (0.011)	Loss 1.1048 (1.2043)	Acc@1 63.281 (56.262)	Acc@5 94.922 (95.080)
1
Epoche: [4/5]; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 3.115 (3.115)	Data 1.222 (1.222)	Loss 1.1324 (1.1324)	Acc@1 58.203 (58.203)	Acc@5 96.484 (96.484)
Epoch: [4][64/196]	Time 3.456 (3.205)	Data 0.000 (0.025)	Loss 1.0858 (1.0480)	Acc@1 59.766 (62.218)	Acc@5 96.484 (96.292)
Epoch: [4][128/196]	Time 3.514 (3.330)	Data 0.000 (0.015)	Loss 0.9304 (1.0060)	Acc@1 67.578 (63.866)	Acc@5 96.875 (96.618)
Epoch: [4][192/196]	Time 2.600 (3.362)	Data 0.000 (0.012)	Loss 0.9608 (0.9875)	Acc@1 68.750 (64.714)	Acc@5 96.484 (96.752)
1
Epoche: [5/5]; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 2.699 (2.699)	Data 0.857 (0.857)	Loss 0.9011 (0.9011)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [5][64/196]	Time 2.820 (2.332)	Data 0.000 (0.015)	Loss 0.8311 (0.8989)	Acc@1 72.656 (68.161)	Acc@5 98.438 (97.536)
Epoch: [5][128/196]	Time 3.097 (2.409)	Data 0.000 (0.009)	Loss 0.7477 (0.8575)	Acc@1 70.703 (69.643)	Acc@5 96.875 (97.732)
Epoch: [5][192/196]	Time 4.564 (2.925)	Data 0.000 (0.008)	Loss 0.7536 (0.8412)	Acc@1 75.000 (70.300)	Acc@5 98.438 (97.824)
Test acc1:  64.41
[INFO] Storing checkpoint...
Max memory: 81.321984
 579.417s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 1003
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 6
First Lr: 0.1
Startepoche: 6
Max memory: 0.3001344
1
Epoche: [6/10]; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 1.847 (1.847)	Data 1.084 (1.084)	Loss 0.8667 (0.8667)	Acc@1 69.141 (69.141)	Acc@5 95.703 (95.703)
Epoch: [6][64/196]	Time 1.153 (1.303)	Data 0.003 (0.021)	Loss 0.6000 (0.7506)	Acc@1 78.516 (73.714)	Acc@5 99.609 (98.275)
Epoch: [6][128/196]	Time 1.885 (1.497)	Data 0.000 (0.014)	Loss 0.8060 (0.7514)	Acc@1 71.875 (73.725)	Acc@5 96.484 (98.226)
Epoch: [6][192/196]	Time 1.958 (1.681)	Data 0.000 (0.011)	Loss 0.8106 (0.7570)	Acc@1 73.438 (73.597)	Acc@5 97.656 (98.227)
1
Epoche: [7/10]; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 2.430 (2.430)	Data 1.027 (1.027)	Loss 0.7747 (0.7747)	Acc@1 74.609 (74.609)	Acc@5 96.875 (96.875)
Epoch: [7][64/196]	Time 2.753 (2.502)	Data 0.010 (0.023)	Loss 0.7312 (0.7628)	Acc@1 74.609 (73.365)	Acc@5 98.438 (98.155)
Epoch: [7][128/196]	Time 2.999 (2.692)	Data 0.005 (0.015)	Loss 0.8761 (0.7547)	Acc@1 69.141 (73.459)	Acc@5 97.656 (98.189)
Epoch: [7][192/196]	Time 3.571 (2.863)	Data 0.000 (0.012)	Loss 0.6976 (0.7551)	Acc@1 74.219 (73.545)	Acc@5 98.828 (98.170)
1
Epoche: [8/10]; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 4.074 (4.074)	Data 1.086 (1.086)	Loss 0.8189 (0.8189)	Acc@1 69.531 (69.531)	Acc@5 100.000 (100.000)
Epoch: [8][64/196]	Time 4.051 (3.755)	Data 0.000 (0.022)	Loss 0.7186 (0.7396)	Acc@1 71.875 (74.201)	Acc@5 99.609 (98.359)
Epoch: [8][128/196]	Time 3.625 (3.880)	Data 0.005 (0.015)	Loss 0.6961 (0.7510)	Acc@1 75.000 (73.871)	Acc@5 100.000 (98.344)
Epoch: [8][192/196]	Time 4.889 (4.022)	Data 0.000 (0.012)	Loss 0.8508 (0.7569)	Acc@1 68.750 (73.664)	Acc@5 98.438 (98.241)
1
Epoche: [9/10]; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 4.568 (4.568)	Data 1.237 (1.237)	Loss 0.7186 (0.7186)	Acc@1 74.219 (74.219)	Acc@5 97.656 (97.656)
Epoch: [9][64/196]	Time 5.428 (4.893)	Data 0.000 (0.024)	Loss 0.7205 (0.7561)	Acc@1 75.781 (73.552)	Acc@5 98.438 (98.155)
Epoch: [9][128/196]	Time 2.782 (4.619)	Data 0.000 (0.014)	Loss 0.7201 (0.7513)	Acc@1 75.000 (73.516)	Acc@5 98.828 (98.229)
Epoch: [9][192/196]	Time 3.541 (4.181)	Data 0.000 (0.010)	Loss 0.6580 (0.7518)	Acc@1 77.734 (73.638)	Acc@5 97.266 (98.247)
1
Epoche: [10/10]; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 3.214 (3.214)	Data 0.997 (0.997)	Loss 0.8310 (0.8310)	Acc@1 74.609 (74.609)	Acc@5 96.484 (96.484)
Epoch: [10][64/196]	Time 6.243 (5.661)	Data 0.031 (0.022)	Loss 0.8177 (0.7629)	Acc@1 70.703 (73.209)	Acc@5 97.656 (98.059)
Epoch: [10][128/196]	Time 7.140 (6.032)	Data 0.005 (0.015)	Loss 0.7176 (0.7551)	Acc@1 76.562 (73.701)	Acc@5 98.828 (98.110)
Epoch: [10][192/196]	Time 7.616 (6.279)	Data 0.000 (0.011)	Loss 0.6652 (0.7541)	Acc@1 79.297 (73.771)	Acc@5 98.438 (98.197)
Test acc1:  73.01
[INFO] Storing checkpoint...
Max memory: 81.4211072
 1235.022s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 6267
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 11
First Lr: 0.1
Startepoche: 11
Max memory: 0.3001344
1
Epoche: [11/15]; Lr: 0.1
batch Size 256
Epoch: [11][0/196]	Time 1.386 (1.386)	Data 1.267 (1.267)	Loss 0.8283 (0.8283)	Acc@1 70.312 (70.312)	Acc@5 98.047 (98.047)
Epoch: [11][64/196]	Time 1.466 (1.340)	Data 0.000 (0.027)	Loss 0.8045 (0.7697)	Acc@1 73.047 (72.891)	Acc@5 96.875 (98.005)
Epoch: [11][128/196]	Time 2.004 (1.536)	Data 0.000 (0.016)	Loss 0.6857 (0.7621)	Acc@1 76.562 (73.486)	Acc@5 98.438 (98.132)
Epoch: [11][192/196]	Time 1.980 (1.658)	Data 0.000 (0.012)	Loss 0.8415 (0.7576)	Acc@1 71.094 (73.705)	Acc@5 96.094 (98.116)
1
Epoche: [12/15]; Lr: 0.1
batch Size 256
Epoch: [12][0/196]	Time 2.517 (2.517)	Data 1.209 (1.209)	Loss 0.8165 (0.8165)	Acc@1 71.875 (71.875)	Acc@5 97.266 (97.266)
Epoch: [12][64/196]	Time 2.393 (2.321)	Data 0.010 (0.024)	Loss 0.6875 (0.7689)	Acc@1 73.047 (73.005)	Acc@5 98.828 (98.113)
Epoch: [12][128/196]	Time 3.079 (2.533)	Data 0.013 (0.016)	Loss 0.7109 (0.7584)	Acc@1 74.609 (73.737)	Acc@5 98.828 (98.141)
Epoch: [12][192/196]	Time 3.556 (2.781)	Data 0.000 (0.013)	Loss 0.8105 (0.7577)	Acc@1 71.875 (73.723)	Acc@5 98.438 (98.154)
1
Epoche: [13/15]; Lr: 0.1
batch Size 256
Epoch: [13][0/196]	Time 3.580 (3.580)	Data 1.225 (1.225)	Loss 0.8251 (0.8251)	Acc@1 70.312 (70.312)	Acc@5 98.047 (98.047)
Epoch: [13][64/196]	Time 3.731 (3.676)	Data 0.005 (0.025)	Loss 0.8959 (0.7572)	Acc@1 65.625 (73.185)	Acc@5 98.828 (98.125)
Epoch: [13][128/196]	Time 1.915 (3.560)	Data 0.010 (0.015)	Loss 0.7988 (0.7600)	Acc@1 73.047 (73.268)	Acc@5 97.266 (98.126)
Epoch: [13][192/196]	Time 2.456 (3.244)	Data 0.000 (0.010)	Loss 0.7586 (0.7559)	Acc@1 72.656 (73.442)	Acc@5 98.828 (98.193)
1
Epoche: [14/15]; Lr: 0.1
batch Size 256
Epoch: [14][0/196]	Time 2.443 (2.443)	Data 0.749 (0.749)	Loss 0.7211 (0.7211)	Acc@1 75.391 (75.391)	Acc@5 99.219 (99.219)
Epoch: [14][64/196]	Time 5.270 (3.675)	Data 0.008 (0.015)	Loss 0.7835 (0.7636)	Acc@1 70.703 (73.065)	Acc@5 98.828 (98.197)
Epoch: [14][128/196]	Time 5.248 (4.378)	Data 0.000 (0.010)	Loss 0.7782 (0.7573)	Acc@1 76.172 (73.428)	Acc@5 96.875 (98.259)
Epoch: [14][192/196]	Time 5.971 (4.779)	Data 0.000 (0.008)	Loss 0.7660 (0.7527)	Acc@1 72.266 (73.717)	Acc@5 98.828 (98.231)
1
Epoche: [15/15]; Lr: 0.1
batch Size 256
Epoch: [15][0/196]	Time 6.167 (6.167)	Data 1.153 (1.153)	Loss 0.8912 (0.8912)	Acc@1 67.578 (67.578)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 6.281 (5.987)	Data 0.021 (0.024)	Loss 0.8672 (0.7582)	Acc@1 73.438 (73.371)	Acc@5 96.484 (98.215)
Epoch: [15][128/196]	Time 6.702 (6.209)	Data 0.000 (0.015)	Loss 0.7500 (0.7532)	Acc@1 73.828 (73.528)	Acc@5 98.438 (98.177)
Epoch: [15][192/196]	Time 7.304 (6.381)	Data 0.000 (0.012)	Loss 0.7598 (0.7538)	Acc@1 73.438 (73.583)	Acc@5 98.047 (98.243)
Test acc1:  72.99
[INFO] Storing checkpoint...
Max memory: 81.4211072
 1255.404s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 5265
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 16
First Lr: 0.1
Startepoche: 16
Max memory: 0.3001344
1
Epoche: [16/20]; Lr: 0.1
batch Size 256
Epoch: [16][0/196]	Time 1.849 (1.849)	Data 1.004 (1.004)	Loss 0.7569 (0.7569)	Acc@1 74.219 (74.219)	Acc@5 98.047 (98.047)
Epoch: [16][64/196]	Time 1.458 (1.305)	Data 0.000 (0.021)	Loss 0.7612 (0.7475)	Acc@1 74.219 (73.798)	Acc@5 98.438 (98.221)
Epoch: [16][128/196]	Time 1.935 (1.509)	Data 0.000 (0.015)	Loss 0.7915 (0.7549)	Acc@1 73.047 (73.665)	Acc@5 98.438 (98.156)
Epoch: [16][192/196]	Time 2.076 (1.706)	Data 0.000 (0.011)	Loss 0.7105 (0.7554)	Acc@1 72.656 (73.616)	Acc@5 98.438 (98.199)
1
Epoche: [17/20]; Lr: 0.1
batch Size 256
Epoch: [17][0/196]	Time 2.155 (2.155)	Data 0.923 (0.923)	Loss 0.7039 (0.7039)	Acc@1 72.266 (72.266)	Acc@5 98.047 (98.047)
Epoch: [17][64/196]	Time 1.786 (1.883)	Data 0.000 (0.018)	Loss 0.7476 (0.7626)	Acc@1 72.266 (73.161)	Acc@5 97.656 (98.311)
Epoch: [17][128/196]	Time 2.027 (1.810)	Data 0.000 (0.010)	Loss 0.7361 (0.7544)	Acc@1 71.875 (73.441)	Acc@5 98.438 (98.247)
Epoch: [17][192/196]	Time 2.326 (1.872)	Data 0.000 (0.007)	Loss 0.7841 (0.7547)	Acc@1 72.656 (73.603)	Acc@5 98.438 (98.227)
1
Epoche: [18/20]; Lr: 0.1
batch Size 256
Epoch: [18][0/196]	Time 2.359 (2.359)	Data 0.936 (0.936)	Loss 0.7182 (0.7182)	Acc@1 75.391 (75.391)	Acc@5 98.438 (98.438)
Epoch: [18][64/196]	Time 3.875 (3.249)	Data 0.005 (0.019)	Loss 0.8022 (0.7601)	Acc@1 70.703 (73.492)	Acc@5 98.438 (98.311)
Epoch: [18][128/196]	Time 4.367 (3.676)	Data 0.000 (0.012)	Loss 0.7159 (0.7539)	Acc@1 76.562 (73.734)	Acc@5 96.484 (98.259)
Epoch: [18][192/196]	Time 4.736 (3.955)	Data 0.000 (0.010)	Loss 0.7615 (0.7530)	Acc@1 71.875 (73.674)	Acc@5 98.047 (98.255)
1
Epoche: [19/20]; Lr: 0.1
batch Size 256
Epoch: [19][0/196]	Time 4.959 (4.959)	Data 1.167 (1.167)	Loss 0.7294 (0.7294)	Acc@1 74.609 (74.609)	Acc@5 98.438 (98.438)
Epoch: [19][64/196]	Time 5.170 (4.879)	Data 0.010 (0.025)	Loss 0.7382 (0.7540)	Acc@1 75.781 (73.786)	Acc@5 98.438 (98.155)
Epoch: [19][128/196]	Time 5.821 (5.095)	Data 0.005 (0.016)	Loss 0.8242 (0.7557)	Acc@1 73.438 (73.577)	Acc@5 97.656 (98.235)
Epoch: [19][192/196]	Time 5.678 (5.212)	Data 0.000 (0.012)	Loss 0.6588 (0.7551)	Acc@1 80.078 (73.705)	Acc@5 98.828 (98.154)
1
Epoche: [20/20]; Lr: 0.1
batch Size 256
Epoch: [20][0/196]	Time 6.149 (6.149)	Data 1.156 (1.156)	Loss 0.8128 (0.8128)	Acc@1 73.438 (73.438)	Acc@5 97.266 (97.266)
Epoch: [20][64/196]	Time 6.435 (5.837)	Data 0.005 (0.021)	Loss 0.8571 (0.7551)	Acc@1 70.703 (73.750)	Acc@5 98.047 (98.365)
Epoch: [20][128/196]	Time 5.192 (5.972)	Data 0.005 (0.013)	Loss 0.7082 (0.7509)	Acc@1 76.172 (73.846)	Acc@5 98.438 (98.319)
Epoch: [20][192/196]	Time 5.602 (5.393)	Data 0.000 (0.010)	Loss 0.6753 (0.7585)	Acc@1 76.953 (73.520)	Acc@5 98.828 (98.239)
Test acc1:  72.96
[INFO] Storing checkpoint...
Max memory: 81.4211072
 1057.456s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 9684
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 21
First Lr: 0.1
Startepoche: 21
Max memory: 0.3001344
1
Epoche: [21/25]; Lr: 0.1
batch Size 256
Epoch: [21][0/196]	Time 1.351 (1.351)	Data 0.853 (0.853)	Loss 0.7164 (0.7164)	Acc@1 73.047 (73.047)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 1.237 (1.146)	Data 0.000 (0.018)	Loss 0.7485 (0.7607)	Acc@1 71.094 (73.462)	Acc@5 99.219 (98.149)
Epoch: [21][128/196]	Time 1.836 (1.387)	Data 0.000 (0.012)	Loss 0.6425 (0.7594)	Acc@1 78.125 (73.404)	Acc@5 98.438 (98.177)
Epoch: [21][192/196]	Time 2.248 (1.585)	Data 0.000 (0.011)	Loss 0.8007 (0.7555)	Acc@1 73.047 (73.549)	Acc@5 97.266 (98.205)
1
Epoche: [22/25]; Lr: 0.1
batch Size 256
Epoch: [22][0/196]	Time 2.318 (2.318)	Data 1.155 (1.155)	Loss 0.7911 (0.7911)	Acc@1 72.266 (72.266)	Acc@5 97.266 (97.266)
Epoch: [22][64/196]	Time 2.908 (2.309)	Data 0.020 (0.023)	Loss 0.7314 (0.7587)	Acc@1 76.953 (73.504)	Acc@5 98.828 (98.155)
Epoch: [22][128/196]	Time 3.201 (2.530)	Data 0.015 (0.014)	Loss 0.8144 (0.7560)	Acc@1 66.016 (73.428)	Acc@5 98.047 (98.216)
Epoch: [22][192/196]	Time 3.430 (2.760)	Data 0.000 (0.011)	Loss 0.8841 (0.7558)	Acc@1 70.703 (73.525)	Acc@5 96.094 (98.162)
1
Epoche: [23/25]; Lr: 0.1
batch Size 256
Epoch: [23][0/196]	Time 3.097 (3.097)	Data 0.816 (0.816)	Loss 0.7383 (0.7383)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [23][64/196]	Time 3.700 (3.560)	Data 0.005 (0.019)	Loss 0.8318 (0.7596)	Acc@1 72.266 (73.365)	Acc@5 97.266 (98.329)
Epoch: [23][128/196]	Time 4.119 (3.773)	Data 0.008 (0.013)	Loss 0.7286 (0.7583)	Acc@1 75.391 (73.534)	Acc@5 98.047 (98.219)
Epoch: [23][192/196]	Time 4.668 (3.978)	Data 0.000 (0.010)	Loss 0.7540 (0.7586)	Acc@1 75.000 (73.593)	Acc@5 97.266 (98.168)
1
Epoche: [24/25]; Lr: 0.1
batch Size 256
Epoch: [24][0/196]	Time 4.019 (4.019)	Data 0.801 (0.801)	Loss 0.8618 (0.8618)	Acc@1 68.750 (68.750)	Acc@5 97.656 (97.656)
Epoch: [24][64/196]	Time 5.135 (4.648)	Data 0.010 (0.019)	Loss 0.7790 (0.7529)	Acc@1 71.484 (73.852)	Acc@5 98.438 (98.185)
Epoch: [24][128/196]	Time 5.552 (4.934)	Data 0.010 (0.013)	Loss 0.7851 (0.7559)	Acc@1 71.484 (73.562)	Acc@5 98.047 (98.141)
Epoch: [24][192/196]	Time 2.987 (4.836)	Data 0.000 (0.010)	Loss 0.7050 (0.7560)	Acc@1 75.391 (73.699)	Acc@5 99.609 (98.146)
1
Epoche: [25/25]; Lr: 0.1
batch Size 256
Epoch: [25][0/196]	Time 4.092 (4.092)	Data 0.872 (0.872)	Loss 0.8172 (0.8172)	Acc@1 71.875 (71.875)	Acc@5 98.438 (98.438)
Epoch: [25][64/196]	Time 5.661 (3.647)	Data 0.005 (0.016)	Loss 0.7437 (0.7607)	Acc@1 75.000 (73.131)	Acc@5 99.219 (98.329)
Epoch: [25][128/196]	Time 6.128 (4.958)	Data 0.000 (0.011)	Loss 0.6910 (0.7512)	Acc@1 76.562 (73.646)	Acc@5 98.828 (98.286)
Epoch: [25][192/196]	Time 7.439 (5.589)	Data 0.000 (0.009)	Loss 0.6932 (0.7570)	Acc@1 77.734 (73.516)	Acc@5 97.656 (98.223)
Test acc1:  73.1
[INFO] Storing checkpoint...
Max memory: 81.4211072
 1102.253s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 6258
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 26
First Lr: 0.1
Startepoche: 26
Max memory: 0.3001344
1
Epoche: [26/30]; Lr: 0.1
batch Size 256
Epoch: [26][0/196]	Time 1.477 (1.477)	Data 1.144 (1.144)	Loss 0.6844 (0.6844)	Acc@1 74.219 (74.219)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 1.549 (1.333)	Data 0.031 (0.023)	Loss 0.7922 (0.7560)	Acc@1 75.781 (73.678)	Acc@5 98.047 (98.275)
Epoch: [26][128/196]	Time 2.018 (1.497)	Data 0.000 (0.014)	Loss 0.8297 (0.7518)	Acc@1 70.703 (73.671)	Acc@5 97.266 (98.268)
Epoch: [26][192/196]	Time 2.338 (1.670)	Data 0.000 (0.012)	Loss 0.8090 (0.7558)	Acc@1 69.922 (73.557)	Acc@5 98.047 (98.233)
1
Epoche: [27/30]; Lr: 0.1
batch Size 256
Epoch: [27][0/196]	Time 2.294 (2.294)	Data 1.289 (1.289)	Loss 0.6027 (0.6027)	Acc@1 77.734 (77.734)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 2.829 (2.552)	Data 0.015 (0.029)	Loss 0.7769 (0.7434)	Acc@1 72.266 (74.093)	Acc@5 98.047 (98.389)
Epoch: [27][128/196]	Time 2.879 (2.708)	Data 0.005 (0.018)	Loss 0.7807 (0.7583)	Acc@1 70.703 (73.501)	Acc@5 99.219 (98.229)
Epoch: [27][192/196]	Time 3.116 (2.843)	Data 0.000 (0.014)	Loss 0.7909 (0.7570)	Acc@1 70.703 (73.512)	Acc@5 99.219 (98.255)
1
Epoche: [28/30]; Lr: 0.1
batch Size 256
Epoch: [28][0/196]	Time 3.433 (3.433)	Data 1.129 (1.129)	Loss 0.6596 (0.6596)	Acc@1 78.125 (78.125)	Acc@5 98.047 (98.047)
Epoch: [28][64/196]	Time 3.386 (3.431)	Data 0.015 (0.023)	Loss 0.8187 (0.7630)	Acc@1 71.875 (72.981)	Acc@5 97.266 (98.287)
Epoch: [28][128/196]	Time 4.276 (3.667)	Data 0.003 (0.014)	Loss 0.7151 (0.7500)	Acc@1 75.781 (73.649)	Acc@5 98.438 (98.313)
Epoch: [28][192/196]	Time 3.629 (3.818)	Data 0.000 (0.011)	Loss 0.7212 (0.7543)	Acc@1 75.000 (73.555)	Acc@5 99.219 (98.223)
1
Epoche: [29/30]; Lr: 0.1
batch Size 256
Epoch: [29][0/196]	Time 2.174 (2.174)	Data 0.911 (0.911)	Loss 0.8294 (0.8294)	Acc@1 72.656 (72.656)	Acc@5 96.484 (96.484)
Epoch: [29][64/196]	Time 3.288 (2.888)	Data 0.000 (0.017)	Loss 0.7375 (0.7556)	Acc@1 76.172 (73.750)	Acc@5 97.266 (98.125)
Epoch: [29][128/196]	Time 5.895 (3.327)	Data 0.005 (0.010)	Loss 0.7387 (0.7581)	Acc@1 74.609 (73.643)	Acc@5 98.828 (98.126)
Epoch: [29][192/196]	Time 5.914 (4.089)	Data 0.000 (0.009)	Loss 0.7391 (0.7533)	Acc@1 71.484 (73.861)	Acc@5 97.656 (98.205)
1
Epoche: [30/30]; Lr: 0.1
batch Size 256
Epoch: [30][0/196]	Time 5.816 (5.816)	Data 1.213 (1.213)	Loss 0.7536 (0.7536)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [30][64/196]	Time 6.154 (5.853)	Data 0.000 (0.025)	Loss 0.8051 (0.7516)	Acc@1 71.094 (74.008)	Acc@5 98.438 (98.017)
Epoch: [30][128/196]	Time 6.828 (6.111)	Data 0.005 (0.016)	Loss 0.7598 (0.7555)	Acc@1 73.438 (73.852)	Acc@5 98.047 (98.141)
Epoch: [30][192/196]	Time 7.051 (6.343)	Data 0.000 (0.013)	Loss 0.6888 (0.7556)	Acc@1 77.734 (73.846)	Acc@5 98.047 (98.110)
Test acc1:  72.9
[INFO] Storing checkpoint...
Max memory: 81.4211072
 1245.915s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 3020
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 31
First Lr: 0.1
Startepoche: 31
Max memory: 0.3001344
1
Epoche: [31/35]; Lr: 0.1
batch Size 256
Epoch: [31][0/196]	Time 1.752 (1.752)	Data 1.034 (1.034)	Loss 0.7804 (0.7804)	Acc@1 70.703 (70.703)	Acc@5 96.875 (96.875)
Epoch: [31][64/196]	Time 1.427 (1.329)	Data 0.000 (0.021)	Loss 0.7860 (0.7554)	Acc@1 71.875 (73.522)	Acc@5 98.828 (98.041)
Epoch: [31][128/196]	Time 2.019 (1.492)	Data 0.010 (0.014)	Loss 0.7240 (0.7573)	Acc@1 77.344 (73.413)	Acc@5 98.828 (98.144)
Epoch: [31][192/196]	Time 2.354 (1.691)	Data 0.000 (0.012)	Loss 0.7951 (0.7578)	Acc@1 72.656 (73.502)	Acc@5 97.266 (98.144)
1
Epoche: [32/35]; Lr: 0.1
batch Size 256
Epoch: [32][0/196]	Time 2.277 (2.277)	Data 1.184 (1.184)	Loss 0.6543 (0.6543)	Acc@1 78.125 (78.125)	Acc@5 98.828 (98.828)
Epoch: [32][64/196]	Time 2.747 (2.540)	Data 0.005 (0.026)	Loss 0.8062 (0.7584)	Acc@1 71.094 (73.792)	Acc@5 97.656 (98.107)
Epoch: [32][128/196]	Time 3.072 (2.680)	Data 0.005 (0.016)	Loss 0.7911 (0.7555)	Acc@1 72.656 (73.722)	Acc@5 99.219 (98.229)
Epoch: [32][192/196]	Time 2.190 (2.522)	Data 0.000 (0.011)	Loss 0.7977 (0.7569)	Acc@1 73.828 (73.622)	Acc@5 97.656 (98.205)
1
Epoche: [33/35]; Lr: 0.1
batch Size 256
Epoch: [33][0/196]	Time 1.727 (1.727)	Data 0.774 (0.774)	Loss 0.7951 (0.7951)	Acc@1 72.266 (72.266)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 2.529 (2.176)	Data 0.000 (0.014)	Loss 0.7047 (0.7568)	Acc@1 72.656 (73.419)	Acc@5 98.438 (98.353)
Epoch: [33][128/196]	Time 4.442 (2.565)	Data 0.000 (0.008)	Loss 0.7376 (0.7550)	Acc@1 73.047 (73.713)	Acc@5 100.000 (98.253)
Epoch: [33][192/196]	Time 4.759 (3.200)	Data 0.000 (0.007)	Loss 0.8809 (0.7576)	Acc@1 70.703 (73.571)	Acc@5 96.484 (98.217)
1
Epoche: [34/35]; Lr: 0.1
batch Size 256
Epoch: [34][0/196]	Time 4.805 (4.805)	Data 1.224 (1.224)	Loss 0.6691 (0.6691)	Acc@1 78.125 (78.125)	Acc@5 98.828 (98.828)
Epoch: [34][64/196]	Time 5.075 (4.880)	Data 0.010 (0.024)	Loss 0.8238 (0.7512)	Acc@1 68.750 (73.924)	Acc@5 97.656 (98.215)
Epoch: [34][128/196]	Time 5.736 (5.053)	Data 0.000 (0.015)	Loss 0.7915 (0.7555)	Acc@1 73.438 (73.707)	Acc@5 95.703 (98.274)
Epoch: [34][192/196]	Time 6.324 (5.261)	Data 0.000 (0.013)	Loss 0.8200 (0.7586)	Acc@1 73.047 (73.478)	Acc@5 97.656 (98.274)
1
Epoche: [35/35]; Lr: 0.1
batch Size 256
Epoch: [35][0/196]	Time 6.149 (6.149)	Data 0.979 (0.979)	Loss 0.6934 (0.6934)	Acc@1 77.344 (77.344)	Acc@5 98.438 (98.438)
Epoch: [35][64/196]	Time 6.759 (5.992)	Data 0.010 (0.020)	Loss 0.8063 (0.7646)	Acc@1 70.703 (73.347)	Acc@5 98.438 (98.107)
Epoch: [35][128/196]	Time 6.465 (6.161)	Data 0.004 (0.014)	Loss 0.7118 (0.7581)	Acc@1 77.734 (73.565)	Acc@5 98.047 (98.162)
Epoch: [35][192/196]	Time 4.318 (6.037)	Data 0.000 (0.010)	Loss 0.9088 (0.7549)	Acc@1 71.094 (73.510)	Acc@5 96.875 (98.201)
Test acc1:  73.0
[INFO] Storing checkpoint...
Max memory: 81.4211072
 1179.657s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 5192
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 36
First Lr: 0.1
Startepoche: 36
Max memory: 0.3001344
Epoche: [36/40]; Lr: 0.1
batch Size 256
Epoch: [36][0/196]	Time 1.202 (1.202)	Data 0.869 (0.869)	Loss 0.6461 (0.6461)	Acc@1 76.172 (76.172)	Acc@5 98.828 (98.828)
Epoch: [36][64/196]	Time 1.031 (0.795)	Data 0.000 (0.015)	Loss 0.7169 (0.7564)	Acc@1 74.609 (73.570)	Acc@5 98.828 (98.167)
Epoch: [36][128/196]	Time 0.943 (0.893)	Data 0.000 (0.008)	Loss 0.8927 (0.7574)	Acc@1 69.922 (73.550)	Acc@5 95.703 (98.259)
Epoch: [36][192/196]	Time 1.554 (1.034)	Data 0.000 (0.006)	Loss 0.6707 (0.7546)	Acc@1 76.562 (73.711)	Acc@5 98.438 (98.263)
Epoche: [37/40]; Lr: 0.1
batch Size 256
Epoch: [37][0/196]	Time 2.008 (2.008)	Data 0.805 (0.805)	Loss 0.6976 (0.6976)	Acc@1 74.609 (74.609)	Acc@5 99.219 (99.219)
Epoch: [37][64/196]	Time 2.950 (2.266)	Data 0.010 (0.017)	Loss 0.7599 (0.7689)	Acc@1 73.828 (73.221)	Acc@5 98.047 (98.131)
Epoch: [37][128/196]	Time 3.336 (2.541)	Data 0.005 (0.011)	Loss 0.7383 (0.7558)	Acc@1 73.828 (73.707)	Acc@5 98.047 (98.229)
Epoch: [37][192/196]	Time 3.445 (2.769)	Data 0.000 (0.009)	Loss 0.8019 (0.7540)	Acc@1 68.750 (73.749)	Acc@5 97.656 (98.235)
Epoche: [38/40]; Lr: 0.1
batch Size 256
Epoch: [38][0/196]	Time 3.643 (3.643)	Data 1.263 (1.263)	Loss 0.7840 (0.7840)	Acc@1 71.094 (71.094)	Acc@5 96.875 (96.875)
Epoch: [38][64/196]	Time 4.216 (3.674)	Data 0.000 (0.026)	Loss 0.6698 (0.7533)	Acc@1 77.734 (74.014)	Acc@5 98.828 (98.041)
Epoch: [38][128/196]	Time 3.385 (3.800)	Data 0.000 (0.016)	Loss 0.6968 (0.7541)	Acc@1 75.391 (73.713)	Acc@5 98.438 (98.177)
Epoch: [38][192/196]	Time 5.010 (3.961)	Data 0.000 (0.013)	Loss 0.8379 (0.7562)	Acc@1 70.312 (73.660)	Acc@5 98.047 (98.215)
Epoche: [39/40]; Lr: 0.1
batch Size 256
Epoch: [39][0/196]	Time 4.263 (4.263)	Data 1.203 (1.203)	Loss 0.7646 (0.7646)	Acc@1 73.438 (73.438)	Acc@5 97.266 (97.266)
Epoch: [39][64/196]	Time 5.288 (4.785)	Data 0.000 (0.025)	Loss 0.7586 (0.7548)	Acc@1 72.266 (73.882)	Acc@5 96.875 (98.155)
Epoch: [39][128/196]	Time 5.146 (4.914)	Data 0.010 (0.015)	Loss 0.7442 (0.7506)	Acc@1 73.047 (73.898)	Acc@5 98.047 (98.180)
Epoch: [39][192/196]	Time 4.548 (5.087)	Data 0.000 (0.011)	Loss 0.7296 (0.7550)	Acc@1 75.000 (73.516)	Acc@5 97.656 (98.195)
Epoche: [40/40]; Lr: 0.1
batch Size 256
Epoch: [40][0/196]	Time 5.937 (5.937)	Data 0.869 (0.869)	Loss 0.7664 (0.7664)	Acc@1 73.047 (73.047)	Acc@5 97.656 (97.656)
Epoch: [40][64/196]	Time 2.907 (4.382)	Data 0.000 (0.015)	Loss 0.7675 (0.7635)	Acc@1 69.922 (73.612)	Acc@5 97.266 (98.053)
Epoch: [40][128/196]	Time 4.803 (4.292)	Data 0.010 (0.008)	Loss 0.7085 (0.7593)	Acc@1 72.656 (73.710)	Acc@5 98.438 (98.077)
Epoch: [40][192/196]	Time 5.759 (4.833)	Data 0.000 (0.006)	Loss 0.8395 (0.7578)	Acc@1 68.359 (73.747)	Acc@5 96.875 (98.130)


now deeper1
i: 3
neues conv: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 3; i0=: 16; i1=: 16
i: 4
neues conv: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 4; i0=: 16; i1=: 16
i: 5
neues conv: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 5; i0=: 16; i1=: 16
i: 6
neues conv: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 6; i0=: 16; i1=: 16
i: 7
neues conv: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 7; i0=: 16; i1=: 16
i: 8
neues conv: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 8; i0=: 32; i1=: 16
skip: 9
i: 10
neues conv: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 10; i0=: 32; i1=: 32
i: 11
neues conv: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 11; i0=: 32; i1=: 32
i: 12
neues conv: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 12; i0=: 32; i1=: 32
i: 13
neues conv: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 13; i0=: 32; i1=: 32
i: 14
neues conv: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 14; i0=: 64; i1=: 32
skip: 15
i: 16
neues conv: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 16; i0=: 64; i1=: 64
i: 17
neues conv: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 17; i0=: 64; i1=: 64
i: 18
neues conv: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 18; i0=: 64; i1=: 64
i: 19
neues conv: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)); j: 3
i: 19; i0=: 64; i1=: 64
archNums: [[1, 1, 1, 1, 1], [2, 1, 1, 1, 1], [2, 1, 1, 1, 1]]
num: 10; numofstages: 3, listofBlocks: [5, 5, 5], layers in blocj: 1
model.para: <generator object Module.named_parameters at 0x7f9dd4421fc0>
Test acc1:  73.11
[INFO] Storing checkpoint...
Max memory: 81.4211072
 950.964s  j: 181 bis 185
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 4951
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 41
First Lr: 0.01
Startepoche: 41
Max memory: 0.4014592
Epoche: [41/45]; Lr: 0.01
batch Size 256
Epoch: [41][0/196]	Time 1.545 (1.545)	Data 1.238 (1.238)	Loss 0.7424 (0.7424)	Acc@1 75.781 (75.781)	Acc@5 98.828 (98.828)
Epoch: [41][64/196]	Time 3.938 (2.268)	Data 0.000 (0.020)	Loss 0.8473 (0.8526)	Acc@1 74.219 (71.142)	Acc@5 95.703 (97.764)
Epoch: [41][128/196]	Time 2.123 (2.507)	Data 0.000 (0.011)	Loss 0.8883 (0.8502)	Acc@1 68.750 (71.000)	Acc@5 96.094 (97.729)
Epoch: [41][192/196]	Time 3.341 (2.769)	Data 0.000 (0.008)	Loss 0.7779 (0.8457)	Acc@1 73.438 (70.982)	Acc@5 98.438 (97.749)
Epoche: [42/45]; Lr: 0.01
batch Size 256
Epoch: [42][0/196]	Time 3.176 (3.176)	Data 0.600 (0.600)	Loss 0.8554 (0.8554)	Acc@1 66.406 (66.406)	Acc@5 98.047 (98.047)
Epoch: [42][64/196]	Time 4.454 (4.106)	Data 0.000 (0.011)	Loss 0.8799 (0.8507)	Acc@1 73.047 (70.986)	Acc@5 98.438 (98.053)
Epoch: [42][128/196]	Time 3.522 (4.415)	Data 0.000 (0.008)	Loss 0.8782 (0.8421)	Acc@1 71.484 (71.294)	Acc@5 98.438 (97.911)
Epoch: [42][192/196]	Time 5.889 (4.623)	Data 0.000 (0.006)	Loss 0.8441 (0.8447)	Acc@1 70.312 (71.033)	Acc@5 97.266 (97.887)
Epoche: [43/45]; Lr: 0.01
batch Size 256
Epoch: [43][0/196]	Time 4.692 (4.692)	Data 1.199 (1.199)	Loss 0.8888 (0.8888)	Acc@1 71.875 (71.875)	Acc@5 96.875 (96.875)
Epoch: [43][64/196]	Time 6.124 (5.540)	Data 0.000 (0.021)	Loss 0.8217 (0.8475)	Acc@1 69.922 (71.070)	Acc@5 98.047 (97.819)
Epoch: [43][128/196]	Time 4.254 (5.672)	Data 0.010 (0.013)	Loss 0.8648 (0.8467)	Acc@1 69.922 (71.188)	Acc@5 97.656 (97.756)
Epoch: [43][192/196]	Time 4.513 (5.062)	Data 0.000 (0.009)	Loss 0.7738 (0.8447)	Acc@1 74.219 (71.189)	Acc@5 97.266 (97.770)
Epoche: [44/45]; Lr: 0.01
batch Size 256
Epoch: [44][0/196]	Time 5.354 (5.354)	Data 0.831 (0.831)	Loss 0.8628 (0.8628)	Acc@1 67.969 (67.969)	Acc@5 98.438 (98.438)
Epoch: [44][64/196]	Time 6.420 (4.896)	Data 0.000 (0.017)	Loss 0.9423 (0.8472)	Acc@1 67.188 (70.871)	Acc@5 96.094 (97.614)
Epoch: [44][128/196]	Time 9.247 (5.707)	Data 0.000 (0.010)	Loss 0.8304 (0.8449)	Acc@1 75.000 (70.912)	Acc@5 97.266 (97.729)
Epoch: [44][192/196]	Time 10.176 (6.137)	Data 0.000 (0.007)	Loss 0.8787 (0.8458)	Acc@1 69.531 (71.047)	Acc@5 97.656 (97.774)
Epoche: [45/45]; Lr: 0.01
batch Size 256
Epoch: [45][0/196]	Time 5.645 (5.645)	Data 1.295 (1.295)	Loss 0.8338 (0.8338)	Acc@1 73.438 (73.438)	Acc@5 97.266 (97.266)
Epoch: [45][64/196]	Time 8.327 (7.394)	Data 0.000 (0.023)	Loss 0.7656 (0.8519)	Acc@1 73.828 (70.649)	Acc@5 98.047 (97.915)
Epoch: [45][128/196]	Time 9.591 (7.882)	Data 0.000 (0.014)	Loss 0.7940 (0.8473)	Acc@1 71.484 (71.000)	Acc@5 98.828 (97.835)
Epoch: [45][192/196]	Time 9.405 (8.175)	Data 0.000 (0.011)	Loss 0.7542 (0.8463)	Acc@1 75.781 (71.039)	Acc@5 98.438 (97.861)
Test acc1:  70.38
[INFO] Storing checkpoint...
Max memory: 129.3952
 1604.937s  j: 186 bis 190
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 6868
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 46
First Lr: 0.01
Startepoche: 46
Max memory: 0.4014592
Epoche: [46/50]; Lr: 0.01
batch Size 256
Epoch: [46][0/196]	Time 2.382 (2.382)	Data 0.819 (0.819)	Loss 1.0288 (1.0288)	Acc@1 71.094 (71.094)	Acc@5 97.266 (97.266)
Epoch: [46][64/196]	Time 2.085 (1.865)	Data 0.000 (0.016)	Loss 0.8821 (0.8328)	Acc@1 69.922 (71.587)	Acc@5 96.094 (98.053)
Epoch: [46][128/196]	Time 2.317 (1.968)	Data 0.000 (0.009)	Loss 0.7653 (0.8368)	Acc@1 71.484 (71.345)	Acc@5 97.656 (97.935)
Epoch: [46][192/196]	Time 4.165 (2.238)	Data 0.000 (0.007)	Loss 0.9324 (0.8445)	Acc@1 69.141 (71.003)	Acc@5 97.266 (97.828)
Epoche: [47/50]; Lr: 0.01
batch Size 256
Epoch: [47][0/196]	Time 4.359 (4.359)	Data 1.369 (1.369)	Loss 0.9726 (0.9726)	Acc@1 70.703 (70.703)	Acc@5 98.047 (98.047)
Epoch: [47][64/196]	Time 4.858 (4.243)	Data 0.000 (0.026)	Loss 0.8624 (0.8423)	Acc@1 69.922 (70.799)	Acc@5 97.656 (97.861)
Epoch: [47][128/196]	Time 4.900 (4.482)	Data 0.015 (0.017)	Loss 0.8230 (0.8465)	Acc@1 72.656 (70.776)	Acc@5 98.438 (97.856)
Epoch: [47][192/196]	Time 5.300 (4.671)	Data 0.000 (0.014)	Loss 1.0161 (0.8465)	Acc@1 67.578 (70.952)	Acc@5 95.703 (97.836)
Epoche: [48/50]; Lr: 0.01
batch Size 256
Epoch: [48][0/196]	Time 4.824 (4.824)	Data 1.059 (1.059)	Loss 0.8515 (0.8515)	Acc@1 71.875 (71.875)	Acc@5 97.266 (97.266)
Epoch: [48][64/196]	Time 6.015 (5.466)	Data 0.007 (0.021)	Loss 0.7050 (0.8576)	Acc@1 74.609 (70.703)	Acc@5 98.438 (97.794)
Epoch: [48][128/196]	Time 5.341 (5.673)	Data 0.010 (0.014)	Loss 0.6667 (0.8461)	Acc@1 78.906 (70.927)	Acc@5 99.219 (97.838)
Epoch: [48][192/196]	Time 6.275 (5.873)	Data 0.000 (0.010)	Loss 0.8912 (0.8459)	Acc@1 68.750 (71.033)	Acc@5 97.656 (97.836)
Epoche: [49/50]; Lr: 0.01
batch Size 256
Epoch: [49][0/196]	Time 6.921 (6.921)	Data 1.010 (1.010)	Loss 0.8248 (0.8248)	Acc@1 70.312 (70.312)	Acc@5 97.266 (97.266)
Epoch: [49][64/196]	Time 3.312 (5.895)	Data 0.000 (0.020)	Loss 0.9721 (0.8307)	Acc@1 65.234 (71.587)	Acc@5 98.047 (98.029)
Epoch: [49][128/196]	Time 5.015 (4.999)	Data 0.005 (0.011)	Loss 0.8106 (0.8398)	Acc@1 73.828 (71.345)	Acc@5 98.047 (97.992)
Epoch: [49][192/196]	Time 7.965 (5.712)	Data 0.000 (0.009)	Loss 0.8125 (0.8415)	Acc@1 75.391 (71.286)	Acc@5 97.266 (97.905)
Epoche: [50/50]; Lr: 0.01
batch Size 256
Epoch: [50][0/196]	Time 7.048 (7.048)	Data 1.357 (1.357)	Loss 0.7171 (0.7171)	Acc@1 75.000 (75.000)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 8.468 (8.038)	Data 0.000 (0.027)	Loss 0.9616 (0.8493)	Acc@1 70.703 (71.184)	Acc@5 96.484 (97.794)
Epoch: [50][128/196]	Time 9.041 (8.116)	Data 0.000 (0.016)	Loss 0.7117 (0.8452)	Acc@1 72.656 (71.269)	Acc@5 97.656 (97.805)
Epoch: [50][192/196]	Time 8.925 (8.245)	Data 0.000 (0.012)	Loss 0.8333 (0.8444)	Acc@1 68.750 (71.187)	Acc@5 98.047 (97.861)
Test acc1:  70.43
[INFO] Storing checkpoint...
Max memory: 129.3952
 1618.141s  j: 191 bis 195
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 7579
Files already downloaded and verified
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01, inplace=True)
    (3): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (4): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (5): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (6): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (7): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (8): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (9): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (10): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (11): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (12): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (13): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (14): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (15): Sequential(
      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (16): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (17): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (18): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (19): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.01, inplace=True)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (20): AdaptiveAvgPool2d(output_size=(1, 1))
    (21): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): LeakyReLU(negative_slope=0.01, inplace=True)
)
==> Resuming from checkpoint..
Start epoch: 51
First Lr: 0.01
Startepoche: 51
Max memory: 0.4014592
Epoche: [51/55]; Lr: 0.01
batch Size 256
Epoch: [51][0/196]	Time 3.289 (3.289)	Data 1.235 (1.235)	Loss 0.7422 (0.7422)	Acc@1 77.734 (77.734)	Acc@5 97.266 (97.266)
Epoch: [51][64/196]	Time 3.256 (3.001)	Data 0.000 (0.024)	Loss 0.8478 (0.8358)	Acc@1 69.922 (71.490)	Acc@5 97.266 (97.770)
Epoch: [51][128/196]	Time 2.378 (3.101)	Data 0.000 (0.014)	Loss 0.9887 (0.8528)	Acc@1 65.234 (70.888)	Acc@5 98.438 (97.829)
Epoch: [51][192/196]	Time 2.704 (2.808)	Data 0.000 (0.010)	Loss 0.9227 (0.8484)	Acc@1 67.969 (71.021)	Acc@5 95.703 (97.798)
Epoche: [52/55]; Lr: 0.01
batch Size 256
Epoch: [52][0/196]	Time 2.758 (2.758)	Data 0.600 (0.600)	Loss 0.8942 (0.8942)	Acc@1 70.312 (70.312)	Acc@5 98.438 (98.438)
Epoch: [52][64/196]	Time 3.434 (2.610)	Data 0.000 (0.011)	Loss 0.7885 (0.8394)	Acc@1 73.047 (71.232)	Acc@5 98.047 (97.921)
Epoch: [52][128/196]	Time 4.996 (3.549)	Data 0.005 (0.009)	Loss 0.9620 (0.8416)	Acc@1 64.844 (71.248)	Acc@5 98.828 (97.817)
Epoch: [52][192/196]	Time 5.650 (4.058)	Data 0.000 (0.008)	Loss 0.7356 (0.8466)	Acc@1 75.781 (71.165)	Acc@5 98.438 (97.830)
Epoche: [53/55]; Lr: 0.01
batch Size 256
Epoch: [53][0/196]	Time 5.909 (5.909)	Data 1.090 (1.090)	Loss 0.8016 (0.8016)	Acc@1 74.219 (74.219)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 5.643 (5.550)	Data 0.000 (0.023)	Loss 0.9364 (0.8447)	Acc@1 68.359 (70.980)	Acc@5 97.656 (97.855)
Epoch: [53][128/196]	Time 6.219 (5.706)	Data 0.010 (0.016)	Loss 0.8263 (0.8369)	Acc@1 72.266 (71.160)	Acc@5 98.828 (97.862)
Epoch: [53][192/196]	Time 6.415 (5.899)	Data 0.000 (0.012)	Loss 0.7679 (0.8423)	Acc@1 73.047 (71.120)	Acc@5 98.438 (97.824)
Epoche: [54/55]; Lr: 0.01
batch Size 256
