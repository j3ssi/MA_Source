Net2Net Deeper 1
j: 1 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 9994
Files already downloaded and verified
width: 16

Arch Num:  [[1, 1, 1, 1, 1], [2, 1, 1, 1, 1], [2, 1, 1, 1, 1]]
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (25): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): AdaptiveAvgPool2d(output_size=(1, 1))
    (37): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.101888
1
Epoche: [1/5]; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.130 (0.130)	Data 0.462 (0.462)	Loss 2.3825 (2.3825)	Acc@1 6.641 (6.641)	Acc@5 48.828 (48.828)
Epoch: [1][64/196]	Time 0.052 (0.047)	Data 0.000 (0.007)	Loss 1.7818 (1.9337)	Acc@1 33.984 (26.629)	Acc@5 83.984 (80.631)
Epoch: [1][128/196]	Time 0.053 (0.050)	Data 0.000 (0.004)	Loss 1.7702 (1.8160)	Acc@1 34.375 (30.926)	Acc@5 88.281 (84.578)
Epoch: [1][192/196]	Time 0.065 (0.054)	Data 0.000 (0.003)	Loss 1.6156 (1.7449)	Acc@1 39.844 (33.881)	Acc@5 87.891 (86.328)
1
Epoche: [2/5]; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.103 (0.103)	Data 0.457 (0.457)	Loss 1.6458 (1.6458)	Acc@1 35.547 (35.547)	Acc@5 89.453 (89.453)
Epoch: [2][64/196]	Time 0.050 (0.064)	Data 0.000 (0.007)	Loss 1.4347 (1.5274)	Acc@1 45.703 (43.450)	Acc@5 91.797 (91.214)
Epoch: [2][128/196]	Time 0.059 (0.063)	Data 0.000 (0.004)	Loss 1.4579 (1.4889)	Acc@1 44.531 (45.040)	Acc@5 92.969 (91.906)
Epoch: [2][192/196]	Time 0.042 (0.061)	Data 0.000 (0.003)	Loss 1.3829 (1.4595)	Acc@1 48.047 (46.337)	Acc@5 94.922 (92.343)
1
Epoche: [3/5]; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.104 (0.104)	Data 0.401 (0.401)	Loss 1.3919 (1.3919)	Acc@1 47.266 (47.266)	Acc@5 94.922 (94.922)
Epoch: [3][64/196]	Time 0.055 (0.063)	Data 0.000 (0.006)	Loss 1.3705 (1.3649)	Acc@1 49.609 (50.355)	Acc@5 91.797 (93.888)
Epoch: [3][128/196]	Time 0.063 (0.063)	Data 0.000 (0.003)	Loss 1.2855 (1.3360)	Acc@1 55.859 (51.441)	Acc@5 91.797 (94.053)
Epoch: [3][192/196]	Time 0.070 (0.062)	Data 0.000 (0.002)	Loss 1.2605 (1.3243)	Acc@1 55.469 (52.024)	Acc@5 94.531 (94.128)
1
Epoche: [4/5]; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.082 (0.082)	Data 0.388 (0.388)	Loss 1.3146 (1.3146)	Acc@1 52.734 (52.734)	Acc@5 94.141 (94.141)
Epoch: [4][64/196]	Time 0.044 (0.058)	Data 0.000 (0.006)	Loss 1.2665 (1.2802)	Acc@1 57.422 (54.020)	Acc@5 94.531 (94.555)
Epoch: [4][128/196]	Time 0.068 (0.059)	Data 0.000 (0.003)	Loss 1.2328 (1.2618)	Acc@1 53.516 (54.648)	Acc@5 94.531 (94.728)
Epoch: [4][192/196]	Time 0.056 (0.060)	Data 0.000 (0.002)	Loss 1.1602 (1.2490)	Acc@1 57.422 (54.949)	Acc@5 96.094 (94.857)
1
Epoche: [5/5]; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.122 (0.122)	Data 0.372 (0.372)	Loss 1.2150 (1.2150)	Acc@1 56.250 (56.250)	Acc@5 95.312 (95.312)
Epoch: [5][64/196]	Time 0.052 (0.064)	Data 0.000 (0.006)	Loss 1.3172 (1.1934)	Acc@1 55.078 (57.169)	Acc@5 92.578 (95.319)
Epoch: [5][128/196]	Time 0.054 (0.064)	Data 0.000 (0.003)	Loss 1.1028 (1.1825)	Acc@1 60.156 (57.461)	Acc@5 96.484 (95.428)
Epoch: [5][192/196]	Time 0.052 (0.059)	Data 0.000 (0.002)	Loss 1.2809 (1.1776)	Acc@1 54.297 (57.823)	Acc@5 93.359 (95.470)
Test acc1:  55.85
Test acc2:  55.85
[INFO] Storing checkpoint...
Max memory: 13.0463232
 12.013s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 5736
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 6
First Lr: 0.1
Startepoche: 6
Max memory: 0.2204672
1
Epoche: [6/10]; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 0.106 (0.106)	Data 0.554 (0.554)	Loss 1.1662 (1.1662)	Acc@1 55.859 (55.859)	Acc@5 95.703 (95.703)
Epoch: [6][64/196]	Time 0.054 (0.059)	Data 0.000 (0.009)	Loss 1.3056 (1.1800)	Acc@1 53.516 (57.518)	Acc@5 94.141 (95.349)
Epoch: [6][128/196]	Time 0.057 (0.059)	Data 0.000 (0.004)	Loss 1.1364 (1.1728)	Acc@1 63.672 (57.997)	Acc@5 96.094 (95.494)
Epoch: [6][192/196]	Time 0.053 (0.060)	Data 0.000 (0.003)	Loss 1.1663 (1.1721)	Acc@1 60.156 (58.165)	Acc@5 94.922 (95.501)
1
Epoche: [7/10]; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 0.104 (0.104)	Data 0.395 (0.395)	Loss 1.2304 (1.2304)	Acc@1 56.250 (56.250)	Acc@5 96.484 (96.484)
Epoch: [7][64/196]	Time 0.064 (0.061)	Data 0.000 (0.006)	Loss 1.2474 (1.1702)	Acc@1 57.031 (57.879)	Acc@5 93.359 (95.517)
Epoch: [7][128/196]	Time 0.041 (0.056)	Data 0.000 (0.003)	Loss 1.1831 (1.1742)	Acc@1 57.031 (57.791)	Acc@5 96.875 (95.537)
Epoch: [7][192/196]	Time 0.037 (0.051)	Data 0.000 (0.002)	Loss 1.0882 (1.1743)	Acc@1 63.281 (57.823)	Acc@5 94.531 (95.592)
1
Epoche: [8/10]; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 0.065 (0.065)	Data 0.347 (0.347)	Loss 1.1396 (1.1396)	Acc@1 62.500 (62.500)	Acc@5 94.922 (94.922)
Epoch: [8][64/196]	Time 0.040 (0.042)	Data 0.000 (0.006)	Loss 1.2781 (1.1900)	Acc@1 57.031 (57.121)	Acc@5 95.312 (95.306)
Epoch: [8][128/196]	Time 0.041 (0.042)	Data 0.000 (0.003)	Loss 1.1659 (1.1814)	Acc@1 61.719 (57.767)	Acc@5 95.703 (95.334)
Epoch: [8][192/196]	Time 0.062 (0.043)	Data 0.000 (0.002)	Loss 1.2339 (1.1779)	Acc@1 59.766 (57.946)	Acc@5 95.312 (95.434)
1
Epoche: [9/10]; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 0.072 (0.072)	Data 0.448 (0.448)	Loss 1.1644 (1.1644)	Acc@1 55.078 (55.078)	Acc@5 96.094 (96.094)
Epoch: [9][64/196]	Time 0.053 (0.059)	Data 0.000 (0.007)	Loss 1.1014 (1.1819)	Acc@1 58.984 (57.728)	Acc@5 96.094 (95.451)
Epoch: [9][128/196]	Time 0.052 (0.061)	Data 0.000 (0.004)	Loss 1.2702 (1.1774)	Acc@1 52.734 (58.006)	Acc@5 94.531 (95.455)
Epoch: [9][192/196]	Time 0.047 (0.060)	Data 0.000 (0.003)	Loss 1.1016 (1.1731)	Acc@1 63.672 (58.047)	Acc@5 96.875 (95.505)
1
Epoche: [10/10]; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 0.231 (0.231)	Data 0.410 (0.410)	Loss 1.1704 (1.1704)	Acc@1 60.547 (60.547)	Acc@5 95.312 (95.312)
Epoch: [10][64/196]	Time 0.055 (0.055)	Data 0.000 (0.007)	Loss 1.1130 (1.1624)	Acc@1 62.891 (58.119)	Acc@5 96.484 (95.853)
Epoch: [10][128/196]	Time 0.056 (0.058)	Data 0.000 (0.003)	Loss 1.1698 (1.1703)	Acc@1 58.984 (57.973)	Acc@5 94.531 (95.694)
Epoch: [10][192/196]	Time 0.061 (0.058)	Data 0.000 (0.002)	Loss 1.2391 (1.1730)	Acc@1 53.906 (57.898)	Acc@5 94.141 (95.541)
Test acc1:  56.71
Test acc2:  56.71
[INFO] Storing checkpoint...
Max memory: 13.1454464
 11.922s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 3948
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 11
First Lr: 0.1
Startepoche: 11
Max memory: 0.2204672
1
Epoche: [11/15]; Lr: 0.1
batch Size 256
Epoch: [11][0/196]	Time 0.126 (0.126)	Data 0.409 (0.409)	Loss 1.2400 (1.2400)	Acc@1 55.469 (55.469)	Acc@5 95.703 (95.703)
Epoch: [11][64/196]	Time 0.053 (0.059)	Data 0.000 (0.006)	Loss 1.1168 (1.1715)	Acc@1 62.109 (58.107)	Acc@5 96.484 (95.607)
Epoch: [11][128/196]	Time 0.062 (0.059)	Data 0.000 (0.003)	Loss 1.0335 (1.1701)	Acc@1 62.891 (58.127)	Acc@5 96.094 (95.534)
Epoch: [11][192/196]	Time 0.048 (0.057)	Data 0.000 (0.002)	Loss 1.0893 (1.1746)	Acc@1 61.328 (58.041)	Acc@5 95.312 (95.535)
1
Epoche: [12/15]; Lr: 0.1
batch Size 256
Epoch: [12][0/196]	Time 0.066 (0.066)	Data 0.501 (0.501)	Loss 1.1061 (1.1061)	Acc@1 62.500 (62.500)	Acc@5 96.094 (96.094)
Epoch: [12][64/196]	Time 0.062 (0.060)	Data 0.000 (0.008)	Loss 1.2291 (1.1738)	Acc@1 52.344 (57.849)	Acc@5 94.531 (95.517)
Epoch: [12][128/196]	Time 0.061 (0.060)	Data 0.000 (0.004)	Loss 1.2204 (1.1748)	Acc@1 53.125 (57.670)	Acc@5 95.703 (95.537)
Epoch: [12][192/196]	Time 0.051 (0.060)	Data 0.000 (0.003)	Loss 1.1515 (1.1736)	Acc@1 62.500 (57.808)	Acc@5 96.094 (95.588)
1
Epoche: [13/15]; Lr: 0.1
batch Size 256
Epoch: [13][0/196]	Time 0.060 (0.060)	Data 0.295 (0.295)	Loss 1.2149 (1.2149)	Acc@1 53.906 (53.906)	Acc@5 95.703 (95.703)
Epoch: [13][64/196]	Time 0.046 (0.052)	Data 0.000 (0.005)	Loss 1.2056 (1.1795)	Acc@1 50.391 (57.133)	Acc@5 96.875 (95.457)
Epoch: [13][128/196]	Time 0.048 (0.053)	Data 0.000 (0.003)	Loss 1.1777 (1.1789)	Acc@1 62.891 (57.628)	Acc@5 96.094 (95.428)
Epoch: [13][192/196]	Time 0.068 (0.055)	Data 0.000 (0.002)	Loss 1.1416 (1.1771)	Acc@1 60.156 (57.768)	Acc@5 94.922 (95.383)
1
Epoche: [14/15]; Lr: 0.1
batch Size 256
Epoch: [14][0/196]	Time 0.049 (0.049)	Data 0.374 (0.374)	Loss 1.1750 (1.1750)	Acc@1 58.984 (58.984)	Acc@5 96.094 (96.094)
Epoch: [14][64/196]	Time 0.058 (0.058)	Data 0.000 (0.006)	Loss 1.1430 (1.1743)	Acc@1 57.812 (58.011)	Acc@5 96.484 (95.607)
Epoch: [14][128/196]	Time 0.054 (0.059)	Data 0.000 (0.003)	Loss 1.1078 (1.1699)	Acc@1 57.422 (57.819)	Acc@5 95.703 (95.633)
Epoch: [14][192/196]	Time 0.041 (0.057)	Data 0.000 (0.002)	Loss 1.1384 (1.1761)	Acc@1 57.812 (57.889)	Acc@5 95.703 (95.572)
1
Epoche: [15/15]; Lr: 0.1
batch Size 256
Epoch: [15][0/196]	Time 0.063 (0.063)	Data 0.389 (0.389)	Loss 1.1100 (1.1100)	Acc@1 61.328 (61.328)	Acc@5 95.703 (95.703)
Epoch: [15][64/196]	Time 0.047 (0.043)	Data 0.000 (0.007)	Loss 1.0528 (1.1570)	Acc@1 59.766 (58.510)	Acc@5 98.438 (95.661)
Epoch: [15][128/196]	Time 0.045 (0.042)	Data 0.000 (0.003)	Loss 1.1609 (1.1691)	Acc@1 55.469 (58.094)	Acc@5 95.312 (95.591)
Epoch: [15][192/196]	Time 0.035 (0.041)	Data 0.000 (0.002)	Loss 1.1146 (1.1750)	Acc@1 60.938 (57.908)	Acc@5 96.094 (95.472)
Test acc1:  56.59
Test acc2:  56.59
[INFO] Storing checkpoint...
Max memory: 13.1449856
 8.596s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 481
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 16
First Lr: 0.1
Startepoche: 16
Max memory: 0.2204672
1
Epoche: [16/20]; Lr: 0.1
batch Size 256
Epoch: [16][0/196]	Time 0.131 (0.131)	Data 0.503 (0.503)	Loss 1.2384 (1.2384)	Acc@1 55.078 (55.078)	Acc@5 96.875 (96.875)
Epoch: [16][64/196]	Time 0.049 (0.053)	Data 0.000 (0.008)	Loss 1.2369 (1.1846)	Acc@1 54.297 (57.903)	Acc@5 96.094 (95.355)
Epoch: [16][128/196]	Time 0.051 (0.056)	Data 0.000 (0.004)	Loss 1.2659 (1.1753)	Acc@1 55.859 (57.991)	Acc@5 95.312 (95.512)
Epoch: [16][192/196]	Time 0.063 (0.058)	Data 0.000 (0.003)	Loss 1.2191 (1.1736)	Acc@1 55.469 (57.968)	Acc@5 94.922 (95.545)
1
Epoche: [17/20]; Lr: 0.1
batch Size 256
Epoch: [17][0/196]	Time 0.069 (0.069)	Data 0.431 (0.431)	Loss 1.0848 (1.0848)	Acc@1 63.281 (63.281)	Acc@5 98.047 (98.047)
Epoch: [17][64/196]	Time 0.061 (0.058)	Data 0.000 (0.007)	Loss 1.1259 (1.1716)	Acc@1 57.422 (57.849)	Acc@5 97.656 (95.577)
Epoch: [17][128/196]	Time 0.062 (0.059)	Data 0.000 (0.004)	Loss 1.1390 (1.1720)	Acc@1 55.078 (57.961)	Acc@5 96.094 (95.594)
Epoch: [17][192/196]	Time 0.058 (0.057)	Data 0.000 (0.002)	Loss 1.1137 (1.1759)	Acc@1 60.938 (57.734)	Acc@5 97.266 (95.565)
1
Epoche: [18/20]; Lr: 0.1
batch Size 256
Epoch: [18][0/196]	Time 0.092 (0.092)	Data 0.539 (0.539)	Loss 1.2253 (1.2253)	Acc@1 56.250 (56.250)	Acc@5 94.531 (94.531)
Epoch: [18][64/196]	Time 0.064 (0.060)	Data 0.000 (0.008)	Loss 1.2137 (1.1791)	Acc@1 55.469 (58.323)	Acc@5 96.875 (95.415)
Epoch: [18][128/196]	Time 0.065 (0.060)	Data 0.000 (0.004)	Loss 1.2030 (1.1753)	Acc@1 61.719 (57.943)	Acc@5 93.750 (95.467)
Epoch: [18][192/196]	Time 0.057 (0.060)	Data 0.000 (0.003)	Loss 1.0660 (1.1746)	Acc@1 58.984 (57.808)	Acc@5 96.094 (95.541)
1
Epoche: [19/20]; Lr: 0.1
batch Size 256
Epoch: [19][0/196]	Time 0.083 (0.083)	Data 0.429 (0.429)	Loss 1.2781 (1.2781)	Acc@1 52.344 (52.344)	Acc@5 94.141 (94.141)
Epoch: [19][64/196]	Time 0.044 (0.052)	Data 0.000 (0.007)	Loss 1.2682 (1.1758)	Acc@1 54.688 (57.386)	Acc@5 97.656 (95.583)
Epoch: [19][128/196]	Time 0.060 (0.055)	Data 0.000 (0.004)	Loss 1.2116 (1.1765)	Acc@1 54.688 (57.903)	Acc@5 95.312 (95.506)
Epoch: [19][192/196]	Time 0.050 (0.056)	Data 0.000 (0.002)	Loss 1.0885 (1.1757)	Acc@1 61.719 (57.839)	Acc@5 96.094 (95.586)
1
Epoche: [20/20]; Lr: 0.1
batch Size 256
Epoch: [20][0/196]	Time 0.086 (0.086)	Data 0.408 (0.408)	Loss 1.1645 (1.1645)	Acc@1 59.766 (59.766)	Acc@5 96.094 (96.094)
Epoch: [20][64/196]	Time 0.068 (0.061)	Data 0.000 (0.006)	Loss 1.2008 (1.1709)	Acc@1 58.203 (57.921)	Acc@5 94.531 (95.288)
Epoch: [20][128/196]	Time 0.072 (0.061)	Data 0.001 (0.003)	Loss 1.1468 (1.1758)	Acc@1 58.984 (57.758)	Acc@5 96.484 (95.409)
Epoch: [20][192/196]	Time 0.043 (0.056)	Data 0.000 (0.002)	Loss 1.2763 (1.1749)	Acc@1 51.953 (57.768)	Acc@5 95.312 (95.491)
Test acc1:  56.49
Test acc2:  56.49
[INFO] Storing checkpoint...
Max memory: 13.1449856
 11.600s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 9816
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 21
First Lr: 0.1
Startepoche: 21
Max memory: 0.2204672
1
Epoche: [21/25]; Lr: 0.1
batch Size 256
Epoch: [21][0/196]	Time 0.086 (0.086)	Data 0.476 (0.476)	Loss 1.1631 (1.1631)	Acc@1 59.766 (59.766)	Acc@5 94.141 (94.141)
Epoch: [21][64/196]	Time 0.034 (0.045)	Data 0.000 (0.008)	Loss 1.2529 (1.1758)	Acc@1 53.906 (57.530)	Acc@5 93.359 (95.625)
Epoch: [21][128/196]	Time 0.037 (0.043)	Data 0.000 (0.004)	Loss 1.2744 (1.1775)	Acc@1 54.297 (57.758)	Acc@5 96.875 (95.534)
Epoch: [21][192/196]	Time 0.036 (0.042)	Data 0.000 (0.003)	Loss 1.1785 (1.1735)	Acc@1 59.766 (57.958)	Acc@5 96.094 (95.557)
1
Epoche: [22/25]; Lr: 0.1
batch Size 256
Epoch: [22][0/196]	Time 0.069 (0.069)	Data 0.443 (0.443)	Loss 1.1465 (1.1465)	Acc@1 57.812 (57.812)	Acc@5 97.266 (97.266)
Epoch: [22][64/196]	Time 0.062 (0.049)	Data 0.000 (0.007)	Loss 1.1253 (1.1696)	Acc@1 61.719 (58.185)	Acc@5 96.875 (95.409)
Epoch: [22][128/196]	Time 0.052 (0.056)	Data 0.000 (0.004)	Loss 1.1513 (1.1709)	Acc@1 59.375 (57.967)	Acc@5 95.312 (95.476)
Epoch: [22][192/196]	Time 0.052 (0.057)	Data 0.000 (0.002)	Loss 1.1805 (1.1743)	Acc@1 59.766 (57.725)	Acc@5 93.750 (95.478)
1
Epoche: [23/25]; Lr: 0.1
batch Size 256
Epoch: [23][0/196]	Time 0.069 (0.069)	Data 0.450 (0.450)	Loss 1.2009 (1.2009)	Acc@1 57.812 (57.812)	Acc@5 96.484 (96.484)
Epoch: [23][64/196]	Time 0.061 (0.062)	Data 0.000 (0.007)	Loss 1.0924 (1.1796)	Acc@1 64.453 (57.819)	Acc@5 96.875 (95.391)
Epoch: [23][128/196]	Time 0.048 (0.060)	Data 0.000 (0.004)	Loss 1.0384 (1.1759)	Acc@1 62.500 (57.934)	Acc@5 96.875 (95.534)
Epoch: [23][192/196]	Time 0.053 (0.057)	Data 0.000 (0.003)	Loss 1.1460 (1.1754)	Acc@1 59.375 (58.013)	Acc@5 95.312 (95.507)
1
Epoche: [24/25]; Lr: 0.1
batch Size 256
Epoch: [24][0/196]	Time 0.076 (0.076)	Data 0.487 (0.487)	Loss 1.1635 (1.1635)	Acc@1 58.594 (58.594)	Acc@5 92.969 (92.969)
Epoch: [24][64/196]	Time 0.060 (0.058)	Data 0.000 (0.008)	Loss 1.1313 (1.1728)	Acc@1 57.422 (57.794)	Acc@5 96.875 (95.457)
Epoch: [24][128/196]	Time 0.049 (0.057)	Data 0.000 (0.004)	Loss 1.1718 (1.1766)	Acc@1 57.812 (57.855)	Acc@5 96.875 (95.440)
Epoch: [24][192/196]	Time 0.065 (0.059)	Data 0.000 (0.003)	Loss 1.0846 (1.1755)	Acc@1 62.500 (57.912)	Acc@5 98.438 (95.503)
1
Epoche: [25/25]; Lr: 0.1
batch Size 256
Epoch: [25][0/196]	Time 0.064 (0.064)	Data 0.431 (0.431)	Loss 1.2144 (1.2144)	Acc@1 53.906 (53.906)	Acc@5 96.484 (96.484)
Epoch: [25][64/196]	Time 0.070 (0.049)	Data 0.000 (0.007)	Loss 1.1984 (1.1704)	Acc@1 57.422 (58.059)	Acc@5 94.531 (95.337)
Epoch: [25][128/196]	Time 0.065 (0.053)	Data 0.000 (0.004)	Loss 1.1971 (1.1664)	Acc@1 57.422 (58.133)	Acc@5 94.922 (95.470)
Epoch: [25][192/196]	Time 0.053 (0.055)	Data 0.000 (0.002)	Loss 1.1555 (1.1748)	Acc@1 58.594 (57.810)	Acc@5 96.484 (95.408)
Test acc1:  56.59
Test acc2:  56.59
[INFO] Storing checkpoint...
Max memory: 13.1454464
 11.340s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 7516
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 26
First Lr: 0.1
Startepoche: 26
Max memory: 0.2204672
1
Epoche: [26/30]; Lr: 0.1
batch Size 256
Epoch: [26][0/196]	Time 0.126 (0.126)	Data 0.452 (0.452)	Loss 1.1285 (1.1285)	Acc@1 60.156 (60.156)	Acc@5 96.484 (96.484)
Epoch: [26][64/196]	Time 0.056 (0.058)	Data 0.000 (0.007)	Loss 1.1882 (1.1770)	Acc@1 55.859 (57.831)	Acc@5 94.922 (95.475)
Epoch: [26][128/196]	Time 0.061 (0.059)	Data 0.000 (0.004)	Loss 1.2927 (1.1733)	Acc@1 55.859 (58.076)	Acc@5 92.969 (95.518)
Epoch: [26][192/196]	Time 0.044 (0.058)	Data 0.000 (0.003)	Loss 1.1036 (1.1751)	Acc@1 56.250 (57.980)	Acc@5 96.484 (95.476)
1
Epoche: [27/30]; Lr: 0.1
batch Size 256
Epoch: [27][0/196]	Time 0.097 (0.097)	Data 0.394 (0.394)	Loss 1.1170 (1.1170)	Acc@1 63.672 (63.672)	Acc@5 96.094 (96.094)
Epoch: [27][64/196]	Time 0.044 (0.060)	Data 0.000 (0.006)	Loss 1.1220 (1.1733)	Acc@1 59.375 (57.686)	Acc@5 98.047 (95.379)
Epoch: [27][128/196]	Time 0.077 (0.060)	Data 0.000 (0.003)	Loss 1.2366 (1.1733)	Acc@1 53.516 (57.761)	Acc@5 95.312 (95.509)
Epoch: [27][192/196]	Time 0.062 (0.060)	Data 0.000 (0.002)	Loss 1.2051 (1.1736)	Acc@1 57.422 (57.683)	Acc@5 96.094 (95.539)
1
Epoche: [28/30]; Lr: 0.1
batch Size 256
Epoch: [28][0/196]	Time 0.075 (0.075)	Data 0.375 (0.375)	Loss 1.2898 (1.2898)	Acc@1 53.516 (53.516)	Acc@5 93.359 (93.359)
Epoch: [28][64/196]	Time 0.042 (0.061)	Data 0.000 (0.006)	Loss 1.1568 (1.1729)	Acc@1 59.766 (57.819)	Acc@5 95.703 (95.481)
Epoch: [28][128/196]	Time 0.044 (0.055)	Data 0.000 (0.003)	Loss 1.3121 (1.1737)	Acc@1 53.516 (57.958)	Acc@5 92.578 (95.309)
Epoch: [28][192/196]	Time 0.037 (0.051)	Data 0.000 (0.002)	Loss 1.2460 (1.1774)	Acc@1 51.953 (57.756)	Acc@5 95.312 (95.438)
1
Epoche: [29/30]; Lr: 0.1
batch Size 256
Epoch: [29][0/196]	Time 0.057 (0.057)	Data 0.360 (0.360)	Loss 1.1913 (1.1913)	Acc@1 58.984 (58.984)	Acc@5 95.703 (95.703)
Epoch: [29][64/196]	Time 0.050 (0.043)	Data 0.000 (0.006)	Loss 1.1375 (1.1683)	Acc@1 59.375 (58.197)	Acc@5 95.312 (95.751)
Epoch: [29][128/196]	Time 0.048 (0.043)	Data 0.000 (0.003)	Loss 1.2811 (1.1701)	Acc@1 50.391 (57.934)	Acc@5 95.312 (95.561)
Epoch: [29][192/196]	Time 0.047 (0.044)	Data 0.000 (0.002)	Loss 1.2957 (1.1744)	Acc@1 51.562 (57.790)	Acc@5 93.750 (95.493)
1
Epoche: [30/30]; Lr: 0.1
batch Size 256
Epoch: [30][0/196]	Time 0.079 (0.079)	Data 0.434 (0.434)	Loss 1.2495 (1.2495)	Acc@1 55.078 (55.078)	Acc@5 94.531 (94.531)
Epoch: [30][64/196]	Time 0.046 (0.058)	Data 0.000 (0.007)	Loss 1.1618 (1.1613)	Acc@1 60.938 (58.438)	Acc@5 95.312 (95.427)
Epoch: [30][128/196]	Time 0.056 (0.058)	Data 0.000 (0.004)	Loss 1.1888 (1.1665)	Acc@1 53.906 (58.049)	Acc@5 95.703 (95.564)
Epoch: [30][192/196]	Time 0.065 (0.058)	Data 0.000 (0.002)	Loss 1.0869 (1.1698)	Acc@1 58.594 (57.837)	Acc@5 98.438 (95.539)
Test acc1:  56.59
Test acc2:  56.59
[INFO] Storing checkpoint...
Max memory: 13.1449856
 11.939s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 4345
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 31
First Lr: 0.1
Startepoche: 31
Max memory: 0.2204672
1
Epoche: [31/35]; Lr: 0.1
batch Size 256
Epoch: [31][0/196]	Time 0.095 (0.095)	Data 0.444 (0.444)	Loss 1.1728 (1.1728)	Acc@1 58.984 (58.984)	Acc@5 96.875 (96.875)
Epoch: [31][64/196]	Time 0.059 (0.062)	Data 0.000 (0.007)	Loss 1.0985 (1.1749)	Acc@1 58.984 (57.987)	Acc@5 96.484 (95.685)
Epoch: [31][128/196]	Time 0.077 (0.056)	Data 0.000 (0.004)	Loss 1.1900 (1.1696)	Acc@1 57.422 (58.100)	Acc@5 92.188 (95.606)
Epoch: [31][192/196]	Time 0.050 (0.056)	Data 0.000 (0.002)	Loss 1.2674 (1.1753)	Acc@1 52.344 (57.843)	Acc@5 96.484 (95.537)
1
Epoche: [32/35]; Lr: 0.1
batch Size 256
Epoch: [32][0/196]	Time 0.069 (0.069)	Data 0.408 (0.408)	Loss 1.2691 (1.2691)	Acc@1 57.422 (57.422)	Acc@5 94.141 (94.141)
Epoch: [32][64/196]	Time 0.065 (0.062)	Data 0.000 (0.006)	Loss 1.1504 (1.1729)	Acc@1 59.375 (58.173)	Acc@5 94.922 (95.397)
Epoch: [32][128/196]	Time 0.074 (0.059)	Data 0.000 (0.003)	Loss 1.1254 (1.1767)	Acc@1 63.281 (57.816)	Acc@5 94.922 (95.391)
Epoch: [32][192/196]	Time 0.052 (0.059)	Data 0.000 (0.002)	Loss 1.2476 (1.1774)	Acc@1 53.125 (57.721)	Acc@5 95.703 (95.400)
1
Epoche: [33/35]; Lr: 0.1
batch Size 256
Epoch: [33][0/196]	Time 0.067 (0.067)	Data 0.367 (0.367)	Loss 1.2206 (1.2206)	Acc@1 53.516 (53.516)	Acc@5 94.922 (94.922)
Epoch: [33][64/196]	Time 0.039 (0.055)	Data 0.000 (0.006)	Loss 1.2325 (1.1684)	Acc@1 56.641 (57.957)	Acc@5 94.531 (95.589)
Epoch: [33][128/196]	Time 0.059 (0.057)	Data 0.000 (0.003)	Loss 1.2049 (1.1745)	Acc@1 54.688 (57.525)	Acc@5 95.312 (95.512)
Epoch: [33][192/196]	Time 0.045 (0.058)	Data 0.000 (0.002)	Loss 1.2511 (1.1759)	Acc@1 57.422 (57.513)	Acc@5 94.141 (95.521)
1
Epoche: [34/35]; Lr: 0.1
batch Size 256
Epoch: [34][0/196]	Time 0.089 (0.089)	Data 0.363 (0.363)	Loss 1.0795 (1.0795)	Acc@1 58.984 (58.984)	Acc@5 95.312 (95.312)
Epoch: [34][64/196]	Time 0.043 (0.060)	Data 0.000 (0.006)	Loss 1.0694 (1.1713)	Acc@1 60.547 (57.855)	Acc@5 96.875 (95.517)
Epoch: [34][128/196]	Time 0.048 (0.057)	Data 0.000 (0.003)	Loss 1.2555 (1.1746)	Acc@1 53.906 (57.946)	Acc@5 92.969 (95.400)
Epoch: [34][192/196]	Time 0.065 (0.057)	Data 0.000 (0.002)	Loss 1.0966 (1.1758)	Acc@1 60.156 (57.823)	Acc@5 97.656 (95.458)
1
Epoche: [35/35]; Lr: 0.1
batch Size 256
Epoch: [35][0/196]	Time 0.073 (0.073)	Data 0.495 (0.495)	Loss 1.2759 (1.2759)	Acc@1 50.391 (50.391)	Acc@5 96.094 (96.094)
Epoch: [35][64/196]	Time 0.055 (0.060)	Data 0.000 (0.008)	Loss 1.1722 (1.1785)	Acc@1 55.469 (57.692)	Acc@5 94.531 (95.258)
Epoch: [35][128/196]	Time 0.056 (0.058)	Data 0.000 (0.004)	Loss 1.1785 (1.1728)	Acc@1 55.469 (57.928)	Acc@5 96.484 (95.431)
Epoch: [35][192/196]	Time 0.056 (0.058)	Data 0.000 (0.003)	Loss 1.1740 (1.1727)	Acc@1 55.078 (57.877)	Acc@5 96.484 (95.517)
Test acc1:  56.79
Test acc2:  56.79
[INFO] Storing checkpoint...
Max memory: 13.1449856
 12.013s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 154
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 36
First Lr: 0.1
Startepoche: 36
Max memory: 0.2204672
1
Epoche: [36/40]; Lr: 0.1
batch Size 256
Epoch: [36][0/196]	Time 0.064 (0.064)	Data 0.433 (0.433)	Loss 1.2291 (1.2291)	Acc@1 59.375 (59.375)	Acc@5 94.141 (94.141)
Epoch: [36][64/196]	Time 0.049 (0.054)	Data 0.000 (0.007)	Loss 1.1655 (1.1698)	Acc@1 56.250 (58.353)	Acc@5 96.484 (95.613)
Epoch: [36][128/196]	Time 0.052 (0.056)	Data 0.000 (0.004)	Loss 1.1844 (1.1723)	Acc@1 60.156 (58.109)	Acc@5 96.094 (95.552)
Epoch: [36][192/196]	Time 0.050 (0.057)	Data 0.000 (0.002)	Loss 1.2051 (1.1741)	Acc@1 53.125 (57.980)	Acc@5 95.703 (95.537)
1
Epoche: [37/40]; Lr: 0.1
batch Size 256
Epoch: [37][0/196]	Time 0.110 (0.110)	Data 0.426 (0.426)	Loss 1.2464 (1.2464)	Acc@1 57.812 (57.812)	Acc@5 94.531 (94.531)
Epoch: [37][64/196]	Time 0.051 (0.061)	Data 0.000 (0.007)	Loss 1.0664 (1.1812)	Acc@1 62.891 (57.620)	Acc@5 97.266 (95.463)
Epoch: [37][128/196]	Time 0.044 (0.058)	Data 0.000 (0.003)	Loss 1.0723 (1.1696)	Acc@1 64.453 (58.158)	Acc@5 95.703 (95.476)
Epoch: [37][192/196]	Time 0.056 (0.057)	Data 0.000 (0.002)	Loss 1.2508 (1.1743)	Acc@1 55.859 (57.900)	Acc@5 95.703 (95.513)
1
Epoche: [38/40]; Lr: 0.1
batch Size 256
Epoch: [38][0/196]	Time 0.073 (0.073)	Data 0.465 (0.465)	Loss 1.2176 (1.2176)	Acc@1 54.297 (54.297)	Acc@5 95.312 (95.312)
Epoch: [38][64/196]	Time 0.060 (0.059)	Data 0.000 (0.007)	Loss 1.1751 (1.1867)	Acc@1 57.031 (57.145)	Acc@5 94.531 (95.451)
Epoch: [38][128/196]	Time 0.067 (0.060)	Data 0.000 (0.004)	Loss 1.1656 (1.1769)	Acc@1 55.469 (57.622)	Acc@5 96.875 (95.612)
Epoch: [38][192/196]	Time 0.048 (0.060)	Data 0.000 (0.003)	Loss 1.1588 (1.1754)	Acc@1 59.375 (57.812)	Acc@5 94.922 (95.543)
1
Epoche: [39/40]; Lr: 0.1
batch Size 256
Epoch: [39][0/196]	Time 0.064 (0.064)	Data 0.397 (0.397)	Loss 1.2660 (1.2660)	Acc@1 53.125 (53.125)	Acc@5 95.312 (95.312)
Epoch: [39][64/196]	Time 0.064 (0.056)	Data 0.000 (0.006)	Loss 1.1056 (1.1699)	Acc@1 58.594 (57.554)	Acc@5 96.875 (95.709)
Epoch: [39][128/196]	Time 0.083 (0.059)	Data 0.000 (0.003)	Loss 1.1662 (1.1702)	Acc@1 55.469 (57.794)	Acc@5 95.312 (95.643)
Epoch: [39][192/196]	Time 0.057 (0.059)	Data 0.000 (0.002)	Loss 1.2174 (1.1749)	Acc@1 53.125 (57.642)	Acc@5 92.969 (95.572)
1
Epoche: [40/40]; Lr: 0.1
batch Size 256
Epoch: [40][0/196]	Time 0.084 (0.084)	Data 0.413 (0.413)	Loss 1.1816 (1.1816)	Acc@1 57.812 (57.812)	Acc@5 93.750 (93.750)
Epoch: [40][64/196]	Time 0.068 (0.060)	Data 0.000 (0.007)	Loss 1.2072 (1.1845)	Acc@1 55.469 (57.314)	Acc@5 94.531 (95.457)
Epoch: [40][128/196]	Time 0.049 (0.057)	Data 0.000 (0.003)	Loss 1.1308 (1.1771)	Acc@1 59.766 (57.655)	Acc@5 94.922 (95.403)
Epoch: [40][192/196]	Time 0.047 (0.057)	Data 0.000 (0.002)	Loss 1.2619 (1.1740)	Acc@1 52.734 (57.738)	Acc@5 93.750 (95.434)


now deeper1
module: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old =0
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old =1
Index: 2
module: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 2


Stage:  0
size:16, 16, 3, 3


	Block:  0
Len: 3
j: 3
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 3
 Shape: (16, 16, 3, 3)
Deeper: float64
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 4
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 3


	Block:  1
Len: 6
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 4
j: 5
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 5
 Shape: (16, 16, 3, 3)
Deeper: float64
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 6
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 5


	Block:  2
Len: 10
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 6
j: 7
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 7
 Shape: (16, 16, 3, 3)
Deeper: float64
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 8
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 7


	Block:  3
Len: 14
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 8
j: 9
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 9
 Shape: (16, 16, 3, 3)
Deeper: float64
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 10
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 9


	Block:  4
Len: 18
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 10
j: 11
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 11
 Shape: (16, 16, 3, 3)
Deeper: float64
module: Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 12
module: BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 11


Stage:  1
module: Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False); old: 12
size:32, 16, 3, 3


	Block:  0
Len: 23
j: 13
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 13
 Shape: (32, 16, 3, 3)
Deeper: float64
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 14
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 13
module: Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False); old: 14
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 15


	Block:  1
Len: 28
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 16
j: 17
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 17
 Shape: (32, 32, 3, 3)
Deeper: float64
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 18
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 17


	Block:  2
Len: 32
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 18
j: 19
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 19
 Shape: (32, 32, 3, 3)
Deeper: float64
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 20
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 19


	Block:  3
Len: 36
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 20
j: 21
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 21
 Shape: (32, 32, 3, 3)
Deeper: float64
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 22
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 21


	Block:  4
Len: 40
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 22
j: 23
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 23
 Shape: (32, 32, 3, 3)
Deeper: float64
module: Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 24
module: BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 23


Stage:  2
module: Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False); old: 24
size:64, 32, 3, 3


	Block:  0
Len: 45
j: 25
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 25
 Shape: (64, 32, 3, 3)
Deeper: float64
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 26
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 25
module: Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False); old: 26
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 27


	Block:  1
Len: 50
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 28
j: 29
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 29
 Shape: (64, 64, 3, 3)
Deeper: float64
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 30
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 29


	Block:  2
Len: 54
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 30
j: 31
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 31
 Shape: (64, 64, 3, 3)
Deeper: float64
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 32
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 31


	Block:  3
Len: 58
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 32
j: 33
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 33
 Shape: (64, 64, 3, 3)
Deeper: float64
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 34
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 33


	Block:  4
Len: 62
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); old: 34
j: 35
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
bn: 35
 Shape: (64, 64, 3, 3)
Deeper: float64
module: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False); j= 36
module: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True); old: 35
module: AdaptiveAvgPool2d(output_size=(1, 1)); old: 36
module: Linear(in_features=64, out_features=10, bias=True); old: 37
Modell: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
ArchNums: [[2, 2, 2, 2, 2], [3, 2, 2, 2, 2], [3, 2, 2, 2, 2]]
args.layersInBlock: 1
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Test acc1:  56.54
Test acc2:  10.0
[INFO] Storing checkpoint...
Reset! 
Max memory: 100.164352
 11.750s  j: 181 bis 185
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 2144
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 1
First Lr: 0.1
Startepoche: 1
Max memory: 0.3999232
1
Epoche: [1/5]; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.284 (0.284)	Data 0.469 (0.469)	Loss 2.2764 (2.2764)	Acc@1 17.578 (17.578)	Acc@5 65.625 (65.625)
Epoch: [1][64/196]	Time 0.194 (0.170)	Data 0.000 (0.007)	Loss 2.3047 (2.2880)	Acc@1 13.672 (17.091)	Acc@5 69.531 (66.502)
Epoch: [1][128/196]	Time 0.212 (0.178)	Data 0.000 (0.004)	Loss 2.2365 (2.2837)	Acc@1 20.703 (17.442)	Acc@5 67.578 (66.452)
Epoch: [1][192/196]	Time 0.104 (0.168)	Data 0.000 (0.003)	Loss 2.2867 (2.2825)	Acc@1 18.359 (17.552)	Acc@5 70.312 (66.714)
1
Epoche: [2/5]; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.131 (0.131)	Data 0.412 (0.412)	Loss 2.2566 (2.2566)	Acc@1 20.312 (20.312)	Acc@5 65.625 (65.625)
Epoch: [2][64/196]	Time 0.262 (0.124)	Data 0.000 (0.007)	Loss 2.4212 (2.2960)	Acc@1 12.891 (17.019)	Acc@5 61.328 (66.472)
Epoch: [2][128/196]	Time 0.168 (0.151)	Data 0.000 (0.003)	Loss 2.3156 (2.2875)	Acc@1 20.312 (17.209)	Acc@5 66.797 (66.630)
Epoch: [2][192/196]	Time 0.140 (0.160)	Data 0.000 (0.002)	Loss 2.2959 (2.2871)	Acc@1 15.234 (17.260)	Acc@5 66.016 (66.635)
1
Epoche: [3/5]; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.210 (0.210)	Data 0.420 (0.420)	Loss 2.3096 (2.3096)	Acc@1 15.234 (15.234)	Acc@5 64.062 (64.062)
Epoch: [3][64/196]	Time 0.185 (0.181)	Data 0.000 (0.007)	Loss 2.3056 (2.2864)	Acc@1 14.062 (17.091)	Acc@5 67.578 (67.025)
Epoch: [3][128/196]	Time 0.098 (0.176)	Data 0.000 (0.004)	Loss 2.2355 (2.2845)	Acc@1 20.312 (17.157)	Acc@5 69.141 (67.009)
Epoch: [3][192/196]	Time 0.184 (0.178)	Data 0.000 (0.002)	Loss 2.3008 (2.2843)	Acc@1 18.359 (17.285)	Acc@5 66.016 (66.702)
1
Epoche: [4/5]; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.269 (0.269)	Data 0.491 (0.491)	Loss 2.2765 (2.2765)	Acc@1 14.062 (14.062)	Acc@5 70.312 (70.312)
Epoch: [4][64/196]	Time 0.171 (0.172)	Data 0.000 (0.008)	Loss 2.2228 (2.2839)	Acc@1 17.578 (17.464)	Acc@5 66.406 (66.629)
Epoch: [4][128/196]	Time 0.187 (0.180)	Data 0.000 (0.004)	Loss 2.2766 (2.2833)	Acc@1 17.969 (17.548)	Acc@5 67.188 (66.754)
Epoch: [4][192/196]	Time 0.212 (0.177)	Data 0.000 (0.003)	Loss 2.2338 (2.2843)	Acc@1 21.094 (17.481)	Acc@5 67.188 (66.659)
1
Epoche: [5/5]; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.236 (0.236)	Data 0.466 (0.466)	Loss 2.2501 (2.2501)	Acc@1 17.578 (17.578)	Acc@5 67.188 (67.188)
Epoch: [5][64/196]	Time 0.212 (0.184)	Data 0.000 (0.007)	Loss 2.2950 (2.2820)	Acc@1 19.141 (17.452)	Acc@5 62.500 (66.641)
Epoch: [5][128/196]	Time 0.122 (0.172)	Data 0.000 (0.004)	Loss 2.2336 (2.2832)	Acc@1 20.312 (17.490)	Acc@5 67.188 (66.791)
Epoch: [5][192/196]	Time 0.123 (0.153)	Data 0.000 (0.003)	Loss 2.2550 (2.2824)	Acc@1 17.188 (17.538)	Acc@5 69.531 (66.718)
Test acc1:  20.07
Test acc2:  20.07
[INFO] Storing checkpoint...
Max memory: 101.0896384
 30.496s  j: 186 bis 190
no display found. Using non-interactive Agg backend
[5, 5, 5]
[16, 32, 64]
random number: 9117
Files already downloaded and verified
==> Resuming from checkpoint..
Start epoch: 6
First Lr: 0.1
Startepoche: 6
Max memory: 0.3999232
1
Epoche: [6/10]; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 0.227 (0.227)	Data 0.380 (0.380)	Loss 2.2871 (2.2871)	Acc@1 19.531 (19.531)	Acc@5 65.234 (65.234)
Epoch: [6][64/196]	Time 0.241 (0.174)	Data 0.000 (0.006)	Loss 2.3490 (2.2895)	Acc@1 14.453 (17.181)	Acc@5 63.672 (66.671)
Epoch: [6][128/196]	Time 0.172 (0.180)	Data 0.000 (0.003)	Loss 2.2472 (2.2855)	Acc@1 19.922 (17.384)	Acc@5 67.578 (66.748)
Epoch: [6][192/196]	Time 0.150 (0.177)	Data 0.000 (0.002)	Loss 2.2954 (2.2857)	Acc@1 18.359 (17.566)	Acc@5 69.141 (66.764)
1
Epoche: [7/10]; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 0.230 (0.230)	Data 0.422 (0.422)	Loss 2.3362 (2.3362)	Acc@1 15.234 (15.234)	Acc@5 65.625 (65.625)
Epoch: [7][64/196]	Time 0.152 (0.179)	Data 0.000 (0.007)	Loss 2.2813 (2.2804)	Acc@1 21.875 (17.668)	Acc@5 67.969 (66.941)
Epoch: [7][128/196]	Time 0.181 (0.178)	Data 0.000 (0.004)	Loss 2.2502 (2.2854)	Acc@1 19.141 (17.496)	Acc@5 69.531 (66.555)
Epoch: [7][192/196]	Time 0.179 (0.180)	Data 0.000 (0.002)	Loss 2.2674 (2.2840)	Acc@1 20.312 (17.465)	Acc@5 69.141 (66.740)
1
Epoche: [8/10]; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 0.227 (0.227)	Data 0.493 (0.493)	Loss 2.2958 (2.2958)	Acc@1 16.016 (16.016)	Acc@5 63.672 (63.672)
Epoch: [8][64/196]	Time 0.233 (0.191)	Data 0.000 (0.008)	Loss 2.3684 (2.2823)	Acc@1 13.672 (17.524)	Acc@5 59.766 (66.857)
Epoch: [8][128/196]	Time 0.156 (0.183)	Data 0.000 (0.004)	Loss 2.3511 (2.2847)	Acc@1 13.281 (17.300)	Acc@5 61.719 (66.770)
Epoch: [8][192/196]	Time 0.117 (0.163)	Data 0.000 (0.003)	Loss 2.2440 (2.2829)	Acc@1 18.750 (17.406)	Acc@5 67.188 (66.805)
1
Epoche: [9/10]; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 0.199 (0.199)	Data 0.364 (0.364)	Loss 2.3053 (2.3053)	Acc@1 16.406 (16.406)	Acc@5 69.922 (69.922)
Epoch: [9][64/196]	Time 0.181 (0.163)	Data 0.000 (0.006)	Loss 2.3383 (2.2862)	Acc@1 17.578 (17.314)	Acc@5 69.531 (66.593)
Epoch: [9][128/196]	Time 0.181 (0.172)	Data 0.000 (0.003)	Loss 2.2501 (2.2890)	Acc@1 18.359 (17.257)	Acc@5 67.969 (66.661)
Epoch: [9][192/196]	Time 0.182 (0.173)	Data 0.000 (0.002)	Loss 2.2476 (2.2856)	Acc@1 19.141 (17.355)	Acc@5 69.531 (66.631)
1
Epoche: [10/10]; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 0.358 (0.358)	Data 0.500 (0.500)	Loss 2.2879 (2.2879)	Acc@1 19.141 (19.141)	Acc@5 64.453 (64.453)
Epoch: [10][64/196]	Time 0.216 (0.181)	Data 0.000 (0.008)	Loss 2.2725 (2.2844)	Acc@1 16.406 (17.326)	Acc@5 68.750 (66.388)
Epoch: [10][128/196]	Time 0.205 (0.178)	Data 0.000 (0.004)	Loss 2.2617 (2.2885)	Acc@1 16.016 (17.018)	Acc@5 69.922 (66.291)
Epoch: [10][192/196]	Time 0.182 (0.180)	Data 0.000 (0.003)	Loss 2.3411 (2.2847)	Acc@1 14.844 (17.214)	Acc@5 61.719 (66.552)
Test acc1:  20.29
Test acc2:  20.29
[INFO] Storing checkpoint...
Max memory: 101.0896384
 35.784s  j: 191 bis 195
