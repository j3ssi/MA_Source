BSize 1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1172
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
batch_size berechnet: 250;389.1 ; lr: 0.1
lr: 0.09765625
1

Epoch: [1 | 5] LR: 0.097656
batch Size 250
Epoch: [1][0/200]	Time 0.198 (0.198)	Data 0.282 (0.282)	Loss 3.0407 (3.0407)	Acc@1 10.000 (10.000)	Acc@5 50.400 (50.400)
Epoch: [1][64/200]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 2.3415 (2.6005)	Acc@1 25.600 (23.908)	Acc@5 88.000 (78.486)
Epoch: [1][128/200]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 2.1164 (2.4342)	Acc@1 33.200 (29.678)	Acc@5 92.000 (83.473)
Epoch: [1][192/200]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 1.9381 (2.3099)	Acc@1 45.600 (34.551)	Acc@5 91.200 (86.116)
Max memory in training epoch: 66.4657408
lr: 0.09765625
1

Epoch: [2 | 5] LR: 0.097656
batch Size 250
Epoch: [2][0/200]	Time 0.176 (0.176)	Data 0.272 (0.272)	Loss 2.0326 (2.0326)	Acc@1 42.000 (42.000)	Acc@5 92.800 (92.800)
Epoch: [2][64/200]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 1.8842 (1.8611)	Acc@1 52.400 (51.569)	Acc@5 93.600 (93.557)
Epoch: [2][128/200]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 1.7333 (1.8032)	Acc@1 56.800 (53.631)	Acc@5 92.000 (94.074)
Epoch: [2][192/200]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 1.5603 (1.7386)	Acc@1 61.200 (55.859)	Acc@5 96.000 (94.686)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [3 | 5] LR: 0.097656
batch Size 250
Epoch: [3][0/200]	Time 0.188 (0.188)	Data 0.263 (0.263)	Loss 1.4938 (1.4938)	Acc@1 66.800 (66.800)	Acc@5 95.600 (95.600)
Epoch: [3][64/200]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 1.3998 (1.4799)	Acc@1 66.800 (64.135)	Acc@5 98.000 (96.634)
Epoch: [3][128/200]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 1.2609 (1.4454)	Acc@1 69.200 (65.095)	Acc@5 98.800 (96.878)
Epoch: [3][192/200]	Time 0.121 (0.131)	Data 0.000 (0.002)	Loss 1.2954 (1.4165)	Acc@1 66.800 (65.934)	Acc@5 98.400 (97.042)
Max memory in training epoch: 66.0135424
Drin!!
old memory: 0
new memory: 660135424
lr: 0.09765625
1

Epoch: [4 | 5] LR: 0.097656
batch Size 250
Epoch: [4][0/200]	Time 0.166 (0.166)	Data 0.298 (0.298)	Loss 1.1935 (1.1935)	Acc@1 73.600 (73.600)	Acc@5 98.400 (98.400)
Epoch: [4][64/200]	Time 0.173 (0.130)	Data 0.000 (0.005)	Loss 1.3039 (1.2522)	Acc@1 70.400 (71.114)	Acc@5 98.400 (97.975)
Epoch: [4][128/200]	Time 0.134 (0.128)	Data 0.000 (0.002)	Loss 1.1448 (1.2324)	Acc@1 75.600 (71.764)	Acc@5 98.400 (97.957)
Epoch: [4][192/200]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 1.1770 (1.2096)	Acc@1 75.200 (72.400)	Acc@5 98.800 (98.023)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [5 | 5] LR: 0.097656
batch Size 250
Epoch: [5][0/200]	Time 0.183 (0.183)	Data 0.257 (0.257)	Loss 1.1558 (1.1558)	Acc@1 72.800 (72.800)	Acc@5 98.800 (98.800)
Epoch: [5][64/200]	Time 0.129 (0.128)	Data 0.000 (0.004)	Loss 0.9985 (1.0987)	Acc@1 76.400 (75.920)	Acc@5 99.200 (98.394)
Epoch: [5][128/200]	Time 0.140 (0.128)	Data 0.000 (0.002)	Loss 1.1162 (1.0958)	Acc@1 75.200 (75.662)	Acc@5 98.400 (98.419)
Epoch: [5][192/200]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.9810 (1.0792)	Acc@1 80.000 (75.979)	Acc@5 97.600 (98.425)
Max memory in training epoch: 66.0135424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  66.5
Max memory: 103.3835008
 25.942s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6243
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.095367431640625
1

Epoch: [6 | 10] LR: 0.095367
batch Size 250
Epoch: [6][0/200]	Time 0.206 (0.206)	Data 0.254 (0.254)	Loss 1.1006 (1.1006)	Acc@1 77.200 (77.200)	Acc@5 97.600 (97.600)
Epoch: [6][64/200]	Time 0.132 (0.129)	Data 0.000 (0.004)	Loss 0.9616 (0.9847)	Acc@1 77.600 (78.437)	Acc@5 99.200 (98.560)
Epoch: [6][128/200]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 1.0154 (0.9954)	Acc@1 74.000 (78.009)	Acc@5 98.400 (98.487)
Epoch: [6][192/200]	Time 0.138 (0.131)	Data 0.000 (0.001)	Loss 1.1058 (0.9863)	Acc@1 74.000 (78.224)	Acc@5 97.600 (98.553)
Max memory in training epoch: 66.4656384
lr: 0.095367431640625
1

Epoch: [7 | 10] LR: 0.095367
batch Size 250
Epoch: [7][0/200]	Time 0.181 (0.181)	Data 0.289 (0.289)	Loss 1.0015 (1.0015)	Acc@1 78.800 (78.800)	Acc@5 99.200 (99.200)
Epoch: [7][64/200]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.8799 (0.9319)	Acc@1 84.000 (79.231)	Acc@5 99.600 (98.825)
Epoch: [7][128/200]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8947 (0.9332)	Acc@1 80.000 (79.200)	Acc@5 99.200 (98.775)
Epoch: [7][192/200]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.9466 (0.9254)	Acc@1 78.400 (79.326)	Acc@5 98.000 (98.790)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [8 | 10] LR: 0.095367
batch Size 250
Epoch: [8][0/200]	Time 0.206 (0.206)	Data 0.271 (0.271)	Loss 0.8065 (0.8065)	Acc@1 85.600 (85.600)	Acc@5 98.000 (98.000)
Epoch: [8][64/200]	Time 0.118 (0.129)	Data 0.000 (0.004)	Loss 0.8942 (0.8865)	Acc@1 78.000 (80.382)	Acc@5 99.200 (99.003)
Epoch: [8][128/200]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.8459 (0.8816)	Acc@1 80.800 (80.456)	Acc@5 99.200 (98.958)
Epoch: [8][192/200]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.8100 (0.8799)	Acc@1 83.600 (80.473)	Acc@5 98.800 (98.953)
Max memory in training epoch: 66.01344
Drin!!
old memory: 660135424
new memory: 660134400
Faktor: 0.9999984488031353
New batch Size größer 253!!
lr: 0.095367431640625
1

Epoch: [9 | 10] LR: 0.095367
batch Size 253
Epoch: [9][0/200]	Time 0.184 (0.184)	Data 0.276 (0.276)	Loss 0.8242 (0.8242)	Acc@1 82.400 (82.400)	Acc@5 99.600 (99.600)
Epoch: [9][64/200]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7753 (0.8567)	Acc@1 82.400 (81.163)	Acc@5 99.600 (98.837)
Epoch: [9][128/200]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.8638 (0.8521)	Acc@1 83.200 (81.256)	Acc@5 97.600 (98.949)
Epoch: [9][192/200]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7499 (0.8461)	Acc@1 82.800 (81.295)	Acc@5 98.400 (99.011)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [10 | 10] LR: 0.095367
batch Size 253
Epoch: [10][0/200]	Time 0.218 (0.218)	Data 0.314 (0.314)	Loss 0.6537 (0.6537)	Acc@1 88.800 (88.800)	Acc@5 99.200 (99.200)
Epoch: [10][64/200]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.8508 (0.8203)	Acc@1 82.000 (81.600)	Acc@5 99.200 (99.175)
Epoch: [10][128/200]	Time 0.129 (0.129)	Data 0.000 (0.003)	Loss 0.8684 (0.8263)	Acc@1 78.400 (81.479)	Acc@5 98.000 (99.113)
Epoch: [10][192/200]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7828 (0.8211)	Acc@1 84.400 (81.631)	Acc@5 99.200 (99.134)
Max memory in training epoch: 66.01344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.54
Max memory: 103.3833984
 26.306s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7059
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.09424984455108643
1

Epoch: [11 | 15] LR: 0.094250
batch Size 253
Epoch: [11][0/198]	Time 0.186 (0.186)	Data 0.289 (0.289)	Loss 0.7959 (0.7959)	Acc@1 83.399 (83.399)	Acc@5 98.814 (98.814)
Epoch: [11][64/198]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.7148 (0.7859)	Acc@1 85.771 (82.803)	Acc@5 100.000 (99.143)
Epoch: [11][128/198]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7651 (0.8007)	Acc@1 82.609 (82.287)	Acc@5 99.605 (99.072)
Epoch: [11][192/198]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7385 (0.8014)	Acc@1 84.190 (82.156)	Acc@5 98.814 (99.101)
Max memory in training epoch: 66.5037312
lr: 0.09424984455108643
1

Epoch: [12 | 15] LR: 0.094250
batch Size 253
Epoch: [12][0/198]	Time 0.180 (0.180)	Data 0.282 (0.282)	Loss 0.7952 (0.7952)	Acc@1 81.423 (81.423)	Acc@5 100.000 (100.000)
Epoch: [12][64/198]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.7448 (0.7830)	Acc@1 84.190 (82.487)	Acc@5 99.605 (99.137)
Epoch: [12][128/198]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.8321 (0.7839)	Acc@1 81.423 (82.495)	Acc@5 98.814 (99.154)
Epoch: [12][192/198]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7518 (0.7854)	Acc@1 83.004 (82.560)	Acc@5 99.605 (99.164)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [13 | 15] LR: 0.094250
batch Size 253
Epoch: [13][0/198]	Time 0.160 (0.160)	Data 0.268 (0.268)	Loss 0.7448 (0.7448)	Acc@1 84.190 (84.190)	Acc@5 99.605 (99.605)
Epoch: [13][64/198]	Time 0.138 (0.132)	Data 0.000 (0.004)	Loss 0.7548 (0.7653)	Acc@1 83.794 (83.144)	Acc@5 99.605 (99.276)
Epoch: [13][128/198]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8025 (0.7748)	Acc@1 83.004 (82.820)	Acc@5 98.814 (99.209)
Epoch: [13][192/198]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8527 (0.7765)	Acc@1 78.656 (82.848)	Acc@5 99.605 (99.201)
Max memory in training epoch: 66.277632
Drin!!
old memory: 660134400
new memory: 662776320
Faktor: 1.0040020941190158
New batch Size kleiner 254!!
lr: 0.09424984455108643
1

Epoch: [14 | 15] LR: 0.094250
batch Size 254
Epoch: [14][0/198]	Time 0.170 (0.170)	Data 0.276 (0.276)	Loss 0.7216 (0.7216)	Acc@1 84.980 (84.980)	Acc@5 99.605 (99.605)
Epoch: [14][64/198]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.7803 (0.7748)	Acc@1 81.028 (82.974)	Acc@5 99.605 (99.143)
Epoch: [14][128/198]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6642 (0.7704)	Acc@1 87.352 (83.071)	Acc@5 99.605 (99.164)
Epoch: [14][192/198]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.7353 (0.7679)	Acc@1 84.980 (83.164)	Acc@5 99.209 (99.181)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [15 | 15] LR: 0.094250
batch Size 254
Epoch: [15][0/198]	Time 0.184 (0.184)	Data 0.302 (0.302)	Loss 0.7830 (0.7830)	Acc@1 83.004 (83.004)	Acc@5 99.605 (99.605)
Epoch: [15][64/198]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 0.7743 (0.7534)	Acc@1 79.842 (83.776)	Acc@5 99.605 (99.185)
Epoch: [15][128/198]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.7469 (0.7594)	Acc@1 83.399 (83.568)	Acc@5 99.605 (99.219)
Epoch: [15][192/198]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.7955 (0.7569)	Acc@1 82.609 (83.594)	Acc@5 98.814 (99.201)
Max memory in training epoch: 66.277632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  69.56
Max memory: 103.3833984
 26.247s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2071
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.09351351764053106
1

Epoch: [16 | 20] LR: 0.093514
batch Size 254
Epoch: [16][0/197]	Time 0.199 (0.199)	Data 0.285 (0.285)	Loss 0.7147 (0.7147)	Acc@1 85.433 (85.433)	Acc@5 99.606 (99.606)
Epoch: [16][64/197]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.7545 (0.7126)	Acc@1 83.465 (85.082)	Acc@5 99.606 (99.303)
Epoch: [16][128/197]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6807 (0.7250)	Acc@1 87.402 (84.746)	Acc@5 99.606 (99.258)
Epoch: [16][192/197]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8444 (0.7367)	Acc@1 81.102 (84.240)	Acc@5 98.031 (99.264)
Max memory in training epoch: 66.5164288
lr: 0.09351351764053106
1

Epoch: [17 | 20] LR: 0.093514
batch Size 254
Epoch: [17][0/197]	Time 0.184 (0.184)	Data 0.283 (0.283)	Loss 0.6985 (0.6985)	Acc@1 84.646 (84.646)	Acc@5 99.213 (99.213)
Epoch: [17][64/197]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.7149 (0.7301)	Acc@1 85.827 (84.325)	Acc@5 98.819 (99.310)
Epoch: [17][128/197]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6989 (0.7362)	Acc@1 83.858 (83.974)	Acc@5 100.000 (99.280)
Epoch: [17][192/197]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7754 (0.7391)	Acc@1 79.528 (83.913)	Acc@5 98.819 (99.280)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [18 | 20] LR: 0.093514
batch Size 254
Epoch: [18][0/197]	Time 0.183 (0.183)	Data 0.270 (0.270)	Loss 0.7281 (0.7281)	Acc@1 81.890 (81.890)	Acc@5 99.606 (99.606)
Epoch: [18][64/197]	Time 0.137 (0.131)	Data 0.000 (0.004)	Loss 0.7489 (0.7260)	Acc@1 85.039 (84.579)	Acc@5 98.031 (99.279)
Epoch: [18][128/197]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.7246 (0.7321)	Acc@1 83.465 (84.340)	Acc@5 98.425 (99.243)
Epoch: [18][192/197]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.6542 (0.7346)	Acc@1 87.402 (84.270)	Acc@5 99.213 (99.284)
Max memory in training epoch: 66.365696
Drin!!
old memory: 662776320
new memory: 663656960
Faktor: 1.0013287137355782
New batch Size kleiner 254!!
lr: 0.09351351764053106
1

Epoch: [19 | 20] LR: 0.093514
batch Size 254
Epoch: [19][0/197]	Time 0.166 (0.166)	Data 0.291 (0.291)	Loss 0.7378 (0.7378)	Acc@1 83.465 (83.465)	Acc@5 98.819 (98.819)
Epoch: [19][64/197]	Time 0.131 (0.129)	Data 0.000 (0.005)	Loss 0.6400 (0.7187)	Acc@1 86.220 (84.791)	Acc@5 100.000 (99.261)
Epoch: [19][128/197]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7690 (0.7203)	Acc@1 86.220 (84.875)	Acc@5 98.425 (99.304)
Epoch: [19][192/197]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.7063 (0.7293)	Acc@1 85.039 (84.570)	Acc@5 99.606 (99.284)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [20 | 20] LR: 0.093514
batch Size 254
Epoch: [20][0/197]	Time 0.190 (0.190)	Data 0.304 (0.304)	Loss 0.6626 (0.6626)	Acc@1 85.433 (85.433)	Acc@5 99.606 (99.606)
Epoch: [20][64/197]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6556 (0.7084)	Acc@1 87.402 (85.161)	Acc@5 99.213 (99.419)
Epoch: [20][128/197]	Time 0.130 (0.130)	Data 0.000 (0.003)	Loss 0.8637 (0.7217)	Acc@1 81.102 (84.688)	Acc@5 99.213 (99.338)
Epoch: [20][192/197]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7388 (0.7192)	Acc@1 83.071 (84.744)	Acc@5 99.606 (99.308)
Max memory in training epoch: 66.365696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  69.71
Max memory: 103.3833984
 25.887s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5525
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2020864
lr: 0.09278294328396441
1

Epoch: [21 | 25] LR: 0.092783
batch Size 254
Epoch: [21][0/197]	Time 0.182 (0.182)	Data 0.302 (0.302)	Loss 0.6634 (0.6634)	Acc@1 87.795 (87.795)	Acc@5 98.819 (98.819)
Epoch: [21][64/197]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7992 (0.6980)	Acc@1 83.071 (85.488)	Acc@5 98.425 (99.352)
Epoch: [21][128/197]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 0.6451 (0.7046)	Acc@1 86.220 (85.143)	Acc@5 99.213 (99.356)
Epoch: [21][192/197]	Time 0.120 (0.129)	Data 0.000 (0.002)	Loss 0.7689 (0.7066)	Acc@1 83.465 (85.152)	Acc@5 98.819 (99.368)
Max memory in training epoch: 66.5147904
lr: 0.09278294328396441
1

Epoch: [22 | 25] LR: 0.092783
batch Size 254
Epoch: [22][0/197]	Time 0.152 (0.152)	Data 0.275 (0.275)	Loss 0.8141 (0.8141)	Acc@1 83.071 (83.071)	Acc@5 99.213 (99.213)
Epoch: [22][64/197]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 0.8401 (0.7169)	Acc@1 77.559 (84.912)	Acc@5 97.638 (99.249)
Epoch: [22][128/197]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.6141 (0.7214)	Acc@1 88.583 (84.737)	Acc@5 98.819 (99.271)
Epoch: [22][192/197]	Time 0.120 (0.132)	Data 0.000 (0.002)	Loss 0.6632 (0.7141)	Acc@1 86.220 (84.921)	Acc@5 99.606 (99.300)
Max memory in training epoch: 66.3640576
lr: 0.09278294328396441
1

Epoch: [23 | 25] LR: 0.092783
batch Size 254
Epoch: [23][0/197]	Time 0.173 (0.173)	Data 0.299 (0.299)	Loss 0.6649 (0.6649)	Acc@1 88.976 (88.976)	Acc@5 99.606 (99.606)
Epoch: [23][64/197]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.6602 (0.7152)	Acc@1 88.583 (84.967)	Acc@5 99.606 (99.358)
Epoch: [23][128/197]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6740 (0.7126)	Acc@1 84.252 (85.024)	Acc@5 98.819 (99.359)
Epoch: [23][192/197]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7179 (0.7169)	Acc@1 85.433 (84.776)	Acc@5 99.213 (99.368)
Max memory in training epoch: 66.3640576
Drin!!
old memory: 663656960
new memory: 663640576
Faktor: 0.9999753125470122
New batch Size größer 256!!
lr: 0.09278294328396441
1

Epoch: [24 | 25] LR: 0.092783
batch Size 256
Epoch: [24][0/197]	Time 0.164 (0.164)	Data 0.322 (0.322)	Loss 0.6992 (0.6992)	Acc@1 85.433 (85.433)	Acc@5 99.606 (99.606)
Epoch: [24][64/197]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.6390 (0.7004)	Acc@1 87.402 (85.300)	Acc@5 99.606 (99.400)
Epoch: [24][128/197]	Time 0.129 (0.129)	Data 0.000 (0.003)	Loss 0.7475 (0.7107)	Acc@1 83.071 (84.835)	Acc@5 100.000 (99.405)
Epoch: [24][192/197]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7444 (0.7114)	Acc@1 83.858 (84.833)	Acc@5 98.031 (99.372)
Max memory in training epoch: 66.3640576
lr: 0.09278294328396441
1

Epoch: [25 | 25] LR: 0.092783
batch Size 256
Epoch: [25][0/197]	Time 0.168 (0.168)	Data 0.261 (0.261)	Loss 0.7907 (0.7907)	Acc@1 83.465 (83.465)	Acc@5 99.213 (99.213)
Epoch: [25][64/197]	Time 0.131 (0.128)	Data 0.000 (0.004)	Loss 0.6828 (0.6940)	Acc@1 86.220 (85.663)	Acc@5 100.000 (99.473)
Epoch: [25][128/197]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.7685 (0.6943)	Acc@1 82.677 (85.613)	Acc@5 99.606 (99.429)
Epoch: [25][192/197]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7495 (0.7055)	Acc@1 83.071 (85.264)	Acc@5 100.000 (99.396)
Max memory in training epoch: 66.3640576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 481038 ; 486232 ; 0.9893178564964873
[INFO] Storing checkpoint...
  78.88
Max memory: 103.3821696
 25.521s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 991
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.2000384
lr: 0.09278294328396441
1

Epoch: [26 | 30] LR: 0.092783
batch Size 256
Epoch: [26][0/196]	Time 0.187 (0.187)	Data 0.265 (0.265)	Loss 0.6335 (0.6335)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.132 (0.134)	Data 0.000 (0.004)	Loss 0.7675 (0.6819)	Acc@1 84.375 (86.304)	Acc@5 100.000 (99.435)
Epoch: [26][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.7023 (0.6969)	Acc@1 83.984 (85.707)	Acc@5 100.000 (99.400)
Epoch: [26][192/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.6741 (0.6993)	Acc@1 87.109 (85.529)	Acc@5 99.219 (99.409)
Max memory in training epoch: 66.6368512
lr: 0.09278294328396441
1

Epoch: [27 | 30] LR: 0.092783
batch Size 256
Epoch: [27][0/196]	Time 0.187 (0.187)	Data 0.271 (0.271)	Loss 0.8496 (0.8496)	Acc@1 78.906 (78.906)	Acc@5 98.828 (98.828)
Epoch: [27][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 0.7062 (0.6990)	Acc@1 86.719 (85.319)	Acc@5 98.828 (99.393)
Epoch: [27][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6424 (0.7043)	Acc@1 88.672 (85.289)	Acc@5 98.828 (99.370)
Epoch: [27][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.8275 (0.6998)	Acc@1 81.250 (85.474)	Acc@5 99.219 (99.383)
Max memory in training epoch: 66.5057792
lr: 0.09278294328396441
1

Epoch: [28 | 30] LR: 0.092783
batch Size 256
Epoch: [28][0/196]	Time 0.169 (0.169)	Data 0.296 (0.296)	Loss 0.6434 (0.6434)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [28][64/196]	Time 0.130 (0.128)	Data 0.000 (0.005)	Loss 0.6976 (0.6844)	Acc@1 86.719 (86.028)	Acc@5 98.828 (99.519)
Epoch: [28][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7053 (0.6867)	Acc@1 83.203 (85.838)	Acc@5 100.000 (99.500)
Epoch: [28][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.7276 (0.6954)	Acc@1 85.938 (85.523)	Acc@5 99.219 (99.431)
Max memory in training epoch: 66.5057792
Drin!!
old memory: 663640576
new memory: 665057792
Faktor: 1.0021355174039268
New batch Size kleiner 256!!
lr: 0.09278294328396441
1

Epoch: [29 | 30] LR: 0.092783
batch Size 256
Epoch: [29][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.6181 (0.6181)	Acc@1 89.453 (89.453)	Acc@5 98.828 (98.828)
Epoch: [29][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6175 (0.6884)	Acc@1 89.453 (85.931)	Acc@5 99.219 (99.357)
Epoch: [29][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.6426 (0.6949)	Acc@1 85.547 (85.647)	Acc@5 99.219 (99.391)
Epoch: [29][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6112 (0.6941)	Acc@1 88.281 (85.757)	Acc@5 100.000 (99.393)
Max memory in training epoch: 66.5057792
lr: 0.09278294328396441
1

Epoch: [30 | 30] LR: 0.092783
batch Size 256
Epoch: [30][0/196]	Time 0.159 (0.159)	Data 0.282 (0.282)	Loss 0.7316 (0.7316)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.7748 (0.6922)	Acc@1 81.250 (85.559)	Acc@5 99.609 (99.369)
Epoch: [30][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.7403 (0.6852)	Acc@1 84.375 (85.856)	Acc@5 99.219 (99.400)
Epoch: [30][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7355 (0.6890)	Acc@1 85.156 (85.796)	Acc@5 98.047 (99.395)
Max memory in training epoch: 66.5057792
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 461992 ; 481038 ; 0.9604064543757458
[INFO] Storing checkpoint...
  83.58
Max memory: 103.3555456
 26.111s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5785
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1924608
lr: 0.09278294328396441
1

Epoch: [31 | 35] LR: 0.092783
batch Size 256
Epoch: [31][0/196]	Time 0.200 (0.200)	Data 0.289 (0.289)	Loss 0.6841 (0.6841)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.6335 (0.6553)	Acc@1 87.500 (86.845)	Acc@5 99.609 (99.495)
Epoch: [31][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7273 (0.6738)	Acc@1 82.031 (86.265)	Acc@5 99.609 (99.437)
Epoch: [31][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6898 (0.6765)	Acc@1 86.719 (86.148)	Acc@5 99.609 (99.427)
Max memory in training epoch: 66.0494848
lr: 0.09278294328396441
1

Epoch: [32 | 35] LR: 0.092783
batch Size 256
Epoch: [32][0/196]	Time 0.200 (0.200)	Data 0.267 (0.267)	Loss 0.7045 (0.7045)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [32][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6552 (0.6671)	Acc@1 87.500 (86.232)	Acc@5 100.000 (99.543)
Epoch: [32][128/196]	Time 0.143 (0.130)	Data 0.000 (0.002)	Loss 0.7305 (0.6753)	Acc@1 85.156 (86.083)	Acc@5 98.828 (99.497)
Epoch: [32][192/196]	Time 0.138 (0.130)	Data 0.000 (0.002)	Loss 0.7581 (0.6827)	Acc@1 81.641 (85.901)	Acc@5 99.219 (99.474)
Max memory in training epoch: 65.9511808
lr: 0.09278294328396441
1

Epoch: [33 | 35] LR: 0.092783
batch Size 256
Epoch: [33][0/196]	Time 0.176 (0.176)	Data 0.328 (0.328)	Loss 0.6947 (0.6947)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.6299 (0.6734)	Acc@1 87.891 (86.226)	Acc@5 99.609 (99.537)
Epoch: [33][128/196]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 0.7004 (0.6812)	Acc@1 86.719 (85.913)	Acc@5 99.219 (99.522)
Epoch: [33][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6391 (0.6890)	Acc@1 88.281 (85.640)	Acc@5 99.219 (99.447)
Max memory in training epoch: 66.0167168
Drin!!
old memory: 665057792
new memory: 660167168
Faktor: 0.9926463172692216
New batch Size größer 259!!
lr: 0.09278294328396441
1

Epoch: [34 | 35] LR: 0.092783
batch Size 259
Epoch: [34][0/196]	Time 0.165 (0.165)	Data 0.304 (0.304)	Loss 0.6298 (0.6298)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [34][64/196]	Time 0.128 (0.134)	Data 0.000 (0.005)	Loss 0.7211 (0.6699)	Acc@1 84.766 (86.526)	Acc@5 99.219 (99.483)
Epoch: [34][128/196]	Time 0.133 (0.133)	Data 0.000 (0.003)	Loss 0.6231 (0.6693)	Acc@1 85.156 (86.531)	Acc@5 99.219 (99.476)
Epoch: [34][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.6590 (0.6764)	Acc@1 85.156 (86.231)	Acc@5 99.219 (99.423)
Max memory in training epoch: 66.0167168
lr: 0.09278294328396441
1

Epoch: [35 | 35] LR: 0.092783
batch Size 259
Epoch: [35][0/196]	Time 0.174 (0.174)	Data 0.314 (0.314)	Loss 0.7262 (0.7262)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [35][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.6841 (0.6903)	Acc@1 87.500 (85.667)	Acc@5 99.219 (99.459)
Epoch: [35][128/196]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.6309 (0.6866)	Acc@1 86.328 (85.832)	Acc@5 100.000 (99.467)
Epoch: [35][192/196]	Time 0.143 (0.130)	Data 0.000 (0.002)	Loss 0.7059 (0.6853)	Acc@1 83.594 (85.867)	Acc@5 99.609 (99.443)
Max memory in training epoch: 66.0167168
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 449002 ; 461992 ; 0.9718826300022512
[INFO] Storing checkpoint...
  78.75
Max memory: 102.6919936
 25.962s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 18
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1874432
lr: 0.09387024340057337
1

Epoch: [36 | 40] LR: 0.093870
batch Size 259
Epoch: [36][0/194]	Time 0.202 (0.202)	Data 0.258 (0.258)	Loss 0.7214 (0.7214)	Acc@1 86.873 (86.873)	Acc@5 99.228 (99.228)
Epoch: [36][64/194]	Time 0.144 (0.131)	Data 0.000 (0.004)	Loss 0.6344 (0.6514)	Acc@1 86.486 (87.259)	Acc@5 99.228 (99.477)
Epoch: [36][128/194]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6797 (0.6654)	Acc@1 86.100 (86.645)	Acc@5 99.228 (99.488)
Epoch: [36][192/194]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6602 (0.6703)	Acc@1 87.259 (86.408)	Acc@5 99.228 (99.466)
Max memory in training epoch: 66.2153728
lr: 0.09387024340057337
1

Epoch: [37 | 40] LR: 0.093870
batch Size 259
Epoch: [37][0/194]	Time 0.199 (0.199)	Data 0.290 (0.290)	Loss 0.6789 (0.6789)	Acc@1 86.486 (86.486)	Acc@5 99.614 (99.614)
Epoch: [37][64/194]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.7711 (0.8330)	Acc@1 84.942 (81.378)	Acc@5 99.614 (98.907)
Epoch: [37][128/194]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7504 (0.7704)	Acc@1 85.714 (83.341)	Acc@5 99.228 (99.177)
Epoch: [37][192/194]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7499 (0.7462)	Acc@1 82.625 (84.132)	Acc@5 99.614 (99.294)
Max memory in training epoch: 66.4338944
lr: 0.09387024340057337
1

Epoch: [38 | 40] LR: 0.093870
batch Size 259
Epoch: [38][0/194]	Time 0.178 (0.178)	Data 0.301 (0.301)	Loss 0.7986 (0.7986)	Acc@1 82.625 (82.625)	Acc@5 99.614 (99.614)
Epoch: [38][64/194]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 0.6425 (0.7388)	Acc@1 87.645 (84.568)	Acc@5 100.000 (99.287)
Epoch: [38][128/194]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.6774 (0.7094)	Acc@1 86.873 (85.478)	Acc@5 99.228 (99.351)
Epoch: [38][192/194]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6707 (0.7004)	Acc@1 86.873 (85.652)	Acc@5 99.228 (99.398)
Max memory in training epoch: 66.4338944
Drin!!
old memory: 660167168
new memory: 664338944
Faktor: 1.0063192721513834
New batch Size kleiner 260!!
lr: 0.09387024340057337
1

Epoch: [39 | 40] LR: 0.093870
batch Size 260
Epoch: [39][0/194]	Time 0.187 (0.187)	Data 0.327 (0.327)	Loss 0.7502 (0.7502)	Acc@1 85.328 (85.328)	Acc@5 100.000 (100.000)
Epoch: [39][64/194]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 0.6424 (0.7031)	Acc@1 87.259 (85.661)	Acc@5 99.614 (99.406)
Epoch: [39][128/194]	Time 0.136 (0.130)	Data 0.000 (0.003)	Loss 0.6614 (0.6966)	Acc@1 86.873 (85.690)	Acc@5 99.614 (99.449)
Epoch: [39][192/194]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.5938 (0.6912)	Acc@1 92.278 (85.890)	Acc@5 99.614 (99.454)
Max memory in training epoch: 66.4338944
lr: 0.09387024340057337
1

Epoch: [40 | 40] LR: 0.093870
batch Size 260
Epoch: [40][0/194]	Time 0.167 (0.167)	Data 0.300 (0.300)	Loss 0.7789 (0.7789)	Acc@1 86.100 (86.100)	Acc@5 99.614 (99.614)
Epoch: [40][64/194]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.7410 (0.8097)	Acc@1 86.486 (82.144)	Acc@5 100.000 (99.121)
Epoch: [40][128/194]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.6874 (0.7533)	Acc@1 86.486 (84.203)	Acc@5 99.228 (99.264)
Epoch: [40][192/194]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6849 (0.7315)	Acc@1 87.259 (84.810)	Acc@5 100.000 (99.332)
Max memory in training epoch: 66.4338944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 436878 ; 449002 ; 0.9729978931051532
[INFO] Storing checkpoint...
  78.73
Max memory: 101.069056
 25.441s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9540
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.182528
lr: 0.09533696595370733
1

Epoch: [41 | 45] LR: 0.095337
batch Size 260
Epoch: [41][0/193]	Time 0.204 (0.204)	Data 0.291 (0.291)	Loss 0.5988 (0.5988)	Acc@1 88.846 (88.846)	Acc@5 99.231 (99.231)
Epoch: [41][64/193]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.6349 (0.6485)	Acc@1 86.154 (87.580)	Acc@5 99.231 (99.396)
Epoch: [41][128/193]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.5864 (0.6549)	Acc@1 88.846 (87.150)	Acc@5 100.000 (99.481)
Epoch: [41][192/193]	Time 0.100 (0.132)	Data 0.000 (0.002)	Loss 0.6267 (0.6621)	Acc@1 85.000 (86.906)	Acc@5 100.000 (99.494)
Max memory in training epoch: 66.1599744
lr: 0.09533696595370733
1

Epoch: [42 | 45] LR: 0.095337
batch Size 260
Epoch: [42][0/193]	Time 0.171 (0.171)	Data 0.312 (0.312)	Loss 0.6301 (0.6301)	Acc@1 87.308 (87.308)	Acc@5 100.000 (100.000)
Epoch: [42][64/193]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.7059 (0.6728)	Acc@1 84.615 (86.189)	Acc@5 98.462 (99.503)
Epoch: [42][128/193]	Time 0.132 (0.130)	Data 0.000 (0.003)	Loss 0.6838 (0.6697)	Acc@1 86.154 (86.360)	Acc@5 100.000 (99.526)
Epoch: [42][192/193]	Time 0.101 (0.130)	Data 0.000 (0.002)	Loss 0.7477 (0.6756)	Acc@1 83.750 (86.244)	Acc@5 98.750 (99.456)
Max memory in training epoch: 66.0627968
lr: 0.09533696595370733
1

Epoch: [43 | 45] LR: 0.095337
batch Size 260
Epoch: [43][0/193]	Time 0.189 (0.189)	Data 0.291 (0.291)	Loss 0.6168 (0.6168)	Acc@1 89.231 (89.231)	Acc@5 99.231 (99.231)
Epoch: [43][64/193]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.6644 (0.6654)	Acc@1 86.923 (86.716)	Acc@5 98.077 (99.414)
Epoch: [43][128/193]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6995 (0.6673)	Acc@1 86.923 (86.583)	Acc@5 99.615 (99.445)
Epoch: [43][192/193]	Time 0.101 (0.130)	Data 0.000 (0.002)	Loss 0.5195 (0.6674)	Acc@1 91.250 (86.592)	Acc@5 100.000 (99.446)
Max memory in training epoch: 66.0627968
Drin!!
old memory: 664338944
new memory: 660627968
Faktor: 0.9944140321239394
New batch Size größer 263!!
lr: 0.09533696595370733
1

Epoch: [44 | 45] LR: 0.095337
batch Size 263
Epoch: [44][0/193]	Time 0.176 (0.176)	Data 0.264 (0.264)	Loss 0.6373 (0.6373)	Acc@1 85.769 (85.769)	Acc@5 100.000 (100.000)
Epoch: [44][64/193]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6807 (0.6509)	Acc@1 83.462 (86.947)	Acc@5 99.615 (99.627)
Epoch: [44][128/193]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6079 (0.6620)	Acc@1 88.077 (86.568)	Acc@5 100.000 (99.472)
Epoch: [44][192/193]	Time 0.099 (0.129)	Data 0.000 (0.002)	Loss 0.8519 (0.6674)	Acc@1 82.500 (86.432)	Acc@5 96.250 (99.462)
Max memory in training epoch: 66.0627968
lr: 0.09533696595370733
1

Epoch: [45 | 45] LR: 0.095337
batch Size 263
Epoch: [45][0/193]	Time 0.181 (0.181)	Data 0.294 (0.294)	Loss 0.6365 (0.6365)	Acc@1 87.308 (87.308)	Acc@5 100.000 (100.000)
Epoch: [45][64/193]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7241 (0.6667)	Acc@1 81.923 (86.544)	Acc@5 99.615 (99.467)
Epoch: [45][128/193]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6367 (0.6670)	Acc@1 88.077 (86.580)	Acc@5 99.231 (99.466)
Epoch: [45][192/193]	Time 0.101 (0.129)	Data 0.000 (0.002)	Loss 0.6301 (0.6680)	Acc@1 88.750 (86.422)	Acc@5 98.750 (99.476)
Max memory in training epoch: 66.0627968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423886 ; 436878 ; 0.9702617206634346
[INFO] Storing checkpoint...
  72.78
Max memory: 100.3072
 25.316s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7876
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.177408
lr: 0.09794383611650402
1

Epoch: [46 | 50] LR: 0.097944
batch Size 263
Epoch: [46][0/191]	Time 0.174 (0.174)	Data 0.312 (0.312)	Loss 0.6052 (0.6052)	Acc@1 90.494 (90.494)	Acc@5 99.620 (99.620)
Epoch: [46][64/191]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.6169 (0.6478)	Acc@1 87.452 (86.815)	Acc@5 100.000 (99.503)
Epoch: [46][128/191]	Time 0.144 (0.128)	Data 0.000 (0.003)	Loss 0.6793 (0.6621)	Acc@1 86.312 (86.400)	Acc@5 99.240 (99.464)
Max memory in training epoch: 66.2083072
lr: 0.09794383611650402
1

Epoch: [47 | 50] LR: 0.097944
batch Size 263
Epoch: [47][0/191]	Time 0.174 (0.174)	Data 0.293 (0.293)	Loss 0.6257 (0.6257)	Acc@1 90.114 (90.114)	Acc@5 100.000 (100.000)
Epoch: [47][64/191]	Time 0.121 (0.129)	Data 0.000 (0.005)	Loss 0.6423 (0.6981)	Acc@1 87.072 (85.288)	Acc@5 99.620 (99.386)
Epoch: [47][128/191]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6877 (0.6812)	Acc@1 84.791 (85.979)	Acc@5 100.000 (99.402)
Max memory in training epoch: 66.2227968
lr: 0.09794383611650402
1

Epoch: [48 | 50] LR: 0.097944
batch Size 263
Epoch: [48][0/191]	Time 0.170 (0.170)	Data 0.312 (0.312)	Loss 0.7234 (0.7234)	Acc@1 83.270 (83.270)	Acc@5 100.000 (100.000)
Epoch: [48][64/191]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.7137 (0.7326)	Acc@1 82.890 (84.610)	Acc@5 99.620 (99.304)
Epoch: [48][128/191]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.7188 (0.6952)	Acc@1 83.270 (85.710)	Acc@5 99.240 (99.422)
Max memory in training epoch: 66.2227968
Drin!!
old memory: 660627968
new memory: 662227968
Faktor: 1.0024219380309372
New batch Size kleiner 263!!
lr: 0.09794383611650402
1

Epoch: [49 | 50] LR: 0.097944
batch Size 263
Epoch: [49][0/191]	Time 0.178 (0.178)	Data 0.294 (0.294)	Loss 0.5553 (0.5553)	Acc@1 90.494 (90.494)	Acc@5 100.000 (100.000)
Epoch: [49][64/191]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.6899 (0.7072)	Acc@1 85.551 (85.282)	Acc@5 99.240 (99.292)
Epoch: [49][128/191]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6118 (0.6785)	Acc@1 89.354 (86.288)	Acc@5 99.620 (99.440)
Max memory in training epoch: 66.2227968
lr: 0.09794383611650402
1

Epoch: [50 | 50] LR: 0.097944
batch Size 263
Epoch: [50][0/191]	Time 0.173 (0.173)	Data 0.278 (0.278)	Loss 0.7402 (0.7402)	Acc@1 83.650 (83.650)	Acc@5 98.859 (98.859)
Epoch: [50][64/191]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.6249 (0.6878)	Acc@1 87.452 (86.119)	Acc@5 98.859 (99.392)
Epoch: [50][128/191]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6872 (0.6791)	Acc@1 86.692 (86.179)	Acc@5 100.000 (99.440)
Max memory in training epoch: 66.2227968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 410896 ; 423886 ; 0.9693549680810406
[INFO] Storing checkpoint...
  71.3
Max memory: 99.187968
 25.163s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 616
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.172288
lr: 0.10062198788531468
1

Epoch: [51 | 55] LR: 0.100622
batch Size 263
Epoch: [51][0/191]	Time 0.188 (0.188)	Data 0.288 (0.288)	Loss 0.7442 (0.7442)	Acc@1 84.411 (84.411)	Acc@5 99.620 (99.620)
Epoch: [51][64/191]	Time 0.131 (0.134)	Data 0.000 (0.005)	Loss 0.6842 (0.6418)	Acc@1 86.692 (87.353)	Acc@5 99.620 (99.485)
Epoch: [51][128/191]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6993 (0.6560)	Acc@1 86.692 (86.987)	Acc@5 98.859 (99.449)
Max memory in training epoch: 65.6796672
lr: 0.10062198788531468
1

Epoch: [52 | 55] LR: 0.100622
batch Size 263
Epoch: [52][0/191]	Time 0.150 (0.150)	Data 0.328 (0.328)	Loss 0.6292 (0.6292)	Acc@1 88.973 (88.973)	Acc@5 100.000 (100.000)
Epoch: [52][64/191]	Time 0.133 (0.128)	Data 0.000 (0.005)	Loss 0.6402 (0.6856)	Acc@1 86.312 (85.984)	Acc@5 98.479 (99.415)
Epoch: [52][128/191]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.6309 (0.6804)	Acc@1 88.593 (86.100)	Acc@5 98.859 (99.428)
Max memory in training epoch: 65.7026048
lr: 0.10062198788531468
1

Epoch: [53 | 55] LR: 0.100622
batch Size 263
Epoch: [53][0/191]	Time 0.185 (0.185)	Data 0.295 (0.295)	Loss 0.6919 (0.6919)	Acc@1 87.072 (87.072)	Acc@5 99.620 (99.620)
Epoch: [53][64/191]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.7176 (0.6806)	Acc@1 82.890 (86.013)	Acc@5 99.240 (99.456)
Epoch: [53][128/191]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.6561 (0.6687)	Acc@1 89.734 (86.556)	Acc@5 99.240 (99.449)
Max memory in training epoch: 65.7026048
Drin!!
old memory: 662227968
new memory: 657026048
Faktor: 0.9921448198334022
New batch Size größer 268!!
lr: 0.10062198788531468
1

Epoch: [54 | 55] LR: 0.100622
batch Size 268
Epoch: [54][0/191]	Time 0.161 (0.161)	Data 0.282 (0.282)	Loss 0.6733 (0.6733)	Acc@1 84.030 (84.030)	Acc@5 100.000 (100.000)
Epoch: [54][64/191]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.6308 (0.6693)	Acc@1 87.072 (86.499)	Acc@5 100.000 (99.538)
Epoch: [54][128/191]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6781 (0.6690)	Acc@1 86.312 (86.512)	Acc@5 99.620 (99.534)
Max memory in training epoch: 65.7026048
lr: 0.10062198788531468
1

Epoch: [55 | 55] LR: 0.100622
batch Size 268
Epoch: [55][0/191]	Time 0.185 (0.185)	Data 0.305 (0.305)	Loss 0.7293 (0.7293)	Acc@1 85.171 (85.171)	Acc@5 99.240 (99.240)
Epoch: [55][64/191]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 0.5793 (0.6540)	Acc@1 90.114 (86.756)	Acc@5 99.240 (99.538)
Epoch: [55][128/191]	Time 0.126 (0.131)	Data 0.000 (0.003)	Loss 0.5892 (0.6519)	Acc@1 87.833 (87.016)	Acc@5 100.000 (99.505)
Max memory in training epoch: 65.7026048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 405696 ; 410896 ; 0.9873447295666057
[INFO] Storing checkpoint...
  81.66
Max memory: 98.2010368
 25.248s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2726
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.17024
lr: 0.1053386435674388
1

Epoch: [56 | 60] LR: 0.105339
batch Size 268
Epoch: [56][0/187]	Time 0.209 (0.209)	Data 0.292 (0.292)	Loss 0.6993 (0.6993)	Acc@1 84.328 (84.328)	Acc@5 99.627 (99.627)
Epoch: [56][64/187]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.6817 (0.6393)	Acc@1 88.806 (87.468)	Acc@5 98.881 (99.558)
Epoch: [56][128/187]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6768 (0.6498)	Acc@1 86.194 (87.059)	Acc@5 100.000 (99.537)
Max memory in training epoch: 66.3872
lr: 0.1053386435674388
1

Epoch: [57 | 60] LR: 0.105339
batch Size 268
Epoch: [57][0/187]	Time 0.201 (0.201)	Data 0.263 (0.263)	Loss 0.6385 (0.6385)	Acc@1 86.567 (86.567)	Acc@5 99.627 (99.627)
Epoch: [57][64/187]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.6197 (0.6376)	Acc@1 89.552 (87.342)	Acc@5 99.627 (99.552)
Epoch: [57][128/187]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6989 (0.6595)	Acc@1 85.075 (86.567)	Acc@5 99.254 (99.474)
Max memory in training epoch: 66.2401536
lr: 0.1053386435674388
1

Epoch: [58 | 60] LR: 0.105339
batch Size 268
Epoch: [58][0/187]	Time 0.191 (0.191)	Data 0.279 (0.279)	Loss 0.6590 (0.6590)	Acc@1 89.179 (89.179)	Acc@5 99.627 (99.627)
Epoch: [58][64/187]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6849 (0.6535)	Acc@1 84.701 (87.061)	Acc@5 98.881 (99.397)
Epoch: [58][128/187]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7817 (0.6633)	Acc@1 81.716 (86.642)	Acc@5 98.881 (99.445)
Max memory in training epoch: 66.1600768
Drin!!
old memory: 657026048
new memory: 661600768
Faktor: 1.0069627680880013
New batch Size kleiner 269!!
lr: 0.1053386435674388
1

Epoch: [59 | 60] LR: 0.105339
batch Size 269
Epoch: [59][0/187]	Time 0.193 (0.193)	Data 0.291 (0.291)	Loss 0.7256 (0.7256)	Acc@1 83.209 (83.209)	Acc@5 99.627 (99.627)
Epoch: [59][64/187]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6512 (0.6490)	Acc@1 86.567 (87.113)	Acc@5 99.254 (99.518)
Epoch: [59][128/187]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.5811 (0.6573)	Acc@1 89.925 (87.062)	Acc@5 99.627 (99.508)
Max memory in training epoch: 66.1600768
lr: 0.1053386435674388
1

Epoch: [60 | 60] LR: 0.105339
batch Size 269
Epoch: [60][0/187]	Time 0.198 (0.198)	Data 0.265 (0.265)	Loss 0.6061 (0.6061)	Acc@1 87.687 (87.687)	Acc@5 100.000 (100.000)
Epoch: [60][64/187]	Time 0.145 (0.132)	Data 0.000 (0.004)	Loss 0.6272 (0.6540)	Acc@1 88.433 (86.825)	Acc@5 99.627 (99.512)
Epoch: [60][128/187]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7137 (0.6575)	Acc@1 83.582 (86.611)	Acc@5 98.507 (99.523)
Max memory in training epoch: 66.1600768
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 398480 ; 405696 ; 0.9822132828521849
[INFO] Storing checkpoint...
  82.69
Max memory: 97.697024
 24.668s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9647
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1672704
lr: 0.1106878715610978
1

Epoch: [61 | 65] LR: 0.110688
batch Size 269
Epoch: [61][0/186]	Time 0.215 (0.215)	Data 0.266 (0.266)	Loss 0.6309 (0.6309)	Acc@1 88.476 (88.476)	Acc@5 99.257 (99.257)
Epoch: [61][64/186]	Time 0.133 (0.136)	Data 0.000 (0.004)	Loss 0.6352 (0.6397)	Acc@1 86.245 (87.355)	Acc@5 100.000 (99.600)
Epoch: [61][128/186]	Time 0.134 (0.135)	Data 0.000 (0.002)	Loss 0.6680 (0.6587)	Acc@1 88.104 (86.735)	Acc@5 99.257 (99.444)
Max memory in training epoch: 65.9713536
lr: 0.1106878715610978
1

Epoch: [62 | 65] LR: 0.110688
batch Size 269
Epoch: [62][0/186]	Time 0.167 (0.167)	Data 0.268 (0.268)	Loss 0.6437 (0.6437)	Acc@1 88.848 (88.848)	Acc@5 98.885 (98.885)
Epoch: [62][64/186]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.6490 (0.6619)	Acc@1 87.732 (86.772)	Acc@5 100.000 (99.520)
Epoch: [62][128/186]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6660 (0.6704)	Acc@1 84.387 (86.565)	Acc@5 99.628 (99.481)
Max memory in training epoch: 65.9168768
lr: 0.1106878715610978
1

Epoch: [63 | 65] LR: 0.110688
batch Size 269
Epoch: [63][0/186]	Time 0.192 (0.192)	Data 0.266 (0.266)	Loss 0.6253 (0.6253)	Acc@1 86.989 (86.989)	Acc@5 100.000 (100.000)
Epoch: [63][64/186]	Time 0.126 (0.132)	Data 0.000 (0.004)	Loss 0.6990 (0.6652)	Acc@1 87.732 (86.760)	Acc@5 98.885 (99.502)
Epoch: [63][128/186]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7361 (0.6790)	Acc@1 84.015 (86.234)	Acc@5 98.885 (99.458)
Max memory in training epoch: 65.9168768
Drin!!
old memory: 661600768
new memory: 659168768
Faktor: 0.9963240671449765
New batch Size größer 273!!
lr: 0.1106878715610978
1

Epoch: [64 | 65] LR: 0.110688
batch Size 273
Epoch: [64][0/186]	Time 0.196 (0.196)	Data 0.298 (0.298)	Loss 0.6445 (0.6445)	Acc@1 88.848 (88.848)	Acc@5 99.628 (99.628)
Epoch: [64][64/186]	Time 0.127 (0.134)	Data 0.000 (0.005)	Loss 0.6438 (0.6557)	Acc@1 89.591 (87.149)	Acc@5 98.885 (99.525)
Epoch: [64][128/186]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.5983 (0.6622)	Acc@1 90.335 (86.974)	Acc@5 99.628 (99.478)
Max memory in training epoch: 65.9168768
lr: 0.1106878715610978
1

Epoch: [65 | 65] LR: 0.110688
batch Size 273
Epoch: [65][0/186]	Time 0.182 (0.182)	Data 0.338 (0.338)	Loss 0.6923 (0.6923)	Acc@1 84.758 (84.758)	Acc@5 98.885 (98.885)
Epoch: [65][64/186]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7949 (0.6642)	Acc@1 82.900 (86.663)	Acc@5 99.628 (99.531)
Epoch: [65][128/186]	Time 0.137 (0.133)	Data 0.000 (0.003)	Loss 0.5863 (0.6640)	Acc@1 89.591 (86.738)	Acc@5 100.000 (99.484)
Max memory in training epoch: 65.9168768
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 397902 ; 398480 ; 0.9985494880546075
[INFO] Storing checkpoint...
  75.8
Max memory: 97.4595584
 25.316s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1737
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1670656
lr: 0.11803823803195194
1

Epoch: [66 | 70] LR: 0.118038
batch Size 273
Epoch: [66][0/184]	Time 0.229 (0.229)	Data 0.351 (0.351)	Loss 0.6368 (0.6368)	Acc@1 89.377 (89.377)	Acc@5 99.634 (99.634)
Epoch: [66][64/184]	Time 0.143 (0.132)	Data 0.000 (0.006)	Loss 0.7042 (0.6470)	Acc@1 86.081 (87.320)	Acc@5 100.000 (99.544)
Epoch: [66][128/184]	Time 0.164 (0.131)	Data 0.000 (0.003)	Loss 0.7352 (0.6624)	Acc@1 84.249 (86.893)	Acc@5 99.634 (99.492)
Max memory in training epoch: 68.3074048
lr: 0.11803823803195194
1

Epoch: [67 | 70] LR: 0.118038
batch Size 273
Epoch: [67][0/184]	Time 0.168 (0.168)	Data 0.298 (0.298)	Loss 0.7562 (0.7562)	Acc@1 80.952 (80.952)	Acc@5 100.000 (100.000)
Epoch: [67][64/184]	Time 0.137 (0.134)	Data 0.000 (0.005)	Loss 0.7721 (0.7021)	Acc@1 81.685 (85.472)	Acc@5 99.267 (99.369)
Epoch: [67][128/184]	Time 0.149 (0.134)	Data 0.000 (0.002)	Loss 0.7266 (0.6918)	Acc@1 87.546 (85.961)	Acc@5 99.634 (99.432)
Max memory in training epoch: 68.3782656
lr: 0.11803823803195194
1

Epoch: [68 | 70] LR: 0.118038
batch Size 273
Epoch: [68][0/184]	Time 0.175 (0.175)	Data 0.304 (0.304)	Loss 0.6558 (0.6558)	Acc@1 88.278 (88.278)	Acc@5 99.634 (99.634)
Epoch: [68][64/184]	Time 0.137 (0.136)	Data 0.000 (0.005)	Loss 0.6258 (0.6951)	Acc@1 89.011 (85.624)	Acc@5 100.000 (99.414)
Epoch: [68][128/184]	Time 0.134 (0.135)	Data 0.000 (0.003)	Loss 0.5834 (0.6837)	Acc@1 89.744 (86.047)	Acc@5 100.000 (99.429)
Max memory in training epoch: 68.3782656
Drin!!
old memory: 659168768
new memory: 683782656
Faktor: 1.0373407982824818
New batch Size kleiner 283!!
lr: 0.11803823803195194
1

Epoch: [69 | 70] LR: 0.118038
batch Size 283
Epoch: [69][0/184]	Time 0.170 (0.170)	Data 0.311 (0.311)	Loss 0.6720 (0.6720)	Acc@1 87.179 (87.179)	Acc@5 98.901 (98.901)
Epoch: [69][64/184]	Time 0.145 (0.133)	Data 0.000 (0.005)	Loss 0.6395 (0.6660)	Acc@1 86.813 (86.734)	Acc@5 99.634 (99.510)
Epoch: [69][128/184]	Time 0.126 (0.133)	Data 0.000 (0.003)	Loss 0.5719 (0.6667)	Acc@1 89.377 (86.685)	Acc@5 99.267 (99.475)
Max memory in training epoch: 68.3782656
lr: 0.11803823803195194
1

Epoch: [70 | 70] LR: 0.118038
batch Size 283
Epoch: [70][0/184]	Time 0.176 (0.176)	Data 0.313 (0.313)	Loss 0.6848 (0.6848)	Acc@1 86.081 (86.081)	Acc@5 99.267 (99.267)
Epoch: [70][64/184]	Time 0.137 (0.136)	Data 0.000 (0.005)	Loss 0.6386 (0.6867)	Acc@1 88.278 (86.081)	Acc@5 99.634 (99.403)
Epoch: [70][128/184]	Time 0.127 (0.134)	Data 0.000 (0.003)	Loss 0.6411 (0.6794)	Acc@1 88.645 (86.274)	Acc@5 98.901 (99.404)
Max memory in training epoch: 68.3782656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 395238 ; 397902 ; 0.9933048841171946
[INFO] Storing checkpoint...
  66.76
Max memory: 97.0649088
 24.900s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5814
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1654272
lr: 0.13048758344938438
1

Epoch: [71 | 75] LR: 0.130488
batch Size 283
Epoch: [71][0/177]	Time 0.218 (0.218)	Data 0.290 (0.290)	Loss 0.7074 (0.7074)	Acc@1 86.219 (86.219)	Acc@5 98.940 (98.940)
Epoch: [71][64/177]	Time 0.126 (0.126)	Data 0.000 (0.005)	Loss 0.6962 (0.6551)	Acc@1 85.159 (86.899)	Acc@5 99.293 (99.397)
Epoch: [71][128/177]	Time 0.118 (0.126)	Data 0.000 (0.002)	Loss 0.7492 (0.6709)	Acc@1 83.746 (86.498)	Acc@5 98.940 (99.417)
Max memory in training epoch: 67.5245568
lr: 0.13048758344938438
1

Epoch: [72 | 75] LR: 0.130488
batch Size 283
Epoch: [72][0/177]	Time 0.189 (0.189)	Data 0.280 (0.280)	Loss 0.6771 (0.6771)	Acc@1 85.866 (85.866)	Acc@5 99.293 (99.293)
Epoch: [72][64/177]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.6401 (0.6746)	Acc@1 86.926 (86.649)	Acc@5 100.000 (99.511)
Epoch: [72][128/177]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6401 (0.6832)	Acc@1 88.339 (86.216)	Acc@5 99.293 (99.491)
Max memory in training epoch: 68.2766848
lr: 0.13048758344938438
1

Epoch: [73 | 75] LR: 0.130488
batch Size 283
Epoch: [73][0/177]	Time 0.174 (0.174)	Data 0.295 (0.295)	Loss 0.6449 (0.6449)	Acc@1 87.986 (87.986)	Acc@5 100.000 (100.000)
Epoch: [73][64/177]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.6834 (0.6773)	Acc@1 84.806 (86.447)	Acc@5 99.647 (99.440)
Epoch: [73][128/177]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7189 (0.6874)	Acc@1 85.159 (86.167)	Acc@5 99.647 (99.463)
Max memory in training epoch: 68.2766848
Drin!!
old memory: 683782656
new memory: 682766848
Faktor: 0.9985144285379476
New batch Size größer 277!!
lr: 0.13048758344938438
1

Epoch: [74 | 75] LR: 0.130488
batch Size 277
Epoch: [74][0/177]	Time 0.158 (0.158)	Data 0.308 (0.308)	Loss 0.6833 (0.6833)	Acc@1 86.219 (86.219)	Acc@5 100.000 (100.000)
Epoch: [74][64/177]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.5928 (0.6852)	Acc@1 89.399 (86.056)	Acc@5 99.647 (99.451)
Epoch: [74][128/177]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.6320 (0.6841)	Acc@1 87.279 (86.052)	Acc@5 99.293 (99.417)
Max memory in training epoch: 68.2766848
lr: 0.13048758344938438
1

Epoch: [75 | 75] LR: 0.130488
batch Size 277
Epoch: [75][0/177]	Time 0.176 (0.176)	Data 0.280 (0.280)	Loss 0.6470 (0.6470)	Acc@1 88.339 (88.339)	Acc@5 98.940 (98.940)
Epoch: [75][64/177]	Time 0.139 (0.128)	Data 0.000 (0.005)	Loss 0.6503 (0.6761)	Acc@1 87.633 (86.279)	Acc@5 99.293 (99.435)
Epoch: [75][128/177]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.5544 (0.6792)	Acc@1 90.459 (86.194)	Acc@5 100.000 (99.471)
Max memory in training epoch: 68.2766848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 390908 ; 395238 ; 0.9890445756733918
[INFO] Storing checkpoint...
  77.13
Max memory: 94.2480896
 22.789s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5062
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1636864
lr: 0.1411916430292167
1

Epoch: [76 | 80] LR: 0.141192
batch Size 277
Epoch: [76][0/181]	Time 0.205 (0.205)	Data 0.296 (0.296)	Loss 0.6054 (0.6054)	Acc@1 89.170 (89.170)	Acc@5 100.000 (100.000)
Epoch: [76][64/181]	Time 0.140 (0.129)	Data 0.000 (0.005)	Loss 0.6838 (0.6601)	Acc@1 85.560 (86.726)	Acc@5 100.000 (99.572)
Epoch: [76][128/181]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.8100 (0.6859)	Acc@1 80.505 (85.935)	Acc@5 99.639 (99.479)
Max memory in training epoch: 66.2450688
lr: 0.1411916430292167
1

Epoch: [77 | 80] LR: 0.141192
batch Size 277
Epoch: [77][0/181]	Time 0.169 (0.169)	Data 0.314 (0.314)	Loss 0.7560 (0.7560)	Acc@1 85.921 (85.921)	Acc@5 99.639 (99.639)
Epoch: [77][64/181]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6292 (0.6954)	Acc@1 86.643 (86.071)	Acc@5 100.000 (99.450)
Epoch: [77][128/181]	Time 0.128 (0.127)	Data 0.000 (0.003)	Loss 0.7630 (0.7081)	Acc@1 84.838 (85.585)	Acc@5 99.278 (99.370)
Max memory in training epoch: 66.4695296
lr: 0.1411916430292167
1

Epoch: [78 | 80] LR: 0.141192
batch Size 277
Epoch: [78][0/181]	Time 0.159 (0.159)	Data 0.318 (0.318)	Loss 0.7257 (0.7257)	Acc@1 85.921 (85.921)	Acc@5 99.278 (99.278)
Epoch: [78][64/181]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6954 (0.6770)	Acc@1 86.282 (86.687)	Acc@5 99.639 (99.489)
Epoch: [78][128/181]	Time 0.119 (0.127)	Data 0.000 (0.003)	Loss 0.6730 (0.6955)	Acc@1 86.282 (86.002)	Acc@5 100.000 (99.412)
Max memory in training epoch: 66.4695296
Drin!!
old memory: 682766848
new memory: 664695296
Faktor: 0.9735318841959942
New batch Size größer 279!!
lr: 0.1411916430292167
1

Epoch: [79 | 80] LR: 0.141192
batch Size 279
Epoch: [79][0/181]	Time 0.163 (0.163)	Data 0.306 (0.306)	Loss 0.7085 (0.7085)	Acc@1 84.477 (84.477)	Acc@5 100.000 (100.000)
Epoch: [79][64/181]	Time 0.129 (0.125)	Data 0.000 (0.005)	Loss 0.8439 (0.7052)	Acc@1 81.588 (85.676)	Acc@5 99.639 (99.456)
Epoch: [79][128/181]	Time 0.119 (0.126)	Data 0.000 (0.003)	Loss 0.7317 (0.7047)	Acc@1 81.949 (85.602)	Acc@5 99.639 (99.418)
Max memory in training epoch: 66.4695296
lr: 0.1411916430292167
1

Epoch: [80 | 80] LR: 0.141192
batch Size 279
Epoch: [80][0/181]	Time 0.188 (0.188)	Data 0.275 (0.275)	Loss 0.7290 (0.7290)	Acc@1 84.838 (84.838)	Acc@5 99.639 (99.639)
Epoch: [80][64/181]	Time 0.129 (0.126)	Data 0.000 (0.004)	Loss 0.6700 (0.6847)	Acc@1 87.365 (86.270)	Acc@5 99.639 (99.411)
Epoch: [80][128/181]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.7760 (0.6956)	Acc@1 82.310 (85.856)	Acc@5 99.278 (99.384)
Max memory in training epoch: 66.4695296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 384558 ; 390908 ; 0.9837557686207496
[INFO] Storing checkpoint...
  78.48
Max memory: 93.4967808
 23.159s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1749
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1611264
lr: 0.15387682970762287
1

Epoch: [81 | 85] LR: 0.153877
batch Size 279
Epoch: [81][0/180]	Time 0.185 (0.185)	Data 0.261 (0.261)	Loss 0.7190 (0.7190)	Acc@1 86.022 (86.022)	Acc@5 98.925 (98.925)
Epoch: [81][64/180]	Time 0.123 (0.126)	Data 0.000 (0.004)	Loss 0.8179 (0.6950)	Acc@1 83.513 (86.016)	Acc@5 99.642 (99.344)
Epoch: [81][128/180]	Time 0.133 (0.125)	Data 0.000 (0.002)	Loss 0.7576 (0.7148)	Acc@1 85.305 (85.369)	Acc@5 99.283 (99.339)
Max memory in training epoch: 66.2928896
lr: 0.15387682970762287
1

Epoch: [82 | 85] LR: 0.153877
batch Size 279
Epoch: [82][0/180]	Time 0.179 (0.179)	Data 0.281 (0.281)	Loss 0.6744 (0.6744)	Acc@1 86.738 (86.738)	Acc@5 99.642 (99.642)
Epoch: [82][64/180]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.7393 (0.7288)	Acc@1 84.229 (84.913)	Acc@5 98.925 (99.349)
Epoch: [82][128/180]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7393 (0.7265)	Acc@1 83.871 (84.916)	Acc@5 99.642 (99.305)
Max memory in training epoch: 67.1549952
lr: 0.15387682970762287
1

Epoch: [83 | 85] LR: 0.153877
batch Size 279
Epoch: [83][0/180]	Time 0.170 (0.170)	Data 0.297 (0.297)	Loss 0.7436 (0.7436)	Acc@1 83.513 (83.513)	Acc@5 99.642 (99.642)
Epoch: [83][64/180]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.6817 (0.7180)	Acc@1 86.022 (85.404)	Acc@5 99.642 (99.311)
Epoch: [83][128/180]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.7440 (0.7085)	Acc@1 84.588 (85.519)	Acc@5 98.925 (99.364)
Max memory in training epoch: 67.1549952
Drin!!
old memory: 664695296
new memory: 671549952
Faktor: 1.01031247857665
New batch Size kleiner 281!!
lr: 0.15387682970762287
1

Epoch: [84 | 85] LR: 0.153877
batch Size 281
Epoch: [84][0/180]	Time 0.182 (0.182)	Data 0.279 (0.279)	Loss 0.6631 (0.6631)	Acc@1 88.172 (88.172)	Acc@5 100.000 (100.000)
Epoch: [84][64/180]	Time 0.132 (0.127)	Data 0.000 (0.004)	Loss 0.7720 (0.7413)	Acc@1 82.437 (84.191)	Acc@5 99.642 (99.349)
Epoch: [84][128/180]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6693 (0.7251)	Acc@1 87.814 (84.824)	Acc@5 99.283 (99.372)
Max memory in training epoch: 67.1549952
lr: 0.15387682970762287
1

Epoch: [85 | 85] LR: 0.153877
batch Size 281
Epoch: [85][0/180]	Time 0.167 (0.167)	Data 0.283 (0.283)	Loss 0.7383 (0.7383)	Acc@1 82.796 (82.796)	Acc@5 97.849 (97.849)
Epoch: [85][64/180]	Time 0.133 (0.126)	Data 0.000 (0.005)	Loss 0.6688 (0.7243)	Acc@1 85.663 (84.720)	Acc@5 99.642 (99.344)
Epoch: [85][128/180]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6985 (0.7284)	Acc@1 86.380 (84.902)	Acc@5 99.283 (99.319)
Max memory in training epoch: 67.1549952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 382100 ; 384558 ; 0.9936082463503555
[INFO] Storing checkpoint...
  72.34
Max memory: 93.2345344
 22.979s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8541
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.160256
lr: 0.1689038638587579
1

Epoch: [86 | 90] LR: 0.168904
batch Size 281
Epoch: [86][0/178]	Time 0.210 (0.210)	Data 0.263 (0.263)	Loss 0.7010 (0.7010)	Acc@1 85.409 (85.409)	Acc@5 99.288 (99.288)
Epoch: [86][64/178]	Time 0.152 (0.128)	Data 0.000 (0.004)	Loss 0.7335 (0.6997)	Acc@1 85.053 (85.853)	Acc@5 100.000 (99.480)
Epoch: [86][128/178]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.8494 (0.7176)	Acc@1 78.648 (85.285)	Acc@5 98.577 (99.371)
Max memory in training epoch: 66.096384
lr: 0.1689038638587579
1

Epoch: [87 | 90] LR: 0.168904
batch Size 281
Epoch: [87][0/178]	Time 0.182 (0.182)	Data 0.308 (0.308)	Loss 0.7889 (0.7889)	Acc@1 81.139 (81.139)	Acc@5 99.288 (99.288)
Epoch: [87][64/178]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.7650 (0.7283)	Acc@1 83.630 (85.026)	Acc@5 100.000 (99.343)
Epoch: [87][128/178]	Time 0.121 (0.128)	Data 0.000 (0.003)	Loss 0.7784 (0.7227)	Acc@1 83.630 (85.078)	Acc@5 98.932 (99.371)
Max memory in training epoch: 66.7749888
lr: 0.1689038638587579
1

Epoch: [88 | 90] LR: 0.168904
batch Size 281
Epoch: [88][0/178]	Time 0.146 (0.146)	Data 0.302 (0.302)	Loss 0.6859 (0.6859)	Acc@1 86.833 (86.833)	Acc@5 100.000 (100.000)
Epoch: [88][64/178]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.6626 (0.7171)	Acc@1 86.833 (85.261)	Acc@5 99.644 (99.376)
Epoch: [88][128/178]	Time 0.130 (0.126)	Data 0.000 (0.003)	Loss 0.6676 (0.7322)	Acc@1 88.968 (84.835)	Acc@5 100.000 (99.382)
Max memory in training epoch: 66.7749888
Drin!!
old memory: 671549952
new memory: 667749888
Faktor: 0.9943413531805301
New batch Size größer 281!!
lr: 0.1689038638587579
1

Epoch: [89 | 90] LR: 0.168904
batch Size 281
Epoch: [89][0/178]	Time 0.184 (0.184)	Data 0.267 (0.267)	Loss 0.6590 (0.6590)	Acc@1 86.833 (86.833)	Acc@5 99.644 (99.644)
Epoch: [89][64/178]	Time 0.123 (0.126)	Data 0.000 (0.004)	Loss 0.7180 (0.7140)	Acc@1 85.053 (85.349)	Acc@5 100.000 (99.387)
Epoch: [89][128/178]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7972 (0.7180)	Acc@1 82.918 (85.293)	Acc@5 99.644 (99.412)
Max memory in training epoch: 66.7749888
lr: 0.1689038638587579
1

Epoch: [90 | 90] LR: 0.168904
batch Size 281
Epoch: [90][0/178]	Time 0.170 (0.170)	Data 0.305 (0.305)	Loss 0.7504 (0.7504)	Acc@1 84.698 (84.698)	Acc@5 99.288 (99.288)
Epoch: [90][64/178]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.7329 (0.7224)	Acc@1 84.342 (84.895)	Acc@5 99.644 (99.348)
Epoch: [90][128/178]	Time 0.120 (0.125)	Data 0.000 (0.003)	Loss 0.7028 (0.7320)	Acc@1 84.698 (84.766)	Acc@5 99.644 (99.283)
Max memory in training epoch: 66.7749888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 376028 ; 382100 ; 0.9841088720230307
[INFO] Storing checkpoint...
  69.69
Max memory: 93.1774464
 22.711s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8067
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1577984
lr: 0.18539838181371474
1

Epoch: [91 | 95] LR: 0.185398
batch Size 281
Epoch: [91][0/178]	Time 0.202 (0.202)	Data 0.267 (0.267)	Loss 0.6629 (0.6629)	Acc@1 87.544 (87.544)	Acc@5 99.288 (99.288)
Epoch: [91][64/178]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.7036 (0.7205)	Acc@1 86.477 (85.092)	Acc@5 99.288 (99.212)
Epoch: [91][128/178]	Time 0.144 (0.127)	Data 0.000 (0.002)	Loss 0.7244 (0.7332)	Acc@1 85.053 (84.783)	Acc@5 99.288 (99.217)
Max memory in training epoch: 64.8748032
lr: 0.18539838181371474
1

Epoch: [92 | 95] LR: 0.185398
batch Size 281
Epoch: [92][0/178]	Time 0.165 (0.165)	Data 0.273 (0.273)	Loss 0.6703 (0.6703)	Acc@1 85.053 (85.053)	Acc@5 100.000 (100.000)
Epoch: [92][64/178]	Time 0.127 (0.124)	Data 0.000 (0.004)	Loss 0.7963 (0.7425)	Acc@1 83.630 (84.243)	Acc@5 99.288 (99.294)
Epoch: [92][128/178]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.8544 (0.7607)	Acc@1 81.139 (83.746)	Acc@5 99.644 (99.261)
Max memory in training epoch: 65.52192
lr: 0.18539838181371474
1

Epoch: [93 | 95] LR: 0.018540
batch Size 281
Epoch: [93][0/178]	Time 0.148 (0.148)	Data 0.276 (0.276)	Loss 0.7424 (0.7424)	Acc@1 85.765 (85.765)	Acc@5 99.288 (99.288)
Epoch: [93][64/178]	Time 0.115 (0.124)	Data 0.000 (0.004)	Loss 0.5595 (0.6344)	Acc@1 91.459 (88.557)	Acc@5 99.644 (99.617)
Epoch: [93][128/178]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.5761 (0.6027)	Acc@1 90.391 (89.459)	Acc@5 100.000 (99.647)
Max memory in training epoch: 65.52192
Drin!!
old memory: 667749888
new memory: 655219200
Faktor: 0.981234458851755
New batch Size größer 287!!
lr: 0.018539838181371473
1

Epoch: [94 | 95] LR: 0.018540
batch Size 287
Epoch: [94][0/178]	Time 0.175 (0.175)	Data 0.276 (0.276)	Loss 0.6234 (0.6234)	Acc@1 87.900 (87.900)	Acc@5 99.644 (99.644)
Epoch: [94][64/178]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.4563 (0.5202)	Acc@1 94.306 (91.996)	Acc@5 100.000 (99.759)
Epoch: [94][128/178]	Time 0.136 (0.124)	Data 0.000 (0.002)	Loss 0.5172 (0.5196)	Acc@1 91.815 (91.994)	Acc@5 99.644 (99.768)
Max memory in training epoch: 65.52192
lr: 0.018539838181371473
1

Epoch: [95 | 95] LR: 0.018540
batch Size 287
Epoch: [95][0/178]	Time 0.157 (0.157)	Data 0.311 (0.311)	Loss 0.5129 (0.5129)	Acc@1 91.815 (91.815)	Acc@5 100.000 (100.000)
Epoch: [95][64/178]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.5005 (0.4925)	Acc@1 91.815 (92.696)	Acc@5 99.644 (99.830)
Epoch: [95][128/178]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.5108 (0.4907)	Acc@1 90.747 (92.590)	Acc@5 100.000 (99.832)
Max memory in training epoch: 65.52192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 372272 ; 376028 ; 0.990011382131118
[INFO] Storing checkpoint...
  90.49
Max memory: 90.9287424
 22.255s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7860
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1563648
lr: 0.020784896711146923
1

Epoch: [96 | 100] LR: 0.020785
batch Size 287
Epoch: [96][0/175]	Time 0.245 (0.245)	Data 0.281 (0.281)	Loss 0.4457 (0.4457)	Acc@1 94.077 (94.077)	Acc@5 100.000 (100.000)
Epoch: [96][64/175]	Time 0.124 (0.127)	Data 0.000 (0.004)	Loss 0.4483 (0.4643)	Acc@1 94.774 (93.417)	Acc@5 100.000 (99.893)
Epoch: [96][128/175]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5664 (0.4674)	Acc@1 90.592 (93.188)	Acc@5 99.652 (99.876)
Max memory in training epoch: 65.223424
lr: 0.020784896711146923
1

Epoch: [97 | 100] LR: 0.020785
batch Size 287
Epoch: [97][0/175]	Time 0.184 (0.184)	Data 0.325 (0.325)	Loss 0.4471 (0.4471)	Acc@1 93.031 (93.031)	Acc@5 100.000 (100.000)
Epoch: [97][64/175]	Time 0.129 (0.127)	Data 0.000 (0.005)	Loss 0.5292 (0.4484)	Acc@1 89.895 (93.337)	Acc@5 99.303 (99.871)
Epoch: [97][128/175]	Time 0.127 (0.126)	Data 0.000 (0.003)	Loss 0.4773 (0.4513)	Acc@1 91.986 (93.345)	Acc@5 100.000 (99.833)
Max memory in training epoch: 65.966336
lr: 0.020784896711146923
1

Epoch: [98 | 100] LR: 0.020785
batch Size 287
Epoch: [98][0/175]	Time 0.160 (0.160)	Data 0.304 (0.304)	Loss 0.4691 (0.4691)	Acc@1 91.986 (91.986)	Acc@5 99.652 (99.652)
Epoch: [98][64/175]	Time 0.117 (0.126)	Data 0.000 (0.005)	Loss 0.4517 (0.4252)	Acc@1 92.334 (94.237)	Acc@5 99.652 (99.893)
Epoch: [98][128/175]	Time 0.121 (0.126)	Data 0.000 (0.003)	Loss 0.4588 (0.4300)	Acc@1 92.334 (93.936)	Acc@5 99.652 (99.870)
Max memory in training epoch: 65.966336
Drin!!
old memory: 655219200
new memory: 659663360
Faktor: 1.0067827072222548
New batch Size kleiner 288!!
lr: 0.020784896711146923
1

Epoch: [99 | 100] LR: 0.020785
batch Size 288
Epoch: [99][0/175]	Time 0.158 (0.158)	Data 0.324 (0.324)	Loss 0.4563 (0.4563)	Acc@1 91.638 (91.638)	Acc@5 100.000 (100.000)
Epoch: [99][64/175]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.4134 (0.4172)	Acc@1 94.077 (94.173)	Acc@5 99.652 (99.877)
Epoch: [99][128/175]	Time 0.125 (0.125)	Data 0.000 (0.003)	Loss 0.4772 (0.4190)	Acc@1 90.244 (94.031)	Acc@5 100.000 (99.873)
Max memory in training epoch: 65.966336
lr: 0.020784896711146923
1

Epoch: [100 | 100] LR: 0.020785
batch Size 288
Epoch: [100][0/175]	Time 0.160 (0.160)	Data 0.291 (0.291)	Loss 0.3664 (0.3664)	Acc@1 95.819 (95.819)	Acc@5 100.000 (100.000)
Epoch: [100][64/175]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.4191 (0.4082)	Acc@1 93.031 (94.061)	Acc@5 100.000 (99.887)
Epoch: [100][128/175]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.3822 (0.4077)	Acc@1 94.774 (94.098)	Acc@5 100.000 (99.887)
Max memory in training epoch: 65.966336
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 371694 ; 372272 ; 0.9984473718141574
[INFO] Storing checkpoint...
  90.05
Max memory: 89.897984
 23.161s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1688
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1560576
lr: 0.023383008800040288
1

Epoch: [101 | 105] LR: 0.023383
batch Size 288
Epoch: [101][0/174]	Time 0.189 (0.189)	Data 0.271 (0.271)	Loss 0.3466 (0.3466)	Acc@1 96.528 (96.528)	Acc@5 100.000 (100.000)
Epoch: [101][64/174]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.3983 (0.3890)	Acc@1 95.486 (94.669)	Acc@5 100.000 (99.925)
Epoch: [101][128/174]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.4167 (0.3961)	Acc@1 93.056 (94.358)	Acc@5 100.000 (99.892)
Max memory in training epoch: 65.3479424
lr: 0.023383008800040288
1

Epoch: [102 | 105] LR: 0.023383
batch Size 288
Epoch: [102][0/174]	Time 0.174 (0.174)	Data 0.296 (0.296)	Loss 0.4211 (0.4211)	Acc@1 92.361 (92.361)	Acc@5 100.000 (100.000)
Epoch: [102][64/174]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.3756 (0.3928)	Acc@1 94.444 (94.081)	Acc@5 100.000 (99.899)
Epoch: [102][128/174]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.3644 (0.3919)	Acc@1 95.486 (94.243)	Acc@5 99.653 (99.900)
Max memory in training epoch: 65.9787264
lr: 0.023383008800040288
1

Epoch: [103 | 105] LR: 0.023383
batch Size 288
Epoch: [103][0/174]	Time 0.177 (0.177)	Data 0.303 (0.303)	Loss 0.3796 (0.3796)	Acc@1 94.097 (94.097)	Acc@5 99.653 (99.653)
Epoch: [103][64/174]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.3660 (0.3788)	Acc@1 94.792 (94.525)	Acc@5 100.000 (99.920)
Epoch: [103][128/174]	Time 0.128 (0.126)	Data 0.000 (0.003)	Loss 0.3947 (0.3867)	Acc@1 94.444 (94.202)	Acc@5 99.653 (99.903)
Max memory in training epoch: 65.9787264
Drin!!
old memory: 659663360
new memory: 659787264
Faktor: 1.000187829137577
New batch Size kleiner 288!!
lr: 0.023383008800040288
1

Epoch: [104 | 105] LR: 0.023383
batch Size 288
Epoch: [104][0/174]	Time 0.172 (0.172)	Data 0.315 (0.315)	Loss 0.3662 (0.3662)	Acc@1 95.486 (95.486)	Acc@5 100.000 (100.000)
Epoch: [104][64/174]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.3972 (0.3738)	Acc@1 94.097 (94.605)	Acc@5 99.653 (99.909)
Epoch: [104][128/174]	Time 0.120 (0.124)	Data 0.000 (0.003)	Loss 0.3983 (0.3749)	Acc@1 91.667 (94.463)	Acc@5 100.000 (99.906)
Max memory in training epoch: 65.9787264
lr: 0.023383008800040288
1

Epoch: [105 | 105] LR: 0.023383
batch Size 288
Epoch: [105][0/174]	Time 0.157 (0.157)	Data 0.305 (0.305)	Loss 0.3727 (0.3727)	Acc@1 94.097 (94.097)	Acc@5 100.000 (100.000)
Epoch: [105][64/174]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.3397 (0.3641)	Acc@1 95.139 (94.728)	Acc@5 100.000 (99.931)
Epoch: [105][128/174]	Time 0.125 (0.127)	Data 0.000 (0.003)	Loss 0.3695 (0.3697)	Acc@1 93.056 (94.479)	Acc@5 100.000 (99.927)
Max memory in training epoch: 65.9787264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 369960 ; 371694 ; 0.9953348722336115
[INFO] Storing checkpoint...
  89.87
Max memory: 89.8466816
 22.363s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9131
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1553408
lr: 0.026305884900045325
1

Epoch: [106 | 110] LR: 0.026306
batch Size 288
Epoch: [106][0/174]	Time 0.174 (0.174)	Data 0.309 (0.309)	Loss 0.3967 (0.3967)	Acc@1 94.792 (94.792)	Acc@5 100.000 (100.000)
Epoch: [106][64/174]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.4068 (0.3556)	Acc@1 91.319 (94.760)	Acc@5 99.653 (99.947)
Epoch: [106][128/174]	Time 0.141 (0.127)	Data 0.000 (0.003)	Loss 0.4186 (0.3698)	Acc@1 92.014 (94.216)	Acc@5 100.000 (99.914)
Max memory in training epoch: 65.1746816
lr: 0.026305884900045325
1

Epoch: [107 | 110] LR: 0.026306
batch Size 288
Epoch: [107][0/174]	Time 0.172 (0.172)	Data 0.301 (0.301)	Loss 0.3953 (0.3953)	Acc@1 93.750 (93.750)	Acc@5 99.653 (99.653)
Epoch: [107][64/174]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.3827 (0.3643)	Acc@1 94.444 (94.610)	Acc@5 99.653 (99.931)
Epoch: [107][128/174]	Time 0.122 (0.126)	Data 0.000 (0.003)	Loss 0.3762 (0.3769)	Acc@1 94.097 (94.051)	Acc@5 100.000 (99.917)
Max memory in training epoch: 65.7120768
lr: 0.026305884900045325
1

Epoch: [108 | 110] LR: 0.026306
batch Size 288
Epoch: [108][0/174]	Time 0.185 (0.185)	Data 0.280 (0.280)	Loss 0.3720 (0.3720)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [108][64/174]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.4161 (0.3727)	Acc@1 91.319 (94.081)	Acc@5 100.000 (99.925)
Epoch: [108][128/174]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.3474 (0.3813)	Acc@1 93.403 (93.769)	Acc@5 100.000 (99.895)
Max memory in training epoch: 65.7120768
Drin!!
old memory: 659787264
new memory: 657120768
Faktor: 0.9959585518765031
New batch Size größer 293!!
lr: 0.026305884900045325
1

Epoch: [109 | 110] LR: 0.026306
batch Size 293
Epoch: [109][0/174]	Time 0.170 (0.170)	Data 0.309 (0.309)	Loss 0.3492 (0.3492)	Acc@1 93.403 (93.403)	Acc@5 100.000 (100.000)
Epoch: [109][64/174]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.4041 (0.3706)	Acc@1 93.750 (94.236)	Acc@5 100.000 (99.904)
Epoch: [109][128/174]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.3720 (0.3783)	Acc@1 93.750 (93.898)	Acc@5 99.306 (99.887)
Max memory in training epoch: 65.7120768
lr: 0.026305884900045325
1

Epoch: [110 | 110] LR: 0.026306
batch Size 293
Epoch: [110][0/174]	Time 0.179 (0.179)	Data 0.278 (0.278)	Loss 0.3672 (0.3672)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [110][64/174]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 0.3731 (0.3811)	Acc@1 93.403 (93.574)	Acc@5 99.306 (99.904)
Epoch: [110][128/174]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.4413 (0.3804)	Acc@1 92.361 (93.575)	Acc@5 100.000 (99.906)
Max memory in training epoch: 65.7120768
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.36
Max memory: 89.532416
 22.569s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1268
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1553408
lr: 0.030107907327005
1

Epoch: [111 | 115] LR: 0.030108
batch Size 293
Epoch: [111][0/171]	Time 0.178 (0.178)	Data 0.303 (0.303)	Loss 0.3938 (0.3938)	Acc@1 92.491 (92.491)	Acc@5 100.000 (100.000)
Epoch: [111][64/171]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.3994 (0.3657)	Acc@1 92.491 (94.172)	Acc@5 100.000 (99.905)
Epoch: [111][128/171]	Time 0.120 (0.127)	Data 0.000 (0.003)	Loss 0.4841 (0.3854)	Acc@1 90.102 (93.402)	Acc@5 99.659 (99.873)
Max memory in training epoch: 66.8323328
lr: 0.030107907327005
1

Epoch: [112 | 115] LR: 0.030108
batch Size 293
Epoch: [112][0/171]	Time 0.188 (0.188)	Data 0.295 (0.295)	Loss 0.3984 (0.3984)	Acc@1 92.833 (92.833)	Acc@5 100.000 (100.000)
Epoch: [112][64/171]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.3965 (0.3959)	Acc@1 93.857 (93.148)	Acc@5 99.659 (99.858)
Epoch: [112][128/171]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.4033 (0.4064)	Acc@1 91.126 (92.735)	Acc@5 100.000 (99.865)
Max memory in training epoch: 67.0291456
lr: 0.030107907327005
1

Epoch: [113 | 115] LR: 0.030108
batch Size 293
Epoch: [113][0/171]	Time 0.186 (0.186)	Data 0.267 (0.267)	Loss 0.4723 (0.4723)	Acc@1 90.785 (90.785)	Acc@5 100.000 (100.000)
Epoch: [113][64/171]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.4481 (0.3982)	Acc@1 90.785 (93.095)	Acc@5 100.000 (99.874)
Epoch: [113][128/171]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.4046 (0.4014)	Acc@1 90.785 (92.952)	Acc@5 100.000 (99.844)
Max memory in training epoch: 67.0291456
Drin!!
old memory: 657120768
new memory: 670291456
Faktor: 1.0200430250288484
New batch Size kleiner 298!!
lr: 0.030107907327005
1

Epoch: [114 | 115] LR: 0.030108
batch Size 298
Epoch: [114][0/171]	Time 0.171 (0.171)	Data 0.309 (0.309)	Loss 0.4429 (0.4429)	Acc@1 92.833 (92.833)	Acc@5 99.659 (99.659)
Epoch: [114][64/171]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.3304 (0.3781)	Acc@1 95.222 (93.815)	Acc@5 100.000 (99.900)
Epoch: [114][128/171]	Time 0.125 (0.125)	Data 0.000 (0.003)	Loss 0.3146 (0.3878)	Acc@1 95.904 (93.455)	Acc@5 100.000 (99.878)
Max memory in training epoch: 67.0291456
lr: 0.030107907327005
1

Epoch: [115 | 115] LR: 0.030108
batch Size 298
Epoch: [115][0/171]	Time 0.177 (0.177)	Data 0.279 (0.279)	Loss 0.4099 (0.4099)	Acc@1 93.174 (93.174)	Acc@5 99.659 (99.659)
Epoch: [115][64/171]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.3904 (0.3992)	Acc@1 93.515 (92.859)	Acc@5 100.000 (99.900)
Epoch: [115][128/171]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.4077 (0.4011)	Acc@1 93.174 (92.764)	Acc@5 99.659 (99.881)
Max memory in training epoch: 67.0291456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 369382 ; 369960 ; 0.9984376689371824
[INFO] Storing checkpoint...
  87.64
Max memory: 89.9428352
 21.946s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4770
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.155136
lr: 0.035047485872841753
1

Epoch: [116 | 120] LR: 0.035047
batch Size 298
Epoch: [116][0/168]	Time 0.214 (0.214)	Data 0.279 (0.279)	Loss 0.3360 (0.3360)	Acc@1 95.638 (95.638)	Acc@5 100.000 (100.000)
Epoch: [116][64/168]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.4483 (0.3919)	Acc@1 90.604 (93.330)	Acc@5 99.664 (99.881)
Epoch: [116][128/168]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.4820 (0.4136)	Acc@1 91.611 (92.420)	Acc@5 99.664 (99.878)
Max memory in training epoch: 67.6896768
lr: 0.035047485872841753
1

Epoch: [117 | 120] LR: 0.035047
batch Size 298
Epoch: [117][0/168]	Time 0.168 (0.168)	Data 0.314 (0.314)	Loss 0.4438 (0.4438)	Acc@1 90.268 (90.268)	Acc@5 100.000 (100.000)
Epoch: [117][64/168]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.3700 (0.3994)	Acc@1 93.624 (93.010)	Acc@5 99.664 (99.871)
Epoch: [117][128/168]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.4461 (0.4131)	Acc@1 89.933 (92.511)	Acc@5 100.000 (99.849)
Max memory in training epoch: 67.7359616
lr: 0.035047485872841753
1

Epoch: [118 | 120] LR: 0.035047
batch Size 298
Epoch: [118][0/168]	Time 0.192 (0.192)	Data 0.284 (0.284)	Loss 0.3876 (0.3876)	Acc@1 91.946 (91.946)	Acc@5 100.000 (100.000)
Epoch: [118][64/168]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.3915 (0.4068)	Acc@1 93.624 (92.721)	Acc@5 99.664 (99.866)
Epoch: [118][128/168]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.4842 (0.4151)	Acc@1 89.262 (92.495)	Acc@5 99.329 (99.865)
Max memory in training epoch: 67.7359616
Drin!!
old memory: 670291456
new memory: 677359616
Faktor: 1.0105449054090285
New batch Size kleiner 301!!
lr: 0.035047485872841753
1

Epoch: [119 | 120] LR: 0.035047
batch Size 301
Epoch: [119][0/168]	Time 0.192 (0.192)	Data 0.317 (0.317)	Loss 0.4132 (0.4132)	Acc@1 92.282 (92.282)	Acc@5 100.000 (100.000)
Epoch: [119][64/168]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.4438 (0.4206)	Acc@1 90.268 (92.297)	Acc@5 100.000 (99.866)
Epoch: [119][128/168]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.4433 (0.4222)	Acc@1 91.946 (92.248)	Acc@5 100.000 (99.826)
Max memory in training epoch: 67.7359616
lr: 0.035047485872841753
1

Epoch: [120 | 120] LR: 0.035047
batch Size 301
Epoch: [120][0/168]	Time 0.166 (0.166)	Data 0.281 (0.281)	Loss 0.4455 (0.4455)	Acc@1 89.933 (89.933)	Acc@5 100.000 (100.000)
Epoch: [120][64/168]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.3694 (0.4155)	Acc@1 93.289 (92.581)	Acc@5 100.000 (99.840)
Epoch: [120][128/168]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.4311 (0.4179)	Acc@1 90.604 (92.407)	Acc@5 99.329 (99.836)
Max memory in training epoch: 67.7359616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 368804 ; 369382 ; 0.9984352242394052
[INFO] Storing checkpoint...
  86.5
Max memory: 89.8947072
 21.977s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8708
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1549312
lr: 0.04120817674892722
1

Epoch: [121 | 125] LR: 0.041208
batch Size 301
Epoch: [121][0/167]	Time 0.229 (0.229)	Data 0.275 (0.275)	Loss 0.3715 (0.3715)	Acc@1 93.355 (93.355)	Acc@5 100.000 (100.000)
Epoch: [121][64/167]	Time 0.125 (0.132)	Data 0.000 (0.004)	Loss 0.5065 (0.4164)	Acc@1 87.708 (92.359)	Acc@5 100.000 (99.877)
Epoch: [121][128/167]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.4170 (0.4327)	Acc@1 93.688 (91.839)	Acc@5 100.000 (99.861)
Max memory in training epoch: 68.2037248
lr: 0.04120817674892722
1

Epoch: [122 | 125] LR: 0.041208
batch Size 301
Epoch: [122][0/167]	Time 0.185 (0.185)	Data 0.305 (0.305)	Loss 0.4402 (0.4402)	Acc@1 91.694 (91.694)	Acc@5 99.668 (99.668)
Epoch: [122][64/167]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 0.4538 (0.4612)	Acc@1 90.698 (90.815)	Acc@5 100.000 (99.816)
Epoch: [122][128/167]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 0.4786 (0.4573)	Acc@1 90.698 (91.169)	Acc@5 100.000 (99.797)
Max memory in training epoch: 68.20864
lr: 0.04120817674892722
1

Epoch: [123 | 125] LR: 0.041208
batch Size 301
Epoch: [123][0/167]	Time 0.178 (0.178)	Data 0.318 (0.318)	Loss 0.4671 (0.4671)	Acc@1 91.694 (91.694)	Acc@5 99.336 (99.336)
Epoch: [123][64/167]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.5153 (0.4567)	Acc@1 89.701 (91.306)	Acc@5 100.000 (99.826)
Epoch: [123][128/167]	Time 0.132 (0.130)	Data 0.000 (0.003)	Loss 0.4255 (0.4532)	Acc@1 93.688 (91.563)	Acc@5 100.000 (99.817)
Max memory in training epoch: 68.20864
Drin!!
old memory: 677359616
new memory: 682086400
Faktor: 1.006978248907003
New batch Size kleiner 303!!
lr: 0.04120817674892722
1

Epoch: [124 | 125] LR: 0.041208
batch Size 303
Epoch: [124][0/167]	Time 0.189 (0.189)	Data 0.321 (0.321)	Loss 0.5273 (0.5273)	Acc@1 89.037 (89.037)	Acc@5 99.336 (99.336)
Epoch: [124][64/167]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.4454 (0.4517)	Acc@1 93.023 (91.659)	Acc@5 100.000 (99.826)
Epoch: [124][128/167]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.4702 (0.4558)	Acc@1 92.027 (91.514)	Acc@5 100.000 (99.809)
Max memory in training epoch: 68.20864
lr: 0.04120817674892722
1

Epoch: [125 | 125] LR: 0.041208
batch Size 303
Epoch: [125][0/167]	Time 0.166 (0.166)	Data 0.332 (0.332)	Loss 0.4393 (0.4393)	Acc@1 91.694 (91.694)	Acc@5 100.000 (100.000)
Epoch: [125][64/167]	Time 0.154 (0.131)	Data 0.000 (0.005)	Loss 0.4335 (0.4631)	Acc@1 92.691 (91.219)	Acc@5 99.668 (99.790)
Epoch: [125][128/167]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.4621 (0.4557)	Acc@1 91.030 (91.563)	Acc@5 100.000 (99.820)
Max memory in training epoch: 68.20864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 365052 ; 368804 ; 0.989826574549083
[INFO] Storing checkpoint...
  85.65
Max memory: 89.6782336
 22.071s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7287
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1534976
lr: 0.04877374044892557
1

Epoch: [126 | 130] LR: 0.048774
batch Size 303
Epoch: [126][0/166]	Time 0.215 (0.215)	Data 0.302 (0.302)	Loss 0.5565 (0.5565)	Acc@1 87.789 (87.789)	Acc@5 100.000 (100.000)
Epoch: [126][64/166]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.3945 (0.4349)	Acc@1 93.399 (92.008)	Acc@5 100.000 (99.863)
Epoch: [126][128/166]	Time 0.137 (0.131)	Data 0.000 (0.003)	Loss 0.5223 (0.4519)	Acc@1 89.439 (91.560)	Acc@5 100.000 (99.831)
Max memory in training epoch: 68.2697728
lr: 0.04877374044892557
1

Epoch: [127 | 130] LR: 0.048774
batch Size 303
Epoch: [127][0/166]	Time 0.168 (0.168)	Data 0.342 (0.342)	Loss 0.6733 (0.6733)	Acc@1 86.469 (86.469)	Acc@5 99.670 (99.670)
Epoch: [127][64/166]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.6257 (0.8630)	Acc@1 85.809 (79.117)	Acc@5 100.000 (98.370)
Epoch: [127][128/166]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.5949 (0.7366)	Acc@1 87.129 (83.207)	Acc@5 99.670 (98.938)
Max memory in training epoch: 68.4295168
lr: 0.04877374044892557
1

Epoch: [128 | 130] LR: 0.048774
batch Size 303
Epoch: [128][0/166]	Time 0.161 (0.161)	Data 0.298 (0.298)	Loss 0.5476 (0.5476)	Acc@1 89.439 (89.439)	Acc@5 100.000 (100.000)
Epoch: [128][64/166]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.5995 (0.5869)	Acc@1 86.799 (88.068)	Acc@5 99.670 (99.594)
Epoch: [128][128/166]	Time 0.129 (0.129)	Data 0.000 (0.003)	Loss 0.4930 (0.5553)	Acc@1 91.419 (89.140)	Acc@5 100.000 (99.652)
Max memory in training epoch: 68.4295168
Drin!!
old memory: 682086400
new memory: 684295168
Faktor: 1.0032382525146375
New batch Size kleiner 303!!
lr: 0.04877374044892557
1

Epoch: [129 | 130] LR: 0.048774
batch Size 303
Epoch: [129][0/166]	Time 0.190 (0.190)	Data 0.287 (0.287)	Loss 0.5779 (0.5779)	Acc@1 88.119 (88.119)	Acc@5 99.010 (99.010)
Epoch: [129][64/166]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.6279 (0.7440)	Acc@1 89.109 (83.072)	Acc@5 99.340 (98.979)
Epoch: [129][128/166]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.5883 (0.6577)	Acc@1 89.439 (85.957)	Acc@5 99.010 (99.312)
Max memory in training epoch: 68.4295168
lr: 0.04877374044892557
1

Epoch: [130 | 130] LR: 0.048774
batch Size 303
Epoch: [130][0/166]	Time 0.176 (0.176)	Data 0.301 (0.301)	Loss 0.5619 (0.5619)	Acc@1 88.779 (88.779)	Acc@5 99.670 (99.670)
Epoch: [130][64/166]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.5031 (0.5191)	Acc@1 88.449 (90.297)	Acc@5 100.000 (99.695)
Epoch: [130][128/166]	Time 0.127 (0.129)	Data 0.000 (0.003)	Loss 0.5125 (0.5129)	Acc@1 91.419 (90.503)	Acc@5 99.670 (99.696)
Max memory in training epoch: 68.4295168
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 362744 ; 365052 ; 0.9936776130523871
[INFO] Storing checkpoint...
  86.94
Max memory: 89.580544
 21.719s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9585
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.152576
lr: 0.0577282943594705
1

Epoch: [131 | 135] LR: 0.057728
batch Size 303
Epoch: [131][0/166]	Time 0.212 (0.212)	Data 0.271 (0.271)	Loss 0.4229 (0.4229)	Acc@1 94.059 (94.059)	Acc@5 100.000 (100.000)
Epoch: [131][64/166]	Time 0.137 (0.132)	Data 0.000 (0.004)	Loss 0.4612 (0.4751)	Acc@1 91.419 (91.749)	Acc@5 100.000 (99.812)
Epoch: [131][128/166]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.5118 (0.5017)	Acc@1 91.419 (90.851)	Acc@5 100.000 (99.754)
Max memory in training epoch: 68.2505728
lr: 0.0577282943594705
1

Epoch: [132 | 135] LR: 0.057728
batch Size 303
Epoch: [132][0/166]	Time 0.180 (0.180)	Data 0.329 (0.329)	Loss 0.5838 (0.5838)	Acc@1 87.789 (87.789)	Acc@5 99.670 (99.670)
Epoch: [132][64/166]	Time 0.130 (0.128)	Data 0.000 (0.005)	Loss 0.5394 (0.7157)	Acc@1 90.099 (83.615)	Acc@5 99.670 (99.238)
Epoch: [132][128/166]	Time 0.121 (0.130)	Data 0.000 (0.003)	Loss 0.6115 (0.6447)	Acc@1 87.789 (86.149)	Acc@5 98.680 (99.401)
Max memory in training epoch: 68.4258304
lr: 0.0577282943594705
1

Epoch: [133 | 135] LR: 0.057728
batch Size 303
Epoch: [133][0/166]	Time 0.150 (0.150)	Data 0.313 (0.313)	Loss 0.5582 (0.5582)	Acc@1 87.459 (87.459)	Acc@5 99.010 (99.010)
Epoch: [133][64/166]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.5902 (0.5770)	Acc@1 86.469 (88.601)	Acc@5 99.340 (99.543)
Epoch: [133][128/166]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.5172 (0.5574)	Acc@1 90.429 (89.175)	Acc@5 99.340 (99.619)
Max memory in training epoch: 68.4258304
Drin!!
old memory: 684295168
new memory: 684258304
Faktor: 0.9999461285104384
New batch Size größer 296!!
lr: 0.0577282943594705
1

Epoch: [134 | 135] LR: 0.057728
batch Size 296
Epoch: [134][0/166]	Time 0.202 (0.202)	Data 0.287 (0.287)	Loss 0.4663 (0.4663)	Acc@1 93.069 (93.069)	Acc@5 100.000 (100.000)
Epoch: [134][64/166]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.4420 (0.5077)	Acc@1 94.059 (90.607)	Acc@5 99.340 (99.711)
Epoch: [134][128/166]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.5171 (0.5106)	Acc@1 89.439 (90.506)	Acc@5 100.000 (99.690)
Max memory in training epoch: 68.4258304
lr: 0.0577282943594705
1

Epoch: [135 | 135] LR: 0.057728
batch Size 296
Epoch: [135][0/166]	Time 0.169 (0.169)	Data 0.360 (0.360)	Loss 0.5884 (0.5884)	Acc@1 89.439 (89.439)	Acc@5 99.340 (99.340)
Epoch: [135][64/166]	Time 0.130 (0.130)	Data 0.000 (0.006)	Loss 0.5392 (0.6191)	Acc@1 90.099 (87.205)	Acc@5 99.670 (99.507)
Epoch: [135][128/166]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.5228 (0.5694)	Acc@1 90.759 (88.720)	Acc@5 99.340 (99.624)
Max memory in training epoch: 68.4258304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  62.44
Max memory: 89.4626816
 21.908s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 959
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.152576
lr: 0.06674834035313777
1

Epoch: [136 | 140] LR: 0.066748
batch Size 296
Epoch: [136][0/169]	Time 0.208 (0.208)	Data 0.275 (0.275)	Loss 0.5560 (0.5560)	Acc@1 87.838 (87.838)	Acc@5 100.000 (100.000)
Epoch: [136][64/169]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.5081 (0.5100)	Acc@1 91.892 (90.577)	Acc@5 98.986 (99.735)
Epoch: [136][128/169]	Time 0.142 (0.128)	Data 0.000 (0.002)	Loss 0.5296 (0.5200)	Acc@1 89.527 (90.153)	Acc@5 100.000 (99.743)
Max memory in training epoch: 66.9648896
lr: 0.06674834035313777
1

Epoch: [137 | 140] LR: 0.066748
batch Size 296
Epoch: [137][0/169]	Time 0.169 (0.169)	Data 0.309 (0.309)	Loss 0.4774 (0.4774)	Acc@1 91.892 (91.892)	Acc@5 99.324 (99.324)
Epoch: [137][64/169]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.5111 (0.5304)	Acc@1 90.541 (89.569)	Acc@5 99.662 (99.683)
Epoch: [137][128/169]	Time 0.125 (0.127)	Data 0.000 (0.003)	Loss 0.5128 (0.5310)	Acc@1 89.865 (89.692)	Acc@5 100.000 (99.722)
Max memory in training epoch: 67.0754816
lr: 0.06674834035313777
1

Epoch: [138 | 140] LR: 0.066748
batch Size 296
Epoch: [138][0/169]	Time 0.170 (0.170)	Data 0.291 (0.291)	Loss 0.5038 (0.5038)	Acc@1 90.878 (90.878)	Acc@5 100.000 (100.000)
Epoch: [138][64/169]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.4953 (0.5218)	Acc@1 91.554 (90.052)	Acc@5 100.000 (99.704)
Epoch: [138][128/169]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.5341 (0.5283)	Acc@1 89.189 (89.831)	Acc@5 99.662 (99.699)
Max memory in training epoch: 67.0754816
Drin!!
old memory: 684258304
new memory: 670754816
Faktor: 0.980265510961194
New batch Size größer 295!!
lr: 0.06674834035313777
1

Epoch: [139 | 140] LR: 0.066748
batch Size 295
Epoch: [139][0/169]	Time 0.162 (0.162)	Data 0.312 (0.312)	Loss 0.5115 (0.5115)	Acc@1 91.216 (91.216)	Acc@5 98.649 (98.649)
Epoch: [139][64/169]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.5968 (0.5064)	Acc@1 87.838 (90.738)	Acc@5 99.324 (99.657)
Epoch: [139][128/169]	Time 0.121 (0.127)	Data 0.000 (0.003)	Loss 0.4911 (0.5134)	Acc@1 90.878 (90.410)	Acc@5 99.662 (99.696)
Max memory in training epoch: 67.0754816
lr: 0.06674834035313777
1

Epoch: [140 | 140] LR: 0.066748
batch Size 295
Epoch: [140][0/169]	Time 0.146 (0.146)	Data 0.310 (0.310)	Loss 0.4545 (0.4545)	Acc@1 92.568 (92.568)	Acc@5 100.000 (100.000)
Epoch: [140][64/169]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.5498 (0.5053)	Acc@1 89.527 (90.489)	Acc@5 98.649 (99.735)
Epoch: [140][128/169]	Time 0.129 (0.127)	Data 0.000 (0.003)	Loss 0.5756 (0.5221)	Acc@1 87.500 (90.056)	Acc@5 99.324 (99.728)
Max memory in training epoch: 67.0754816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 362454 ; 362744 ; 0.9992005381205479
[INFO] Storing checkpoint...
  83.79
Max memory: 89.6228352
 22.059s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6523
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1524736
lr: 0.0769170328288111
1

Epoch: [141 | 145] LR: 0.076917
batch Size 295
Epoch: [141][0/170]	Time 0.207 (0.207)	Data 0.298 (0.298)	Loss 0.5165 (0.5165)	Acc@1 89.153 (89.153)	Acc@5 100.000 (100.000)
Epoch: [141][64/170]	Time 0.129 (0.127)	Data 0.000 (0.005)	Loss 0.6172 (0.5297)	Acc@1 86.780 (89.643)	Acc@5 99.322 (99.687)
Epoch: [141][128/170]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6018 (0.5497)	Acc@1 86.441 (89.105)	Acc@5 99.322 (99.635)
Max memory in training epoch: 66.5524736
lr: 0.0769170328288111
1

Epoch: [142 | 145] LR: 0.076917
batch Size 295
Epoch: [142][0/170]	Time 0.182 (0.182)	Data 0.295 (0.295)	Loss 0.4910 (0.4910)	Acc@1 91.525 (91.525)	Acc@5 99.661 (99.661)
Epoch: [142][64/170]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.6282 (0.5433)	Acc@1 86.780 (89.622)	Acc@5 100.000 (99.677)
Epoch: [142][128/170]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.6113 (0.5567)	Acc@1 86.441 (89.095)	Acc@5 100.000 (99.664)
Max memory in training epoch: 66.6884608
lr: 0.0769170328288111
1

Epoch: [143 | 145] LR: 0.076917
batch Size 295
Epoch: [143][0/170]	Time 0.159 (0.159)	Data 0.300 (0.300)	Loss 0.5688 (0.5688)	Acc@1 88.475 (88.475)	Acc@5 100.000 (100.000)
Epoch: [143][64/170]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.5040 (0.5457)	Acc@1 90.847 (89.361)	Acc@5 100.000 (99.703)
Epoch: [143][128/170]	Time 0.122 (0.126)	Data 0.000 (0.003)	Loss 0.5475 (0.5440)	Acc@1 88.136 (89.481)	Acc@5 100.000 (99.703)
Max memory in training epoch: 66.7245056
Drin!!
old memory: 670754816
new memory: 667245056
Faktor: 0.9947674471859476
New batch Size größer 296!!
lr: 0.0769170328288111
1

Epoch: [144 | 145] LR: 0.076917
batch Size 296
Epoch: [144][0/170]	Time 0.181 (0.181)	Data 0.277 (0.277)	Loss 0.5122 (0.5122)	Acc@1 90.847 (90.847)	Acc@5 100.000 (100.000)
Epoch: [144][64/170]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.5650 (0.5364)	Acc@1 88.814 (89.914)	Acc@5 100.000 (99.713)
Epoch: [144][128/170]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.5400 (0.5443)	Acc@1 90.508 (89.626)	Acc@5 99.322 (99.682)
Max memory in training epoch: 66.7245056
lr: 0.0769170328288111
1

Epoch: [145 | 145] LR: 0.076917
batch Size 296
Epoch: [145][0/170]	Time 0.180 (0.180)	Data 0.265 (0.265)	Loss 0.4336 (0.4336)	Acc@1 94.915 (94.915)	Acc@5 99.661 (99.661)
Epoch: [145][64/170]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.5913 (0.5160)	Acc@1 87.119 (90.472)	Acc@5 99.661 (99.750)
Epoch: [145][128/170]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.5703 (0.5357)	Acc@1 87.119 (89.883)	Acc@5 100.000 (99.685)
Max memory in training epoch: 66.7245056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356100 ; 362454 ; 0.9824694995778774
[INFO] Storing checkpoint...
  82.38
Max memory: 89.022464
 21.845s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6446
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.150016
lr: 0.08893531920831284
1

Epoch: [146 | 150] LR: 0.088935
batch Size 296
Epoch: [146][0/169]	Time 0.228 (0.228)	Data 0.314 (0.314)	Loss 0.5058 (0.5058)	Acc@1 90.541 (90.541)	Acc@5 99.324 (99.324)
Epoch: [146][64/169]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.5677 (0.5455)	Acc@1 86.824 (89.163)	Acc@5 99.662 (99.709)
Epoch: [146][128/169]	Time 0.124 (0.127)	Data 0.000 (0.003)	Loss 0.5429 (0.5619)	Acc@1 89.865 (88.726)	Acc@5 99.324 (99.670)
Max memory in training epoch: 65.6617472
lr: 0.08893531920831284
1

Epoch: [147 | 150] LR: 0.088935
batch Size 296
Epoch: [147][0/169]	Time 0.151 (0.151)	Data 0.302 (0.302)	Loss 0.5369 (0.5369)	Acc@1 90.878 (90.878)	Acc@5 99.662 (99.662)
Epoch: [147][64/169]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.5384 (0.5681)	Acc@1 89.189 (89.018)	Acc@5 99.662 (99.678)
Epoch: [147][128/169]	Time 0.123 (0.127)	Data 0.000 (0.003)	Loss 0.5863 (0.5709)	Acc@1 89.189 (88.956)	Acc@5 99.324 (99.615)
Max memory in training epoch: 65.9050496
lr: 0.08893531920831284
1

Epoch: [148 | 150] LR: 0.088935
batch Size 296
Epoch: [148][0/169]	Time 0.181 (0.181)	Data 0.293 (0.293)	Loss 0.6677 (0.6677)	Acc@1 87.838 (87.838)	Acc@5 99.662 (99.662)
Epoch: [148][64/169]	Time 0.140 (0.129)	Data 0.000 (0.005)	Loss 0.5171 (0.5675)	Acc@1 90.541 (88.810)	Acc@5 100.000 (99.657)
Epoch: [148][128/169]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.5334 (0.5701)	Acc@1 89.527 (88.830)	Acc@5 100.000 (99.625)
Max memory in training epoch: 66.0318208
Drin!!
old memory: 667245056
new memory: 660318208
Faktor: 0.9896187346197437
New batch Size größer 300!!
lr: 0.08893531920831284
1

Epoch: [149 | 150] LR: 0.088935
batch Size 300
Epoch: [149][0/169]	Time 0.179 (0.179)	Data 0.300 (0.300)	Loss 0.5932 (0.5932)	Acc@1 89.527 (89.527)	Acc@5 100.000 (100.000)
Epoch: [149][64/169]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.5669 (0.5662)	Acc@1 88.176 (89.148)	Acc@5 99.324 (99.636)
Epoch: [149][128/169]	Time 0.134 (0.129)	Data 0.000 (0.003)	Loss 0.5098 (0.5731)	Acc@1 90.878 (88.741)	Acc@5 99.662 (99.623)
Max memory in training epoch: 66.0318208
lr: 0.08893531920831284
1

Epoch: [150 | 150] LR: 0.008894
batch Size 300
Epoch: [150][0/169]	Time 0.184 (0.184)	Data 0.267 (0.267)	Loss 0.5123 (0.5123)	Acc@1 91.554 (91.554)	Acc@5 99.662 (99.662)
Epoch: [150][64/169]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.4873 (0.4781)	Acc@1 90.878 (92.115)	Acc@5 100.000 (99.813)
Epoch: [150][128/169]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.4425 (0.4579)	Acc@1 93.581 (92.840)	Acc@5 99.662 (99.840)
Max memory in training epoch: 66.0318208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 346576 ; 356100 ; 0.973254703734906
[INFO] Storing checkpoint...
  91.35
Max memory: 87.7776896
 21.764s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5919
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.146176
lr: 0.01042210771972416
1

Epoch: [151 | 155] LR: 0.010422
batch Size 300
Epoch: [151][0/167]	Time 0.195 (0.195)	Data 0.311 (0.311)	Loss 0.4326 (0.4326)	Acc@1 94.000 (94.000)	Acc@5 100.000 (100.000)
Epoch: [151][64/167]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.3754 (0.4077)	Acc@1 95.000 (94.482)	Acc@5 100.000 (99.928)
Epoch: [151][128/167]	Time 0.133 (0.128)	Data 0.000 (0.003)	Loss 0.4737 (0.4063)	Acc@1 91.000 (94.553)	Acc@5 99.667 (99.910)
Max memory in training epoch: 66.2883328
lr: 0.01042210771972416
1

Epoch: [152 | 155] LR: 0.010422
batch Size 300
Epoch: [152][0/167]	Time 0.177 (0.177)	Data 0.307 (0.307)	Loss 0.3688 (0.3688)	Acc@1 96.000 (96.000)	Acc@5 100.000 (100.000)
Epoch: [152][64/167]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 0.3772 (0.3804)	Acc@1 95.333 (95.441)	Acc@5 100.000 (99.908)
Epoch: [152][128/167]	Time 0.120 (0.127)	Data 0.000 (0.003)	Loss 0.4256 (0.3865)	Acc@1 93.667 (95.116)	Acc@5 99.667 (99.910)
Max memory in training epoch: 66.4978432
lr: 0.01042210771972416
1

Epoch: [153 | 155] LR: 0.010422
batch Size 300
Epoch: [153][0/167]	Time 0.165 (0.165)	Data 0.302 (0.302)	Loss 0.3570 (0.3570)	Acc@1 96.333 (96.333)	Acc@5 100.000 (100.000)
Epoch: [153][64/167]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.3575 (0.3694)	Acc@1 95.667 (95.441)	Acc@5 100.000 (99.903)
Epoch: [153][128/167]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.3821 (0.3709)	Acc@1 93.333 (95.354)	Acc@5 100.000 (99.915)
Max memory in training epoch: 66.3453696
Drin!!
old memory: 660318208
new memory: 663453696
Faktor: 1.004748450007909
New batch Size kleiner 301!!
lr: 0.01042210771972416
1

Epoch: [154 | 155] LR: 0.010422
batch Size 301
Epoch: [154][0/167]	Time 0.150 (0.150)	Data 0.315 (0.315)	Loss 0.3371 (0.3371)	Acc@1 97.000 (97.000)	Acc@5 100.000 (100.000)
Epoch: [154][64/167]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.3693 (0.3562)	Acc@1 95.333 (95.841)	Acc@5 100.000 (99.949)
Epoch: [154][128/167]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.3313 (0.3570)	Acc@1 97.000 (95.765)	Acc@5 100.000 (99.941)
Max memory in training epoch: 66.484736
lr: 0.01042210771972416
1

Epoch: [155 | 155] LR: 0.010422
batch Size 301
Epoch: [155][0/167]	Time 0.159 (0.159)	Data 0.290 (0.290)	Loss 0.3015 (0.3015)	Acc@1 97.000 (97.000)	Acc@5 100.000 (100.000)
Epoch: [155][64/167]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.3138 (0.3466)	Acc@1 98.000 (96.092)	Acc@5 100.000 (99.938)
Epoch: [155][128/167]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.3296 (0.3468)	Acc@1 96.667 (96.085)	Acc@5 100.000 (99.941)
Max memory in training epoch: 66.484736
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 345998 ; 346576 ; 0.9983322561285259
[INFO] Storing checkpoint...
  91.94
Max memory: 87.9181312
 21.736s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1939
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1459712
lr: 0.012254118842331923
1

Epoch: [156 | 160] LR: 0.012254
batch Size 301
Epoch: [156][0/167]	Time 0.173 (0.173)	Data 0.304 (0.304)	Loss 0.3082 (0.3082)	Acc@1 97.674 (97.674)	Acc@5 100.000 (100.000)
Epoch: [156][64/167]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.3257 (0.3390)	Acc@1 96.678 (96.187)	Acc@5 100.000 (99.934)
Epoch: [156][128/167]	Time 0.127 (0.127)	Data 0.000 (0.003)	Loss 0.2884 (0.3387)	Acc@1 98.007 (96.145)	Acc@5 100.000 (99.920)
Max memory in training epoch: 66.4225792
lr: 0.012254118842331923
1

Epoch: [157 | 160] LR: 0.012254
batch Size 301
Epoch: [157][0/167]	Time 0.177 (0.177)	Data 0.309 (0.309)	Loss 0.3190 (0.3190)	Acc@1 96.678 (96.678)	Acc@5 99.668 (99.668)
Epoch: [157][64/167]	Time 0.130 (0.128)	Data 0.000 (0.005)	Loss 0.3290 (0.3407)	Acc@1 96.346 (95.967)	Acc@5 100.000 (99.928)
Epoch: [157][128/167]	Time 0.127 (0.129)	Data 0.000 (0.003)	Loss 0.3467 (0.3378)	Acc@1 94.684 (96.049)	Acc@5 100.000 (99.933)
Max memory in training epoch: 66.6139136
lr: 0.012254118842331923
1

Epoch: [158 | 160] LR: 0.012254
batch Size 301
Epoch: [158][0/167]	Time 0.181 (0.181)	Data 0.303 (0.303)	Loss 0.3451 (0.3451)	Acc@1 95.349 (95.349)	Acc@5 100.000 (100.000)
Epoch: [158][64/167]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.2943 (0.3355)	Acc@1 97.674 (95.875)	Acc@5 100.000 (99.939)
Epoch: [158][128/167]	Time 0.122 (0.128)	Data 0.000 (0.003)	Loss 0.3749 (0.3315)	Acc@1 95.017 (96.008)	Acc@5 100.000 (99.948)
Max memory in training epoch: 66.456064
Drin!!
old memory: 664847360
new memory: 664560640
Faktor: 0.9995687431172171
New batch Size größer 303!!
lr: 0.012254118842331923
1

Epoch: [159 | 160] LR: 0.012254
batch Size 303
Epoch: [159][0/167]	Time 0.174 (0.174)	Data 0.309 (0.309)	Loss 0.3240 (0.3240)	Acc@1 96.013 (96.013)	Acc@5 100.000 (100.000)
Epoch: [159][64/167]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.3697 (0.3370)	Acc@1 94.020 (95.635)	Acc@5 99.668 (99.944)
Epoch: [159][128/167]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.3106 (0.3297)	Acc@1 95.681 (96.029)	Acc@5 100.000 (99.951)
Max memory in training epoch: 66.590976
lr: 0.012254118842331923
1

Epoch: [160 | 160] LR: 0.012254
batch Size 303
Epoch: [160][0/167]	Time 0.168 (0.168)	Data 0.278 (0.278)	Loss 0.3063 (0.3063)	Acc@1 96.678 (96.678)	Acc@5 99.668 (99.668)
Epoch: [160][64/167]	Time 0.129 (0.128)	Data 0.000 (0.004)	Loss 0.2989 (0.3102)	Acc@1 96.678 (96.821)	Acc@5 100.000 (99.923)
Epoch: [160][128/167]	Time 0.154 (0.127)	Data 0.000 (0.002)	Loss 0.2883 (0.3098)	Acc@1 97.674 (96.724)	Acc@5 100.000 (99.933)
Max memory in training epoch: 66.590976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.61
Max memory: 87.8839296
 21.602s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2942
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1459712
lr: 0.0145038984735413
1

Epoch: [161 | 165] LR: 0.014504
batch Size 303
Epoch: [161][0/166]	Time 0.203 (0.203)	Data 0.342 (0.342)	Loss 0.3583 (0.3583)	Acc@1 95.380 (95.380)	Acc@5 100.000 (100.000)
Epoch: [161][64/166]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.3527 (0.3011)	Acc@1 95.380 (96.923)	Acc@5 100.000 (99.964)
Epoch: [161][128/166]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 0.3433 (0.3081)	Acc@1 95.050 (96.577)	Acc@5 100.000 (99.954)
Max memory in training epoch: 66.953472
lr: 0.0145038984735413
1

Epoch: [162 | 165] LR: 0.014504
batch Size 303
Epoch: [162][0/166]	Time 0.165 (0.165)	Data 0.311 (0.311)	Loss 0.2688 (0.2688)	Acc@1 98.020 (98.020)	Acc@5 100.000 (100.000)
Epoch: [162][64/166]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.3236 (0.3275)	Acc@1 97.030 (95.725)	Acc@5 100.000 (99.949)
Epoch: [162][128/166]	Time 0.131 (0.127)	Data 0.000 (0.003)	Loss 0.3382 (0.3188)	Acc@1 95.710 (95.976)	Acc@5 100.000 (99.964)
Max memory in training epoch: 66.9627392
lr: 0.0145038984735413
1

Epoch: [163 | 165] LR: 0.014504
batch Size 303
Epoch: [163][0/166]	Time 0.192 (0.192)	Data 0.278 (0.278)	Loss 0.2924 (0.2924)	Acc@1 96.700 (96.700)	Acc@5 100.000 (100.000)
Epoch: [163][64/166]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.3738 (0.3786)	Acc@1 94.719 (94.044)	Acc@5 99.670 (99.898)
Epoch: [163][128/166]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.3024 (0.3530)	Acc@1 96.700 (94.883)	Acc@5 100.000 (99.913)
Max memory in training epoch: 67.0483456
Drin!!
old memory: 665909760
new memory: 670483456
Faktor: 1.0068683420408195
New batch Size kleiner 305!!
lr: 0.0145038984735413
1

Epoch: [164 | 165] LR: 0.014504
batch Size 305
Epoch: [164][0/166]	Time 0.178 (0.178)	Data 0.266 (0.266)	Loss 0.2993 (0.2993)	Acc@1 96.700 (96.700)	Acc@5 100.000 (100.000)
Epoch: [164][64/166]	Time 0.133 (0.127)	Data 0.000 (0.004)	Loss 0.3390 (0.3718)	Acc@1 94.389 (94.090)	Acc@5 100.000 (99.914)
Epoch: [164][128/166]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.3240 (0.3486)	Acc@1 97.360 (94.970)	Acc@5 99.670 (99.933)
Max memory in training epoch: 67.0483456
lr: 0.0145038984735413
1

Epoch: [165 | 165] LR: 0.014504
batch Size 305
Epoch: [165][0/166]	Time 0.185 (0.185)	Data 0.306 (0.306)	Loss 0.3303 (0.3303)	Acc@1 97.030 (97.030)	Acc@5 99.670 (99.670)
Epoch: [165][64/166]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.3267 (0.3916)	Acc@1 95.710 (93.628)	Acc@5 100.000 (99.868)
Epoch: [165][128/166]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.2904 (0.3626)	Acc@1 97.030 (94.423)	Acc@5 100.000 (99.908)
Max memory in training epoch: 67.0483456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.5
Max memory: 87.9314432
 21.633s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2279
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1459712
lr: 0.017280035290742565
1

Epoch: [166 | 170] LR: 0.017280
batch Size 305
Epoch: [166][0/164]	Time 0.196 (0.196)	Data 0.312 (0.312)	Loss 0.3166 (0.3166)	Acc@1 97.705 (97.705)	Acc@5 99.672 (99.672)
Epoch: [166][64/164]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.3484 (0.3160)	Acc@1 93.443 (95.768)	Acc@5 100.000 (99.924)
Epoch: [166][128/164]	Time 0.122 (0.126)	Data 0.000 (0.003)	Loss 0.3319 (0.3164)	Acc@1 95.410 (95.809)	Acc@5 100.000 (99.936)
Max memory in training epoch: 69.223424
lr: 0.017280035290742565
1

Epoch: [167 | 170] LR: 0.017280
batch Size 305
Epoch: [167][0/164]	Time 0.186 (0.186)	Data 0.277 (0.277)	Loss 0.3316 (0.3316)	Acc@1 94.098 (94.098)	Acc@5 99.672 (99.672)
Epoch: [167][64/164]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.2937 (0.3162)	Acc@1 96.393 (95.707)	Acc@5 100.000 (99.965)
Epoch: [167][128/164]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.3249 (0.3162)	Acc@1 96.393 (95.679)	Acc@5 100.000 (99.949)
Max memory in training epoch: 68.9970688
lr: 0.017280035290742565
1

Epoch: [168 | 170] LR: 0.017280
batch Size 305
Epoch: [168][0/164]	Time 0.179 (0.179)	Data 0.307 (0.307)	Loss 0.2852 (0.2852)	Acc@1 96.721 (96.721)	Acc@5 100.000 (100.000)
Epoch: [168][64/164]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.2919 (0.3077)	Acc@1 96.393 (96.005)	Acc@5 100.000 (99.955)
Epoch: [168][128/164]	Time 0.122 (0.127)	Data 0.000 (0.003)	Loss 0.2978 (0.3113)	Acc@1 96.393 (95.905)	Acc@5 100.000 (99.962)
Max memory in training epoch: 69.1735552
Drin!!
old memory: 670483456
new memory: 691735552
Faktor: 1.031696674705125
New batch Size kleiner 314!!
lr: 0.017280035290742565
1

Epoch: [169 | 170] LR: 0.017280
batch Size 314
Epoch: [169][0/164]	Time 0.187 (0.187)	Data 0.274 (0.274)	Loss 0.3576 (0.3576)	Acc@1 93.770 (93.770)	Acc@5 100.000 (100.000)
Epoch: [169][64/164]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.3190 (0.3106)	Acc@1 95.410 (95.823)	Acc@5 99.672 (99.919)
Epoch: [169][128/164]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.3696 (0.3105)	Acc@1 93.443 (95.822)	Acc@5 100.000 (99.929)
Max memory in training epoch: 69.1735552
lr: 0.017280035290742565
1

Epoch: [170 | 170] LR: 0.017280
batch Size 314
Epoch: [170][0/164]	Time 0.156 (0.156)	Data 0.312 (0.312)	Loss 0.2673 (0.2673)	Acc@1 97.377 (97.377)	Acc@5 100.000 (100.000)
Epoch: [170][64/164]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.3055 (0.3029)	Acc@1 94.426 (95.990)	Acc@5 100.000 (99.929)
Epoch: [170][128/164]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.3134 (0.3037)	Acc@1 95.410 (95.890)	Acc@5 99.672 (99.944)
Max memory in training epoch: 69.1735552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.05
Max memory: 87.9314432
 21.202s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3863
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1459712
lr: 0.021195043286301427
1

Epoch: [171 | 175] LR: 0.021195
batch Size 314
Epoch: [171][0/160]	Time 0.203 (0.203)	Data 0.369 (0.369)	Loss 0.3315 (0.3315)	Acc@1 94.586 (94.586)	Acc@5 100.000 (100.000)
Epoch: [171][64/160]	Time 0.129 (0.129)	Data 0.000 (0.006)	Loss 0.2836 (0.3025)	Acc@1 97.134 (96.007)	Acc@5 100.000 (99.941)
Epoch: [171][128/160]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.4042 (0.3176)	Acc@1 92.038 (95.349)	Acc@5 100.000 (99.946)
Max memory in training epoch: 70.6002432
lr: 0.021195043286301427
1

Epoch: [172 | 175] LR: 0.021195
batch Size 314
Epoch: [172][0/160]	Time 0.168 (0.168)	Data 0.307 (0.307)	Loss 0.3385 (0.3385)	Acc@1 93.949 (93.949)	Acc@5 100.000 (100.000)
Epoch: [172][64/160]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.3018 (0.3375)	Acc@1 95.860 (94.527)	Acc@5 100.000 (99.941)
Epoch: [172][128/160]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.3755 (0.3363)	Acc@1 92.675 (94.569)	Acc@5 99.682 (99.931)
Max memory in training epoch: 70.287616
lr: 0.021195043286301427
1

Epoch: [173 | 175] LR: 0.021195
batch Size 314
Epoch: [173][0/160]	Time 0.165 (0.165)	Data 0.308 (0.308)	Loss 0.2964 (0.2964)	Acc@1 95.223 (95.223)	Acc@5 100.000 (100.000)
Epoch: [173][64/160]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.2942 (0.3211)	Acc@1 95.223 (95.140)	Acc@5 100.000 (99.951)
Epoch: [173][128/160]	Time 0.126 (0.128)	Data 0.000 (0.003)	Loss 0.3610 (0.3234)	Acc@1 93.949 (95.124)	Acc@5 100.000 (99.943)
Max memory in training epoch: 70.287616
Drin!!
old memory: 691735552
new memory: 702876160
Faktor: 1.0161052991533968
New batch Size kleiner 319!!
lr: 0.021195043286301427
1

Epoch: [174 | 175] LR: 0.021195
batch Size 319
Epoch: [174][0/160]	Time 0.176 (0.176)	Data 0.306 (0.306)	Loss 0.3427 (0.3427)	Acc@1 94.904 (94.904)	Acc@5 99.682 (99.682)
Epoch: [174][64/160]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.2989 (0.3233)	Acc@1 96.497 (95.061)	Acc@5 100.000 (99.946)
Epoch: [174][128/160]	Time 0.129 (0.129)	Data 0.000 (0.003)	Loss 0.3664 (0.3268)	Acc@1 94.268 (94.986)	Acc@5 99.363 (99.946)
Max memory in training epoch: 70.287616
lr: 0.021195043286301427
1

Epoch: [175 | 175] LR: 0.021195
batch Size 319
Epoch: [175][0/160]	Time 0.161 (0.161)	Data 0.326 (0.326)	Loss 0.3568 (0.3568)	Acc@1 94.586 (94.586)	Acc@5 100.000 (100.000)
Epoch: [175][64/160]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.3299 (0.3246)	Acc@1 95.223 (95.130)	Acc@5 100.000 (99.912)
Epoch: [175][128/160]	Time 0.130 (0.128)	Data 0.000 (0.003)	Loss 0.3180 (0.3306)	Acc@1 95.860 (94.912)	Acc@5 100.000 (99.921)
Max memory in training epoch: 70.287616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.58
Max memory: 87.7415936
 20.927s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6690
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1459712
lr: 0.02641101097003967
1

Epoch: [176 | 180] LR: 0.026411
batch Size 319
Epoch: [176][0/157]	Time 0.212 (0.212)	Data 0.295 (0.295)	Loss 0.3030 (0.3030)	Acc@1 95.611 (95.611)	Acc@5 100.000 (100.000)
Epoch: [176][64/157]	Time 0.151 (0.136)	Data 0.000 (0.005)	Loss 0.3241 (0.3233)	Acc@1 94.044 (94.984)	Acc@5 100.000 (99.937)
Epoch: [176][128/157]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.3691 (0.3402)	Acc@1 91.850 (94.404)	Acc@5 99.373 (99.920)
Max memory in training epoch: 70.8936192
lr: 0.02641101097003967
1

Epoch: [177 | 180] LR: 0.026411
batch Size 319
Epoch: [177][0/157]	Time 0.198 (0.198)	Data 0.281 (0.281)	Loss 0.3561 (0.3561)	Acc@1 91.536 (91.536)	Acc@5 100.000 (100.000)
Epoch: [177][64/157]	Time 0.123 (0.131)	Data 0.000 (0.005)	Loss 0.3567 (0.3579)	Acc@1 93.730 (93.909)	Acc@5 100.000 (99.904)
Epoch: [177][128/157]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.3939 (0.3605)	Acc@1 94.044 (93.786)	Acc@5 100.000 (99.888)
Max memory in training epoch: 70.7459584
lr: 0.02641101097003967
1

Epoch: [178 | 180] LR: 0.026411
batch Size 319
Epoch: [178][0/157]	Time 0.157 (0.157)	Data 0.320 (0.320)	Loss 0.3943 (0.3943)	Acc@1 91.850 (91.850)	Acc@5 100.000 (100.000)
Epoch: [178][64/157]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.3482 (0.3468)	Acc@1 94.671 (94.415)	Acc@5 100.000 (99.894)
Epoch: [178][128/157]	Time 0.132 (0.131)	Data 0.000 (0.003)	Loss 0.3269 (0.3539)	Acc@1 94.984 (94.112)	Acc@5 100.000 (99.905)
Max memory in training epoch: 70.7394048
Drin!!
old memory: 702876160
new memory: 707394048
Faktor: 1.0064277155167705
New batch Size kleiner 321!!
lr: 0.02641101097003967
1

Epoch: [179 | 180] LR: 0.026411
batch Size 321
Epoch: [179][0/157]	Time 0.180 (0.180)	Data 0.326 (0.326)	Loss 0.3440 (0.3440)	Acc@1 94.984 (94.984)	Acc@5 100.000 (100.000)
Epoch: [179][64/157]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.3273 (0.3543)	Acc@1 94.044 (94.000)	Acc@5 100.000 (99.932)
Epoch: [179][128/157]	Time 0.121 (0.130)	Data 0.000 (0.003)	Loss 0.3655 (0.3578)	Acc@1 92.163 (93.918)	Acc@5 100.000 (99.920)
Max memory in training epoch: 70.7394048
lr: 0.02641101097003967
1

Epoch: [180 | 180] LR: 0.026411
batch Size 321
Epoch: [180][0/157]	Time 0.157 (0.157)	Data 0.284 (0.284)	Loss 0.2843 (0.2843)	Acc@1 96.865 (96.865)	Acc@5 100.000 (100.000)
Epoch: [180][64/157]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.3663 (0.3561)	Acc@1 94.044 (94.010)	Acc@5 100.000 (99.923)
Epoch: [180][128/157]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.3674 (0.3594)	Acc@1 93.417 (93.942)	Acc@5 99.373 (99.920)
Max memory in training epoch: 70.7394048
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  88.24
Max memory: 87.7415936
 20.654s  BSize 2
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6595
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
batch_size berechnet: 250;389.1 ; lr: 0.1
lr: 0.09765625
1

Epoch: [1 | 5] LR: 0.097656
batch Size 250
Epoch: [1][0/200]	Time 0.194 (0.194)	Data 0.284 (0.284)	Loss 3.2591 (3.2591)	Acc@1 10.800 (10.800)	Acc@5 52.000 (52.000)
Epoch: [1][64/200]	Time 0.119 (0.126)	Data 0.000 (0.005)	Loss 2.4506 (2.6684)	Acc@1 29.600 (23.815)	Acc@5 86.400 (77.705)
Epoch: [1][128/200]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 2.3290 (2.5025)	Acc@1 36.000 (29.116)	Acc@5 86.800 (82.642)
Epoch: [1][192/200]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 1.9159 (2.3716)	Acc@1 53.200 (33.915)	Acc@5 94.800 (85.600)
Max memory in training epoch: 66.4657408
lr: 0.09765625
1

Epoch: [2 | 5] LR: 0.097656
batch Size 250
Epoch: [2][0/200]	Time 0.192 (0.192)	Data 0.295 (0.295)	Loss 1.9454 (1.9454)	Acc@1 47.200 (47.200)	Acc@5 93.200 (93.200)
Epoch: [2][64/200]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 1.8333 (1.9165)	Acc@1 53.200 (50.825)	Acc@5 94.800 (93.785)
Epoch: [2][128/200]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 1.6500 (1.8289)	Acc@1 60.000 (53.625)	Acc@5 95.200 (94.505)
Epoch: [2][192/200]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 1.5952 (1.7633)	Acc@1 58.000 (55.840)	Acc@5 95.600 (95.007)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [3 | 5] LR: 0.097656
batch Size 250
Epoch: [3][0/200]	Time 0.152 (0.152)	Data 0.294 (0.294)	Loss 1.5188 (1.5188)	Acc@1 68.400 (68.400)	Acc@5 96.400 (96.400)
Epoch: [3][64/200]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 1.4957 (1.5164)	Acc@1 67.600 (64.117)	Acc@5 93.600 (96.535)
Epoch: [3][128/200]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 1.3517 (1.4693)	Acc@1 69.600 (65.485)	Acc@5 99.200 (96.878)
Epoch: [3][192/200]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 1.2462 (1.4253)	Acc@1 72.400 (66.736)	Acc@5 97.600 (97.142)
Max memory in training epoch: 66.0135424
Drin!!
old memory: 0
new memory: 660135424
lr: 0.09765625
1

Epoch: [4 | 5] LR: 0.097656
batch Size 250
Epoch: [4][0/200]	Time 0.192 (0.192)	Data 0.271 (0.271)	Loss 1.2224 (1.2224)	Acc@1 72.800 (72.800)	Acc@5 97.600 (97.600)
Epoch: [4][64/200]	Time 0.138 (0.126)	Data 0.000 (0.004)	Loss 1.2071 (1.2485)	Acc@1 74.400 (72.148)	Acc@5 98.000 (97.945)
Epoch: [4][128/200]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 1.0645 (1.2391)	Acc@1 80.000 (72.301)	Acc@5 98.800 (98.062)
Epoch: [4][192/200]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.2163 (1.2206)	Acc@1 72.400 (72.692)	Acc@5 98.400 (98.095)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [5 | 5] LR: 0.097656
batch Size 250
Epoch: [5][0/200]	Time 0.156 (0.156)	Data 0.317 (0.317)	Loss 1.0744 (1.0744)	Acc@1 77.600 (77.600)	Acc@5 99.200 (99.200)
Epoch: [5][64/200]	Time 0.119 (0.128)	Data 0.000 (0.005)	Loss 1.0938 (1.1147)	Acc@1 76.000 (75.175)	Acc@5 98.800 (98.455)
Epoch: [5][128/200]	Time 0.118 (0.127)	Data 0.000 (0.003)	Loss 1.1546 (1.1045)	Acc@1 72.800 (75.491)	Acc@5 98.000 (98.505)
Epoch: [5][192/200]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.9913 (1.0916)	Acc@1 81.600 (75.948)	Acc@5 99.200 (98.518)
Max memory in training epoch: 66.0135424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  72.52
Max memory: 103.3835008
 25.682s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3398
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.095367431640625
1

Epoch: [6 | 10] LR: 0.095367
batch Size 250
Epoch: [6][0/200]	Time 0.181 (0.181)	Data 0.305 (0.305)	Loss 1.0041 (1.0041)	Acc@1 79.600 (79.600)	Acc@5 98.800 (98.800)
Epoch: [6][64/200]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 1.0264 (1.0078)	Acc@1 78.000 (78.203)	Acc@5 97.600 (98.886)
Epoch: [6][128/200]	Time 0.123 (0.129)	Data 0.000 (0.003)	Loss 1.0532 (1.0113)	Acc@1 78.400 (77.997)	Acc@5 97.200 (98.825)
Epoch: [6][192/200]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.9383 (1.0022)	Acc@1 78.000 (78.110)	Acc@5 99.200 (98.792)
Max memory in training epoch: 66.4656384
lr: 0.095367431640625
1

Epoch: [7 | 10] LR: 0.095367
batch Size 250
Epoch: [7][0/200]	Time 0.174 (0.174)	Data 0.279 (0.279)	Loss 0.9589 (0.9589)	Acc@1 76.400 (76.400)	Acc@5 99.600 (99.600)
Epoch: [7][64/200]	Time 0.124 (0.127)	Data 0.000 (0.004)	Loss 1.0565 (0.9506)	Acc@1 76.800 (79.040)	Acc@5 98.400 (98.615)
Epoch: [7][128/200]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 1.0289 (0.9524)	Acc@1 74.000 (78.850)	Acc@5 98.800 (98.664)
Epoch: [7][192/200]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.7947 (0.9480)	Acc@1 82.800 (78.955)	Acc@5 100.000 (98.746)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [8 | 10] LR: 0.095367
batch Size 250
Epoch: [8][0/200]	Time 0.163 (0.163)	Data 0.283 (0.283)	Loss 0.8553 (0.8553)	Acc@1 79.600 (79.600)	Acc@5 99.600 (99.600)
Epoch: [8][64/200]	Time 0.137 (0.131)	Data 0.000 (0.005)	Loss 0.9637 (0.9106)	Acc@1 75.600 (79.674)	Acc@5 98.800 (98.960)
Epoch: [8][128/200]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.9338 (0.9006)	Acc@1 79.600 (79.984)	Acc@5 98.800 (98.955)
Epoch: [8][192/200]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.8301 (0.8927)	Acc@1 83.600 (80.269)	Acc@5 99.600 (98.945)
Max memory in training epoch: 66.01344
Drin!!
old memory: 660135424
new memory: 660134400
Faktor: 0.9999984488031353
New batch Size größer 253!!
lr: 0.095367431640625
1

Epoch: [9 | 10] LR: 0.095367
batch Size 253
Epoch: [9][0/200]	Time 0.155 (0.155)	Data 0.286 (0.286)	Loss 0.7807 (0.7807)	Acc@1 84.400 (84.400)	Acc@5 99.200 (99.200)
Epoch: [9][64/200]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.9622 (0.8601)	Acc@1 76.400 (81.015)	Acc@5 99.600 (98.948)
Epoch: [9][128/200]	Time 0.146 (0.128)	Data 0.000 (0.002)	Loss 0.9874 (0.8638)	Acc@1 76.800 (80.964)	Acc@5 98.800 (98.964)
Epoch: [9][192/200]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.9072 (0.8638)	Acc@1 79.600 (80.920)	Acc@5 98.400 (99.001)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [10 | 10] LR: 0.095367
batch Size 253
Epoch: [10][0/200]	Time 0.156 (0.156)	Data 0.278 (0.278)	Loss 0.7845 (0.7845)	Acc@1 84.000 (84.000)	Acc@5 98.400 (98.400)
Epoch: [10][64/200]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7848 (0.8372)	Acc@1 81.600 (81.680)	Acc@5 100.000 (99.071)
Epoch: [10][128/200]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.7332 (0.8331)	Acc@1 84.000 (81.721)	Acc@5 99.600 (99.023)
Epoch: [10][192/200]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.8674 (0.8365)	Acc@1 81.200 (81.484)	Acc@5 98.800 (99.020)
Max memory in training epoch: 66.01344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  79.22
Max memory: 103.3833984
 26.037s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6403
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.09424984455108643
1

Epoch: [11 | 15] LR: 0.094250
batch Size 253
Epoch: [11][0/198]	Time 0.208 (0.208)	Data 0.258 (0.258)	Loss 0.6404 (0.6404)	Acc@1 91.700 (91.700)	Acc@5 98.814 (98.814)
Epoch: [11][64/198]	Time 0.125 (0.133)	Data 0.000 (0.004)	Loss 0.8234 (0.7899)	Acc@1 82.213 (82.749)	Acc@5 99.209 (99.161)
Epoch: [11][128/198]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8331 (0.8087)	Acc@1 80.632 (82.229)	Acc@5 98.419 (99.145)
Epoch: [11][192/198]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8390 (0.8111)	Acc@1 80.237 (82.031)	Acc@5 98.814 (99.132)
Max memory in training epoch: 66.5037312
lr: 0.09424984455108643
1

Epoch: [12 | 15] LR: 0.094250
batch Size 253
Epoch: [12][0/198]	Time 0.184 (0.184)	Data 0.285 (0.285)	Loss 0.7264 (0.7264)	Acc@1 83.399 (83.399)	Acc@5 100.000 (100.000)
Epoch: [12][64/198]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7760 (0.7909)	Acc@1 82.609 (82.858)	Acc@5 98.814 (99.282)
Epoch: [12][128/198]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.7371 (0.7986)	Acc@1 81.028 (82.566)	Acc@5 99.605 (99.203)
Epoch: [12][192/198]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7844 (0.7957)	Acc@1 81.028 (82.584)	Acc@5 99.209 (99.189)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [13 | 15] LR: 0.094250
batch Size 253
Epoch: [13][0/198]	Time 0.190 (0.190)	Data 0.281 (0.281)	Loss 0.8179 (0.8179)	Acc@1 81.423 (81.423)	Acc@5 98.419 (98.419)
Epoch: [13][64/198]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.8591 (0.7944)	Acc@1 79.447 (82.560)	Acc@5 98.419 (99.137)
Epoch: [13][128/198]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7557 (0.7895)	Acc@1 86.561 (82.793)	Acc@5 99.209 (99.133)
Epoch: [13][192/198]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.8211 (0.7883)	Acc@1 79.447 (82.852)	Acc@5 98.814 (99.146)
Max memory in training epoch: 66.277632
Drin!!
old memory: 660134400
new memory: 662776320
Faktor: 1.0040020941190158
New batch Size kleiner 254!!
lr: 0.09424984455108643
1

Epoch: [14 | 15] LR: 0.094250
batch Size 254
Epoch: [14][0/198]	Time 0.166 (0.166)	Data 0.287 (0.287)	Loss 0.8311 (0.8311)	Acc@1 82.213 (82.213)	Acc@5 98.419 (98.419)
Epoch: [14][64/198]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.8909 (0.7735)	Acc@1 80.632 (83.235)	Acc@5 97.628 (99.209)
Epoch: [14][128/198]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7808 (0.7818)	Acc@1 84.585 (83.041)	Acc@5 99.209 (99.176)
Epoch: [14][192/198]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7439 (0.7823)	Acc@1 85.375 (83.033)	Acc@5 99.605 (99.162)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [15 | 15] LR: 0.094250
batch Size 254
Epoch: [15][0/198]	Time 0.158 (0.158)	Data 0.297 (0.297)	Loss 0.6603 (0.6603)	Acc@1 86.957 (86.957)	Acc@5 100.000 (100.000)
Epoch: [15][64/198]	Time 0.140 (0.130)	Data 0.000 (0.005)	Loss 0.8392 (0.7572)	Acc@1 82.213 (83.630)	Acc@5 99.209 (99.246)
Epoch: [15][128/198]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8290 (0.7679)	Acc@1 83.794 (83.313)	Acc@5 98.419 (99.237)
Epoch: [15][192/198]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8033 (0.7710)	Acc@1 83.004 (83.325)	Acc@5 98.419 (99.224)
Max memory in training epoch: 66.277632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.27
Max memory: 103.3833984
 25.972s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 344
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.09351351764053106
1

Epoch: [16 | 20] LR: 0.093514
batch Size 254
Epoch: [16][0/197]	Time 0.183 (0.183)	Data 0.251 (0.251)	Loss 0.8353 (0.8353)	Acc@1 81.496 (81.496)	Acc@5 99.213 (99.213)
Epoch: [16][64/197]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 0.7669 (0.7404)	Acc@1 82.283 (84.428)	Acc@5 99.213 (99.400)
Epoch: [16][128/197]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7787 (0.7524)	Acc@1 83.071 (84.154)	Acc@5 99.606 (99.313)
Epoch: [16][192/197]	Time 0.126 (0.131)	Data 0.000 (0.001)	Loss 0.7166 (0.7569)	Acc@1 84.646 (84.046)	Acc@5 98.819 (99.274)
Max memory in training epoch: 66.5164288
lr: 0.09351351764053106
1

Epoch: [17 | 20] LR: 0.093514
batch Size 254
Epoch: [17][0/197]	Time 0.156 (0.156)	Data 0.313 (0.313)	Loss 0.7826 (0.7826)	Acc@1 79.921 (79.921)	Acc@5 100.000 (100.000)
Epoch: [17][64/197]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.7158 (0.7418)	Acc@1 85.827 (84.579)	Acc@5 99.213 (99.328)
Epoch: [17][128/197]	Time 0.124 (0.129)	Data 0.000 (0.003)	Loss 0.7130 (0.7517)	Acc@1 87.402 (84.151)	Acc@5 98.819 (99.316)
Epoch: [17][192/197]	Time 0.148 (0.129)	Data 0.000 (0.002)	Loss 0.6727 (0.7491)	Acc@1 87.402 (84.205)	Acc@5 99.606 (99.321)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [18 | 20] LR: 0.093514
batch Size 254
Epoch: [18][0/197]	Time 0.187 (0.187)	Data 0.326 (0.326)	Loss 0.6771 (0.6771)	Acc@1 86.614 (86.614)	Acc@5 100.000 (100.000)
Epoch: [18][64/197]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.8326 (0.7326)	Acc@1 81.102 (84.561)	Acc@5 98.819 (99.382)
Epoch: [18][128/197]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.7626 (0.7485)	Acc@1 83.071 (84.093)	Acc@5 99.213 (99.313)
Epoch: [18][192/197]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.8217 (0.7503)	Acc@1 81.496 (84.083)	Acc@5 98.031 (99.302)
Max memory in training epoch: 66.365696
Drin!!
old memory: 662776320
new memory: 663656960
Faktor: 1.0013287137355782
New batch Size kleiner 254!!
lr: 0.09351351764053106
1

Epoch: [19 | 20] LR: 0.093514
batch Size 254
Epoch: [19][0/197]	Time 0.201 (0.201)	Data 0.325 (0.325)	Loss 0.7127 (0.7127)	Acc@1 87.008 (87.008)	Acc@5 99.213 (99.213)
Epoch: [19][64/197]	Time 0.150 (0.133)	Data 0.000 (0.005)	Loss 0.7547 (0.7535)	Acc@1 85.039 (83.998)	Acc@5 98.819 (99.243)
Epoch: [19][128/197]	Time 0.125 (0.131)	Data 0.000 (0.003)	Loss 0.7770 (0.7444)	Acc@1 81.496 (84.359)	Acc@5 99.213 (99.271)
Epoch: [19][192/197]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.7212 (0.7467)	Acc@1 83.858 (84.174)	Acc@5 99.213 (99.286)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [20 | 20] LR: 0.093514
batch Size 254
Epoch: [20][0/197]	Time 0.164 (0.164)	Data 0.293 (0.293)	Loss 0.6743 (0.6743)	Acc@1 87.402 (87.402)	Acc@5 99.213 (99.213)
Epoch: [20][64/197]	Time 0.138 (0.135)	Data 0.000 (0.005)	Loss 0.6909 (0.7319)	Acc@1 83.858 (84.585)	Acc@5 99.606 (99.376)
Epoch: [20][128/197]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.6777 (0.7333)	Acc@1 88.583 (84.688)	Acc@5 99.213 (99.332)
Epoch: [20][192/197]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7572 (0.7494)	Acc@1 82.677 (84.289)	Acc@5 99.606 (99.311)
Max memory in training epoch: 66.365696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 485078 ; 487386 ; 0.9952645336550496
[INFO] Storing checkpoint...
  75.53
Max memory: 103.3833984
 26.526s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5581
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2015744
lr: 0.09278294328396441
1

Epoch: [21 | 25] LR: 0.092783
batch Size 254
Epoch: [21][0/197]	Time 0.197 (0.197)	Data 0.294 (0.294)	Loss 0.7504 (0.7504)	Acc@1 84.646 (84.646)	Acc@5 98.819 (98.819)
Epoch: [21][64/197]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.7291 (0.7053)	Acc@1 86.220 (85.609)	Acc@5 99.213 (99.412)
Epoch: [21][128/197]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6933 (0.7207)	Acc@1 88.976 (85.161)	Acc@5 98.425 (99.344)
Epoch: [21][192/197]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7353 (0.7275)	Acc@1 84.646 (84.923)	Acc@5 99.606 (99.304)
Max memory in training epoch: 66.5127424
lr: 0.09278294328396441
1

Epoch: [22 | 25] LR: 0.092783
batch Size 254
Epoch: [22][0/197]	Time 0.198 (0.198)	Data 0.287 (0.287)	Loss 0.6832 (0.6832)	Acc@1 87.008 (87.008)	Acc@5 100.000 (100.000)
Epoch: [22][64/197]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.6770 (0.7260)	Acc@1 84.646 (84.621)	Acc@5 99.606 (99.370)
Epoch: [22][128/197]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7055 (0.7441)	Acc@1 84.646 (84.322)	Acc@5 100.000 (99.274)
Epoch: [22][192/197]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8257 (0.7416)	Acc@1 78.740 (84.478)	Acc@5 99.213 (99.300)
Max memory in training epoch: 66.3620096
lr: 0.09278294328396441
1

Epoch: [23 | 25] LR: 0.092783
batch Size 254
Epoch: [23][0/197]	Time 0.179 (0.179)	Data 0.293 (0.293)	Loss 0.7284 (0.7284)	Acc@1 84.646 (84.646)	Acc@5 100.000 (100.000)
Epoch: [23][64/197]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.7036 (0.7219)	Acc@1 86.220 (85.409)	Acc@5 99.606 (99.515)
Epoch: [23][128/197]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.7388 (0.7357)	Acc@1 84.252 (84.783)	Acc@5 99.213 (99.347)
Epoch: [23][192/197]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8053 (0.7386)	Acc@1 80.709 (84.686)	Acc@5 99.213 (99.323)
Max memory in training epoch: 66.3620096
Drin!!
old memory: 663656960
new memory: 663620096
Faktor: 0.9999444532307775
New batch Size größer 256!!
lr: 0.09278294328396441
1

Epoch: [24 | 25] LR: 0.092783
batch Size 256
Epoch: [24][0/197]	Time 0.187 (0.187)	Data 0.299 (0.299)	Loss 0.7009 (0.7009)	Acc@1 85.039 (85.039)	Acc@5 99.606 (99.606)
Epoch: [24][64/197]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.7304 (0.7041)	Acc@1 85.433 (85.494)	Acc@5 99.606 (99.425)
Epoch: [24][128/197]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8074 (0.7183)	Acc@1 83.071 (85.137)	Acc@5 98.819 (99.399)
Epoch: [24][192/197]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8201 (0.7286)	Acc@1 81.102 (84.831)	Acc@5 99.213 (99.343)
Max memory in training epoch: 66.3620096
lr: 0.09278294328396441
1

Epoch: [25 | 25] LR: 0.092783
batch Size 256
Epoch: [25][0/197]	Time 0.180 (0.180)	Data 0.312 (0.312)	Loss 0.7374 (0.7374)	Acc@1 84.252 (84.252)	Acc@5 99.213 (99.213)
Epoch: [25][64/197]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6466 (0.7120)	Acc@1 86.614 (85.245)	Acc@5 98.819 (99.406)
Epoch: [25][128/197]	Time 0.144 (0.130)	Data 0.000 (0.003)	Loss 0.7045 (0.7194)	Acc@1 84.646 (85.100)	Acc@5 99.606 (99.408)
Epoch: [25][192/197]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6926 (0.7258)	Acc@1 87.795 (84.976)	Acc@5 99.213 (99.343)
Max memory in training epoch: 66.3620096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 478154 ; 485078 ; 0.9857260069514594
[INFO] Storing checkpoint...
  74.45
Max memory: 103.3806336
 25.855s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2645
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1988096
lr: 0.09278294328396441
1

Epoch: [26 | 30] LR: 0.092783
batch Size 256
Epoch: [26][0/196]	Time 0.186 (0.186)	Data 0.257 (0.257)	Loss 0.7286 (0.7286)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.123 (0.131)	Data 0.000 (0.004)	Loss 0.6448 (0.6893)	Acc@1 86.719 (86.424)	Acc@5 99.609 (99.351)
Epoch: [26][128/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.7335 (0.7074)	Acc@1 80.859 (85.662)	Acc@5 99.609 (99.361)
Epoch: [26][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7132 (0.7134)	Acc@1 83.594 (85.403)	Acc@5 99.609 (99.381)
Max memory in training epoch: 66.631936
lr: 0.09278294328396441
1

Epoch: [27 | 30] LR: 0.092783
batch Size 256
Epoch: [27][0/196]	Time 0.180 (0.180)	Data 0.290 (0.290)	Loss 0.6177 (0.6177)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [27][64/196]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.7003 (0.6883)	Acc@1 86.328 (86.280)	Acc@5 99.609 (99.519)
Epoch: [27][128/196]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.7010 (0.7013)	Acc@1 85.156 (85.901)	Acc@5 99.219 (99.458)
Epoch: [27][192/196]	Time 0.129 (0.134)	Data 0.000 (0.002)	Loss 0.7138 (0.7111)	Acc@1 83.594 (85.521)	Acc@5 99.609 (99.383)
Max memory in training epoch: 66.5270784
lr: 0.09278294328396441
1

Epoch: [28 | 30] LR: 0.092783
batch Size 256
Epoch: [28][0/196]	Time 0.159 (0.159)	Data 0.304 (0.304)	Loss 0.7303 (0.7303)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.7014 (0.7112)	Acc@1 83.984 (85.300)	Acc@5 99.609 (99.399)
Epoch: [28][128/196]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.7387 (0.7093)	Acc@1 84.766 (85.553)	Acc@5 99.609 (99.382)
Epoch: [28][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7558 (0.7210)	Acc@1 80.469 (85.160)	Acc@5 100.000 (99.348)
Max memory in training epoch: 66.5270784
Drin!!
old memory: 663620096
new memory: 665270784
Faktor: 1.002487399055498
New batch Size kleiner 256!!
lr: 0.09278294328396441
1

Epoch: [29 | 30] LR: 0.092783
batch Size 256
Epoch: [29][0/196]	Time 0.181 (0.181)	Data 0.303 (0.303)	Loss 0.7314 (0.7314)	Acc@1 87.109 (87.109)	Acc@5 98.047 (98.047)
Epoch: [29][64/196]	Time 0.149 (0.132)	Data 0.000 (0.005)	Loss 0.6620 (0.7166)	Acc@1 87.109 (85.306)	Acc@5 99.219 (99.363)
Epoch: [29][128/196]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.7573 (0.7164)	Acc@1 82.422 (85.341)	Acc@5 100.000 (99.397)
Epoch: [29][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8170 (0.7136)	Acc@1 82.031 (85.361)	Acc@5 98.047 (99.401)
Max memory in training epoch: 66.5270784
lr: 0.09278294328396441
1

Epoch: [30 | 30] LR: 0.092783
batch Size 256
Epoch: [30][0/196]	Time 0.191 (0.191)	Data 0.280 (0.280)	Loss 0.7038 (0.7038)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.139 (0.131)	Data 0.000 (0.004)	Loss 0.6803 (0.7067)	Acc@1 86.328 (85.715)	Acc@5 99.609 (99.333)
Epoch: [30][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6775 (0.7133)	Acc@1 86.328 (85.417)	Acc@5 98.828 (99.400)
Epoch: [30][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7485 (0.7175)	Acc@1 86.719 (85.286)	Acc@5 98.438 (99.379)
Max memory in training epoch: 66.5270784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 455072 ; 478154 ; 0.9517268495087357
[INFO] Storing checkpoint...
  78.72
Max memory: 103.3723392
 26.095s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7871
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.189696
lr: 0.09278294328396441
1

Epoch: [31 | 35] LR: 0.092783
batch Size 256
Epoch: [31][0/196]	Time 0.206 (0.206)	Data 0.259 (0.259)	Loss 0.6692 (0.6692)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [31][64/196]	Time 0.135 (0.131)	Data 0.000 (0.004)	Loss 0.7129 (0.6835)	Acc@1 83.984 (86.406)	Acc@5 99.609 (99.489)
Epoch: [31][128/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.8366 (0.6979)	Acc@1 77.344 (86.062)	Acc@5 99.219 (99.458)
Epoch: [31][192/196]	Time 0.120 (0.131)	Data 0.000 (0.002)	Loss 0.7057 (0.7004)	Acc@1 87.891 (85.974)	Acc@5 100.000 (99.478)
Max memory in training epoch: 66.261248
lr: 0.09278294328396441
1

Epoch: [32 | 35] LR: 0.092783
batch Size 256
Epoch: [32][0/196]	Time 0.183 (0.183)	Data 0.277 (0.277)	Loss 0.6743 (0.6743)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.128 (0.128)	Data 0.000 (0.004)	Loss 0.7291 (0.7021)	Acc@1 84.375 (86.130)	Acc@5 98.828 (99.489)
Epoch: [32][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6407 (0.6985)	Acc@1 87.891 (86.034)	Acc@5 99.219 (99.464)
Epoch: [32][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7153 (0.7043)	Acc@1 85.938 (85.848)	Acc@5 98.828 (99.443)
Max memory in training epoch: 66.1367296
lr: 0.09278294328396441
1

Epoch: [33 | 35] LR: 0.092783
batch Size 256
Epoch: [33][0/196]	Time 0.186 (0.186)	Data 0.333 (0.333)	Loss 0.6402 (0.6402)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.6354 (0.6955)	Acc@1 88.281 (85.950)	Acc@5 99.609 (99.423)
Epoch: [33][128/196]	Time 0.142 (0.129)	Data 0.000 (0.003)	Loss 0.7272 (0.6999)	Acc@1 84.375 (85.971)	Acc@5 100.000 (99.349)
Epoch: [33][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7143 (0.7009)	Acc@1 87.891 (85.897)	Acc@5 99.609 (99.366)
Max memory in training epoch: 66.1367296
Drin!!
old memory: 665270784
new memory: 661367296
Faktor: 0.9941324824509353
New batch Size größer 259!!
lr: 0.09278294328396441
1

Epoch: [34 | 35] LR: 0.092783
batch Size 259
Epoch: [34][0/196]	Time 0.174 (0.174)	Data 0.293 (0.293)	Loss 0.6163 (0.6163)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.149 (0.129)	Data 0.000 (0.005)	Loss 0.6686 (0.7095)	Acc@1 87.109 (85.319)	Acc@5 98.828 (99.381)
Epoch: [34][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6071 (0.7033)	Acc@1 88.672 (85.850)	Acc@5 100.000 (99.406)
Epoch: [34][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6735 (0.6988)	Acc@1 87.109 (86.008)	Acc@5 99.609 (99.429)
Max memory in training epoch: 66.1367296
lr: 0.09278294328396441
1

Epoch: [35 | 35] LR: 0.092783
batch Size 259
Epoch: [35][0/196]	Time 0.200 (0.200)	Data 0.284 (0.284)	Loss 0.8021 (0.8021)	Acc@1 79.297 (79.297)	Acc@5 98.828 (98.828)
Epoch: [35][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.7072 (0.6808)	Acc@1 84.766 (86.484)	Acc@5 100.000 (99.477)
Epoch: [35][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6728 (0.6884)	Acc@1 89.062 (86.258)	Acc@5 99.609 (99.461)
Epoch: [35][192/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.6684 (0.6960)	Acc@1 89.453 (85.966)	Acc@5 99.219 (99.447)
Max memory in training epoch: 66.1367296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 443524 ; 455072 ; 0.9746237957949512
[INFO] Storing checkpoint...
  72.53
Max memory: 102.8936192
 25.548s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 156
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.185088
lr: 0.09387024340057337
1

Epoch: [36 | 40] LR: 0.093870
batch Size 259
Epoch: [36][0/194]	Time 0.194 (0.194)	Data 0.262 (0.262)	Loss 0.6625 (0.6625)	Acc@1 88.031 (88.031)	Acc@5 100.000 (100.000)
Epoch: [36][64/194]	Time 0.124 (0.132)	Data 0.000 (0.004)	Loss 0.6613 (0.6646)	Acc@1 86.100 (87.116)	Acc@5 99.614 (99.394)
Epoch: [36][128/194]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.6652 (0.6772)	Acc@1 85.328 (86.687)	Acc@5 99.228 (99.428)
Epoch: [36][192/194]	Time 0.158 (0.131)	Data 0.000 (0.002)	Loss 0.5639 (0.6857)	Acc@1 92.278 (86.442)	Acc@5 100.000 (99.428)
Max memory in training epoch: 66.5304576
lr: 0.09387024340057337
1

Epoch: [37 | 40] LR: 0.093870
batch Size 259
Epoch: [37][0/194]	Time 0.160 (0.160)	Data 0.298 (0.298)	Loss 0.7620 (0.7620)	Acc@1 83.398 (83.398)	Acc@5 98.456 (98.456)
Epoch: [37][64/194]	Time 0.149 (0.131)	Data 0.000 (0.005)	Loss 0.7197 (0.7273)	Acc@1 83.398 (85.079)	Acc@5 100.000 (99.394)
Epoch: [37][128/194]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6695 (0.7143)	Acc@1 86.100 (85.589)	Acc@5 99.614 (99.371)
Epoch: [37][192/194]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7348 (0.7103)	Acc@1 88.417 (85.754)	Acc@5 99.614 (99.406)
Max memory in training epoch: 66.6217984
lr: 0.09387024340057337
1

Epoch: [38 | 40] LR: 0.093870
batch Size 259
Epoch: [38][0/194]	Time 0.167 (0.167)	Data 0.278 (0.278)	Loss 0.6868 (0.6868)	Acc@1 89.189 (89.189)	Acc@5 100.000 (100.000)
Epoch: [38][64/194]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 0.7214 (0.7828)	Acc@1 84.170 (83.445)	Acc@5 99.228 (99.121)
Epoch: [38][128/194]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.6964 (0.7439)	Acc@1 86.100 (84.652)	Acc@5 99.228 (99.294)
Epoch: [38][192/194]	Time 0.148 (0.131)	Data 0.000 (0.002)	Loss 0.6957 (0.7263)	Acc@1 86.100 (85.224)	Acc@5 99.614 (99.350)
Max memory in training epoch: 66.6217984
Drin!!
old memory: 661367296
new memory: 666217984
Faktor: 1.00733433302393
New batch Size kleiner 260!!
lr: 0.09387024340057337
1

Epoch: [39 | 40] LR: 0.093870
batch Size 260
Epoch: [39][0/194]	Time 0.163 (0.163)	Data 0.303 (0.303)	Loss 0.7242 (0.7242)	Acc@1 86.486 (86.486)	Acc@5 98.842 (98.842)
Epoch: [39][64/194]	Time 0.132 (0.135)	Data 0.000 (0.005)	Loss 0.6058 (0.7240)	Acc@1 87.645 (85.263)	Acc@5 100.000 (99.394)
Epoch: [39][128/194]	Time 0.135 (0.135)	Data 0.000 (0.003)	Loss 0.6939 (0.7055)	Acc@1 86.100 (85.822)	Acc@5 99.614 (99.467)
Epoch: [39][192/194]	Time 0.139 (0.134)	Data 0.000 (0.002)	Loss 0.5753 (0.7035)	Acc@1 91.120 (85.944)	Acc@5 99.614 (99.466)
Max memory in training epoch: 66.6217984
lr: 0.09387024340057337
1

Epoch: [40 | 40] LR: 0.093870
batch Size 260
Epoch: [40][0/194]	Time 0.184 (0.184)	Data 0.330 (0.330)	Loss 0.7453 (0.7453)	Acc@1 85.714 (85.714)	Acc@5 98.842 (98.842)
Epoch: [40][64/194]	Time 0.121 (0.130)	Data 0.000 (0.005)	Loss 0.6516 (0.7654)	Acc@1 89.961 (83.885)	Acc@5 99.614 (99.145)
Epoch: [40][128/194]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.6889 (0.7315)	Acc@1 86.100 (85.095)	Acc@5 99.614 (99.276)
Epoch: [40][192/194]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7961 (0.7175)	Acc@1 83.784 (85.630)	Acc@5 98.456 (99.316)
Max memory in training epoch: 66.6217984
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 430822 ; 443524 ; 0.9713611890224655
[INFO] Storing checkpoint...
  76.36
Max memory: 101.1357184
 25.534s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9033
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1801728
lr: 0.09533696595370733
1

Epoch: [41 | 45] LR: 0.095337
batch Size 260
Epoch: [41][0/193]	Time 0.197 (0.197)	Data 0.286 (0.286)	Loss 0.6958 (0.6958)	Acc@1 87.308 (87.308)	Acc@5 99.231 (99.231)
Epoch: [41][64/193]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.6978 (0.6381)	Acc@1 84.615 (87.870)	Acc@5 99.615 (99.580)
Epoch: [41][128/193]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.7128 (0.6659)	Acc@1 87.308 (87.045)	Acc@5 99.615 (99.568)
Epoch: [41][192/193]	Time 0.097 (0.131)	Data 0.000 (0.002)	Loss 0.7727 (0.6730)	Acc@1 80.000 (86.722)	Acc@5 98.750 (99.548)
Max memory in training epoch: 66.2019584
lr: 0.09533696595370733
1

Epoch: [42 | 45] LR: 0.095337
batch Size 260
Epoch: [42][0/193]	Time 0.188 (0.188)	Data 0.305 (0.305)	Loss 0.6750 (0.6750)	Acc@1 87.308 (87.308)	Acc@5 99.615 (99.615)
Epoch: [42][64/193]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.6865 (0.6864)	Acc@1 85.385 (86.136)	Acc@5 99.615 (99.515)
Epoch: [42][128/193]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.6791 (0.6814)	Acc@1 85.385 (86.380)	Acc@5 99.615 (99.481)
Epoch: [42][192/193]	Time 0.095 (0.130)	Data 0.000 (0.002)	Loss 0.5840 (0.6876)	Acc@1 90.000 (86.236)	Acc@5 98.750 (99.452)
Max memory in training epoch: 66.0790784
lr: 0.09533696595370733
1

Epoch: [43 | 45] LR: 0.095337
batch Size 260
Epoch: [43][0/193]	Time 0.160 (0.160)	Data 0.269 (0.269)	Loss 0.6324 (0.6324)	Acc@1 86.538 (86.538)	Acc@5 99.231 (99.231)
Epoch: [43][64/193]	Time 0.136 (0.135)	Data 0.000 (0.004)	Loss 0.7474 (0.6723)	Acc@1 86.154 (86.609)	Acc@5 99.231 (99.556)
Epoch: [43][128/193]	Time 0.135 (0.135)	Data 0.000 (0.002)	Loss 0.6481 (0.6810)	Acc@1 88.077 (86.431)	Acc@5 100.000 (99.529)
Epoch: [43][192/193]	Time 0.094 (0.133)	Data 0.000 (0.002)	Loss 0.5434 (0.6816)	Acc@1 92.500 (86.430)	Acc@5 100.000 (99.452)
Max memory in training epoch: 66.0790784
Drin!!
old memory: 666217984
new memory: 660790784
Faktor: 0.99185371735627
New batch Size größer 263!!
lr: 0.09533696595370733
1

Epoch: [44 | 45] LR: 0.095337
batch Size 263
Epoch: [44][0/193]	Time 0.173 (0.173)	Data 0.312 (0.312)	Loss 0.6627 (0.6627)	Acc@1 87.308 (87.308)	Acc@5 99.615 (99.615)
Epoch: [44][64/193]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.6974 (0.6738)	Acc@1 84.231 (86.580)	Acc@5 99.615 (99.515)
Epoch: [44][128/193]	Time 0.131 (0.131)	Data 0.000 (0.003)	Loss 0.7311 (0.6752)	Acc@1 86.154 (86.619)	Acc@5 99.231 (99.505)
Epoch: [44][192/193]	Time 0.107 (0.131)	Data 0.000 (0.002)	Loss 0.6102 (0.6750)	Acc@1 92.500 (86.686)	Acc@5 100.000 (99.452)
Max memory in training epoch: 66.0790784
lr: 0.09533696595370733
1

Epoch: [45 | 45] LR: 0.095337
batch Size 263
Epoch: [45][0/193]	Time 0.185 (0.185)	Data 0.314 (0.314)	Loss 0.7308 (0.7308)	Acc@1 84.615 (84.615)	Acc@5 98.846 (98.846)
Epoch: [45][64/193]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.7272 (0.6886)	Acc@1 87.308 (86.272)	Acc@5 98.846 (99.491)
Epoch: [45][128/193]	Time 0.132 (0.131)	Data 0.000 (0.003)	Loss 0.6782 (0.6855)	Acc@1 87.692 (86.380)	Acc@5 99.231 (99.478)
Epoch: [45][192/193]	Time 0.101 (0.131)	Data 0.000 (0.002)	Loss 1.0025 (0.6848)	Acc@1 78.750 (86.364)	Acc@5 97.500 (99.458)
Max memory in training epoch: 66.0790784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 419276 ; 430822 ; 0.9732000687058693
[INFO] Storing checkpoint...
  76.84
Max memory: 100.124416
 25.671s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2110
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1755648
lr: 0.09794383611650402
1

Epoch: [46 | 50] LR: 0.097944
batch Size 263
Epoch: [46][0/191]	Time 0.203 (0.203)	Data 0.298 (0.298)	Loss 0.6438 (0.6438)	Acc@1 88.593 (88.593)	Acc@5 99.240 (99.240)
Epoch: [46][64/191]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.6152 (0.6535)	Acc@1 88.593 (87.371)	Acc@5 99.620 (99.567)
Epoch: [46][128/191]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.6726 (0.6673)	Acc@1 85.551 (86.934)	Acc@5 100.000 (99.472)
Max memory in training epoch: 66.225664
lr: 0.09794383611650402
1

Epoch: [47 | 50] LR: 0.097944
batch Size 263
Epoch: [47][0/191]	Time 0.157 (0.157)	Data 0.301 (0.301)	Loss 0.7251 (0.7251)	Acc@1 84.791 (84.791)	Acc@5 99.620 (99.620)
Epoch: [47][64/191]	Time 0.130 (0.136)	Data 0.000 (0.005)	Loss 0.6664 (0.7264)	Acc@1 86.692 (84.955)	Acc@5 99.620 (99.397)
Epoch: [47][128/191]	Time 0.129 (0.133)	Data 0.000 (0.003)	Loss 0.6823 (0.7036)	Acc@1 88.213 (85.631)	Acc@5 98.859 (99.455)
Max memory in training epoch: 66.3420928
lr: 0.09794383611650402
1

Epoch: [48 | 50] LR: 0.097944
batch Size 263
Epoch: [48][0/191]	Time 0.218 (0.218)	Data 0.330 (0.330)	Loss 0.7510 (0.7510)	Acc@1 83.270 (83.270)	Acc@5 98.859 (98.859)
Epoch: [48][64/191]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.6720 (0.7213)	Acc@1 87.072 (85.364)	Acc@5 100.000 (99.368)
Epoch: [48][128/191]	Time 0.125 (0.131)	Data 0.000 (0.003)	Loss 0.6830 (0.6981)	Acc@1 88.213 (86.049)	Acc@5 99.620 (99.416)
Max memory in training epoch: 66.3420928
Drin!!
old memory: 660790784
new memory: 663420928
Faktor: 1.003980297642892
New batch Size kleiner 264!!
lr: 0.09794383611650402
1

Epoch: [49 | 50] LR: 0.097944
batch Size 264
Epoch: [49][0/191]	Time 0.178 (0.178)	Data 0.303 (0.303)	Loss 0.6002 (0.6002)	Acc@1 89.354 (89.354)	Acc@5 99.240 (99.240)
Epoch: [49][64/191]	Time 0.137 (0.131)	Data 0.000 (0.005)	Loss 0.6768 (0.6921)	Acc@1 87.072 (85.820)	Acc@5 99.620 (99.550)
Epoch: [49][128/191]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.7154 (0.6931)	Acc@1 85.171 (85.914)	Acc@5 99.240 (99.508)
Max memory in training epoch: 66.3420928
lr: 0.09794383611650402
1

Epoch: [50 | 50] LR: 0.097944
batch Size 264
Epoch: [50][0/191]	Time 0.157 (0.157)	Data 0.301 (0.301)	Loss 0.7092 (0.7092)	Acc@1 84.791 (84.791)	Acc@5 98.859 (98.859)
Epoch: [50][64/191]	Time 0.135 (0.131)	Data 0.000 (0.005)	Loss 0.6837 (0.7142)	Acc@1 86.692 (85.294)	Acc@5 99.620 (99.415)
Epoch: [50][128/191]	Time 0.123 (0.130)	Data 0.000 (0.003)	Loss 0.7833 (0.6958)	Acc@1 83.270 (85.946)	Acc@5 99.240 (99.449)
Max memory in training epoch: 66.3420928
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 408880 ; 419276 ; 0.9752048769784104
[INFO] Storing checkpoint...
  78.24
Max memory: 99.4718208
 25.202s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8848
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1714688
lr: 0.10100458099514477
1

Epoch: [51 | 55] LR: 0.101005
batch Size 264
Epoch: [51][0/190]	Time 0.177 (0.177)	Data 0.274 (0.274)	Loss 0.7192 (0.7192)	Acc@1 84.470 (84.470)	Acc@5 100.000 (100.000)
Epoch: [51][64/190]	Time 0.125 (0.132)	Data 0.000 (0.004)	Loss 0.6869 (0.6612)	Acc@1 86.364 (87.145)	Acc@5 99.621 (99.470)
Epoch: [51][128/190]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6985 (0.6700)	Acc@1 85.606 (86.593)	Acc@5 99.621 (99.454)
Max memory in training epoch: 66.1014016
lr: 0.10100458099514477
1

Epoch: [52 | 55] LR: 0.101005
batch Size 264
Epoch: [52][0/190]	Time 0.197 (0.197)	Data 0.287 (0.287)	Loss 0.6493 (0.6493)	Acc@1 85.985 (85.985)	Acc@5 100.000 (100.000)
Epoch: [52][64/190]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.7147 (0.6742)	Acc@1 85.227 (86.387)	Acc@5 98.485 (99.371)
Epoch: [52][128/190]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6637 (0.6700)	Acc@1 87.121 (86.713)	Acc@5 99.242 (99.351)
Max memory in training epoch: 66.081536
lr: 0.10100458099514477
1

Epoch: [53 | 55] LR: 0.101005
batch Size 264
Epoch: [53][0/190]	Time 0.177 (0.177)	Data 0.270 (0.270)	Loss 0.7244 (0.7244)	Acc@1 84.848 (84.848)	Acc@5 99.621 (99.621)
Epoch: [53][64/190]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.6851 (0.6735)	Acc@1 86.742 (86.847)	Acc@5 100.000 (99.435)
Epoch: [53][128/190]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8058 (0.6833)	Acc@1 82.576 (86.440)	Acc@5 98.864 (99.427)
Max memory in training epoch: 66.081536
Drin!!
old memory: 663420928
new memory: 660815360
Faktor: 0.9960725266719352
New batch Size größer 267!!
lr: 0.10100458099514477
1

Epoch: [54 | 55] LR: 0.101005
batch Size 267
Epoch: [54][0/190]	Time 0.215 (0.215)	Data 0.325 (0.325)	Loss 0.6396 (0.6396)	Acc@1 85.227 (85.227)	Acc@5 100.000 (100.000)
Epoch: [54][64/190]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.6448 (0.6737)	Acc@1 86.742 (86.661)	Acc@5 100.000 (99.464)
Epoch: [54][128/190]	Time 0.137 (0.130)	Data 0.000 (0.003)	Loss 0.7274 (0.6751)	Acc@1 85.606 (86.493)	Acc@5 98.864 (99.454)
Max memory in training epoch: 66.081536
lr: 0.10100458099514477
1

Epoch: [55 | 55] LR: 0.101005
batch Size 267
Epoch: [55][0/190]	Time 0.182 (0.182)	Data 0.278 (0.278)	Loss 0.6396 (0.6396)	Acc@1 89.015 (89.015)	Acc@5 98.485 (98.485)
Epoch: [55][64/190]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.7225 (0.6747)	Acc@1 83.712 (86.777)	Acc@5 99.621 (99.441)
Epoch: [55][128/190]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.6109 (0.6691)	Acc@1 89.394 (86.836)	Acc@5 99.621 (99.451)
Max memory in training epoch: 66.081536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 398484 ; 408880 ; 0.9745744472705928
[INFO] Storing checkpoint...
  79.55
Max memory: 98.6538496
 25.208s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9093
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1672704
lr: 0.10534462158477989
1

Epoch: [56 | 60] LR: 0.105345
batch Size 267
Epoch: [56][0/188]	Time 0.220 (0.220)	Data 0.302 (0.302)	Loss 0.6149 (0.6149)	Acc@1 87.640 (87.640)	Acc@5 100.000 (100.000)
Epoch: [56][64/188]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7129 (0.6521)	Acc@1 84.270 (87.485)	Acc@5 100.000 (99.487)
Epoch: [56][128/188]	Time 0.137 (0.131)	Data 0.000 (0.002)	Loss 0.7927 (0.6696)	Acc@1 86.142 (86.822)	Acc@5 98.502 (99.454)
Max memory in training epoch: 65.9696128
lr: 0.10534462158477989
1

Epoch: [57 | 60] LR: 0.105345
batch Size 267
Epoch: [57][0/188]	Time 0.197 (0.197)	Data 0.268 (0.268)	Loss 0.6312 (0.6312)	Acc@1 85.393 (85.393)	Acc@5 99.251 (99.251)
Epoch: [57][64/188]	Time 0.124 (0.130)	Data 0.000 (0.004)	Loss 0.7047 (0.6814)	Acc@1 84.270 (86.580)	Acc@5 99.251 (99.441)
Epoch: [57][128/188]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6189 (0.6748)	Acc@1 87.266 (86.677)	Acc@5 99.251 (99.466)
Max memory in training epoch: 65.9941376
lr: 0.10534462158477989
1

Epoch: [58 | 60] LR: 0.105345
batch Size 267
Epoch: [58][0/188]	Time 0.157 (0.157)	Data 0.270 (0.270)	Loss 0.5927 (0.5927)	Acc@1 90.262 (90.262)	Acc@5 100.000 (100.000)
Epoch: [58][64/188]	Time 0.137 (0.130)	Data 0.000 (0.004)	Loss 0.6557 (0.6696)	Acc@1 88.015 (86.909)	Acc@5 100.000 (99.424)
Epoch: [58][128/188]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.5490 (0.6729)	Acc@1 91.386 (86.897)	Acc@5 100.000 (99.419)
Max memory in training epoch: 65.9941376
Drin!!
old memory: 660815360
new memory: 659941376
Faktor: 0.9986774157307724
New batch Size größer 271!!
lr: 0.10534462158477989
1

Epoch: [59 | 60] LR: 0.105345
batch Size 271
Epoch: [59][0/188]	Time 0.152 (0.152)	Data 0.295 (0.295)	Loss 0.6531 (0.6531)	Acc@1 88.015 (88.015)	Acc@5 99.625 (99.625)
Epoch: [59][64/188]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.7628 (0.6719)	Acc@1 84.644 (86.805)	Acc@5 100.000 (99.493)
Epoch: [59][128/188]	Time 0.120 (0.132)	Data 0.000 (0.002)	Loss 0.7116 (0.6765)	Acc@1 84.270 (86.575)	Acc@5 99.625 (99.443)
Max memory in training epoch: 65.9941376
lr: 0.10534462158477989
1

Epoch: [60 | 60] LR: 0.105345
batch Size 271
Epoch: [60][0/188]	Time 0.159 (0.159)	Data 0.306 (0.306)	Loss 0.6402 (0.6402)	Acc@1 87.640 (87.640)	Acc@5 99.625 (99.625)
Epoch: [60][64/188]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.7246 (0.6897)	Acc@1 84.270 (86.442)	Acc@5 99.625 (99.441)
Epoch: [60][128/188]	Time 0.126 (0.129)	Data 0.000 (0.003)	Loss 0.6317 (0.6859)	Acc@1 90.637 (86.401)	Acc@5 98.502 (99.434)
Max memory in training epoch: 65.9941376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 386932 ; 398484 ; 0.9710101283865852
[INFO] Storing checkpoint...
  81.45
Max memory: 97.5494656
 24.692s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5366
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1627648
lr: 0.11151715800576309
1

Epoch: [61 | 65] LR: 0.111517
batch Size 271
Epoch: [61][0/185]	Time 0.194 (0.194)	Data 0.316 (0.316)	Loss 0.6270 (0.6270)	Acc@1 87.454 (87.454)	Acc@5 99.631 (99.631)
Epoch: [61][64/185]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.5914 (0.6605)	Acc@1 88.930 (87.272)	Acc@5 100.000 (99.444)
Epoch: [61][128/185]	Time 0.126 (0.131)	Data 0.000 (0.003)	Loss 0.7060 (0.6770)	Acc@1 84.871 (86.739)	Acc@5 99.262 (99.416)
Max memory in training epoch: 65.6211968
lr: 0.11151715800576309
1

Epoch: [62 | 65] LR: 0.111517
batch Size 271
Epoch: [62][0/185]	Time 0.177 (0.177)	Data 0.306 (0.306)	Loss 0.7317 (0.7317)	Acc@1 83.395 (83.395)	Acc@5 99.631 (99.631)
Epoch: [62][64/185]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.7151 (0.6875)	Acc@1 85.978 (86.341)	Acc@5 99.262 (99.398)
Epoch: [62][128/185]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.7102 (0.6905)	Acc@1 83.764 (86.170)	Acc@5 99.262 (99.405)
Max memory in training epoch: 65.6362496
lr: 0.11151715800576309
1

Epoch: [63 | 65] LR: 0.111517
batch Size 271
Epoch: [63][0/185]	Time 0.161 (0.161)	Data 0.304 (0.304)	Loss 0.5900 (0.5900)	Acc@1 91.882 (91.882)	Acc@5 99.262 (99.262)
Epoch: [63][64/185]	Time 0.139 (0.134)	Data 0.000 (0.005)	Loss 0.6431 (0.6760)	Acc@1 88.561 (86.511)	Acc@5 99.262 (99.461)
Epoch: [63][128/185]	Time 0.125 (0.134)	Data 0.000 (0.003)	Loss 0.6605 (0.6709)	Acc@1 85.978 (86.659)	Acc@5 99.631 (99.479)
Max memory in training epoch: 65.6362496
Drin!!
old memory: 659941376
new memory: 656362496
Faktor: 0.9945769728491762
New batch Size größer 276!!
lr: 0.11151715800576309
1

Epoch: [64 | 65] LR: 0.111517
batch Size 276
Epoch: [64][0/185]	Time 0.160 (0.160)	Data 0.285 (0.285)	Loss 0.6834 (0.6834)	Acc@1 86.347 (86.347)	Acc@5 99.631 (99.631)
Epoch: [64][64/185]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.7555 (0.6728)	Acc@1 83.395 (86.653)	Acc@5 99.631 (99.489)
Epoch: [64][128/185]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7321 (0.6814)	Acc@1 84.871 (86.413)	Acc@5 98.893 (99.428)
Max memory in training epoch: 65.6362496
lr: 0.11151715800576309
1

Epoch: [65 | 65] LR: 0.111517
batch Size 276
Epoch: [65][0/185]	Time 0.215 (0.215)	Data 0.355 (0.355)	Loss 0.6662 (0.6662)	Acc@1 87.823 (87.823)	Acc@5 99.631 (99.631)
Epoch: [65][64/185]	Time 0.121 (0.131)	Data 0.000 (0.006)	Loss 0.7350 (0.6729)	Acc@1 86.347 (86.716)	Acc@5 99.262 (99.455)
Epoch: [65][128/185]	Time 0.120 (0.132)	Data 0.000 (0.003)	Loss 0.6796 (0.6763)	Acc@1 86.347 (86.593)	Acc@5 99.262 (99.451)
Max memory in training epoch: 65.6362496
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 376968 ; 386932 ; 0.9742487051988463
[INFO] Storing checkpoint...
  71.35
Max memory: 96.1609216
 24.607s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4007
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.15872
lr: 0.12022943597496333
1

Epoch: [66 | 70] LR: 0.120229
batch Size 276
Epoch: [66][0/182]	Time 0.214 (0.214)	Data 0.265 (0.265)	Loss 0.7388 (0.7388)	Acc@1 85.870 (85.870)	Acc@5 99.275 (99.275)
Epoch: [66][64/182]	Time 0.138 (0.134)	Data 0.000 (0.004)	Loss 0.6631 (0.6651)	Acc@1 86.594 (86.745)	Acc@5 100.000 (99.454)
Epoch: [66][128/182]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.6568 (0.6820)	Acc@1 84.783 (86.229)	Acc@5 99.638 (99.449)
Max memory in training epoch: 66.8807168
lr: 0.12022943597496333
1

Epoch: [67 | 70] LR: 0.120229
batch Size 276
Epoch: [67][0/182]	Time 0.185 (0.185)	Data 0.284 (0.284)	Loss 0.7230 (0.7230)	Acc@1 84.420 (84.420)	Acc@5 99.275 (99.275)
Epoch: [67][64/182]	Time 0.134 (0.138)	Data 0.000 (0.005)	Loss 0.6718 (0.6719)	Acc@1 86.594 (86.728)	Acc@5 99.638 (99.548)
Epoch: [67][128/182]	Time 0.131 (0.136)	Data 0.000 (0.002)	Loss 0.6894 (0.6846)	Acc@1 85.145 (86.355)	Acc@5 100.000 (99.447)
Max memory in training epoch: 67.0445568
lr: 0.12022943597496333
1

Epoch: [68 | 70] LR: 0.120229
batch Size 276
Epoch: [68][0/182]	Time 0.163 (0.163)	Data 0.299 (0.299)	Loss 0.7575 (0.7575)	Acc@1 82.971 (82.971)	Acc@5 99.275 (99.275)
Epoch: [68][64/182]	Time 0.134 (0.135)	Data 0.000 (0.005)	Loss 0.6413 (0.7097)	Acc@1 87.319 (85.697)	Acc@5 99.638 (99.281)
Epoch: [68][128/182]	Time 0.139 (0.135)	Data 0.000 (0.002)	Loss 0.6497 (0.6948)	Acc@1 88.043 (86.201)	Acc@5 100.000 (99.393)
Max memory in training epoch: 67.0445568
Drin!!
old memory: 656362496
new memory: 670445568
Faktor: 1.0214562411561066
New batch Size kleiner 281!!
lr: 0.12022943597496333
1

Epoch: [69 | 70] LR: 0.120229
batch Size 281
Epoch: [69][0/182]	Time 0.186 (0.186)	Data 0.308 (0.308)	Loss 0.7792 (0.7792)	Acc@1 83.696 (83.696)	Acc@5 98.913 (98.913)
Epoch: [69][64/182]	Time 0.132 (0.135)	Data 0.000 (0.005)	Loss 0.6991 (0.7317)	Acc@1 85.145 (85.033)	Acc@5 99.275 (99.353)
Epoch: [69][128/182]	Time 0.131 (0.134)	Data 0.000 (0.003)	Loss 0.6628 (0.7129)	Acc@1 85.145 (85.606)	Acc@5 99.638 (99.405)
Max memory in training epoch: 67.0445568
lr: 0.12022943597496333
1

Epoch: [70 | 70] LR: 0.120229
batch Size 281
Epoch: [70][0/182]	Time 0.192 (0.192)	Data 0.305 (0.305)	Loss 0.6513 (0.6513)	Acc@1 86.957 (86.957)	Acc@5 100.000 (100.000)
Epoch: [70][64/182]	Time 0.133 (0.135)	Data 0.000 (0.005)	Loss 0.6995 (0.6970)	Acc@1 86.232 (85.975)	Acc@5 98.913 (99.398)
Epoch: [70][128/182]	Time 0.133 (0.134)	Data 0.000 (0.003)	Loss 0.7158 (0.6919)	Acc@1 83.696 (86.201)	Acc@5 99.275 (99.393)
Max memory in training epoch: 67.0445568
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 374078 ; 376968 ; 0.9923335667748987
[INFO] Storing checkpoint...
  74.38
Max memory: 94.9513216
 24.534s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6924
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1575936
lr: 0.13197059183189333
1

Epoch: [71 | 75] LR: 0.131971
batch Size 281
Epoch: [71][0/178]	Time 0.204 (0.204)	Data 0.261 (0.261)	Loss 0.7285 (0.7285)	Acc@1 85.409 (85.409)	Acc@5 99.644 (99.644)
Epoch: [71][64/178]	Time 0.131 (0.138)	Data 0.000 (0.004)	Loss 0.7049 (0.6650)	Acc@1 84.698 (86.816)	Acc@5 100.000 (99.524)
Epoch: [71][128/178]	Time 0.138 (0.136)	Data 0.000 (0.002)	Loss 0.6987 (0.6820)	Acc@1 86.121 (86.347)	Acc@5 100.000 (99.506)
Max memory in training epoch: 67.380224
lr: 0.13197059183189333
1

Epoch: [72 | 75] LR: 0.131971
batch Size 281
Epoch: [72][0/178]	Time 0.168 (0.168)	Data 0.308 (0.308)	Loss 0.8361 (0.8361)	Acc@1 79.715 (79.715)	Acc@5 99.644 (99.644)
Epoch: [72][64/178]	Time 0.139 (0.135)	Data 0.000 (0.005)	Loss 0.6964 (0.7030)	Acc@1 85.409 (85.853)	Acc@5 98.932 (99.474)
Epoch: [72][128/178]	Time 0.130 (0.134)	Data 0.000 (0.003)	Loss 0.6617 (0.7001)	Acc@1 88.612 (85.851)	Acc@5 100.000 (99.437)
Max memory in training epoch: 68.2148864
lr: 0.13197059183189333
1

Epoch: [73 | 75] LR: 0.131971
batch Size 281
Epoch: [73][0/178]	Time 0.160 (0.160)	Data 0.282 (0.282)	Loss 0.6916 (0.6916)	Acc@1 84.342 (84.342)	Acc@5 100.000 (100.000)
Epoch: [73][64/178]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.6639 (0.6805)	Acc@1 87.544 (86.526)	Acc@5 99.644 (99.474)
Epoch: [73][128/178]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6485 (0.6917)	Acc@1 87.189 (86.168)	Acc@5 99.644 (99.459)
Max memory in training epoch: 68.2148864
Drin!!
old memory: 670445568
new memory: 682148864
Faktor: 1.0174559972630022
New batch Size kleiner 285!!
lr: 0.13197059183189333
1

Epoch: [74 | 75] LR: 0.131971
batch Size 285
Epoch: [74][0/178]	Time 0.186 (0.186)	Data 0.302 (0.302)	Loss 0.6832 (0.6832)	Acc@1 85.409 (85.409)	Acc@5 99.644 (99.644)
Epoch: [74][64/178]	Time 0.127 (0.134)	Data 0.000 (0.005)	Loss 0.6495 (0.6807)	Acc@1 86.121 (86.564)	Acc@5 99.644 (99.529)
Epoch: [74][128/178]	Time 0.129 (0.133)	Data 0.000 (0.003)	Loss 0.6790 (0.6945)	Acc@1 87.900 (86.066)	Acc@5 99.288 (99.443)
Max memory in training epoch: 68.2148864
lr: 0.13197059183189333
1

Epoch: [75 | 75] LR: 0.131971
batch Size 285
Epoch: [75][0/178]	Time 0.199 (0.199)	Data 0.372 (0.372)	Loss 0.7350 (0.7350)	Acc@1 82.918 (82.918)	Acc@5 98.577 (98.577)
Epoch: [75][64/178]	Time 0.135 (0.136)	Data 0.000 (0.006)	Loss 0.6851 (0.6883)	Acc@1 83.986 (86.356)	Acc@5 99.288 (99.447)
Epoch: [75][128/178]	Time 0.136 (0.136)	Data 0.000 (0.003)	Loss 0.7013 (0.7036)	Acc@1 87.189 (85.804)	Acc@5 98.932 (99.377)
Max memory in training epoch: 68.2148864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 369458 ; 374078 ; 0.9876496345681917
[INFO] Storing checkpoint...
  83.05
Max memory: 94.2587904
 24.635s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4386
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1557504
lr: 0.14692038543785
1

Epoch: [76 | 80] LR: 0.146920
batch Size 285
Epoch: [76][0/176]	Time 0.210 (0.210)	Data 0.290 (0.290)	Loss 0.6740 (0.6740)	Acc@1 85.614 (85.614)	Acc@5 99.298 (99.298)
Epoch: [76][64/176]	Time 0.131 (0.135)	Data 0.000 (0.005)	Loss 0.7167 (0.6857)	Acc@1 87.018 (86.478)	Acc@5 100.000 (99.417)
Epoch: [76][128/176]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.7980 (0.7008)	Acc@1 81.053 (85.902)	Acc@5 99.298 (99.374)
Max memory in training epoch: 67.6338176
lr: 0.14692038543785
1

Epoch: [77 | 80] LR: 0.146920
batch Size 285
Epoch: [77][0/176]	Time 0.194 (0.194)	Data 0.316 (0.316)	Loss 0.6645 (0.6645)	Acc@1 88.772 (88.772)	Acc@5 99.649 (99.649)
Epoch: [77][64/176]	Time 0.127 (0.134)	Data 0.000 (0.005)	Loss 0.6915 (0.7145)	Acc@1 85.614 (85.404)	Acc@5 99.298 (99.374)
Epoch: [77][128/176]	Time 0.143 (0.133)	Data 0.000 (0.003)	Loss 0.7137 (0.7196)	Acc@1 85.965 (85.277)	Acc@5 99.298 (99.369)
Max memory in training epoch: 68.2151936
lr: 0.14692038543785
1

Epoch: [78 | 80] LR: 0.146920
batch Size 285
Epoch: [78][0/176]	Time 0.176 (0.176)	Data 0.314 (0.314)	Loss 0.7604 (0.7604)	Acc@1 83.860 (83.860)	Acc@5 99.298 (99.298)
Epoch: [78][64/176]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.6586 (0.7028)	Acc@1 88.070 (86.008)	Acc@5 99.298 (99.401)
Epoch: [78][128/176]	Time 0.133 (0.133)	Data 0.000 (0.003)	Loss 0.8230 (0.7202)	Acc@1 82.456 (85.388)	Acc@5 99.298 (99.364)
Max memory in training epoch: 68.2151936
Drin!!
old memory: 682148864
new memory: 682151936
Faktor: 1.000004503415841
New batch Size kleiner 285!!
lr: 0.14692038543785
1

Epoch: [79 | 80] LR: 0.146920
batch Size 285
Epoch: [79][0/176]	Time 0.158 (0.158)	Data 0.317 (0.317)	Loss 0.6414 (0.6414)	Acc@1 87.018 (87.018)	Acc@5 99.298 (99.298)
Epoch: [79][64/176]	Time 0.127 (0.133)	Data 0.000 (0.005)	Loss 0.7744 (0.7049)	Acc@1 82.456 (85.852)	Acc@5 99.298 (99.341)
Epoch: [79][128/176]	Time 0.133 (0.133)	Data 0.000 (0.003)	Loss 0.7460 (0.7058)	Acc@1 83.860 (85.625)	Acc@5 98.947 (99.374)
Max memory in training epoch: 68.2151936
lr: 0.14692038543785
1

Epoch: [80 | 80] LR: 0.146920
batch Size 285
Epoch: [80][0/176]	Time 0.171 (0.171)	Data 0.316 (0.316)	Loss 0.6973 (0.6973)	Acc@1 85.965 (85.965)	Acc@5 99.298 (99.298)
Epoch: [80][64/176]	Time 0.135 (0.135)	Data 0.000 (0.005)	Loss 0.8959 (0.7129)	Acc@1 77.544 (85.328)	Acc@5 98.947 (99.412)
Epoch: [80][128/176]	Time 0.123 (0.133)	Data 0.000 (0.003)	Loss 0.7385 (0.7228)	Acc@1 84.561 (85.040)	Acc@5 99.298 (99.358)
Max memory in training epoch: 68.2151936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 364836 ; 369458 ; 0.9874897823297912
[INFO] Storing checkpoint...
  77.19
Max memory: 94.0599296
 23.784s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1557
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1540096
lr: 0.16356371035073144
1

Epoch: [81 | 85] LR: 0.163564
batch Size 285
Epoch: [81][0/176]	Time 0.219 (0.219)	Data 0.276 (0.276)	Loss 0.6998 (0.6998)	Acc@1 84.561 (84.561)	Acc@5 100.000 (100.000)
Epoch: [81][64/176]	Time 0.129 (0.135)	Data 0.000 (0.004)	Loss 0.7571 (0.7070)	Acc@1 83.860 (85.657)	Acc@5 98.947 (99.314)
Epoch: [81][128/176]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 0.7488 (0.7249)	Acc@1 85.263 (85.160)	Acc@5 98.947 (99.315)
Max memory in training epoch: 67.2288256
lr: 0.16356371035073144
1

Epoch: [82 | 85] LR: 0.163564
batch Size 285
Epoch: [82][0/176]	Time 0.203 (0.203)	Data 0.273 (0.273)	Loss 0.7326 (0.7326)	Acc@1 83.860 (83.860)	Acc@5 100.000 (100.000)
Epoch: [82][64/176]	Time 0.126 (0.134)	Data 0.000 (0.004)	Loss 0.7163 (0.7383)	Acc@1 85.965 (85.020)	Acc@5 99.649 (99.331)
Epoch: [82][128/176]	Time 0.134 (0.135)	Data 0.000 (0.002)	Loss 0.7111 (0.7371)	Acc@1 88.421 (85.084)	Acc@5 100.000 (99.342)
Max memory in training epoch: 67.9358976
lr: 0.16356371035073144
1

Epoch: [83 | 85] LR: 0.163564
batch Size 285
Epoch: [83][0/176]	Time 0.181 (0.181)	Data 0.312 (0.312)	Loss 0.7682 (0.7682)	Acc@1 84.211 (84.211)	Acc@5 100.000 (100.000)
Epoch: [83][64/176]	Time 0.131 (0.135)	Data 0.000 (0.005)	Loss 0.8194 (0.7340)	Acc@1 84.211 (85.085)	Acc@5 99.298 (99.320)
Epoch: [83][128/176]	Time 0.132 (0.134)	Data 0.000 (0.003)	Loss 0.7924 (0.7466)	Acc@1 83.509 (84.670)	Acc@5 98.246 (99.296)
Max memory in training epoch: 67.9358976
Drin!!
old memory: 682151936
new memory: 679358976
Faktor: 0.9959056628698039
New batch Size größer 281!!
lr: 0.16356371035073144
1

Epoch: [84 | 85] LR: 0.163564
batch Size 281
Epoch: [84][0/176]	Time 0.168 (0.168)	Data 0.276 (0.276)	Loss 0.7194 (0.7194)	Acc@1 86.316 (86.316)	Acc@5 99.298 (99.298)
Epoch: [84][64/176]	Time 0.137 (0.137)	Data 0.000 (0.004)	Loss 0.7287 (0.7248)	Acc@1 87.719 (85.177)	Acc@5 99.298 (99.309)
Epoch: [84][128/176]	Time 0.143 (0.137)	Data 0.000 (0.002)	Loss 0.7265 (0.7335)	Acc@1 84.912 (84.915)	Acc@5 98.947 (99.325)
Max memory in training epoch: 67.9358976
lr: 0.16356371035073144
1

Epoch: [85 | 85] LR: 0.163564
batch Size 281
Epoch: [85][0/176]	Time 0.178 (0.178)	Data 0.318 (0.318)	Loss 0.7194 (0.7194)	Acc@1 85.614 (85.614)	Acc@5 99.649 (99.649)
Epoch: [85][64/176]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 0.8309 (0.7311)	Acc@1 80.702 (85.015)	Acc@5 99.649 (99.401)
Epoch: [85][128/176]	Time 0.131 (0.135)	Data 0.000 (0.003)	Loss 0.6980 (0.7320)	Acc@1 85.263 (85.043)	Acc@5 100.000 (99.407)
Max memory in training epoch: 67.9358976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 357408 ; 364836 ; 0.9796401670887741
[INFO] Storing checkpoint...
  77.53
Max memory: 93.41696
 24.051s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5860
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1504256
lr: 0.17953672893967007
1

Epoch: [86 | 90] LR: 0.179537
batch Size 281
Epoch: [86][0/178]	Time 0.185 (0.185)	Data 0.294 (0.294)	Loss 0.7257 (0.7257)	Acc@1 84.342 (84.342)	Acc@5 99.288 (99.288)
Epoch: [86][64/178]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.7518 (0.7216)	Acc@1 82.562 (85.234)	Acc@5 99.288 (99.381)
Epoch: [86][128/178]	Time 0.117 (0.126)	Data 0.000 (0.002)	Loss 0.7712 (0.7471)	Acc@1 85.053 (84.471)	Acc@5 99.288 (99.313)
Max memory in training epoch: 64.4496384
lr: 0.17953672893967007
1

Epoch: [87 | 90] LR: 0.179537
batch Size 281
Epoch: [87][0/178]	Time 0.162 (0.162)	Data 0.305 (0.305)	Loss 0.8080 (0.8080)	Acc@1 82.918 (82.918)	Acc@5 99.288 (99.288)
Epoch: [87][64/178]	Time 0.128 (0.125)	Data 0.000 (0.005)	Loss 0.7209 (0.7421)	Acc@1 84.342 (84.637)	Acc@5 99.644 (99.354)
Epoch: [87][128/178]	Time 0.120 (0.124)	Data 0.000 (0.003)	Loss 0.8212 (0.7534)	Acc@1 83.630 (84.355)	Acc@5 99.288 (99.316)
Max memory in training epoch: 65.0945536
lr: 0.17953672893967007
1

Epoch: [88 | 90] LR: 0.179537
batch Size 281
Epoch: [88][0/178]	Time 0.175 (0.175)	Data 0.270 (0.270)	Loss 0.7267 (0.7267)	Acc@1 83.274 (83.274)	Acc@5 99.644 (99.644)
Epoch: [88][64/178]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.7596 (0.7507)	Acc@1 82.918 (84.396)	Acc@5 99.288 (99.381)
Epoch: [88][128/178]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.7379 (0.7541)	Acc@1 83.986 (84.333)	Acc@5 99.644 (99.349)
Max memory in training epoch: 65.0945536
Drin!!
old memory: 679358976
new memory: 650945536
Faktor: 0.9581761027619071
New batch Size größer 289!!
lr: 0.17953672893967007
1

Epoch: [89 | 90] LR: 0.179537
batch Size 289
Epoch: [89][0/178]	Time 0.178 (0.178)	Data 0.306 (0.306)	Loss 0.5964 (0.5964)	Acc@1 88.612 (88.612)	Acc@5 99.288 (99.288)
Epoch: [89][64/178]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.7333 (0.7424)	Acc@1 84.342 (84.692)	Acc@5 100.000 (99.425)
Epoch: [89][128/178]	Time 0.121 (0.125)	Data 0.000 (0.003)	Loss 0.8923 (0.7563)	Acc@1 81.495 (84.366)	Acc@5 98.577 (99.349)
Max memory in training epoch: 65.0945536
lr: 0.17953672893967007
1

Epoch: [90 | 90] LR: 0.179537
batch Size 289
Epoch: [90][0/178]	Time 0.186 (0.186)	Data 0.272 (0.272)	Loss 0.7771 (0.7771)	Acc@1 84.698 (84.698)	Acc@5 99.288 (99.288)
Epoch: [90][64/178]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.7887 (0.7489)	Acc@1 80.783 (84.511)	Acc@5 99.288 (99.266)
Epoch: [90][128/178]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.8174 (0.7502)	Acc@1 81.139 (84.557)	Acc@5 97.865 (99.250)
Max memory in training epoch: 65.0945536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353074 ; 357408 ; 0.9878738024890321
[INFO] Storing checkpoint...
  75.65
Max memory: 89.8879488
 22.513s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3006
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1488896
lr: 0.2026801354045494
1

Epoch: [91 | 95] LR: 0.202680
batch Size 289
Epoch: [91][0/174]	Time 0.210 (0.210)	Data 0.292 (0.292)	Loss 0.7237 (0.7237)	Acc@1 83.391 (83.391)	Acc@5 99.654 (99.654)
Epoch: [91][64/174]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 0.6909 (0.7391)	Acc@1 87.889 (84.557)	Acc@5 98.962 (99.452)
Epoch: [91][128/174]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.8625 (0.7681)	Acc@1 79.585 (83.718)	Acc@5 98.616 (99.346)
Max memory in training epoch: 64.8078848
lr: 0.2026801354045494
1

Epoch: [92 | 95] LR: 0.202680
batch Size 289
Epoch: [92][0/174]	Time 0.183 (0.183)	Data 0.284 (0.284)	Loss 1.3418 (1.3418)	Acc@1 63.668 (63.668)	Acc@5 96.540 (96.540)
Epoch: [92][64/174]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 1.0299 (1.3757)	Acc@1 78.201 (65.941)	Acc@5 98.270 (96.114)
Epoch: [92][128/174]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.8916 (1.2085)	Acc@1 82.353 (71.463)	Acc@5 99.654 (97.261)
Max memory in training epoch: 65.3649408
lr: 0.2026801354045494
1

Epoch: [93 | 95] LR: 0.020268
batch Size 289
Epoch: [93][0/174]	Time 0.201 (0.201)	Data 0.287 (0.287)	Loss 0.9759 (0.9759)	Acc@1 77.509 (77.509)	Acc@5 99.654 (99.654)
Epoch: [93][64/174]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.7662 (0.8293)	Acc@1 85.121 (83.742)	Acc@5 99.308 (99.212)
Epoch: [93][128/174]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6910 (0.7971)	Acc@1 89.619 (84.638)	Acc@5 99.654 (99.308)
Max memory in training epoch: 65.3649408
Drin!!
old memory: 650945536
new memory: 653649408
Faktor: 1.0041537607226174
New batch Size kleiner 290!!
lr: 0.020268013540454943
1

Epoch: [94 | 95] LR: 0.020268
batch Size 290
Epoch: [94][0/174]	Time 0.166 (0.166)	Data 0.307 (0.307)	Loss 0.8071 (0.8071)	Acc@1 84.429 (84.429)	Acc@5 98.616 (98.616)
Epoch: [94][64/174]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6946 (0.7261)	Acc@1 86.159 (86.670)	Acc@5 100.000 (99.505)
Epoch: [94][128/174]	Time 0.125 (0.127)	Data 0.000 (0.003)	Loss 0.6951 (0.7148)	Acc@1 89.273 (87.047)	Acc@5 99.308 (99.541)
Max memory in training epoch: 65.3649408
lr: 0.020268013540454943
1

Epoch: [95 | 95] LR: 0.020268
batch Size 290
Epoch: [95][0/174]	Time 0.178 (0.178)	Data 0.287 (0.287)	Loss 0.6768 (0.6768)	Acc@1 87.889 (87.889)	Acc@5 99.308 (99.308)
Epoch: [95][64/174]	Time 0.122 (0.128)	Data 0.000 (0.005)	Loss 0.6456 (0.6962)	Acc@1 89.273 (87.117)	Acc@5 99.654 (99.473)
Epoch: [95][128/174]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.6279 (0.6811)	Acc@1 88.927 (87.651)	Acc@5 100.000 (99.528)
Max memory in training epoch: 65.3649408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 349894 ; 353074 ; 0.9909933894877561
[INFO] Storing checkpoint...
  85.45
Max memory: 89.0725376
 22.603s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3471
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1476608
lr: 0.022959859088796615
1

Epoch: [96 | 100] LR: 0.022960
batch Size 290
Epoch: [96][0/173]	Time 0.200 (0.200)	Data 0.268 (0.268)	Loss 0.6831 (0.6831)	Acc@1 88.276 (88.276)	Acc@5 99.655 (99.655)
Epoch: [96][64/173]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.6531 (0.6435)	Acc@1 86.207 (88.928)	Acc@5 99.310 (99.613)
Epoch: [96][128/173]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.5880 (0.6422)	Acc@1 89.310 (88.968)	Acc@5 100.000 (99.588)
Max memory in training epoch: 64.4256768
lr: 0.022959859088796615
1

Epoch: [97 | 100] LR: 0.022960
batch Size 290
Epoch: [97][0/173]	Time 0.184 (0.184)	Data 0.299 (0.299)	Loss 0.5669 (0.5669)	Acc@1 93.793 (93.793)	Acc@5 98.966 (98.966)
Epoch: [97][64/173]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.6787 (0.6174)	Acc@1 88.276 (89.597)	Acc@5 99.310 (99.645)
Epoch: [97][128/173]	Time 0.124 (0.127)	Data 0.000 (0.003)	Loss 0.6335 (0.6191)	Acc@1 86.207 (89.265)	Acc@5 100.000 (99.658)
Max memory in training epoch: 64.6888448
lr: 0.022959859088796615
1

Epoch: [98 | 100] LR: 0.022960
batch Size 290
Epoch: [98][0/173]	Time 0.175 (0.175)	Data 0.300 (0.300)	Loss 0.5525 (0.5525)	Acc@1 90.345 (90.345)	Acc@5 99.655 (99.655)
Epoch: [98][64/173]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.5501 (0.5946)	Acc@1 91.034 (89.846)	Acc@5 100.000 (99.629)
Epoch: [98][128/173]	Time 0.120 (0.127)	Data 0.000 (0.003)	Loss 0.5486 (0.5897)	Acc@1 91.724 (89.877)	Acc@5 99.310 (99.663)
Max memory in training epoch: 64.6833152
Drin!!
old memory: 653649408
new memory: 646833152
Faktor: 0.9895720000407313
New batch Size größer 300!!
lr: 0.022959859088796615
1

Epoch: [99 | 100] LR: 0.022960
batch Size 300
Epoch: [99][0/173]	Time 0.189 (0.189)	Data 0.309 (0.309)	Loss 0.5451 (0.5451)	Acc@1 91.724 (91.724)	Acc@5 99.310 (99.310)
Epoch: [99][64/173]	Time 0.138 (0.127)	Data 0.000 (0.005)	Loss 0.5411 (0.5607)	Acc@1 90.000 (90.727)	Acc@5 100.000 (99.761)
Epoch: [99][128/173]	Time 0.117 (0.127)	Data 0.000 (0.003)	Loss 0.5561 (0.5651)	Acc@1 90.000 (90.503)	Acc@5 100.000 (99.735)
Max memory in training epoch: 64.6833152
lr: 0.022959859088796615
1

Epoch: [100 | 100] LR: 0.022960
batch Size 300
Epoch: [100][0/173]	Time 0.185 (0.185)	Data 0.287 (0.287)	Loss 0.4939 (0.4939)	Acc@1 92.759 (92.759)	Acc@5 100.000 (100.000)
Epoch: [100][64/173]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.5596 (0.5392)	Acc@1 91.034 (90.971)	Acc@5 99.310 (99.777)
Epoch: [100][128/173]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.5056 (0.5441)	Acc@1 91.379 (90.885)	Acc@5 99.310 (99.770)
Max memory in training epoch: 64.6833152
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 347586 ; 349894 ; 0.9934037165541564
[INFO] Storing checkpoint...
  89.02
Max memory: 87.9117312
 22.218s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 449
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1467392
lr: 0.026906084869683534
1

Epoch: [101 | 105] LR: 0.026906
batch Size 300
Epoch: [101][0/167]	Time 0.209 (0.209)	Data 0.276 (0.276)	Loss 0.5061 (0.5061)	Acc@1 92.000 (92.000)	Acc@5 100.000 (100.000)
Epoch: [101][64/167]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.5571 (0.5238)	Acc@1 90.667 (91.579)	Acc@5 99.667 (99.831)
Epoch: [101][128/167]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.4270 (0.5262)	Acc@1 94.000 (91.326)	Acc@5 100.000 (99.804)
Max memory in training epoch: 66.5216
lr: 0.026906084869683534
1

Epoch: [102 | 105] LR: 0.026906
batch Size 300
Epoch: [102][0/167]	Time 0.165 (0.165)	Data 0.281 (0.281)	Loss 0.5200 (0.5200)	Acc@1 91.667 (91.667)	Acc@5 99.667 (99.667)
Epoch: [102][64/167]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.4967 (0.5103)	Acc@1 92.667 (91.600)	Acc@5 100.000 (99.769)
Epoch: [102][128/167]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.5243 (0.5141)	Acc@1 91.667 (91.364)	Acc@5 99.333 (99.793)
Max memory in training epoch: 66.6720256
lr: 0.026906084869683534
1

Epoch: [103 | 105] LR: 0.026906
batch Size 300
Epoch: [103][0/167]	Time 0.190 (0.190)	Data 0.337 (0.337)	Loss 0.4807 (0.4807)	Acc@1 92.333 (92.333)	Acc@5 100.000 (100.000)
Epoch: [103][64/167]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.5063 (0.4942)	Acc@1 91.000 (91.892)	Acc@5 100.000 (99.841)
Epoch: [103][128/167]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.5298 (0.4999)	Acc@1 89.667 (91.548)	Acc@5 99.667 (99.837)
Max memory in training epoch: 66.6720256
Drin!!
old memory: 646833152
new memory: 666720256
Faktor: 1.0307453381733904
New batch Size kleiner 309!!
lr: 0.026906084869683534
1

Epoch: [104 | 105] LR: 0.026906
batch Size 309
Epoch: [104][0/167]	Time 0.181 (0.181)	Data 0.271 (0.271)	Loss 0.5061 (0.5061)	Acc@1 91.000 (91.000)	Acc@5 100.000 (100.000)
Epoch: [104][64/167]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.4526 (0.4773)	Acc@1 94.333 (92.256)	Acc@5 99.667 (99.831)
Epoch: [104][128/167]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.4323 (0.4802)	Acc@1 92.333 (92.067)	Acc@5 100.000 (99.817)
Max memory in training epoch: 66.6720256
lr: 0.026906084869683534
1

Epoch: [105 | 105] LR: 0.026906
batch Size 309
Epoch: [105][0/167]	Time 0.194 (0.194)	Data 0.313 (0.313)	Loss 0.4442 (0.4442)	Acc@1 93.333 (93.333)	Acc@5 100.000 (100.000)
Epoch: [105][64/167]	Time 0.120 (0.130)	Data 0.000 (0.005)	Loss 0.4003 (0.4672)	Acc@1 95.667 (92.226)	Acc@5 100.000 (99.846)
Epoch: [105][128/167]	Time 0.132 (0.129)	Data 0.000 (0.003)	Loss 0.5038 (0.4742)	Acc@1 90.667 (91.925)	Acc@5 100.000 (99.819)
Max memory in training epoch: 66.6720256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 345998 ; 347586 ; 0.9954313464869126
[INFO] Storing checkpoint...
  88.54
Max memory: 88.3871744
 22.030s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5176
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.146176
lr: 0.032476485252860204
1

Epoch: [106 | 110] LR: 0.032476
batch Size 309
Epoch: [106][0/162]	Time 0.199 (0.199)	Data 0.285 (0.285)	Loss 0.4687 (0.4687)	Acc@1 94.498 (94.498)	Acc@5 99.676 (99.676)
Epoch: [106][64/162]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.4695 (0.4680)	Acc@1 92.880 (92.074)	Acc@5 100.000 (99.866)
Epoch: [106][128/162]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.4600 (0.4789)	Acc@1 92.557 (91.648)	Acc@5 99.676 (99.827)
Max memory in training epoch: 69.7690112
lr: 0.032476485252860204
1

Epoch: [107 | 110] LR: 0.032476
batch Size 309
Epoch: [107][0/162]	Time 0.188 (0.188)	Data 0.308 (0.308)	Loss 0.4704 (0.4704)	Acc@1 91.586 (91.586)	Acc@5 100.000 (100.000)
Epoch: [107][64/162]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.4779 (0.4664)	Acc@1 91.586 (91.845)	Acc@5 99.676 (99.831)
Epoch: [107][128/162]	Time 0.120 (0.130)	Data 0.000 (0.003)	Loss 0.5017 (0.4721)	Acc@1 90.939 (91.674)	Acc@5 99.676 (99.802)
Max memory in training epoch: 69.9052544
lr: 0.032476485252860204
1

Epoch: [108 | 110] LR: 0.032476
batch Size 309
Epoch: [108][0/162]	Time 0.197 (0.197)	Data 0.293 (0.293)	Loss 0.5237 (0.5237)	Acc@1 88.997 (88.997)	Acc@5 100.000 (100.000)
Epoch: [108][64/162]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.4240 (0.4522)	Acc@1 93.851 (92.143)	Acc@5 100.000 (99.846)
Epoch: [108][128/162]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.4865 (0.4649)	Acc@1 91.262 (91.779)	Acc@5 100.000 (99.827)
Max memory in training epoch: 69.9405824
Drin!!
old memory: 666720256
new memory: 699405824
Faktor: 1.0490244112217284
New batch Size kleiner 324!!
lr: 0.032476485252860204
1

Epoch: [109 | 110] LR: 0.032476
batch Size 324
Epoch: [109][0/162]	Time 0.169 (0.169)	Data 0.316 (0.316)	Loss 0.4320 (0.4320)	Acc@1 92.557 (92.557)	Acc@5 99.676 (99.676)
Epoch: [109][64/162]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.4725 (0.4570)	Acc@1 91.909 (92.024)	Acc@5 100.000 (99.816)
Epoch: [109][128/162]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.5939 (0.4644)	Acc@1 87.379 (91.661)	Acc@5 100.000 (99.822)
Max memory in training epoch: 69.9405824
lr: 0.032476485252860204
1

Epoch: [110 | 110] LR: 0.032476
batch Size 324
Epoch: [110][0/162]	Time 0.184 (0.184)	Data 0.325 (0.325)	Loss 0.5244 (0.5244)	Acc@1 90.939 (90.939)	Acc@5 99.029 (99.029)
Epoch: [110][64/162]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.4076 (0.4452)	Acc@1 94.498 (92.228)	Acc@5 100.000 (99.816)
Epoch: [110][128/162]	Time 0.132 (0.132)	Data 0.000 (0.003)	Loss 0.4968 (0.4526)	Acc@1 90.291 (91.927)	Acc@5 100.000 (99.817)
Max memory in training epoch: 69.9405824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 345564 ; 345998 ; 0.9987456574893496
[INFO] Storing checkpoint...
  87.25
Max memory: 87.92448
 21.929s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5319
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.14592
lr: 0.041103051648151194
1

Epoch: [111 | 115] LR: 0.041103
batch Size 324
Epoch: [111][0/155]	Time 0.203 (0.203)	Data 0.271 (0.271)	Loss 0.4646 (0.4646)	Acc@1 92.901 (92.901)	Acc@5 100.000 (100.000)
Epoch: [111][64/155]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.4652 (0.4612)	Acc@1 90.741 (91.709)	Acc@5 99.691 (99.782)
Epoch: [111][128/155]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.4378 (0.4685)	Acc@1 91.049 (91.336)	Acc@5 100.000 (99.785)
Max memory in training epoch: 71.7292032
lr: 0.041103051648151194
1

Epoch: [112 | 115] LR: 0.041103
batch Size 324
Epoch: [112][0/155]	Time 0.163 (0.163)	Data 0.312 (0.312)	Loss 0.4739 (0.4739)	Acc@1 92.284 (92.284)	Acc@5 98.765 (98.765)
Epoch: [112][64/155]	Time 0.121 (0.130)	Data 0.000 (0.005)	Loss 0.5501 (0.4767)	Acc@1 89.815 (91.083)	Acc@5 99.383 (99.782)
Epoch: [112][128/155]	Time 0.136 (0.130)	Data 0.000 (0.003)	Loss 0.4442 (0.4816)	Acc@1 91.358 (90.868)	Acc@5 100.000 (99.780)
Max memory in training epoch: 71.8462464
lr: 0.041103051648151194
1

Epoch: [113 | 115] LR: 0.041103
batch Size 324
Epoch: [113][0/155]	Time 0.163 (0.163)	Data 0.270 (0.270)	Loss 0.4046 (0.4046)	Acc@1 93.827 (93.827)	Acc@5 100.000 (100.000)
Epoch: [113][64/155]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.4947 (0.4640)	Acc@1 90.123 (91.273)	Acc@5 99.074 (99.810)
Epoch: [113][128/155]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.4584 (0.4727)	Acc@1 91.358 (90.994)	Acc@5 99.691 (99.782)
Max memory in training epoch: 71.8462464
Drin!!
old memory: 699405824
new memory: 718462464
Faktor: 1.027246899219415
New batch Size kleiner 332!!
lr: 0.041103051648151194
1

Epoch: [114 | 115] LR: 0.041103
batch Size 332
Epoch: [114][0/155]	Time 0.199 (0.199)	Data 0.355 (0.355)	Loss 0.4677 (0.4677)	Acc@1 89.815 (89.815)	Acc@5 100.000 (100.000)
Epoch: [114][64/155]	Time 0.129 (0.131)	Data 0.000 (0.006)	Loss 0.4883 (0.4718)	Acc@1 92.593 (91.064)	Acc@5 99.691 (99.791)
Epoch: [114][128/155]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.5250 (0.4722)	Acc@1 90.432 (91.064)	Acc@5 99.691 (99.789)
Max memory in training epoch: 71.8462464
lr: 0.041103051648151194
1

Epoch: [115 | 115] LR: 0.041103
batch Size 332
Epoch: [115][0/155]	Time 0.150 (0.150)	Data 0.311 (0.311)	Loss 0.4472 (0.4472)	Acc@1 90.432 (90.432)	Acc@5 100.000 (100.000)
Epoch: [115][64/155]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.5256 (0.4638)	Acc@1 89.815 (91.097)	Acc@5 99.383 (99.753)
Epoch: [115][128/155]	Time 0.133 (0.131)	Data 0.000 (0.003)	Loss 0.4218 (0.4710)	Acc@1 93.210 (90.942)	Acc@5 100.000 (99.737)
Max memory in training epoch: 71.8462464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 343768 ; 345564 ; 0.9948026993552569
[INFO] Storing checkpoint...
  85.65
Max memory: 88.666112
 20.615s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 133
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1445888
lr: 0.05330552010619608
1

Epoch: [116 | 120] LR: 0.053306
batch Size 332
Epoch: [116][0/151]	Time 0.188 (0.188)	Data 0.286 (0.286)	Loss 0.4232 (0.4232)	Acc@1 92.169 (92.169)	Acc@5 100.000 (100.000)
Epoch: [116][64/151]	Time 0.115 (0.125)	Data 0.000 (0.005)	Loss 0.5258 (0.4717)	Acc@1 87.349 (90.908)	Acc@5 100.000 (99.824)
Epoch: [116][128/151]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.5228 (0.4976)	Acc@1 91.265 (89.908)	Acc@5 100.000 (99.797)
Max memory in training epoch: 71.4510848
lr: 0.05330552010619608
1

Epoch: [117 | 120] LR: 0.053306
batch Size 332
Epoch: [117][0/151]	Time 0.213 (0.213)	Data 0.329 (0.329)	Loss 0.4925 (0.4925)	Acc@1 90.060 (90.060)	Acc@5 99.699 (99.699)
Epoch: [117][64/151]	Time 0.125 (0.125)	Data 0.000 (0.005)	Loss 0.5477 (0.4889)	Acc@1 87.048 (90.236)	Acc@5 100.000 (99.815)
Epoch: [117][128/151]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.5110 (0.5007)	Acc@1 89.759 (89.969)	Acc@5 99.699 (99.755)
Max memory in training epoch: 71.5991552
lr: 0.05330552010619608
1

Epoch: [118 | 120] LR: 0.053306
batch Size 332
Epoch: [118][0/151]	Time 0.166 (0.166)	Data 0.311 (0.311)	Loss 0.4792 (0.4792)	Acc@1 90.663 (90.663)	Acc@5 99.699 (99.699)
Epoch: [118][64/151]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.4718 (0.4964)	Acc@1 92.470 (90.139)	Acc@5 100.000 (99.773)
Epoch: [118][128/151]	Time 0.123 (0.124)	Data 0.000 (0.003)	Loss 0.5568 (0.5006)	Acc@1 88.554 (90.016)	Acc@5 99.699 (99.741)
Max memory in training epoch: 71.5991552
Drin!!
old memory: 718462464
new memory: 715991552
Faktor: 0.9965608335524679
New batch Size größer 310!!
lr: 0.05330552010619608
1

Epoch: [119 | 120] LR: 0.053306
batch Size 310
Epoch: [119][0/151]	Time 0.140 (0.140)	Data 0.323 (0.323)	Loss 0.5169 (0.5169)	Acc@1 87.651 (87.651)	Acc@5 99.699 (99.699)
Epoch: [119][64/151]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.4821 (0.4904)	Acc@1 90.663 (90.449)	Acc@5 100.000 (99.754)
Epoch: [119][128/151]	Time 0.128 (0.127)	Data 0.000 (0.003)	Loss 0.4857 (0.5014)	Acc@1 90.964 (90.009)	Acc@5 99.699 (99.713)
Max memory in training epoch: 71.5991552
lr: 0.05330552010619608
1

Epoch: [120 | 120] LR: 0.053306
batch Size 310
Epoch: [120][0/151]	Time 0.176 (0.176)	Data 0.314 (0.314)	Loss 0.4479 (0.4479)	Acc@1 92.470 (92.470)	Acc@5 99.699 (99.699)
Epoch: [120][64/151]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.5297 (0.4876)	Acc@1 89.759 (90.538)	Acc@5 99.699 (99.787)
Epoch: [120][128/151]	Time 0.123 (0.124)	Data 0.000 (0.003)	Loss 0.4783 (0.4937)	Acc@1 89.759 (90.352)	Acc@5 100.000 (99.755)
Max memory in training epoch: 71.5991552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 342756 ; 343768 ; 0.9970561541504736
[INFO] Storing checkpoint...
  78.82
Max memory: 85.698048
 19.110s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5580
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.144128
lr: 0.06454965325359682
1

Epoch: [121 | 125] LR: 0.064550
batch Size 310
Epoch: [121][0/162]	Time 0.211 (0.211)	Data 0.279 (0.279)	Loss 0.4882 (0.4882)	Acc@1 90.968 (90.968)	Acc@5 99.355 (99.355)
Epoch: [121][64/162]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.5471 (0.5099)	Acc@1 89.032 (89.816)	Acc@5 99.355 (99.593)
Epoch: [121][128/162]	Time 0.128 (0.123)	Data 0.000 (0.002)	Loss 0.5260 (0.5294)	Acc@1 89.677 (89.175)	Acc@5 99.355 (99.627)
Max memory in training epoch: 67.5241472
lr: 0.06454965325359682
1

Epoch: [122 | 125] LR: 0.064550
batch Size 310
Epoch: [122][0/162]	Time 0.198 (0.198)	Data 0.272 (0.272)	Loss 0.5272 (0.5272)	Acc@1 88.710 (88.710)	Acc@5 99.355 (99.355)
Epoch: [122][64/162]	Time 0.127 (0.123)	Data 0.000 (0.004)	Loss 0.5308 (0.5371)	Acc@1 89.032 (89.012)	Acc@5 100.000 (99.653)
Epoch: [122][128/162]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.5747 (0.5437)	Acc@1 88.387 (88.990)	Acc@5 99.677 (99.657)
Max memory in training epoch: 67.5646976
lr: 0.06454965325359682
1

Epoch: [123 | 125] LR: 0.064550
batch Size 310
Epoch: [123][0/162]	Time 0.166 (0.166)	Data 0.278 (0.278)	Loss 0.5101 (0.5101)	Acc@1 90.645 (90.645)	Acc@5 99.677 (99.677)
Epoch: [123][64/162]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.4882 (0.5296)	Acc@1 92.258 (89.469)	Acc@5 99.677 (99.633)
Epoch: [123][128/162]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.4809 (0.5353)	Acc@1 91.613 (89.377)	Acc@5 100.000 (99.645)
Max memory in training epoch: 67.5646976
Drin!!
old memory: 715991552
new memory: 675646976
Faktor: 0.9436521619741123
New batch Size größer 307!!
lr: 0.06454965325359682
1

Epoch: [124 | 125] LR: 0.064550
batch Size 307
Epoch: [124][0/162]	Time 0.153 (0.153)	Data 0.292 (0.292)	Loss 0.5098 (0.5098)	Acc@1 89.677 (89.677)	Acc@5 99.355 (99.355)
Epoch: [124][64/162]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.4666 (0.5310)	Acc@1 90.968 (89.429)	Acc@5 99.677 (99.692)
Epoch: [124][128/162]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6307 (0.5369)	Acc@1 87.742 (89.207)	Acc@5 99.032 (99.700)
Max memory in training epoch: 67.5646976
lr: 0.06454965325359682
1

Epoch: [125 | 125] LR: 0.064550
batch Size 307
Epoch: [125][0/162]	Time 0.165 (0.165)	Data 0.279 (0.279)	Loss 0.4892 (0.4892)	Acc@1 90.323 (90.323)	Acc@5 99.355 (99.355)
Epoch: [125][64/162]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.5379 (0.5382)	Acc@1 89.355 (89.290)	Acc@5 100.000 (99.643)
Epoch: [125][128/162]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.5117 (0.5357)	Acc@1 91.290 (89.325)	Acc@5 99.677 (99.667)
Max memory in training epoch: 67.5646976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 328902 ; 342756 ; 0.9595805762699996
[INFO] Storing checkpoint...
  78.57
Max memory: 85.019392
 20.317s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3681
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1387008
lr: 0.07740915448771181
1

Epoch: [126 | 130] LR: 0.077409
batch Size 307
Epoch: [126][0/163]	Time 0.175 (0.175)	Data 0.315 (0.315)	Loss 0.4934 (0.4934)	Acc@1 88.599 (88.599)	Acc@5 100.000 (100.000)
Epoch: [126][64/163]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.5547 (0.5360)	Acc@1 88.274 (89.151)	Acc@5 99.674 (99.724)
Epoch: [126][128/163]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.5720 (0.5533)	Acc@1 88.925 (88.753)	Acc@5 99.674 (99.669)
Max memory in training epoch: 66.0217856
lr: 0.07740915448771181
1

Epoch: [127 | 130] LR: 0.077409
batch Size 307
Epoch: [127][0/163]	Time 0.165 (0.165)	Data 0.311 (0.311)	Loss 0.5546 (0.5546)	Acc@1 89.902 (89.902)	Acc@5 99.674 (99.674)
Epoch: [127][64/163]	Time 0.126 (0.121)	Data 0.000 (0.005)	Loss 0.5929 (0.5639)	Acc@1 85.993 (88.539)	Acc@5 99.349 (99.699)
Epoch: [127][128/163]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.5860 (0.5652)	Acc@1 86.319 (88.577)	Acc@5 99.349 (99.657)
Max memory in training epoch: 66.2224896
lr: 0.07740915448771181
1

Epoch: [128 | 130] LR: 0.077409
batch Size 307
Epoch: [128][0/163]	Time 0.153 (0.153)	Data 0.302 (0.302)	Loss 0.6237 (0.6237)	Acc@1 89.577 (89.577)	Acc@5 99.349 (99.349)
Epoch: [128][64/163]	Time 0.125 (0.121)	Data 0.000 (0.005)	Loss 0.6534 (0.5586)	Acc@1 83.713 (88.820)	Acc@5 99.023 (99.689)
Epoch: [128][128/163]	Time 0.127 (0.122)	Data 0.000 (0.003)	Loss 0.5605 (0.5627)	Acc@1 86.645 (88.549)	Acc@5 99.674 (99.646)
Max memory in training epoch: 66.2224896
Drin!!
old memory: 675646976
new memory: 662224896
Faktor: 0.9801344778016146
New batch Size größer 310!!
lr: 0.07740915448771181
1

Epoch: [129 | 130] LR: 0.077409
batch Size 310
Epoch: [129][0/163]	Time 0.173 (0.173)	Data 0.290 (0.290)	Loss 0.5739 (0.5739)	Acc@1 89.577 (89.577)	Acc@5 99.674 (99.674)
Epoch: [129][64/163]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.6077 (0.5499)	Acc@1 86.971 (89.020)	Acc@5 99.674 (99.609)
Epoch: [129][128/163]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.6072 (0.5582)	Acc@1 87.622 (88.781)	Acc@5 100.000 (99.649)
Max memory in training epoch: 66.2224896
lr: 0.07740915448771181
1

Epoch: [130 | 130] LR: 0.077409
batch Size 310
Epoch: [130][0/163]	Time 0.149 (0.149)	Data 0.277 (0.277)	Loss 0.6210 (0.6210)	Acc@1 87.948 (87.948)	Acc@5 99.674 (99.674)
Epoch: [130][64/163]	Time 0.122 (0.122)	Data 0.000 (0.004)	Loss 0.5868 (0.5532)	Acc@1 86.971 (89.070)	Acc@5 99.674 (99.724)
Epoch: [130][128/163]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.5391 (0.5555)	Acc@1 87.948 (88.953)	Acc@5 99.674 (99.715)
Max memory in training epoch: 66.2224896
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 317208 ; 328902 ; 0.9644453363007826
[INFO] Storing checkpoint...
  81.36
Max memory: 84.1939456
 20.223s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2805
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1340416
lr: 0.09373764801246352
1

Epoch: [131 | 135] LR: 0.093738
batch Size 310
Epoch: [131][0/162]	Time 0.206 (0.206)	Data 0.284 (0.284)	Loss 0.5779 (0.5779)	Acc@1 87.419 (87.419)	Acc@5 100.000 (100.000)
Epoch: [131][64/162]	Time 0.113 (0.121)	Data 0.000 (0.005)	Loss 0.6308 (0.5737)	Acc@1 83.871 (88.129)	Acc@5 99.677 (99.603)
Epoch: [131][128/162]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6047 (0.5917)	Acc@1 87.742 (87.714)	Acc@5 100.000 (99.550)
Max memory in training epoch: 65.4356992
lr: 0.09373764801246352
1

Epoch: [132 | 135] LR: 0.093738
batch Size 310
Epoch: [132][0/162]	Time 0.174 (0.174)	Data 0.303 (0.303)	Loss 0.5700 (0.5700)	Acc@1 89.032 (89.032)	Acc@5 100.000 (100.000)
Epoch: [132][64/162]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.5732 (0.6130)	Acc@1 89.677 (87.434)	Acc@5 99.355 (99.489)
Epoch: [132][128/162]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.5540 (0.6056)	Acc@1 89.355 (87.659)	Acc@5 100.000 (99.545)
Max memory in training epoch: 65.3554688
lr: 0.09373764801246352
1

Epoch: [133 | 135] LR: 0.093738
batch Size 310
Epoch: [133][0/162]	Time 0.181 (0.181)	Data 0.280 (0.280)	Loss 0.5991 (0.5991)	Acc@1 87.742 (87.742)	Acc@5 99.677 (99.677)
Epoch: [133][64/162]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.5915 (0.5930)	Acc@1 87.419 (88.213)	Acc@5 100.000 (99.548)
Epoch: [133][128/162]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.5495 (0.6036)	Acc@1 88.065 (87.962)	Acc@5 100.000 (99.550)
Max memory in training epoch: 65.3554688
Drin!!
old memory: 662224896
new memory: 653554688
Faktor: 0.9869074568890868
New batch Size größer 317!!
lr: 0.09373764801246352
1

Epoch: [134 | 135] LR: 0.093738
batch Size 317
Epoch: [134][0/162]	Time 0.148 (0.148)	Data 0.306 (0.306)	Loss 0.5645 (0.5645)	Acc@1 88.710 (88.710)	Acc@5 99.677 (99.677)
Epoch: [134][64/162]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6355 (0.5920)	Acc@1 87.419 (88.174)	Acc@5 99.677 (99.608)
Epoch: [134][128/162]	Time 0.118 (0.119)	Data 0.000 (0.003)	Loss 0.6260 (0.5976)	Acc@1 87.419 (88.009)	Acc@5 99.032 (99.542)
Max memory in training epoch: 65.3554688
lr: 0.09373764801246352
1

Epoch: [135 | 135] LR: 0.093738
batch Size 317
Epoch: [135][0/162]	Time 0.180 (0.180)	Data 0.276 (0.276)	Loss 0.6257 (0.6257)	Acc@1 87.097 (87.097)	Acc@5 99.677 (99.677)
Epoch: [135][64/162]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.5596 (0.6009)	Acc@1 88.065 (87.801)	Acc@5 100.000 (99.613)
Epoch: [135][128/162]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6726 (0.5952)	Acc@1 86.452 (88.105)	Acc@5 99.032 (99.610)
Max memory in training epoch: 65.3554688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 315188 ; 317208 ; 0.9936319386648508
[INFO] Storing checkpoint...
  80.3
Max memory: 83.6206592
 19.665s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5203
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1331712
lr: 0.11607357195293334
1

Epoch: [136 | 140] LR: 0.116074
batch Size 317
Epoch: [136][0/158]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.5934 (0.5934)	Acc@1 87.382 (87.382)	Acc@5 100.000 (100.000)
Epoch: [136][64/158]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.6984 (0.6060)	Acc@1 85.174 (87.678)	Acc@5 99.685 (99.515)
Epoch: [136][128/158]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6381 (0.6176)	Acc@1 85.489 (87.450)	Acc@5 99.685 (99.491)
Max memory in training epoch: 65.9793408
lr: 0.11607357195293334
1

Epoch: [137 | 140] LR: 0.116074
batch Size 317
Epoch: [137][0/158]	Time 0.180 (0.180)	Data 0.269 (0.269)	Loss 0.6478 (0.6478)	Acc@1 86.751 (86.751)	Acc@5 98.423 (98.423)
Epoch: [137][64/158]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.6202 (0.6221)	Acc@1 87.697 (87.197)	Acc@5 99.369 (99.505)
Epoch: [137][128/158]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6389 (0.6338)	Acc@1 87.382 (86.944)	Acc@5 98.738 (99.494)
Max memory in training epoch: 66.0972032
lr: 0.11607357195293334
1

Epoch: [138 | 140] LR: 0.116074
batch Size 317
Epoch: [138][0/158]	Time 0.181 (0.181)	Data 0.327 (0.327)	Loss 0.5222 (0.5222)	Acc@1 90.852 (90.852)	Acc@5 100.000 (100.000)
Epoch: [138][64/158]	Time 0.124 (0.125)	Data 0.000 (0.005)	Loss 0.6496 (0.6245)	Acc@1 87.066 (87.411)	Acc@5 99.054 (99.486)
Epoch: [138][128/158]	Time 0.129 (0.124)	Data 0.000 (0.003)	Loss 0.7202 (0.6353)	Acc@1 82.650 (87.025)	Acc@5 99.054 (99.506)
Max memory in training epoch: 66.0972032
Drin!!
old memory: 653554688
new memory: 660972032
Faktor: 1.0113492323384574
New batch Size kleiner 320!!
lr: 0.11607357195293334
1

Epoch: [139 | 140] LR: 0.116074
batch Size 320
Epoch: [139][0/158]	Time 0.158 (0.158)	Data 0.316 (0.316)	Loss 0.6484 (0.6484)	Acc@1 86.751 (86.751)	Acc@5 99.369 (99.369)
Epoch: [139][64/158]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.5615 (0.6205)	Acc@1 89.274 (87.488)	Acc@5 99.685 (99.592)
Epoch: [139][128/158]	Time 0.125 (0.123)	Data 0.000 (0.003)	Loss 0.6334 (0.6316)	Acc@1 87.066 (87.142)	Acc@5 99.685 (99.538)
Max memory in training epoch: 66.0972032
lr: 0.11607357195293334
1

Epoch: [140 | 140] LR: 0.116074
batch Size 320
Epoch: [140][0/158]	Time 0.179 (0.179)	Data 0.289 (0.289)	Loss 0.6753 (0.6753)	Acc@1 87.382 (87.382)	Acc@5 98.738 (98.738)
Epoch: [140][64/158]	Time 0.127 (0.124)	Data 0.000 (0.005)	Loss 0.5827 (0.6221)	Acc@1 89.274 (87.610)	Acc@5 99.685 (99.534)
Epoch: [140][128/158]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.5697 (0.6320)	Acc@1 91.167 (87.203)	Acc@5 99.369 (99.482)
Max memory in training epoch: 66.0972032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 314754 ; 315188 ; 0.9986230440245187
[INFO] Storing checkpoint...
  80.77
Max memory: 83.516672
 19.759s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8733
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1330176
lr: 0.1450919649411667
1

Epoch: [141 | 145] LR: 0.145092
batch Size 320
Epoch: [141][0/157]	Time 0.177 (0.177)	Data 0.310 (0.310)	Loss 0.5586 (0.5586)	Acc@1 88.438 (88.438)	Acc@5 99.688 (99.688)
Epoch: [141][64/157]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.6742 (0.6436)	Acc@1 86.250 (86.913)	Acc@5 99.375 (99.466)
Epoch: [141][128/157]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.6291 (0.6640)	Acc@1 87.812 (86.134)	Acc@5 99.375 (99.402)
Max memory in training epoch: 66.2070784
lr: 0.1450919649411667
1

Epoch: [142 | 145] LR: 0.145092
batch Size 320
Epoch: [142][0/157]	Time 0.156 (0.156)	Data 0.305 (0.305)	Loss 0.6519 (0.6519)	Acc@1 89.062 (89.062)	Acc@5 99.688 (99.688)
Epoch: [142][64/157]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.6553 (0.6750)	Acc@1 86.875 (86.038)	Acc@5 99.688 (99.452)
Epoch: [142][128/157]	Time 0.122 (0.123)	Data 0.000 (0.003)	Loss 0.7388 (0.6702)	Acc@1 84.062 (86.252)	Acc@5 99.688 (99.462)
Max memory in training epoch: 66.2988288
lr: 0.1450919649411667
1

Epoch: [143 | 145] LR: 0.145092
batch Size 320
Epoch: [143][0/157]	Time 0.180 (0.180)	Data 0.289 (0.289)	Loss 0.6860 (0.6860)	Acc@1 86.875 (86.875)	Acc@5 100.000 (100.000)
Epoch: [143][64/157]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.7050 (0.6714)	Acc@1 83.438 (86.495)	Acc@5 99.375 (99.438)
Epoch: [143][128/157]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.6748 (0.6747)	Acc@1 85.312 (86.303)	Acc@5 100.000 (99.455)
Max memory in training epoch: 66.2988288
Drin!!
old memory: 660972032
new memory: 662988288
Faktor: 1.0030504407181937
New batch Size kleiner 320!!
lr: 0.1450919649411667
1

Epoch: [144 | 145] LR: 0.145092
batch Size 320
Epoch: [144][0/157]	Time 0.161 (0.161)	Data 0.342 (0.342)	Loss 0.6694 (0.6694)	Acc@1 86.562 (86.562)	Acc@5 99.062 (99.062)
Epoch: [144][64/157]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.7268 (0.6695)	Acc@1 85.625 (86.510)	Acc@5 99.375 (99.447)
Epoch: [144][128/157]	Time 0.122 (0.124)	Data 0.000 (0.003)	Loss 0.6895 (0.6661)	Acc@1 85.625 (86.519)	Acc@5 99.375 (99.474)
Max memory in training epoch: 66.2988288
lr: 0.1450919649411667
1

Epoch: [145 | 145] LR: 0.145092
batch Size 320
Epoch: [145][0/157]	Time 0.147 (0.147)	Data 0.309 (0.309)	Loss 0.6529 (0.6529)	Acc@1 85.625 (85.625)	Acc@5 99.688 (99.688)
Epoch: [145][64/157]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.7121 (0.6778)	Acc@1 84.375 (86.130)	Acc@5 99.375 (99.418)
Epoch: [145][128/157]	Time 0.118 (0.123)	Data 0.000 (0.003)	Loss 0.6658 (0.6761)	Acc@1 86.562 (86.134)	Acc@5 99.062 (99.414)
Max memory in training epoch: 66.2988288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 313310 ; 314754 ; 0.9954122902330074
[INFO] Storing checkpoint...
  78.86
Max memory: 83.808256
 19.673s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5889
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1324032
lr: 0.18136495617645837
1

Epoch: [146 | 150] LR: 0.181365
batch Size 320
Epoch: [146][0/157]	Time 0.196 (0.196)	Data 0.301 (0.301)	Loss 0.6794 (0.6794)	Acc@1 86.250 (86.250)	Acc@5 98.750 (98.750)
Epoch: [146][64/157]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.7689 (0.6928)	Acc@1 84.062 (85.534)	Acc@5 99.375 (99.341)
Epoch: [146][128/157]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.8056 (0.7152)	Acc@1 82.500 (84.816)	Acc@5 99.062 (99.317)
Max memory in training epoch: 65.8638336
lr: 0.18136495617645837
1

Epoch: [147 | 150] LR: 0.181365
batch Size 320
Epoch: [147][0/157]	Time 0.189 (0.189)	Data 0.280 (0.280)	Loss 0.7071 (0.7071)	Acc@1 85.625 (85.625)	Acc@5 98.125 (98.125)
Epoch: [147][64/157]	Time 0.130 (0.124)	Data 0.000 (0.004)	Loss 0.6747 (0.7326)	Acc@1 85.312 (84.587)	Acc@5 99.375 (99.327)
Epoch: [147][128/157]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.7050 (0.7394)	Acc@1 86.250 (84.351)	Acc@5 100.000 (99.312)
Max memory in training epoch: 65.8769408
lr: 0.18136495617645837
1

Epoch: [148 | 150] LR: 0.181365
batch Size 320
Epoch: [148][0/157]	Time 0.154 (0.154)	Data 0.299 (0.299)	Loss 0.6171 (0.6171)	Acc@1 88.750 (88.750)	Acc@5 99.688 (99.688)
Epoch: [148][64/157]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.6784 (0.7192)	Acc@1 85.312 (85.269)	Acc@5 100.000 (99.322)
Epoch: [148][128/157]	Time 0.120 (0.124)	Data 0.000 (0.003)	Loss 0.6918 (0.7202)	Acc@1 86.875 (85.184)	Acc@5 99.375 (99.334)
Max memory in training epoch: 65.8769408
Drin!!
old memory: 662988288
new memory: 658769408
Faktor: 0.9936365693386126
New batch Size größer 325!!
lr: 0.18136495617645837
1

Epoch: [149 | 150] LR: 0.181365
batch Size 325
Epoch: [149][0/157]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.6382 (0.6382)	Acc@1 88.438 (88.438)	Acc@5 100.000 (100.000)
Epoch: [149][64/157]	Time 0.136 (0.123)	Data 0.000 (0.005)	Loss 0.7009 (0.7201)	Acc@1 86.875 (85.346)	Acc@5 99.062 (99.317)
Epoch: [149][128/157]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.8080 (0.7184)	Acc@1 82.500 (85.148)	Acc@5 99.062 (99.329)
Max memory in training epoch: 65.8769408
lr: 0.18136495617645837
1

Epoch: [150 | 150] LR: 0.018136
batch Size 325
Epoch: [150][0/157]	Time 0.143 (0.143)	Data 0.342 (0.342)	Loss 0.7077 (0.7077)	Acc@1 86.250 (86.250)	Acc@5 99.375 (99.375)
Epoch: [150][64/157]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.5782 (0.5992)	Acc@1 89.688 (89.226)	Acc@5 99.062 (99.649)
Epoch: [150][128/157]	Time 0.118 (0.123)	Data 0.000 (0.003)	Loss 0.5138 (0.5702)	Acc@1 92.500 (90.189)	Acc@5 99.688 (99.663)
Max memory in training epoch: 65.8769408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.87
Max memory: 83.039232
 19.702s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7400
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1324032
lr: 0.02302484795208944
1

Epoch: [151 | 155] LR: 0.023025
batch Size 325
Epoch: [151][0/154]	Time 0.200 (0.200)	Data 0.311 (0.311)	Loss 0.4770 (0.4770)	Acc@1 92.615 (92.615)	Acc@5 99.385 (99.385)
Epoch: [151][64/154]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.4712 (0.5039)	Acc@1 92.000 (92.279)	Acc@5 100.000 (99.759)
Epoch: [151][128/154]	Time 0.120 (0.125)	Data 0.000 (0.003)	Loss 0.5654 (0.5058)	Acc@1 88.000 (92.100)	Acc@5 100.000 (99.783)
Max memory in training epoch: 66.9748736
lr: 0.02302484795208944
1

Epoch: [152 | 155] LR: 0.023025
batch Size 325
Epoch: [152][0/154]	Time 0.188 (0.188)	Data 0.276 (0.276)	Loss 0.4937 (0.4937)	Acc@1 91.692 (91.692)	Acc@5 100.000 (100.000)
Epoch: [152][64/154]	Time 0.117 (0.124)	Data 0.000 (0.004)	Loss 0.4567 (0.4734)	Acc@1 93.231 (93.141)	Acc@5 100.000 (99.801)
Epoch: [152][128/154]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.4540 (0.4755)	Acc@1 93.538 (92.890)	Acc@5 99.692 (99.816)
Max memory in training epoch: 66.995456
lr: 0.02302484795208944
1

Epoch: [153 | 155] LR: 0.023025
batch Size 325
Epoch: [153][0/154]	Time 0.172 (0.172)	Data 0.310 (0.310)	Loss 0.4719 (0.4719)	Acc@1 91.385 (91.385)	Acc@5 99.385 (99.385)
Epoch: [153][64/154]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.4526 (0.4539)	Acc@1 93.231 (93.378)	Acc@5 99.692 (99.806)
Epoch: [153][128/154]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.4302 (0.4512)	Acc@1 93.231 (93.355)	Acc@5 99.692 (99.816)
Max memory in training epoch: 66.995456
Drin!!
old memory: 658769408
new memory: 669954560
Faktor: 1.016978857646043
New batch Size kleiner 330!!
lr: 0.02302484795208944
1

Epoch: [154 | 155] LR: 0.023025
batch Size 330
Epoch: [154][0/154]	Time 0.156 (0.156)	Data 0.350 (0.350)	Loss 0.4170 (0.4170)	Acc@1 93.231 (93.231)	Acc@5 100.000 (100.000)
Epoch: [154][64/154]	Time 0.120 (0.124)	Data 0.000 (0.006)	Loss 0.3916 (0.4302)	Acc@1 95.385 (93.794)	Acc@5 100.000 (99.858)
Epoch: [154][128/154]	Time 0.135 (0.124)	Data 0.000 (0.003)	Loss 0.4448 (0.4324)	Acc@1 93.538 (93.701)	Acc@5 100.000 (99.845)
Max memory in training epoch: 66.995456
lr: 0.02302484795208944
1

Epoch: [155 | 155] LR: 0.023025
batch Size 330
Epoch: [155][0/154]	Time 0.210 (0.210)	Data 0.275 (0.275)	Loss 0.4286 (0.4286)	Acc@1 93.538 (93.538)	Acc@5 100.000 (100.000)
Epoch: [155][64/154]	Time 0.123 (0.125)	Data 0.000 (0.004)	Loss 0.4314 (0.4147)	Acc@1 93.538 (94.234)	Acc@5 99.692 (99.905)
Epoch: [155][128/154]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.4165 (0.4157)	Acc@1 92.615 (94.123)	Acc@5 100.000 (99.888)
Max memory in training epoch: 66.995456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.98
Max memory: 82.3363584
 19.554s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7420
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1324032
lr: 0.029680468063240293
1

Epoch: [156 | 160] LR: 0.029680
batch Size 330
Epoch: [156][0/152]	Time 0.175 (0.175)	Data 0.345 (0.345)	Loss 0.3899 (0.3899)	Acc@1 94.545 (94.545)	Acc@5 100.000 (100.000)
Epoch: [156][64/152]	Time 0.129 (0.125)	Data 0.000 (0.006)	Loss 0.4091 (0.4042)	Acc@1 91.818 (94.238)	Acc@5 100.000 (99.897)
Epoch: [156][128/152]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.4106 (0.4129)	Acc@1 92.727 (93.914)	Acc@5 99.697 (99.890)
Max memory in training epoch: 67.8957568
lr: 0.029680468063240293
1

Epoch: [157 | 160] LR: 0.029680
batch Size 330
Epoch: [157][0/152]	Time 0.175 (0.175)	Data 0.308 (0.308)	Loss 0.4422 (0.4422)	Acc@1 91.212 (91.212)	Acc@5 100.000 (100.000)
Epoch: [157][64/152]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.4309 (0.4065)	Acc@1 93.636 (93.897)	Acc@5 99.697 (99.911)
Epoch: [157][128/152]	Time 0.127 (0.125)	Data 0.000 (0.003)	Loss 0.4026 (0.4094)	Acc@1 93.636 (93.759)	Acc@5 100.000 (99.901)
Max memory in training epoch: 67.8598144
lr: 0.029680468063240293
1

Epoch: [158 | 160] LR: 0.029680
batch Size 330
Epoch: [158][0/152]	Time 0.153 (0.153)	Data 0.321 (0.321)	Loss 0.4010 (0.4010)	Acc@1 94.545 (94.545)	Acc@5 99.697 (99.697)
Epoch: [158][64/152]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.3611 (0.4019)	Acc@1 94.848 (93.758)	Acc@5 100.000 (99.888)
Epoch: [158][128/152]	Time 0.128 (0.125)	Data 0.000 (0.003)	Loss 0.4388 (0.4003)	Acc@1 93.939 (93.855)	Acc@5 99.697 (99.868)
Max memory in training epoch: 67.8598144
Drin!!
old memory: 669954560
new memory: 678598144
Faktor: 1.0129017466498027
New batch Size kleiner 334!!
lr: 0.029680468063240293
1

Epoch: [159 | 160] LR: 0.029680
batch Size 334
Epoch: [159][0/152]	Time 0.194 (0.194)	Data 0.333 (0.333)	Loss 0.4265 (0.4265)	Acc@1 93.636 (93.636)	Acc@5 99.394 (99.394)
Epoch: [159][64/152]	Time 0.124 (0.125)	Data 0.000 (0.005)	Loss 0.4016 (0.3932)	Acc@1 93.939 (93.865)	Acc@5 100.000 (99.907)
Epoch: [159][128/152]	Time 0.134 (0.124)	Data 0.000 (0.003)	Loss 0.4508 (0.3927)	Acc@1 90.909 (93.930)	Acc@5 99.697 (99.901)
Max memory in training epoch: 67.8598144
lr: 0.029680468063240293
1

Epoch: [160 | 160] LR: 0.029680
batch Size 334
Epoch: [160][0/152]	Time 0.186 (0.186)	Data 0.289 (0.289)	Loss 0.3817 (0.3817)	Acc@1 95.455 (95.455)	Acc@5 100.000 (100.000)
Epoch: [160][64/152]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.3962 (0.3822)	Acc@1 93.333 (94.345)	Acc@5 100.000 (99.897)
Epoch: [160][128/152]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3562 (0.3890)	Acc@1 95.152 (93.855)	Acc@5 100.000 (99.890)
Max memory in training epoch: 67.8598144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.49
Max memory: 82.7123712
 19.058s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5991
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1324032
lr: 0.03872373567625882
1

Epoch: [161 | 165] LR: 0.038724
batch Size 334
Epoch: [161][0/150]	Time 0.201 (0.201)	Data 0.315 (0.315)	Loss 0.3454 (0.3454)	Acc@1 95.808 (95.808)	Acc@5 100.000 (100.000)
Epoch: [161][64/150]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.4156 (0.3948)	Acc@1 93.713 (93.722)	Acc@5 100.000 (99.866)
Epoch: [161][128/150]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.4923 (0.4134)	Acc@1 91.617 (93.028)	Acc@5 99.102 (99.856)
Max memory in training epoch: 68.6112768
lr: 0.03872373567625882
1

Epoch: [162 | 165] LR: 0.038724
batch Size 334
Epoch: [162][0/150]	Time 0.175 (0.175)	Data 0.323 (0.323)	Loss 0.3942 (0.3942)	Acc@1 93.413 (93.413)	Acc@5 100.000 (100.000)
Epoch: [162][64/150]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 0.4672 (0.4108)	Acc@1 91.617 (93.054)	Acc@5 100.000 (99.857)
Epoch: [162][128/150]	Time 0.126 (0.123)	Data 0.000 (0.003)	Loss 0.3942 (0.4196)	Acc@1 92.814 (92.640)	Acc@5 100.000 (99.856)
Max memory in training epoch: 68.614656
lr: 0.03872373567625882
1

Epoch: [163 | 165] LR: 0.038724
batch Size 334
Epoch: [163][0/150]	Time 0.189 (0.189)	Data 0.287 (0.287)	Loss 0.4555 (0.4555)	Acc@1 90.419 (90.419)	Acc@5 99.401 (99.401)
Epoch: [163][64/150]	Time 0.128 (0.123)	Data 0.000 (0.005)	Loss 0.4591 (0.4131)	Acc@1 92.216 (92.920)	Acc@5 99.701 (99.811)
Epoch: [163][128/150]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.3609 (0.4198)	Acc@1 94.012 (92.622)	Acc@5 99.701 (99.821)
Max memory in training epoch: 68.614656
Drin!!
old memory: 678598144
new memory: 686146560
Faktor: 1.0111235435386041
New batch Size kleiner 337!!
lr: 0.03872373567625882
1

Epoch: [164 | 165] LR: 0.038724
batch Size 337
Epoch: [164][0/150]	Time 0.166 (0.166)	Data 0.321 (0.321)	Loss 0.4072 (0.4072)	Acc@1 91.617 (91.617)	Acc@5 100.000 (100.000)
Epoch: [164][64/150]	Time 0.116 (0.126)	Data 0.000 (0.005)	Loss 0.3666 (0.4061)	Acc@1 95.509 (93.077)	Acc@5 99.701 (99.843)
Epoch: [164][128/150]	Time 0.120 (0.124)	Data 0.000 (0.003)	Loss 0.4022 (0.4170)	Acc@1 92.814 (92.587)	Acc@5 100.000 (99.844)
Max memory in training epoch: 68.614656
lr: 0.03872373567625882
1

Epoch: [165 | 165] LR: 0.038724
batch Size 337
Epoch: [165][0/150]	Time 0.167 (0.167)	Data 0.325 (0.325)	Loss 0.3741 (0.3741)	Acc@1 94.012 (94.012)	Acc@5 100.000 (100.000)
Epoch: [165][64/150]	Time 0.120 (0.125)	Data 0.000 (0.005)	Loss 0.3837 (0.4071)	Acc@1 95.210 (92.989)	Acc@5 100.000 (99.871)
Epoch: [165][128/150]	Time 0.122 (0.123)	Data 0.000 (0.003)	Loss 0.3942 (0.4146)	Acc@1 94.910 (92.701)	Acc@5 100.000 (99.872)
Max memory in training epoch: 68.614656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 312442 ; 313310 ; 0.9972295809262391
[INFO] Storing checkpoint...
  85.75
Max memory: 82.4133632
 18.878s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 767
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.132096
lr: 0.05097616766757509
1

Epoch: [166 | 170] LR: 0.050976
batch Size 337
Epoch: [166][0/149]	Time 0.193 (0.193)	Data 0.303 (0.303)	Loss 0.4158 (0.4158)	Acc@1 92.285 (92.285)	Acc@5 100.000 (100.000)
Epoch: [166][64/149]	Time 0.120 (0.125)	Data 0.000 (0.005)	Loss 0.4336 (0.4357)	Acc@1 92.878 (91.865)	Acc@5 99.703 (99.790)
Epoch: [166][128/149]	Time 0.120 (0.125)	Data 0.000 (0.003)	Loss 0.4456 (0.4618)	Acc@1 91.395 (91.082)	Acc@5 100.000 (99.795)
Max memory in training epoch: 70.3568384
lr: 0.05097616766757509
1

Epoch: [167 | 170] LR: 0.050976
batch Size 337
Epoch: [167][0/149]	Time 0.191 (0.191)	Data 0.330 (0.330)	Loss 0.4331 (0.4331)	Acc@1 90.801 (90.801)	Acc@5 100.000 (100.000)
Epoch: [167][64/149]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.4567 (0.4643)	Acc@1 93.175 (91.189)	Acc@5 100.000 (99.795)
Epoch: [167][128/149]	Time 0.116 (0.125)	Data 0.000 (0.003)	Loss 0.4851 (0.4727)	Acc@1 91.395 (90.877)	Acc@5 99.703 (99.754)
Max memory in training epoch: 70.1889536
lr: 0.05097616766757509
1

Epoch: [168 | 170] LR: 0.050976
batch Size 337
Epoch: [168][0/149]	Time 0.171 (0.171)	Data 0.285 (0.285)	Loss 0.4661 (0.4661)	Acc@1 90.208 (90.208)	Acc@5 99.703 (99.703)
Epoch: [168][64/149]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.4664 (0.4527)	Acc@1 91.098 (91.536)	Acc@5 100.000 (99.790)
Epoch: [168][128/149]	Time 0.129 (0.125)	Data 0.000 (0.002)	Loss 0.4532 (0.4605)	Acc@1 91.098 (91.321)	Acc@5 99.703 (99.786)
Max memory in training epoch: 70.1889536
Drin!!
old memory: 686146560
new memory: 701889536
Faktor: 1.0229440427421221
New batch Size kleiner 344!!
lr: 0.05097616766757509
1

Epoch: [169 | 170] LR: 0.050976
batch Size 344
Epoch: [169][0/149]	Time 0.175 (0.175)	Data 0.343 (0.343)	Loss 0.4627 (0.4627)	Acc@1 89.911 (89.911)	Acc@5 100.000 (100.000)
Epoch: [169][64/149]	Time 0.125 (0.128)	Data 0.000 (0.006)	Loss 0.4581 (0.4537)	Acc@1 91.691 (91.545)	Acc@5 100.000 (99.790)
Epoch: [169][128/149]	Time 0.123 (0.127)	Data 0.000 (0.003)	Loss 0.4740 (0.4613)	Acc@1 89.911 (91.264)	Acc@5 99.703 (99.786)
Max memory in training epoch: 70.1889536
lr: 0.05097616766757509
1

Epoch: [170 | 170] LR: 0.050976
batch Size 344
Epoch: [170][0/149]	Time 0.146 (0.146)	Data 0.322 (0.322)	Loss 0.4767 (0.4767)	Acc@1 89.318 (89.318)	Acc@5 99.703 (99.703)
Epoch: [170][64/149]	Time 0.160 (0.126)	Data 0.000 (0.005)	Loss 0.4439 (0.4644)	Acc@1 91.691 (91.130)	Acc@5 99.407 (99.785)
Epoch: [170][128/149]	Time 0.136 (0.125)	Data 0.000 (0.003)	Loss 0.4353 (0.4649)	Acc@1 91.098 (91.185)	Acc@5 100.000 (99.781)
Max memory in training epoch: 70.1889536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 311864 ; 312442 ; 0.9981500566505144
[INFO] Storing checkpoint...
  83.54
Max memory: 81.8250752
 18.937s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2146
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1318912
lr: 0.06849922530330403
1

Epoch: [171 | 175] LR: 0.068499
batch Size 344
Epoch: [171][0/146]	Time 0.203 (0.203)	Data 0.308 (0.308)	Loss 0.4315 (0.4315)	Acc@1 92.442 (92.442)	Acc@5 99.419 (99.419)
Epoch: [171][64/146]	Time 0.126 (0.126)	Data 0.000 (0.005)	Loss 0.5557 (0.4850)	Acc@1 87.791 (90.711)	Acc@5 100.000 (99.754)
Epoch: [171][128/146]	Time 0.129 (0.126)	Data 0.000 (0.003)	Loss 0.5533 (0.5148)	Acc@1 87.209 (89.591)	Acc@5 99.419 (99.698)
Max memory in training epoch: 71.008768
lr: 0.06849922530330403
1

Epoch: [172 | 175] LR: 0.068499
batch Size 344
Epoch: [172][0/146]	Time 0.177 (0.177)	Data 0.292 (0.292)	Loss 0.5816 (0.5816)	Acc@1 88.081 (88.081)	Acc@5 99.419 (99.419)
Epoch: [172][64/146]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.5300 (0.5145)	Acc@1 90.407 (89.624)	Acc@5 99.709 (99.741)
Epoch: [172][128/146]	Time 0.134 (0.126)	Data 0.000 (0.002)	Loss 0.5269 (0.5218)	Acc@1 87.791 (89.517)	Acc@5 99.709 (99.718)
Max memory in training epoch: 70.8844544
lr: 0.06849922530330403
1

Epoch: [173 | 175] LR: 0.068499
batch Size 344
Epoch: [173][0/146]	Time 0.169 (0.169)	Data 0.288 (0.288)	Loss 0.4165 (0.4165)	Acc@1 93.895 (93.895)	Acc@5 99.709 (99.709)
Epoch: [173][64/146]	Time 0.134 (0.128)	Data 0.000 (0.005)	Loss 0.5614 (0.5014)	Acc@1 88.372 (90.094)	Acc@5 99.709 (99.776)
Epoch: [173][128/146]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.5460 (0.5056)	Acc@1 88.081 (90.069)	Acc@5 100.000 (99.730)
Max memory in training epoch: 70.8844544
Drin!!
old memory: 701889536
new memory: 708844544
Faktor: 1.0099089780418098
New batch Size kleiner 347!!
lr: 0.06849922530330403
1

Epoch: [174 | 175] LR: 0.068499
batch Size 347
Epoch: [174][0/146]	Time 0.178 (0.178)	Data 0.307 (0.307)	Loss 0.6031 (0.6031)	Acc@1 86.337 (86.337)	Acc@5 99.419 (99.419)
Epoch: [174][64/146]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.5407 (0.5040)	Acc@1 89.244 (90.309)	Acc@5 100.000 (99.736)
Epoch: [174][128/146]	Time 0.126 (0.126)	Data 0.000 (0.003)	Loss 0.4999 (0.5080)	Acc@1 89.826 (90.008)	Acc@5 99.709 (99.730)
Max memory in training epoch: 70.8844544
lr: 0.06849922530330403
1

Epoch: [175 | 175] LR: 0.068499
batch Size 347
Epoch: [175][0/146]	Time 0.162 (0.162)	Data 0.339 (0.339)	Loss 0.5022 (0.5022)	Acc@1 88.372 (88.372)	Acc@5 99.709 (99.709)
Epoch: [175][64/146]	Time 0.130 (0.126)	Data 0.000 (0.005)	Loss 0.5486 (0.5173)	Acc@1 88.663 (89.884)	Acc@5 100.000 (99.656)
Epoch: [175][128/146]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.5271 (0.5136)	Acc@1 89.244 (90.044)	Acc@5 99.709 (99.655)
Max memory in training epoch: 70.8844544
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  71.87
Max memory: 82.17344
 18.850s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8238
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1318912
lr: 0.09284855929783789
1

Epoch: [176 | 180] LR: 0.092849
batch Size 347
Epoch: [176][0/145]	Time 0.206 (0.206)	Data 0.314 (0.314)	Loss 0.5373 (0.5373)	Acc@1 91.354 (91.354)	Acc@5 98.559 (98.559)
Epoch: [176][64/145]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.6254 (0.5363)	Acc@1 88.184 (89.550)	Acc@5 99.135 (99.645)
Epoch: [176][128/145]	Time 0.140 (0.128)	Data 0.000 (0.003)	Loss 0.5930 (0.5624)	Acc@1 88.473 (88.622)	Acc@5 99.424 (99.571)
Max memory in training epoch: 71.35616
lr: 0.09284855929783789
1

Epoch: [177 | 180] LR: 0.092849
batch Size 347
Epoch: [177][0/145]	Time 0.167 (0.167)	Data 0.321 (0.321)	Loss 0.6248 (0.6248)	Acc@1 87.896 (87.896)	Acc@5 99.135 (99.135)
Epoch: [177][64/145]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.5392 (0.6168)	Acc@1 91.931 (87.103)	Acc@5 100.000 (99.490)
Epoch: [177][128/145]	Time 0.124 (0.127)	Data 0.000 (0.003)	Loss 0.6406 (0.5979)	Acc@1 86.455 (87.615)	Acc@5 99.712 (99.558)
Max memory in training epoch: 71.30752
lr: 0.09284855929783789
1

Epoch: [178 | 180] LR: 0.092849
batch Size 347
Epoch: [178][0/145]	Time 0.174 (0.174)	Data 0.329 (0.329)	Loss 0.5898 (0.5898)	Acc@1 86.167 (86.167)	Acc@5 99.712 (99.712)
Epoch: [178][64/145]	Time 0.129 (0.126)	Data 0.000 (0.005)	Loss 0.5681 (0.6392)	Acc@1 90.202 (86.810)	Acc@5 99.712 (99.410)
Epoch: [178][128/145]	Time 0.126 (0.126)	Data 0.000 (0.003)	Loss 0.5893 (0.6079)	Acc@1 87.032 (87.697)	Acc@5 100.000 (99.551)
Max memory in training epoch: 71.30752
Drin!!
old memory: 708844544
new memory: 713075200
Faktor: 1.0059683833864708
New batch Size kleiner 349!!
lr: 0.09284855929783789
1

Epoch: [179 | 180] LR: 0.092849
batch Size 349
Epoch: [179][0/145]	Time 0.183 (0.183)	Data 0.316 (0.316)	Loss 0.6255 (0.6255)	Acc@1 86.455 (86.455)	Acc@5 99.424 (99.424)
Epoch: [179][64/145]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.5932 (0.6526)	Acc@1 86.744 (86.061)	Acc@5 99.424 (99.508)
Epoch: [179][128/145]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.5607 (0.6196)	Acc@1 89.914 (87.293)	Acc@5 99.712 (99.567)
Max memory in training epoch: 71.30752
lr: 0.09284855929783789
1

Epoch: [180 | 180] LR: 0.092849
batch Size 349
Epoch: [180][0/145]	Time 0.180 (0.180)	Data 0.290 (0.290)	Loss 0.5173 (0.5173)	Acc@1 89.625 (89.625)	Acc@5 99.712 (99.712)
Epoch: [180][64/145]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.5691 (0.6014)	Acc@1 88.761 (87.732)	Acc@5 99.712 (99.623)
Epoch: [180][128/145]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5180 (0.5861)	Acc@1 91.354 (88.419)	Acc@5 99.424 (99.629)
Max memory in training epoch: 71.30752
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(21, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(18, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  80.86
Max memory: 81.8473984
 18.679s  BSize 3
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6962
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
batch_size berechnet: 250;389.1 ; lr: 0.1
lr: 0.09765625
1

Epoch: [1 | 5] LR: 0.097656
batch Size 250
Epoch: [1][0/200]	Time 0.217 (0.217)	Data 0.262 (0.262)	Loss 3.6336 (3.6336)	Acc@1 10.800 (10.800)	Acc@5 45.200 (45.200)
Epoch: [1][64/200]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 2.4879 (2.7805)	Acc@1 32.800 (22.535)	Acc@5 85.600 (76.295)
Epoch: [1][128/200]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 2.3681 (2.5806)	Acc@1 36.800 (28.403)	Acc@5 89.200 (82.611)
Epoch: [1][192/200]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 2.0100 (2.4527)	Acc@1 48.800 (32.777)	Acc@5 94.400 (85.476)
Max memory in training epoch: 66.4657408
lr: 0.09765625
1

Epoch: [2 | 5] LR: 0.097656
batch Size 250
Epoch: [2][0/200]	Time 0.147 (0.147)	Data 0.294 (0.294)	Loss 2.0916 (2.0916)	Acc@1 48.000 (48.000)	Acc@5 93.600 (93.600)
Epoch: [2][64/200]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 1.8910 (2.0119)	Acc@1 53.600 (48.351)	Acc@5 94.000 (93.138)
Epoch: [2][128/200]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 1.7757 (1.9359)	Acc@1 58.000 (51.191)	Acc@5 94.000 (93.991)
Epoch: [2][192/200]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 1.5702 (1.8802)	Acc@1 66.000 (53.175)	Acc@5 96.000 (94.336)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [3 | 5] LR: 0.097656
batch Size 250
Epoch: [3][0/200]	Time 0.177 (0.177)	Data 0.283 (0.283)	Loss 1.6372 (1.6372)	Acc@1 66.000 (66.000)	Acc@5 96.400 (96.400)
Epoch: [3][64/200]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 1.6627 (1.6455)	Acc@1 62.000 (60.492)	Acc@5 95.600 (96.160)
Epoch: [3][128/200]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 1.5150 (1.5932)	Acc@1 64.800 (62.112)	Acc@5 96.800 (96.540)
Epoch: [3][192/200]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 1.3769 (1.5497)	Acc@1 66.800 (63.299)	Acc@5 98.000 (96.771)
Max memory in training epoch: 66.0135424
Drin!!
old memory: 0
new memory: 660135424
lr: 0.09765625
1

Epoch: [4 | 5] LR: 0.097656
batch Size 250
Epoch: [4][0/200]	Time 0.173 (0.173)	Data 0.255 (0.255)	Loss 1.4299 (1.4299)	Acc@1 68.000 (68.000)	Acc@5 96.800 (96.800)
Epoch: [4][64/200]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 1.2721 (1.3852)	Acc@1 72.400 (68.382)	Acc@5 98.000 (97.268)
Epoch: [4][128/200]	Time 0.147 (0.129)	Data 0.000 (0.002)	Loss 1.2484 (1.3536)	Acc@1 70.000 (69.042)	Acc@5 100.000 (97.647)
Epoch: [4][192/200]	Time 0.130 (0.130)	Data 0.000 (0.001)	Loss 1.2696 (1.3291)	Acc@1 70.400 (69.824)	Acc@5 98.000 (97.683)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [5 | 5] LR: 0.097656
batch Size 250
Epoch: [5][0/200]	Time 0.165 (0.165)	Data 0.324 (0.324)	Loss 1.1910 (1.1910)	Acc@1 74.800 (74.800)	Acc@5 98.400 (98.400)
Epoch: [5][64/200]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 1.0749 (1.1938)	Acc@1 77.600 (73.717)	Acc@5 98.800 (98.240)
Epoch: [5][128/200]	Time 0.131 (0.128)	Data 0.000 (0.003)	Loss 1.1631 (1.1844)	Acc@1 74.000 (73.746)	Acc@5 97.600 (98.264)
Epoch: [5][192/200]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.2228 (1.1686)	Acc@1 69.600 (74.062)	Acc@5 98.000 (98.332)
Max memory in training epoch: 66.0135424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  72.7
Max memory: 103.3835008
 26.003s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8573
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.095367431640625
1

Epoch: [6 | 10] LR: 0.095367
batch Size 250
Epoch: [6][0/200]	Time 0.181 (0.181)	Data 0.257 (0.257)	Loss 0.9472 (0.9472)	Acc@1 80.800 (80.800)	Acc@5 99.600 (99.600)
Epoch: [6][64/200]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 1.1500 (1.0664)	Acc@1 73.600 (76.942)	Acc@5 98.000 (98.560)
Epoch: [6][128/200]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 1.0499 (1.0634)	Acc@1 75.600 (76.899)	Acc@5 97.600 (98.574)
Epoch: [6][192/200]	Time 0.132 (0.127)	Data 0.000 (0.001)	Loss 1.0116 (1.0547)	Acc@1 78.000 (76.939)	Acc@5 97.600 (98.609)
Max memory in training epoch: 66.4656384
lr: 0.095367431640625
1

Epoch: [7 | 10] LR: 0.095367
batch Size 250
Epoch: [7][0/200]	Time 0.170 (0.170)	Data 0.311 (0.311)	Loss 0.9599 (0.9599)	Acc@1 78.800 (78.800)	Acc@5 99.200 (99.200)
Epoch: [7][64/200]	Time 0.123 (0.132)	Data 0.000 (0.005)	Loss 0.9022 (0.9927)	Acc@1 81.600 (78.486)	Acc@5 99.600 (98.757)
Epoch: [7][128/200]	Time 0.133 (0.131)	Data 0.000 (0.003)	Loss 0.9323 (0.9978)	Acc@1 78.000 (77.953)	Acc@5 99.600 (98.732)
Epoch: [7][192/200]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 1.0154 (0.9904)	Acc@1 76.800 (78.197)	Acc@5 98.800 (98.732)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [8 | 10] LR: 0.095367
batch Size 250
Epoch: [8][0/200]	Time 0.161 (0.161)	Data 0.290 (0.290)	Loss 0.9197 (0.9197)	Acc@1 78.800 (78.800)	Acc@5 98.800 (98.800)
Epoch: [8][64/200]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.9094 (0.9478)	Acc@1 78.400 (78.898)	Acc@5 99.200 (98.806)
Epoch: [8][128/200]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.8434 (0.9534)	Acc@1 81.600 (78.636)	Acc@5 100.000 (98.822)
Epoch: [8][192/200]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.9915 (0.9447)	Acc@1 77.600 (78.951)	Acc@5 99.200 (98.866)
Max memory in training epoch: 66.01344
Drin!!
old memory: 660135424
new memory: 660134400
Faktor: 0.9999984488031353
New batch Size größer 253!!
lr: 0.095367431640625
1

Epoch: [9 | 10] LR: 0.095367
batch Size 253
Epoch: [9][0/200]	Time 0.165 (0.165)	Data 0.290 (0.290)	Loss 0.8406 (0.8406)	Acc@1 81.200 (81.200)	Acc@5 100.000 (100.000)
Epoch: [9][64/200]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.9595 (0.9019)	Acc@1 77.600 (80.055)	Acc@5 97.600 (98.966)
Epoch: [9][128/200]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7766 (0.8997)	Acc@1 85.200 (80.102)	Acc@5 99.200 (98.930)
Epoch: [9][192/200]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.8791 (0.9032)	Acc@1 76.800 (79.992)	Acc@5 99.600 (98.918)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [10 | 10] LR: 0.095367
batch Size 253
Epoch: [10][0/200]	Time 0.185 (0.185)	Data 0.266 (0.266)	Loss 0.9043 (0.9043)	Acc@1 80.800 (80.800)	Acc@5 99.600 (99.600)
Epoch: [10][64/200]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.8595 (0.8704)	Acc@1 82.800 (80.911)	Acc@5 98.800 (99.022)
Epoch: [10][128/200]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.9308 (0.8778)	Acc@1 76.400 (80.561)	Acc@5 98.400 (98.983)
Epoch: [10][192/200]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.8996 (0.8762)	Acc@1 78.800 (80.767)	Acc@5 100.000 (98.991)
Max memory in training epoch: 66.01344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  68.57
Max memory: 103.3833984
 25.894s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5957
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.09424984455108643
1

Epoch: [11 | 15] LR: 0.094250
batch Size 253
Epoch: [11][0/198]	Time 0.186 (0.186)	Data 0.258 (0.258)	Loss 0.7999 (0.7999)	Acc@1 83.004 (83.004)	Acc@5 99.209 (99.209)
Epoch: [11][64/198]	Time 0.122 (0.129)	Data 0.000 (0.004)	Loss 0.8659 (0.8384)	Acc@1 82.213 (81.648)	Acc@5 98.419 (99.039)
Epoch: [11][128/198]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.9338 (0.8471)	Acc@1 78.656 (81.545)	Acc@5 99.209 (99.035)
Epoch: [11][192/198]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.8197 (0.8481)	Acc@1 83.004 (81.382)	Acc@5 99.605 (99.128)
Max memory in training epoch: 66.5037312
lr: 0.09424984455108643
1

Epoch: [12 | 15] LR: 0.094250
batch Size 253
Epoch: [12][0/198]	Time 0.173 (0.173)	Data 0.290 (0.290)	Loss 0.9752 (0.9752)	Acc@1 79.447 (79.447)	Acc@5 98.814 (98.814)
Epoch: [12][64/198]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.9220 (0.8274)	Acc@1 76.680 (82.001)	Acc@5 99.209 (99.124)
Epoch: [12][128/198]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.8492 (0.8246)	Acc@1 79.051 (82.112)	Acc@5 98.024 (99.056)
Epoch: [12][192/198]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.9908 (0.8316)	Acc@1 74.704 (81.863)	Acc@5 97.233 (99.066)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [13 | 15] LR: 0.094250
batch Size 253
Epoch: [13][0/198]	Time 0.187 (0.187)	Data 0.312 (0.312)	Loss 0.8545 (0.8545)	Acc@1 81.818 (81.818)	Acc@5 99.209 (99.209)
Epoch: [13][64/198]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.7791 (0.8209)	Acc@1 81.423 (82.292)	Acc@5 99.605 (99.027)
Epoch: [13][128/198]	Time 0.123 (0.129)	Data 0.000 (0.003)	Loss 0.8502 (0.8226)	Acc@1 79.447 (82.137)	Acc@5 99.209 (99.111)
Epoch: [13][192/198]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.8522 (0.8298)	Acc@1 81.818 (82.009)	Acc@5 98.419 (99.103)
Max memory in training epoch: 66.277632
Drin!!
old memory: 660134400
new memory: 662776320
Faktor: 1.0040020941190158
New batch Size kleiner 254!!
lr: 0.09424984455108643
1

Epoch: [14 | 15] LR: 0.094250
batch Size 254
Epoch: [14][0/198]	Time 0.180 (0.180)	Data 0.295 (0.295)	Loss 0.8674 (0.8674)	Acc@1 80.237 (80.237)	Acc@5 99.605 (99.605)
Epoch: [14][64/198]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.8592 (0.8055)	Acc@1 81.423 (82.724)	Acc@5 99.605 (99.197)
Epoch: [14][128/198]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8100 (0.8051)	Acc@1 83.794 (82.777)	Acc@5 98.814 (99.127)
Epoch: [14][192/198]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7030 (0.8097)	Acc@1 86.561 (82.678)	Acc@5 99.209 (99.146)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [15 | 15] LR: 0.094250
batch Size 254
Epoch: [15][0/198]	Time 0.178 (0.178)	Data 0.283 (0.283)	Loss 0.8301 (0.8301)	Acc@1 81.028 (81.028)	Acc@5 98.024 (98.024)
Epoch: [15][64/198]	Time 0.142 (0.131)	Data 0.000 (0.005)	Loss 0.8358 (0.8039)	Acc@1 83.794 (82.967)	Acc@5 98.814 (99.282)
Epoch: [15][128/198]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7481 (0.8050)	Acc@1 85.771 (83.056)	Acc@5 99.605 (99.182)
Epoch: [15][192/198]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.7715 (0.8059)	Acc@1 84.190 (82.986)	Acc@5 98.419 (99.177)
Max memory in training epoch: 66.277632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  68.66
Max memory: 103.3833984
 25.880s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5116
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.09351351764053106
1

Epoch: [16 | 20] LR: 0.093514
batch Size 254
Epoch: [16][0/197]	Time 0.200 (0.200)	Data 0.265 (0.265)	Loss 0.8907 (0.8907)	Acc@1 81.890 (81.890)	Acc@5 98.425 (98.425)
Epoch: [16][64/197]	Time 0.135 (0.129)	Data 0.000 (0.004)	Loss 0.7774 (0.7818)	Acc@1 84.646 (83.907)	Acc@5 99.606 (99.231)
Epoch: [16][128/197]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.8716 (0.7900)	Acc@1 79.134 (83.526)	Acc@5 99.606 (99.240)
Epoch: [16][192/197]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.8344 (0.7974)	Acc@1 84.252 (83.322)	Acc@5 99.213 (99.158)
Max memory in training epoch: 66.5164288
lr: 0.09351351764053106
1

Epoch: [17 | 20] LR: 0.093514
batch Size 254
Epoch: [17][0/197]	Time 0.165 (0.165)	Data 0.260 (0.260)	Loss 0.8140 (0.8140)	Acc@1 80.709 (80.709)	Acc@5 99.606 (99.606)
Epoch: [17][64/197]	Time 0.119 (0.128)	Data 0.000 (0.004)	Loss 0.7762 (0.7853)	Acc@1 83.071 (83.319)	Acc@5 99.213 (99.182)
Epoch: [17][128/197]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.7257 (0.7865)	Acc@1 86.614 (83.230)	Acc@5 99.213 (99.200)
Epoch: [17][192/197]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7416 (0.7928)	Acc@1 83.465 (83.140)	Acc@5 99.606 (99.213)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [18 | 20] LR: 0.093514
batch Size 254
Epoch: [18][0/197]	Time 0.177 (0.177)	Data 0.296 (0.296)	Loss 0.8054 (0.8054)	Acc@1 80.709 (80.709)	Acc@5 99.213 (99.213)
Epoch: [18][64/197]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.8324 (0.7829)	Acc@1 81.890 (83.446)	Acc@5 99.606 (99.237)
Epoch: [18][128/197]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7810 (0.7914)	Acc@1 85.039 (83.385)	Acc@5 99.213 (99.228)
Epoch: [18][192/197]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7785 (0.7894)	Acc@1 83.071 (83.477)	Acc@5 99.213 (99.188)
Max memory in training epoch: 66.365696
Drin!!
old memory: 662776320
new memory: 663656960
Faktor: 1.0013287137355782
New batch Size kleiner 254!!
lr: 0.09351351764053106
1

Epoch: [19 | 20] LR: 0.093514
batch Size 254
Epoch: [19][0/197]	Time 0.156 (0.156)	Data 0.289 (0.289)	Loss 0.7611 (0.7611)	Acc@1 84.252 (84.252)	Acc@5 98.425 (98.425)
Epoch: [19][64/197]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.8673 (0.7738)	Acc@1 79.528 (83.937)	Acc@5 99.213 (99.322)
Epoch: [19][128/197]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7184 (0.7708)	Acc@1 85.827 (83.974)	Acc@5 100.000 (99.298)
Epoch: [19][192/197]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8302 (0.7790)	Acc@1 81.102 (83.742)	Acc@5 98.425 (99.241)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [20 | 20] LR: 0.093514
batch Size 254
Epoch: [20][0/197]	Time 0.181 (0.181)	Data 0.278 (0.278)	Loss 0.7614 (0.7614)	Acc@1 84.252 (84.252)	Acc@5 99.213 (99.213)
Epoch: [20][64/197]	Time 0.135 (0.128)	Data 0.000 (0.004)	Loss 0.8029 (0.7827)	Acc@1 82.677 (83.574)	Acc@5 99.606 (99.279)
Epoch: [20][128/197]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.8584 (0.7859)	Acc@1 80.709 (83.684)	Acc@5 98.819 (99.268)
Epoch: [20][192/197]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7252 (0.7884)	Acc@1 86.614 (83.624)	Acc@5 100.000 (99.247)
Max memory in training epoch: 66.365696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  80.28
Max memory: 103.3833984
 25.673s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7862
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2020864
lr: 0.09278294328396441
1

Epoch: [21 | 25] LR: 0.092783
batch Size 254
Epoch: [21][0/197]	Time 0.203 (0.203)	Data 0.259 (0.259)	Loss 0.6763 (0.6763)	Acc@1 87.008 (87.008)	Acc@5 100.000 (100.000)
Epoch: [21][64/197]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 0.6641 (0.7428)	Acc@1 88.583 (85.336)	Acc@5 100.000 (99.370)
Epoch: [21][128/197]	Time 0.137 (0.129)	Data 0.000 (0.002)	Loss 0.9394 (0.7654)	Acc@1 79.528 (84.423)	Acc@5 98.425 (99.322)
Epoch: [21][192/197]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6781 (0.7698)	Acc@1 87.795 (84.195)	Acc@5 99.213 (99.329)
Max memory in training epoch: 66.5147904
lr: 0.09278294328396441
1

Epoch: [22 | 25] LR: 0.092783
batch Size 254
Epoch: [22][0/197]	Time 0.164 (0.164)	Data 0.324 (0.324)	Loss 0.6416 (0.6416)	Acc@1 90.945 (90.945)	Acc@5 99.213 (99.213)
Epoch: [22][64/197]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.8274 (0.7732)	Acc@1 82.283 (84.240)	Acc@5 98.819 (99.310)
Epoch: [22][128/197]	Time 0.145 (0.133)	Data 0.000 (0.003)	Loss 0.7339 (0.7725)	Acc@1 84.646 (84.261)	Acc@5 98.819 (99.286)
Epoch: [22][192/197]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.7492 (0.7679)	Acc@1 84.252 (84.409)	Acc@5 99.606 (99.323)
Max memory in training epoch: 66.3640576
lr: 0.09278294328396441
1

Epoch: [23 | 25] LR: 0.092783
batch Size 254
Epoch: [23][0/197]	Time 0.202 (0.202)	Data 0.266 (0.266)	Loss 0.6953 (0.6953)	Acc@1 85.827 (85.827)	Acc@5 99.213 (99.213)
Epoch: [23][64/197]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.7747 (0.7487)	Acc@1 81.890 (84.779)	Acc@5 98.819 (99.273)
Epoch: [23][128/197]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7602 (0.7538)	Acc@1 82.677 (84.737)	Acc@5 99.606 (99.246)
Epoch: [23][192/197]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7700 (0.7657)	Acc@1 83.858 (84.364)	Acc@5 98.819 (99.227)
Max memory in training epoch: 66.3640576
Drin!!
old memory: 663656960
new memory: 663640576
Faktor: 0.9999753125470122
New batch Size größer 256!!
lr: 0.09278294328396441
1

Epoch: [24 | 25] LR: 0.092783
batch Size 256
Epoch: [24][0/197]	Time 0.190 (0.190)	Data 0.300 (0.300)	Loss 0.8942 (0.8942)	Acc@1 79.134 (79.134)	Acc@5 98.819 (98.819)
Epoch: [24][64/197]	Time 0.123 (0.131)	Data 0.000 (0.005)	Loss 0.9218 (0.7582)	Acc@1 81.496 (84.737)	Acc@5 97.638 (99.255)
Epoch: [24][128/197]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.7718 (0.7554)	Acc@1 81.496 (84.752)	Acc@5 99.606 (99.316)
Epoch: [24][192/197]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6866 (0.7595)	Acc@1 87.402 (84.560)	Acc@5 98.819 (99.315)
Max memory in training epoch: 66.3640576
lr: 0.09278294328396441
1

Epoch: [25 | 25] LR: 0.092783
batch Size 256
Epoch: [25][0/197]	Time 0.186 (0.186)	Data 0.280 (0.280)	Loss 0.7468 (0.7468)	Acc@1 82.677 (82.677)	Acc@5 99.213 (99.213)
Epoch: [25][64/197]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.7130 (0.7490)	Acc@1 88.583 (85.257)	Acc@5 99.606 (99.207)
Epoch: [25][128/197]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8095 (0.7584)	Acc@1 84.252 (84.826)	Acc@5 99.606 (99.280)
Epoch: [25][192/197]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7809 (0.7602)	Acc@1 81.102 (84.678)	Acc@5 99.606 (99.284)
Max memory in training epoch: 66.3640576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 480460 ; 486232 ; 0.9881291235459616
[INFO] Storing checkpoint...
  68.38
Max memory: 103.3821696
 25.867s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4167
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1998336
lr: 0.09278294328396441
1

Epoch: [26 | 30] LR: 0.092783
batch Size 256
Epoch: [26][0/196]	Time 0.195 (0.195)	Data 0.276 (0.276)	Loss 0.7749 (0.7749)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.6774 (0.7341)	Acc@1 86.719 (85.222)	Acc@5 100.000 (99.453)
Epoch: [26][128/196]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.7590 (0.7535)	Acc@1 82.812 (84.841)	Acc@5 100.000 (99.379)
Epoch: [26][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.6872 (0.7529)	Acc@1 86.328 (84.800)	Acc@5 100.000 (99.375)
Max memory in training epoch: 66.636032
lr: 0.09278294328396441
1

Epoch: [27 | 30] LR: 0.092783
batch Size 256
Epoch: [27][0/196]	Time 0.195 (0.195)	Data 0.295 (0.295)	Loss 0.7320 (0.7320)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.126 (0.133)	Data 0.000 (0.005)	Loss 0.7523 (0.7586)	Acc@1 83.594 (84.519)	Acc@5 100.000 (99.273)
Epoch: [27][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7925 (0.7505)	Acc@1 83.984 (84.926)	Acc@5 98.828 (99.313)
Epoch: [27][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7146 (0.7486)	Acc@1 83.203 (84.970)	Acc@5 100.000 (99.336)
Max memory in training epoch: 66.4787456
lr: 0.09278294328396441
1

Epoch: [28 | 30] LR: 0.092783
batch Size 256
Epoch: [28][0/196]	Time 0.155 (0.155)	Data 0.307 (0.307)	Loss 0.6453 (0.6453)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.7464 (0.7390)	Acc@1 85.547 (85.373)	Acc@5 99.219 (99.381)
Epoch: [28][128/196]	Time 0.143 (0.131)	Data 0.000 (0.003)	Loss 0.8674 (0.7492)	Acc@1 82.422 (85.047)	Acc@5 98.828 (99.373)
Epoch: [28][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.6977 (0.7496)	Acc@1 86.719 (84.970)	Acc@5 99.609 (99.371)
Max memory in training epoch: 66.4787456
Drin!!
old memory: 663640576
new memory: 664787456
Faktor: 1.00172816437312
New batch Size kleiner 256!!
lr: 0.09278294328396441
1

Epoch: [29 | 30] LR: 0.092783
batch Size 256
Epoch: [29][0/196]	Time 0.194 (0.194)	Data 0.268 (0.268)	Loss 0.7115 (0.7115)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.124 (0.131)	Data 0.000 (0.004)	Loss 0.6687 (0.7459)	Acc@1 88.672 (85.030)	Acc@5 99.219 (99.429)
Epoch: [29][128/196]	Time 0.147 (0.130)	Data 0.000 (0.002)	Loss 0.8555 (0.7455)	Acc@1 80.078 (85.168)	Acc@5 99.609 (99.391)
Epoch: [29][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8725 (0.7459)	Acc@1 80.469 (85.089)	Acc@5 98.438 (99.338)
Max memory in training epoch: 66.4787456
lr: 0.09278294328396441
1

Epoch: [30 | 30] LR: 0.092783
batch Size 256
Epoch: [30][0/196]	Time 0.189 (0.189)	Data 0.285 (0.285)	Loss 0.7401 (0.7401)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [30][64/196]	Time 0.147 (0.134)	Data 0.000 (0.005)	Loss 0.7255 (0.7336)	Acc@1 85.547 (85.415)	Acc@5 100.000 (99.435)
Epoch: [30][128/196]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.7289 (0.7405)	Acc@1 84.766 (85.217)	Acc@5 99.219 (99.376)
Epoch: [30][192/196]	Time 0.126 (0.133)	Data 0.000 (0.002)	Loss 0.7408 (0.7464)	Acc@1 86.328 (85.045)	Acc@5 99.219 (99.364)
Max memory in training epoch: 66.4787456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 466030 ; 480460 ; 0.9699662823127836
[INFO] Storing checkpoint...
  77.04
Max memory: 103.3344512
 26.331s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9742
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1939968
lr: 0.09278294328396441
1

Epoch: [31 | 35] LR: 0.092783
batch Size 256
Epoch: [31][0/196]	Time 0.203 (0.203)	Data 0.288 (0.288)	Loss 0.7353 (0.7353)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [31][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8368 (0.7115)	Acc@1 82.031 (86.184)	Acc@5 98.438 (99.351)
Epoch: [31][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8263 (0.7299)	Acc@1 83.984 (85.610)	Acc@5 99.219 (99.355)
Epoch: [31][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7757 (0.7387)	Acc@1 85.547 (85.292)	Acc@5 99.609 (99.294)
Max memory in training epoch: 66.49472
lr: 0.09278294328396441
1

Epoch: [32 | 35] LR: 0.092783
batch Size 256
Epoch: [32][0/196]	Time 0.174 (0.174)	Data 0.301 (0.301)	Loss 0.7743 (0.7743)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [32][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.8315 (0.7313)	Acc@1 82.812 (85.601)	Acc@5 98.438 (99.303)
Epoch: [32][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6823 (0.7342)	Acc@1 84.375 (85.489)	Acc@5 99.219 (99.328)
Epoch: [32][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7875 (0.7359)	Acc@1 86.328 (85.425)	Acc@5 98.828 (99.338)
Max memory in training epoch: 66.298112
lr: 0.09278294328396441
1

Epoch: [33 | 35] LR: 0.092783
batch Size 256
Epoch: [33][0/196]	Time 0.191 (0.191)	Data 0.290 (0.290)	Loss 0.7379 (0.7379)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.6490 (0.7352)	Acc@1 89.844 (85.288)	Acc@5 99.609 (99.399)
Epoch: [33][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7513 (0.7350)	Acc@1 85.938 (85.480)	Acc@5 99.219 (99.370)
Epoch: [33][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.8599 (0.7398)	Acc@1 80.859 (85.375)	Acc@5 99.219 (99.320)
Max memory in training epoch: 66.298112
Drin!!
old memory: 664787456
new memory: 662981120
Faktor: 0.997282836816945
New batch Size größer 258!!
lr: 0.09278294328396441
1

Epoch: [34 | 35] LR: 0.092783
batch Size 258
Epoch: [34][0/196]	Time 0.176 (0.176)	Data 0.284 (0.284)	Loss 0.7126 (0.7126)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7432 (0.7323)	Acc@1 87.500 (85.607)	Acc@5 99.609 (99.429)
Epoch: [34][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.8054 (0.7330)	Acc@1 82.031 (85.607)	Acc@5 99.219 (99.416)
Epoch: [34][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7107 (0.7338)	Acc@1 86.719 (85.512)	Acc@5 99.609 (99.373)
Max memory in training epoch: 66.298112
lr: 0.09278294328396441
1

Epoch: [35 | 35] LR: 0.092783
batch Size 258
Epoch: [35][0/196]	Time 0.181 (0.181)	Data 0.275 (0.275)	Loss 0.6758 (0.6758)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [35][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6903 (0.7338)	Acc@1 88.672 (85.361)	Acc@5 100.000 (99.429)
Epoch: [35][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6632 (0.7428)	Acc@1 89.453 (85.111)	Acc@5 99.609 (99.403)
Epoch: [35][192/196]	Time 0.140 (0.130)	Data 0.000 (0.002)	Loss 0.6843 (0.7378)	Acc@1 85.938 (85.298)	Acc@5 99.609 (99.383)
Max memory in training epoch: 66.298112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 446406 ; 466030 ; 0.9578911228890844
[INFO] Storing checkpoint...
  75.77
Max memory: 102.3363584
 25.921s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7154
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1864192
lr: 0.09350781002837039
1

Epoch: [36 | 40] LR: 0.093508
batch Size 258
Epoch: [36][0/194]	Time 0.187 (0.187)	Data 0.286 (0.286)	Loss 0.6908 (0.6908)	Acc@1 87.597 (87.597)	Acc@5 99.612 (99.612)
Epoch: [36][64/194]	Time 0.141 (0.131)	Data 0.000 (0.005)	Loss 0.6718 (0.7051)	Acc@1 88.760 (86.422)	Acc@5 100.000 (99.499)
Epoch: [36][128/194]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.7623 (0.7270)	Acc@1 86.822 (85.539)	Acc@5 99.612 (99.444)
Epoch: [36][192/194]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6238 (0.7241)	Acc@1 89.147 (85.673)	Acc@5 99.225 (99.420)
Max memory in training epoch: 65.80992
lr: 0.09350781002837039
1

Epoch: [37 | 40] LR: 0.093508
batch Size 258
Epoch: [37][0/194]	Time 0.179 (0.179)	Data 0.268 (0.268)	Loss 0.7077 (0.7077)	Acc@1 86.047 (86.047)	Acc@5 99.225 (99.225)
Epoch: [37][64/194]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7672 (0.7179)	Acc@1 83.333 (85.713)	Acc@5 100.000 (99.463)
Epoch: [37][128/194]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.6859 (0.7229)	Acc@1 87.984 (85.722)	Acc@5 100.000 (99.408)
Epoch: [37][192/194]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7844 (0.7268)	Acc@1 81.395 (85.589)	Acc@5 99.612 (99.349)
Max memory in training epoch: 65.8198016
lr: 0.09350781002837039
1

Epoch: [38 | 40] LR: 0.093508
batch Size 258
Epoch: [38][0/194]	Time 0.186 (0.186)	Data 0.306 (0.306)	Loss 0.6754 (0.6754)	Acc@1 88.372 (88.372)	Acc@5 100.000 (100.000)
Epoch: [38][64/194]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.7692 (0.7171)	Acc@1 84.109 (85.987)	Acc@5 99.612 (99.475)
Epoch: [38][128/194]	Time 0.129 (0.131)	Data 0.000 (0.003)	Loss 0.7643 (0.7196)	Acc@1 82.946 (85.860)	Acc@5 100.000 (99.441)
Epoch: [38][192/194]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7958 (0.7238)	Acc@1 86.047 (85.806)	Acc@5 98.450 (99.418)
Max memory in training epoch: 65.8198016
Drin!!
old memory: 662981120
new memory: 658198016
Faktor: 0.9927854597126385
New batch Size größer 262!!
lr: 0.09350781002837039
1

Epoch: [39 | 40] LR: 0.093508
batch Size 262
Epoch: [39][0/194]	Time 0.208 (0.208)	Data 0.285 (0.285)	Loss 0.5999 (0.5999)	Acc@1 91.860 (91.860)	Acc@5 100.000 (100.000)
Epoch: [39][64/194]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.7510 (0.7029)	Acc@1 84.109 (86.392)	Acc@5 98.837 (99.493)
Epoch: [39][128/194]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7429 (0.7146)	Acc@1 84.496 (86.167)	Acc@5 98.837 (99.450)
Epoch: [39][192/194]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7783 (0.7208)	Acc@1 83.333 (85.882)	Acc@5 99.225 (99.414)
Max memory in training epoch: 65.8198016
lr: 0.09350781002837039
1

Epoch: [40 | 40] LR: 0.093508
batch Size 262
Epoch: [40][0/194]	Time 0.171 (0.171)	Data 0.297 (0.297)	Loss 0.7358 (0.7358)	Acc@1 83.721 (83.721)	Acc@5 100.000 (100.000)
Epoch: [40][64/194]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.8108 (0.7153)	Acc@1 83.333 (85.921)	Acc@5 98.450 (99.326)
Epoch: [40][128/194]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.6952 (0.7187)	Acc@1 84.884 (85.854)	Acc@5 99.612 (99.381)
Epoch: [40][192/194]	Time 0.142 (0.128)	Data 0.000 (0.002)	Loss 0.7029 (0.7190)	Acc@1 88.372 (85.878)	Acc@5 99.612 (99.420)
Max memory in training epoch: 65.8198016
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 427064 ; 446406 ; 0.9566717293226346
[INFO] Storing checkpoint...
  77.16
Max memory: 100.864256
 25.251s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8435
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1786368
lr: 0.09569939932591032
1

Epoch: [41 | 45] LR: 0.095699
batch Size 262
Epoch: [41][0/191]	Time 0.217 (0.217)	Data 0.265 (0.265)	Loss 0.7740 (0.7740)	Acc@1 85.115 (85.115)	Acc@5 99.618 (99.618)
Epoch: [41][64/191]	Time 0.123 (0.131)	Data 0.000 (0.004)	Loss 0.6731 (0.6968)	Acc@1 87.023 (86.383)	Acc@5 99.237 (99.501)
Epoch: [41][128/191]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6886 (0.7090)	Acc@1 88.550 (85.952)	Acc@5 99.618 (99.390)
Max memory in training epoch: 65.7845248
lr: 0.09569939932591032
1

Epoch: [42 | 45] LR: 0.095699
batch Size 262
Epoch: [42][0/191]	Time 0.163 (0.163)	Data 0.330 (0.330)	Loss 0.8190 (0.8190)	Acc@1 83.206 (83.206)	Acc@5 99.618 (99.618)
Epoch: [42][64/191]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.7317 (0.7140)	Acc@1 85.878 (86.295)	Acc@5 99.618 (99.477)
Epoch: [42][128/191]	Time 0.141 (0.130)	Data 0.000 (0.003)	Loss 0.7291 (0.7202)	Acc@1 87.786 (85.973)	Acc@5 98.473 (99.414)
Max memory in training epoch: 65.874432
lr: 0.09569939932591032
1

Epoch: [43 | 45] LR: 0.095699
batch Size 262
Epoch: [43][0/191]	Time 0.192 (0.192)	Data 0.284 (0.284)	Loss 0.7061 (0.7061)	Acc@1 84.351 (84.351)	Acc@5 99.618 (99.618)
Epoch: [43][64/191]	Time 0.123 (0.129)	Data 0.000 (0.005)	Loss 0.6791 (0.7022)	Acc@1 86.260 (86.471)	Acc@5 99.618 (99.483)
Epoch: [43][128/191]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7208 (0.7143)	Acc@1 85.878 (86.032)	Acc@5 98.855 (99.408)
Max memory in training epoch: 65.874432
Drin!!
old memory: 658198016
new memory: 658744320
Faktor: 1.000829999463262
New batch Size kleiner 262!!
lr: 0.09569939932591032
1

Epoch: [44 | 45] LR: 0.095699
batch Size 262
Epoch: [44][0/191]	Time 0.159 (0.159)	Data 0.290 (0.290)	Loss 0.6843 (0.6843)	Acc@1 87.405 (87.405)	Acc@5 100.000 (100.000)
Epoch: [44][64/191]	Time 0.155 (0.130)	Data 0.000 (0.005)	Loss 0.7492 (0.7051)	Acc@1 82.443 (86.171)	Acc@5 100.000 (99.442)
Epoch: [44][128/191]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7464 (0.7088)	Acc@1 87.023 (86.076)	Acc@5 99.618 (99.379)
Max memory in training epoch: 65.874432
lr: 0.09569939932591032
1

Epoch: [45 | 45] LR: 0.095699
batch Size 262
Epoch: [45][0/191]	Time 0.190 (0.190)	Data 0.282 (0.282)	Loss 0.6400 (0.6400)	Acc@1 90.076 (90.076)	Acc@5 99.618 (99.618)
Epoch: [45][64/191]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.7439 (0.6956)	Acc@1 85.878 (86.559)	Acc@5 98.473 (99.383)
Epoch: [45][128/191]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.8422 (0.7043)	Acc@1 83.588 (86.289)	Acc@5 98.092 (99.361)
Max memory in training epoch: 65.874432
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 400796 ; 427064 ; 0.9384916546466103
[INFO] Storing checkpoint...
  79.61
Max memory: 99.6213248
 25.127s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5508
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.168192
lr: 0.09794235399761134
1

Epoch: [46 | 50] LR: 0.097942
batch Size 262
Epoch: [46][0/191]	Time 0.224 (0.224)	Data 0.256 (0.256)	Loss 0.6741 (0.6741)	Acc@1 88.550 (88.550)	Acc@5 99.237 (99.237)
Epoch: [46][64/191]	Time 0.123 (0.133)	Data 0.000 (0.004)	Loss 0.6152 (0.6772)	Acc@1 90.840 (87.270)	Acc@5 100.000 (99.513)
Epoch: [46][128/191]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6992 (0.7050)	Acc@1 87.023 (86.257)	Acc@5 100.000 (99.464)
Max memory in training epoch: 64.6414848
lr: 0.09794235399761134
1

Epoch: [47 | 50] LR: 0.097942
batch Size 262
Epoch: [47][0/191]	Time 0.153 (0.153)	Data 0.290 (0.290)	Loss 0.6255 (0.6255)	Acc@1 89.313 (89.313)	Acc@5 99.237 (99.237)
Epoch: [47][64/191]	Time 0.120 (0.129)	Data 0.000 (0.005)	Loss 0.7173 (0.7051)	Acc@1 86.260 (86.336)	Acc@5 99.237 (99.395)
Epoch: [47][128/191]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6770 (0.7081)	Acc@1 88.168 (86.159)	Acc@5 98.855 (99.414)
Max memory in training epoch: 64.708096
lr: 0.09794235399761134
1

Epoch: [48 | 50] LR: 0.097942
batch Size 262
Epoch: [48][0/191]	Time 0.181 (0.181)	Data 0.268 (0.268)	Loss 0.6144 (0.6144)	Acc@1 89.695 (89.695)	Acc@5 100.000 (100.000)
Epoch: [48][64/191]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 0.7466 (0.7190)	Acc@1 83.969 (85.831)	Acc@5 99.618 (99.507)
Epoch: [48][128/191]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6980 (0.7165)	Acc@1 86.641 (85.851)	Acc@5 99.237 (99.459)
Max memory in training epoch: 64.708096
Drin!!
old memory: 658744320
new memory: 647080960
Faktor: 0.982294557014169
New batch Size größer 271!!
lr: 0.09794235399761134
1

Epoch: [49 | 50] LR: 0.097942
batch Size 271
Epoch: [49][0/191]	Time 0.191 (0.191)	Data 0.271 (0.271)	Loss 0.6259 (0.6259)	Acc@1 86.641 (86.641)	Acc@5 99.618 (99.618)
Epoch: [49][64/191]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.6459 (0.6854)	Acc@1 88.931 (86.870)	Acc@5 99.618 (99.583)
Epoch: [49][128/191]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7723 (0.7139)	Acc@1 85.496 (86.032)	Acc@5 98.092 (99.417)
Max memory in training epoch: 64.708096
lr: 0.09794235399761134
1

Epoch: [50 | 50] LR: 0.097942
batch Size 271
Epoch: [50][0/191]	Time 0.153 (0.153)	Data 0.274 (0.274)	Loss 0.6483 (0.6483)	Acc@1 88.168 (88.168)	Acc@5 99.618 (99.618)
Epoch: [50][64/191]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.7318 (0.6907)	Acc@1 83.969 (86.653)	Acc@5 100.000 (99.513)
Epoch: [50][128/191]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7520 (0.7006)	Acc@1 84.351 (86.452)	Acc@5 100.000 (99.497)
Max memory in training epoch: 64.708096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 387802 ; 400796 ; 0.9675795167616443
[INFO] Storing checkpoint...
  76.85
Max memory: 98.020608
 25.190s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1311
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.163072
lr: 0.10368116380215887
1

Epoch: [51 | 55] LR: 0.103681
batch Size 271
Epoch: [51][0/185]	Time 0.190 (0.190)	Data 0.296 (0.296)	Loss 0.6411 (0.6411)	Acc@1 89.668 (89.668)	Acc@5 100.000 (100.000)
Epoch: [51][64/185]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.6941 (0.6796)	Acc@1 85.609 (86.971)	Acc@5 99.631 (99.478)
Epoch: [51][128/185]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6927 (0.6994)	Acc@1 87.085 (86.416)	Acc@5 99.262 (99.425)
Max memory in training epoch: 65.7207296
lr: 0.10368116380215887
1

Epoch: [52 | 55] LR: 0.103681
batch Size 271
Epoch: [52][0/185]	Time 0.162 (0.162)	Data 0.272 (0.272)	Loss 0.7160 (0.7160)	Acc@1 84.133 (84.133)	Acc@5 99.631 (99.631)
Epoch: [52][64/185]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.6049 (0.7179)	Acc@1 90.406 (85.558)	Acc@5 100.000 (99.483)
Epoch: [52][128/185]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8258 (0.7163)	Acc@1 83.395 (85.849)	Acc@5 98.524 (99.439)
Max memory in training epoch: 65.6980992
lr: 0.10368116380215887
1

Epoch: [53 | 55] LR: 0.103681
batch Size 271
Epoch: [53][0/185]	Time 0.170 (0.170)	Data 0.300 (0.300)	Loss 0.7528 (0.7528)	Acc@1 83.395 (83.395)	Acc@5 100.000 (100.000)
Epoch: [53][64/185]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.6505 (0.6990)	Acc@1 89.299 (86.858)	Acc@5 99.631 (99.506)
Epoch: [53][128/185]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.6936 (0.7086)	Acc@1 85.978 (86.464)	Acc@5 99.631 (99.439)
Max memory in training epoch: 65.6980992
Drin!!
old memory: 647080960
new memory: 656980992
Faktor: 1.0152995260438509
New batch Size kleiner 275!!
lr: 0.10368116380215887
1

Epoch: [54 | 55] LR: 0.103681
batch Size 275
Epoch: [54][0/185]	Time 0.186 (0.186)	Data 0.275 (0.275)	Loss 0.7023 (0.7023)	Acc@1 87.454 (87.454)	Acc@5 98.893 (98.893)
Epoch: [54][64/185]	Time 0.127 (0.133)	Data 0.000 (0.004)	Loss 0.7982 (0.7041)	Acc@1 85.240 (86.409)	Acc@5 99.631 (99.466)
Epoch: [54][128/185]	Time 0.164 (0.132)	Data 0.000 (0.002)	Loss 0.7049 (0.7111)	Acc@1 85.240 (86.089)	Acc@5 99.262 (99.454)
Max memory in training epoch: 65.6980992
lr: 0.10368116380215887
1

Epoch: [55 | 55] LR: 0.103681
batch Size 275
Epoch: [55][0/185]	Time 0.192 (0.192)	Data 0.301 (0.301)	Loss 0.6879 (0.6879)	Acc@1 85.240 (85.240)	Acc@5 100.000 (100.000)
Epoch: [55][64/185]	Time 0.123 (0.131)	Data 0.000 (0.005)	Loss 0.6788 (0.6982)	Acc@1 85.240 (86.336)	Acc@5 100.000 (99.472)
Epoch: [55][128/185]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.6644 (0.7053)	Acc@1 85.978 (86.158)	Acc@5 100.000 (99.371)
Max memory in training epoch: 65.6980992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 376540 ; 387802 ; 0.9709594071201283
[INFO] Storing checkpoint...
  78.69
Max memory: 96.0500224
 24.360s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2190
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1585664
lr: 0.11137625017810035
1

Epoch: [56 | 60] LR: 0.111376
batch Size 275
Epoch: [56][0/182]	Time 0.193 (0.193)	Data 0.330 (0.330)	Loss 0.6330 (0.6330)	Acc@1 89.455 (89.455)	Acc@5 100.000 (100.000)
Epoch: [56][64/182]	Time 0.134 (0.135)	Data 0.000 (0.005)	Loss 0.7178 (0.6940)	Acc@1 82.182 (86.657)	Acc@5 99.273 (99.519)
Epoch: [56][128/182]	Time 0.130 (0.133)	Data 0.000 (0.003)	Loss 0.7756 (0.7084)	Acc@1 82.545 (86.128)	Acc@5 99.273 (99.431)
Max memory in training epoch: 66.795008
lr: 0.11137625017810035
1

Epoch: [57 | 60] LR: 0.111376
batch Size 275
Epoch: [57][0/182]	Time 0.172 (0.172)	Data 0.306 (0.306)	Loss 0.8217 (0.8217)	Acc@1 83.636 (83.636)	Acc@5 98.909 (98.909)
Epoch: [57][64/182]	Time 0.155 (0.133)	Data 0.000 (0.005)	Loss 0.7454 (0.7147)	Acc@1 82.909 (86.042)	Acc@5 98.545 (99.379)
Epoch: [57][128/182]	Time 0.132 (0.133)	Data 0.000 (0.003)	Loss 0.6179 (0.7191)	Acc@1 89.091 (85.728)	Acc@5 99.636 (99.391)
Max memory in training epoch: 67.0083072
lr: 0.11137625017810035
1

Epoch: [58 | 60] LR: 0.111376
batch Size 275
Epoch: [58][0/182]	Time 0.172 (0.172)	Data 0.328 (0.328)	Loss 0.6554 (0.6554)	Acc@1 88.000 (88.000)	Acc@5 99.636 (99.636)
Epoch: [58][64/182]	Time 0.134 (0.136)	Data 0.000 (0.005)	Loss 0.6678 (0.6895)	Acc@1 87.636 (86.797)	Acc@5 99.636 (99.463)
Epoch: [58][128/182]	Time 0.130 (0.134)	Data 0.000 (0.003)	Loss 0.7822 (0.7029)	Acc@1 83.636 (86.311)	Acc@5 99.273 (99.433)
Max memory in training epoch: 67.0083072
Drin!!
old memory: 656980992
new memory: 670083072
Faktor: 1.019942860082016
New batch Size kleiner 280!!
lr: 0.11137625017810035
1

Epoch: [59 | 60] LR: 0.111376
batch Size 280
Epoch: [59][0/182]	Time 0.170 (0.170)	Data 0.268 (0.268)	Loss 0.6458 (0.6458)	Acc@1 88.000 (88.000)	Acc@5 99.636 (99.636)
Epoch: [59][64/182]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 0.6859 (0.7092)	Acc@1 88.727 (86.137)	Acc@5 98.545 (99.418)
Epoch: [59][128/182]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7140 (0.7147)	Acc@1 84.000 (85.990)	Acc@5 99.273 (99.363)
Max memory in training epoch: 67.0083072
lr: 0.11137625017810035
1

Epoch: [60 | 60] LR: 0.111376
batch Size 280
Epoch: [60][0/182]	Time 0.170 (0.170)	Data 0.306 (0.306)	Loss 0.7464 (0.7464)	Acc@1 82.182 (82.182)	Acc@5 100.000 (100.000)
Epoch: [60][64/182]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7206 (0.6991)	Acc@1 87.273 (86.378)	Acc@5 98.182 (99.508)
Epoch: [60][128/182]	Time 0.137 (0.131)	Data 0.000 (0.003)	Loss 0.7221 (0.7035)	Acc@1 87.273 (86.331)	Acc@5 98.909 (99.448)
Max memory in training epoch: 67.0083072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 371278 ; 376540 ; 0.9860253890688905
[INFO] Storing checkpoint...
  77.71
Max memory: 94.7051008
 24.212s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5037
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1560064
lr: 0.12181777363229726
1

Epoch: [61 | 65] LR: 0.121818
batch Size 280
Epoch: [61][0/179]	Time 0.209 (0.209)	Data 0.290 (0.290)	Loss 0.7837 (0.7837)	Acc@1 85.357 (85.357)	Acc@5 98.929 (98.929)
Epoch: [61][64/179]	Time 0.140 (0.127)	Data 0.000 (0.005)	Loss 0.8013 (0.7055)	Acc@1 82.500 (86.330)	Acc@5 99.286 (99.412)
Epoch: [61][128/179]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.7727 (0.7246)	Acc@1 85.000 (85.670)	Acc@5 98.929 (99.405)
Max memory in training epoch: 65.0320896
lr: 0.12181777363229726
1

Epoch: [62 | 65] LR: 0.121818
batch Size 280
Epoch: [62][0/179]	Time 0.153 (0.153)	Data 0.298 (0.298)	Loss 0.6849 (0.6849)	Acc@1 87.143 (87.143)	Acc@5 99.643 (99.643)
Epoch: [62][64/179]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.8198 (0.7186)	Acc@1 81.429 (85.918)	Acc@5 99.286 (99.434)
Epoch: [62][128/179]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7636 (0.7276)	Acc@1 84.286 (85.573)	Acc@5 99.286 (99.405)
Max memory in training epoch: 65.9127296
lr: 0.12181777363229726
1

Epoch: [63 | 65] LR: 0.121818
batch Size 280
Epoch: [63][0/179]	Time 0.165 (0.165)	Data 0.301 (0.301)	Loss 0.7552 (0.7552)	Acc@1 84.643 (84.643)	Acc@5 100.000 (100.000)
Epoch: [63][64/179]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.7308 (0.7005)	Acc@1 86.429 (86.588)	Acc@5 100.000 (99.467)
Epoch: [63][128/179]	Time 0.120 (0.125)	Data 0.000 (0.003)	Loss 0.7658 (0.7236)	Acc@1 84.286 (85.631)	Acc@5 99.643 (99.372)
Max memory in training epoch: 65.9127296
Drin!!
old memory: 670083072
new memory: 659127296
Faktor: 0.9836501227119494
New batch Size größer 284!!
lr: 0.12181777363229726
1

Epoch: [64 | 65] LR: 0.121818
batch Size 284
Epoch: [64][0/179]	Time 0.187 (0.187)	Data 0.354 (0.354)	Loss 0.6781 (0.6781)	Acc@1 88.571 (88.571)	Acc@5 99.643 (99.643)
Epoch: [64][64/179]	Time 0.150 (0.126)	Data 0.000 (0.006)	Loss 0.6534 (0.7219)	Acc@1 85.714 (85.582)	Acc@5 100.000 (99.505)
Epoch: [64][128/179]	Time 0.128 (0.125)	Data 0.000 (0.003)	Loss 0.6368 (0.7266)	Acc@1 89.286 (85.545)	Acc@5 98.929 (99.449)
Max memory in training epoch: 65.9127296
lr: 0.12181777363229726
1

Epoch: [65 | 65] LR: 0.121818
batch Size 284
Epoch: [65][0/179]	Time 0.195 (0.195)	Data 0.272 (0.272)	Loss 0.6991 (0.6991)	Acc@1 87.143 (87.143)	Acc@5 99.643 (99.643)
Epoch: [65][64/179]	Time 0.125 (0.126)	Data 0.000 (0.004)	Loss 0.7371 (0.7244)	Acc@1 87.143 (85.527)	Acc@5 99.286 (99.385)
Epoch: [65][128/179]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6934 (0.7231)	Acc@1 85.714 (85.717)	Acc@5 99.286 (99.388)
Max memory in training epoch: 65.9127296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 363774 ; 371278 ; 0.9797887297389019
[INFO] Storing checkpoint...
  76.0
Max memory: 91.092736
 22.967s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4518
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1530368
lr: 0.13514159262332978
1

Epoch: [66 | 70] LR: 0.135142
batch Size 284
Epoch: [66][0/177]	Time 0.193 (0.193)	Data 0.275 (0.275)	Loss 0.7787 (0.7787)	Acc@1 83.451 (83.451)	Acc@5 99.296 (99.296)
Epoch: [66][64/177]	Time 0.133 (0.129)	Data 0.000 (0.004)	Loss 0.7944 (0.7299)	Acc@1 83.803 (85.471)	Acc@5 98.944 (99.339)
Epoch: [66][128/177]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7297 (0.7430)	Acc@1 85.211 (85.162)	Acc@5 98.944 (99.380)
Max memory in training epoch: 65.366272
lr: 0.13514159262332978
1

Epoch: [67 | 70] LR: 0.135142
batch Size 284
Epoch: [67][0/177]	Time 0.182 (0.182)	Data 0.312 (0.312)	Loss 0.7695 (0.7695)	Acc@1 83.803 (83.803)	Acc@5 99.648 (99.648)
Epoch: [67][64/177]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 0.7848 (0.8009)	Acc@1 86.268 (82.990)	Acc@5 98.592 (99.242)
Epoch: [67][128/177]	Time 0.118 (0.128)	Data 0.000 (0.003)	Loss 0.8139 (0.7761)	Acc@1 83.099 (84.029)	Acc@5 99.296 (99.315)
Max memory in training epoch: 65.9524096
lr: 0.13514159262332978
1

Epoch: [68 | 70] LR: 0.135142
batch Size 284
Epoch: [68][0/177]	Time 0.173 (0.173)	Data 0.298 (0.298)	Loss 0.8134 (0.8134)	Acc@1 83.803 (83.803)	Acc@5 98.944 (98.944)
Epoch: [68][64/177]	Time 0.117 (0.129)	Data 0.000 (0.005)	Loss 0.7764 (0.8554)	Acc@1 83.099 (81.934)	Acc@5 99.648 (99.047)
Epoch: [68][128/177]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.8443 (0.8144)	Acc@1 81.338 (83.342)	Acc@5 98.944 (99.132)
Max memory in training epoch: 65.9524096
Drin!!
old memory: 659127296
new memory: 659524096
Faktor: 1.0006020081438107
New batch Size kleiner 284!!
lr: 0.13514159262332978
1

Epoch: [69 | 70] LR: 0.135142
batch Size 284
Epoch: [69][0/177]	Time 0.172 (0.172)	Data 0.320 (0.320)	Loss 0.7516 (0.7516)	Acc@1 85.915 (85.915)	Acc@5 98.592 (98.592)
Epoch: [69][64/177]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.7321 (0.8337)	Acc@1 86.268 (82.616)	Acc@5 99.296 (99.198)
Epoch: [69][128/177]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.8220 (0.8019)	Acc@1 82.042 (83.647)	Acc@5 99.296 (99.222)
Max memory in training epoch: 65.9524096
lr: 0.13514159262332978
1

Epoch: [70 | 70] LR: 0.135142
batch Size 284
Epoch: [70][0/177]	Time 0.183 (0.183)	Data 0.278 (0.278)	Loss 0.7636 (0.7636)	Acc@1 84.859 (84.859)	Acc@5 97.887 (97.887)
Epoch: [70][64/177]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.7182 (0.7615)	Acc@1 86.972 (84.772)	Acc@5 98.944 (99.209)
Epoch: [70][128/177]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7718 (0.7589)	Acc@1 84.859 (84.906)	Acc@5 99.296 (99.252)
Max memory in training epoch: 65.9524096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 357134 ; 363774 ; 0.9817469087950211
[INFO] Storing checkpoint...
  78.0
Max memory: 90.9271552
 22.702s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5153
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1503744
lr: 0.14992270431650648
1

Epoch: [71 | 75] LR: 0.149923
batch Size 284
Epoch: [71][0/177]	Time 0.220 (0.220)	Data 0.274 (0.274)	Loss 0.7772 (0.7772)	Acc@1 83.451 (83.451)	Acc@5 98.592 (98.592)
Epoch: [71][64/177]	Time 0.119 (0.128)	Data 0.000 (0.004)	Loss 0.7045 (0.7240)	Acc@1 85.915 (85.715)	Acc@5 99.648 (99.388)
Epoch: [71][128/177]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.8850 (0.7504)	Acc@1 85.563 (85.007)	Acc@5 97.887 (99.320)
Max memory in training epoch: 64.8550912
lr: 0.14992270431650648
1

Epoch: [72 | 75] LR: 0.149923
batch Size 284
Epoch: [72][0/177]	Time 0.175 (0.175)	Data 0.279 (0.279)	Loss 0.9690 (0.9690)	Acc@1 76.056 (76.056)	Acc@5 99.296 (99.296)
Epoch: [72][64/177]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.7269 (0.9441)	Acc@1 86.620 (79.009)	Acc@5 99.296 (98.684)
Epoch: [72][128/177]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7913 (0.8769)	Acc@1 82.746 (81.431)	Acc@5 99.648 (98.922)
Max memory in training epoch: 65.6598528
lr: 0.14992270431650648
1

Epoch: [73 | 75] LR: 0.149923
batch Size 284
Epoch: [73][0/177]	Time 0.153 (0.153)	Data 0.272 (0.272)	Loss 0.7445 (0.7445)	Acc@1 85.211 (85.211)	Acc@5 98.944 (98.944)
Epoch: [73][64/177]	Time 0.134 (0.127)	Data 0.000 (0.004)	Loss 0.8019 (0.8290)	Acc@1 82.394 (83.120)	Acc@5 99.648 (99.177)
Epoch: [73][128/177]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7352 (0.8039)	Acc@1 86.972 (83.849)	Acc@5 99.296 (99.219)
Max memory in training epoch: 65.6598528
Drin!!
old memory: 659524096
new memory: 656598528
Faktor: 0.9955641226488259
New batch Size größer 289!!
lr: 0.14992270431650648
1

Epoch: [74 | 75] LR: 0.149923
batch Size 289
Epoch: [74][0/177]	Time 0.176 (0.176)	Data 0.313 (0.313)	Loss 0.7427 (0.7427)	Acc@1 87.324 (87.324)	Acc@5 99.648 (99.648)
Epoch: [74][64/177]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 0.7246 (0.8187)	Acc@1 85.211 (83.007)	Acc@5 100.000 (99.090)
Epoch: [74][128/177]	Time 0.118 (0.126)	Data 0.000 (0.003)	Loss 0.8270 (0.7951)	Acc@1 82.394 (83.803)	Acc@5 99.296 (99.206)
Max memory in training epoch: 65.6598528
lr: 0.14992270431650648
1

Epoch: [75 | 75] LR: 0.149923
batch Size 289
Epoch: [75][0/177]	Time 0.188 (0.188)	Data 0.273 (0.273)	Loss 0.7738 (0.7738)	Acc@1 85.915 (85.915)	Acc@5 99.296 (99.296)
Epoch: [75][64/177]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.8522 (0.8070)	Acc@1 83.451 (83.380)	Acc@5 99.648 (99.252)
Epoch: [75][128/177]	Time 0.159 (0.131)	Data 0.000 (0.002)	Loss 0.7853 (0.7842)	Acc@1 83.451 (84.188)	Acc@5 98.592 (99.285)
Max memory in training epoch: 65.6598528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 344284 ; 357134 ; 0.9640191076738703
[INFO] Storing checkpoint...
  75.22
Max memory: 90.1097984
 23.286s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3420
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1453056
lr: 0.16924867791980613
1

Epoch: [76 | 80] LR: 0.169249
batch Size 289
Epoch: [76][0/174]	Time 0.206 (0.206)	Data 0.270 (0.270)	Loss 0.7516 (0.7516)	Acc@1 84.083 (84.083)	Acc@5 99.654 (99.654)
Epoch: [76][64/174]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 0.7357 (0.7415)	Acc@1 84.083 (85.190)	Acc@5 99.654 (99.345)
Epoch: [76][128/174]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.8783 (0.7683)	Acc@1 81.661 (84.311)	Acc@5 99.308 (99.257)
Max memory in training epoch: 64.811008
lr: 0.16924867791980613
1

Epoch: [77 | 80] LR: 0.169249
batch Size 289
Epoch: [77][0/174]	Time 0.166 (0.166)	Data 0.321 (0.321)	Loss 1.1692 (1.1692)	Acc@1 69.896 (69.896)	Acc@5 99.654 (99.654)
Epoch: [77][64/174]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.9406 (1.1802)	Acc@1 80.969 (72.483)	Acc@5 98.270 (97.636)
Epoch: [77][128/174]	Time 0.118 (0.126)	Data 0.000 (0.003)	Loss 0.9016 (1.0412)	Acc@1 80.969 (76.860)	Acc@5 98.270 (98.340)
Max memory in training epoch: 65.040896
lr: 0.16924867791980613
1

Epoch: [78 | 80] LR: 0.169249
batch Size 289
Epoch: [78][0/174]	Time 0.196 (0.196)	Data 0.276 (0.276)	Loss 1.2576 (1.2576)	Acc@1 72.664 (72.664)	Acc@5 97.924 (97.924)
Epoch: [78][64/174]	Time 0.119 (0.127)	Data 0.000 (0.004)	Loss 1.0134 (1.2886)	Acc@1 76.471 (69.284)	Acc@5 98.616 (97.136)
Epoch: [78][128/174]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.8895 (1.1372)	Acc@1 82.007 (74.282)	Acc@5 99.308 (97.961)
Max memory in training epoch: 65.0884096
Drin!!
old memory: 656598528
new memory: 650884096
Faktor: 0.9912969162184903
New batch Size größer 297!!
lr: 0.16924867791980613
1

Epoch: [79 | 80] LR: 0.169249
batch Size 297
Epoch: [79][0/174]	Time 0.190 (0.190)	Data 0.358 (0.358)	Loss 2.0507 (2.0507)	Acc@1 61.592 (61.592)	Acc@5 94.464 (94.464)
Epoch: [79][64/174]	Time 0.128 (0.129)	Data 0.000 (0.006)	Loss 1.4148 (1.7188)	Acc@1 62.630 (55.709)	Acc@5 97.924 (94.245)
Epoch: [79][128/174]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 1.1863 (1.5049)	Acc@1 75.087 (62.901)	Acc@5 98.270 (95.971)
Max memory in training epoch: 65.0884096
lr: 0.16924867791980613
1

Epoch: [80 | 80] LR: 0.169249
batch Size 297
Epoch: [80][0/174]	Time 0.154 (0.154)	Data 0.300 (0.300)	Loss 1.3677 (1.3677)	Acc@1 66.782 (66.782)	Acc@5 97.924 (97.924)
Epoch: [80][64/174]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.9705 (1.2724)	Acc@1 79.239 (70.216)	Acc@5 98.616 (97.652)
Epoch: [80][128/174]	Time 0.141 (0.127)	Data 0.000 (0.003)	Loss 0.9390 (1.1526)	Acc@1 80.277 (73.888)	Acc@5 98.616 (98.074)
Max memory in training epoch: 65.0884096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 333312 ; 344284 ; 0.9681309616479418
[INFO] Storing checkpoint...
  55.2
Max memory: 89.0574848
 22.366s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7989
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1411072
lr: 0.19635491149290007
1

Epoch: [81 | 85] LR: 0.196355
batch Size 297
Epoch: [81][0/169]	Time 0.182 (0.182)	Data 0.312 (0.312)	Loss 0.9579 (0.9579)	Acc@1 82.492 (82.492)	Acc@5 97.980 (97.980)
Epoch: [81][64/169]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.9233 (0.9412)	Acc@1 79.125 (79.347)	Acc@5 99.327 (98.897)
Epoch: [81][128/169]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 1.0124 (0.9286)	Acc@1 79.125 (79.631)	Acc@5 98.653 (98.852)
Max memory in training epoch: 65.644288
lr: 0.19635491149290007
1

Epoch: [82 | 85] LR: 0.196355
batch Size 297
Epoch: [82][0/169]	Time 0.176 (0.176)	Data 0.297 (0.297)	Loss 0.9727 (0.9727)	Acc@1 74.747 (74.747)	Acc@5 98.653 (98.653)
Epoch: [82][64/169]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.8351 (0.8911)	Acc@1 81.481 (79.746)	Acc@5 99.327 (98.907)
Epoch: [82][128/169]	Time 0.135 (0.125)	Data 0.000 (0.002)	Loss 0.8317 (0.8846)	Acc@1 80.135 (79.944)	Acc@5 99.327 (98.993)
Max memory in training epoch: 65.7757184
lr: 0.19635491149290007
1

Epoch: [83 | 85] LR: 0.196355
batch Size 297
Epoch: [83][0/169]	Time 0.188 (0.188)	Data 0.273 (0.273)	Loss 0.8839 (0.8839)	Acc@1 81.145 (81.145)	Acc@5 98.990 (98.990)
Epoch: [83][64/169]	Time 0.126 (0.125)	Data 0.000 (0.004)	Loss 1.0102 (0.8492)	Acc@1 73.401 (80.699)	Acc@5 98.317 (99.047)
Epoch: [83][128/169]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.8300 (0.8494)	Acc@1 79.798 (80.495)	Acc@5 97.643 (98.917)
Max memory in training epoch: 65.7757184
Drin!!
old memory: 650884096
new memory: 657757184
Faktor: 1.0105596188971868
New batch Size kleiner 300!!
lr: 0.19635491149290007
1

Epoch: [84 | 85] LR: 0.196355
batch Size 300
Epoch: [84][0/169]	Time 0.184 (0.184)	Data 0.279 (0.279)	Loss 0.8221 (0.8221)	Acc@1 80.471 (80.471)	Acc@5 99.663 (99.663)
Epoch: [84][64/169]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.7826 (0.8271)	Acc@1 82.492 (81.202)	Acc@5 98.653 (98.959)
Epoch: [84][128/169]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.8023 (0.8269)	Acc@1 81.481 (81.147)	Acc@5 99.663 (98.977)
Max memory in training epoch: 65.7757184
lr: 0.19635491149290007
1

Epoch: [85 | 85] LR: 0.196355
batch Size 300
Epoch: [85][0/169]	Time 0.177 (0.177)	Data 0.307 (0.307)	Loss 0.8836 (0.8836)	Acc@1 80.471 (80.471)	Acc@5 98.317 (98.317)
Epoch: [85][64/169]	Time 0.132 (0.125)	Data 0.000 (0.005)	Loss 0.8378 (0.8122)	Acc@1 80.471 (81.678)	Acc@5 98.317 (98.980)
Epoch: [85][128/169]	Time 0.122 (0.125)	Data 0.000 (0.003)	Loss 0.8114 (0.8209)	Acc@1 80.471 (81.043)	Acc@5 98.653 (98.977)
Max memory in training epoch: 65.7757184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 287120 ; 333312 ; 0.8614151305683564
[INFO] Storing checkpoint...
  72.61
Max memory: 87.5867136
 21.548s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5120
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1227776
lr: 0.23010341190574227
1

Epoch: [86 | 90] LR: 0.230103
batch Size 300
Epoch: [86][0/167]	Time 0.194 (0.194)	Data 0.308 (0.308)	Loss 0.7298 (0.7298)	Acc@1 84.333 (84.333)	Acc@5 99.667 (99.667)
Epoch: [86][64/167]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.7505 (0.8097)	Acc@1 83.333 (81.231)	Acc@5 100.000 (99.108)
Epoch: [86][128/167]	Time 0.128 (0.127)	Data 0.000 (0.003)	Loss 0.9141 (0.8282)	Acc@1 78.667 (80.889)	Acc@5 98.333 (99.010)
Max memory in training epoch: 62.2854144
lr: 0.23010341190574227
1

Epoch: [87 | 90] LR: 0.230103
batch Size 300
Epoch: [87][0/167]	Time 0.169 (0.169)	Data 0.305 (0.305)	Loss 0.7795 (0.7795)	Acc@1 85.667 (85.667)	Acc@5 99.000 (99.000)
Epoch: [87][64/167]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.8548 (0.8349)	Acc@1 81.667 (80.846)	Acc@5 99.000 (98.923)
Epoch: [87][128/167]	Time 0.120 (0.127)	Data 0.000 (0.003)	Loss 0.8956 (0.8477)	Acc@1 79.667 (80.468)	Acc@5 99.000 (98.935)
Max memory in training epoch: 62.1307904
lr: 0.23010341190574227
1

Epoch: [88 | 90] LR: 0.230103
batch Size 300
Epoch: [88][0/167]	Time 0.196 (0.196)	Data 0.280 (0.280)	Loss 0.8123 (0.8123)	Acc@1 82.333 (82.333)	Acc@5 99.333 (99.333)
Epoch: [88][64/167]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.8795 (0.8236)	Acc@1 80.667 (81.077)	Acc@5 98.667 (98.985)
Epoch: [88][128/167]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7765 (0.8318)	Acc@1 84.333 (80.775)	Acc@5 99.333 (98.912)
Max memory in training epoch: 62.1307904
Drin!!
old memory: 657757184
new memory: 621307904
Faktor: 0.9445855083203469
New batch Size größer 323!!
lr: 0.23010341190574227
1

Epoch: [89 | 90] LR: 0.230103
batch Size 323
Epoch: [89][0/167]	Time 0.204 (0.204)	Data 0.278 (0.278)	Loss 0.8509 (0.8509)	Acc@1 78.000 (78.000)	Acc@5 99.333 (99.333)
Epoch: [89][64/167]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.9400 (0.8166)	Acc@1 79.333 (81.482)	Acc@5 98.333 (99.067)
Epoch: [89][128/167]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7986 (0.8225)	Acc@1 84.000 (81.186)	Acc@5 99.667 (99.059)
Max memory in training epoch: 62.1307904
lr: 0.23010341190574227
1

Epoch: [90 | 90] LR: 0.230103
batch Size 323
Epoch: [90][0/167]	Time 0.191 (0.191)	Data 0.351 (0.351)	Loss 0.7881 (0.7881)	Acc@1 85.000 (85.000)	Acc@5 98.333 (98.333)
Epoch: [90][64/167]	Time 0.127 (0.124)	Data 0.000 (0.006)	Loss 0.8825 (0.8148)	Acc@1 80.000 (81.369)	Acc@5 98.333 (99.159)
Epoch: [90][128/167]	Time 0.121 (0.124)	Data 0.000 (0.003)	Loss 0.9372 (0.8273)	Acc@1 76.667 (81.065)	Acc@5 98.333 (99.023)
Max memory in training epoch: 62.1307904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 246632 ; 287120 ; 0.858985789913625
[INFO] Storing checkpoint...
  74.62
Max memory: 82.2181888
 21.329s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1007
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1068032
lr: 0.2903257892404483
1

Epoch: [91 | 95] LR: 0.290326
batch Size 323
Epoch: [91][0/155]	Time 0.186 (0.186)	Data 0.348 (0.348)	Loss 0.8126 (0.8126)	Acc@1 83.282 (83.282)	Acc@5 97.833 (97.833)
Epoch: [91][64/155]	Time 0.140 (0.130)	Data 0.000 (0.006)	Loss 0.9942 (0.8433)	Acc@1 78.638 (80.610)	Acc@5 97.833 (98.895)
Epoch: [91][128/155]	Time 0.136 (0.128)	Data 0.000 (0.003)	Loss 0.8675 (0.8592)	Acc@1 80.186 (80.109)	Acc@5 98.452 (98.822)
Max memory in training epoch: 64.2625024
lr: 0.2903257892404483
1

Epoch: [92 | 95] LR: 0.290326
batch Size 323
Epoch: [92][0/155]	Time 0.194 (0.194)	Data 0.326 (0.326)	Loss 0.8804 (0.8804)	Acc@1 79.567 (79.567)	Acc@5 99.690 (99.690)
Epoch: [92][64/155]	Time 0.142 (0.127)	Data 0.000 (0.005)	Loss 0.8641 (0.8438)	Acc@1 81.115 (80.929)	Acc@5 99.071 (98.995)
Epoch: [92][128/155]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.9087 (0.8578)	Acc@1 79.876 (80.450)	Acc@5 100.000 (98.903)
Max memory in training epoch: 64.5735424
lr: 0.2903257892404483
1

Epoch: [93 | 95] LR: 0.029033
batch Size 323
Epoch: [93][0/155]	Time 0.166 (0.166)	Data 0.281 (0.281)	Loss 0.8706 (0.8706)	Acc@1 77.709 (77.709)	Acc@5 98.762 (98.762)
Epoch: [93][64/155]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.6802 (0.7243)	Acc@1 88.545 (84.958)	Acc@5 99.381 (99.324)
Epoch: [93][128/155]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.5957 (0.6891)	Acc@1 88.235 (85.987)	Acc@5 99.690 (99.410)
Max memory in training epoch: 64.5735424
Drin!!
old memory: 621307904
new memory: 645735424
Faktor: 1.0393162872107933
New batch Size kleiner 335!!
lr: 0.02903257892404483
1

Epoch: [94 | 95] LR: 0.029033
batch Size 335
Epoch: [94][0/155]	Time 0.228 (0.228)	Data 0.371 (0.371)	Loss 0.6556 (0.6556)	Acc@1 87.616 (87.616)	Acc@5 99.381 (99.381)
Epoch: [94][64/155]	Time 0.129 (0.128)	Data 0.000 (0.006)	Loss 0.6620 (0.6172)	Acc@1 85.449 (88.235)	Acc@5 98.762 (99.538)
Epoch: [94][128/155]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.6039 (0.6085)	Acc@1 91.022 (88.451)	Acc@5 99.071 (99.628)
Max memory in training epoch: 64.5735424
lr: 0.02903257892404483
1

Epoch: [95 | 95] LR: 0.029033
batch Size 335
Epoch: [95][0/155]	Time 0.180 (0.180)	Data 0.319 (0.319)	Loss 0.5442 (0.5442)	Acc@1 90.402 (90.402)	Acc@5 99.381 (99.381)
Epoch: [95][64/155]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.5398 (0.5737)	Acc@1 91.022 (89.374)	Acc@5 99.690 (99.671)
Epoch: [95][128/155]	Time 0.136 (0.129)	Data 0.000 (0.003)	Loss 0.5343 (0.5727)	Acc@1 88.235 (89.349)	Acc@5 99.690 (99.666)
Max memory in training epoch: 64.5735424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 235284 ; 246632 ; 0.953988128061241
[INFO] Storing checkpoint...
  88.4
Max memory: 79.979008
 20.298s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2421
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1022976
lr: 0.03799185132638679
1

Epoch: [96 | 100] LR: 0.037992
batch Size 335
Epoch: [96][0/150]	Time 0.218 (0.218)	Data 0.283 (0.283)	Loss 0.5037 (0.5037)	Acc@1 91.940 (91.940)	Acc@5 99.403 (99.403)
Epoch: [96][64/150]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.5745 (0.5424)	Acc@1 88.358 (90.154)	Acc@5 99.701 (99.734)
Epoch: [96][128/150]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.5340 (0.5457)	Acc@1 91.045 (89.814)	Acc@5 99.701 (99.729)
Max memory in training epoch: 66.0123648
lr: 0.03799185132638679
1

Epoch: [97 | 100] LR: 0.037992
batch Size 335
Epoch: [97][0/150]	Time 0.191 (0.191)	Data 0.277 (0.277)	Loss 0.4975 (0.4975)	Acc@1 93.134 (93.134)	Acc@5 99.701 (99.701)
Epoch: [97][64/150]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.5465 (0.5303)	Acc@1 90.448 (90.122)	Acc@5 98.806 (99.720)
Epoch: [97][128/150]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.5392 (0.5301)	Acc@1 88.358 (89.936)	Acc@5 99.403 (99.715)
Max memory in training epoch: 66.0123648
lr: 0.03799185132638679
1

Epoch: [98 | 100] LR: 0.037992
batch Size 335
Epoch: [98][0/150]	Time 0.199 (0.199)	Data 0.320 (0.320)	Loss 0.5238 (0.5238)	Acc@1 88.955 (88.955)	Acc@5 99.701 (99.701)
Epoch: [98][64/150]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.5435 (0.5135)	Acc@1 88.358 (90.246)	Acc@5 100.000 (99.761)
Epoch: [98][128/150]	Time 0.143 (0.129)	Data 0.000 (0.003)	Loss 0.5016 (0.5093)	Acc@1 91.045 (90.422)	Acc@5 99.403 (99.745)
Max memory in training epoch: 66.0123648
Drin!!
old memory: 645735424
new memory: 660123648
Faktor: 1.0222819183604213
New batch Size kleiner 342!!
lr: 0.03799185132638679
1

Epoch: [99 | 100] LR: 0.037992
batch Size 342
Epoch: [99][0/150]	Time 0.183 (0.183)	Data 0.281 (0.281)	Loss 0.4184 (0.4184)	Acc@1 93.134 (93.134)	Acc@5 99.701 (99.701)
Epoch: [99][64/150]	Time 0.131 (0.129)	Data 0.000 (0.005)	Loss 0.5435 (0.4982)	Acc@1 89.254 (90.544)	Acc@5 100.000 (99.724)
Epoch: [99][128/150]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.5579 (0.4989)	Acc@1 88.657 (90.404)	Acc@5 99.701 (99.713)
Max memory in training epoch: 66.0123648
lr: 0.03799185132638679
1

Epoch: [100 | 100] LR: 0.037992
batch Size 342
Epoch: [100][0/150]	Time 0.169 (0.169)	Data 0.322 (0.322)	Loss 0.5482 (0.5482)	Acc@1 87.761 (87.761)	Acc@5 99.104 (99.104)
Epoch: [100][64/150]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.5349 (0.4909)	Acc@1 87.761 (90.397)	Acc@5 100.000 (99.724)
Epoch: [100][128/150]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.4746 (0.4908)	Acc@1 91.642 (90.492)	Acc@5 99.701 (99.732)
Max memory in training epoch: 66.0123648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  85.72
Max memory: 78.5398784
 19.657s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3828
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1022976
lr: 0.05075473888134486
1

Epoch: [101 | 105] LR: 0.050755
batch Size 342
Epoch: [101][0/147]	Time 0.212 (0.212)	Data 0.287 (0.287)	Loss 0.5002 (0.5002)	Acc@1 90.058 (90.058)	Acc@5 99.415 (99.415)
Epoch: [101][64/147]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.6255 (0.4890)	Acc@1 87.427 (90.274)	Acc@5 99.708 (99.730)
Epoch: [101][128/147]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.4999 (0.5036)	Acc@1 88.596 (89.848)	Acc@5 100.000 (99.710)
Max memory in training epoch: 68.1305088
lr: 0.05075473888134486
1

Epoch: [102 | 105] LR: 0.050755
batch Size 342
Epoch: [102][0/147]	Time 0.187 (0.187)	Data 0.290 (0.290)	Loss 0.5148 (0.5148)	Acc@1 88.012 (88.012)	Acc@5 99.708 (99.708)
Epoch: [102][64/147]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.4681 (0.5078)	Acc@1 90.936 (89.564)	Acc@5 99.415 (99.690)
Epoch: [102][128/147]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.4979 (0.5089)	Acc@1 90.058 (89.451)	Acc@5 99.415 (99.714)
Max memory in training epoch: 68.0871424
lr: 0.05075473888134486
1

Epoch: [103 | 105] LR: 0.050755
batch Size 342
Epoch: [103][0/147]	Time 0.197 (0.197)	Data 0.316 (0.316)	Loss 0.4600 (0.4600)	Acc@1 91.228 (91.228)	Acc@5 99.708 (99.708)
Epoch: [103][64/147]	Time 0.140 (0.131)	Data 0.000 (0.005)	Loss 0.4609 (0.5047)	Acc@1 91.228 (89.577)	Acc@5 100.000 (99.694)
Epoch: [103][128/147]	Time 0.125 (0.130)	Data 0.000 (0.003)	Loss 0.5147 (0.5084)	Acc@1 90.936 (89.394)	Acc@5 99.708 (99.689)
Max memory in training epoch: 68.0871424
Drin!!
old memory: 660123648
new memory: 680871424
Faktor: 1.0314301359493183
New batch Size kleiner 352!!
lr: 0.05075473888134486
1

Epoch: [104 | 105] LR: 0.050755
batch Size 352
Epoch: [104][0/147]	Time 0.182 (0.182)	Data 0.322 (0.322)	Loss 0.4610 (0.4610)	Acc@1 89.181 (89.181)	Acc@5 100.000 (100.000)
Epoch: [104][64/147]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.5129 (0.5117)	Acc@1 88.304 (88.929)	Acc@5 100.000 (99.694)
Epoch: [104][128/147]	Time 0.122 (0.130)	Data 0.000 (0.003)	Loss 0.5389 (0.5112)	Acc@1 87.134 (89.100)	Acc@5 99.415 (99.708)
Max memory in training epoch: 68.0871424
lr: 0.05075473888134486
1

Epoch: [105 | 105] LR: 0.050755
batch Size 352
Epoch: [105][0/147]	Time 0.205 (0.205)	Data 0.290 (0.290)	Loss 0.5055 (0.5055)	Acc@1 88.889 (88.889)	Acc@5 99.415 (99.415)
Epoch: [105][64/147]	Time 0.135 (0.130)	Data 0.000 (0.005)	Loss 0.4813 (0.4983)	Acc@1 88.889 (89.262)	Acc@5 99.708 (99.699)
Epoch: [105][128/147]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.4627 (0.5048)	Acc@1 90.936 (89.208)	Acc@5 100.000 (99.665)
Max memory in training epoch: 68.0871424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 232450 ; 235284 ; 0.9879549820642287
[INFO] Storing checkpoint...
  84.66
Max memory: 78.8214784
 19.426s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8157
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1010688
lr: 0.06978776596184919
1

Epoch: [106 | 110] LR: 0.069788
batch Size 352
Epoch: [106][0/143]	Time 0.216 (0.216)	Data 0.332 (0.332)	Loss 0.4810 (0.4810)	Acc@1 90.057 (90.057)	Acc@5 99.432 (99.432)
Epoch: [106][64/143]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.5814 (0.5177)	Acc@1 85.227 (88.947)	Acc@5 98.864 (99.650)
Epoch: [106][128/143]	Time 0.132 (0.131)	Data 0.000 (0.003)	Loss 0.5671 (0.5406)	Acc@1 87.216 (88.002)	Acc@5 98.580 (99.621)
Max memory in training epoch: 68.878592
lr: 0.06978776596184919
1

Epoch: [107 | 110] LR: 0.069788
batch Size 352
Epoch: [107][0/143]	Time 0.196 (0.196)	Data 0.374 (0.374)	Loss 0.5502 (0.5502)	Acc@1 88.352 (88.352)	Acc@5 99.716 (99.716)
Epoch: [107][64/143]	Time 0.126 (0.134)	Data 0.000 (0.006)	Loss 0.6069 (0.6892)	Acc@1 85.795 (83.470)	Acc@5 98.864 (99.231)
Epoch: [107][128/143]	Time 0.135 (0.133)	Data 0.000 (0.003)	Loss 0.5083 (0.6449)	Acc@1 89.205 (85.025)	Acc@5 99.432 (99.335)
Max memory in training epoch: 68.698368
lr: 0.06978776596184919
1

Epoch: [108 | 110] LR: 0.069788
batch Size 352
Epoch: [108][0/143]	Time 0.198 (0.198)	Data 0.289 (0.289)	Loss 0.5387 (0.5387)	Acc@1 89.205 (89.205)	Acc@5 99.432 (99.432)
Epoch: [108][64/143]	Time 0.134 (0.133)	Data 0.000 (0.005)	Loss 0.5434 (0.5968)	Acc@1 89.205 (86.608)	Acc@5 99.148 (99.567)
Epoch: [108][128/143]	Time 0.161 (0.133)	Data 0.000 (0.002)	Loss 0.5180 (0.5836)	Acc@1 88.352 (87.007)	Acc@5 100.000 (99.568)
Max memory in training epoch: 68.698368
Drin!!
old memory: 680871424
new memory: 686983680
Faktor: 1.0089771075485758
New batch Size kleiner 355!!
lr: 0.06978776596184919
1

Epoch: [109 | 110] LR: 0.069788
batch Size 355
Epoch: [109][0/143]	Time 0.175 (0.175)	Data 0.286 (0.286)	Loss 0.5426 (0.5426)	Acc@1 88.920 (88.920)	Acc@5 99.432 (99.432)
Epoch: [109][64/143]	Time 0.147 (0.134)	Data 0.000 (0.005)	Loss 0.5273 (0.6686)	Acc@1 89.205 (84.672)	Acc@5 99.716 (99.296)
Epoch: [109][128/143]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.5901 (0.6238)	Acc@1 87.500 (86.113)	Acc@5 99.716 (99.447)
Max memory in training epoch: 68.698368
lr: 0.06978776596184919
1

Epoch: [110 | 110] LR: 0.069788
batch Size 355
Epoch: [110][0/143]	Time 0.201 (0.201)	Data 0.329 (0.329)	Loss 0.5468 (0.5468)	Acc@1 87.784 (87.784)	Acc@5 99.716 (99.716)
Epoch: [110][64/143]	Time 0.129 (0.134)	Data 0.000 (0.005)	Loss 0.5431 (0.6348)	Acc@1 88.352 (85.809)	Acc@5 99.148 (99.401)
Epoch: [110][128/143]	Time 0.147 (0.134)	Data 0.000 (0.003)	Loss 0.6197 (0.6053)	Acc@1 84.091 (86.632)	Acc@5 99.432 (99.491)
Max memory in training epoch: 68.698368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 230039 ; 232450 ; 0.9896278769627876
[INFO] Storing checkpoint...
  78.68
Max memory: 78.3567872
 19.428s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4613
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1000448
lr: 0.09677600357990805
1

Epoch: [111 | 115] LR: 0.096776
batch Size 355
Epoch: [111][0/141]	Time 0.227 (0.227)	Data 0.324 (0.324)	Loss 0.5943 (0.5943)	Acc@1 86.761 (86.761)	Acc@5 99.718 (99.718)
Epoch: [111][64/141]	Time 0.147 (0.132)	Data 0.000 (0.005)	Loss 0.5430 (0.5885)	Acc@1 87.887 (87.450)	Acc@5 99.718 (99.528)
Epoch: [111][128/141]	Time 0.152 (0.131)	Data 0.001 (0.003)	Loss 0.6636 (0.5986)	Acc@1 83.099 (86.944)	Acc@5 99.437 (99.520)
Max memory in training epoch: 68.7141376
lr: 0.09677600357990805
1

Epoch: [112 | 115] LR: 0.096776
batch Size 355
Epoch: [112][0/141]	Time 0.189 (0.189)	Data 0.380 (0.380)	Loss 0.6101 (0.6101)	Acc@1 87.324 (87.324)	Acc@5 99.437 (99.437)
Epoch: [112][64/141]	Time 0.128 (0.130)	Data 0.000 (0.006)	Loss 0.6536 (0.6004)	Acc@1 84.789 (87.042)	Acc@5 99.437 (99.489)
Epoch: [112][128/141]	Time 0.125 (0.130)	Data 0.001 (0.003)	Loss 0.6255 (0.6058)	Acc@1 86.197 (86.776)	Acc@5 99.718 (99.472)
Max memory in training epoch: 68.7141376
lr: 0.09677600357990805
1

Epoch: [113 | 115] LR: 0.096776
batch Size 355
Epoch: [113][0/141]	Time 0.161 (0.161)	Data 0.293 (0.293)	Loss 0.6343 (0.6343)	Acc@1 84.789 (84.789)	Acc@5 99.718 (99.718)
Epoch: [113][64/141]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.6050 (0.5931)	Acc@1 85.915 (87.081)	Acc@5 99.718 (99.545)
Epoch: [113][128/141]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6087 (0.5997)	Acc@1 86.479 (86.913)	Acc@5 99.718 (99.513)
Max memory in training epoch: 68.7141376
Drin!!
old memory: 686983680
new memory: 687141376
Faktor: 1.0002295483933477
New batch Size kleiner 355!!
lr: 0.09677600357990805
1

Epoch: [114 | 115] LR: 0.096776
batch Size 355
Epoch: [114][0/141]	Time 0.191 (0.191)	Data 0.322 (0.322)	Loss 0.5888 (0.5888)	Acc@1 87.324 (87.324)	Acc@5 99.718 (99.718)
Epoch: [114][64/141]	Time 0.120 (0.131)	Data 0.000 (0.005)	Loss 0.5288 (0.5889)	Acc@1 90.986 (87.341)	Acc@5 98.873 (99.506)
Epoch: [114][128/141]	Time 0.125 (0.130)	Data 0.000 (0.003)	Loss 0.6456 (0.5959)	Acc@1 84.507 (87.018)	Acc@5 99.437 (99.541)
Max memory in training epoch: 68.7141376
lr: 0.09677600357990805
1

Epoch: [115 | 115] LR: 0.096776
batch Size 355
Epoch: [115][0/141]	Time 0.193 (0.193)	Data 0.306 (0.306)	Loss 0.6342 (0.6342)	Acc@1 85.070 (85.070)	Acc@5 99.718 (99.718)
Epoch: [115][64/141]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.6306 (0.5901)	Acc@1 85.915 (87.359)	Acc@5 99.437 (99.489)
Epoch: [115][128/141]	Time 0.169 (0.129)	Data 0.001 (0.003)	Loss 0.5704 (0.5976)	Acc@1 89.014 (87.029)	Acc@5 99.155 (99.511)
Max memory in training epoch: 68.7141376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 225981 ; 230039 ; 0.9823595129521516
[INFO] Storing checkpoint...
  68.06
Max memory: 78.2902272
 18.636s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4463
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0985088
lr: 0.13420109871432562
1

Epoch: [116 | 120] LR: 0.134201
batch Size 355
Epoch: [116][0/141]	Time 0.209 (0.209)	Data 0.320 (0.320)	Loss 0.5782 (0.5782)	Acc@1 88.169 (88.169)	Acc@5 99.718 (99.718)
Epoch: [116][64/141]	Time 0.144 (0.134)	Data 0.000 (0.005)	Loss 0.5865 (0.6504)	Acc@1 86.197 (85.248)	Acc@5 99.437 (99.419)
Epoch: [116][128/141]	Time 0.130 (0.132)	Data 0.001 (0.003)	Loss 0.7137 (0.6672)	Acc@1 84.507 (85.007)	Acc@5 99.155 (99.303)
Max memory in training epoch: 68.2910208
lr: 0.13420109871432562
1

Epoch: [117 | 120] LR: 0.134201
batch Size 355
Epoch: [117][0/141]	Time 0.220 (0.220)	Data 0.318 (0.318)	Loss 0.6730 (0.6730)	Acc@1 85.070 (85.070)	Acc@5 99.155 (99.155)
Epoch: [117][64/141]	Time 0.131 (0.134)	Data 0.000 (0.005)	Loss 0.6564 (0.6677)	Acc@1 85.070 (85.378)	Acc@5 99.437 (99.380)
Epoch: [117][128/141]	Time 0.131 (0.132)	Data 0.001 (0.003)	Loss 0.5719 (0.6670)	Acc@1 89.296 (85.391)	Acc@5 99.437 (99.369)
Max memory in training epoch: 68.2910208
lr: 0.13420109871432562
1

Epoch: [118 | 120] LR: 0.134201
batch Size 355
Epoch: [118][0/141]	Time 0.201 (0.201)	Data 0.283 (0.283)	Loss 0.6578 (0.6578)	Acc@1 85.634 (85.634)	Acc@5 99.437 (99.437)
Epoch: [118][64/141]	Time 0.124 (0.135)	Data 0.000 (0.005)	Loss 0.7071 (0.6502)	Acc@1 83.662 (85.911)	Acc@5 99.155 (99.467)
Epoch: [118][128/141]	Time 0.137 (0.132)	Data 0.001 (0.002)	Loss 0.6338 (0.6499)	Acc@1 86.197 (85.883)	Acc@5 99.718 (99.474)
Max memory in training epoch: 68.2910208
Drin!!
old memory: 687141376
new memory: 682910208
Faktor: 0.9938423617791282
New batch Size größer 348!!
lr: 0.13420109871432562
1

Epoch: [119 | 120] LR: 0.134201
batch Size 348
Epoch: [119][0/141]	Time 0.181 (0.181)	Data 0.287 (0.287)	Loss 0.5892 (0.5892)	Acc@1 89.014 (89.014)	Acc@5 99.437 (99.437)
Epoch: [119][64/141]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.6572 (0.6547)	Acc@1 85.070 (85.777)	Acc@5 99.718 (99.510)
Epoch: [119][128/141]	Time 0.125 (0.131)	Data 0.001 (0.002)	Loss 0.7456 (0.6573)	Acc@1 80.563 (85.623)	Acc@5 99.718 (99.513)
Max memory in training epoch: 68.2910208
lr: 0.13420109871432562
1

Epoch: [120 | 120] LR: 0.134201
batch Size 348
Epoch: [120][0/141]	Time 0.189 (0.189)	Data 0.349 (0.349)	Loss 0.7209 (0.7209)	Acc@1 84.507 (84.507)	Acc@5 99.155 (99.155)
Epoch: [120][64/141]	Time 0.129 (0.134)	Data 0.000 (0.006)	Loss 0.6300 (0.6488)	Acc@1 86.761 (86.020)	Acc@5 99.155 (99.437)
Epoch: [120][128/141]	Time 0.121 (0.131)	Data 0.000 (0.003)	Loss 0.6320 (0.6625)	Acc@1 86.197 (85.538)	Acc@5 99.718 (99.417)
Max memory in training epoch: 68.2910208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 224996 ; 225981 ; 0.9956412264747921
[INFO] Storing checkpoint...
  76.24
Max memory: 78.0140544
 18.954s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 999
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0981504
lr: 0.1824296185647864
1

Epoch: [121 | 125] LR: 0.182430
batch Size 348
Epoch: [121][0/144]	Time 0.232 (0.232)	Data 0.286 (0.286)	Loss 0.6526 (0.6526)	Acc@1 87.356 (87.356)	Acc@5 98.851 (98.851)
Epoch: [121][64/144]	Time 0.145 (0.135)	Data 0.000 (0.005)	Loss 0.7767 (0.6859)	Acc@1 81.322 (84.797)	Acc@5 99.138 (99.359)
Epoch: [121][128/144]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7618 (0.7201)	Acc@1 81.897 (83.835)	Acc@5 99.713 (99.260)
Max memory in training epoch: 67.508992
lr: 0.1824296185647864
1

Epoch: [122 | 125] LR: 0.182430
batch Size 348
Epoch: [122][0/144]	Time 0.190 (0.190)	Data 0.332 (0.332)	Loss 0.7032 (0.7032)	Acc@1 85.632 (85.632)	Acc@5 99.138 (99.138)
Epoch: [122][64/144]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.7211 (0.7349)	Acc@1 81.609 (83.749)	Acc@5 99.713 (99.293)
Epoch: [122][128/144]	Time 0.133 (0.133)	Data 0.000 (0.003)	Loss 0.7675 (0.7313)	Acc@1 83.333 (83.850)	Acc@5 99.425 (99.296)
Max memory in training epoch: 67.271424
lr: 0.1824296185647864
1

Epoch: [123 | 125] LR: 0.182430
batch Size 348
Epoch: [123][0/144]	Time 0.200 (0.200)	Data 0.282 (0.282)	Loss 0.6326 (0.6326)	Acc@1 85.057 (85.057)	Acc@5 99.425 (99.425)
Epoch: [123][64/144]	Time 0.135 (0.134)	Data 0.000 (0.005)	Loss 0.6865 (0.7194)	Acc@1 84.195 (84.328)	Acc@5 99.713 (99.337)
Epoch: [123][128/144]	Time 0.126 (0.133)	Data 0.000 (0.002)	Loss 0.6572 (0.7219)	Acc@1 89.368 (84.276)	Acc@5 98.851 (99.341)
Max memory in training epoch: 67.271424
Drin!!
old memory: 682910208
new memory: 672714240
Faktor: 0.9850698263394534
New batch Size größer 346!!
lr: 0.1824296185647864
1

Epoch: [124 | 125] LR: 0.182430
batch Size 346
Epoch: [124][0/144]	Time 0.192 (0.192)	Data 0.280 (0.280)	Loss 0.7240 (0.7240)	Acc@1 82.759 (82.759)	Acc@5 99.138 (99.138)
Epoch: [124][64/144]	Time 0.123 (0.135)	Data 0.000 (0.005)	Loss 0.7790 (0.7102)	Acc@1 80.460 (84.500)	Acc@5 99.713 (99.302)
Epoch: [124][128/144]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6638 (0.7200)	Acc@1 85.920 (84.146)	Acc@5 99.713 (99.312)
Max memory in training epoch: 67.271424
lr: 0.1824296185647864
1

Epoch: [125 | 125] LR: 0.182430
batch Size 346
Epoch: [125][0/144]	Time 0.194 (0.194)	Data 0.291 (0.291)	Loss 0.6434 (0.6434)	Acc@1 88.218 (88.218)	Acc@5 100.000 (100.000)
Epoch: [125][64/144]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7909 (0.7163)	Acc@1 81.897 (84.319)	Acc@5 98.851 (99.302)
Epoch: [125][128/144]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6809 (0.7266)	Acc@1 84.770 (84.037)	Acc@5 99.713 (99.312)
Max memory in training epoch: 67.271424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.47
Max memory: 77.693696
 19.272s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5276
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0981504
lr: 0.24656503134146912
1

Epoch: [126 | 130] LR: 0.246565
batch Size 346
Epoch: [126][0/145]	Time 0.236 (0.236)	Data 0.291 (0.291)	Loss 0.6750 (0.6750)	Acc@1 86.127 (86.127)	Acc@5 98.844 (98.844)
Epoch: [126][64/145]	Time 0.134 (0.131)	Data 0.000 (0.005)	Loss 0.7996 (0.7763)	Acc@1 82.948 (82.352)	Acc@5 98.555 (99.186)
Epoch: [126][128/145]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.8666 (0.7926)	Acc@1 79.480 (81.935)	Acc@5 99.422 (99.149)
Max memory in training epoch: 67.05152
lr: 0.24656503134146912
1

Epoch: [127 | 130] LR: 0.246565
batch Size 346
Epoch: [127][0/145]	Time 0.167 (0.167)	Data 0.315 (0.315)	Loss 0.7366 (0.7366)	Acc@1 85.838 (85.838)	Acc@5 98.844 (98.844)
Epoch: [127][64/145]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.8908 (0.7858)	Acc@1 79.191 (82.601)	Acc@5 98.555 (99.151)
Epoch: [127][128/145]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.8310 (0.7898)	Acc@1 82.659 (82.545)	Acc@5 97.977 (99.097)
Max memory in training epoch: 67.0893056
lr: 0.24656503134146912
1

Epoch: [128 | 130] LR: 0.246565
batch Size 346
Epoch: [128][0/145]	Time 0.200 (0.200)	Data 0.288 (0.288)	Loss 0.8221 (0.8221)	Acc@1 80.636 (80.636)	Acc@5 97.977 (97.977)
Epoch: [128][64/145]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7113 (0.7863)	Acc@1 85.838 (82.534)	Acc@5 100.000 (99.133)
Epoch: [128][128/145]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7165 (0.7782)	Acc@1 85.549 (82.807)	Acc@5 99.133 (99.111)
Max memory in training epoch: 67.0893056
Drin!!
old memory: 672714240
new memory: 670893056
Faktor: 0.9972927821477363
New batch Size größer 345!!
lr: 0.24656503134146912
1

Epoch: [129 | 130] LR: 0.246565
batch Size 345
Epoch: [129][0/145]	Time 0.184 (0.184)	Data 0.328 (0.328)	Loss 0.8408 (0.8408)	Acc@1 80.058 (80.058)	Acc@5 98.844 (98.844)
Epoch: [129][64/145]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.7650 (0.7892)	Acc@1 80.636 (82.432)	Acc@5 99.711 (99.142)
Epoch: [129][128/145]	Time 0.132 (0.130)	Data 0.000 (0.003)	Loss 0.8372 (0.7907)	Acc@1 82.659 (82.433)	Acc@5 98.844 (99.099)
Max memory in training epoch: 67.0893056
lr: 0.24656503134146912
1

Epoch: [130 | 130] LR: 0.246565
batch Size 345
Epoch: [130][0/145]	Time 0.182 (0.182)	Data 0.362 (0.362)	Loss 0.8177 (0.8177)	Acc@1 81.503 (81.503)	Acc@5 99.133 (99.133)
Epoch: [130][64/145]	Time 0.132 (0.130)	Data 0.000 (0.006)	Loss 0.7969 (0.7839)	Acc@1 82.948 (82.557)	Acc@5 99.422 (99.186)
Epoch: [130][128/145]	Time 0.123 (0.129)	Data 0.000 (0.003)	Loss 0.7520 (0.7844)	Acc@1 85.260 (82.435)	Acc@5 99.133 (99.144)
Max memory in training epoch: 67.0893056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 223876 ; 224996 ; 0.9950221337268218
[INFO] Storing checkpoint...
  75.55
Max memory: 77.4209024
 19.127s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9856
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.0977408
lr: 0.33228490551877676
1

Epoch: [131 | 135] LR: 0.332285
batch Size 345
Epoch: [131][0/145]	Time 0.219 (0.219)	Data 0.327 (0.327)	Loss 0.7769 (0.7769)	Acc@1 81.159 (81.159)	Acc@5 99.710 (99.710)
Epoch: [131][64/145]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.7813 (0.8401)	Acc@1 82.899 (80.941)	Acc@5 99.130 (98.778)
Epoch: [131][128/145]	Time 0.123 (0.129)	Data 0.000 (0.003)	Loss 0.8766 (0.8587)	Acc@1 78.551 (80.357)	Acc@5 98.551 (98.778)
Max memory in training epoch: 66.658304
lr: 0.33228490551877676
1

Epoch: [132 | 135] LR: 0.332285
batch Size 345
Epoch: [132][0/145]	Time 0.159 (0.159)	Data 0.306 (0.306)	Loss 0.8706 (0.8706)	Acc@1 80.290 (80.290)	Acc@5 99.130 (99.130)
Epoch: [132][64/145]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.8506 (0.8710)	Acc@1 82.899 (80.214)	Acc@5 99.420 (98.805)
Epoch: [132][128/145]	Time 0.127 (0.130)	Data 0.000 (0.003)	Loss 0.8037 (0.8675)	Acc@1 83.768 (80.463)	Acc@5 99.710 (98.814)
Max memory in training epoch: 66.658304
lr: 0.33228490551877676
1

Epoch: [133 | 135] LR: 0.332285
batch Size 345
Epoch: [133][0/145]	Time 0.181 (0.181)	Data 0.323 (0.323)	Loss 0.7689 (0.7689)	Acc@1 84.638 (84.638)	Acc@5 99.130 (99.130)
Epoch: [133][64/145]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.8597 (0.8478)	Acc@1 80.580 (81.097)	Acc@5 99.420 (98.903)
Epoch: [133][128/145]	Time 0.123 (0.131)	Data 0.000 (0.003)	Loss 0.8436 (0.8410)	Acc@1 80.580 (81.132)	Acc@5 99.710 (98.987)
Max memory in training epoch: 66.658304
Drin!!
old memory: 670893056
new memory: 666583040
Faktor: 0.9935757033681386
New batch Size größer 346!!
lr: 0.33228490551877676
1

Epoch: [134 | 135] LR: 0.332285
batch Size 346
Epoch: [134][0/145]	Time 0.190 (0.190)	Data 0.317 (0.317)	Loss 0.9172 (0.9172)	Acc@1 78.261 (78.261)	Acc@5 99.130 (99.130)
Epoch: [134][64/145]	Time 0.136 (0.129)	Data 0.000 (0.005)	Loss 0.8397 (0.8448)	Acc@1 82.029 (80.994)	Acc@5 98.841 (98.979)
Epoch: [134][128/145]	Time 0.126 (0.129)	Data 0.000 (0.003)	Loss 0.8821 (0.8537)	Acc@1 79.710 (80.658)	Acc@5 98.551 (98.946)
Max memory in training epoch: 66.658304
lr: 0.33228490551877676
1

Epoch: [135 | 135] LR: 0.332285
batch Size 346
Epoch: [135][0/145]	Time 0.194 (0.194)	Data 0.312 (0.312)	Loss 0.9901 (0.9901)	Acc@1 75.362 (75.362)	Acc@5 97.101 (97.101)
Epoch: [135][64/145]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.8269 (0.8422)	Acc@1 81.739 (81.008)	Acc@5 98.841 (98.961)
Epoch: [135][128/145]	Time 0.133 (0.130)	Data 0.000 (0.003)	Loss 0.8036 (0.8434)	Acc@1 82.029 (80.955)	Acc@5 98.841 (98.980)
Max memory in training epoch: 66.658304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 219878 ; 223876 ; 0.9821418999803463
[INFO] Storing checkpoint...
  66.49
Max memory: 77.5587328
 19.185s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8897
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.095488
lr: 0.4491038176152217
1

Epoch: [136 | 140] LR: 0.449104
batch Size 346
Epoch: [136][0/145]	Time 0.220 (0.220)	Data 0.299 (0.299)	Loss 0.8299 (0.8299)	Acc@1 80.636 (80.636)	Acc@5 99.422 (99.422)
Epoch: [136][64/145]	Time 0.138 (0.126)	Data 0.000 (0.005)	Loss 0.8601 (0.8823)	Acc@1 79.480 (79.876)	Acc@5 98.555 (98.715)
Epoch: [136][128/145]	Time 0.116 (0.126)	Data 0.000 (0.003)	Loss 0.9906 (0.9186)	Acc@1 76.301 (78.808)	Acc@5 98.844 (98.633)
Max memory in training epoch: 63.71968
lr: 0.4491038176152217
1

Epoch: [137 | 140] LR: 0.449104
batch Size 346
Epoch: [137][0/145]	Time 0.180 (0.180)	Data 0.325 (0.325)	Loss 0.9419 (0.9419)	Acc@1 76.590 (76.590)	Acc@5 99.422 (99.422)
Epoch: [137][64/145]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.8713 (0.9340)	Acc@1 81.792 (78.337)	Acc@5 99.711 (98.622)
Epoch: [137][128/145]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.9118 (0.9349)	Acc@1 78.324 (78.458)	Acc@5 98.844 (98.656)
Max memory in training epoch: 63.6983296
lr: 0.4491038176152217
1

Epoch: [138 | 140] LR: 0.449104
batch Size 346
Epoch: [138][0/145]	Time 0.153 (0.153)	Data 0.322 (0.322)	Loss 1.0246 (1.0246)	Acc@1 75.145 (75.145)	Acc@5 98.555 (98.555)
Epoch: [138][64/145]	Time 0.130 (0.125)	Data 0.000 (0.005)	Loss 0.8899 (0.9361)	Acc@1 78.902 (78.506)	Acc@5 98.844 (98.688)
Epoch: [138][128/145]	Time 0.126 (0.126)	Data 0.000 (0.003)	Loss 0.9826 (0.9254)	Acc@1 76.012 (78.767)	Acc@5 98.844 (98.705)
Max memory in training epoch: 63.6983296
Drin!!
old memory: 666583040
new memory: 636983296
Faktor: 0.9555948138134448
New batch Size größer 363!!
lr: 0.4491038176152217
1

Epoch: [139 | 140] LR: 0.449104
batch Size 363
Epoch: [139][0/145]	Time 0.184 (0.184)	Data 0.350 (0.350)	Loss 0.9454 (0.9454)	Acc@1 77.746 (77.746)	Acc@5 98.844 (98.844)
Epoch: [139][64/145]	Time 0.119 (0.125)	Data 0.000 (0.006)	Loss 0.9920 (0.9229)	Acc@1 75.145 (78.444)	Acc@5 98.844 (98.662)
Epoch: [139][128/145]	Time 0.127 (0.126)	Data 0.000 (0.003)	Loss 0.8375 (0.9190)	Acc@1 78.902 (78.541)	Acc@5 98.555 (98.736)
Max memory in training epoch: 63.6983296
lr: 0.4491038176152217
1

Epoch: [140 | 140] LR: 0.449104
batch Size 363
Epoch: [140][0/145]	Time 0.145 (0.145)	Data 0.330 (0.330)	Loss 0.8432 (0.8432)	Acc@1 81.214 (81.214)	Acc@5 99.133 (99.133)
Epoch: [140][64/145]	Time 0.142 (0.125)	Data 0.000 (0.005)	Loss 0.9008 (0.9245)	Acc@1 78.902 (78.737)	Acc@5 100.000 (98.715)
Epoch: [140][128/145]	Time 0.121 (0.124)	Data 0.000 (0.003)	Loss 0.9157 (0.9182)	Acc@1 80.058 (78.877)	Acc@5 97.688 (98.620)
Max memory in training epoch: 63.6983296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 205989 ; 219878 ; 0.9368331529302614
[INFO] Storing checkpoint...
  68.87
Max memory: 73.7658368
 18.422s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7656
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0899584
lr: 0.6368151788840839
1

Epoch: [141 | 145] LR: 0.636815
batch Size 363
Epoch: [141][0/138]	Time 0.203 (0.203)	Data 0.378 (0.378)	Loss 0.9500 (0.9500)	Acc@1 74.380 (74.380)	Acc@5 99.725 (99.725)
Epoch: [141][64/138]	Time 0.121 (0.125)	Data 0.000 (0.006)	Loss 1.1305 (1.0230)	Acc@1 74.380 (75.185)	Acc@5 97.521 (98.381)
Epoch: [141][128/138]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.9681 (1.0394)	Acc@1 76.860 (74.995)	Acc@5 98.347 (98.285)
Max memory in training epoch: 64.6531072
lr: 0.6368151788840839
1

Epoch: [142 | 145] LR: 0.636815
batch Size 363
Epoch: [142][0/138]	Time 0.182 (0.182)	Data 0.338 (0.338)	Loss 1.0016 (1.0016)	Acc@1 77.135 (77.135)	Acc@5 97.796 (97.796)
Epoch: [142][64/138]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 1.0666 (1.0059)	Acc@1 72.452 (76.529)	Acc@5 98.347 (98.415)
Epoch: [142][128/138]	Time 0.118 (0.123)	Data 0.000 (0.003)	Loss 0.9782 (1.0043)	Acc@1 77.961 (76.403)	Acc@5 98.072 (98.433)
Max memory in training epoch: 64.576256
lr: 0.6368151788840839
1

Epoch: [143 | 145] LR: 0.636815
batch Size 363
Epoch: [143][0/138]	Time 0.132 (0.132)	Data 0.292 (0.292)	Loss 1.0160 (1.0160)	Acc@1 75.207 (75.207)	Acc@5 98.623 (98.623)
Epoch: [143][64/138]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 1.1790 (1.0140)	Acc@1 71.074 (76.143)	Acc@5 97.796 (98.245)
Epoch: [143][128/138]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.9845 (1.0185)	Acc@1 74.380 (75.894)	Acc@5 98.898 (98.326)
Max memory in training epoch: 64.576256
Drin!!
old memory: 636983296
new memory: 645762560
Faktor: 1.0137825655007444
New batch Size kleiner 368!!
lr: 0.6368151788840839
1

Epoch: [144 | 145] LR: 0.636815
batch Size 368
Epoch: [144][0/138]	Time 0.155 (0.155)	Data 0.329 (0.329)	Loss 0.9591 (0.9591)	Acc@1 77.686 (77.686)	Acc@5 98.072 (98.072)
Epoch: [144][64/138]	Time 0.114 (0.125)	Data 0.000 (0.005)	Loss 0.9761 (1.0009)	Acc@1 77.135 (76.152)	Acc@5 98.898 (98.411)
Epoch: [144][128/138]	Time 0.122 (0.124)	Data 0.000 (0.003)	Loss 1.0233 (1.0085)	Acc@1 76.309 (75.950)	Acc@5 97.796 (98.319)
Max memory in training epoch: 64.576256
lr: 0.6368151788840839
1

Epoch: [145 | 145] LR: 0.636815
batch Size 368
Epoch: [145][0/138]	Time 0.186 (0.186)	Data 0.320 (0.320)	Loss 1.0075 (1.0075)	Acc@1 75.758 (75.758)	Acc@5 97.796 (97.796)
Epoch: [145][64/138]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 1.0245 (1.0197)	Acc@1 74.931 (75.414)	Acc@5 98.347 (98.224)
Epoch: [145][128/138]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 1.1116 (1.0086)	Acc@1 73.003 (75.685)	Acc@5 96.143 (98.285)
Max memory in training epoch: 64.576256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv28.weight

 RM:  module.conv29.weight
numoFStages: 3
Count: 195861 ; 205989 ; 0.9508323259979902
[INFO] Storing checkpoint...
  62.82
Max memory: 71.5836928
 17.544s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2292
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.085504
lr: 0.9154218196458705
1

Epoch: [146 | 150] LR: 0.915422
batch Size 368
Epoch: [146][0/136]	Time 0.199 (0.199)	Data 0.330 (0.330)	Loss 0.9929 (0.9929)	Acc@1 76.087 (76.087)	Acc@5 98.913 (98.913)
Epoch: [146][64/136]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 1.1185 (1.0870)	Acc@1 71.467 (73.549)	Acc@5 98.641 (97.868)
Epoch: [146][128/136]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 1.1173 (1.1090)	Acc@1 73.370 (73.051)	Acc@5 97.554 (97.875)
Max memory in training epoch: 63.7508608
lr: 0.9154218196458705
1

Epoch: [147 | 150] LR: 0.915422
batch Size 368
Epoch: [147][0/136]	Time 0.187 (0.187)	Data 0.328 (0.328)	Loss 1.1656 (1.1656)	Acc@1 70.652 (70.652)	Acc@5 97.826 (97.826)
Epoch: [147][64/136]	Time 0.127 (0.123)	Data 0.000 (0.005)	Loss 1.0701 (1.1246)	Acc@1 76.902 (72.893)	Acc@5 98.370 (97.634)
Epoch: [147][128/136]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 1.0131 (1.1171)	Acc@1 75.000 (72.936)	Acc@5 98.913 (97.803)
Max memory in training epoch: 63.6171264
lr: 0.9154218196458705
1

Epoch: [148 | 150] LR: 0.915422
batch Size 368
Epoch: [148][0/136]	Time 0.178 (0.178)	Data 0.287 (0.287)	Loss 1.0077 (1.0077)	Acc@1 76.359 (76.359)	Acc@5 98.098 (98.098)
Epoch: [148][64/136]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 1.0820 (1.1025)	Acc@1 76.087 (73.010)	Acc@5 97.826 (97.784)
Epoch: [148][128/136]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 1.1051 (1.1094)	Acc@1 70.652 (72.731)	Acc@5 98.098 (97.826)
Max memory in training epoch: 63.6171264
Drin!!
old memory: 645762560
new memory: 636171264
Faktor: 0.9851473334099766
New batch Size größer 387!!
lr: 0.9154218196458705
1

Epoch: [149 | 150] LR: 0.915422
batch Size 387
Epoch: [149][0/136]	Time 0.131 (0.131)	Data 0.284 (0.284)	Loss 1.0997 (1.0997)	Acc@1 73.098 (73.098)	Acc@5 97.826 (97.826)
Epoch: [149][64/136]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 1.1601 (1.1025)	Acc@1 69.022 (72.952)	Acc@5 96.739 (97.738)
Epoch: [149][128/136]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 1.0331 (1.1079)	Acc@1 75.815 (72.805)	Acc@5 98.370 (97.767)
Max memory in training epoch: 63.6171264
lr: 0.9154218196458705
1

Epoch: [150 | 150] LR: 0.091542
batch Size 387
Epoch: [150][0/136]	Time 0.150 (0.150)	Data 0.292 (0.292)	Loss 1.0023 (1.0023)	Acc@1 77.174 (77.174)	Acc@5 98.098 (98.098)
Epoch: [150][64/136]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.7731 (0.8873)	Acc@1 83.152 (79.812)	Acc@5 99.185 (98.796)
Epoch: [150][128/136]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.7899 (0.8409)	Acc@1 82.065 (81.058)	Acc@5 98.913 (98.945)
Max memory in training epoch: 63.6171264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 176360 ; 195861 ; 0.9004344918079659
[INFO] Storing checkpoint...
  81.82
Max memory: 67.8800384
 16.877s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3067
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0775168
lr: 0.1383860328917781
1

Epoch: [151 | 155] LR: 0.138386
batch Size 387
Epoch: [151][0/130]	Time 0.203 (0.203)	Data 0.328 (0.328)	Loss 0.7826 (0.7826)	Acc@1 85.013 (85.013)	Acc@5 98.966 (98.966)
Epoch: [151][64/130]	Time 0.130 (0.122)	Data 0.000 (0.005)	Loss 0.8044 (0.7598)	Acc@1 82.171 (83.216)	Acc@5 98.966 (99.102)
Epoch: [151][128/130]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.6920 (0.7462)	Acc@1 84.755 (83.398)	Acc@5 99.742 (99.171)
Max memory in training epoch: 62.884864
lr: 0.1383860328917781
1

Epoch: [152 | 155] LR: 0.138386
batch Size 387
Epoch: [152][0/130]	Time 0.182 (0.182)	Data 0.332 (0.332)	Loss 0.7587 (0.7587)	Acc@1 80.362 (80.362)	Acc@5 98.708 (98.708)
Epoch: [152][64/130]	Time 0.131 (0.123)	Data 0.000 (0.005)	Loss 0.6763 (0.6914)	Acc@1 85.788 (84.580)	Acc@5 99.742 (99.177)
Epoch: [152][128/130]	Time 0.115 (0.122)	Data 0.000 (0.003)	Loss 0.6696 (0.6913)	Acc@1 85.013 (84.332)	Acc@5 99.225 (99.267)
Max memory in training epoch: 62.708736
lr: 0.1383860328917781
1

Epoch: [153 | 155] LR: 0.138386
batch Size 387
Epoch: [153][0/130]	Time 0.169 (0.169)	Data 0.333 (0.333)	Loss 0.6233 (0.6233)	Acc@1 88.114 (88.114)	Acc@5 98.966 (98.966)
Epoch: [153][64/130]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.6557 (0.6682)	Acc@1 84.496 (84.576)	Acc@5 99.483 (99.276)
Epoch: [153][128/130]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.6828 (0.6693)	Acc@1 82.429 (84.404)	Acc@5 99.742 (99.297)
Max memory in training epoch: 62.708736
Drin!!
old memory: 636171264
new memory: 627087360
Faktor: 0.9857209771738448
New batch Size größer 413!!
lr: 0.1383860328917781
1

Epoch: [154 | 155] LR: 0.138386
batch Size 413
Epoch: [154][0/130]	Time 0.180 (0.180)	Data 0.323 (0.323)	Loss 0.6859 (0.6859)	Acc@1 86.047 (86.047)	Acc@5 98.966 (98.966)
Epoch: [154][64/130]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.6549 (0.6634)	Acc@1 84.238 (84.103)	Acc@5 99.483 (99.233)
Epoch: [154][128/130]	Time 0.116 (0.122)	Data 0.000 (0.003)	Loss 0.6958 (0.6552)	Acc@1 82.687 (84.152)	Acc@5 99.483 (99.305)
Max memory in training epoch: 62.708736
lr: 0.1383860328917781
1

Epoch: [155 | 155] LR: 0.138386
batch Size 413
Epoch: [155][0/130]	Time 0.149 (0.149)	Data 0.334 (0.334)	Loss 0.6148 (0.6148)	Acc@1 85.788 (85.788)	Acc@5 99.225 (99.225)
Epoch: [155][64/130]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.5909 (0.6508)	Acc@1 86.305 (84.043)	Acc@5 100.000 (99.384)
Epoch: [155][128/130]	Time 0.122 (0.122)	Data 0.000 (0.003)	Loss 0.6875 (0.6601)	Acc@1 84.755 (83.743)	Acc@5 99.742 (99.269)
Max memory in training epoch: 62.708736
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 173834 ; 176360 ; 0.9856770242685416
[INFO] Storing checkpoint...
  73.82
Max memory: 65.778176
 16.231s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4463
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0765952
lr: 0.22325559212618887
1

Epoch: [156 | 160] LR: 0.223256
batch Size 413
Epoch: [156][0/122]	Time 0.198 (0.198)	Data 0.341 (0.341)	Loss 0.5927 (0.5927)	Acc@1 85.956 (85.956)	Acc@5 99.516 (99.516)
Epoch: [156][64/122]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.7035 (0.6981)	Acc@1 82.082 (82.757)	Acc@5 99.031 (99.177)
Max memory in training epoch: 67.2568832
lr: 0.22325559212618887
1

Epoch: [157 | 160] LR: 0.223256
batch Size 413
Epoch: [157][0/122]	Time 0.160 (0.160)	Data 0.368 (0.368)	Loss 0.8719 (0.8719)	Acc@1 74.092 (74.092)	Acc@5 98.305 (98.305)
Epoch: [157][64/122]	Time 0.124 (0.123)	Data 0.000 (0.006)	Loss 0.7653 (0.8094)	Acc@1 81.840 (79.762)	Acc@5 99.274 (98.842)
Max memory in training epoch: 67.2568832
lr: 0.22325559212618887
1

Epoch: [158 | 160] LR: 0.223256
batch Size 413
Epoch: [158][0/122]	Time 0.185 (0.185)	Data 0.364 (0.364)	Loss 0.7663 (0.7663)	Acc@1 80.145 (80.145)	Acc@5 99.031 (99.031)
Epoch: [158][64/122]	Time 0.122 (0.124)	Data 0.000 (0.006)	Loss 0.7955 (0.7620)	Acc@1 81.840 (81.356)	Acc@5 98.547 (98.991)
Max memory in training epoch: 67.2568832
Drin!!
old memory: 627087360
new memory: 672568832
Faktor: 1.072528127500449
New batch Size kleiner 442!!
lr: 0.22325559212618887
1

Epoch: [159 | 160] LR: 0.223256
batch Size 442
Epoch: [159][0/122]	Time 0.185 (0.185)	Data 0.353 (0.353)	Loss 0.6774 (0.6774)	Acc@1 84.988 (84.988)	Acc@5 98.789 (98.789)
Epoch: [159][64/122]	Time 0.118 (0.124)	Data 0.000 (0.006)	Loss 0.7407 (0.7722)	Acc@1 83.051 (80.842)	Acc@5 99.274 (99.031)
Max memory in training epoch: 67.2568832
lr: 0.22325559212618887
1

Epoch: [160 | 160] LR: 0.223256
batch Size 442
Epoch: [160][0/122]	Time 0.176 (0.176)	Data 0.342 (0.342)	Loss 0.7368 (0.7368)	Acc@1 83.051 (83.051)	Acc@5 97.821 (97.821)
Epoch: [160][64/122]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.7581 (0.7705)	Acc@1 81.598 (81.050)	Acc@5 99.031 (98.972)
Max memory in training epoch: 67.2568832
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv17.weight

 RM:  module.conv18.weight
numoFStages: 3
Count: 168457 ; 173834 ; 0.9690681914930336
[INFO] Storing checkpoint...
  75.52
Max memory: 67.2568832
 15.296s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 147
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.0738304
lr: 0.38546473328037295
1

Epoch: [161 | 165] LR: 0.385465
batch Size 442
Epoch: [161][0/114]	Time 0.191 (0.191)	Data 0.347 (0.347)	Loss 0.7471 (0.7471)	Acc@1 81.674 (81.674)	Acc@5 99.321 (99.321)
Epoch: [161][64/114]	Time 0.123 (0.123)	Data 0.000 (0.006)	Loss 0.8819 (0.7965)	Acc@1 77.828 (79.892)	Acc@5 98.643 (98.977)
Max memory in training epoch: 68.5830144
lr: 0.38546473328037295
1

Epoch: [162 | 165] LR: 0.385465
batch Size 442
Epoch: [162][0/114]	Time 0.151 (0.151)	Data 0.309 (0.309)	Loss 0.8983 (0.8983)	Acc@1 77.376 (77.376)	Acc@5 98.643 (98.643)
Epoch: [162][64/114]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.8102 (0.8651)	Acc@1 76.471 (79.039)	Acc@5 99.774 (98.723)
Max memory in training epoch: 68.493312
lr: 0.38546473328037295
1

Epoch: [163 | 165] LR: 0.385465
batch Size 442
Epoch: [163][0/114]	Time 0.175 (0.175)	Data 0.385 (0.385)	Loss 0.9306 (0.9306)	Acc@1 76.697 (76.697)	Acc@5 98.869 (98.869)
Epoch: [163][64/114]	Time 0.116 (0.121)	Data 0.000 (0.006)	Loss 0.8181 (0.8369)	Acc@1 80.090 (79.638)	Acc@5 99.095 (98.931)
Max memory in training epoch: 68.493312
Drin!!
old memory: 672568832
new memory: 684933120
Faktor: 1.0183836767505754
New batch Size kleiner 450!!
lr: 0.38546473328037295
1

Epoch: [164 | 165] LR: 0.385465
batch Size 450
Epoch: [164][0/114]	Time 0.164 (0.164)	Data 0.358 (0.358)	Loss 0.9206 (0.9206)	Acc@1 76.018 (76.018)	Acc@5 97.964 (97.964)
Epoch: [164][64/114]	Time 0.121 (0.123)	Data 0.000 (0.006)	Loss 0.8128 (0.8520)	Acc@1 79.186 (79.011)	Acc@5 98.416 (98.792)
Max memory in training epoch: 68.493312
lr: 0.38546473328037295
1

Epoch: [165 | 165] LR: 0.385465
batch Size 450
Epoch: [165][0/114]	Time 0.182 (0.182)	Data 0.317 (0.317)	Loss 0.7384 (0.7384)	Acc@1 84.163 (84.163)	Acc@5 98.416 (98.416)
Epoch: [165][64/114]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.8058 (0.8246)	Acc@1 79.864 (80.010)	Acc@5 98.416 (98.900)
Max memory in training epoch: 68.493312
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 166624 ; 168457 ; 0.989118884937996
[INFO] Storing checkpoint...
  53.35
Max memory: 68.493312
 14.297s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6285
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0731648
lr: 0.6775747264694055
1

Epoch: [166 | 170] LR: 0.677575
batch Size 450
Epoch: [166][0/112]	Time 0.172 (0.172)	Data 0.359 (0.359)	Loss 0.8251 (0.8251)	Acc@1 81.556 (81.556)	Acc@5 99.778 (99.778)
Epoch: [166][64/112]	Time 0.115 (0.120)	Data 0.000 (0.006)	Loss 0.9802 (0.9387)	Acc@1 77.111 (76.766)	Acc@5 98.889 (98.462)
Max memory in training epoch: 68.9222144
lr: 0.6775747264694055
1

Epoch: [167 | 170] LR: 0.677575
batch Size 450
Epoch: [167][0/112]	Time 0.182 (0.182)	Data 0.355 (0.355)	Loss 0.9561 (0.9561)	Acc@1 77.778 (77.778)	Acc@5 97.778 (97.778)
Epoch: [167][64/112]	Time 0.120 (0.122)	Data 0.000 (0.006)	Loss 0.9668 (0.9738)	Acc@1 75.556 (76.154)	Acc@5 97.333 (98.304)
Max memory in training epoch: 68.9222144
lr: 0.6775747264694055
1

Epoch: [168 | 170] LR: 0.677575
batch Size 450
Epoch: [168][0/112]	Time 0.153 (0.153)	Data 0.310 (0.310)	Loss 1.0014 (1.0014)	Acc@1 73.556 (73.556)	Acc@5 98.667 (98.667)
Epoch: [168][64/112]	Time 0.125 (0.121)	Data 0.000 (0.005)	Loss 0.9511 (1.0112)	Acc@1 76.000 (75.043)	Acc@5 99.111 (98.263)
Max memory in training epoch: 68.9222144
Drin!!
old memory: 684933120
new memory: 689222144
Faktor: 1.006261960291831
New batch Size kleiner 452!!
lr: 0.6775747264694055
1

Epoch: [169 | 170] LR: 0.677575
batch Size 452
Epoch: [169][0/112]	Time 0.179 (0.179)	Data 0.329 (0.329)	Loss 0.9763 (0.9763)	Acc@1 74.222 (74.222)	Acc@5 99.111 (99.111)
Epoch: [169][64/112]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.9096 (0.9909)	Acc@1 78.222 (75.726)	Acc@5 98.889 (98.263)
Max memory in training epoch: 68.9222144
lr: 0.6775747264694055
1

Epoch: [170 | 170] LR: 0.677575
batch Size 452
Epoch: [170][0/112]	Time 0.146 (0.146)	Data 0.334 (0.334)	Loss 0.9710 (0.9710)	Acc@1 73.556 (73.556)	Acc@5 97.556 (97.556)
Epoch: [170][64/112]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.9560 (0.9951)	Acc@1 76.444 (75.132)	Acc@5 98.444 (98.195)
Max memory in training epoch: 68.9222144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 164521 ; 166624 ; 0.987378768964855
[INFO] Storing checkpoint...
  35.36
Max memory: 68.9222144
 13.754s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 610
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.0723456
lr: 1.196342876422544
1

Epoch: [171 | 175] LR: 1.196343
batch Size 452
Epoch: [171][0/111]	Time 0.180 (0.180)	Data 0.368 (0.368)	Loss 1.0310 (1.0310)	Acc@1 75.885 (75.885)	Acc@5 97.345 (97.345)
Epoch: [171][64/111]	Time 0.139 (0.121)	Data 0.000 (0.006)	Loss 1.0833 (1.1150)	Acc@1 73.894 (71.957)	Acc@5 98.451 (97.777)
Max memory in training epoch: 68.8710144
lr: 1.196342876422544
1

Epoch: [172 | 175] LR: 1.196343
batch Size 452
Epoch: [172][0/111]	Time 0.163 (0.163)	Data 0.325 (0.325)	Loss 1.1588 (1.1588)	Acc@1 73.673 (73.673)	Acc@5 97.788 (97.788)
Epoch: [172][64/111]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 1.0218 (1.1377)	Acc@1 73.451 (71.590)	Acc@5 98.673 (97.682)
Max memory in training epoch: 68.8710144
lr: 1.196342876422544
1

Epoch: [173 | 175] LR: 1.196343
batch Size 452
Epoch: [173][0/111]	Time 0.176 (0.176)	Data 0.371 (0.371)	Loss 1.0541 (1.0541)	Acc@1 74.336 (74.336)	Acc@5 98.673 (98.673)
Epoch: [173][64/111]	Time 0.117 (0.120)	Data 0.000 (0.006)	Loss 1.1610 (1.1311)	Acc@1 70.796 (71.504)	Acc@5 98.009 (97.764)
Max memory in training epoch: 68.8710144
Drin!!
old memory: 689222144
new memory: 688710144
Faktor: 0.9992571335607
New batch Size größer 439!!
lr: 1.196342876422544
1

Epoch: [174 | 175] LR: 1.196343
batch Size 439
Epoch: [174][0/111]	Time 0.149 (0.149)	Data 0.404 (0.404)	Loss 1.0172 (1.0172)	Acc@1 76.106 (76.106)	Acc@5 98.009 (98.009)
Epoch: [174][64/111]	Time 0.113 (0.120)	Data 0.000 (0.006)	Loss 1.1425 (1.0991)	Acc@1 71.903 (72.274)	Acc@5 97.566 (97.747)
Max memory in training epoch: 68.8710144
lr: 1.196342876422544
1

Epoch: [175 | 175] LR: 1.196343
batch Size 439
Epoch: [175][0/111]	Time 0.176 (0.176)	Data 0.331 (0.331)	Loss 1.0276 (1.0276)	Acc@1 74.336 (74.336)	Acc@5 99.115 (99.115)
Epoch: [175][64/111]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 1.0324 (1.1322)	Acc@1 74.336 (71.171)	Acc@5 98.230 (97.675)
Max memory in training epoch: 68.8710144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 157242 ; 164521 ; 0.9557564079965476
[INFO] Storing checkpoint...
  42.17
Max memory: 68.8710144
 13.872s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3145
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.0694784
lr: 2.051541104490222
1

Epoch: [176 | 180] LR: 2.051541
batch Size 439
Epoch: [176][0/114]	Time 0.217 (0.217)	Data 0.305 (0.305)	Loss 1.0243 (1.0243)	Acc@1 73.349 (73.349)	Acc@5 98.633 (98.633)
Epoch: [176][64/114]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 1.4252 (1.3323)	Acc@1 63.098 (65.446)	Acc@5 95.216 (96.331)
Max memory in training epoch: 67.1109632
lr: 2.051541104490222
1

Epoch: [177 | 180] LR: 2.051541
batch Size 439
Epoch: [177][0/114]	Time 0.181 (0.181)	Data 0.340 (0.340)	Loss 1.3660 (1.3660)	Acc@1 63.781 (63.781)	Acc@5 96.355 (96.355)
Epoch: [177][64/114]	Time 0.128 (0.123)	Data 0.000 (0.005)	Loss 1.2273 (1.3220)	Acc@1 69.021 (65.695)	Acc@5 97.494 (96.569)
Max memory in training epoch: 66.9417472
lr: 2.051541104490222
1

Epoch: [178 | 180] LR: 2.051541
batch Size 439
Epoch: [178][0/114]	Time 0.158 (0.158)	Data 0.305 (0.305)	Loss 1.4137 (1.4137)	Acc@1 61.276 (61.276)	Acc@5 97.494 (97.494)
Epoch: [178][64/114]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 1.3239 (1.3103)	Acc@1 64.009 (65.449)	Acc@5 97.267 (96.429)
Max memory in training epoch: 66.9417472
Drin!!
old memory: 688710144
new memory: 669417472
Faktor: 0.9719872399614314
New batch Size größer 439!!
lr: 2.051541104490222
1

Epoch: [179 | 180] LR: 2.051541
batch Size 439
Epoch: [179][0/114]	Time 0.169 (0.169)	Data 0.357 (0.357)	Loss 1.2650 (1.2650)	Acc@1 64.692 (64.692)	Acc@5 97.494 (97.494)
Epoch: [179][64/114]	Time 0.131 (0.120)	Data 0.000 (0.006)	Loss 1.2946 (1.3124)	Acc@1 67.198 (64.714)	Acc@5 96.583 (96.517)
Max memory in training epoch: 66.9417472
lr: 2.051541104490222
1

Epoch: [180 | 180] LR: 2.051541
batch Size 439
Epoch: [180][0/114]	Time 0.184 (0.184)	Data 0.343 (0.343)	Loss 1.2354 (1.2354)	Acc@1 67.198 (67.198)	Acc@5 97.039 (97.039)
Epoch: [180][64/114]	Time 0.112 (0.121)	Data 0.000 (0.005)	Loss 1.4022 (1.3263)	Acc@1 64.237 (64.507)	Acc@5 96.355 (96.303)
Max memory in training epoch: 66.9417472
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(12, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(31, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(13, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(31, 46, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(46, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(31, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(62, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(31, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(62, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(1, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(62, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(35, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): AdaptiveAvgPool2d(output_size=(1, 1))
    (51): Linear(in_features=62, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  27.36
Max memory: 66.9417472
 14.095s  BSize 4
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 791
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
batch_size berechnet: 250;389.1 ; lr: 0.1
lr: 0.09765625
1

Epoch: [1 | 5] LR: 0.097656
batch Size 250
Epoch: [1][0/200]	Time 0.215 (0.215)	Data 0.263 (0.263)	Loss 3.2088 (3.2088)	Acc@1 12.800 (12.800)	Acc@5 49.600 (49.600)
Epoch: [1][64/200]	Time 0.122 (0.130)	Data 0.000 (0.004)	Loss 2.4331 (2.6696)	Acc@1 33.600 (24.234)	Acc@5 86.400 (77.932)
Epoch: [1][128/200]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 2.2246 (2.4963)	Acc@1 38.800 (29.464)	Acc@5 89.200 (82.691)
Epoch: [1][192/200]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 2.0930 (2.3791)	Acc@1 46.000 (33.405)	Acc@5 91.200 (85.563)
Max memory in training epoch: 66.4657408
lr: 0.09765625
1

Epoch: [2 | 5] LR: 0.097656
batch Size 250
Epoch: [2][0/200]	Time 0.172 (0.172)	Data 0.282 (0.282)	Loss 2.0518 (2.0518)	Acc@1 47.200 (47.200)	Acc@5 92.000 (92.000)
Epoch: [2][64/200]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 1.8137 (1.9597)	Acc@1 54.000 (48.443)	Acc@5 94.000 (93.206)
Epoch: [2][128/200]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 1.7111 (1.8736)	Acc@1 58.400 (51.429)	Acc@5 96.800 (93.888)
Epoch: [2][192/200]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 1.5737 (1.8023)	Acc@1 62.800 (53.865)	Acc@5 96.000 (94.535)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [3 | 5] LR: 0.097656
batch Size 250
Epoch: [3][0/200]	Time 0.190 (0.190)	Data 0.280 (0.280)	Loss 1.6173 (1.6173)	Acc@1 61.200 (61.200)	Acc@5 96.400 (96.400)
Epoch: [3][64/200]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 1.5030 (1.5543)	Acc@1 63.200 (61.982)	Acc@5 97.600 (96.418)
Epoch: [3][128/200]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 1.5503 (1.5149)	Acc@1 64.000 (63.172)	Acc@5 94.400 (96.657)
Epoch: [3][192/200]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 1.2710 (1.4785)	Acc@1 69.200 (64.184)	Acc@5 97.200 (96.827)
Max memory in training epoch: 66.0135424
Drin!!
old memory: 0
new memory: 660135424
lr: 0.09765625
1

Epoch: [4 | 5] LR: 0.097656
batch Size 250
Epoch: [4][0/200]	Time 0.168 (0.168)	Data 0.306 (0.306)	Loss 1.3491 (1.3491)	Acc@1 70.400 (70.400)	Acc@5 96.000 (96.000)
Epoch: [4][64/200]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 1.1812 (1.3172)	Acc@1 74.400 (69.052)	Acc@5 98.800 (97.471)
Epoch: [4][128/200]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 1.4318 (1.2832)	Acc@1 64.800 (70.195)	Acc@5 95.600 (97.733)
Epoch: [4][192/200]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 1.1835 (1.2579)	Acc@1 74.400 (70.864)	Acc@5 99.200 (97.896)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [5 | 5] LR: 0.097656
batch Size 250
Epoch: [5][0/200]	Time 0.153 (0.153)	Data 0.261 (0.261)	Loss 1.1186 (1.1186)	Acc@1 75.200 (75.200)	Acc@5 98.800 (98.800)
Epoch: [5][64/200]	Time 0.124 (0.131)	Data 0.000 (0.004)	Loss 1.2917 (1.1357)	Acc@1 70.800 (74.455)	Acc@5 97.200 (98.338)
Epoch: [5][128/200]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 1.0470 (1.1217)	Acc@1 77.600 (74.930)	Acc@5 99.200 (98.347)
Epoch: [5][192/200]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 1.0532 (1.1118)	Acc@1 76.800 (75.016)	Acc@5 98.400 (98.365)
Max memory in training epoch: 66.0135424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  64.09
Max memory: 103.3835008
 26.097s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9342
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.095367431640625
1

Epoch: [6 | 10] LR: 0.095367
batch Size 250
Epoch: [6][0/200]	Time 0.205 (0.205)	Data 0.301 (0.301)	Loss 1.1045 (1.1045)	Acc@1 74.000 (74.000)	Acc@5 98.000 (98.000)
Epoch: [6][64/200]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.9829 (1.0065)	Acc@1 78.000 (77.994)	Acc@5 98.400 (98.702)
Epoch: [6][128/200]	Time 0.123 (0.129)	Data 0.000 (0.003)	Loss 1.0595 (1.0145)	Acc@1 73.600 (77.557)	Acc@5 98.000 (98.626)
Epoch: [6][192/200]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 1.1898 (1.0091)	Acc@1 69.600 (77.689)	Acc@5 97.200 (98.647)
Max memory in training epoch: 66.4656384
lr: 0.095367431640625
1

Epoch: [7 | 10] LR: 0.095367
batch Size 250
Epoch: [7][0/200]	Time 0.187 (0.187)	Data 0.301 (0.301)	Loss 0.9535 (0.9535)	Acc@1 80.400 (80.400)	Acc@5 97.600 (97.600)
Epoch: [7][64/200]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 1.0317 (0.9640)	Acc@1 77.200 (78.474)	Acc@5 98.000 (98.812)
Epoch: [7][128/200]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.9568 (0.9579)	Acc@1 76.400 (78.729)	Acc@5 99.600 (98.806)
Epoch: [7][192/200]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.9586 (0.9491)	Acc@1 78.000 (78.870)	Acc@5 98.000 (98.841)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [8 | 10] LR: 0.095367
batch Size 250
Epoch: [8][0/200]	Time 0.183 (0.183)	Data 0.320 (0.320)	Loss 0.8328 (0.8328)	Acc@1 80.800 (80.800)	Acc@5 100.000 (100.000)
Epoch: [8][64/200]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.8818 (0.9049)	Acc@1 82.000 (80.000)	Acc@5 98.000 (98.874)
Epoch: [8][128/200]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.9214 (0.8995)	Acc@1 77.200 (80.189)	Acc@5 98.800 (98.986)
Epoch: [8][192/200]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.8966 (0.8980)	Acc@1 81.600 (80.187)	Acc@5 98.400 (98.945)
Max memory in training epoch: 66.01344
Drin!!
old memory: 660135424
new memory: 660134400
Faktor: 0.9999984488031353
New batch Size größer 253!!
lr: 0.095367431640625
1

Epoch: [9 | 10] LR: 0.095367
batch Size 253
Epoch: [9][0/200]	Time 0.195 (0.195)	Data 0.287 (0.287)	Loss 0.7885 (0.7885)	Acc@1 82.400 (82.400)	Acc@5 99.200 (99.200)
Epoch: [9][64/200]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8744 (0.8548)	Acc@1 80.400 (81.218)	Acc@5 98.000 (99.083)
Epoch: [9][128/200]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.8593 (0.8597)	Acc@1 81.600 (81.184)	Acc@5 98.000 (99.008)
Epoch: [9][192/200]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.9095 (0.8628)	Acc@1 78.000 (80.922)	Acc@5 98.800 (98.974)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [10 | 10] LR: 0.095367
batch Size 253
Epoch: [10][0/200]	Time 0.183 (0.183)	Data 0.291 (0.291)	Loss 0.8576 (0.8576)	Acc@1 83.600 (83.600)	Acc@5 97.600 (97.600)
Epoch: [10][64/200]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.8486 (0.8246)	Acc@1 83.200 (82.000)	Acc@5 98.800 (99.034)
Epoch: [10][128/200]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7861 (0.8295)	Acc@1 84.000 (81.758)	Acc@5 98.800 (99.054)
Epoch: [10][192/200]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7601 (0.8355)	Acc@1 83.600 (81.432)	Acc@5 99.200 (99.049)
Max memory in training epoch: 66.01344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  78.65
Max memory: 103.3833984
 26.243s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7093
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.09424984455108643
1

Epoch: [11 | 15] LR: 0.094250
batch Size 253
Epoch: [11][0/198]	Time 0.192 (0.192)	Data 0.291 (0.291)	Loss 0.8017 (0.8017)	Acc@1 81.028 (81.028)	Acc@5 99.209 (99.209)
Epoch: [11][64/198]	Time 0.128 (0.134)	Data 0.000 (0.005)	Loss 0.7919 (0.7922)	Acc@1 82.609 (82.803)	Acc@5 100.000 (99.209)
Epoch: [11][128/198]	Time 0.123 (0.132)	Data 0.000 (0.002)	Loss 0.8107 (0.8095)	Acc@1 80.632 (82.223)	Acc@5 98.814 (99.200)
Epoch: [11][192/198]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.8025 (0.8088)	Acc@1 83.004 (82.304)	Acc@5 100.000 (99.191)
Max memory in training epoch: 66.5037312
lr: 0.09424984455108643
1

Epoch: [12 | 15] LR: 0.094250
batch Size 253
Epoch: [12][0/198]	Time 0.158 (0.158)	Data 0.280 (0.280)	Loss 0.7015 (0.7015)	Acc@1 86.561 (86.561)	Acc@5 99.605 (99.605)
Epoch: [12][64/198]	Time 0.137 (0.134)	Data 0.000 (0.005)	Loss 0.8215 (0.7777)	Acc@1 84.585 (83.247)	Acc@5 99.605 (99.222)
Epoch: [12][128/198]	Time 0.143 (0.135)	Data 0.000 (0.002)	Loss 0.7680 (0.7903)	Acc@1 82.213 (82.832)	Acc@5 98.814 (99.157)
Epoch: [12][192/198]	Time 0.127 (0.134)	Data 0.000 (0.002)	Loss 0.7984 (0.7968)	Acc@1 82.609 (82.605)	Acc@5 99.605 (99.113)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [13 | 15] LR: 0.094250
batch Size 253
Epoch: [13][0/198]	Time 0.162 (0.162)	Data 0.272 (0.272)	Loss 0.8759 (0.8759)	Acc@1 78.656 (78.656)	Acc@5 98.814 (98.814)
Epoch: [13][64/198]	Time 0.134 (0.132)	Data 0.000 (0.004)	Loss 0.7052 (0.7869)	Acc@1 84.190 (82.700)	Acc@5 99.209 (99.246)
Epoch: [13][128/198]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8103 (0.7911)	Acc@1 82.213 (82.550)	Acc@5 98.814 (99.179)
Epoch: [13][192/198]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8283 (0.7915)	Acc@1 83.399 (82.586)	Acc@5 98.814 (99.183)
Max memory in training epoch: 66.277632
Drin!!
old memory: 660134400
new memory: 662776320
Faktor: 1.0040020941190158
New batch Size kleiner 254!!
lr: 0.09424984455108643
1

Epoch: [14 | 15] LR: 0.094250
batch Size 254
Epoch: [14][0/198]	Time 0.188 (0.188)	Data 0.279 (0.279)	Loss 0.7187 (0.7187)	Acc@1 85.375 (85.375)	Acc@5 99.209 (99.209)
Epoch: [14][64/198]	Time 0.123 (0.133)	Data 0.000 (0.004)	Loss 0.7776 (0.7715)	Acc@1 83.794 (83.290)	Acc@5 98.814 (99.216)
Epoch: [14][128/198]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.8457 (0.7800)	Acc@1 83.004 (82.979)	Acc@5 98.419 (99.182)
Epoch: [14][192/198]	Time 0.136 (0.132)	Data 0.000 (0.002)	Loss 0.7745 (0.7884)	Acc@1 81.818 (82.633)	Acc@5 99.209 (99.162)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [15 | 15] LR: 0.094250
batch Size 254
Epoch: [15][0/198]	Time 0.185 (0.185)	Data 0.269 (0.269)	Loss 0.7720 (0.7720)	Acc@1 84.190 (84.190)	Acc@5 97.628 (97.628)
Epoch: [15][64/198]	Time 0.144 (0.130)	Data 0.000 (0.004)	Loss 0.7429 (0.7659)	Acc@1 83.399 (83.642)	Acc@5 98.814 (99.197)
Epoch: [15][128/198]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7539 (0.7697)	Acc@1 84.190 (83.436)	Acc@5 98.814 (99.151)
Epoch: [15][192/198]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8461 (0.7735)	Acc@1 79.447 (83.223)	Acc@5 99.209 (99.154)
Max memory in training epoch: 66.277632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  62.11
Max memory: 103.3833984
 26.077s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6694
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.09351351764053106
1

Epoch: [16 | 20] LR: 0.093514
batch Size 254
Epoch: [16][0/197]	Time 0.186 (0.186)	Data 0.257 (0.257)	Loss 0.7777 (0.7777)	Acc@1 83.465 (83.465)	Acc@5 98.031 (98.031)
Epoch: [16][64/197]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.6676 (0.7397)	Acc@1 85.827 (84.385)	Acc@5 100.000 (99.303)
Epoch: [16][128/197]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7730 (0.7528)	Acc@1 83.858 (83.788)	Acc@5 97.638 (99.283)
Epoch: [16][192/197]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7675 (0.7584)	Acc@1 82.283 (83.585)	Acc@5 100.000 (99.249)
Max memory in training epoch: 66.5164288
lr: 0.09351351764053106
1

Epoch: [17 | 20] LR: 0.093514
batch Size 254
Epoch: [17][0/197]	Time 0.179 (0.179)	Data 0.293 (0.293)	Loss 0.7224 (0.7224)	Acc@1 84.252 (84.252)	Acc@5 99.213 (99.213)
Epoch: [17][64/197]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.7324 (0.7533)	Acc@1 85.433 (84.185)	Acc@5 99.213 (99.194)
Epoch: [17][128/197]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7904 (0.7506)	Acc@1 82.283 (84.179)	Acc@5 99.213 (99.243)
Epoch: [17][192/197]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7185 (0.7498)	Acc@1 85.039 (84.158)	Acc@5 99.213 (99.219)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [18 | 20] LR: 0.093514
batch Size 254
Epoch: [18][0/197]	Time 0.175 (0.175)	Data 0.266 (0.266)	Loss 0.7185 (0.7185)	Acc@1 83.071 (83.071)	Acc@5 99.213 (99.213)
Epoch: [18][64/197]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.8273 (0.7570)	Acc@1 79.921 (83.834)	Acc@5 98.819 (99.176)
Epoch: [18][128/197]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6880 (0.7570)	Acc@1 85.039 (83.736)	Acc@5 99.213 (99.222)
Epoch: [18][192/197]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7522 (0.7605)	Acc@1 82.677 (83.613)	Acc@5 98.819 (99.200)
Max memory in training epoch: 66.365696
Drin!!
old memory: 662776320
new memory: 663656960
Faktor: 1.0013287137355782
New batch Size kleiner 254!!
lr: 0.09351351764053106
1

Epoch: [19 | 20] LR: 0.093514
batch Size 254
Epoch: [19][0/197]	Time 0.184 (0.184)	Data 0.295 (0.295)	Loss 0.7616 (0.7616)	Acc@1 82.283 (82.283)	Acc@5 99.606 (99.606)
Epoch: [19][64/197]	Time 0.140 (0.133)	Data 0.000 (0.005)	Loss 0.8815 (0.7522)	Acc@1 78.346 (84.143)	Acc@5 99.213 (99.213)
Epoch: [19][128/197]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.8453 (0.7520)	Acc@1 79.921 (83.968)	Acc@5 98.819 (99.203)
Epoch: [19][192/197]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.7756 (0.7539)	Acc@1 82.283 (83.875)	Acc@5 99.606 (99.213)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [20 | 20] LR: 0.093514
batch Size 254
Epoch: [20][0/197]	Time 0.166 (0.166)	Data 0.281 (0.281)	Loss 0.7013 (0.7013)	Acc@1 87.795 (87.795)	Acc@5 99.213 (99.213)
Epoch: [20][64/197]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.6749 (0.7435)	Acc@1 87.008 (84.185)	Acc@5 100.000 (99.364)
Epoch: [20][128/197]	Time 0.136 (0.131)	Data 0.002 (0.002)	Loss 0.7663 (0.7419)	Acc@1 82.677 (84.258)	Acc@5 98.425 (99.332)
Epoch: [20][192/197]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8206 (0.7449)	Acc@1 81.890 (84.125)	Acc@5 99.213 (99.333)
Max memory in training epoch: 66.365696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  80.01
Max memory: 103.3833984
 26.145s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9087
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2020864
lr: 0.09278294328396441
1

Epoch: [21 | 25] LR: 0.092783
batch Size 254
Epoch: [21][0/197]	Time 0.216 (0.216)	Data 0.255 (0.255)	Loss 0.8122 (0.8122)	Acc@1 82.677 (82.677)	Acc@5 98.425 (98.425)
Epoch: [21][64/197]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.6840 (0.6979)	Acc@1 87.795 (85.936)	Acc@5 99.213 (99.491)
Epoch: [21][128/197]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7122 (0.7167)	Acc@1 84.646 (85.207)	Acc@5 99.213 (99.438)
Epoch: [21][192/197]	Time 0.130 (0.129)	Data 0.000 (0.001)	Loss 0.7771 (0.7305)	Acc@1 84.252 (84.750)	Acc@5 98.425 (99.337)
Max memory in training epoch: 66.5147904
lr: 0.09278294328396441
1

Epoch: [22 | 25] LR: 0.092783
batch Size 254
Epoch: [22][0/197]	Time 0.182 (0.182)	Data 0.283 (0.283)	Loss 0.6140 (0.6140)	Acc@1 88.976 (88.976)	Acc@5 100.000 (100.000)
Epoch: [22][64/197]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.6835 (0.7205)	Acc@1 85.827 (85.058)	Acc@5 98.819 (99.340)
Epoch: [22][128/197]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7178 (0.7396)	Acc@1 87.402 (84.374)	Acc@5 99.213 (99.292)
Epoch: [22][192/197]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7845 (0.7370)	Acc@1 80.709 (84.427)	Acc@5 98.819 (99.304)
Max memory in training epoch: 66.3640576
lr: 0.09278294328396441
1

Epoch: [23 | 25] LR: 0.092783
batch Size 254
Epoch: [23][0/197]	Time 0.156 (0.156)	Data 0.299 (0.299)	Loss 0.7271 (0.7271)	Acc@1 83.465 (83.465)	Acc@5 99.213 (99.213)
Epoch: [23][64/197]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.8029 (0.7252)	Acc@1 84.252 (84.500)	Acc@5 98.031 (99.455)
Epoch: [23][128/197]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.5717 (0.7198)	Acc@1 89.370 (84.905)	Acc@5 100.000 (99.396)
Epoch: [23][192/197]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.7281 (0.7257)	Acc@1 82.677 (84.727)	Acc@5 100.000 (99.386)
Max memory in training epoch: 66.3640576
Drin!!
old memory: 663656960
new memory: 663640576
Faktor: 0.9999753125470122
New batch Size größer 256!!
lr: 0.09278294328396441
1

Epoch: [24 | 25] LR: 0.092783
batch Size 256
Epoch: [24][0/197]	Time 0.183 (0.183)	Data 0.309 (0.309)	Loss 0.7320 (0.7320)	Acc@1 82.677 (82.677)	Acc@5 99.213 (99.213)
Epoch: [24][64/197]	Time 0.126 (0.132)	Data 0.000 (0.005)	Loss 0.7833 (0.7253)	Acc@1 82.677 (84.827)	Acc@5 99.213 (99.279)
Epoch: [24][128/197]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.7778 (0.7353)	Acc@1 83.071 (84.402)	Acc@5 98.819 (99.283)
Epoch: [24][192/197]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.6014 (0.7317)	Acc@1 91.339 (84.682)	Acc@5 99.606 (99.308)
Max memory in training epoch: 66.3640576
lr: 0.09278294328396441
1

Epoch: [25 | 25] LR: 0.092783
batch Size 256
Epoch: [25][0/197]	Time 0.165 (0.165)	Data 0.292 (0.292)	Loss 0.6310 (0.6310)	Acc@1 88.583 (88.583)	Acc@5 100.000 (100.000)
Epoch: [25][64/197]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.8062 (0.7221)	Acc@1 81.102 (84.906)	Acc@5 99.606 (99.352)
Epoch: [25][128/197]	Time 0.132 (0.127)	Data 0.000 (0.002)	Loss 0.6890 (0.7210)	Acc@1 85.827 (84.942)	Acc@5 100.000 (99.371)
Epoch: [25][192/197]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6917 (0.7251)	Acc@1 86.220 (84.844)	Acc@5 99.606 (99.343)
Max memory in training epoch: 66.3640576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 478438 ; 486232 ; 0.9839706148505241
[INFO] Storing checkpoint...
  75.78
Max memory: 103.3821696
 25.554s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4941
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1990144
lr: 0.09278294328396441
1

Epoch: [26 | 30] LR: 0.092783
batch Size 256
Epoch: [26][0/196]	Time 0.203 (0.203)	Data 0.291 (0.291)	Loss 0.7613 (0.7613)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.7586 (0.6943)	Acc@1 81.250 (85.974)	Acc@5 100.000 (99.483)
Epoch: [26][128/196]	Time 0.154 (0.128)	Data 0.000 (0.002)	Loss 0.6934 (0.7065)	Acc@1 86.719 (85.653)	Acc@5 100.000 (99.416)
Epoch: [26][192/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.7325 (0.7155)	Acc@1 83.984 (85.181)	Acc@5 99.219 (99.360)
Max memory in training epoch: 66.6327552
lr: 0.09278294328396441
1

Epoch: [27 | 30] LR: 0.092783
batch Size 256
Epoch: [27][0/196]	Time 0.193 (0.193)	Data 0.267 (0.267)	Loss 0.7212 (0.7212)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.122 (0.129)	Data 0.000 (0.004)	Loss 0.6473 (0.7140)	Acc@1 85.547 (85.433)	Acc@5 99.609 (99.297)
Epoch: [27][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.7726 (0.7157)	Acc@1 81.250 (85.135)	Acc@5 98.438 (99.291)
Epoch: [27][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7205 (0.7189)	Acc@1 84.375 (85.160)	Acc@5 99.609 (99.281)
Max memory in training epoch: 66.5278976
lr: 0.09278294328396441
1

Epoch: [28 | 30] LR: 0.092783
batch Size 256
Epoch: [28][0/196]	Time 0.178 (0.178)	Data 0.311 (0.311)	Loss 0.7545 (0.7545)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.123 (0.132)	Data 0.000 (0.005)	Loss 0.6889 (0.7144)	Acc@1 87.500 (85.024)	Acc@5 98.828 (99.255)
Epoch: [28][128/196]	Time 0.127 (0.129)	Data 0.000 (0.003)	Loss 0.6649 (0.7175)	Acc@1 87.891 (85.099)	Acc@5 99.609 (99.297)
Epoch: [28][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7216 (0.7149)	Acc@1 87.891 (85.217)	Acc@5 98.828 (99.306)
Max memory in training epoch: 66.5278976
Drin!!
old memory: 663640576
new memory: 665278976
Faktor: 1.0024688062473142
New batch Size kleiner 256!!
lr: 0.09278294328396441
1

Epoch: [29 | 30] LR: 0.092783
batch Size 256
Epoch: [29][0/196]	Time 0.172 (0.172)	Data 0.297 (0.297)	Loss 0.6786 (0.6786)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.7519 (0.7048)	Acc@1 83.594 (85.511)	Acc@5 100.000 (99.369)
Epoch: [29][128/196]	Time 0.139 (0.129)	Data 0.000 (0.002)	Loss 0.6189 (0.7100)	Acc@1 91.016 (85.511)	Acc@5 98.828 (99.364)
Epoch: [29][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6475 (0.7104)	Acc@1 87.891 (85.545)	Acc@5 99.219 (99.379)
Max memory in training epoch: 66.5278976
lr: 0.09278294328396441
1

Epoch: [30 | 30] LR: 0.092783
batch Size 256
Epoch: [30][0/196]	Time 0.155 (0.155)	Data 0.306 (0.306)	Loss 0.6233 (0.6233)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [30][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6827 (0.7071)	Acc@1 88.281 (85.469)	Acc@5 99.609 (99.453)
Epoch: [30][128/196]	Time 0.123 (0.128)	Data 0.000 (0.003)	Loss 0.6956 (0.7101)	Acc@1 83.984 (85.441)	Acc@5 99.219 (99.403)
Epoch: [30][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.6401 (0.7156)	Acc@1 88.672 (85.322)	Acc@5 98.828 (99.379)
Max memory in training epoch: 66.5278976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 458240 ; 478438 ; 0.957783453655437
[INFO] Storing checkpoint...
  75.15
Max memory: 103.0968832
 25.402s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7490
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1910272
lr: 0.09278294328396441
1

Epoch: [31 | 35] LR: 0.092783
batch Size 256
Epoch: [31][0/196]	Time 0.214 (0.214)	Data 0.286 (0.286)	Loss 0.7472 (0.7472)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.128 (0.133)	Data 0.000 (0.005)	Loss 0.6302 (0.6798)	Acc@1 87.891 (86.268)	Acc@5 100.000 (99.417)
Epoch: [31][128/196]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.6457 (0.6934)	Acc@1 86.719 (85.726)	Acc@5 99.609 (99.382)
Epoch: [31][192/196]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.7209 (0.6998)	Acc@1 85.156 (85.595)	Acc@5 99.219 (99.389)
Max memory in training epoch: 66.0568576
lr: 0.09278294328396441
1

Epoch: [32 | 35] LR: 0.092783
batch Size 256
Epoch: [32][0/196]	Time 0.184 (0.184)	Data 0.341 (0.341)	Loss 0.6506 (0.6506)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.7265 (0.7051)	Acc@1 85.156 (85.541)	Acc@5 99.219 (99.399)
Epoch: [32][128/196]	Time 0.153 (0.131)	Data 0.000 (0.003)	Loss 0.7101 (0.7133)	Acc@1 85.938 (85.235)	Acc@5 99.219 (99.364)
Epoch: [32][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6328 (0.7123)	Acc@1 88.672 (85.286)	Acc@5 99.609 (99.381)
Max memory in training epoch: 66.0568576
lr: 0.09278294328396441
1

Epoch: [33 | 35] LR: 0.092783
batch Size 256
Epoch: [33][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.6789 (0.6789)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.145 (0.131)	Data 0.000 (0.004)	Loss 0.8193 (0.7077)	Acc@1 81.250 (85.661)	Acc@5 100.000 (99.381)
Epoch: [33][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6988 (0.7111)	Acc@1 86.328 (85.423)	Acc@5 98.438 (99.376)
Epoch: [33][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6642 (0.7109)	Acc@1 85.547 (85.379)	Acc@5 98.438 (99.375)
Max memory in training epoch: 66.0568576
Drin!!
old memory: 665278976
new memory: 660568576
Faktor: 0.9929196620216058
New batch Size größer 259!!
lr: 0.09278294328396441
1

Epoch: [34 | 35] LR: 0.092783
batch Size 259
Epoch: [34][0/196]	Time 0.196 (0.196)	Data 0.367 (0.367)	Loss 0.6424 (0.6424)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.129 (0.130)	Data 0.000 (0.006)	Loss 0.6038 (0.6960)	Acc@1 87.891 (86.058)	Acc@5 100.000 (99.345)
Epoch: [34][128/196]	Time 0.130 (0.130)	Data 0.000 (0.003)	Loss 0.7697 (0.6903)	Acc@1 85.156 (86.177)	Acc@5 98.047 (99.391)
Epoch: [34][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7027 (0.6942)	Acc@1 86.719 (85.974)	Acc@5 98.828 (99.373)
Max memory in training epoch: 66.0568576
lr: 0.09278294328396441
1

Epoch: [35 | 35] LR: 0.092783
batch Size 259
Epoch: [35][0/196]	Time 0.172 (0.172)	Data 0.319 (0.319)	Loss 0.7446 (0.7446)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.143 (0.131)	Data 0.000 (0.005)	Loss 0.6856 (0.7023)	Acc@1 85.547 (85.859)	Acc@5 99.219 (99.333)
Epoch: [35][128/196]	Time 0.124 (0.131)	Data 0.000 (0.003)	Loss 0.6942 (0.7010)	Acc@1 86.719 (85.677)	Acc@5 99.609 (99.425)
Epoch: [35][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7769 (0.7021)	Acc@1 82.422 (85.660)	Acc@5 99.609 (99.433)
Max memory in training epoch: 66.0568576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 437456 ; 458240 ; 0.9546438547486034
[INFO] Storing checkpoint...
  76.65
Max memory: 102.550272
 25.855s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7827
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1827328
lr: 0.09387024340057337
1

Epoch: [36 | 40] LR: 0.093870
batch Size 259
Epoch: [36][0/194]	Time 0.188 (0.188)	Data 0.277 (0.277)	Loss 0.6324 (0.6324)	Acc@1 89.575 (89.575)	Acc@5 99.614 (99.614)
Epoch: [36][64/194]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.7412 (0.6618)	Acc@1 82.625 (87.092)	Acc@5 100.000 (99.549)
Epoch: [36][128/194]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7187 (0.6805)	Acc@1 86.100 (86.418)	Acc@5 99.614 (99.539)
Epoch: [36][192/194]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.5811 (0.6863)	Acc@1 89.189 (86.170)	Acc@5 100.000 (99.476)
Max memory in training epoch: 65.9400704
lr: 0.09387024340057337
1

Epoch: [37 | 40] LR: 0.093870
batch Size 259
Epoch: [37][0/194]	Time 0.159 (0.159)	Data 0.271 (0.271)	Loss 0.6921 (0.6921)	Acc@1 84.942 (84.942)	Acc@5 99.228 (99.228)
Epoch: [37][64/194]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.7863 (0.7571)	Acc@1 83.398 (84.116)	Acc@5 100.000 (99.394)
Epoch: [37][128/194]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6855 (0.7278)	Acc@1 84.170 (84.978)	Acc@5 100.000 (99.374)
Epoch: [37][192/194]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6458 (0.7192)	Acc@1 89.575 (85.178)	Acc@5 98.842 (99.422)
Max memory in training epoch: 65.8733056
lr: 0.09387024340057337
1

Epoch: [38 | 40] LR: 0.093870
batch Size 259
Epoch: [38][0/194]	Time 0.186 (0.186)	Data 0.258 (0.258)	Loss 0.7405 (0.7405)	Acc@1 84.942 (84.942)	Acc@5 100.000 (100.000)
Epoch: [38][64/194]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.7368 (0.7806)	Acc@1 84.556 (83.297)	Acc@5 99.614 (99.228)
Epoch: [38][128/194]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6556 (0.7366)	Acc@1 88.031 (84.870)	Acc@5 100.000 (99.365)
Epoch: [38][192/194]	Time 0.129 (0.129)	Data 0.000 (0.001)	Loss 0.6372 (0.7288)	Acc@1 88.031 (85.012)	Acc@5 99.614 (99.352)
Max memory in training epoch: 65.8733056
Drin!!
old memory: 660568576
new memory: 658733056
Faktor: 0.9972213028795364
New batch Size größer 263!!
lr: 0.09387024340057337
1

Epoch: [39 | 40] LR: 0.093870
batch Size 263
Epoch: [39][0/194]	Time 0.161 (0.161)	Data 0.273 (0.273)	Loss 0.8120 (0.8120)	Acc@1 82.625 (82.625)	Acc@5 98.842 (98.842)
Epoch: [39][64/194]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.7673 (0.7997)	Acc@1 83.398 (82.887)	Acc@5 100.000 (99.050)
Epoch: [39][128/194]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7099 (0.7608)	Acc@1 86.100 (83.999)	Acc@5 99.614 (99.225)
Epoch: [39][192/194]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6390 (0.7436)	Acc@1 86.486 (84.622)	Acc@5 99.614 (99.306)
Max memory in training epoch: 65.8733056
lr: 0.09387024340057337
1

Epoch: [40 | 40] LR: 0.093870
batch Size 263
Epoch: [40][0/194]	Time 0.169 (0.169)	Data 0.291 (0.291)	Loss 0.7421 (0.7421)	Acc@1 81.853 (81.853)	Acc@5 98.842 (98.842)
Epoch: [40][64/194]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.7027 (0.7124)	Acc@1 88.031 (85.661)	Acc@5 99.614 (99.430)
Epoch: [40][128/194]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6694 (0.7052)	Acc@1 86.100 (85.810)	Acc@5 99.614 (99.440)
Epoch: [40][192/194]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6780 (0.7014)	Acc@1 88.031 (85.960)	Acc@5 99.614 (99.424)
Max memory in training epoch: 65.8733056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 424320 ; 437456 ; 0.9699718371676237
[INFO] Storing checkpoint...
  74.13
Max memory: 100.5609472
 25.277s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3442
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1775616
lr: 0.0964370078685578
1

Epoch: [41 | 45] LR: 0.096437
batch Size 263
Epoch: [41][0/191]	Time 0.225 (0.225)	Data 0.282 (0.282)	Loss 0.7547 (0.7547)	Acc@1 82.129 (82.129)	Acc@5 99.240 (99.240)
Epoch: [41][64/191]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6594 (0.6441)	Acc@1 88.973 (87.874)	Acc@5 99.240 (99.555)
Epoch: [41][128/191]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7334 (0.6676)	Acc@1 82.510 (86.951)	Acc@5 99.240 (99.461)
Max memory in training epoch: 66.1326336
lr: 0.0964370078685578
1

Epoch: [42 | 45] LR: 0.096437
batch Size 263
Epoch: [42][0/191]	Time 0.167 (0.167)	Data 0.304 (0.304)	Loss 0.7683 (0.7683)	Acc@1 81.749 (81.749)	Acc@5 99.620 (99.620)
Epoch: [42][64/191]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.7009 (0.6878)	Acc@1 84.030 (85.908)	Acc@5 99.620 (99.438)
Epoch: [42][128/191]	Time 0.131 (0.130)	Data 0.000 (0.003)	Loss 0.8087 (0.6934)	Acc@1 79.848 (85.761)	Acc@5 99.620 (99.440)
Max memory in training epoch: 66.0014592
lr: 0.0964370078685578
1

Epoch: [43 | 45] LR: 0.096437
batch Size 263
Epoch: [43][0/191]	Time 0.176 (0.176)	Data 0.293 (0.293)	Loss 0.6978 (0.6978)	Acc@1 84.411 (84.411)	Acc@5 99.620 (99.620)
Epoch: [43][64/191]	Time 0.134 (0.135)	Data 0.000 (0.005)	Loss 0.6676 (0.7165)	Acc@1 87.072 (85.183)	Acc@5 99.620 (99.380)
Epoch: [43][128/191]	Time 0.133 (0.135)	Data 0.000 (0.002)	Loss 0.6404 (0.7005)	Acc@1 86.692 (85.722)	Acc@5 100.000 (99.437)
Max memory in training epoch: 66.0014592
Drin!!
old memory: 658733056
new memory: 660014592
Faktor: 1.0019454557325267
New batch Size kleiner 263!!
lr: 0.0964370078685578
1

Epoch: [44 | 45] LR: 0.096437
batch Size 263
Epoch: [44][0/191]	Time 0.186 (0.186)	Data 0.263 (0.263)	Loss 0.6169 (0.6169)	Acc@1 89.734 (89.734)	Acc@5 100.000 (100.000)
Epoch: [44][64/191]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.7241 (0.6885)	Acc@1 84.411 (86.002)	Acc@5 98.859 (99.509)
Epoch: [44][128/191]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6625 (0.6863)	Acc@1 87.452 (86.161)	Acc@5 98.859 (99.481)
Max memory in training epoch: 66.0014592
lr: 0.0964370078685578
1

Epoch: [45 | 45] LR: 0.096437
batch Size 263
Epoch: [45][0/191]	Time 0.189 (0.189)	Data 0.283 (0.283)	Loss 0.6712 (0.6712)	Acc@1 82.890 (82.890)	Acc@5 100.000 (100.000)
Epoch: [45][64/191]	Time 0.154 (0.130)	Data 0.000 (0.005)	Loss 0.6918 (0.7035)	Acc@1 86.312 (85.417)	Acc@5 99.240 (99.386)
Epoch: [45][128/191]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7132 (0.6844)	Acc@1 85.932 (86.200)	Acc@5 98.859 (99.413)
Max memory in training epoch: 66.0014592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 409884 ; 424320 ; 0.9659785067873303
[INFO] Storing checkpoint...
  75.78
Max memory: 99.2384
 24.941s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4307
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1717248
lr: 0.09907395730246368
1

Epoch: [46 | 50] LR: 0.099074
batch Size 263
Epoch: [46][0/191]	Time 0.203 (0.203)	Data 0.259 (0.259)	Loss 0.7606 (0.7606)	Acc@1 82.510 (82.510)	Acc@5 99.620 (99.620)
Epoch: [46][64/191]	Time 0.126 (0.132)	Data 0.000 (0.004)	Loss 0.7117 (0.6581)	Acc@1 85.551 (87.031)	Acc@5 98.859 (99.479)
Epoch: [46][128/191]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6658 (0.6688)	Acc@1 85.551 (86.483)	Acc@5 99.240 (99.525)
Max memory in training epoch: 65.4327296
lr: 0.09907395730246368
1

Epoch: [47 | 50] LR: 0.099074
batch Size 263
Epoch: [47][0/191]	Time 0.157 (0.157)	Data 0.276 (0.276)	Loss 0.7037 (0.7037)	Acc@1 87.452 (87.452)	Acc@5 98.859 (98.859)
Epoch: [47][64/191]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.7130 (0.7110)	Acc@1 84.030 (85.428)	Acc@5 98.859 (99.362)
Epoch: [47][128/191]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.6151 (0.7010)	Acc@1 87.833 (85.604)	Acc@5 99.620 (99.449)
Max memory in training epoch: 65.352448
lr: 0.09907395730246368
1

Epoch: [48 | 50] LR: 0.099074
batch Size 263
Epoch: [48][0/191]	Time 0.188 (0.188)	Data 0.263 (0.263)	Loss 0.7190 (0.7190)	Acc@1 87.452 (87.452)	Acc@5 99.620 (99.620)
Epoch: [48][64/191]	Time 0.129 (0.133)	Data 0.000 (0.004)	Loss 0.7269 (0.7454)	Acc@1 84.411 (84.463)	Acc@5 99.240 (99.263)
Epoch: [48][128/191]	Time 0.140 (0.132)	Data 0.000 (0.002)	Loss 0.6702 (0.7116)	Acc@1 88.593 (85.498)	Acc@5 99.240 (99.393)
Max memory in training epoch: 65.352448
Drin!!
old memory: 660014592
new memory: 653524480
Faktor: 0.9901667143747028
New batch Size größer 269!!
lr: 0.09907395730246368
1

Epoch: [49 | 50] LR: 0.099074
batch Size 269
Epoch: [49][0/191]	Time 0.183 (0.183)	Data 0.286 (0.286)	Loss 0.6947 (0.6947)	Acc@1 84.791 (84.791)	Acc@5 100.000 (100.000)
Epoch: [49][64/191]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.7378 (0.7351)	Acc@1 87.833 (84.615)	Acc@5 99.620 (99.263)
Epoch: [49][128/191]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.6877 (0.7065)	Acc@1 86.312 (85.516)	Acc@5 100.000 (99.387)
Max memory in training epoch: 65.352448
lr: 0.09907395730246368
1

Epoch: [50 | 50] LR: 0.099074
batch Size 269
Epoch: [50][0/191]	Time 0.185 (0.185)	Data 0.302 (0.302)	Loss 0.6844 (0.6844)	Acc@1 85.171 (85.171)	Acc@5 99.620 (99.620)
Epoch: [50][64/191]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.6589 (0.7295)	Acc@1 87.072 (84.890)	Acc@5 99.620 (99.380)
Epoch: [50][128/191]	Time 0.125 (0.130)	Data 0.000 (0.003)	Loss 0.6593 (0.7079)	Acc@1 87.452 (85.525)	Acc@5 99.620 (99.399)
Max memory in training epoch: 65.352448
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 400066 ; 409884 ; 0.9760468815567331
[INFO] Storing checkpoint...
  71.45
Max memory: 98.515968
 25.107s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7939
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.167936
lr: 0.10410505669672941
1

Epoch: [51 | 55] LR: 0.104105
batch Size 269
Epoch: [51][0/186]	Time 0.189 (0.189)	Data 0.262 (0.262)	Loss 0.7483 (0.7483)	Acc@1 82.900 (82.900)	Acc@5 98.885 (98.885)
Epoch: [51][64/186]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.6971 (0.6609)	Acc@1 85.502 (86.915)	Acc@5 99.628 (99.565)
Epoch: [51][128/186]	Time 0.139 (0.132)	Data 0.000 (0.002)	Loss 0.6167 (0.6759)	Acc@1 88.848 (86.528)	Acc@5 100.000 (99.467)
Max memory in training epoch: 66.1841408
lr: 0.10410505669672941
1

Epoch: [52 | 55] LR: 0.104105
batch Size 269
Epoch: [52][0/186]	Time 0.177 (0.177)	Data 0.294 (0.294)	Loss 0.6491 (0.6491)	Acc@1 86.617 (86.617)	Acc@5 100.000 (100.000)
Epoch: [52][64/186]	Time 0.125 (0.132)	Data 0.000 (0.005)	Loss 0.6510 (0.6675)	Acc@1 86.617 (86.486)	Acc@5 100.000 (99.537)
Epoch: [52][128/186]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6307 (0.6751)	Acc@1 88.476 (86.268)	Acc@5 99.628 (99.458)
Max memory in training epoch: 66.0332544
lr: 0.10410505669672941
1

Epoch: [53 | 55] LR: 0.104105
batch Size 269
Epoch: [53][0/186]	Time 0.201 (0.201)	Data 0.303 (0.303)	Loss 0.6777 (0.6777)	Acc@1 86.617 (86.617)	Acc@5 98.885 (98.885)
Epoch: [53][64/186]	Time 0.127 (0.133)	Data 0.000 (0.005)	Loss 0.7415 (0.6863)	Acc@1 83.643 (86.057)	Acc@5 99.628 (99.445)
Epoch: [53][128/186]	Time 0.127 (0.132)	Data 0.000 (0.003)	Loss 0.6701 (0.6845)	Acc@1 86.617 (86.029)	Acc@5 99.257 (99.461)
Max memory in training epoch: 66.0332544
Drin!!
old memory: 653524480
new memory: 660332544
Faktor: 1.0104174582718004
New batch Size kleiner 271!!
lr: 0.10410505669672941
1

Epoch: [54 | 55] LR: 0.104105
batch Size 271
Epoch: [54][0/186]	Time 0.189 (0.189)	Data 0.290 (0.290)	Loss 0.5911 (0.5911)	Acc@1 91.822 (91.822)	Acc@5 99.628 (99.628)
Epoch: [54][64/186]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7592 (0.6576)	Acc@1 82.900 (87.086)	Acc@5 99.257 (99.525)
Epoch: [54][128/186]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.6400 (0.6751)	Acc@1 87.732 (86.407)	Acc@5 99.257 (99.522)
Max memory in training epoch: 66.0332544
lr: 0.10410505669672941
1

Epoch: [55 | 55] LR: 0.104105
batch Size 271
Epoch: [55][0/186]	Time 0.213 (0.213)	Data 0.313 (0.313)	Loss 0.6224 (0.6224)	Acc@1 86.245 (86.245)	Acc@5 100.000 (100.000)
Epoch: [55][64/186]	Time 0.137 (0.136)	Data 0.000 (0.005)	Loss 0.6759 (0.6867)	Acc@1 85.130 (86.154)	Acc@5 99.628 (99.480)
Epoch: [55][128/186]	Time 0.132 (0.137)	Data 0.000 (0.003)	Loss 0.6219 (0.6799)	Acc@1 90.706 (86.384)	Acc@5 99.257 (99.481)
Max memory in training epoch: 66.0332544
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 390824 ; 400066 ; 0.9768988116960702
[INFO] Storing checkpoint...
  76.98
Max memory: 97.2368896
 25.763s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4432
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.164352
lr: 0.11020496236255341
1

Epoch: [56 | 60] LR: 0.110205
batch Size 271
Epoch: [56][0/185]	Time 0.174 (0.174)	Data 0.287 (0.287)	Loss 0.5987 (0.5987)	Acc@1 87.823 (87.823)	Acc@5 100.000 (100.000)
Epoch: [56][64/185]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.6560 (0.6513)	Acc@1 86.347 (87.198)	Acc@5 98.893 (99.500)
Epoch: [56][128/185]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8014 (0.6688)	Acc@1 79.705 (86.656)	Acc@5 98.524 (99.491)
Max memory in training epoch: 65.5862784
lr: 0.11020496236255341
1

Epoch: [57 | 60] LR: 0.110205
batch Size 271
Epoch: [57][0/185]	Time 0.172 (0.172)	Data 0.326 (0.326)	Loss 0.7217 (0.7217)	Acc@1 84.133 (84.133)	Acc@5 99.631 (99.631)
Epoch: [57][64/185]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7673 (0.6712)	Acc@1 84.502 (86.880)	Acc@5 99.262 (99.495)
Epoch: [57][128/185]	Time 0.129 (0.131)	Data 0.000 (0.003)	Loss 0.8177 (0.6826)	Acc@1 82.288 (86.450)	Acc@5 98.524 (99.436)
Max memory in training epoch: 65.7819648
lr: 0.11020496236255341
1

Epoch: [58 | 60] LR: 0.110205
batch Size 271
Epoch: [58][0/185]	Time 0.193 (0.193)	Data 0.272 (0.272)	Loss 0.6390 (0.6390)	Acc@1 87.454 (87.454)	Acc@5 99.631 (99.631)
Epoch: [58][64/185]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6524 (0.6632)	Acc@1 85.978 (86.886)	Acc@5 99.262 (99.427)
Epoch: [58][128/185]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7221 (0.6696)	Acc@1 86.347 (86.722)	Acc@5 98.893 (99.451)
Max memory in training epoch: 65.7819648
Drin!!
old memory: 660332544
new memory: 657819648
Faktor: 0.996194499237039
New batch Size größer 275!!
lr: 0.11020496236255341
1

Epoch: [59 | 60] LR: 0.110205
batch Size 275
Epoch: [59][0/185]	Time 0.163 (0.163)	Data 0.311 (0.311)	Loss 0.6795 (0.6795)	Acc@1 86.347 (86.347)	Acc@5 100.000 (100.000)
Epoch: [59][64/185]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6921 (0.6779)	Acc@1 83.764 (86.517)	Acc@5 99.262 (99.410)
Epoch: [59][128/185]	Time 0.129 (0.131)	Data 0.000 (0.003)	Loss 0.6641 (0.6783)	Acc@1 87.085 (86.338)	Acc@5 98.524 (99.442)
Max memory in training epoch: 65.7819648
lr: 0.11020496236255341
1

Epoch: [60 | 60] LR: 0.110205
batch Size 275
Epoch: [60][0/185]	Time 0.230 (0.230)	Data 0.300 (0.300)	Loss 0.6457 (0.6457)	Acc@1 87.454 (87.454)	Acc@5 98.893 (98.893)
Epoch: [60][64/185]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.6843 (0.6798)	Acc@1 87.823 (86.506)	Acc@5 100.000 (99.455)
Epoch: [60][128/185]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7538 (0.6770)	Acc@1 84.502 (86.544)	Acc@5 99.262 (99.454)
Max memory in training epoch: 65.7819648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 384180 ; 390824 ; 0.983000020469572
[INFO] Storing checkpoint...
  74.37
Max memory: 96.058368
 24.348s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3462
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1615872
lr: 0.11838423691289916
1

Epoch: [61 | 65] LR: 0.118384
batch Size 275
Epoch: [61][0/182]	Time 0.190 (0.190)	Data 0.279 (0.279)	Loss 0.6541 (0.6541)	Acc@1 86.909 (86.909)	Acc@5 99.273 (99.273)
Epoch: [61][64/182]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 0.7124 (0.6667)	Acc@1 84.727 (87.032)	Acc@5 99.273 (99.424)
Epoch: [61][128/182]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6672 (0.6843)	Acc@1 87.273 (86.323)	Acc@5 99.273 (99.416)
Max memory in training epoch: 66.9509632
lr: 0.11838423691289916
1

Epoch: [62 | 65] LR: 0.118384
batch Size 275
Epoch: [62][0/182]	Time 0.162 (0.162)	Data 0.294 (0.294)	Loss 0.7650 (0.7650)	Acc@1 84.364 (84.364)	Acc@5 98.909 (98.909)
Epoch: [62][64/182]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.6547 (0.6896)	Acc@1 86.545 (86.048)	Acc@5 99.273 (99.340)
Epoch: [62][128/182]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.6720 (0.6932)	Acc@1 87.636 (85.900)	Acc@5 99.636 (99.411)
Max memory in training epoch: 66.9717504
lr: 0.11838423691289916
1

Epoch: [63 | 65] LR: 0.118384
batch Size 275
Epoch: [63][0/182]	Time 0.161 (0.161)	Data 0.304 (0.304)	Loss 0.6871 (0.6871)	Acc@1 84.000 (84.000)	Acc@5 100.000 (100.000)
Epoch: [63][64/182]	Time 0.132 (0.135)	Data 0.000 (0.005)	Loss 0.7237 (0.6791)	Acc@1 86.909 (86.473)	Acc@5 99.636 (99.502)
Epoch: [63][128/182]	Time 0.134 (0.135)	Data 0.000 (0.003)	Loss 0.7232 (0.6887)	Acc@1 86.182 (86.035)	Acc@5 98.909 (99.490)
Max memory in training epoch: 66.9717504
Drin!!
old memory: 657819648
new memory: 669717504
Faktor: 1.0180868054582644
New batch Size kleiner 279!!
lr: 0.11838423691289916
1

Epoch: [64 | 65] LR: 0.118384
batch Size 279
Epoch: [64][0/182]	Time 0.187 (0.187)	Data 0.301 (0.301)	Loss 0.6678 (0.6678)	Acc@1 87.636 (87.636)	Acc@5 99.273 (99.273)
Epoch: [64][64/182]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7123 (0.6704)	Acc@1 85.818 (86.965)	Acc@5 99.636 (99.519)
Epoch: [64][128/182]	Time 0.135 (0.132)	Data 0.000 (0.003)	Loss 0.5819 (0.6762)	Acc@1 89.455 (86.774)	Acc@5 100.000 (99.467)
Max memory in training epoch: 66.9717504
lr: 0.11838423691289916
1

Epoch: [65 | 65] LR: 0.118384
batch Size 279
Epoch: [65][0/182]	Time 0.182 (0.182)	Data 0.279 (0.279)	Loss 0.6817 (0.6817)	Acc@1 85.818 (85.818)	Acc@5 99.636 (99.636)
Epoch: [65][64/182]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 0.6272 (0.6844)	Acc@1 86.545 (86.227)	Acc@5 99.636 (99.407)
Epoch: [65][128/182]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.6616 (0.6929)	Acc@1 86.545 (85.965)	Acc@5 99.273 (99.366)
Max memory in training epoch: 66.9717504
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 379846 ; 384180 ; 0.9887188297152376
[INFO] Storing checkpoint...
  72.73
Max memory: 94.7117056
 24.421s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9298
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1598464
lr: 0.12902032069804245
1

Epoch: [66 | 70] LR: 0.129020
batch Size 279
Epoch: [66][0/180]	Time 0.209 (0.209)	Data 0.289 (0.289)	Loss 0.6374 (0.6374)	Acc@1 88.889 (88.889)	Acc@5 100.000 (100.000)
Epoch: [66][64/180]	Time 0.141 (0.131)	Data 0.000 (0.005)	Loss 0.7161 (0.6720)	Acc@1 86.022 (86.567)	Acc@5 99.642 (99.509)
Epoch: [66][128/180]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7242 (0.6922)	Acc@1 85.663 (86.019)	Acc@5 99.283 (99.458)
Max memory in training epoch: 66.9537792
lr: 0.12902032069804245
1

Epoch: [67 | 70] LR: 0.129020
batch Size 279
Epoch: [67][0/180]	Time 0.184 (0.184)	Data 0.307 (0.307)	Loss 0.6653 (0.6653)	Acc@1 86.738 (86.738)	Acc@5 99.642 (99.642)
Epoch: [67][64/180]	Time 0.135 (0.135)	Data 0.000 (0.005)	Loss 0.6253 (0.6931)	Acc@1 89.247 (86.071)	Acc@5 99.642 (99.509)
Epoch: [67][128/180]	Time 0.135 (0.134)	Data 0.000 (0.003)	Loss 0.6797 (0.7018)	Acc@1 88.172 (85.788)	Acc@5 99.283 (99.447)
Max memory in training epoch: 67.6996096
lr: 0.12902032069804245
1

Epoch: [68 | 70] LR: 0.129020
batch Size 279
Epoch: [68][0/180]	Time 0.170 (0.170)	Data 0.275 (0.275)	Loss 0.6438 (0.6438)	Acc@1 89.606 (89.606)	Acc@5 99.642 (99.642)
Epoch: [68][64/180]	Time 0.129 (0.133)	Data 0.000 (0.004)	Loss 0.7073 (0.7033)	Acc@1 84.229 (85.641)	Acc@5 100.000 (99.371)
Epoch: [68][128/180]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7734 (0.7052)	Acc@1 83.513 (85.699)	Acc@5 98.566 (99.380)
Max memory in training epoch: 67.6996096
Drin!!
old memory: 669717504
new memory: 676996096
Faktor: 1.0108681525516765
New batch Size kleiner 282!!
lr: 0.12902032069804245
1

Epoch: [69 | 70] LR: 0.129020
batch Size 282
Epoch: [69][0/180]	Time 0.164 (0.164)	Data 0.270 (0.270)	Loss 0.7807 (0.7807)	Acc@1 83.154 (83.154)	Acc@5 98.925 (98.925)
Epoch: [69][64/180]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.6482 (0.7030)	Acc@1 87.455 (85.966)	Acc@5 99.642 (99.371)
Epoch: [69][128/180]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7409 (0.7030)	Acc@1 82.437 (85.944)	Acc@5 100.000 (99.403)
Max memory in training epoch: 67.6996096
lr: 0.12902032069804245
1

Epoch: [70 | 70] LR: 0.129020
batch Size 282
Epoch: [70][0/180]	Time 0.193 (0.193)	Data 0.264 (0.264)	Loss 0.6871 (0.6871)	Acc@1 86.380 (86.380)	Acc@5 99.283 (99.283)
Epoch: [70][64/180]	Time 0.128 (0.133)	Data 0.000 (0.004)	Loss 0.7683 (0.7029)	Acc@1 86.022 (85.757)	Acc@5 99.283 (99.438)
Epoch: [70][128/180]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7119 (0.7078)	Acc@1 86.022 (85.680)	Acc@5 98.925 (99.436)
Max memory in training epoch: 67.6996096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 376670 ; 379846 ; 0.9916387167431011
[INFO] Storing checkpoint...
  81.63
Max memory: 94.2614528
 23.927s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8410
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.15872
lr: 0.14212394701893738
1

Epoch: [71 | 75] LR: 0.142124
batch Size 282
Epoch: [71][0/178]	Time 0.187 (0.187)	Data 0.348 (0.348)	Loss 0.7214 (0.7214)	Acc@1 85.816 (85.816)	Acc@5 99.645 (99.645)
Epoch: [71][64/178]	Time 0.135 (0.136)	Data 0.000 (0.006)	Loss 0.7469 (0.7023)	Acc@1 81.915 (85.614)	Acc@5 99.291 (99.400)
Epoch: [71][128/178]	Time 0.139 (0.138)	Data 0.000 (0.003)	Loss 0.7165 (0.7159)	Acc@1 83.688 (85.271)	Acc@5 100.000 (99.371)
Max memory in training epoch: 67.1187456
lr: 0.14212394701893738
1

Epoch: [72 | 75] LR: 0.142124
batch Size 282
Epoch: [72][0/178]	Time 0.188 (0.188)	Data 0.289 (0.289)	Loss 0.7096 (0.7096)	Acc@1 86.879 (86.879)	Acc@5 99.645 (99.645)
Epoch: [72][64/178]	Time 0.129 (0.135)	Data 0.000 (0.005)	Loss 0.8178 (0.7314)	Acc@1 79.078 (85.090)	Acc@5 99.645 (99.329)
Epoch: [72][128/178]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.7749 (0.7259)	Acc@1 84.397 (85.238)	Acc@5 99.291 (99.414)
Max memory in training epoch: 67.68384
lr: 0.14212394701893738
1

Epoch: [73 | 75] LR: 0.142124
batch Size 282
Epoch: [73][0/178]	Time 0.202 (0.202)	Data 0.272 (0.272)	Loss 0.6506 (0.6506)	Acc@1 87.943 (87.943)	Acc@5 99.291 (99.291)
Epoch: [73][64/178]	Time 0.136 (0.134)	Data 0.000 (0.004)	Loss 0.6837 (0.7201)	Acc@1 89.007 (85.526)	Acc@5 98.227 (99.405)
Epoch: [73][128/178]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.8310 (0.7180)	Acc@1 82.624 (85.576)	Acc@5 98.936 (99.343)
Max memory in training epoch: 67.68384
Drin!!
old memory: 676996096
new memory: 676838400
Faktor: 0.9997670651264731
New batch Size größer 279!!
lr: 0.14212394701893738
1

Epoch: [74 | 75] LR: 0.142124
batch Size 279
Epoch: [74][0/178]	Time 0.186 (0.186)	Data 0.300 (0.300)	Loss 0.6702 (0.6702)	Acc@1 87.234 (87.234)	Acc@5 99.291 (99.291)
Epoch: [74][64/178]	Time 0.138 (0.135)	Data 0.000 (0.005)	Loss 0.7630 (0.7329)	Acc@1 86.170 (85.003)	Acc@5 98.582 (99.231)
Epoch: [74][128/178]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.7161 (0.7256)	Acc@1 83.688 (85.247)	Acc@5 98.936 (99.302)
Max memory in training epoch: 67.68384
lr: 0.14212394701893738
1

Epoch: [75 | 75] LR: 0.142124
batch Size 279
Epoch: [75][0/178]	Time 0.195 (0.195)	Data 0.285 (0.285)	Loss 0.6569 (0.6569)	Acc@1 85.816 (85.816)	Acc@5 99.645 (99.645)
Epoch: [75][64/178]	Time 0.140 (0.134)	Data 0.000 (0.005)	Loss 0.6338 (0.7291)	Acc@1 89.007 (85.052)	Acc@5 99.291 (99.367)
Epoch: [75][128/178]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7641 (0.7179)	Acc@1 85.106 (85.455)	Acc@5 97.872 (99.401)
Max memory in training epoch: 67.68384
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 371900 ; 376670 ; 0.9873363952531393
[INFO] Storing checkpoint...
  80.42
Max memory: 93.981184
 23.992s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2914
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1568256
lr: 0.15489289538392004
1

Epoch: [76 | 80] LR: 0.154893
batch Size 279
Epoch: [76][0/180]	Time 0.196 (0.196)	Data 0.307 (0.307)	Loss 0.7167 (0.7167)	Acc@1 84.946 (84.946)	Acc@5 100.000 (100.000)
Epoch: [76][64/180]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7033 (0.6948)	Acc@1 88.172 (85.999)	Acc@5 99.283 (99.471)
Epoch: [76][128/180]	Time 0.133 (0.131)	Data 0.000 (0.003)	Loss 0.6689 (0.7221)	Acc@1 86.738 (85.221)	Acc@5 99.283 (99.342)
Max memory in training epoch: 65.8698752
lr: 0.15489289538392004
1

Epoch: [77 | 80] LR: 0.154893
batch Size 279
Epoch: [77][0/180]	Time 0.192 (0.192)	Data 0.264 (0.264)	Loss 0.6399 (0.6399)	Acc@1 87.455 (87.455)	Acc@5 100.000 (100.000)
Epoch: [77][64/180]	Time 0.125 (0.132)	Data 0.000 (0.004)	Loss 0.7544 (0.7420)	Acc@1 87.097 (84.759)	Acc@5 99.283 (99.305)
Epoch: [77][128/180]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7001 (0.7404)	Acc@1 86.380 (84.893)	Acc@5 98.566 (99.269)
Max memory in training epoch: 66.9563904
lr: 0.15489289538392004
1

Epoch: [78 | 80] LR: 0.154893
batch Size 279
Epoch: [78][0/180]	Time 0.183 (0.183)	Data 0.296 (0.296)	Loss 0.7990 (0.7990)	Acc@1 81.720 (81.720)	Acc@5 99.642 (99.642)
Epoch: [78][64/180]	Time 0.131 (0.133)	Data 0.000 (0.005)	Loss 0.6394 (0.7470)	Acc@1 88.889 (84.825)	Acc@5 100.000 (99.360)
Epoch: [78][128/180]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6902 (0.7477)	Acc@1 86.738 (84.579)	Acc@5 99.642 (99.367)
Max memory in training epoch: 66.9563904
Drin!!
old memory: 676838400
new memory: 669563904
Faktor: 0.9892522410076025
New batch Size größer 279!!
lr: 0.15489289538392004
1

Epoch: [79 | 80] LR: 0.154893
batch Size 279
Epoch: [79][0/180]	Time 0.176 (0.176)	Data 0.286 (0.286)	Loss 0.7803 (0.7803)	Acc@1 80.287 (80.287)	Acc@5 99.642 (99.642)
Epoch: [79][64/180]	Time 0.142 (0.132)	Data 0.000 (0.005)	Loss 0.7565 (0.7376)	Acc@1 86.380 (84.847)	Acc@5 98.566 (99.316)
Epoch: [79][128/180]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7139 (0.7311)	Acc@1 82.437 (85.105)	Acc@5 98.925 (99.347)
Max memory in training epoch: 66.9563904
lr: 0.15489289538392004
1

Epoch: [80 | 80] LR: 0.154893
batch Size 279
Epoch: [80][0/180]	Time 0.188 (0.188)	Data 0.322 (0.322)	Loss 0.6720 (0.6720)	Acc@1 87.814 (87.814)	Acc@5 99.642 (99.642)
Epoch: [80][64/180]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.7621 (0.7318)	Acc@1 84.229 (84.880)	Acc@5 99.642 (99.366)
Epoch: [80][128/180]	Time 0.129 (0.132)	Data 0.000 (0.003)	Loss 0.7135 (0.7374)	Acc@1 84.588 (84.880)	Acc@5 98.925 (99.353)
Max memory in training epoch: 66.9563904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 363752 ; 371900 ; 0.9780908846464104
[INFO] Storing checkpoint...
  68.48
Max memory: 93.067008
 24.090s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1266
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1530368
lr: 0.1688090539535691
1

Epoch: [81 | 85] LR: 0.168809
batch Size 279
Epoch: [81][0/180]	Time 0.193 (0.193)	Data 0.290 (0.290)	Loss 0.7260 (0.7260)	Acc@1 86.738 (86.738)	Acc@5 99.283 (99.283)
Epoch: [81][64/180]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.6852 (0.7073)	Acc@1 86.738 (86.121)	Acc@5 100.000 (99.460)
Epoch: [81][128/180]	Time 0.135 (0.126)	Data 0.000 (0.002)	Loss 0.7449 (0.7306)	Acc@1 86.380 (85.230)	Acc@5 99.642 (99.375)
Max memory in training epoch: 63.6363264
lr: 0.1688090539535691
1

Epoch: [82 | 85] LR: 0.168809
batch Size 279
Epoch: [82][0/180]	Time 0.182 (0.182)	Data 0.322 (0.322)	Loss 0.7061 (0.7061)	Acc@1 84.946 (84.946)	Acc@5 100.000 (100.000)
Epoch: [82][64/180]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.7331 (0.7646)	Acc@1 85.663 (83.876)	Acc@5 99.642 (99.294)
Epoch: [82][128/180]	Time 0.119 (0.125)	Data 0.000 (0.003)	Loss 0.6824 (0.7589)	Acc@1 87.097 (84.210)	Acc@5 99.642 (99.286)
Max memory in training epoch: 64.4237824
lr: 0.1688090539535691
1

Epoch: [83 | 85] LR: 0.168809
batch Size 279
Epoch: [83][0/180]	Time 0.160 (0.160)	Data 0.267 (0.267)	Loss 0.7239 (0.7239)	Acc@1 85.305 (85.305)	Acc@5 100.000 (100.000)
Epoch: [83][64/180]	Time 0.126 (0.125)	Data 0.000 (0.004)	Loss 0.7588 (0.7680)	Acc@1 83.871 (83.645)	Acc@5 100.000 (99.327)
Epoch: [83][128/180]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.8799 (0.7576)	Acc@1 78.853 (84.029)	Acc@5 99.283 (99.311)
Max memory in training epoch: 64.4237824
Drin!!
old memory: 669563904
new memory: 644237824
Faktor: 0.9621752608694987
New batch Size größer 290!!
lr: 0.1688090539535691
1

Epoch: [84 | 85] LR: 0.168809
batch Size 290
Epoch: [84][0/180]	Time 0.163 (0.163)	Data 0.316 (0.316)	Loss 0.7470 (0.7470)	Acc@1 84.229 (84.229)	Acc@5 99.283 (99.283)
Epoch: [84][64/180]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.8561 (0.7542)	Acc@1 82.437 (84.036)	Acc@5 99.642 (99.311)
Epoch: [84][128/180]	Time 0.120 (0.123)	Data 0.000 (0.003)	Loss 0.8041 (0.7584)	Acc@1 83.154 (84.190)	Acc@5 98.566 (99.258)
Max memory in training epoch: 64.4237824
lr: 0.1688090539535691
1

Epoch: [85 | 85] LR: 0.168809
batch Size 290
Epoch: [85][0/180]	Time 0.186 (0.186)	Data 0.310 (0.310)	Loss 0.7045 (0.7045)	Acc@1 87.455 (87.455)	Acc@5 99.642 (99.642)
Epoch: [85][64/180]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.6484 (0.7619)	Acc@1 87.814 (84.290)	Acc@5 98.925 (99.250)
Epoch: [85][128/180]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.7847 (0.7515)	Acc@1 82.437 (84.521)	Acc@5 99.642 (99.291)
Max memory in training epoch: 64.4237824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 361728 ; 363752 ; 0.9944357694253227
[INFO] Storing checkpoint...
  73.25
Max memory: 89.8933248
 22.977s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8547
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.15232
lr: 0.19122900643177748
1

Epoch: [86 | 90] LR: 0.191229
batch Size 290
Epoch: [86][0/173]	Time 0.219 (0.219)	Data 0.273 (0.273)	Loss 0.7206 (0.7206)	Acc@1 85.172 (85.172)	Acc@5 98.966 (98.966)
Epoch: [86][64/173]	Time 0.119 (0.127)	Data 0.000 (0.004)	Loss 0.7494 (0.7459)	Acc@1 85.517 (84.260)	Acc@5 98.966 (99.337)
Epoch: [86][128/173]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.7179 (0.7596)	Acc@1 84.483 (84.023)	Acc@5 99.655 (99.270)
Max memory in training epoch: 64.8573952
lr: 0.19122900643177748
1

Epoch: [87 | 90] LR: 0.191229
batch Size 290
Epoch: [87][0/173]	Time 0.183 (0.183)	Data 0.302 (0.302)	Loss 0.7647 (0.7647)	Acc@1 84.483 (84.483)	Acc@5 99.310 (99.310)
Epoch: [87][64/173]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.7574 (0.7501)	Acc@1 83.793 (84.684)	Acc@5 100.000 (99.347)
Epoch: [87][128/173]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.7269 (0.7598)	Acc@1 86.897 (84.320)	Acc@5 100.000 (99.254)
Max memory in training epoch: 65.3431296
lr: 0.19122900643177748
1

Epoch: [88 | 90] LR: 0.191229
batch Size 290
Epoch: [88][0/173]	Time 0.153 (0.153)	Data 0.283 (0.283)	Loss 0.6836 (0.6836)	Acc@1 86.207 (86.207)	Acc@5 99.655 (99.655)
Epoch: [88][64/173]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.8251 (0.7350)	Acc@1 82.414 (84.902)	Acc@5 98.966 (99.353)
Epoch: [88][128/173]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7353 (0.7557)	Acc@1 81.379 (84.213)	Acc@5 99.655 (99.313)
Max memory in training epoch: 65.474816
Drin!!
old memory: 644237824
new memory: 654748160
Faktor: 1.0163143727494026
New batch Size kleiner 294!!
lr: 0.19122900643177748
1

Epoch: [89 | 90] LR: 0.191229
batch Size 294
Epoch: [89][0/173]	Time 0.197 (0.197)	Data 0.283 (0.283)	Loss 0.7678 (0.7678)	Acc@1 82.069 (82.069)	Acc@5 98.966 (98.966)
Epoch: [89][64/173]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.7666 (0.7558)	Acc@1 83.793 (84.223)	Acc@5 99.655 (99.363)
Epoch: [89][128/173]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.8159 (0.7554)	Acc@1 81.379 (84.301)	Acc@5 98.966 (99.337)
Max memory in training epoch: 65.400576
lr: 0.19122900643177748
1

Epoch: [90 | 90] LR: 0.191229
batch Size 294
Epoch: [90][0/173]	Time 0.188 (0.188)	Data 0.320 (0.320)	Loss 0.7799 (0.7799)	Acc@1 84.138 (84.138)	Acc@5 99.655 (99.655)
Epoch: [90][64/173]	Time 0.137 (0.127)	Data 0.000 (0.005)	Loss 0.7109 (0.7601)	Acc@1 87.586 (84.424)	Acc@5 100.000 (99.316)
Epoch: [90][128/173]	Time 0.118 (0.126)	Data 0.000 (0.003)	Loss 0.7535 (0.7649)	Acc@1 84.483 (84.010)	Acc@5 98.621 (99.297)
Max memory in training epoch: 65.400576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356242 ; 361728 ; 0.9848339083510261
[INFO] Storing checkpoint...
  76.09
Max memory: 88.5251584
 22.175s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5485
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1500672
lr: 0.21961456207399446
1

Epoch: [91 | 95] LR: 0.219615
batch Size 294
Epoch: [91][0/171]	Time 0.192 (0.192)	Data 0.277 (0.277)	Loss 0.7442 (0.7442)	Acc@1 84.694 (84.694)	Acc@5 98.980 (98.980)
Epoch: [91][64/171]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.8340 (0.7667)	Acc@1 81.633 (83.773)	Acc@5 98.980 (99.257)
Epoch: [91][128/171]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.7901 (0.7962)	Acc@1 83.333 (82.843)	Acc@5 99.660 (99.183)
Max memory in training epoch: 65.1367936
lr: 0.21961456207399446
1

Epoch: [92 | 95] LR: 0.219615
batch Size 294
Epoch: [92][0/171]	Time 0.177 (0.177)	Data 0.285 (0.285)	Loss 0.8833 (0.8833)	Acc@1 81.633 (81.633)	Acc@5 99.660 (99.660)
Epoch: [92][64/171]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6567 (0.8218)	Acc@1 88.095 (82.664)	Acc@5 99.320 (99.042)
Epoch: [92][128/171]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7406 (0.8077)	Acc@1 84.354 (82.853)	Acc@5 99.320 (99.148)
Max memory in training epoch: 65.6141824
lr: 0.21961456207399446
1

Epoch: [93 | 95] LR: 0.021961
batch Size 294
Epoch: [93][0/171]	Time 0.169 (0.169)	Data 0.338 (0.338)	Loss 0.7027 (0.7027)	Acc@1 87.415 (87.415)	Acc@5 99.660 (99.660)
Epoch: [93][64/171]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.6115 (0.6634)	Acc@1 90.476 (87.813)	Acc@5 99.320 (99.519)
Epoch: [93][128/171]	Time 0.132 (0.127)	Data 0.000 (0.003)	Loss 0.5739 (0.6311)	Acc@1 91.837 (88.797)	Acc@5 100.000 (99.610)
Max memory in training epoch: 65.6141824
Drin!!
old memory: 654005760
new memory: 656141824
Faktor: 1.0032661241393348
New batch Size kleiner 294!!
lr: 0.02196145620739945
1

Epoch: [94 | 95] LR: 0.021961
batch Size 294
Epoch: [94][0/171]	Time 0.178 (0.178)	Data 0.271 (0.271)	Loss 0.6018 (0.6018)	Acc@1 89.796 (89.796)	Acc@5 100.000 (100.000)
Epoch: [94][64/171]	Time 0.124 (0.126)	Data 0.000 (0.004)	Loss 0.5324 (0.5500)	Acc@1 93.197 (91.444)	Acc@5 99.660 (99.775)
Epoch: [94][128/171]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.5333 (0.5523)	Acc@1 92.177 (91.301)	Acc@5 99.660 (99.771)
Max memory in training epoch: 65.6141824
lr: 0.02196145620739945
1

Epoch: [95 | 95] LR: 0.021961
batch Size 294
Epoch: [95][0/171]	Time 0.177 (0.177)	Data 0.273 (0.273)	Loss 0.4886 (0.4886)	Acc@1 93.537 (93.537)	Acc@5 100.000 (100.000)
Epoch: [95][64/171]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.4920 (0.5202)	Acc@1 91.156 (92.140)	Acc@5 99.660 (99.848)
Epoch: [95][128/171]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.4705 (0.5147)	Acc@1 92.177 (92.082)	Acc@5 100.000 (99.829)
Max memory in training epoch: 65.6141824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353354 ; 356242 ; 0.9918931512848008
[INFO] Storing checkpoint...
  90.13
Max memory: 88.1812992
 21.792s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1654
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1489408
lr: 0.025221359863185303
1

Epoch: [96 | 100] LR: 0.025221
batch Size 294
Epoch: [96][0/171]	Time 0.168 (0.168)	Data 0.295 (0.295)	Loss 0.4538 (0.4538)	Acc@1 93.197 (93.197)	Acc@5 100.000 (100.000)
Epoch: [96][64/171]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.4475 (0.4885)	Acc@1 93.197 (92.632)	Acc@5 100.000 (99.864)
Epoch: [96][128/171]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.4575 (0.4903)	Acc@1 93.537 (92.667)	Acc@5 100.000 (99.850)
Max memory in training epoch: 64.9043968
lr: 0.025221359863185303
1

Epoch: [97 | 100] LR: 0.025221
batch Size 294
Epoch: [97][0/171]	Time 0.174 (0.174)	Data 0.299 (0.299)	Loss 0.4535 (0.4535)	Acc@1 93.197 (93.197)	Acc@5 99.660 (99.660)
Epoch: [97][64/171]	Time 0.137 (0.130)	Data 0.000 (0.005)	Loss 0.4780 (0.4829)	Acc@1 92.517 (92.664)	Acc@5 100.000 (99.838)
Epoch: [97][128/171]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.4287 (0.4767)	Acc@1 93.878 (92.696)	Acc@5 100.000 (99.837)
Max memory in training epoch: 65.389312
lr: 0.025221359863185303
1

Epoch: [98 | 100] LR: 0.025221
batch Size 294
Epoch: [98][0/171]	Time 0.172 (0.172)	Data 0.275 (0.275)	Loss 0.4554 (0.4554)	Acc@1 92.857 (92.857)	Acc@5 100.000 (100.000)
Epoch: [98][64/171]	Time 0.120 (0.126)	Data 0.000 (0.004)	Loss 0.4371 (0.4522)	Acc@1 92.517 (93.318)	Acc@5 100.000 (99.812)
Epoch: [98][128/171]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.4025 (0.4544)	Acc@1 95.238 (93.179)	Acc@5 100.000 (99.839)
Max memory in training epoch: 65.389312
Drin!!
old memory: 656141824
new memory: 653893120
Faktor: 0.9965728384965747
New batch Size größer 301!!
lr: 0.025221359863185303
1

Epoch: [99 | 100] LR: 0.025221
batch Size 301
Epoch: [99][0/171]	Time 0.169 (0.169)	Data 0.305 (0.305)	Loss 0.4404 (0.4404)	Acc@1 91.497 (91.497)	Acc@5 99.660 (99.660)
Epoch: [99][64/171]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.4220 (0.4505)	Acc@1 93.878 (93.124)	Acc@5 100.000 (99.822)
Epoch: [99][128/171]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.4733 (0.4497)	Acc@1 90.816 (93.105)	Acc@5 100.000 (99.860)
Max memory in training epoch: 65.389312
lr: 0.025221359863185303
1

Epoch: [100 | 100] LR: 0.025221
batch Size 301
Epoch: [100][0/171]	Time 0.158 (0.158)	Data 0.313 (0.313)	Loss 0.3760 (0.3760)	Acc@1 95.918 (95.918)	Acc@5 100.000 (100.000)
Epoch: [100][64/171]	Time 0.118 (0.125)	Data 0.000 (0.005)	Loss 0.4782 (0.4395)	Acc@1 92.177 (93.114)	Acc@5 100.000 (99.869)
Epoch: [100][128/171]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.4171 (0.4331)	Acc@1 94.218 (93.374)	Acc@5 100.000 (99.879)
Max memory in training epoch: 65.389312
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 352200 ; 353354 ; 0.9967341532853738
[INFO] Storing checkpoint...
  90.08
Max memory: 88.0501248
 21.898s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4798
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1485312
lr: 0.029654802026635844
1

Epoch: [101 | 105] LR: 0.029655
batch Size 301
Epoch: [101][0/167]	Time 0.189 (0.189)	Data 0.287 (0.287)	Loss 0.3983 (0.3983)	Acc@1 95.017 (95.017)	Acc@5 100.000 (100.000)
Epoch: [101][64/167]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.5245 (0.4157)	Acc@1 89.701 (93.877)	Acc@5 99.336 (99.857)
Epoch: [101][128/167]	Time 0.141 (0.131)	Data 0.000 (0.002)	Loss 0.4719 (0.4213)	Acc@1 92.691 (93.665)	Acc@5 99.003 (99.843)
Max memory in training epoch: 66.5397248
lr: 0.029654802026635844
1

Epoch: [102 | 105] LR: 0.029655
batch Size 301
Epoch: [102][0/167]	Time 0.188 (0.188)	Data 0.268 (0.268)	Loss 0.3651 (0.3651)	Acc@1 95.681 (95.681)	Acc@5 100.000 (100.000)
Epoch: [102][64/167]	Time 0.148 (0.127)	Data 0.000 (0.004)	Loss 0.3980 (0.4396)	Acc@1 95.017 (92.803)	Acc@5 100.000 (99.842)
Epoch: [102][128/167]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.4067 (0.4331)	Acc@1 94.684 (92.964)	Acc@5 99.668 (99.838)
Max memory in training epoch: 66.8177408
lr: 0.029654802026635844
1

Epoch: [103 | 105] LR: 0.029655
batch Size 301
Epoch: [103][0/167]	Time 0.177 (0.177)	Data 0.325 (0.325)	Loss 0.3752 (0.3752)	Acc@1 95.681 (95.681)	Acc@5 99.668 (99.668)
Epoch: [103][64/167]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.4014 (0.4217)	Acc@1 94.020 (93.141)	Acc@5 100.000 (99.893)
Epoch: [103][128/167]	Time 0.129 (0.128)	Data 0.000 (0.003)	Loss 0.4174 (0.4210)	Acc@1 93.355 (93.167)	Acc@5 100.000 (99.869)
Max memory in training epoch: 66.8177408
Drin!!
old memory: 653893120
new memory: 668177408
Faktor: 1.0218449889792387
New batch Size kleiner 307!!
lr: 0.029654802026635844
1

Epoch: [104 | 105] LR: 0.029655
batch Size 307
Epoch: [104][0/167]	Time 0.177 (0.177)	Data 0.307 (0.307)	Loss 0.3880 (0.3880)	Acc@1 94.684 (94.684)	Acc@5 100.000 (100.000)
Epoch: [104][64/167]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.3971 (0.4338)	Acc@1 93.688 (92.711)	Acc@5 100.000 (99.796)
Epoch: [104][128/167]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 0.4662 (0.4226)	Acc@1 90.698 (92.990)	Acc@5 100.000 (99.845)
Max memory in training epoch: 66.8177408
lr: 0.029654802026635844
1

Epoch: [105 | 105] LR: 0.029655
batch Size 307
Epoch: [105][0/167]	Time 0.186 (0.186)	Data 0.318 (0.318)	Loss 0.4286 (0.4286)	Acc@1 93.023 (93.023)	Acc@5 100.000 (100.000)
Epoch: [105][64/167]	Time 0.140 (0.129)	Data 0.000 (0.005)	Loss 0.4281 (0.4084)	Acc@1 94.020 (93.166)	Acc@5 99.003 (99.872)
Epoch: [105][128/167]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.4495 (0.4109)	Acc@1 91.694 (93.155)	Acc@5 100.000 (99.887)
Max memory in training epoch: 66.8177408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 350756 ; 352200 ; 0.9959000567859171
[INFO] Storing checkpoint...
  88.77
Max memory: 88.048896
 21.553s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5483
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1479168
lr: 0.0355625946178797
1

Epoch: [106 | 110] LR: 0.035563
batch Size 307
Epoch: [106][0/163]	Time 0.213 (0.213)	Data 0.273 (0.273)	Loss 0.3596 (0.3596)	Acc@1 95.114 (95.114)	Acc@5 99.674 (99.674)
Epoch: [106][64/163]	Time 0.125 (0.131)	Data 0.000 (0.004)	Loss 0.3900 (0.4034)	Acc@1 93.811 (93.215)	Acc@5 99.674 (99.880)
Epoch: [106][128/163]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.4323 (0.4153)	Acc@1 89.902 (92.862)	Acc@5 100.000 (99.879)
Max memory in training epoch: 69.4632448
lr: 0.0355625946178797
1

Epoch: [107 | 110] LR: 0.035563
batch Size 307
Epoch: [107][0/163]	Time 0.180 (0.180)	Data 0.285 (0.285)	Loss 0.4423 (0.4423)	Acc@1 91.531 (91.531)	Acc@5 99.674 (99.674)
Epoch: [107][64/163]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.3715 (0.4116)	Acc@1 94.788 (92.799)	Acc@5 100.000 (99.845)
Epoch: [107][128/163]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.3989 (0.4242)	Acc@1 94.463 (92.448)	Acc@5 99.349 (99.821)
Max memory in training epoch: 69.33504
lr: 0.0355625946178797
1

Epoch: [108 | 110] LR: 0.035563
batch Size 307
Epoch: [108][0/163]	Time 0.191 (0.191)	Data 0.310 (0.310)	Loss 0.3766 (0.3766)	Acc@1 93.811 (93.811)	Acc@5 100.000 (100.000)
Epoch: [108][64/163]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.3458 (0.4195)	Acc@1 94.463 (92.658)	Acc@5 99.674 (99.860)
Epoch: [108][128/163]	Time 0.156 (0.127)	Data 0.000 (0.003)	Loss 0.4807 (0.4234)	Acc@1 91.857 (92.473)	Acc@5 99.023 (99.851)
Max memory in training epoch: 69.33504
Drin!!
old memory: 668177408
new memory: 693350400
Faktor: 1.0376741142376367
New batch Size kleiner 318!!
lr: 0.0355625946178797
1

Epoch: [109 | 110] LR: 0.035563
batch Size 318
Epoch: [109][0/163]	Time 0.149 (0.149)	Data 0.310 (0.310)	Loss 0.4252 (0.4252)	Acc@1 93.160 (93.160)	Acc@5 99.674 (99.674)
Epoch: [109][64/163]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.4255 (0.4191)	Acc@1 91.857 (92.378)	Acc@5 99.349 (99.890)
Epoch: [109][128/163]	Time 0.127 (0.127)	Data 0.000 (0.003)	Loss 0.4270 (0.4248)	Acc@1 90.879 (92.256)	Acc@5 99.674 (99.866)
Max memory in training epoch: 69.33504
lr: 0.0355625946178797
1

Epoch: [110 | 110] LR: 0.035563
batch Size 318
Epoch: [110][0/163]	Time 0.171 (0.171)	Data 0.315 (0.315)	Loss 0.3880 (0.3880)	Acc@1 95.114 (95.114)	Acc@5 100.000 (100.000)
Epoch: [110][64/163]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.3760 (0.4096)	Acc@1 94.137 (92.804)	Acc@5 100.000 (99.905)
Epoch: [110][128/163]	Time 0.132 (0.127)	Data 0.000 (0.003)	Loss 0.4121 (0.4183)	Acc@1 90.879 (92.549)	Acc@5 100.000 (99.886)
Max memory in training epoch: 69.33504
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 349602 ; 350756 ; 0.9967099636214348
[INFO] Storing checkpoint...
  88.25
Max memory: 87.9563264
 21.229s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2033
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1475072
lr: 0.04417541050189744
1

Epoch: [111 | 115] LR: 0.044175
batch Size 318
Epoch: [111][0/158]	Time 0.206 (0.206)	Data 0.275 (0.275)	Loss 0.4266 (0.4266)	Acc@1 91.824 (91.824)	Acc@5 100.000 (100.000)
Epoch: [111][64/158]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.4602 (0.4294)	Acc@1 90.881 (92.380)	Acc@5 99.686 (99.874)
Epoch: [111][128/158]	Time 0.146 (0.130)	Data 0.000 (0.002)	Loss 0.4209 (0.4462)	Acc@1 92.767 (91.661)	Acc@5 100.000 (99.849)
Max memory in training epoch: 70.4669696
lr: 0.04417541050189744
1

Epoch: [112 | 115] LR: 0.044175
batch Size 318
Epoch: [112][0/158]	Time 0.181 (0.181)	Data 0.288 (0.288)	Loss 0.4907 (0.4907)	Acc@1 88.994 (88.994)	Acc@5 100.000 (100.000)
Epoch: [112][64/158]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.4033 (0.4539)	Acc@1 92.767 (91.437)	Acc@5 100.000 (99.821)
Epoch: [112][128/158]	Time 0.120 (0.130)	Data 0.000 (0.002)	Loss 0.4992 (0.4610)	Acc@1 89.623 (91.178)	Acc@5 100.000 (99.790)
Max memory in training epoch: 70.2940672
lr: 0.04417541050189744
1

Epoch: [113 | 115] LR: 0.044175
batch Size 318
Epoch: [113][0/158]	Time 0.191 (0.191)	Data 0.287 (0.287)	Loss 0.4729 (0.4729)	Acc@1 90.566 (90.566)	Acc@5 100.000 (100.000)
Epoch: [113][64/158]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.5008 (0.4593)	Acc@1 91.509 (91.359)	Acc@5 99.686 (99.782)
Epoch: [113][128/158]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.4433 (0.4607)	Acc@1 91.509 (91.280)	Acc@5 99.057 (99.798)
Max memory in training epoch: 70.2940672
Drin!!
old memory: 693350400
new memory: 702940672
Faktor: 1.0138317826022745
New batch Size kleiner 322!!
lr: 0.04417541050189744
1

Epoch: [114 | 115] LR: 0.044175
batch Size 322
Epoch: [114][0/158]	Time 0.192 (0.192)	Data 0.281 (0.281)	Loss 0.4676 (0.4676)	Acc@1 90.566 (90.566)	Acc@5 99.686 (99.686)
Epoch: [114][64/158]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.4358 (0.4585)	Acc@1 92.453 (91.476)	Acc@5 99.686 (99.777)
Epoch: [114][128/158]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.4535 (0.4567)	Acc@1 91.509 (91.536)	Acc@5 99.686 (99.800)
Max memory in training epoch: 70.2940672
lr: 0.04417541050189744
1

Epoch: [115 | 115] LR: 0.044175
batch Size 322
Epoch: [115][0/158]	Time 0.203 (0.203)	Data 0.309 (0.309)	Loss 0.4932 (0.4932)	Acc@1 92.138 (92.138)	Acc@5 100.000 (100.000)
Epoch: [115][64/158]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.4057 (0.4459)	Acc@1 91.509 (91.848)	Acc@5 100.000 (99.821)
Epoch: [115][128/158]	Time 0.123 (0.128)	Data 0.000 (0.003)	Loss 0.5474 (0.4525)	Acc@1 89.308 (91.612)	Acc@5 99.371 (99.827)
Max memory in training epoch: 70.2940672
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  85.87
Max memory: 88.0648704
 20.577s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4542
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1475072
lr: 0.05556438352191787
1

Epoch: [116 | 120] LR: 0.055564
batch Size 322
Epoch: [116][0/156]	Time 0.226 (0.226)	Data 0.269 (0.269)	Loss 0.4529 (0.4529)	Acc@1 91.615 (91.615)	Acc@5 100.000 (100.000)
Epoch: [116][64/156]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.5126 (0.4698)	Acc@1 90.062 (91.247)	Acc@5 99.689 (99.699)
Epoch: [116][128/156]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.4675 (0.4898)	Acc@1 92.547 (90.541)	Acc@5 99.689 (99.704)
Max memory in training epoch: 70.98496
lr: 0.05556438352191787
1

Epoch: [117 | 120] LR: 0.055564
batch Size 322
Epoch: [117][0/156]	Time 0.197 (0.197)	Data 0.275 (0.275)	Loss 0.4204 (0.4204)	Acc@1 93.478 (93.478)	Acc@5 100.000 (100.000)
Epoch: [117][64/156]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.5220 (0.5003)	Acc@1 90.062 (90.282)	Acc@5 99.689 (99.775)
Epoch: [117][128/156]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.5079 (0.4971)	Acc@1 90.683 (90.325)	Acc@5 100.000 (99.786)
Max memory in training epoch: 70.989824
lr: 0.05556438352191787
1

Epoch: [118 | 120] LR: 0.055564
batch Size 322
Epoch: [118][0/156]	Time 0.158 (0.158)	Data 0.292 (0.292)	Loss 0.4665 (0.4665)	Acc@1 91.615 (91.615)	Acc@5 100.000 (100.000)
Epoch: [118][64/156]	Time 0.122 (0.130)	Data 0.000 (0.005)	Loss 0.4905 (0.4949)	Acc@1 91.925 (90.645)	Acc@5 99.689 (99.742)
Epoch: [118][128/156]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.5143 (0.4938)	Acc@1 90.062 (90.515)	Acc@5 99.689 (99.757)
Max memory in training epoch: 70.989824
Drin!!
old memory: 702940672
new memory: 709898240
Faktor: 1.0098978025843979
New batch Size kleiner 325!!
lr: 0.05556438352191787
1

Epoch: [119 | 120] LR: 0.055564
batch Size 325
Epoch: [119][0/156]	Time 0.183 (0.183)	Data 0.312 (0.312)	Loss 0.4825 (0.4825)	Acc@1 90.683 (90.683)	Acc@5 100.000 (100.000)
Epoch: [119][64/156]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.4553 (0.4789)	Acc@1 91.615 (91.022)	Acc@5 99.689 (99.799)
Epoch: [119][128/156]	Time 0.131 (0.130)	Data 0.000 (0.003)	Loss 0.5656 (0.4884)	Acc@1 88.820 (90.712)	Acc@5 100.000 (99.783)
Max memory in training epoch: 70.989824
lr: 0.05556438352191787
1

Epoch: [120 | 120] LR: 0.055564
batch Size 325
Epoch: [120][0/156]	Time 0.195 (0.195)	Data 0.281 (0.281)	Loss 0.5260 (0.5260)	Acc@1 87.888 (87.888)	Acc@5 99.068 (99.068)
Epoch: [120][64/156]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.4201 (0.4828)	Acc@1 93.789 (91.113)	Acc@5 99.379 (99.766)
Epoch: [120][128/156]	Time 0.137 (0.131)	Data 0.000 (0.002)	Loss 0.4680 (0.4904)	Acc@1 90.373 (90.770)	Acc@5 100.000 (99.779)
Max memory in training epoch: 70.989824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 348448 ; 349602 ; 0.9966991035520392
[INFO] Storing checkpoint...
  84.65
Max memory: 87.3896448
 20.830s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 886
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1469952
lr: 0.0705407212680598
1

Epoch: [121 | 125] LR: 0.070541
batch Size 325
Epoch: [121][0/154]	Time 0.211 (0.211)	Data 0.294 (0.294)	Loss 0.4582 (0.4582)	Acc@1 92.923 (92.923)	Acc@5 99.385 (99.385)
Epoch: [121][64/154]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.4780 (0.4934)	Acc@1 92.000 (90.755)	Acc@5 99.692 (99.721)
Epoch: [121][128/154]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.5179 (0.5174)	Acc@1 90.462 (89.932)	Acc@5 99.385 (99.702)
Max memory in training epoch: 71.4904064
lr: 0.0705407212680598
1

Epoch: [122 | 125] LR: 0.070541
batch Size 325
Epoch: [122][0/154]	Time 0.163 (0.163)	Data 0.288 (0.288)	Loss 0.5520 (0.5520)	Acc@1 89.231 (89.231)	Acc@5 99.692 (99.692)
Epoch: [122][64/154]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.5916 (0.5394)	Acc@1 86.769 (89.174)	Acc@5 99.692 (99.735)
Epoch: [122][128/154]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.5207 (0.5410)	Acc@1 89.538 (89.209)	Acc@5 100.000 (99.738)
Max memory in training epoch: 71.4904064
lr: 0.0705407212680598
1

Epoch: [123 | 125] LR: 0.070541
batch Size 325
Epoch: [123][0/154]	Time 0.187 (0.187)	Data 0.311 (0.311)	Loss 0.5893 (0.5893)	Acc@1 86.462 (86.462)	Acc@5 99.385 (99.385)
Epoch: [123][64/154]	Time 0.124 (0.132)	Data 0.000 (0.005)	Loss 0.4798 (0.5170)	Acc@1 90.154 (90.433)	Acc@5 100.000 (99.716)
Epoch: [123][128/154]	Time 0.133 (0.132)	Data 0.000 (0.003)	Loss 0.5078 (0.5262)	Acc@1 89.538 (89.968)	Acc@5 100.000 (99.709)
Max memory in training epoch: 71.4904064
Drin!!
old memory: 709898240
new memory: 714904064
Faktor: 1.0070514669820847
New batch Size kleiner 327!!
lr: 0.0705407212680598
1

Epoch: [124 | 125] LR: 0.070541
batch Size 327
Epoch: [124][0/154]	Time 0.182 (0.182)	Data 0.303 (0.303)	Loss 0.4910 (0.4910)	Acc@1 91.077 (91.077)	Acc@5 100.000 (100.000)
Epoch: [124][64/154]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.5107 (0.5116)	Acc@1 90.462 (90.310)	Acc@5 100.000 (99.782)
Epoch: [124][128/154]	Time 0.127 (0.129)	Data 0.000 (0.003)	Loss 0.4808 (0.5209)	Acc@1 91.385 (89.980)	Acc@5 99.692 (99.742)
Max memory in training epoch: 71.4904064
lr: 0.0705407212680598
1

Epoch: [125 | 125] LR: 0.070541
batch Size 327
Epoch: [125][0/154]	Time 0.180 (0.180)	Data 0.287 (0.287)	Loss 0.4730 (0.4730)	Acc@1 92.308 (92.308)	Acc@5 100.000 (100.000)
Epoch: [125][64/154]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.5657 (0.5397)	Acc@1 89.231 (89.510)	Acc@5 99.692 (99.711)
Epoch: [125][128/154]	Time 0.146 (0.130)	Data 0.000 (0.002)	Loss 0.4945 (0.5320)	Acc@1 91.692 (89.782)	Acc@5 99.385 (99.697)
Max memory in training epoch: 71.4904064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 347290 ; 348448 ; 0.9966766920745707
[INFO] Storing checkpoint...
  81.53
Max memory: 87.3676288
 20.372s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2039
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1464832
lr: 0.09010474943224826
1

Epoch: [126 | 130] LR: 0.090105
batch Size 327
Epoch: [126][0/153]	Time 0.215 (0.215)	Data 0.312 (0.312)	Loss 0.4498 (0.4498)	Acc@1 92.355 (92.355)	Acc@5 99.694 (99.694)
Epoch: [126][64/153]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.5219 (0.5357)	Acc@1 89.297 (89.678)	Acc@5 99.694 (99.699)
Epoch: [126][128/153]	Time 0.132 (0.131)	Data 0.000 (0.003)	Loss 0.6349 (0.5634)	Acc@1 86.544 (88.815)	Acc@5 100.000 (99.673)
Max memory in training epoch: 71.2340992
lr: 0.09010474943224826
1

Epoch: [127 | 130] LR: 0.090105
batch Size 327
Epoch: [127][0/153]	Time 0.159 (0.159)	Data 0.340 (0.340)	Loss 0.5378 (0.5378)	Acc@1 89.908 (89.908)	Acc@5 100.000 (100.000)
Epoch: [127][64/153]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.5699 (0.5762)	Acc@1 87.768 (88.534)	Acc@5 99.694 (99.638)
Epoch: [127][128/153]	Time 0.125 (0.131)	Data 0.000 (0.003)	Loss 0.5842 (0.5747)	Acc@1 88.379 (88.623)	Acc@5 100.000 (99.678)
Max memory in training epoch: 71.2340992
lr: 0.09010474943224826
1

Epoch: [128 | 130] LR: 0.090105
batch Size 327
Epoch: [128][0/153]	Time 0.157 (0.157)	Data 0.322 (0.322)	Loss 0.6201 (0.6201)	Acc@1 86.239 (86.239)	Acc@5 99.694 (99.694)
Epoch: [128][64/153]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.5192 (0.5741)	Acc@1 89.908 (88.798)	Acc@5 100.000 (99.671)
Epoch: [128][128/153]	Time 0.135 (0.130)	Data 0.000 (0.003)	Loss 0.5973 (0.5760)	Acc@1 89.602 (88.673)	Acc@5 99.694 (99.652)
Max memory in training epoch: 71.2340992
Drin!!
old memory: 714904064
new memory: 712340992
Faktor: 0.9964148028678712
New batch Size größer 307!!
lr: 0.09010474943224826
1

Epoch: [129 | 130] LR: 0.090105
batch Size 307
Epoch: [129][0/153]	Time 0.167 (0.167)	Data 0.286 (0.286)	Loss 0.5605 (0.5605)	Acc@1 89.602 (89.602)	Acc@5 99.388 (99.388)
Epoch: [129][64/153]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.6019 (0.5710)	Acc@1 85.933 (88.680)	Acc@5 100.000 (99.694)
Epoch: [129][128/153]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.6414 (0.5822)	Acc@1 85.933 (88.436)	Acc@5 99.694 (99.640)
Max memory in training epoch: 71.2340992
lr: 0.09010474943224826
1

Epoch: [130 | 130] LR: 0.090105
batch Size 307
Epoch: [130][0/153]	Time 0.164 (0.164)	Data 0.335 (0.335)	Loss 0.5239 (0.5239)	Acc@1 88.379 (88.379)	Acc@5 100.000 (100.000)
Epoch: [130][64/153]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.6116 (0.5421)	Acc@1 85.627 (89.842)	Acc@5 99.388 (99.793)
Epoch: [130][128/153]	Time 0.125 (0.132)	Data 0.000 (0.003)	Loss 0.5018 (0.5617)	Acc@1 92.966 (89.306)	Acc@5 99.388 (99.701)
Max memory in training epoch: 71.2340992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 347000 ; 347290 ; 0.9991649629992225
[INFO] Storing checkpoint...
  79.77
Max memory: 86.5403392
 20.466s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7664
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1463808
lr: 0.10805530498320397
1

Epoch: [131 | 135] LR: 0.108055
batch Size 307
Epoch: [131][0/163]	Time 0.205 (0.205)	Data 0.293 (0.293)	Loss 0.5401 (0.5401)	Acc@1 89.251 (89.251)	Acc@5 100.000 (100.000)
Epoch: [131][64/163]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.6060 (0.5859)	Acc@1 90.554 (88.499)	Acc@5 99.674 (99.619)
Epoch: [131][128/163]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6023 (0.6090)	Acc@1 88.274 (87.809)	Acc@5 99.674 (99.545)
Max memory in training epoch: 68.5835264
lr: 0.10805530498320397
1

Epoch: [132 | 135] LR: 0.108055
batch Size 307
Epoch: [132][0/163]	Time 0.174 (0.174)	Data 0.311 (0.311)	Loss 0.6125 (0.6125)	Acc@1 89.251 (89.251)	Acc@5 99.349 (99.349)
Epoch: [132][64/163]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.6138 (0.6288)	Acc@1 90.554 (87.337)	Acc@5 99.674 (99.549)
Epoch: [132][128/163]	Time 0.129 (0.128)	Data 0.000 (0.003)	Loss 0.5748 (0.6176)	Acc@1 89.577 (87.799)	Acc@5 98.697 (99.528)
Max memory in training epoch: 68.45696
lr: 0.10805530498320397
1

Epoch: [133 | 135] LR: 0.108055
batch Size 307
Epoch: [133][0/163]	Time 0.162 (0.162)	Data 0.311 (0.311)	Loss 0.5548 (0.5548)	Acc@1 89.251 (89.251)	Acc@5 99.674 (99.674)
Epoch: [133][64/163]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 0.5659 (0.6082)	Acc@1 89.902 (88.078)	Acc@5 99.674 (99.534)
Epoch: [133][128/163]	Time 0.128 (0.127)	Data 0.000 (0.003)	Loss 0.6438 (0.6233)	Acc@1 86.319 (87.582)	Acc@5 99.023 (99.535)
Max memory in training epoch: 68.45696
Drin!!
old memory: 712340992
new memory: 684569600
Faktor: 0.9610139072271725
New batch Size größer 300!!
lr: 0.10805530498320397
1

Epoch: [134 | 135] LR: 0.108055
batch Size 300
Epoch: [134][0/163]	Time 0.187 (0.187)	Data 0.304 (0.304)	Loss 0.6054 (0.6054)	Acc@1 87.622 (87.622)	Acc@5 99.349 (99.349)
Epoch: [134][64/163]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.5884 (0.5989)	Acc@1 90.228 (88.614)	Acc@5 99.674 (99.679)
Epoch: [134][128/163]	Time 0.137 (0.130)	Data 0.000 (0.003)	Loss 0.7011 (0.6142)	Acc@1 86.645 (88.067)	Acc@5 99.674 (99.621)
Max memory in training epoch: 68.45696
lr: 0.10805530498320397
1

Epoch: [135 | 135] LR: 0.108055
batch Size 300
Epoch: [135][0/163]	Time 0.190 (0.190)	Data 0.277 (0.277)	Loss 0.6001 (0.6001)	Acc@1 87.622 (87.622)	Acc@5 100.000 (100.000)
Epoch: [135][64/163]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.5787 (0.6046)	Acc@1 90.879 (88.414)	Acc@5 100.000 (99.669)
Epoch: [135][128/163]	Time 0.143 (0.128)	Data 0.000 (0.002)	Loss 0.5931 (0.6155)	Acc@1 86.645 (87.968)	Acc@5 99.674 (99.586)
Max memory in training epoch: 68.45696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 346566 ; 347000 ; 0.9987492795389049
[INFO] Storing checkpoint...
  77.97
Max memory: 86.5760768
 21.224s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4598
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1462272
lr: 0.12662731052719214
1

Epoch: [136 | 140] LR: 0.126627
batch Size 300
Epoch: [136][0/167]	Time 0.169 (0.169)	Data 0.310 (0.310)	Loss 0.5932 (0.5932)	Acc@1 88.000 (88.000)	Acc@5 99.667 (99.667)
Epoch: [136][64/167]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.6554 (0.6144)	Acc@1 87.000 (88.062)	Acc@5 100.000 (99.492)
Epoch: [136][128/167]	Time 0.119 (0.126)	Data 0.000 (0.003)	Loss 0.5674 (0.6484)	Acc@1 90.667 (86.925)	Acc@5 99.667 (99.413)
Max memory in training epoch: 65.0331136
lr: 0.12662731052719214
1

Epoch: [137 | 140] LR: 0.126627
batch Size 300
Epoch: [137][0/167]	Time 0.165 (0.165)	Data 0.329 (0.329)	Loss 0.5889 (0.5889)	Acc@1 89.000 (89.000)	Acc@5 100.000 (100.000)
Epoch: [137][64/167]	Time 0.119 (0.126)	Data 0.000 (0.005)	Loss 0.7065 (0.6492)	Acc@1 85.000 (87.036)	Acc@5 99.000 (99.533)
Epoch: [137][128/167]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.7680 (0.6598)	Acc@1 84.333 (86.897)	Acc@5 99.333 (99.450)
Max memory in training epoch: 65.19296
lr: 0.12662731052719214
1

Epoch: [138 | 140] LR: 0.126627
batch Size 300
Epoch: [138][0/167]	Time 0.192 (0.192)	Data 0.327 (0.327)	Loss 0.6049 (0.6049)	Acc@1 89.333 (89.333)	Acc@5 99.667 (99.667)
Epoch: [138][64/167]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.6945 (0.6566)	Acc@1 83.333 (86.867)	Acc@5 99.000 (99.487)
Epoch: [138][128/167]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.6824 (0.6586)	Acc@1 85.000 (86.806)	Acc@5 99.333 (99.465)
Max memory in training epoch: 65.19296
Drin!!
old memory: 684569600
new memory: 651929600
Faktor: 0.9523204068658614
New batch Size größer 308!!
lr: 0.12662731052719214
1

Epoch: [139 | 140] LR: 0.126627
batch Size 308
Epoch: [139][0/167]	Time 0.168 (0.168)	Data 0.331 (0.331)	Loss 0.6796 (0.6796)	Acc@1 85.667 (85.667)	Acc@5 99.667 (99.667)
Epoch: [139][64/167]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.6508 (0.6539)	Acc@1 86.333 (86.959)	Acc@5 99.667 (99.513)
Epoch: [139][128/167]	Time 0.121 (0.129)	Data 0.000 (0.003)	Loss 0.6832 (0.6490)	Acc@1 86.667 (87.132)	Acc@5 99.333 (99.512)
Max memory in training epoch: 65.19296
lr: 0.12662731052719214
1

Epoch: [140 | 140] LR: 0.126627
batch Size 308
Epoch: [140][0/167]	Time 0.191 (0.191)	Data 0.278 (0.278)	Loss 0.7013 (0.7013)	Acc@1 83.667 (83.667)	Acc@5 99.000 (99.000)
Epoch: [140][64/167]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.6253 (0.6421)	Acc@1 87.333 (87.595)	Acc@5 100.000 (99.503)
Epoch: [140][128/167]	Time 0.117 (0.127)	Data 0.000 (0.002)	Loss 0.5812 (0.6525)	Acc@1 89.667 (87.134)	Acc@5 99.667 (99.463)
Max memory in training epoch: 65.19296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 345924 ; 346566 ; 0.998147538996901
[INFO] Storing checkpoint...
  70.07
Max memory: 86.575616
 21.498s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7386
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.145408
lr: 0.15234848297802805
1

Epoch: [141 | 145] LR: 0.152348
batch Size 308
Epoch: [141][0/163]	Time 0.202 (0.202)	Data 0.299 (0.299)	Loss 0.6652 (0.6652)	Acc@1 85.065 (85.065)	Acc@5 99.675 (99.675)
Epoch: [141][64/163]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.7094 (0.6535)	Acc@1 85.714 (86.758)	Acc@5 100.000 (99.525)
Epoch: [141][128/163]	Time 0.125 (0.121)	Data 0.000 (0.003)	Loss 0.7120 (0.6814)	Acc@1 83.766 (86.019)	Acc@5 99.351 (99.419)
Max memory in training epoch: 66.4503808
lr: 0.15234848297802805
1

Epoch: [142 | 145] LR: 0.152348
batch Size 308
Epoch: [142][0/163]	Time 0.164 (0.164)	Data 0.298 (0.298)	Loss 0.6434 (0.6434)	Acc@1 87.987 (87.987)	Acc@5 99.026 (99.026)
Epoch: [142][64/163]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.5926 (0.6940)	Acc@1 90.584 (86.089)	Acc@5 99.351 (99.416)
Epoch: [142][128/163]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.7118 (0.6960)	Acc@1 84.740 (85.941)	Acc@5 99.026 (99.409)
Max memory in training epoch: 66.3635456
lr: 0.15234848297802805
1

Epoch: [143 | 145] LR: 0.152348
batch Size 308
Epoch: [143][0/163]	Time 0.167 (0.167)	Data 0.307 (0.307)	Loss 0.6499 (0.6499)	Acc@1 87.013 (87.013)	Acc@5 99.351 (99.351)
Epoch: [143][64/163]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.5807 (0.6849)	Acc@1 89.286 (86.139)	Acc@5 99.675 (99.505)
Epoch: [143][128/163]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.7044 (0.6892)	Acc@1 84.091 (86.001)	Acc@5 99.675 (99.456)
Max memory in training epoch: 66.3635456
Drin!!
old memory: 651929600
new memory: 663635456
Faktor: 1.0179557056467448
New batch Size kleiner 313!!
lr: 0.15234848297802805
1

Epoch: [144 | 145] LR: 0.152348
batch Size 313
Epoch: [144][0/163]	Time 0.177 (0.177)	Data 0.298 (0.298)	Loss 0.6876 (0.6876)	Acc@1 85.065 (85.065)	Acc@5 99.675 (99.675)
Epoch: [144][64/163]	Time 0.130 (0.123)	Data 0.000 (0.005)	Loss 0.6101 (0.6801)	Acc@1 90.260 (86.344)	Acc@5 99.026 (99.466)
Epoch: [144][128/163]	Time 0.118 (0.122)	Data 0.000 (0.003)	Loss 0.7280 (0.6836)	Acc@1 85.065 (86.205)	Acc@5 100.000 (99.441)
Max memory in training epoch: 66.3635456
lr: 0.15234848297802805
1

Epoch: [145 | 145] LR: 0.152348
batch Size 313
Epoch: [145][0/163]	Time 0.175 (0.175)	Data 0.290 (0.290)	Loss 0.6546 (0.6546)	Acc@1 86.364 (86.364)	Acc@5 99.351 (99.351)
Epoch: [145][64/163]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.6543 (0.6718)	Acc@1 87.662 (86.658)	Acc@5 99.675 (99.396)
Epoch: [145][128/163]	Time 0.132 (0.121)	Data 0.000 (0.002)	Loss 0.6673 (0.6854)	Acc@1 86.364 (86.094)	Acc@5 99.351 (99.388)
Max memory in training epoch: 66.3635456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  78.88
Max memory: 83.6779008
 20.061s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6784
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.145408
lr: 0.1862698248911046
1

Epoch: [146 | 150] LR: 0.186270
batch Size 313
Epoch: [146][0/160]	Time 0.211 (0.211)	Data 0.277 (0.277)	Loss 0.5622 (0.5622)	Acc@1 89.457 (89.457)	Acc@5 99.681 (99.681)
Epoch: [146][64/160]	Time 0.124 (0.122)	Data 0.000 (0.004)	Loss 0.8337 (0.6919)	Acc@1 79.233 (85.933)	Acc@5 99.361 (99.430)
Epoch: [146][128/160]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.7207 (0.7137)	Acc@1 84.026 (85.445)	Acc@5 99.681 (99.349)
Max memory in training epoch: 66.7807232
lr: 0.1862698248911046
1

Epoch: [147 | 150] LR: 0.186270
batch Size 313
Epoch: [147][0/160]	Time 0.184 (0.184)	Data 0.277 (0.277)	Loss 0.7340 (0.7340)	Acc@1 84.665 (84.665)	Acc@5 99.681 (99.681)
Epoch: [147][64/160]	Time 0.114 (0.124)	Data 0.000 (0.004)	Loss 0.7586 (0.7386)	Acc@1 84.665 (84.655)	Acc@5 98.722 (99.371)
Epoch: [147][128/160]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.7305 (0.7412)	Acc@1 84.026 (84.719)	Acc@5 99.042 (99.294)
Max memory in training epoch: 66.7680256
lr: 0.1862698248911046
1

Epoch: [148 | 150] LR: 0.186270
batch Size 313
Epoch: [148][0/160]	Time 0.166 (0.166)	Data 0.273 (0.273)	Loss 0.6609 (0.6609)	Acc@1 87.220 (87.220)	Acc@5 99.681 (99.681)
Epoch: [148][64/160]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.6944 (0.7183)	Acc@1 86.901 (85.480)	Acc@5 99.681 (99.435)
Epoch: [148][128/160]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6907 (0.7246)	Acc@1 85.304 (85.145)	Acc@5 98.722 (99.386)
Max memory in training epoch: 66.7680256
Drin!!
old memory: 663635456
new memory: 667680256
Faktor: 1.0060949124454255
New batch Size kleiner 314!!
lr: 0.1862698248911046
1

Epoch: [149 | 150] LR: 0.186270
batch Size 314
Epoch: [149][0/160]	Time 0.158 (0.158)	Data 0.303 (0.303)	Loss 0.7158 (0.7158)	Acc@1 83.387 (83.387)	Acc@5 99.361 (99.361)
Epoch: [149][64/160]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.6920 (0.7076)	Acc@1 88.498 (86.016)	Acc@5 99.361 (99.410)
Epoch: [149][128/160]	Time 0.123 (0.124)	Data 0.000 (0.003)	Loss 0.6997 (0.7154)	Acc@1 86.262 (85.559)	Acc@5 99.361 (99.401)
Max memory in training epoch: 66.7680256
lr: 0.1862698248911046
1

Epoch: [150 | 150] LR: 0.018627
batch Size 314
Epoch: [150][0/160]	Time 0.170 (0.170)	Data 0.312 (0.312)	Loss 0.7449 (0.7449)	Acc@1 84.665 (84.665)	Acc@5 99.042 (99.042)
Epoch: [150][64/160]	Time 0.120 (0.125)	Data 0.000 (0.005)	Loss 0.5633 (0.6030)	Acc@1 91.054 (89.403)	Acc@5 100.000 (99.671)
Epoch: [150][128/160]	Time 0.124 (0.123)	Data 0.000 (0.003)	Loss 0.5569 (0.5766)	Acc@1 90.735 (90.254)	Acc@5 99.681 (99.723)
Max memory in training epoch: 66.7680256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 343898 ; 345924 ; 0.994143222210659
[INFO] Storing checkpoint...
  89.97
Max memory: 83.6779008
 20.051s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5537
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1446912
lr: 0.02284715820929955
1

Epoch: [151 | 155] LR: 0.022847
batch Size 314
Epoch: [151][0/160]	Time 0.213 (0.213)	Data 0.275 (0.275)	Loss 0.5380 (0.5380)	Acc@1 90.127 (90.127)	Acc@5 99.682 (99.682)
Epoch: [151][64/160]	Time 0.124 (0.124)	Data 0.000 (0.004)	Loss 0.5511 (0.5117)	Acc@1 89.172 (92.249)	Acc@5 100.000 (99.853)
Epoch: [151][128/160]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.5201 (0.5073)	Acc@1 91.401 (92.310)	Acc@5 99.682 (99.835)
Max memory in training epoch: 65.9902464
lr: 0.02284715820929955
1

Epoch: [152 | 155] LR: 0.022847
batch Size 314
Epoch: [152][0/160]	Time 0.165 (0.165)	Data 0.278 (0.278)	Loss 0.5438 (0.5438)	Acc@1 91.083 (91.083)	Acc@5 100.000 (100.000)
Epoch: [152][64/160]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.4898 (0.4783)	Acc@1 91.401 (92.959)	Acc@5 100.000 (99.853)
Epoch: [152][128/160]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.5146 (0.4741)	Acc@1 90.764 (93.060)	Acc@5 100.000 (99.872)
Max memory in training epoch: 66.1159424
lr: 0.02284715820929955
1

Epoch: [153 | 155] LR: 0.022847
batch Size 314
Epoch: [153][0/160]	Time 0.189 (0.189)	Data 0.291 (0.291)	Loss 0.4848 (0.4848)	Acc@1 91.720 (91.720)	Acc@5 100.000 (100.000)
Epoch: [153][64/160]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.4586 (0.4567)	Acc@1 93.949 (93.523)	Acc@5 100.000 (99.868)
Epoch: [153][128/160]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.4766 (0.4532)	Acc@1 91.401 (93.576)	Acc@5 99.682 (99.864)
Max memory in training epoch: 66.1159424
Drin!!
old memory: 667680256
new memory: 661159424
Faktor: 0.9902336006772678
New batch Size größer 318!!
lr: 0.02284715820929955
1

Epoch: [154 | 155] LR: 0.022847
batch Size 318
Epoch: [154][0/160]	Time 0.177 (0.177)	Data 0.285 (0.285)	Loss 0.4273 (0.4273)	Acc@1 95.223 (95.223)	Acc@5 100.000 (100.000)
Epoch: [154][64/160]	Time 0.115 (0.124)	Data 0.000 (0.005)	Loss 0.4651 (0.4317)	Acc@1 92.675 (94.125)	Acc@5 100.000 (99.912)
Epoch: [154][128/160]	Time 0.129 (0.123)	Data 0.000 (0.002)	Loss 0.4591 (0.4336)	Acc@1 92.357 (93.976)	Acc@5 100.000 (99.914)
Max memory in training epoch: 66.1159424
lr: 0.02284715820929955
1

Epoch: [155 | 155] LR: 0.022847
batch Size 318
Epoch: [155][0/160]	Time 0.168 (0.168)	Data 0.278 (0.278)	Loss 0.4020 (0.4020)	Acc@1 94.904 (94.904)	Acc@5 99.682 (99.682)
Epoch: [155][64/160]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.3803 (0.4165)	Acc@1 96.178 (94.424)	Acc@5 100.000 (99.917)
Epoch: [155][128/160]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.4190 (0.4168)	Acc@1 92.675 (94.230)	Acc@5 100.000 (99.896)
Max memory in training epoch: 66.1159424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.49
Max memory: 83.0466048
 19.629s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9729
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1446912
lr: 0.028380454338114283
1

Epoch: [156 | 160] LR: 0.028380
batch Size 318
Epoch: [156][0/158]	Time 0.199 (0.199)	Data 0.305 (0.305)	Loss 0.3871 (0.3871)	Acc@1 95.283 (95.283)	Acc@5 100.000 (100.000)
Epoch: [156][64/158]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.4091 (0.4000)	Acc@1 93.711 (94.620)	Acc@5 100.000 (99.884)
Epoch: [156][128/158]	Time 0.118 (0.123)	Data 0.000 (0.003)	Loss 0.3964 (0.4094)	Acc@1 94.025 (94.245)	Acc@5 100.000 (99.890)
Max memory in training epoch: 66.2593024
lr: 0.028380454338114283
1

Epoch: [157 | 160] LR: 0.028380
batch Size 318
Epoch: [157][0/158]	Time 0.175 (0.175)	Data 0.321 (0.321)	Loss 0.4066 (0.4066)	Acc@1 94.654 (94.654)	Acc@5 100.000 (100.000)
Epoch: [157][64/158]	Time 0.127 (0.124)	Data 0.000 (0.005)	Loss 0.4277 (0.3995)	Acc@1 93.711 (94.465)	Acc@5 100.000 (99.927)
Epoch: [157][128/158]	Time 0.118 (0.123)	Data 0.000 (0.003)	Loss 0.4086 (0.4009)	Acc@1 93.711 (94.374)	Acc@5 99.686 (99.920)
Max memory in training epoch: 66.4038912
lr: 0.028380454338114283
1

Epoch: [158 | 160] LR: 0.028380
batch Size 318
Epoch: [158][0/158]	Time 0.184 (0.184)	Data 0.299 (0.299)	Loss 0.3978 (0.3978)	Acc@1 94.654 (94.654)	Acc@5 100.000 (100.000)
Epoch: [158][64/158]	Time 0.127 (0.124)	Data 0.000 (0.005)	Loss 0.4008 (0.3984)	Acc@1 94.654 (94.204)	Acc@5 99.686 (99.908)
Epoch: [158][128/158]	Time 0.124 (0.124)	Data 0.000 (0.003)	Loss 0.4465 (0.3980)	Acc@1 92.453 (94.071)	Acc@5 99.686 (99.900)
Max memory in training epoch: 66.4038912
Drin!!
old memory: 661159424
new memory: 664038912
Faktor: 1.0043552097958146
New batch Size kleiner 319!!
lr: 0.028380454338114283
1

Epoch: [159 | 160] LR: 0.028380
batch Size 319
Epoch: [159][0/158]	Time 0.176 (0.176)	Data 0.305 (0.305)	Loss 0.3583 (0.3583)	Acc@1 96.855 (96.855)	Acc@5 99.686 (99.686)
Epoch: [159][64/158]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 0.3668 (0.3915)	Acc@1 95.912 (94.170)	Acc@5 100.000 (99.879)
Epoch: [159][128/158]	Time 0.116 (0.123)	Data 0.000 (0.003)	Loss 0.4777 (0.3897)	Acc@1 90.252 (94.191)	Acc@5 99.686 (99.910)
Max memory in training epoch: 66.4038912
lr: 0.028380454338114283
1

Epoch: [160 | 160] LR: 0.028380
batch Size 319
Epoch: [160][0/158]	Time 0.164 (0.164)	Data 0.293 (0.293)	Loss 0.3674 (0.3674)	Acc@1 94.025 (94.025)	Acc@5 100.000 (100.000)
Epoch: [160][64/158]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.4218 (0.3880)	Acc@1 94.025 (94.359)	Acc@5 99.686 (99.889)
Epoch: [160][128/158]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3051 (0.3877)	Acc@1 97.484 (94.218)	Acc@5 100.000 (99.900)
Max memory in training epoch: 66.4038912
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 342744 ; 343898 ; 0.9966443538491064
[INFO] Storing checkpoint...
  89.05
Max memory: 83.2444416
 19.744s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5140
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1442816
lr: 0.03536470677288459
1

Epoch: [161 | 165] LR: 0.035365
batch Size 319
Epoch: [161][0/157]	Time 0.193 (0.193)	Data 0.313 (0.313)	Loss 0.4136 (0.4136)	Acc@1 92.790 (92.790)	Acc@5 99.687 (99.687)
Epoch: [161][64/157]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.4568 (0.3827)	Acc@1 92.476 (94.174)	Acc@5 100.000 (99.928)
Epoch: [161][128/157]	Time 0.123 (0.125)	Data 0.000 (0.003)	Loss 0.4029 (0.3944)	Acc@1 93.730 (93.726)	Acc@5 100.000 (99.913)
Max memory in training epoch: 66.5229824
lr: 0.03536470677288459
1

Epoch: [162 | 165] LR: 0.035365
batch Size 319
Epoch: [162][0/157]	Time 0.158 (0.158)	Data 0.309 (0.309)	Loss 0.4299 (0.4299)	Acc@1 92.790 (92.790)	Acc@5 99.373 (99.373)
Epoch: [162][64/157]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.3783 (0.3970)	Acc@1 94.044 (93.562)	Acc@5 100.000 (99.894)
Epoch: [162][128/157]	Time 0.116 (0.123)	Data 0.000 (0.003)	Loss 0.3908 (0.4000)	Acc@1 93.103 (93.368)	Acc@5 100.000 (99.886)
Max memory in training epoch: 66.562816
lr: 0.03536470677288459
1

Epoch: [163 | 165] LR: 0.035365
batch Size 319
Epoch: [163][0/157]	Time 0.157 (0.157)	Data 0.275 (0.275)	Loss 0.4322 (0.4322)	Acc@1 92.476 (92.476)	Acc@5 100.000 (100.000)
Epoch: [163][64/157]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.3728 (0.3926)	Acc@1 94.671 (93.701)	Acc@5 99.687 (99.875)
Epoch: [163][128/157]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3807 (0.4003)	Acc@1 94.044 (93.368)	Acc@5 100.000 (99.866)
Max memory in training epoch: 66.562816
Drin!!
old memory: 664038912
new memory: 665628160
Faktor: 1.0023933055296614
New batch Size kleiner 319!!
lr: 0.03536470677288459
1

Epoch: [164 | 165] LR: 0.035365
batch Size 319
Epoch: [164][0/157]	Time 0.169 (0.169)	Data 0.277 (0.277)	Loss 0.3627 (0.3627)	Acc@1 95.298 (95.298)	Acc@5 100.000 (100.000)
Epoch: [164][64/157]	Time 0.120 (0.125)	Data 0.000 (0.004)	Loss 0.4257 (0.3955)	Acc@1 93.103 (93.595)	Acc@5 99.687 (99.884)
Epoch: [164][128/157]	Time 0.147 (0.124)	Data 0.000 (0.002)	Loss 0.3678 (0.4020)	Acc@1 94.357 (93.237)	Acc@5 100.000 (99.905)
Max memory in training epoch: 66.562816
lr: 0.03536470677288459
1

Epoch: [165 | 165] LR: 0.035365
batch Size 319
Epoch: [165][0/157]	Time 0.176 (0.176)	Data 0.319 (0.319)	Loss 0.3663 (0.3663)	Acc@1 94.671 (94.671)	Acc@5 100.000 (100.000)
Epoch: [165][64/157]	Time 0.118 (0.125)	Data 0.000 (0.005)	Loss 0.3797 (0.3964)	Acc@1 92.163 (93.374)	Acc@5 100.000 (99.889)
Epoch: [165][128/157]	Time 0.124 (0.124)	Data 0.000 (0.003)	Loss 0.3901 (0.3994)	Acc@1 94.357 (93.184)	Acc@5 100.000 (99.900)
Max memory in training epoch: 66.562816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  86.99
Max memory: 83.0570496
 19.798s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5262
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1442816
lr: 0.04406774008027416
1

Epoch: [166 | 170] LR: 0.044068
batch Size 319
Epoch: [166][0/157]	Time 0.203 (0.203)	Data 0.273 (0.273)	Loss 0.4182 (0.4182)	Acc@1 93.730 (93.730)	Acc@5 100.000 (100.000)
Epoch: [166][64/157]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.4021 (0.4042)	Acc@1 93.417 (93.041)	Acc@5 100.000 (99.875)
Epoch: [166][128/157]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.4805 (0.4271)	Acc@1 89.655 (92.275)	Acc@5 99.687 (99.825)
Max memory in training epoch: 66.5229824
lr: 0.04406774008027416
1

Epoch: [167 | 170] LR: 0.044068
batch Size 319
Epoch: [167][0/157]	Time 0.188 (0.188)	Data 0.323 (0.323)	Loss 0.4089 (0.4089)	Acc@1 92.790 (92.790)	Acc@5 100.000 (100.000)
Epoch: [167][64/157]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.4758 (0.4284)	Acc@1 89.342 (92.341)	Acc@5 100.000 (99.865)
Epoch: [167][128/157]	Time 0.120 (0.121)	Data 0.000 (0.003)	Loss 0.4508 (0.4407)	Acc@1 91.850 (91.905)	Acc@5 100.000 (99.825)
Max memory in training epoch: 66.562816
lr: 0.04406774008027416
1

Epoch: [168 | 170] LR: 0.044068
batch Size 319
Epoch: [168][0/157]	Time 0.167 (0.167)	Data 0.334 (0.334)	Loss 0.3798 (0.3798)	Acc@1 94.357 (94.357)	Acc@5 100.000 (100.000)
Epoch: [168][64/157]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.4998 (0.4295)	Acc@1 89.028 (92.366)	Acc@5 99.687 (99.831)
Epoch: [168][128/157]	Time 0.129 (0.125)	Data 0.000 (0.003)	Loss 0.4421 (0.4408)	Acc@1 92.790 (91.935)	Acc@5 99.687 (99.830)
Max memory in training epoch: 66.562816
Drin!!
old memory: 665628160
new memory: 665628160
Faktor: 1.0
lr: 0.04406774008027416
1

Epoch: [169 | 170] LR: 0.044068
batch Size 319
Epoch: [169][0/157]	Time 0.177 (0.177)	Data 0.308 (0.308)	Loss 0.4326 (0.4326)	Acc@1 92.163 (92.163)	Acc@5 100.000 (100.000)
Epoch: [169][64/157]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.4862 (0.4324)	Acc@1 91.536 (92.361)	Acc@5 99.373 (99.831)
Epoch: [169][128/157]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.4679 (0.4441)	Acc@1 91.223 (91.952)	Acc@5 100.000 (99.823)
Max memory in training epoch: 66.562816
lr: 0.04406774008027416
1

Epoch: [170 | 170] LR: 0.044068
batch Size 319
Epoch: [170][0/157]	Time 0.178 (0.178)	Data 0.333 (0.333)	Loss 0.4421 (0.4421)	Acc@1 91.536 (91.536)	Acc@5 100.000 (100.000)
Epoch: [170][64/157]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.4501 (0.4348)	Acc@1 92.476 (92.235)	Acc@5 99.373 (99.841)
Epoch: [170][128/157]	Time 0.125 (0.122)	Data 0.000 (0.003)	Loss 0.4785 (0.4433)	Acc@1 89.342 (91.876)	Acc@5 99.687 (99.832)
Max memory in training epoch: 66.562816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  86.15
Max memory: 83.0570496
 19.656s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2783
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1442816
lr: 0.054912535490654134
1

Epoch: [171 | 175] LR: 0.054913
batch Size 319
Epoch: [171][0/157]	Time 0.184 (0.184)	Data 0.317 (0.317)	Loss 0.4308 (0.4308)	Acc@1 91.850 (91.850)	Acc@5 99.687 (99.687)
Epoch: [171][64/157]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.4410 (0.4450)	Acc@1 91.223 (91.956)	Acc@5 100.000 (99.812)
Epoch: [171][128/157]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.4875 (0.4680)	Acc@1 92.163 (91.218)	Acc@5 100.000 (99.745)
Max memory in training epoch: 66.5229824
lr: 0.054912535490654134
1

Epoch: [172 | 175] LR: 0.054913
batch Size 319
Epoch: [172][0/157]	Time 0.195 (0.195)	Data 0.293 (0.293)	Loss 0.4215 (0.4215)	Acc@1 92.476 (92.476)	Acc@5 99.687 (99.687)
Epoch: [172][64/157]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.5042 (0.4845)	Acc@1 89.969 (90.504)	Acc@5 99.687 (99.812)
Epoch: [172][128/157]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.4709 (0.4937)	Acc@1 91.223 (90.275)	Acc@5 99.687 (99.752)
Max memory in training epoch: 66.562816
lr: 0.054912535490654134
1

Epoch: [173 | 175] LR: 0.054913
batch Size 319
Epoch: [173][0/157]	Time 0.145 (0.145)	Data 0.329 (0.329)	Loss 0.4825 (0.4825)	Acc@1 90.596 (90.596)	Acc@5 100.000 (100.000)
Epoch: [173][64/157]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.4747 (0.4828)	Acc@1 90.596 (90.803)	Acc@5 99.687 (99.788)
Epoch: [173][128/157]	Time 0.127 (0.125)	Data 0.000 (0.003)	Loss 0.5474 (0.4815)	Acc@1 88.088 (90.892)	Acc@5 100.000 (99.774)
Max memory in training epoch: 66.562816
Drin!!
old memory: 665628160
new memory: 665628160
Faktor: 1.0
lr: 0.054912535490654134
1

Epoch: [174 | 175] LR: 0.054913
batch Size 319
Epoch: [174][0/157]	Time 0.170 (0.170)	Data 0.310 (0.310)	Loss 0.4085 (0.4085)	Acc@1 92.476 (92.476)	Acc@5 100.000 (100.000)
Epoch: [174][64/157]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.4609 (0.4652)	Acc@1 92.163 (91.353)	Acc@5 99.687 (99.850)
Epoch: [174][128/157]	Time 0.122 (0.123)	Data 0.000 (0.003)	Loss 0.4741 (0.4758)	Acc@1 90.909 (90.987)	Acc@5 100.000 (99.813)
Max memory in training epoch: 66.562816
lr: 0.054912535490654134
1

Epoch: [175 | 175] LR: 0.054913
batch Size 319
Epoch: [175][0/157]	Time 0.168 (0.168)	Data 0.292 (0.292)	Loss 0.4615 (0.4615)	Acc@1 90.596 (90.596)	Acc@5 99.687 (99.687)
Epoch: [175][64/157]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.4157 (0.4798)	Acc@1 93.103 (91.025)	Acc@5 100.000 (99.744)
Epoch: [175][128/157]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.4562 (0.4831)	Acc@1 91.536 (90.885)	Acc@5 99.687 (99.774)
Max memory in training epoch: 66.562816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  85.09
Max memory: 83.0570496
 19.634s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8482
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1442816
lr: 0.0684261672715573
1

Epoch: [176 | 180] LR: 0.068426
batch Size 319
Epoch: [176][0/157]	Time 0.184 (0.184)	Data 0.297 (0.297)	Loss 0.4407 (0.4407)	Acc@1 93.103 (93.103)	Acc@5 99.373 (99.373)
Epoch: [176][64/157]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.5131 (0.4796)	Acc@1 90.596 (91.121)	Acc@5 99.687 (99.744)
Epoch: [176][128/157]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.5011 (0.5051)	Acc@1 90.596 (90.350)	Acc@5 99.687 (99.699)
Max memory in training epoch: 66.5229824
lr: 0.0684261672715573
1

Epoch: [177 | 180] LR: 0.068426
batch Size 319
Epoch: [177][0/157]	Time 0.177 (0.177)	Data 0.300 (0.300)	Loss 0.5351 (0.5351)	Acc@1 90.909 (90.909)	Acc@5 99.373 (99.373)
Epoch: [177][64/157]	Time 0.142 (0.123)	Data 0.000 (0.005)	Loss 0.5339 (0.5180)	Acc@1 88.088 (89.983)	Acc@5 100.000 (99.691)
Epoch: [177][128/157]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.5730 (0.5264)	Acc@1 89.342 (89.716)	Acc@5 99.687 (99.679)
Max memory in training epoch: 66.562816
lr: 0.0684261672715573
1

Epoch: [178 | 180] LR: 0.068426
batch Size 319
Epoch: [178][0/157]	Time 0.177 (0.177)	Data 0.318 (0.318)	Loss 0.5601 (0.5601)	Acc@1 89.342 (89.342)	Acc@5 100.000 (100.000)
Epoch: [178][64/157]	Time 0.130 (0.127)	Data 0.000 (0.005)	Loss 0.4566 (0.5111)	Acc@1 92.790 (90.152)	Acc@5 100.000 (99.769)
Epoch: [178][128/157]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.5308 (0.5163)	Acc@1 90.909 (90.178)	Acc@5 99.373 (99.721)
Max memory in training epoch: 66.562816
Drin!!
old memory: 665628160
new memory: 665628160
Faktor: 1.0
lr: 0.0684261672715573
1

Epoch: [179 | 180] LR: 0.068426
batch Size 319
Epoch: [179][0/157]	Time 0.210 (0.210)	Data 0.360 (0.360)	Loss 0.5482 (0.5482)	Acc@1 90.596 (90.596)	Acc@5 99.373 (99.373)
Epoch: [179][64/157]	Time 0.117 (0.125)	Data 0.000 (0.006)	Loss 0.6068 (0.5182)	Acc@1 87.461 (90.186)	Acc@5 99.687 (99.744)
Epoch: [179][128/157]	Time 0.122 (0.125)	Data 0.000 (0.003)	Loss 0.5042 (0.5197)	Acc@1 90.909 (90.139)	Acc@5 100.000 (99.745)
Max memory in training epoch: 66.562816
lr: 0.0684261672715573
1

Epoch: [180 | 180] LR: 0.068426
batch Size 319
Epoch: [180][0/157]	Time 0.168 (0.168)	Data 0.311 (0.311)	Loss 0.4408 (0.4408)	Acc@1 93.103 (93.103)	Acc@5 99.687 (99.687)
Epoch: [180][64/157]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.4765 (0.4970)	Acc@1 92.790 (90.967)	Acc@5 100.000 (99.740)
Epoch: [180][128/157]	Time 0.160 (0.123)	Data 0.000 (0.003)	Loss 0.5792 (0.5121)	Acc@1 87.774 (90.285)	Acc@5 99.373 (99.747)
Max memory in training epoch: 66.562816
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 29, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(15, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(53, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  83.8
Max memory: 83.0570496
 19.699s  BSize 5
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 584
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
batch_size berechnet: 250;389.1 ; lr: 0.1
lr: 0.09765625
1

Epoch: [1 | 5] LR: 0.097656
batch Size 250
Epoch: [1][0/200]	Time 0.179 (0.179)	Data 0.289 (0.289)	Loss 3.2322 (3.2322)	Acc@1 12.800 (12.800)	Acc@5 48.800 (48.800)
Epoch: [1][64/200]	Time 0.120 (0.127)	Data 0.000 (0.005)	Loss 2.4279 (2.5897)	Acc@1 33.200 (26.677)	Acc@5 86.400 (79.846)
Epoch: [1][128/200]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 2.3055 (2.4438)	Acc@1 34.800 (31.395)	Acc@5 88.000 (84.276)
Epoch: [1][192/200]	Time 0.130 (0.126)	Data 0.000 (0.002)	Loss 1.9213 (2.3281)	Acc@1 51.200 (35.743)	Acc@5 94.000 (86.730)
Max memory in training epoch: 66.4657408
lr: 0.09765625
1

Epoch: [2 | 5] LR: 0.097656
batch Size 250
Epoch: [2][0/200]	Time 0.157 (0.157)	Data 0.280 (0.280)	Loss 2.1091 (2.1091)	Acc@1 44.400 (44.400)	Acc@5 91.600 (91.600)
Epoch: [2][64/200]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 1.8512 (1.8940)	Acc@1 56.800 (51.360)	Acc@5 94.000 (93.865)
Epoch: [2][128/200]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 1.6451 (1.8020)	Acc@1 58.800 (54.611)	Acc@5 96.000 (94.648)
Epoch: [2][192/200]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 1.4947 (1.7452)	Acc@1 65.200 (56.466)	Acc@5 97.600 (95.057)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [3 | 5] LR: 0.097656
batch Size 250
Epoch: [3][0/200]	Time 0.161 (0.161)	Data 0.297 (0.297)	Loss 1.4042 (1.4042)	Acc@1 66.800 (66.800)	Acc@5 97.200 (97.200)
Epoch: [3][64/200]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 1.4161 (1.4999)	Acc@1 65.200 (64.351)	Acc@5 98.400 (96.757)
Epoch: [3][128/200]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 1.4878 (1.4583)	Acc@1 64.400 (65.851)	Acc@5 96.000 (97.029)
Epoch: [3][192/200]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 1.3875 (1.4277)	Acc@1 65.600 (66.682)	Acc@5 98.000 (97.200)
Max memory in training epoch: 66.0135424
Drin!!
old memory: 0
new memory: 660135424
lr: 0.09765625
1

Epoch: [4 | 5] LR: 0.097656
batch Size 250
Epoch: [4][0/200]	Time 0.163 (0.163)	Data 0.302 (0.302)	Loss 1.3450 (1.3450)	Acc@1 66.400 (66.400)	Acc@5 97.600 (97.600)
Epoch: [4][64/200]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 1.2996 (1.2775)	Acc@1 70.400 (71.151)	Acc@5 97.200 (97.932)
Epoch: [4][128/200]	Time 0.127 (0.127)	Data 0.000 (0.003)	Loss 1.1484 (1.2512)	Acc@1 74.000 (71.851)	Acc@5 98.400 (98.016)
Epoch: [4][192/200]	Time 0.141 (0.127)	Data 0.000 (0.002)	Loss 1.1150 (1.2324)	Acc@1 74.400 (72.025)	Acc@5 98.400 (98.147)
Max memory in training epoch: 66.0135424
lr: 0.09765625
1

Epoch: [5 | 5] LR: 0.097656
batch Size 250
Epoch: [5][0/200]	Time 0.182 (0.182)	Data 0.262 (0.262)	Loss 1.1964 (1.1964)	Acc@1 72.400 (72.400)	Acc@5 99.200 (99.200)
Epoch: [5][64/200]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 1.0256 (1.1233)	Acc@1 78.000 (75.188)	Acc@5 98.800 (98.474)
Epoch: [5][128/200]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 1.0810 (1.1028)	Acc@1 77.200 (75.647)	Acc@5 97.200 (98.456)
Epoch: [5][192/200]	Time 0.130 (0.126)	Data 0.000 (0.002)	Loss 1.1397 (1.0862)	Acc@1 74.000 (76.106)	Acc@5 96.800 (98.526)
Max memory in training epoch: 66.0135424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  69.6
Max memory: 103.3835008
 25.631s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2257
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.095367431640625
1

Epoch: [6 | 10] LR: 0.095367
batch Size 250
Epoch: [6][0/200]	Time 0.203 (0.203)	Data 0.256 (0.256)	Loss 1.0037 (1.0037)	Acc@1 80.000 (80.000)	Acc@5 99.200 (99.200)
Epoch: [6][64/200]	Time 0.135 (0.133)	Data 0.000 (0.004)	Loss 1.1111 (1.0074)	Acc@1 76.400 (78.302)	Acc@5 97.200 (98.677)
Epoch: [6][128/200]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.9686 (1.0031)	Acc@1 79.600 (78.282)	Acc@5 98.800 (98.664)
Epoch: [6][192/200]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.9001 (0.9991)	Acc@1 79.200 (78.172)	Acc@5 99.200 (98.694)
Max memory in training epoch: 66.4656384
lr: 0.095367431640625
1

Epoch: [7 | 10] LR: 0.095367
batch Size 250
Epoch: [7][0/200]	Time 0.183 (0.183)	Data 0.276 (0.276)	Loss 0.9317 (0.9317)	Acc@1 80.000 (80.000)	Acc@5 98.400 (98.400)
Epoch: [7][64/200]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.9005 (0.9489)	Acc@1 79.200 (79.342)	Acc@5 99.600 (98.911)
Epoch: [7][128/200]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8725 (0.9415)	Acc@1 80.400 (79.510)	Acc@5 99.200 (98.862)
Epoch: [7][192/200]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.9709 (0.9358)	Acc@1 76.000 (79.546)	Acc@5 98.400 (98.906)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [8 | 10] LR: 0.095367
batch Size 250
Epoch: [8][0/200]	Time 0.187 (0.187)	Data 0.292 (0.292)	Loss 0.8347 (0.8347)	Acc@1 82.000 (82.000)	Acc@5 100.000 (100.000)
Epoch: [8][64/200]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.9182 (0.8961)	Acc@1 81.600 (80.671)	Acc@5 99.200 (98.849)
Epoch: [8][128/200]	Time 0.150 (0.130)	Data 0.000 (0.002)	Loss 0.8813 (0.9053)	Acc@1 82.800 (80.022)	Acc@5 98.000 (98.868)
Epoch: [8][192/200]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7871 (0.8989)	Acc@1 82.000 (80.073)	Acc@5 99.600 (98.910)
Max memory in training epoch: 66.01344
Drin!!
old memory: 660135424
new memory: 660134400
Faktor: 0.9999984488031353
New batch Size größer 253!!
lr: 0.095367431640625
1

Epoch: [9 | 10] LR: 0.095367
batch Size 253
Epoch: [9][0/200]	Time 0.176 (0.176)	Data 0.268 (0.268)	Loss 0.7496 (0.7496)	Acc@1 85.600 (85.600)	Acc@5 99.600 (99.600)
Epoch: [9][64/200]	Time 0.124 (0.129)	Data 0.000 (0.004)	Loss 0.8519 (0.8570)	Acc@1 82.000 (81.465)	Acc@5 98.000 (99.003)
Epoch: [9][128/200]	Time 0.139 (0.129)	Data 0.000 (0.002)	Loss 0.8189 (0.8627)	Acc@1 83.200 (81.237)	Acc@5 99.200 (99.008)
Epoch: [9][192/200]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8697 (0.8628)	Acc@1 79.600 (81.206)	Acc@5 98.800 (98.989)
Max memory in training epoch: 66.01344
lr: 0.095367431640625
1

Epoch: [10 | 10] LR: 0.095367
batch Size 253
Epoch: [10][0/200]	Time 0.160 (0.160)	Data 0.311 (0.311)	Loss 0.7921 (0.7921)	Acc@1 84.800 (84.800)	Acc@5 99.600 (99.600)
Epoch: [10][64/200]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.8811 (0.8346)	Acc@1 79.200 (81.895)	Acc@5 99.200 (99.065)
Epoch: [10][128/200]	Time 0.139 (0.134)	Data 0.000 (0.003)	Loss 0.9401 (0.8384)	Acc@1 78.000 (81.526)	Acc@5 98.000 (99.079)
Epoch: [10][192/200]	Time 0.128 (0.133)	Data 0.000 (0.002)	Loss 0.7217 (0.8334)	Acc@1 88.400 (81.714)	Acc@5 99.600 (99.074)
Max memory in training epoch: 66.01344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  75.0
Max memory: 103.3833984
 27.010s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2926
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.09424984455108643
1

Epoch: [11 | 15] LR: 0.094250
batch Size 253
Epoch: [11][0/198]	Time 0.191 (0.191)	Data 0.279 (0.279)	Loss 0.8959 (0.8959)	Acc@1 79.447 (79.447)	Acc@5 98.814 (98.814)
Epoch: [11][64/198]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.8893 (0.7902)	Acc@1 81.818 (82.949)	Acc@5 98.024 (99.191)
Epoch: [11][128/198]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7747 (0.8091)	Acc@1 83.004 (82.367)	Acc@5 99.605 (99.148)
Epoch: [11][192/198]	Time 0.139 (0.131)	Data 0.000 (0.002)	Loss 0.7980 (0.8085)	Acc@1 83.399 (82.308)	Acc@5 99.209 (99.146)
Max memory in training epoch: 66.5037312
lr: 0.09424984455108643
1

Epoch: [12 | 15] LR: 0.094250
batch Size 253
Epoch: [12][0/198]	Time 0.171 (0.171)	Data 0.255 (0.255)	Loss 0.6553 (0.6553)	Acc@1 87.352 (87.352)	Acc@5 98.814 (98.814)
Epoch: [12][64/198]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 0.8307 (0.7814)	Acc@1 83.794 (83.442)	Acc@5 99.209 (99.240)
Epoch: [12][128/198]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.7733 (0.7873)	Acc@1 81.028 (83.102)	Acc@5 98.814 (99.246)
Epoch: [12][192/198]	Time 0.143 (0.131)	Data 0.000 (0.001)	Loss 0.8795 (0.7962)	Acc@1 80.237 (82.795)	Acc@5 98.814 (99.187)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [13 | 15] LR: 0.094250
batch Size 253
Epoch: [13][0/198]	Time 0.164 (0.164)	Data 0.285 (0.285)	Loss 0.8616 (0.8616)	Acc@1 81.423 (81.423)	Acc@5 99.605 (99.605)
Epoch: [13][64/198]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7393 (0.7737)	Acc@1 85.771 (83.290)	Acc@5 98.814 (99.222)
Epoch: [13][128/198]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7139 (0.7900)	Acc@1 87.352 (82.771)	Acc@5 99.209 (99.151)
Epoch: [13][192/198]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.8444 (0.7896)	Acc@1 80.237 (82.811)	Acc@5 99.209 (99.154)
Max memory in training epoch: 66.277632
Drin!!
old memory: 660134400
new memory: 662776320
Faktor: 1.0040020941190158
New batch Size kleiner 254!!
lr: 0.09424984455108643
1

Epoch: [14 | 15] LR: 0.094250
batch Size 254
Epoch: [14][0/198]	Time 0.175 (0.175)	Data 0.303 (0.303)	Loss 0.6678 (0.6678)	Acc@1 87.747 (87.747)	Acc@5 99.605 (99.605)
Epoch: [14][64/198]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8620 (0.7656)	Acc@1 78.656 (83.946)	Acc@5 98.814 (99.295)
Epoch: [14][128/198]	Time 0.134 (0.131)	Data 0.000 (0.003)	Loss 0.8364 (0.7840)	Acc@1 84.190 (83.267)	Acc@5 98.024 (99.182)
Epoch: [14][192/198]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7170 (0.7831)	Acc@1 85.375 (83.285)	Acc@5 99.605 (99.175)
Max memory in training epoch: 66.277632
lr: 0.09424984455108643
1

Epoch: [15 | 15] LR: 0.094250
batch Size 254
Epoch: [15][0/198]	Time 0.158 (0.158)	Data 0.316 (0.316)	Loss 0.7484 (0.7484)	Acc@1 86.166 (86.166)	Acc@5 99.605 (99.605)
Epoch: [15][64/198]	Time 0.123 (0.131)	Data 0.000 (0.005)	Loss 0.7841 (0.7625)	Acc@1 81.423 (83.758)	Acc@5 98.814 (99.191)
Epoch: [15][128/198]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.7162 (0.7615)	Acc@1 86.957 (83.724)	Acc@5 99.209 (99.240)
Epoch: [15][192/198]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.7117 (0.7681)	Acc@1 86.561 (83.516)	Acc@5 100.000 (99.191)
Max memory in training epoch: 66.277632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.23
Max memory: 103.3833984
 26.119s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7901
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.09351351764053106
1

Epoch: [16 | 20] LR: 0.093514
batch Size 254
Epoch: [16][0/197]	Time 0.180 (0.180)	Data 0.287 (0.287)	Loss 0.7827 (0.7827)	Acc@1 81.890 (81.890)	Acc@5 100.000 (100.000)
Epoch: [16][64/197]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7443 (0.7467)	Acc@1 83.858 (84.167)	Acc@5 99.213 (99.412)
Epoch: [16][128/197]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7958 (0.7574)	Acc@1 80.315 (83.916)	Acc@5 99.606 (99.332)
Epoch: [16][192/197]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.8030 (0.7598)	Acc@1 81.496 (83.901)	Acc@5 98.425 (99.251)
Max memory in training epoch: 66.5164288
lr: 0.09351351764053106
1

Epoch: [17 | 20] LR: 0.093514
batch Size 254
Epoch: [17][0/197]	Time 0.183 (0.183)	Data 0.301 (0.301)	Loss 0.7089 (0.7089)	Acc@1 85.039 (85.039)	Acc@5 99.606 (99.606)
Epoch: [17][64/197]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.7676 (0.7469)	Acc@1 81.890 (84.040)	Acc@5 98.819 (99.310)
Epoch: [17][128/197]	Time 0.133 (0.129)	Data 0.000 (0.003)	Loss 0.7978 (0.7590)	Acc@1 81.496 (83.645)	Acc@5 99.606 (99.286)
Epoch: [17][192/197]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7140 (0.7594)	Acc@1 85.433 (83.736)	Acc@5 99.606 (99.266)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [18 | 20] LR: 0.093514
batch Size 254
Epoch: [18][0/197]	Time 0.174 (0.174)	Data 0.317 (0.317)	Loss 0.7267 (0.7267)	Acc@1 85.433 (85.433)	Acc@5 98.425 (98.425)
Epoch: [18][64/197]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7256 (0.7300)	Acc@1 85.039 (84.985)	Acc@5 100.000 (99.370)
Epoch: [18][128/197]	Time 0.121 (0.129)	Data 0.000 (0.003)	Loss 0.6984 (0.7513)	Acc@1 83.465 (84.194)	Acc@5 99.606 (99.280)
Epoch: [18][192/197]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7455 (0.7537)	Acc@1 84.252 (84.109)	Acc@5 99.606 (99.288)
Max memory in training epoch: 66.365696
Drin!!
old memory: 662776320
new memory: 663656960
Faktor: 1.0013287137355782
New batch Size kleiner 254!!
lr: 0.09351351764053106
1

Epoch: [19 | 20] LR: 0.093514
batch Size 254
Epoch: [19][0/197]	Time 0.183 (0.183)	Data 0.266 (0.266)	Loss 0.7384 (0.7384)	Acc@1 83.858 (83.858)	Acc@5 99.606 (99.606)
Epoch: [19][64/197]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6370 (0.7453)	Acc@1 87.402 (84.131)	Acc@5 100.000 (99.352)
Epoch: [19][128/197]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.7898 (0.7476)	Acc@1 80.709 (84.176)	Acc@5 99.213 (99.338)
Epoch: [19][192/197]	Time 0.138 (0.129)	Data 0.000 (0.002)	Loss 0.7422 (0.7460)	Acc@1 83.071 (84.240)	Acc@5 99.213 (99.304)
Max memory in training epoch: 66.365696
lr: 0.09351351764053106
1

Epoch: [20 | 20] LR: 0.093514
batch Size 254
Epoch: [20][0/197]	Time 0.177 (0.177)	Data 0.283 (0.283)	Loss 0.6527 (0.6527)	Acc@1 87.795 (87.795)	Acc@5 99.606 (99.606)
Epoch: [20][64/197]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7101 (0.7408)	Acc@1 86.614 (84.397)	Acc@5 99.213 (99.194)
Epoch: [20][128/197]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6878 (0.7376)	Acc@1 86.614 (84.594)	Acc@5 100.000 (99.292)
Epoch: [20][192/197]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7432 (0.7389)	Acc@1 85.433 (84.601)	Acc@5 99.213 (99.292)
Max memory in training epoch: 66.365696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  78.43
Max memory: 103.3833984
 25.657s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3872
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.202496
lr: 0.09278294328396441
1

Epoch: [21 | 25] LR: 0.092783
batch Size 254
Epoch: [21][0/197]	Time 0.197 (0.197)	Data 0.275 (0.275)	Loss 0.7539 (0.7539)	Acc@1 85.039 (85.039)	Acc@5 98.425 (98.425)
Epoch: [21][64/197]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.6919 (0.7134)	Acc@1 84.646 (85.312)	Acc@5 100.000 (99.352)
Epoch: [21][128/197]	Time 0.137 (0.133)	Data 0.000 (0.002)	Loss 0.6779 (0.7217)	Acc@1 86.614 (85.088)	Acc@5 100.000 (99.329)
Epoch: [21][192/197]	Time 0.128 (0.133)	Data 0.000 (0.002)	Loss 0.7954 (0.7249)	Acc@1 83.071 (85.023)	Acc@5 98.031 (99.341)
Max memory in training epoch: 66.5164288
lr: 0.09278294328396441
1

Epoch: [22 | 25] LR: 0.092783
batch Size 254
Epoch: [22][0/197]	Time 0.189 (0.189)	Data 0.294 (0.294)	Loss 0.6812 (0.6812)	Acc@1 85.039 (85.039)	Acc@5 100.000 (100.000)
Epoch: [22][64/197]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.7175 (0.7137)	Acc@1 85.039 (85.245)	Acc@5 99.606 (99.461)
Epoch: [22][128/197]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7573 (0.7237)	Acc@1 82.283 (84.896)	Acc@5 99.606 (99.396)
Epoch: [22][192/197]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6749 (0.7284)	Acc@1 86.220 (84.750)	Acc@5 100.000 (99.359)
Max memory in training epoch: 66.365696
lr: 0.09278294328396441
1

Epoch: [23 | 25] LR: 0.092783
batch Size 254
Epoch: [23][0/197]	Time 0.165 (0.165)	Data 0.305 (0.305)	Loss 0.6333 (0.6333)	Acc@1 87.008 (87.008)	Acc@5 99.606 (99.606)
Epoch: [23][64/197]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.6958 (0.7227)	Acc@1 86.220 (85.058)	Acc@5 100.000 (99.419)
Epoch: [23][128/197]	Time 0.123 (0.129)	Data 0.000 (0.003)	Loss 0.8666 (0.7299)	Acc@1 80.709 (84.780)	Acc@5 98.819 (99.377)
Epoch: [23][192/197]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6376 (0.7330)	Acc@1 89.370 (84.644)	Acc@5 99.606 (99.355)
Max memory in training epoch: 66.365696
Drin!!
old memory: 663656960
new memory: 663656960
Faktor: 1.0
lr: 0.09278294328396441
1

Epoch: [24 | 25] LR: 0.092783
batch Size 254
Epoch: [24][0/197]	Time 0.173 (0.173)	Data 0.290 (0.290)	Loss 0.7119 (0.7119)	Acc@1 87.402 (87.402)	Acc@5 99.606 (99.606)
Epoch: [24][64/197]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.6016 (0.7112)	Acc@1 90.945 (85.851)	Acc@5 99.606 (99.346)
Epoch: [24][128/197]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7479 (0.7183)	Acc@1 85.827 (85.418)	Acc@5 99.213 (99.335)
Epoch: [24][192/197]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8027 (0.7250)	Acc@1 83.858 (85.154)	Acc@5 98.425 (99.335)
Max memory in training epoch: 66.365696
lr: 0.09278294328396441
1

Epoch: [25 | 25] LR: 0.092783
batch Size 254
Epoch: [25][0/197]	Time 0.188 (0.188)	Data 0.269 (0.269)	Loss 0.7606 (0.7606)	Acc@1 83.465 (83.465)	Acc@5 98.425 (98.425)
Epoch: [25][64/197]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.7926 (0.7114)	Acc@1 82.283 (85.706)	Acc@5 99.606 (99.370)
Epoch: [25][128/197]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8309 (0.7159)	Acc@1 79.921 (85.421)	Acc@5 99.606 (99.387)
Epoch: [25][192/197]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7612 (0.7161)	Acc@1 83.858 (85.488)	Acc@5 99.606 (99.402)
Max memory in training epoch: 66.365696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 481616 ; 487386 ; 0.988161334137624
[INFO] Storing checkpoint...
  79.55
Max memory: 103.3833984
 25.456s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1627
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.2002432
lr: 0.09205807653955844
1

Epoch: [26 | 30] LR: 0.092058
batch Size 254
Epoch: [26][0/197]	Time 0.211 (0.211)	Data 0.279 (0.279)	Loss 0.6615 (0.6615)	Acc@1 85.827 (85.827)	Acc@5 99.606 (99.606)
Epoch: [26][64/197]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.7968 (0.6933)	Acc@1 83.071 (86.008)	Acc@5 99.606 (99.522)
Epoch: [26][128/197]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6916 (0.6999)	Acc@1 87.402 (85.790)	Acc@5 99.213 (99.490)
Epoch: [26][192/197]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7005 (0.7061)	Acc@1 86.220 (85.676)	Acc@5 99.213 (99.435)
Max memory in training epoch: 66.5074176
lr: 0.09205807653955844
1

Epoch: [27 | 30] LR: 0.092058
batch Size 254
Epoch: [27][0/197]	Time 0.176 (0.176)	Data 0.259 (0.259)	Loss 0.7231 (0.7231)	Acc@1 84.646 (84.646)	Acc@5 100.000 (100.000)
Epoch: [27][64/197]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.7754 (0.7026)	Acc@1 85.039 (85.912)	Acc@5 97.244 (99.491)
Epoch: [27][128/197]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.6777 (0.6972)	Acc@1 85.039 (86.123)	Acc@5 99.606 (99.432)
Epoch: [27][192/197]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7144 (0.7060)	Acc@1 88.583 (85.806)	Acc@5 98.031 (99.404)
Max memory in training epoch: 66.3566848
lr: 0.09205807653955844
1

Epoch: [28 | 30] LR: 0.092058
batch Size 254
Epoch: [28][0/197]	Time 0.188 (0.188)	Data 0.262 (0.262)	Loss 0.7351 (0.7351)	Acc@1 84.252 (84.252)	Acc@5 99.606 (99.606)
Epoch: [28][64/197]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 0.7317 (0.7192)	Acc@1 84.252 (85.276)	Acc@5 98.819 (99.437)
Epoch: [28][128/197]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6056 (0.7055)	Acc@1 88.976 (85.708)	Acc@5 100.000 (99.441)
Epoch: [28][192/197]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7853 (0.7138)	Acc@1 81.890 (85.431)	Acc@5 99.606 (99.408)
Max memory in training epoch: 66.3566848
Drin!!
old memory: 663656960
new memory: 663566848
Faktor: 0.9998642190085674
New batch Size größer 256!!
lr: 0.09205807653955844
1

Epoch: [29 | 30] LR: 0.092058
batch Size 256
Epoch: [29][0/197]	Time 0.169 (0.169)	Data 0.281 (0.281)	Loss 0.6828 (0.6828)	Acc@1 86.220 (86.220)	Acc@5 98.819 (98.819)
Epoch: [29][64/197]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 0.7035 (0.7000)	Acc@1 85.827 (86.033)	Acc@5 100.000 (99.473)
Epoch: [29][128/197]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.7196 (0.7018)	Acc@1 86.220 (85.815)	Acc@5 99.213 (99.423)
Epoch: [29][192/197]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.6593 (0.7061)	Acc@1 88.189 (85.696)	Acc@5 99.213 (99.423)
Max memory in training epoch: 66.3566848
lr: 0.09205807653955844
1

Epoch: [30 | 30] LR: 0.092058
batch Size 256
Epoch: [30][0/197]	Time 0.179 (0.179)	Data 0.257 (0.257)	Loss 0.6474 (0.6474)	Acc@1 87.008 (87.008)	Acc@5 100.000 (100.000)
Epoch: [30][64/197]	Time 0.134 (0.129)	Data 0.000 (0.004)	Loss 0.6862 (0.6849)	Acc@1 84.252 (86.227)	Acc@5 99.606 (99.461)
Epoch: [30][128/197]	Time 0.158 (0.129)	Data 0.000 (0.002)	Loss 0.7092 (0.6956)	Acc@1 88.976 (85.958)	Acc@5 99.606 (99.448)
Epoch: [30][192/197]	Time 0.126 (0.128)	Data 0.000 (0.001)	Loss 0.7822 (0.7028)	Acc@1 83.465 (85.761)	Acc@5 100.000 (99.451)
Max memory in training epoch: 66.3566848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 465456 ; 481616 ; 0.9664462974652005
[INFO] Storing checkpoint...
  71.08
Max memory: 103.37664
 25.604s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8683
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.193792
lr: 0.09205807653955844
1

Epoch: [31 | 35] LR: 0.092058
batch Size 256
Epoch: [31][0/196]	Time 0.198 (0.198)	Data 0.269 (0.269)	Loss 0.7398 (0.7398)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.127 (0.133)	Data 0.000 (0.004)	Loss 0.6792 (0.6633)	Acc@1 85.938 (86.959)	Acc@5 99.219 (99.555)
Epoch: [31][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7715 (0.6797)	Acc@1 83.984 (86.567)	Acc@5 99.219 (99.491)
Epoch: [31][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6064 (0.6910)	Acc@1 88.672 (86.176)	Acc@5 99.609 (99.429)
Max memory in training epoch: 65.8647552
lr: 0.09205807653955844
1

Epoch: [32 | 35] LR: 0.092058
batch Size 256
Epoch: [32][0/196]	Time 0.182 (0.182)	Data 0.284 (0.284)	Loss 0.6926 (0.6926)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [32][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.5717 (0.6977)	Acc@1 90.234 (85.757)	Acc@5 100.000 (99.405)
Epoch: [32][128/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6474 (0.6952)	Acc@1 86.719 (86.037)	Acc@5 99.609 (99.425)
Epoch: [32][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6836 (0.6938)	Acc@1 87.891 (85.968)	Acc@5 99.219 (99.431)
Max memory in training epoch: 65.9565056
lr: 0.09205807653955844
1

Epoch: [33 | 35] LR: 0.092058
batch Size 256
Epoch: [33][0/196]	Time 0.175 (0.175)	Data 0.281 (0.281)	Loss 0.6683 (0.6683)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [33][64/196]	Time 0.133 (0.135)	Data 0.000 (0.005)	Loss 0.6868 (0.6910)	Acc@1 83.594 (86.358)	Acc@5 100.000 (99.489)
Epoch: [33][128/196]	Time 0.141 (0.135)	Data 0.000 (0.002)	Loss 0.6098 (0.6971)	Acc@1 87.500 (86.186)	Acc@5 99.609 (99.491)
Epoch: [33][192/196]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 0.6377 (0.6958)	Acc@1 87.891 (86.211)	Acc@5 99.219 (99.482)
Max memory in training epoch: 65.9565056
Drin!!
old memory: 663566848
new memory: 659565056
Faktor: 0.9939692707493428
New batch Size größer 260!!
lr: 0.09205807653955844
1

Epoch: [34 | 35] LR: 0.092058
batch Size 260
Epoch: [34][0/196]	Time 0.182 (0.182)	Data 0.263 (0.263)	Loss 0.6409 (0.6409)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.124 (0.131)	Data 0.000 (0.004)	Loss 0.6259 (0.6892)	Acc@1 89.062 (86.112)	Acc@5 98.828 (99.423)
Epoch: [34][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.6425 (0.6874)	Acc@1 88.281 (86.201)	Acc@5 100.000 (99.422)
Epoch: [34][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7048 (0.6860)	Acc@1 86.719 (86.223)	Acc@5 99.219 (99.447)
Max memory in training epoch: 65.9565056
lr: 0.09205807653955844
1

Epoch: [35 | 35] LR: 0.092058
batch Size 260
Epoch: [35][0/196]	Time 0.180 (0.180)	Data 0.285 (0.285)	Loss 0.6788 (0.6788)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.131 (0.133)	Data 0.000 (0.005)	Loss 0.6451 (0.6869)	Acc@1 86.719 (86.052)	Acc@5 99.219 (99.411)
Epoch: [35][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6788 (0.6849)	Acc@1 87.500 (86.349)	Acc@5 99.609 (99.373)
Epoch: [35][192/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.8653 (0.6917)	Acc@1 81.250 (86.055)	Acc@5 98.438 (99.403)
Max memory in training epoch: 65.9565056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 446986 ; 465456 ; 0.9603184833797395
[INFO] Storing checkpoint...
  80.0
Max memory: 102.5700352
 25.947s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7514
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1865216
lr: 0.09349648398548904
1

Epoch: [36 | 40] LR: 0.093496
batch Size 260
Epoch: [36][0/193]	Time 0.223 (0.223)	Data 0.251 (0.251)	Loss 0.7529 (0.7529)	Acc@1 86.154 (86.154)	Acc@5 98.462 (98.462)
Epoch: [36][64/193]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.7540 (0.6624)	Acc@1 86.154 (87.284)	Acc@5 99.231 (99.503)
Epoch: [36][128/193]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7285 (0.6831)	Acc@1 85.000 (86.553)	Acc@5 99.231 (99.508)
Epoch: [36][192/193]	Time 0.100 (0.129)	Data 0.000 (0.001)	Loss 0.8399 (0.6869)	Acc@1 82.500 (86.428)	Acc@5 97.500 (99.490)
Max memory in training epoch: 66.5748992
lr: 0.09349648398548904
1

Epoch: [37 | 40] LR: 0.093496
batch Size 260
Epoch: [37][0/193]	Time 0.159 (0.159)	Data 0.284 (0.284)	Loss 0.6849 (0.6849)	Acc@1 87.692 (87.692)	Acc@5 98.846 (98.846)
Epoch: [37][64/193]	Time 0.136 (0.135)	Data 0.000 (0.005)	Loss 0.6876 (0.6762)	Acc@1 87.308 (86.746)	Acc@5 100.000 (99.450)
Epoch: [37][128/193]	Time 0.125 (0.133)	Data 0.000 (0.002)	Loss 0.6578 (0.6870)	Acc@1 86.538 (86.422)	Acc@5 99.615 (99.490)
Epoch: [37][192/193]	Time 0.098 (0.132)	Data 0.000 (0.002)	Loss 0.6844 (0.6952)	Acc@1 86.250 (86.124)	Acc@5 100.000 (99.442)
Max memory in training epoch: 66.5814528
lr: 0.09349648398548904
1

Epoch: [38 | 40] LR: 0.093496
batch Size 260
Epoch: [38][0/193]	Time 0.185 (0.185)	Data 0.260 (0.260)	Loss 0.6485 (0.6485)	Acc@1 89.231 (89.231)	Acc@5 99.615 (99.615)
Epoch: [38][64/193]	Time 0.138 (0.132)	Data 0.000 (0.004)	Loss 0.6258 (0.6632)	Acc@1 86.923 (87.065)	Acc@5 99.615 (99.503)
Epoch: [38][128/193]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6902 (0.6787)	Acc@1 86.154 (86.705)	Acc@5 100.000 (99.434)
Epoch: [38][192/193]	Time 0.101 (0.130)	Data 0.000 (0.002)	Loss 0.7402 (0.6820)	Acc@1 86.250 (86.450)	Acc@5 100.000 (99.468)
Max memory in training epoch: 66.5814528
Drin!!
old memory: 659565056
new memory: 665814528
Faktor: 1.0094751411451368
New batch Size kleiner 262!!
lr: 0.09349648398548904
1

Epoch: [39 | 40] LR: 0.093496
batch Size 262
Epoch: [39][0/193]	Time 0.176 (0.176)	Data 0.289 (0.289)	Loss 0.7299 (0.7299)	Acc@1 85.000 (85.000)	Acc@5 99.231 (99.231)
Epoch: [39][64/193]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.7038 (0.6837)	Acc@1 86.923 (86.704)	Acc@5 99.231 (99.414)
Epoch: [39][128/193]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7319 (0.6860)	Acc@1 83.846 (86.530)	Acc@5 99.615 (99.407)
Epoch: [39][192/193]	Time 0.099 (0.131)	Data 0.000 (0.002)	Loss 0.7551 (0.6859)	Acc@1 85.000 (86.368)	Acc@5 100.000 (99.438)
Max memory in training epoch: 66.5814528
lr: 0.09349648398548904
1

Epoch: [40 | 40] LR: 0.093496
batch Size 262
Epoch: [40][0/193]	Time 0.186 (0.186)	Data 0.276 (0.276)	Loss 0.6173 (0.6173)	Acc@1 86.923 (86.923)	Acc@5 99.615 (99.615)
Epoch: [40][64/193]	Time 0.139 (0.132)	Data 0.000 (0.004)	Loss 0.6059 (0.6786)	Acc@1 88.077 (86.509)	Acc@5 100.000 (99.538)
Epoch: [40][128/193]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.7634 (0.6827)	Acc@1 85.385 (86.437)	Acc@5 98.846 (99.508)
Epoch: [40][192/193]	Time 0.105 (0.130)	Data 0.000 (0.002)	Loss 0.4587 (0.6841)	Acc@1 93.750 (86.476)	Acc@5 100.000 (99.488)
Max memory in training epoch: 66.5814528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 430246 ; 446986 ; 0.9625491626135941
[INFO] Storing checkpoint...
  82.15
Max memory: 101.0875904
 25.556s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8752
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1798656
lr: 0.09568780782889894
1

Epoch: [41 | 45] LR: 0.095688
batch Size 262
Epoch: [41][0/191]	Time 0.193 (0.193)	Data 0.264 (0.264)	Loss 0.6551 (0.6551)	Acc@1 87.023 (87.023)	Acc@5 99.618 (99.618)
Epoch: [41][64/191]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 0.5605 (0.6483)	Acc@1 90.076 (87.622)	Acc@5 99.618 (99.472)
Epoch: [41][128/191]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.5798 (0.6649)	Acc@1 90.458 (87.100)	Acc@5 100.000 (99.405)
Max memory in training epoch: 66.0879872
lr: 0.09568780782889894
1

Epoch: [42 | 45] LR: 0.095688
batch Size 262
Epoch: [42][0/191]	Time 0.185 (0.185)	Data 0.291 (0.291)	Loss 0.7137 (0.7137)	Acc@1 87.023 (87.023)	Acc@5 98.092 (98.092)
Epoch: [42][64/191]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.7846 (0.6727)	Acc@1 80.153 (86.823)	Acc@5 100.000 (99.495)
Epoch: [42][128/191]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6755 (0.6766)	Acc@1 86.641 (86.771)	Acc@5 100.000 (99.509)
Max memory in training epoch: 66.097408
lr: 0.09568780782889894
1

Epoch: [43 | 45] LR: 0.095688
batch Size 262
Epoch: [43][0/191]	Time 0.167 (0.167)	Data 0.296 (0.296)	Loss 0.6098 (0.6098)	Acc@1 90.076 (90.076)	Acc@5 100.000 (100.000)
Epoch: [43][64/191]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.6444 (0.6652)	Acc@1 87.786 (87.099)	Acc@5 99.618 (99.524)
Epoch: [43][128/191]	Time 0.150 (0.130)	Data 0.000 (0.002)	Loss 0.6939 (0.6707)	Acc@1 86.260 (86.804)	Acc@5 99.618 (99.556)
Max memory in training epoch: 66.0946944
Drin!!
old memory: 665814528
new memory: 660946944
Faktor: 0.9926892793784158
New batch Size größer 265!!
lr: 0.09568780782889894
1

Epoch: [44 | 45] LR: 0.095688
batch Size 265
Epoch: [44][0/191]	Time 0.170 (0.170)	Data 0.324 (0.324)	Loss 0.7390 (0.7390)	Acc@1 83.588 (83.588)	Acc@5 99.237 (99.237)
Epoch: [44][64/191]	Time 0.131 (0.129)	Data 0.000 (0.005)	Loss 0.6978 (0.6701)	Acc@1 87.023 (86.770)	Acc@5 99.618 (99.489)
Epoch: [44][128/191]	Time 0.122 (0.129)	Data 0.000 (0.003)	Loss 0.6710 (0.6761)	Acc@1 85.878 (86.591)	Acc@5 99.237 (99.476)
Max memory in training epoch: 66.0946944
lr: 0.09568780782889894
1

Epoch: [45 | 45] LR: 0.095688
batch Size 265
Epoch: [45][0/191]	Time 0.165 (0.165)	Data 0.286 (0.286)	Loss 0.6786 (0.6786)	Acc@1 86.641 (86.641)	Acc@5 98.092 (98.092)
Epoch: [45][64/191]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.6196 (0.6734)	Acc@1 89.695 (86.553)	Acc@5 99.618 (99.501)
Epoch: [45][128/191]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6798 (0.6818)	Acc@1 87.405 (86.328)	Acc@5 99.618 (99.488)
Max memory in training epoch: 66.0946944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 421870 ; 430246 ; 0.9805320677008037
[INFO] Storing checkpoint...
  77.45
Max memory: 99.5879424
 25.496s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6632
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1765888
lr: 0.09905183232288366
1

Epoch: [46 | 50] LR: 0.099052
batch Size 265
Epoch: [46][0/189]	Time 0.190 (0.190)	Data 0.295 (0.295)	Loss 0.6396 (0.6396)	Acc@1 86.038 (86.038)	Acc@5 100.000 (100.000)
Epoch: [46][64/189]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.7908 (0.6617)	Acc@1 82.264 (87.193)	Acc@5 99.623 (99.588)
Epoch: [46][128/189]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.5983 (0.6706)	Acc@1 90.189 (86.863)	Acc@5 99.245 (99.511)
Max memory in training epoch: 65.9694592
lr: 0.09905183232288366
1

Epoch: [47 | 50] LR: 0.099052
batch Size 265
Epoch: [47][0/189]	Time 0.195 (0.195)	Data 0.272 (0.272)	Loss 0.6325 (0.6325)	Acc@1 87.170 (87.170)	Acc@5 99.623 (99.623)
Epoch: [47][64/189]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.6877 (0.6631)	Acc@1 86.415 (87.286)	Acc@5 99.623 (99.501)
Epoch: [47][128/189]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.7055 (0.6701)	Acc@1 87.170 (86.927)	Acc@5 98.113 (99.482)
Max memory in training epoch: 66.2273024
lr: 0.09905183232288366
1

Epoch: [48 | 50] LR: 0.099052
batch Size 265
Epoch: [48][0/189]	Time 0.182 (0.182)	Data 0.289 (0.289)	Loss 0.5656 (0.5656)	Acc@1 91.321 (91.321)	Acc@5 100.000 (100.000)
Epoch: [48][64/189]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6866 (0.6816)	Acc@1 85.660 (86.351)	Acc@5 99.623 (99.460)
Epoch: [48][128/189]	Time 0.136 (0.130)	Data 0.000 (0.002)	Loss 0.7446 (0.6787)	Acc@1 83.396 (86.576)	Acc@5 100.000 (99.424)
Max memory in training epoch: 66.2273024
Drin!!
old memory: 660946944
new memory: 662273024
Faktor: 1.002006333506854
New batch Size kleiner 265!!
lr: 0.09905183232288366
1

Epoch: [49 | 50] LR: 0.099052
batch Size 265
Epoch: [49][0/189]	Time 0.173 (0.173)	Data 0.302 (0.302)	Loss 0.8217 (0.8217)	Acc@1 80.377 (80.377)	Acc@5 98.868 (98.868)
Epoch: [49][64/189]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.6362 (0.6770)	Acc@1 87.925 (86.752)	Acc@5 98.868 (99.408)
Epoch: [49][128/189]	Time 0.123 (0.132)	Data 0.000 (0.003)	Loss 0.6268 (0.6788)	Acc@1 89.057 (86.608)	Acc@5 99.245 (99.438)
Max memory in training epoch: 66.2273024
lr: 0.09905183232288366
1

Epoch: [50 | 50] LR: 0.099052
batch Size 265
Epoch: [50][0/189]	Time 0.155 (0.155)	Data 0.293 (0.293)	Loss 0.6415 (0.6415)	Acc@1 87.547 (87.547)	Acc@5 99.623 (99.623)
Epoch: [50][64/189]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7101 (0.6765)	Acc@1 85.660 (86.729)	Acc@5 99.245 (99.483)
Epoch: [50][128/189]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6964 (0.6778)	Acc@1 84.528 (86.453)	Acc@5 99.623 (99.500)
Max memory in training epoch: 66.2273024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 412634 ; 421870 ; 0.9781069997866642
[INFO] Storing checkpoint...
  80.87
Max memory: 98.4285696
 24.961s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4021
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1729024
lr: 0.10253412330298503
1

Epoch: [51 | 55] LR: 0.102534
batch Size 265
Epoch: [51][0/189]	Time 0.201 (0.201)	Data 0.309 (0.309)	Loss 0.6747 (0.6747)	Acc@1 87.925 (87.925)	Acc@5 99.245 (99.245)
Epoch: [51][64/189]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6756 (0.6578)	Acc@1 86.792 (87.419)	Acc@5 99.245 (99.541)
Epoch: [51][128/189]	Time 0.141 (0.130)	Data 0.000 (0.003)	Loss 0.7563 (0.6743)	Acc@1 86.038 (86.792)	Acc@5 98.868 (99.500)
Max memory in training epoch: 65.5650816
lr: 0.10253412330298503
1

Epoch: [52 | 55] LR: 0.102534
batch Size 265
Epoch: [52][0/189]	Time 0.178 (0.178)	Data 0.268 (0.268)	Loss 0.8328 (0.8328)	Acc@1 84.151 (84.151)	Acc@5 99.245 (99.245)
Epoch: [52][64/189]	Time 0.144 (0.130)	Data 0.000 (0.004)	Loss 0.7243 (0.6761)	Acc@1 84.906 (86.891)	Acc@5 98.868 (99.582)
Epoch: [52][128/189]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7720 (0.6843)	Acc@1 83.019 (86.462)	Acc@5 99.623 (99.526)
Max memory in training epoch: 65.7022976
lr: 0.10253412330298503
1

Epoch: [53 | 55] LR: 0.102534
batch Size 265
Epoch: [53][0/189]	Time 0.157 (0.157)	Data 0.297 (0.297)	Loss 0.6521 (0.6521)	Acc@1 86.415 (86.415)	Acc@5 100.000 (100.000)
Epoch: [53][64/189]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.6497 (0.6557)	Acc@1 85.283 (87.350)	Acc@5 99.623 (99.576)
Epoch: [53][128/189]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6380 (0.6659)	Acc@1 87.925 (87.141)	Acc@5 100.000 (99.500)
Max memory in training epoch: 65.7022976
Drin!!
old memory: 662273024
new memory: 657022976
Faktor: 0.992072683304703
New batch Size größer 270!!
lr: 0.10253412330298503
1

Epoch: [54 | 55] LR: 0.102534
batch Size 270
Epoch: [54][0/189]	Time 0.188 (0.188)	Data 0.267 (0.267)	Loss 0.6832 (0.6832)	Acc@1 86.415 (86.415)	Acc@5 98.868 (98.868)
Epoch: [54][64/189]	Time 0.124 (0.130)	Data 0.000 (0.004)	Loss 0.6248 (0.6695)	Acc@1 87.170 (87.030)	Acc@5 99.245 (99.408)
Epoch: [54][128/189]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7168 (0.6798)	Acc@1 83.774 (86.769)	Acc@5 99.245 (99.415)
Max memory in training epoch: 65.7022976
lr: 0.10253412330298503
1

Epoch: [55 | 55] LR: 0.102534
batch Size 270
Epoch: [55][0/189]	Time 0.198 (0.198)	Data 0.272 (0.272)	Loss 0.6106 (0.6106)	Acc@1 89.811 (89.811)	Acc@5 99.623 (99.623)
Epoch: [55][64/189]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.5904 (0.6592)	Acc@1 90.566 (87.274)	Acc@5 100.000 (99.553)
Epoch: [55][128/189]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.6620 (0.6724)	Acc@1 88.302 (86.708)	Acc@5 99.245 (99.544)
Max memory in training epoch: 65.7022976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 403972 ; 412634 ; 0.9790080313304285
[INFO] Storing checkpoint...
  76.46
Max memory: 98.1000704
 24.810s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9789
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1694208
lr: 0.10814145817111702
1

Epoch: [56 | 60] LR: 0.108141
batch Size 270
Epoch: [56][0/186]	Time 0.192 (0.192)	Data 0.279 (0.279)	Loss 0.6260 (0.6260)	Acc@1 89.630 (89.630)	Acc@5 99.259 (99.259)
Epoch: [56][64/186]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 0.8143 (0.6559)	Acc@1 82.222 (87.670)	Acc@5 99.259 (99.487)
Epoch: [56][128/186]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.6820 (0.6748)	Acc@1 86.667 (86.764)	Acc@5 99.630 (99.469)
Max memory in training epoch: 66.2412288
lr: 0.10814145817111702
1

Epoch: [57 | 60] LR: 0.108141
batch Size 270
Epoch: [57][0/186]	Time 0.168 (0.168)	Data 0.271 (0.271)	Loss 0.7198 (0.7198)	Acc@1 85.556 (85.556)	Acc@5 98.519 (98.519)
Epoch: [57][64/186]	Time 0.126 (0.132)	Data 0.000 (0.004)	Loss 0.7080 (0.6899)	Acc@1 86.667 (86.376)	Acc@5 98.889 (99.442)
Epoch: [57][128/186]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6796 (0.6838)	Acc@1 85.926 (86.523)	Acc@5 99.259 (99.460)
Max memory in training epoch: 66.311424
lr: 0.10814145817111702
1

Epoch: [58 | 60] LR: 0.108141
batch Size 270
Epoch: [58][0/186]	Time 0.182 (0.182)	Data 0.325 (0.325)	Loss 0.6459 (0.6459)	Acc@1 87.407 (87.407)	Acc@5 100.000 (100.000)
Epoch: [58][64/186]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.6707 (0.6960)	Acc@1 87.037 (86.279)	Acc@5 99.630 (99.396)
Epoch: [58][128/186]	Time 0.131 (0.130)	Data 0.000 (0.003)	Loss 0.6973 (0.6967)	Acc@1 84.444 (86.158)	Acc@5 99.259 (99.400)
Max memory in training epoch: 66.311424
Drin!!
old memory: 657022976
new memory: 663114240
Faktor: 1.009271006072092
New batch Size kleiner 272!!
lr: 0.10814145817111702
1

Epoch: [59 | 60] LR: 0.108141
batch Size 272
Epoch: [59][0/186]	Time 0.183 (0.183)	Data 0.297 (0.297)	Loss 0.6881 (0.6881)	Acc@1 86.667 (86.667)	Acc@5 100.000 (100.000)
Epoch: [59][64/186]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.6507 (0.6794)	Acc@1 86.667 (86.855)	Acc@5 99.259 (99.459)
Epoch: [59][128/186]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6212 (0.6835)	Acc@1 88.889 (86.612)	Acc@5 100.000 (99.460)
Max memory in training epoch: 66.311424
lr: 0.10814145817111702
1

Epoch: [60 | 60] LR: 0.108141
batch Size 272
Epoch: [60][0/186]	Time 0.204 (0.204)	Data 0.308 (0.308)	Loss 0.6874 (0.6874)	Acc@1 87.778 (87.778)	Acc@5 100.000 (100.000)
Epoch: [60][64/186]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7009 (0.6844)	Acc@1 83.704 (86.274)	Acc@5 99.259 (99.487)
Epoch: [60][128/186]	Time 0.133 (0.133)	Data 0.000 (0.003)	Loss 0.6946 (0.6768)	Acc@1 85.185 (86.721)	Acc@5 99.259 (99.469)
Max memory in training epoch: 66.311424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 396604 ; 403972 ; 0.981761112156288
[INFO] Storing checkpoint...
  83.93
Max memory: 97.2794368
 25.061s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3315
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1667072
lr: 0.11490029930681184
1

Epoch: [61 | 65] LR: 0.114900
batch Size 272
Epoch: [61][0/184]	Time 0.213 (0.213)	Data 0.270 (0.270)	Loss 0.6096 (0.6096)	Acc@1 88.971 (88.971)	Acc@5 100.000 (100.000)
Epoch: [61][64/184]	Time 0.132 (0.135)	Data 0.000 (0.004)	Loss 0.7077 (0.6617)	Acc@1 86.397 (87.064)	Acc@5 99.632 (99.525)
Epoch: [61][128/184]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.7554 (0.6781)	Acc@1 82.721 (86.594)	Acc@5 98.897 (99.481)
Max memory in training epoch: 67.1623168
lr: 0.11490029930681184
1

Epoch: [62 | 65] LR: 0.114900
batch Size 272
Epoch: [62][0/184]	Time 0.160 (0.160)	Data 0.313 (0.313)	Loss 0.6778 (0.6778)	Acc@1 85.662 (85.662)	Acc@5 99.632 (99.632)
Epoch: [62][64/184]	Time 0.139 (0.134)	Data 0.000 (0.005)	Loss 0.6323 (0.6694)	Acc@1 87.868 (86.900)	Acc@5 100.000 (99.581)
Epoch: [62][128/184]	Time 0.130 (0.134)	Data 0.000 (0.003)	Loss 0.7130 (0.6761)	Acc@1 85.294 (86.765)	Acc@5 99.265 (99.524)
Max memory in training epoch: 67.273728
lr: 0.11490029930681184
1

Epoch: [63 | 65] LR: 0.114900
batch Size 272
Epoch: [63][0/184]	Time 0.159 (0.159)	Data 0.307 (0.307)	Loss 0.5841 (0.5841)	Acc@1 91.176 (91.176)	Acc@5 100.000 (100.000)
Epoch: [63][64/184]	Time 0.135 (0.134)	Data 0.000 (0.005)	Loss 0.6122 (0.6891)	Acc@1 89.706 (86.340)	Acc@5 100.000 (99.434)
Epoch: [63][128/184]	Time 0.131 (0.135)	Data 0.000 (0.003)	Loss 0.7662 (0.6957)	Acc@1 83.456 (86.035)	Acc@5 99.265 (99.461)
Max memory in training epoch: 67.273728
Drin!!
old memory: 663114240
new memory: 672737280
Faktor: 1.0145118886302307
New batch Size kleiner 275!!
lr: 0.11490029930681184
1

Epoch: [64 | 65] LR: 0.114900
batch Size 275
Epoch: [64][0/184]	Time 0.167 (0.167)	Data 0.274 (0.274)	Loss 0.6029 (0.6029)	Acc@1 89.706 (89.706)	Acc@5 100.000 (100.000)
Epoch: [64][64/184]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.7799 (0.6813)	Acc@1 82.353 (86.420)	Acc@5 99.265 (99.440)
Epoch: [64][128/184]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6712 (0.6803)	Acc@1 87.500 (86.457)	Acc@5 99.265 (99.459)
Max memory in training epoch: 67.273728
lr: 0.11490029930681184
1

Epoch: [65 | 65] LR: 0.114900
batch Size 275
Epoch: [65][0/184]	Time 0.187 (0.187)	Data 0.320 (0.320)	Loss 0.7250 (0.7250)	Acc@1 85.294 (85.294)	Acc@5 100.000 (100.000)
Epoch: [65][64/184]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 0.6321 (0.6762)	Acc@1 87.500 (86.861)	Acc@5 100.000 (99.525)
Epoch: [65][128/184]	Time 0.125 (0.131)	Data 0.000 (0.003)	Loss 0.7468 (0.6891)	Acc@1 84.926 (86.340)	Acc@5 99.265 (99.478)
Max memory in training epoch: 67.273728
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 390534 ; 396604 ; 0.9846950610684713
[INFO] Storing checkpoint...
  74.66
Max memory: 96.538112
 24.602s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5522
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.164352
lr: 0.12342805589598928
1

Epoch: [66 | 70] LR: 0.123428
batch Size 275
Epoch: [66][0/182]	Time 0.218 (0.218)	Data 0.260 (0.260)	Loss 0.6208 (0.6208)	Acc@1 88.364 (88.364)	Acc@5 99.273 (99.273)
Epoch: [66][64/182]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.7239 (0.6735)	Acc@1 86.545 (86.613)	Acc@5 100.000 (99.513)
Epoch: [66][128/182]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.6847 (0.6904)	Acc@1 87.636 (86.063)	Acc@5 99.273 (99.456)
Max memory in training epoch: 67.0446592
lr: 0.12342805589598928
1

Epoch: [67 | 70] LR: 0.123428
batch Size 275
Epoch: [67][0/182]	Time 0.174 (0.174)	Data 0.297 (0.297)	Loss 0.6667 (0.6667)	Acc@1 86.545 (86.545)	Acc@5 100.000 (100.000)
Epoch: [67][64/182]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.6913 (0.6858)	Acc@1 86.545 (86.568)	Acc@5 99.636 (99.435)
Epoch: [67][128/182]	Time 0.136 (0.133)	Data 0.000 (0.002)	Loss 0.6526 (0.6987)	Acc@1 86.182 (86.052)	Acc@5 99.636 (99.473)
Max memory in training epoch: 66.9642752
lr: 0.12342805589598928
1

Epoch: [68 | 70] LR: 0.123428
batch Size 275
Epoch: [68][0/182]	Time 0.153 (0.153)	Data 0.283 (0.283)	Loss 0.7221 (0.7221)	Acc@1 84.364 (84.364)	Acc@5 99.273 (99.273)
Epoch: [68][64/182]	Time 0.134 (0.134)	Data 0.000 (0.005)	Loss 0.6842 (0.6739)	Acc@1 86.545 (86.926)	Acc@5 99.636 (99.513)
Epoch: [68][128/182]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7181 (0.6877)	Acc@1 85.091 (86.390)	Acc@5 99.636 (99.448)
Max memory in training epoch: 66.9642752
Drin!!
old memory: 672737280
new memory: 669642752
Faktor: 0.9954000943726502
New batch Size größer 275!!
lr: 0.12342805589598928
1

Epoch: [69 | 70] LR: 0.123428
batch Size 275
Epoch: [69][0/182]	Time 0.191 (0.191)	Data 0.304 (0.304)	Loss 0.7097 (0.7097)	Acc@1 85.818 (85.818)	Acc@5 99.273 (99.273)
Epoch: [69][64/182]	Time 0.134 (0.134)	Data 0.000 (0.005)	Loss 0.7122 (0.6931)	Acc@1 85.818 (86.204)	Acc@5 99.636 (99.418)
Epoch: [69][128/182]	Time 0.132 (0.134)	Data 0.000 (0.003)	Loss 0.6363 (0.6990)	Acc@1 88.000 (86.013)	Acc@5 100.000 (99.419)
Max memory in training epoch: 66.9642752
lr: 0.12342805589598928
1

Epoch: [70 | 70] LR: 0.123428
batch Size 275
Epoch: [70][0/182]	Time 0.177 (0.177)	Data 0.293 (0.293)	Loss 0.6405 (0.6405)	Acc@1 89.455 (89.455)	Acc@5 99.273 (99.273)
Epoch: [70][64/182]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.6220 (0.6810)	Acc@1 87.636 (86.422)	Acc@5 99.636 (99.463)
Epoch: [70][128/182]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.8192 (0.6922)	Acc@1 83.636 (86.196)	Acc@5 98.182 (99.442)
Max memory in training epoch: 66.9642752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 383600 ; 390534 ; 0.9822448237541418
[INFO] Storing checkpoint...
  79.5
Max memory: 95.448064
 24.261s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 681
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1614848
lr: 0.13258873191951973
1

Epoch: [71 | 75] LR: 0.132589
batch Size 275
Epoch: [71][0/182]	Time 0.196 (0.196)	Data 0.275 (0.275)	Loss 0.7217 (0.7217)	Acc@1 87.636 (87.636)	Acc@5 99.636 (99.636)
Epoch: [71][64/182]	Time 0.136 (0.136)	Data 0.000 (0.004)	Loss 0.7349 (0.6830)	Acc@1 84.000 (86.562)	Acc@5 99.273 (99.457)
Epoch: [71][128/182]	Time 0.135 (0.135)	Data 0.000 (0.002)	Loss 0.7470 (0.7019)	Acc@1 83.273 (85.948)	Acc@5 99.636 (99.428)
Max memory in training epoch: 66.692608
lr: 0.13258873191951973
1

Epoch: [72 | 75] LR: 0.132589
batch Size 275
Epoch: [72][0/182]	Time 0.156 (0.156)	Data 0.298 (0.298)	Loss 0.6755 (0.6755)	Acc@1 88.000 (88.000)	Acc@5 100.000 (100.000)
Epoch: [72][64/182]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.6903 (0.7075)	Acc@1 87.273 (85.874)	Acc@5 99.636 (99.362)
Epoch: [72][128/182]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.6710 (0.7059)	Acc@1 88.364 (85.782)	Acc@5 99.273 (99.414)
Max memory in training epoch: 66.5392128
lr: 0.13258873191951973
1

Epoch: [73 | 75] LR: 0.132589
batch Size 275
Epoch: [73][0/182]	Time 0.157 (0.157)	Data 0.311 (0.311)	Loss 0.7798 (0.7798)	Acc@1 81.091 (81.091)	Acc@5 99.273 (99.273)
Epoch: [73][64/182]	Time 0.140 (0.133)	Data 0.000 (0.005)	Loss 0.7208 (0.7076)	Acc@1 86.182 (85.779)	Acc@5 98.545 (99.452)
Epoch: [73][128/182]	Time 0.143 (0.134)	Data 0.000 (0.003)	Loss 0.6546 (0.7059)	Acc@1 88.364 (85.810)	Acc@5 99.636 (99.464)
Max memory in training epoch: 66.5392128
Drin!!
old memory: 669642752
new memory: 665392128
Faktor: 0.9936524004966756
New batch Size größer 276!!
lr: 0.13258873191951973
1

Epoch: [74 | 75] LR: 0.132589
batch Size 276
Epoch: [74][0/182]	Time 0.156 (0.156)	Data 0.300 (0.300)	Loss 0.5678 (0.5678)	Acc@1 90.182 (90.182)	Acc@5 99.636 (99.636)
Epoch: [74][64/182]	Time 0.134 (0.136)	Data 0.000 (0.005)	Loss 0.7011 (0.6962)	Acc@1 86.909 (86.036)	Acc@5 99.636 (99.441)
Epoch: [74][128/182]	Time 0.133 (0.135)	Data 0.000 (0.002)	Loss 0.6809 (0.7060)	Acc@1 84.727 (85.720)	Acc@5 100.000 (99.391)
Max memory in training epoch: 66.5392128
lr: 0.13258873191951973
1

Epoch: [75 | 75] LR: 0.132589
batch Size 276
Epoch: [75][0/182]	Time 0.191 (0.191)	Data 0.305 (0.305)	Loss 0.6805 (0.6805)	Acc@1 86.909 (86.909)	Acc@5 99.636 (99.636)
Epoch: [75][64/182]	Time 0.133 (0.137)	Data 0.000 (0.005)	Loss 0.7363 (0.6931)	Acc@1 84.364 (86.020)	Acc@5 98.909 (99.396)
Epoch: [75][128/182]	Time 0.132 (0.135)	Data 0.000 (0.003)	Loss 0.6606 (0.7016)	Acc@1 87.273 (85.886)	Acc@5 99.273 (99.402)
Max memory in training epoch: 66.5392128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 374068 ; 383600 ; 0.9751511991657977
[INFO] Storing checkpoint...
  77.17
Max memory: 94.651392
 24.891s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2129
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1575936
lr: 0.1429472266007322
1

Epoch: [76 | 80] LR: 0.142947
batch Size 276
Epoch: [76][0/182]	Time 0.195 (0.195)	Data 0.294 (0.294)	Loss 0.6078 (0.6078)	Acc@1 89.493 (89.493)	Acc@5 100.000 (100.000)
Epoch: [76][64/182]	Time 0.137 (0.134)	Data 0.000 (0.005)	Loss 0.8008 (0.6915)	Acc@1 84.058 (85.987)	Acc@5 99.638 (99.420)
Epoch: [76][128/182]	Time 0.135 (0.134)	Data 0.000 (0.002)	Loss 0.8226 (0.7076)	Acc@1 81.522 (85.547)	Acc@5 99.275 (99.385)
Max memory in training epoch: 65.7798144
lr: 0.1429472266007322
1

Epoch: [77 | 80] LR: 0.142947
batch Size 276
Epoch: [77][0/182]	Time 0.187 (0.187)	Data 0.297 (0.297)	Loss 0.7306 (0.7306)	Acc@1 84.783 (84.783)	Acc@5 99.275 (99.275)
Epoch: [77][64/182]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7445 (0.7651)	Acc@1 85.145 (84.125)	Acc@5 99.638 (99.231)
Epoch: [77][128/182]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7998 (0.7430)	Acc@1 82.609 (84.771)	Acc@5 98.913 (99.298)
Max memory in training epoch: 65.939968
lr: 0.1429472266007322
1

Epoch: [78 | 80] LR: 0.142947
batch Size 276
Epoch: [78][0/182]	Time 0.186 (0.186)	Data 0.308 (0.308)	Loss 0.7942 (0.7942)	Acc@1 80.797 (80.797)	Acc@5 99.638 (99.638)
Epoch: [78][64/182]	Time 0.135 (0.135)	Data 0.000 (0.005)	Loss 0.7242 (0.7542)	Acc@1 85.870 (84.599)	Acc@5 100.000 (99.247)
Epoch: [78][128/182]	Time 0.135 (0.135)	Data 0.000 (0.003)	Loss 0.7493 (0.7433)	Acc@1 83.696 (84.769)	Acc@5 98.551 (99.287)
Max memory in training epoch: 65.90464
Drin!!
old memory: 665392128
new memory: 659046400
Faktor: 0.9904631754224781
New batch Size größer 280!!
lr: 0.1429472266007322
1

Epoch: [79 | 80] LR: 0.142947
batch Size 280
Epoch: [79][0/182]	Time 0.187 (0.187)	Data 0.315 (0.315)	Loss 0.7160 (0.7160)	Acc@1 85.507 (85.507)	Acc@5 99.638 (99.638)
Epoch: [79][64/182]	Time 0.135 (0.137)	Data 0.000 (0.005)	Loss 0.6710 (0.7289)	Acc@1 88.406 (85.329)	Acc@5 99.275 (99.342)
Epoch: [79][128/182]	Time 0.133 (0.136)	Data 0.000 (0.003)	Loss 0.7152 (0.7218)	Acc@1 85.870 (85.406)	Acc@5 99.275 (99.332)
Max memory in training epoch: 65.90464
lr: 0.1429472266007322
1

Epoch: [80 | 80] LR: 0.142947
batch Size 280
Epoch: [80][0/182]	Time 0.160 (0.160)	Data 0.290 (0.290)	Loss 0.6808 (0.6808)	Acc@1 86.957 (86.957)	Acc@5 98.913 (98.913)
Epoch: [80][64/182]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 0.7457 (0.6939)	Acc@1 84.058 (86.154)	Acc@5 98.913 (99.359)
Epoch: [80][128/182]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7327 (0.7088)	Acc@1 82.971 (85.676)	Acc@5 99.275 (99.315)
Max memory in training epoch: 65.90464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 367136 ; 374068 ; 0.9814686099853502
[INFO] Storing checkpoint...
  79.64
Max memory: 92.9931264
 24.778s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2821
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1550336
lr: 0.15634852909455085
1

Epoch: [81 | 85] LR: 0.156349
batch Size 280
Epoch: [81][0/179]	Time 0.212 (0.212)	Data 0.265 (0.265)	Loss 0.7964 (0.7964)	Acc@1 84.286 (84.286)	Acc@5 99.286 (99.286)
Epoch: [81][64/179]	Time 0.140 (0.134)	Data 0.000 (0.004)	Loss 0.7625 (0.6847)	Acc@1 85.357 (86.599)	Acc@5 99.286 (99.511)
Epoch: [81][128/179]	Time 0.140 (0.136)	Data 0.000 (0.002)	Loss 0.6658 (0.7163)	Acc@1 89.643 (85.648)	Acc@5 99.643 (99.385)
Max memory in training epoch: 65.6031744
lr: 0.15634852909455085
1

Epoch: [82 | 85] LR: 0.156349
batch Size 280
Epoch: [82][0/179]	Time 0.162 (0.162)	Data 0.308 (0.308)	Loss 0.7119 (0.7119)	Acc@1 83.214 (83.214)	Acc@5 99.643 (99.643)
Epoch: [82][64/179]	Time 0.138 (0.133)	Data 0.000 (0.005)	Loss 0.7834 (0.7435)	Acc@1 83.929 (84.692)	Acc@5 98.929 (99.324)
Epoch: [82][128/179]	Time 0.134 (0.134)	Data 0.000 (0.003)	Loss 0.7475 (0.7425)	Acc@1 83.214 (84.682)	Acc@5 98.571 (99.319)
Max memory in training epoch: 66.1794816
lr: 0.15634852909455085
1

Epoch: [83 | 85] LR: 0.156349
batch Size 280
Epoch: [83][0/179]	Time 0.163 (0.163)	Data 0.324 (0.324)	Loss 0.7707 (0.7707)	Acc@1 85.357 (85.357)	Acc@5 99.286 (99.286)
Epoch: [83][64/179]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.7035 (0.7218)	Acc@1 85.357 (85.209)	Acc@5 99.286 (99.308)
Epoch: [83][128/179]	Time 0.135 (0.134)	Data 0.000 (0.003)	Loss 0.6674 (0.7189)	Acc@1 89.643 (85.310)	Acc@5 99.643 (99.360)
Max memory in training epoch: 66.4059904
Drin!!
old memory: 659046400
new memory: 664059904
Faktor: 1.0076072094468613
New batch Size kleiner 282!!
lr: 0.15634852909455085
1

Epoch: [84 | 85] LR: 0.156349
batch Size 282
Epoch: [84][0/179]	Time 0.167 (0.167)	Data 0.301 (0.301)	Loss 0.6375 (0.6375)	Acc@1 89.286 (89.286)	Acc@5 100.000 (100.000)
Epoch: [84][64/179]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.8087 (0.7177)	Acc@1 82.143 (85.505)	Acc@5 99.286 (99.357)
Epoch: [84][128/179]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.7623 (0.7321)	Acc@1 84.643 (84.873)	Acc@5 99.286 (99.377)
Max memory in training epoch: 66.4059904
lr: 0.15634852909455085
1

Epoch: [85 | 85] LR: 0.156349
batch Size 282
Epoch: [85][0/179]	Time 0.181 (0.181)	Data 0.291 (0.291)	Loss 0.5732 (0.5732)	Acc@1 92.500 (92.500)	Acc@5 99.643 (99.643)
Epoch: [85][64/179]	Time 0.134 (0.138)	Data 0.000 (0.005)	Loss 0.7601 (0.7144)	Acc@1 83.214 (85.566)	Acc@5 98.571 (99.412)
Epoch: [85][128/179]	Time 0.139 (0.137)	Data 0.000 (0.002)	Loss 0.7683 (0.7226)	Acc@1 83.929 (85.399)	Acc@5 98.929 (99.394)
Max memory in training epoch: 66.4059904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 365114 ; 367136 ; 0.9944925041401551
[INFO] Storing checkpoint...
  75.15
Max memory: 92.3771904
 24.842s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9663
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1542656
lr: 0.17222767658071617
1

Epoch: [86 | 90] LR: 0.172228
batch Size 282
Epoch: [86][0/178]	Time 0.198 (0.198)	Data 0.264 (0.264)	Loss 0.8092 (0.8092)	Acc@1 84.397 (84.397)	Acc@5 98.582 (98.582)
Epoch: [86][64/178]	Time 0.132 (0.134)	Data 0.000 (0.004)	Loss 0.8386 (0.7239)	Acc@1 83.688 (85.014)	Acc@5 99.291 (99.422)
Epoch: [86][128/178]	Time 0.133 (0.135)	Data 0.000 (0.002)	Loss 0.8266 (0.7460)	Acc@1 80.496 (84.364)	Acc@5 99.645 (99.305)
Max memory in training epoch: 65.7690112
lr: 0.17222767658071617
1

Epoch: [87 | 90] LR: 0.172228
batch Size 282
Epoch: [87][0/178]	Time 0.190 (0.190)	Data 0.297 (0.297)	Loss 0.7123 (0.7123)	Acc@1 86.170 (86.170)	Acc@5 100.000 (100.000)
Epoch: [87][64/178]	Time 0.145 (0.135)	Data 0.000 (0.005)	Loss 0.8022 (0.7595)	Acc@1 84.043 (84.375)	Acc@5 99.645 (99.209)
Epoch: [87][128/178]	Time 0.137 (0.135)	Data 0.000 (0.002)	Loss 0.7288 (0.7563)	Acc@1 85.106 (84.304)	Acc@5 99.291 (99.296)
Max memory in training epoch: 66.2406144
lr: 0.17222767658071617
1

Epoch: [88 | 90] LR: 0.172228
batch Size 282
Epoch: [88][0/178]	Time 0.185 (0.185)	Data 0.319 (0.319)	Loss 0.7469 (0.7469)	Acc@1 85.816 (85.816)	Acc@5 98.936 (98.936)
Epoch: [88][64/178]	Time 0.136 (0.136)	Data 0.000 (0.005)	Loss 0.8027 (0.7557)	Acc@1 81.915 (84.610)	Acc@5 99.645 (99.231)
Epoch: [88][128/178]	Time 0.133 (0.135)	Data 0.000 (0.003)	Loss 0.7692 (0.7531)	Acc@1 84.397 (84.529)	Acc@5 99.291 (99.250)
Max memory in training epoch: 66.2406144
Drin!!
old memory: 664059904
new memory: 662406144
Faktor: 0.9975096222644395
New batch Size größer 285!!
lr: 0.17222767658071617
1

Epoch: [89 | 90] LR: 0.172228
batch Size 285
Epoch: [89][0/178]	Time 0.194 (0.194)	Data 0.266 (0.266)	Loss 0.7110 (0.7110)	Acc@1 84.043 (84.043)	Acc@5 99.645 (99.645)
Epoch: [89][64/178]	Time 0.133 (0.136)	Data 0.000 (0.004)	Loss 0.6708 (0.7394)	Acc@1 87.589 (84.610)	Acc@5 99.291 (99.378)
Epoch: [89][128/178]	Time 0.134 (0.136)	Data 0.000 (0.002)	Loss 0.6952 (0.7436)	Acc@1 85.106 (84.554)	Acc@5 99.291 (99.343)
Max memory in training epoch: 66.2406144
lr: 0.17222767658071617
1

Epoch: [90 | 90] LR: 0.172228
batch Size 285
Epoch: [90][0/178]	Time 0.165 (0.165)	Data 0.283 (0.283)	Loss 0.7627 (0.7627)	Acc@1 82.624 (82.624)	Acc@5 99.645 (99.645)
Epoch: [90][64/178]	Time 0.134 (0.136)	Data 0.000 (0.005)	Loss 0.7217 (0.7631)	Acc@1 85.816 (84.053)	Acc@5 99.645 (99.373)
Epoch: [90][128/178]	Time 0.135 (0.136)	Data 0.000 (0.002)	Loss 0.8141 (0.7577)	Acc@1 82.624 (84.367)	Acc@5 99.645 (99.384)
Max memory in training epoch: 66.2406144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 363604 ; 365114 ; 0.9958643053950273
[INFO] Storing checkpoint...
  72.63
Max memory: 92.2077696
 24.422s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 616
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1531392
lr: 0.1917378430683754
1

Epoch: [91 | 95] LR: 0.191738
batch Size 285
Epoch: [91][0/176]	Time 0.196 (0.196)	Data 0.269 (0.269)	Loss 0.7899 (0.7899)	Acc@1 83.509 (83.509)	Acc@5 98.947 (98.947)
Epoch: [91][64/176]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.7628 (0.7453)	Acc@1 84.211 (84.594)	Acc@5 99.298 (99.347)
Epoch: [91][128/176]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.7436 (0.7614)	Acc@1 85.263 (84.137)	Acc@5 100.000 (99.255)
Max memory in training epoch: 63.9842304
lr: 0.1917378430683754
1

Epoch: [92 | 95] LR: 0.191738
batch Size 285
Epoch: [92][0/176]	Time 0.168 (0.168)	Data 0.298 (0.298)	Loss 0.7478 (0.7478)	Acc@1 83.509 (83.509)	Acc@5 98.947 (98.947)
Epoch: [92][64/176]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.7303 (0.7615)	Acc@1 85.614 (84.178)	Acc@5 98.947 (99.201)
Epoch: [92][128/176]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6800 (0.7735)	Acc@1 89.123 (83.792)	Acc@5 99.649 (99.219)
Max memory in training epoch: 64.2679808
lr: 0.1917378430683754
1

Epoch: [93 | 95] LR: 0.019174
batch Size 285
Epoch: [93][0/176]	Time 0.180 (0.180)	Data 0.315 (0.315)	Loss 0.7428 (0.7428)	Acc@1 86.667 (86.667)	Acc@5 98.947 (98.947)
Epoch: [93][64/176]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.5563 (0.6366)	Acc@1 92.281 (88.934)	Acc@5 100.000 (99.579)
Epoch: [93][128/176]	Time 0.131 (0.131)	Data 0.000 (0.003)	Loss 0.6303 (0.6098)	Acc@1 88.070 (89.561)	Acc@5 99.298 (99.622)
Max memory in training epoch: 64.2847744
Drin!!
old memory: 662406144
new memory: 642847744
Faktor: 0.9704737038187858
New batch Size größer 297!!
lr: 0.01917378430683754
1

Epoch: [94 | 95] LR: 0.019174
batch Size 297
Epoch: [94][0/176]	Time 0.177 (0.177)	Data 0.297 (0.297)	Loss 0.5386 (0.5386)	Acc@1 91.579 (91.579)	Acc@5 99.649 (99.649)
Epoch: [94][64/176]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.4949 (0.5360)	Acc@1 94.035 (91.719)	Acc@5 100.000 (99.735)
Epoch: [94][128/176]	Time 0.131 (0.132)	Data 0.000 (0.003)	Loss 0.5272 (0.5341)	Acc@1 92.632 (91.682)	Acc@5 100.000 (99.777)
Max memory in training epoch: 64.2847744
lr: 0.01917378430683754
1

Epoch: [95 | 95] LR: 0.019174
batch Size 297
Epoch: [95][0/176]	Time 0.176 (0.176)	Data 0.313 (0.313)	Loss 0.5745 (0.5745)	Acc@1 90.175 (90.175)	Acc@5 99.298 (99.298)
Epoch: [95][64/176]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.5205 (0.5008)	Acc@1 92.632 (92.702)	Acc@5 99.649 (99.833)
Epoch: [95][128/176]	Time 0.132 (0.130)	Data 0.000 (0.003)	Loss 0.5343 (0.5041)	Acc@1 91.930 (92.607)	Acc@5 99.298 (99.801)
Max memory in training epoch: 64.2847744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 360428 ; 363604 ; 0.9912652226048119
[INFO] Storing checkpoint...
  90.41
Max memory: 89.2077568
 23.374s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2457
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1519104
lr: 0.02224458569972949
1

Epoch: [96 | 100] LR: 0.022245
batch Size 297
Epoch: [96][0/169]	Time 0.220 (0.220)	Data 0.267 (0.267)	Loss 0.4593 (0.4593)	Acc@1 93.603 (93.603)	Acc@5 100.000 (100.000)
Epoch: [96][64/169]	Time 0.130 (0.126)	Data 0.000 (0.004)	Loss 0.4609 (0.4793)	Acc@1 93.603 (93.100)	Acc@5 100.000 (99.839)
Epoch: [96][128/169]	Time 0.132 (0.127)	Data 0.000 (0.002)	Loss 0.4704 (0.4832)	Acc@1 92.929 (92.877)	Acc@5 100.000 (99.825)
Max memory in training epoch: 66.055936
lr: 0.02224458569972949
1

Epoch: [97 | 100] LR: 0.022245
batch Size 297
Epoch: [97][0/169]	Time 0.160 (0.160)	Data 0.313 (0.313)	Loss 0.4910 (0.4910)	Acc@1 92.593 (92.593)	Acc@5 99.327 (99.327)
Epoch: [97][64/169]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.4527 (0.4689)	Acc@1 93.603 (93.225)	Acc@5 100.000 (99.855)
Epoch: [97][128/169]	Time 0.128 (0.131)	Data 0.000 (0.003)	Loss 0.4387 (0.4650)	Acc@1 94.613 (93.271)	Acc@5 100.000 (99.851)
Max memory in training epoch: 66.3090176
lr: 0.02224458569972949
1

Epoch: [98 | 100] LR: 0.022245
batch Size 297
Epoch: [98][0/169]	Time 0.163 (0.163)	Data 0.286 (0.286)	Loss 0.4071 (0.4071)	Acc@1 95.286 (95.286)	Acc@5 100.000 (100.000)
Epoch: [98][64/169]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.3896 (0.4450)	Acc@1 95.623 (93.696)	Acc@5 100.000 (99.814)
Epoch: [98][128/169]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.4134 (0.4473)	Acc@1 94.613 (93.519)	Acc@5 100.000 (99.830)
Max memory in training epoch: 66.3090176
Drin!!
old memory: 642847744
new memory: 663090176
Faktor: 1.031488687934168
New batch Size kleiner 306!!
lr: 0.02224458569972949
1

Epoch: [99 | 100] LR: 0.022245
batch Size 306
Epoch: [99][0/169]	Time 0.161 (0.161)	Data 0.305 (0.305)	Loss 0.4677 (0.4677)	Acc@1 91.582 (91.582)	Acc@5 100.000 (100.000)
Epoch: [99][64/169]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.4045 (0.4366)	Acc@1 93.939 (93.618)	Acc@5 100.000 (99.922)
Epoch: [99][128/169]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.4065 (0.4346)	Acc@1 96.296 (93.671)	Acc@5 99.663 (99.906)
Max memory in training epoch: 66.3090176
lr: 0.02224458569972949
1

Epoch: [100 | 100] LR: 0.022245
batch Size 306
Epoch: [100][0/169]	Time 0.184 (0.184)	Data 0.276 (0.276)	Loss 0.3996 (0.3996)	Acc@1 94.613 (94.613)	Acc@5 100.000 (100.000)
Epoch: [100][64/169]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.3729 (0.4164)	Acc@1 95.623 (94.084)	Acc@5 100.000 (99.907)
Epoch: [100][128/169]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.3880 (0.4172)	Acc@1 95.286 (94.031)	Acc@5 100.000 (99.883)
Max memory in training epoch: 66.3090176
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.14
Max memory: 88.5263872
 22.435s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6910
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1519104
lr: 0.026589231344207907
1

Epoch: [101 | 105] LR: 0.026589
batch Size 306
Epoch: [101][0/164]	Time 0.207 (0.207)	Data 0.276 (0.276)	Loss 0.3965 (0.3965)	Acc@1 95.098 (95.098)	Acc@5 100.000 (100.000)
Epoch: [101][64/164]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.3830 (0.4023)	Acc@1 95.098 (94.465)	Acc@5 100.000 (99.925)
Epoch: [101][128/164]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.4229 (0.4094)	Acc@1 93.137 (94.100)	Acc@5 100.000 (99.883)
Max memory in training epoch: 69.6648192
lr: 0.026589231344207907
1

Epoch: [102 | 105] LR: 0.026589
batch Size 306
Epoch: [102][0/164]	Time 0.160 (0.160)	Data 0.285 (0.285)	Loss 0.3760 (0.3760)	Acc@1 94.444 (94.444)	Acc@5 100.000 (100.000)
Epoch: [102][64/164]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.4085 (0.4089)	Acc@1 92.810 (93.866)	Acc@5 100.000 (99.874)
Epoch: [102][128/164]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.4010 (0.4079)	Acc@1 94.771 (93.874)	Acc@5 100.000 (99.904)
Max memory in training epoch: 69.8104832
lr: 0.026589231344207907
1

Epoch: [103 | 105] LR: 0.026589
batch Size 306
Epoch: [103][0/164]	Time 0.185 (0.185)	Data 0.313 (0.313)	Loss 0.3393 (0.3393)	Acc@1 96.405 (96.405)	Acc@5 100.000 (100.000)
Epoch: [103][64/164]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.4337 (0.3926)	Acc@1 93.791 (94.279)	Acc@5 100.000 (99.930)
Epoch: [103][128/164]	Time 0.128 (0.132)	Data 0.000 (0.003)	Loss 0.4358 (0.3989)	Acc@1 92.484 (93.953)	Acc@5 100.000 (99.894)
Max memory in training epoch: 69.8080256
Drin!!
old memory: 663090176
new memory: 698080256
Faktor: 1.0527682075024438
New batch Size kleiner 322!!
lr: 0.026589231344207907
1

Epoch: [104 | 105] LR: 0.026589
batch Size 322
Epoch: [104][0/164]	Time 0.153 (0.153)	Data 0.315 (0.315)	Loss 0.3927 (0.3927)	Acc@1 95.752 (95.752)	Acc@5 100.000 (100.000)
Epoch: [104][64/164]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.4246 (0.3975)	Acc@1 93.137 (94.128)	Acc@5 100.000 (99.874)
Epoch: [104][128/164]	Time 0.133 (0.133)	Data 0.000 (0.003)	Loss 0.3907 (0.3967)	Acc@1 94.771 (94.042)	Acc@5 99.673 (99.881)
Max memory in training epoch: 69.7428992
lr: 0.026589231344207907
1

Epoch: [105 | 105] LR: 0.026589
batch Size 322
Epoch: [105][0/164]	Time 0.172 (0.172)	Data 0.314 (0.314)	Loss 0.3855 (0.3855)	Acc@1 95.098 (95.098)	Acc@5 100.000 (100.000)
Epoch: [105][64/164]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.4231 (0.3875)	Acc@1 92.484 (94.007)	Acc@5 99.673 (99.894)
Epoch: [105][128/164]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.4043 (0.3924)	Acc@1 91.830 (93.839)	Acc@5 100.000 (99.876)
Max memory in training epoch: 69.7428992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.56
Max memory: 88.4749824
 21.730s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8538
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1519104
lr: 0.033444267550136506
1

Epoch: [106 | 110] LR: 0.033444
batch Size 322
Epoch: [106][0/156]	Time 0.194 (0.194)	Data 0.278 (0.278)	Loss 0.3354 (0.3354)	Acc@1 96.273 (96.273)	Acc@5 100.000 (100.000)
Epoch: [106][64/156]	Time 0.125 (0.133)	Data 0.000 (0.004)	Loss 0.4363 (0.3820)	Acc@1 92.547 (94.004)	Acc@5 100.000 (99.857)
Epoch: [106][128/156]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.3598 (0.3980)	Acc@1 93.478 (93.377)	Acc@5 100.000 (99.877)
Max memory in training epoch: 71.624704
lr: 0.033444267550136506
1

Epoch: [107 | 110] LR: 0.033444
batch Size 322
Epoch: [107][0/156]	Time 0.158 (0.158)	Data 0.295 (0.295)	Loss 0.3781 (0.3781)	Acc@1 93.789 (93.789)	Acc@5 100.000 (100.000)
Epoch: [107][64/156]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.4303 (0.4096)	Acc@1 91.925 (93.000)	Acc@5 100.000 (99.857)
Epoch: [107][128/156]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.4358 (0.4120)	Acc@1 90.373 (92.903)	Acc@5 100.000 (99.865)
Max memory in training epoch: 71.7281792
lr: 0.033444267550136506
1

Epoch: [108 | 110] LR: 0.033444
batch Size 322
Epoch: [108][0/156]	Time 0.155 (0.155)	Data 0.333 (0.333)	Loss 0.3564 (0.3564)	Acc@1 94.720 (94.720)	Acc@5 100.000 (100.000)
Epoch: [108][64/156]	Time 0.137 (0.134)	Data 0.000 (0.005)	Loss 0.4085 (0.4005)	Acc@1 92.236 (93.306)	Acc@5 100.000 (99.871)
Epoch: [108][128/156]	Time 0.127 (0.132)	Data 0.000 (0.003)	Loss 0.4268 (0.4078)	Acc@1 91.925 (93.030)	Acc@5 99.689 (99.882)
Max memory in training epoch: 71.7281792
Drin!!
old memory: 697428992
new memory: 717281792
Faktor: 1.0284656936085617
New batch Size kleiner 331!!
lr: 0.033444267550136506
1

Epoch: [109 | 110] LR: 0.033444
batch Size 331
Epoch: [109][0/156]	Time 0.187 (0.187)	Data 0.284 (0.284)	Loss 0.3880 (0.3880)	Acc@1 94.410 (94.410)	Acc@5 100.000 (100.000)
Epoch: [109][64/156]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 0.4002 (0.3969)	Acc@1 90.994 (93.397)	Acc@5 99.689 (99.914)
Epoch: [109][128/156]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.4216 (0.4106)	Acc@1 92.236 (92.816)	Acc@5 100.000 (99.875)
Max memory in training epoch: 71.7281792
lr: 0.033444267550136506
1

Epoch: [110 | 110] LR: 0.033444
batch Size 331
Epoch: [110][0/156]	Time 0.157 (0.157)	Data 0.314 (0.314)	Loss 0.3824 (0.3824)	Acc@1 95.342 (95.342)	Acc@5 99.379 (99.379)
Epoch: [110][64/156]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.3761 (0.4070)	Acc@1 94.410 (92.977)	Acc@5 100.000 (99.861)
Epoch: [110][128/156]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.4069 (0.4155)	Acc@1 93.168 (92.648)	Acc@5 100.000 (99.856)
Max memory in training epoch: 71.7281792
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 359274 ; 360428 ; 0.9967982509682932
[INFO] Storing checkpoint...
  84.48
Max memory: 88.8856064
 20.788s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1662
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1513984
lr: 0.04324239280896556
1

Epoch: [111 | 115] LR: 0.043242
batch Size 331
Epoch: [111][0/152]	Time 0.201 (0.201)	Data 0.284 (0.284)	Loss 0.3926 (0.3926)	Acc@1 93.051 (93.051)	Acc@5 100.000 (100.000)
Epoch: [111][64/152]	Time 0.131 (0.135)	Data 0.000 (0.005)	Loss 0.4789 (0.4106)	Acc@1 90.634 (92.865)	Acc@5 100.000 (99.851)
Epoch: [111][128/152]	Time 0.132 (0.135)	Data 0.000 (0.002)	Loss 0.4325 (0.4337)	Acc@1 91.541 (92.063)	Acc@5 100.000 (99.834)
Max memory in training epoch: 73.4702592
lr: 0.04324239280896556
1

Epoch: [112 | 115] LR: 0.043242
batch Size 331
Epoch: [112][0/152]	Time 0.186 (0.186)	Data 0.312 (0.312)	Loss 0.4672 (0.4672)	Acc@1 91.541 (91.541)	Acc@5 100.000 (100.000)
Epoch: [112][64/152]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.5125 (0.6024)	Acc@1 89.124 (86.953)	Acc@5 100.000 (99.447)
Epoch: [112][128/152]	Time 0.139 (0.132)	Data 0.000 (0.003)	Loss 0.5137 (0.5476)	Acc@1 89.728 (88.721)	Acc@5 100.000 (99.625)
Max memory in training epoch: 73.5083008
lr: 0.04324239280896556
1

Epoch: [113 | 115] LR: 0.043242
batch Size 331
Epoch: [113][0/152]	Time 0.188 (0.188)	Data 0.323 (0.323)	Loss 0.4482 (0.4482)	Acc@1 91.541 (91.541)	Acc@5 100.000 (100.000)
Epoch: [113][64/152]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.5229 (0.4969)	Acc@1 90.332 (90.523)	Acc@5 99.698 (99.726)
Epoch: [113][128/152]	Time 0.132 (0.134)	Data 0.000 (0.003)	Loss 0.4399 (0.4889)	Acc@1 91.843 (90.677)	Acc@5 100.000 (99.778)
Max memory in training epoch: 73.5083008
Drin!!
old memory: 717281792
new memory: 735083008
Faktor: 1.0248176047385293
New batch Size kleiner 339!!
lr: 0.04324239280896556
1

Epoch: [114 | 115] LR: 0.043242
batch Size 339
Epoch: [114][0/152]	Time 0.162 (0.162)	Data 0.308 (0.308)	Loss 0.4197 (0.4197)	Acc@1 93.656 (93.656)	Acc@5 100.000 (100.000)
Epoch: [114][64/152]	Time 0.138 (0.137)	Data 0.000 (0.005)	Loss 0.5229 (0.4778)	Acc@1 90.937 (91.025)	Acc@5 99.094 (99.833)
Epoch: [114][128/152]	Time 0.138 (0.136)	Data 0.000 (0.003)	Loss 0.5294 (0.4664)	Acc@1 89.426 (91.396)	Acc@5 100.000 (99.817)
Max memory in training epoch: 73.5083008
lr: 0.04324239280896556
1

Epoch: [115 | 115] LR: 0.043242
batch Size 339
Epoch: [115][0/152]	Time 0.185 (0.185)	Data 0.308 (0.308)	Loss 0.3856 (0.3856)	Acc@1 96.375 (96.375)	Acc@5 99.698 (99.698)
Epoch: [115][64/152]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.4630 (0.5002)	Acc@1 90.030 (90.342)	Acc@5 100.000 (99.777)
Epoch: [115][128/152]	Time 0.130 (0.134)	Data 0.000 (0.003)	Loss 0.4407 (0.4811)	Acc@1 94.260 (90.915)	Acc@5 99.698 (99.773)
Max memory in training epoch: 73.5083008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 358120 ; 359274 ; 0.996787966844247
[INFO] Storing checkpoint...
  72.88
Max memory: 88.8863232
 20.634s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2615
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1509888
lr: 0.05726238735249736
1

Epoch: [116 | 120] LR: 0.057262
batch Size 339
Epoch: [116][0/148]	Time 0.230 (0.230)	Data 0.277 (0.277)	Loss 0.4065 (0.4065)	Acc@1 93.215 (93.215)	Acc@5 100.000 (100.000)
Epoch: [116][64/148]	Time 0.141 (0.138)	Data 0.000 (0.004)	Loss 0.5270 (0.4653)	Acc@1 88.791 (91.359)	Acc@5 99.705 (99.746)
Epoch: [116][128/148]	Time 0.134 (0.138)	Data 0.000 (0.002)	Loss 0.5663 (0.4808)	Acc@1 87.316 (90.855)	Acc@5 100.000 (99.760)
Max memory in training epoch: 76.447232
lr: 0.05726238735249736
1

Epoch: [117 | 120] LR: 0.057262
batch Size 339
Epoch: [117][0/148]	Time 0.176 (0.176)	Data 0.307 (0.307)	Loss 0.4627 (0.4627)	Acc@1 92.920 (92.920)	Acc@5 100.000 (100.000)
Epoch: [117][64/148]	Time 0.133 (0.136)	Data 0.000 (0.005)	Loss 0.4834 (0.4850)	Acc@1 91.445 (90.842)	Acc@5 99.705 (99.796)
Epoch: [117][128/148]	Time 0.137 (0.136)	Data 0.000 (0.003)	Loss 0.5073 (0.4889)	Acc@1 91.150 (90.725)	Acc@5 99.705 (99.769)
Max memory in training epoch: 76.2349056
lr: 0.05726238735249736
1

Epoch: [118 | 120] LR: 0.057262
batch Size 339
Epoch: [118][0/148]	Time 0.176 (0.176)	Data 0.289 (0.289)	Loss 0.4780 (0.4780)	Acc@1 90.855 (90.855)	Acc@5 100.000 (100.000)
Epoch: [118][64/148]	Time 0.137 (0.135)	Data 0.000 (0.005)	Loss 0.5169 (0.4823)	Acc@1 90.560 (91.064)	Acc@5 99.115 (99.764)
Epoch: [118][128/148]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.5438 (0.4877)	Acc@1 87.611 (90.771)	Acc@5 99.115 (99.753)
Max memory in training epoch: 76.2349056
Drin!!
old memory: 735083008
new memory: 762349056
Faktor: 1.0370924748678179
New batch Size kleiner 351!!
lr: 0.05726238735249736
1

Epoch: [119 | 120] LR: 0.057262
batch Size 351
Epoch: [119][0/148]	Time 0.158 (0.158)	Data 0.291 (0.291)	Loss 0.5404 (0.5404)	Acc@1 88.791 (88.791)	Acc@5 100.000 (100.000)
Epoch: [119][64/148]	Time 0.135 (0.136)	Data 0.000 (0.005)	Loss 0.5408 (0.4836)	Acc@1 88.791 (90.869)	Acc@5 100.000 (99.787)
Epoch: [119][128/148]	Time 0.134 (0.135)	Data 0.000 (0.002)	Loss 0.5878 (0.4914)	Acc@1 86.136 (90.627)	Acc@5 99.705 (99.778)
Max memory in training epoch: 76.2349056
lr: 0.05726238735249736
1

Epoch: [120 | 120] LR: 0.057262
batch Size 351
Epoch: [120][0/148]	Time 0.184 (0.184)	Data 0.313 (0.313)	Loss 0.4731 (0.4731)	Acc@1 90.560 (90.560)	Acc@5 100.000 (100.000)
Epoch: [120][64/148]	Time 0.133 (0.137)	Data 0.000 (0.005)	Loss 0.4550 (0.4706)	Acc@1 92.920 (91.396)	Acc@5 99.705 (99.805)
Epoch: [120][128/148]	Time 0.140 (0.137)	Data 0.000 (0.003)	Loss 0.5727 (0.4826)	Acc@1 88.496 (91.000)	Acc@5 99.410 (99.790)
Max memory in training epoch: 76.2349056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356966 ; 358120 ; 0.9967776164414163
[INFO] Storing checkpoint...
  84.21
Max memory: 88.974592
 20.673s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4799
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1504768
lr: 0.07851210140908818
1

Epoch: [121 | 125] LR: 0.078512
batch Size 351
Epoch: [121][0/143]	Time 0.194 (0.194)	Data 0.322 (0.322)	Loss 0.5549 (0.5549)	Acc@1 89.459 (89.459)	Acc@5 99.715 (99.715)
Epoch: [121][64/143]	Time 0.132 (0.136)	Data 0.000 (0.005)	Loss 0.6392 (0.5167)	Acc@1 84.900 (89.853)	Acc@5 98.860 (99.693)
Epoch: [121][128/143]	Time 0.139 (0.136)	Data 0.000 (0.003)	Loss 0.5125 (0.5400)	Acc@1 89.459 (89.057)	Acc@5 99.715 (99.671)
Max memory in training epoch: 78.4838144
lr: 0.07851210140908818
1

Epoch: [122 | 125] LR: 0.078512
batch Size 351
Epoch: [122][0/143]	Time 0.188 (0.188)	Data 0.332 (0.332)	Loss 0.4888 (0.4888)	Acc@1 92.023 (92.023)	Acc@5 100.000 (100.000)
Epoch: [122][64/143]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.4899 (0.5311)	Acc@1 90.883 (89.397)	Acc@5 99.430 (99.706)
Epoch: [122][128/143]	Time 0.137 (0.134)	Data 0.000 (0.003)	Loss 0.6261 (0.5443)	Acc@1 84.615 (89.019)	Acc@5 99.715 (99.684)
Max memory in training epoch: 78.365184
lr: 0.07851210140908818
1

Epoch: [123 | 125] LR: 0.078512
batch Size 351
Epoch: [123][0/143]	Time 0.166 (0.166)	Data 0.295 (0.295)	Loss 0.4570 (0.4570)	Acc@1 91.738 (91.738)	Acc@5 99.715 (99.715)
Epoch: [123][64/143]	Time 0.133 (0.135)	Data 0.000 (0.005)	Loss 0.4960 (0.5399)	Acc@1 90.883 (89.673)	Acc@5 100.000 (99.649)
Epoch: [123][128/143]	Time 0.134 (0.134)	Data 0.000 (0.003)	Loss 0.5222 (0.5383)	Acc@1 88.319 (89.710)	Acc@5 99.715 (99.711)
Max memory in training epoch: 78.365184
Drin!!
old memory: 762349056
new memory: 783651840
Faktor: 1.027943609075578
New batch Size kleiner 360!!
lr: 0.07851210140908818
1

Epoch: [124 | 125] LR: 0.078512
batch Size 360
Epoch: [124][0/143]	Time 0.197 (0.197)	Data 0.325 (0.325)	Loss 0.4993 (0.4993)	Acc@1 90.598 (90.598)	Acc@5 99.430 (99.430)
Epoch: [124][64/143]	Time 0.139 (0.139)	Data 0.000 (0.005)	Loss 0.5282 (0.5356)	Acc@1 88.889 (89.717)	Acc@5 99.715 (99.684)
Epoch: [124][128/143]	Time 0.138 (0.139)	Data 0.000 (0.003)	Loss 0.5362 (0.5362)	Acc@1 90.598 (89.710)	Acc@5 100.000 (99.713)
Max memory in training epoch: 78.365184
lr: 0.07851210140908818
1

Epoch: [125 | 125] LR: 0.078512
batch Size 360
Epoch: [125][0/143]	Time 0.189 (0.189)	Data 0.351 (0.351)	Loss 0.5652 (0.5652)	Acc@1 88.604 (88.604)	Acc@5 99.715 (99.715)
Epoch: [125][64/143]	Time 0.134 (0.138)	Data 0.000 (0.006)	Loss 0.5580 (0.5353)	Acc@1 88.319 (89.840)	Acc@5 99.715 (99.719)
Epoch: [125][128/143]	Time 0.132 (0.137)	Data 0.000 (0.003)	Loss 0.5734 (0.5370)	Acc@1 88.319 (89.677)	Acc@5 99.715 (99.720)
Max memory in training epoch: 78.365184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.61
Max memory: 88.817408
 20.002s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8346
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1504768
lr: 0.11040764260653026
1

Epoch: [126 | 130] LR: 0.110408
batch Size 360
Epoch: [126][0/139]	Time 0.214 (0.214)	Data 0.288 (0.288)	Loss 0.5329 (0.5329)	Acc@1 90.556 (90.556)	Acc@5 99.722 (99.722)
Epoch: [126][64/139]	Time 0.134 (0.138)	Data 0.000 (0.005)	Loss 0.6338 (0.5781)	Acc@1 85.833 (88.462)	Acc@5 99.444 (99.598)
Epoch: [126][128/139]	Time 0.135 (0.137)	Data 0.000 (0.002)	Loss 0.5936 (0.5996)	Acc@1 89.167 (87.814)	Acc@5 99.722 (99.554)
Max memory in training epoch: 80.2944
lr: 0.11040764260653026
1

Epoch: [127 | 130] LR: 0.110408
batch Size 360
Epoch: [127][0/139]	Time 0.209 (0.209)	Data 0.327 (0.327)	Loss 0.5638 (0.5638)	Acc@1 88.333 (88.333)	Acc@5 100.000 (100.000)
Epoch: [127][64/139]	Time 0.137 (0.140)	Data 0.000 (0.005)	Loss 0.6978 (0.6062)	Acc@1 86.667 (87.808)	Acc@5 99.722 (99.581)
Epoch: [127][128/139]	Time 0.134 (0.139)	Data 0.000 (0.003)	Loss 0.6207 (0.6104)	Acc@1 86.111 (87.662)	Acc@5 99.167 (99.533)
Max memory in training epoch: 80.3658752
lr: 0.11040764260653026
1

Epoch: [128 | 130] LR: 0.110408
batch Size 360
Epoch: [128][0/139]	Time 0.194 (0.194)	Data 0.359 (0.359)	Loss 0.6046 (0.6046)	Acc@1 85.556 (85.556)	Acc@5 99.444 (99.444)
Epoch: [128][64/139]	Time 0.138 (0.139)	Data 0.000 (0.006)	Loss 0.6486 (0.5971)	Acc@1 86.944 (88.248)	Acc@5 99.444 (99.624)
Epoch: [128][128/139]	Time 0.135 (0.139)	Data 0.000 (0.003)	Loss 0.5081 (0.5987)	Acc@1 91.667 (88.232)	Acc@5 100.000 (99.595)
Max memory in training epoch: 80.3658752
Drin!!
old memory: 783651840
new memory: 803658752
Faktor: 1.0255303579712134
New batch Size kleiner 369!!
lr: 0.11040764260653026
1

Epoch: [129 | 130] LR: 0.110408
batch Size 369
Epoch: [129][0/139]	Time 0.191 (0.191)	Data 0.327 (0.327)	Loss 0.4978 (0.4978)	Acc@1 91.944 (91.944)	Acc@5 99.722 (99.722)
Epoch: [129][64/139]	Time 0.133 (0.136)	Data 0.000 (0.005)	Loss 0.6081 (0.5924)	Acc@1 89.167 (88.444)	Acc@5 99.444 (99.607)
Epoch: [129][128/139]	Time 0.132 (0.135)	Data 0.000 (0.003)	Loss 0.5768 (0.6009)	Acc@1 89.444 (88.157)	Acc@5 100.000 (99.610)
Max memory in training epoch: 80.3658752
lr: 0.11040764260653026
1

Epoch: [130 | 130] LR: 0.110408
batch Size 369
Epoch: [130][0/139]	Time 0.176 (0.176)	Data 0.358 (0.358)	Loss 0.6319 (0.6319)	Acc@1 87.778 (87.778)	Acc@5 99.722 (99.722)
Epoch: [130][64/139]	Time 0.133 (0.136)	Data 0.000 (0.006)	Loss 0.5492 (0.5808)	Acc@1 91.389 (88.829)	Acc@5 100.000 (99.697)
Epoch: [130][128/139]	Time 0.128 (0.135)	Data 0.000 (0.003)	Loss 0.6625 (0.5923)	Acc@1 86.667 (88.422)	Acc@5 100.000 (99.658)
Max memory in training epoch: 80.3658752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353498 ; 356966 ; 0.9902847890275265
[INFO] Storing checkpoint...
  79.61
Max memory: 88.954624
 19.194s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4175
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1491456
lr: 0.159142266100819
1

Epoch: [131 | 135] LR: 0.159142
batch Size 369
Epoch: [131][0/136]	Time 0.215 (0.215)	Data 0.316 (0.316)	Loss 0.6545 (0.6545)	Acc@1 86.992 (86.992)	Acc@5 99.729 (99.729)
Epoch: [131][64/136]	Time 0.139 (0.136)	Data 0.000 (0.005)	Loss 0.6013 (0.6499)	Acc@1 88.076 (86.725)	Acc@5 99.729 (99.496)
Epoch: [131][128/136]	Time 0.138 (0.136)	Data 0.000 (0.003)	Loss 0.6757 (0.6671)	Acc@1 86.450 (86.097)	Acc@5 99.458 (99.452)
Max memory in training epoch: 82.741504
lr: 0.159142266100819
1

Epoch: [132 | 135] LR: 0.159142
batch Size 369
Epoch: [132][0/136]	Time 0.206 (0.206)	Data 0.319 (0.319)	Loss 0.7316 (0.7316)	Acc@1 84.553 (84.553)	Acc@5 99.187 (99.187)
Epoch: [132][64/136]	Time 0.138 (0.140)	Data 0.000 (0.005)	Loss 0.6320 (0.6849)	Acc@1 87.534 (85.833)	Acc@5 100.000 (99.516)
Epoch: [132][128/136]	Time 0.135 (0.139)	Data 0.000 (0.003)	Loss 0.7368 (0.6772)	Acc@1 86.450 (86.107)	Acc@5 99.729 (99.517)
Max memory in training epoch: 82.7727872
lr: 0.159142266100819
1

Epoch: [133 | 135] LR: 0.159142
batch Size 369
Epoch: [133][0/136]	Time 0.189 (0.189)	Data 0.315 (0.315)	Loss 0.6504 (0.6504)	Acc@1 86.450 (86.450)	Acc@5 99.458 (99.458)
Epoch: [133][64/136]	Time 0.140 (0.141)	Data 0.000 (0.005)	Loss 0.7578 (0.6636)	Acc@1 83.469 (86.654)	Acc@5 99.187 (99.504)
Epoch: [133][128/136]	Time 0.135 (0.140)	Data 0.000 (0.003)	Loss 0.7504 (0.6679)	Acc@1 82.927 (86.517)	Acc@5 99.729 (99.515)
Max memory in training epoch: 82.7727872
Drin!!
old memory: 803658752
new memory: 827727872
Faktor: 1.029949428087607
New batch Size kleiner 380!!
lr: 0.159142266100819
1

Epoch: [134 | 135] LR: 0.159142
batch Size 380
Epoch: [134][0/136]	Time 0.202 (0.202)	Data 0.298 (0.298)	Loss 0.6752 (0.6752)	Acc@1 86.450 (86.450)	Acc@5 100.000 (100.000)
Epoch: [134][64/136]	Time 0.137 (0.137)	Data 0.000 (0.005)	Loss 0.6736 (0.6574)	Acc@1 87.263 (87.059)	Acc@5 99.458 (99.537)
Epoch: [134][128/136]	Time 0.136 (0.137)	Data 0.000 (0.003)	Loss 0.7569 (0.6616)	Acc@1 82.114 (86.878)	Acc@5 98.645 (99.502)
Max memory in training epoch: 82.7727872
lr: 0.159142266100819
1

Epoch: [135 | 135] LR: 0.159142
batch Size 380
Epoch: [135][0/136]	Time 0.165 (0.165)	Data 0.306 (0.306)	Loss 0.6243 (0.6243)	Acc@1 87.805 (87.805)	Acc@5 99.729 (99.729)
Epoch: [135][64/136]	Time 0.138 (0.140)	Data 0.000 (0.005)	Loss 0.6822 (0.6587)	Acc@1 85.908 (86.746)	Acc@5 99.187 (99.562)
Epoch: [135][128/136]	Time 0.138 (0.139)	Data 0.000 (0.003)	Loss 0.6270 (0.6634)	Acc@1 88.889 (86.616)	Acc@5 99.458 (99.515)
Max memory in training epoch: 82.7727872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353064 ; 353498 ; 0.9987722702815858
[INFO] Storing checkpoint...
  80.25
Max memory: 87.9788544
 19.240s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3748
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1488896
lr: 0.2362268012434032
1

Epoch: [136 | 140] LR: 0.236227
batch Size 380
Epoch: [136][0/132]	Time 0.196 (0.196)	Data 0.320 (0.320)	Loss 0.6167 (0.6167)	Acc@1 88.158 (88.158)	Acc@5 100.000 (100.000)
Epoch: [136][64/132]	Time 0.141 (0.139)	Data 0.000 (0.005)	Loss 0.7676 (0.7215)	Acc@1 82.105 (84.919)	Acc@5 98.947 (99.328)
Epoch: [136][128/132]	Time 0.140 (0.140)	Data 0.000 (0.003)	Loss 0.7966 (0.7456)	Acc@1 83.421 (84.380)	Acc@5 98.684 (99.280)
Max memory in training epoch: 83.9799296
lr: 0.2362268012434032
1

Epoch: [137 | 140] LR: 0.236227
batch Size 380
Epoch: [137][0/132]	Time 0.174 (0.174)	Data 0.362 (0.362)	Loss 0.7968 (0.7968)	Acc@1 82.895 (82.895)	Acc@5 99.211 (99.211)
Epoch: [137][64/132]	Time 0.137 (0.140)	Data 0.000 (0.006)	Loss 0.7389 (0.7643)	Acc@1 85.789 (84.283)	Acc@5 99.474 (99.247)
Epoch: [137][128/132]	Time 0.139 (0.140)	Data 0.000 (0.003)	Loss 0.7065 (0.7676)	Acc@1 86.842 (84.198)	Acc@5 99.737 (99.251)
Max memory in training epoch: 84.0339968
lr: 0.2362268012434032
1

Epoch: [138 | 140] LR: 0.236227
batch Size 380
Epoch: [138][0/132]	Time 0.198 (0.198)	Data 0.318 (0.318)	Loss 0.7503 (0.7503)	Acc@1 85.789 (85.789)	Acc@5 99.474 (99.474)
Epoch: [138][64/132]	Time 0.143 (0.140)	Data 0.000 (0.005)	Loss 0.7801 (0.7484)	Acc@1 83.947 (84.789)	Acc@5 98.684 (99.324)
Epoch: [138][128/132]	Time 0.143 (0.141)	Data 0.000 (0.003)	Loss 0.7826 (0.7470)	Acc@1 84.737 (84.782)	Acc@5 99.737 (99.317)
Max memory in training epoch: 83.9853568
Drin!!
old memory: 827727872
new memory: 839853568
Faktor: 1.0146493750061856
New batch Size kleiner 385!!
lr: 0.2362268012434032
1

Epoch: [139 | 140] LR: 0.236227
batch Size 385
Epoch: [139][0/132]	Time 0.184 (0.184)	Data 0.323 (0.323)	Loss 0.7291 (0.7291)	Acc@1 83.421 (83.421)	Acc@5 99.474 (99.474)
Epoch: [139][64/132]	Time 0.141 (0.141)	Data 0.000 (0.005)	Loss 0.8162 (0.7432)	Acc@1 81.316 (84.765)	Acc@5 99.211 (99.235)
Epoch: [139][128/132]	Time 0.137 (0.142)	Data 0.000 (0.003)	Loss 0.7467 (0.7541)	Acc@1 83.947 (84.361)	Acc@5 99.211 (99.249)
Max memory in training epoch: 83.9591424
lr: 0.2362268012434032
1

Epoch: [140 | 140] LR: 0.236227
batch Size 385
Epoch: [140][0/132]	Time 0.165 (0.165)	Data 0.303 (0.303)	Loss 0.7326 (0.7326)	Acc@1 85.789 (85.789)	Acc@5 99.474 (99.474)
Epoch: [140][64/132]	Time 0.144 (0.143)	Data 0.000 (0.005)	Loss 0.7569 (0.7290)	Acc@1 86.053 (85.534)	Acc@5 99.474 (99.344)
Epoch: [140][128/132]	Time 0.139 (0.143)	Data 0.000 (0.003)	Loss 0.8055 (0.7455)	Acc@1 81.579 (84.871)	Acc@5 99.737 (99.272)
Max memory in training epoch: 83.9591424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 350254 ; 353064 ; 0.9920411030294791
[INFO] Storing checkpoint...
  63.19
Max memory: 88.2310144
 19.259s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3338
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1472
lr: 0.35526296280746184
1

Epoch: [141 | 145] LR: 0.355263
batch Size 385
Epoch: [141][0/130]	Time 0.223 (0.223)	Data 0.289 (0.289)	Loss 0.7127 (0.7127)	Acc@1 87.792 (87.792)	Acc@5 98.442 (98.442)
Epoch: [141][64/130]	Time 0.134 (0.133)	Data 0.000 (0.005)	Loss 0.9262 (0.8364)	Acc@1 80.000 (81.830)	Acc@5 98.701 (99.005)
Epoch: [141][128/130]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 1.0287 (0.8513)	Acc@1 77.922 (81.687)	Acc@5 98.961 (98.971)
Max memory in training epoch: 81.4663168
lr: 0.35526296280746184
1

Epoch: [142 | 145] LR: 0.355263
batch Size 385
Epoch: [142][0/130]	Time 0.148 (0.148)	Data 0.295 (0.295)	Loss 0.9148 (0.9148)	Acc@1 79.481 (79.481)	Acc@5 97.922 (97.922)
Epoch: [142][64/130]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.8104 (0.8743)	Acc@1 81.818 (81.071)	Acc@5 99.740 (98.997)
Epoch: [142][128/130]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8423 (0.8589)	Acc@1 81.558 (81.752)	Acc@5 100.000 (98.995)
Max memory in training epoch: 81.4663168
lr: 0.35526296280746184
1

Epoch: [143 | 145] LR: 0.355263
batch Size 385
Epoch: [143][0/130]	Time 0.165 (0.165)	Data 0.303 (0.303)	Loss 0.8885 (0.8885)	Acc@1 82.078 (82.078)	Acc@5 98.961 (98.961)
Epoch: [143][64/130]	Time 0.136 (0.135)	Data 0.000 (0.005)	Loss 0.8946 (0.8435)	Acc@1 79.221 (82.222)	Acc@5 98.961 (99.037)
Epoch: [143][128/130]	Time 0.132 (0.135)	Data 0.000 (0.003)	Loss 0.8369 (0.8477)	Acc@1 81.039 (81.951)	Acc@5 98.961 (99.021)
Max memory in training epoch: 81.4663168
Drin!!
old memory: 839591424
new memory: 814663168
Faktor: 0.9703090630901918
New batch Size größer 316!!
lr: 0.35526296280746184
1

Epoch: [144 | 145] LR: 0.355263
batch Size 316
Epoch: [144][0/130]	Time 0.187 (0.187)	Data 0.331 (0.331)	Loss 0.8284 (0.8284)	Acc@1 82.857 (82.857)	Acc@5 99.221 (99.221)
Epoch: [144][64/130]	Time 0.133 (0.137)	Data 0.000 (0.005)	Loss 0.8193 (0.8404)	Acc@1 83.636 (82.442)	Acc@5 98.701 (99.057)
Epoch: [144][128/130]	Time 0.130 (0.136)	Data 0.000 (0.003)	Loss 0.8556 (0.8463)	Acc@1 82.857 (82.112)	Acc@5 98.701 (99.019)
Max memory in training epoch: 81.4663168
lr: 0.35526296280746184
1

Epoch: [145 | 145] LR: 0.355263
batch Size 316
Epoch: [145][0/130]	Time 0.183 (0.183)	Data 0.318 (0.318)	Loss 0.8084 (0.8084)	Acc@1 84.156 (84.156)	Acc@5 98.701 (98.701)
Epoch: [145][64/130]	Time 0.133 (0.135)	Data 0.000 (0.005)	Loss 0.8299 (0.8238)	Acc@1 81.039 (82.609)	Acc@5 98.701 (99.169)
Epoch: [145][128/130]	Time 0.131 (0.136)	Data 0.000 (0.003)	Loss 0.8327 (0.8388)	Acc@1 82.078 (82.062)	Acc@5 99.221 (99.100)
Max memory in training epoch: 81.4663168
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 344766 ; 350254 ; 0.9843313709479407
[INFO] Storing checkpoint...
  66.24
Max memory: 85.961472
 18.062s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 303
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1450496
lr: 0.43852771971546073
1

Epoch: [146 | 150] LR: 0.438528
batch Size 316
Epoch: [146][0/159]	Time 0.185 (0.185)	Data 0.304 (0.304)	Loss 0.8111 (0.8111)	Acc@1 82.911 (82.911)	Acc@5 99.367 (99.367)
Epoch: [146][64/159]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.9708 (0.9360)	Acc@1 76.582 (79.012)	Acc@5 99.051 (98.627)
Epoch: [146][128/159]	Time 0.126 (0.122)	Data 0.000 (0.003)	Loss 1.0892 (0.9572)	Acc@1 74.684 (78.856)	Acc@5 97.785 (98.594)
Max memory in training epoch: 66.940672
lr: 0.43852771971546073
1

Epoch: [147 | 150] LR: 0.438528
batch Size 316
Epoch: [147][0/159]	Time 0.155 (0.155)	Data 0.282 (0.282)	Loss 1.0340 (1.0340)	Acc@1 77.848 (77.848)	Acc@5 99.367 (99.367)
Epoch: [147][64/159]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.9189 (0.9877)	Acc@1 81.646 (78.043)	Acc@5 98.734 (98.564)
Epoch: [147][128/159]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 1.0742 (0.9673)	Acc@1 74.684 (78.704)	Acc@5 98.101 (98.646)
Max memory in training epoch: 66.9306368
lr: 0.43852771971546073
1

Epoch: [148 | 150] LR: 0.438528
batch Size 316
Epoch: [148][0/159]	Time 0.174 (0.174)	Data 0.320 (0.320)	Loss 0.9690 (0.9690)	Acc@1 78.797 (78.797)	Acc@5 98.101 (98.101)
Epoch: [148][64/159]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.9855 (0.9788)	Acc@1 77.848 (78.340)	Acc@5 98.418 (98.666)
Epoch: [148][128/159]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.9527 (0.9662)	Acc@1 77.848 (78.496)	Acc@5 99.367 (98.688)
Max memory in training epoch: 66.9306368
Drin!!
old memory: 814663168
new memory: 669306368
Faktor: 0.8215743564829974
New batch Size größer 316!!
lr: 0.43852771971546073
1

Epoch: [149 | 150] LR: 0.438528
batch Size 316
Epoch: [149][0/159]	Time 0.172 (0.172)	Data 0.313 (0.313)	Loss 0.8846 (0.8846)	Acc@1 79.430 (79.430)	Acc@5 99.367 (99.367)
Epoch: [149][64/159]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 1.0023 (0.9337)	Acc@1 74.684 (79.401)	Acc@5 98.734 (98.836)
Epoch: [149][128/159]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.9369 (0.9509)	Acc@1 80.063 (78.756)	Acc@5 98.734 (98.734)
Max memory in training epoch: 66.9306368
lr: 0.43852771971546073
1

Epoch: [150 | 150] LR: 0.043853
batch Size 316
Epoch: [150][0/159]	Time 0.176 (0.176)	Data 0.318 (0.318)	Loss 0.9839 (0.9839)	Acc@1 78.797 (78.797)	Acc@5 97.152 (97.152)
Epoch: [150][64/159]	Time 0.128 (0.125)	Data 0.000 (0.005)	Loss 0.6947 (0.7800)	Acc@1 87.342 (84.396)	Acc@5 99.051 (99.172)
Epoch: [150][128/159]	Time 0.120 (0.125)	Data 0.000 (0.003)	Loss 0.6471 (0.7343)	Acc@1 88.608 (85.840)	Acc@5 98.734 (99.323)
Max memory in training epoch: 66.9306368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 324846 ; 344766 ; 0.9422216807921895
[INFO] Storing checkpoint...
  87.06
Max memory: 83.1597056
 20.280s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1905
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.13696
lr: 0.05413076540237719
1

Epoch: [151 | 155] LR: 0.054131
batch Size 316
Epoch: [151][0/159]	Time 0.200 (0.200)	Data 0.280 (0.280)	Loss 0.6232 (0.6232)	Acc@1 90.190 (90.190)	Acc@5 100.000 (100.000)
Epoch: [151][64/159]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.6811 (0.6435)	Acc@1 86.076 (88.651)	Acc@5 99.367 (99.576)
Epoch: [151][128/159]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.6147 (0.6336)	Acc@1 88.924 (88.804)	Acc@5 99.367 (99.620)
Max memory in training epoch: 65.1523584
lr: 0.05413076540237719
1

Epoch: [152 | 155] LR: 0.054131
batch Size 316
Epoch: [152][0/159]	Time 0.185 (0.185)	Data 0.309 (0.309)	Loss 0.5892 (0.5892)	Acc@1 89.873 (89.873)	Acc@5 100.000 (100.000)
Epoch: [152][64/159]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.5325 (0.5854)	Acc@1 90.823 (89.688)	Acc@5 100.000 (99.669)
Epoch: [152][128/159]	Time 0.126 (0.124)	Data 0.000 (0.003)	Loss 0.5400 (0.5849)	Acc@1 90.823 (89.508)	Acc@5 100.000 (99.642)
Max memory in training epoch: 65.2187136
lr: 0.05413076540237719
1

Epoch: [153 | 155] LR: 0.054131
batch Size 316
Epoch: [153][0/159]	Time 0.181 (0.181)	Data 0.282 (0.282)	Loss 0.5178 (0.5178)	Acc@1 93.038 (93.038)	Acc@5 99.684 (99.684)
Epoch: [153][64/159]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.5408 (0.5501)	Acc@1 91.139 (90.394)	Acc@5 100.000 (99.776)
Epoch: [153][128/159]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.5047 (0.5532)	Acc@1 92.405 (90.185)	Acc@5 100.000 (99.752)
Max memory in training epoch: 65.2187136
Drin!!
old memory: 669306368
new memory: 652187136
Faktor: 0.9744224277274469
New batch Size größer 324!!
lr: 0.05413076540237719
1

Epoch: [154 | 155] LR: 0.054131
batch Size 324
Epoch: [154][0/159]	Time 0.180 (0.180)	Data 0.297 (0.297)	Loss 0.4683 (0.4683)	Acc@1 92.089 (92.089)	Acc@5 100.000 (100.000)
Epoch: [154][64/159]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.5598 (0.5304)	Acc@1 90.506 (90.579)	Acc@5 99.051 (99.761)
Epoch: [154][128/159]	Time 0.127 (0.122)	Data 0.000 (0.003)	Loss 0.5103 (0.5309)	Acc@1 89.557 (90.457)	Acc@5 99.367 (99.715)
Max memory in training epoch: 65.2187136
lr: 0.05413076540237719
1

Epoch: [155 | 155] LR: 0.054131
batch Size 324
Epoch: [155][0/159]	Time 0.145 (0.145)	Data 0.320 (0.320)	Loss 0.4852 (0.4852)	Acc@1 92.405 (92.405)	Acc@5 100.000 (100.000)
Epoch: [155][64/159]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.5202 (0.5182)	Acc@1 88.924 (90.526)	Acc@5 99.684 (99.761)
Epoch: [155][128/159]	Time 0.127 (0.125)	Data 0.000 (0.003)	Loss 0.4626 (0.5125)	Acc@1 92.405 (90.757)	Acc@5 99.684 (99.762)
Max memory in training epoch: 65.2187136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 320806 ; 324846 ; 0.9875633377046354
[INFO] Storing checkpoint...
  86.0
Max memory: 81.103616
 20.206s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7014
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.135424
lr: 0.06850924996238364
1

Epoch: [156 | 160] LR: 0.068509
batch Size 324
Epoch: [156][0/155]	Time 0.204 (0.204)	Data 0.310 (0.310)	Loss 0.4514 (0.4514)	Acc@1 91.975 (91.975)	Acc@5 100.000 (100.000)
Epoch: [156][64/155]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.5015 (0.4990)	Acc@1 89.198 (90.845)	Acc@5 100.000 (99.729)
Epoch: [156][128/155]	Time 0.128 (0.123)	Data 0.000 (0.003)	Loss 0.5394 (0.5120)	Acc@1 89.198 (90.274)	Acc@5 99.691 (99.722)
Max memory in training epoch: 66.1672448
lr: 0.06850924996238364
1

Epoch: [157 | 160] LR: 0.068509
batch Size 324
Epoch: [157][0/155]	Time 0.147 (0.147)	Data 0.317 (0.317)	Loss 0.5555 (0.5555)	Acc@1 88.580 (88.580)	Acc@5 100.000 (100.000)
Epoch: [157][64/155]	Time 0.129 (0.126)	Data 0.000 (0.005)	Loss 0.4700 (0.5109)	Acc@1 91.358 (90.033)	Acc@5 99.691 (99.720)
Epoch: [157][128/155]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.5756 (0.5243)	Acc@1 88.272 (89.532)	Acc@5 98.765 (99.703)
Max memory in training epoch: 66.1727744
lr: 0.06850924996238364
1

Epoch: [158 | 160] LR: 0.068509
batch Size 324
Epoch: [158][0/155]	Time 0.170 (0.170)	Data 0.315 (0.315)	Loss 0.4720 (0.4720)	Acc@1 93.210 (93.210)	Acc@5 99.383 (99.383)
Epoch: [158][64/155]	Time 0.126 (0.125)	Data 0.000 (0.005)	Loss 0.5651 (0.5077)	Acc@1 88.272 (90.028)	Acc@5 99.383 (99.701)
Epoch: [158][128/155]	Time 0.122 (0.125)	Data 0.000 (0.003)	Loss 0.5314 (0.5159)	Acc@1 89.506 (89.671)	Acc@5 99.691 (99.658)
Max memory in training epoch: 66.2058496
Drin!!
old memory: 652187136
new memory: 662058496
Faktor: 1.015135778452398
New batch Size kleiner 328!!
lr: 0.06850924996238364
1

Epoch: [159 | 160] LR: 0.068509
batch Size 328
Epoch: [159][0/155]	Time 0.168 (0.168)	Data 0.341 (0.341)	Loss 0.5069 (0.5069)	Acc@1 91.049 (91.049)	Acc@5 100.000 (100.000)
Epoch: [159][64/155]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.5508 (0.5130)	Acc@1 86.420 (89.858)	Acc@5 100.000 (99.710)
Epoch: [159][128/155]	Time 0.126 (0.123)	Data 0.000 (0.003)	Loss 0.5284 (0.5252)	Acc@1 88.889 (89.425)	Acc@5 100.000 (99.694)
Max memory in training epoch: 66.2058496
lr: 0.06850924996238364
1

Epoch: [160 | 160] LR: 0.068509
batch Size 328
Epoch: [160][0/155]	Time 0.174 (0.174)	Data 0.320 (0.320)	Loss 0.5415 (0.5415)	Acc@1 88.580 (88.580)	Acc@5 100.000 (100.000)
Epoch: [160][64/155]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.5033 (0.5120)	Acc@1 88.889 (89.530)	Acc@5 99.691 (99.677)
Epoch: [160][128/155]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.4465 (0.5157)	Acc@1 91.975 (89.530)	Acc@5 100.000 (99.689)
Max memory in training epoch: 66.2058496
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 315612 ; 320806 ; 0.9838095297469499
[INFO] Storing checkpoint...
  83.31
Max memory: 81.2370432
 20.064s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4329
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.133376
lr: 0.08777747651430404
1

Epoch: [161 | 165] LR: 0.087777
batch Size 328
Epoch: [161][0/153]	Time 0.190 (0.190)	Data 0.282 (0.282)	Loss 0.4516 (0.4516)	Acc@1 90.854 (90.854)	Acc@5 99.695 (99.695)
Epoch: [161][64/153]	Time 0.124 (0.121)	Data 0.000 (0.005)	Loss 0.6041 (0.5344)	Acc@1 87.805 (88.846)	Acc@5 98.476 (99.615)
Epoch: [161][128/153]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.5780 (0.5623)	Acc@1 86.890 (87.942)	Acc@5 100.000 (99.567)
Max memory in training epoch: 66.8656128
lr: 0.08777747651430404
1

Epoch: [162 | 165] LR: 0.087777
batch Size 328
Epoch: [162][0/153]	Time 0.173 (0.173)	Data 0.330 (0.330)	Loss 0.5838 (0.5838)	Acc@1 87.805 (87.805)	Acc@5 100.000 (100.000)
Epoch: [162][64/153]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.5923 (0.5685)	Acc@1 86.890 (87.936)	Acc@5 99.695 (99.634)
Epoch: [162][128/153]	Time 0.129 (0.127)	Data 0.000 (0.003)	Loss 0.5845 (0.5656)	Acc@1 87.195 (88.103)	Acc@5 98.171 (99.584)
Max memory in training epoch: 66.7718144
lr: 0.08777747651430404
1

Epoch: [163 | 165] LR: 0.087777
batch Size 328
Epoch: [163][0/153]	Time 0.177 (0.177)	Data 0.314 (0.314)	Loss 0.5445 (0.5445)	Acc@1 89.329 (89.329)	Acc@5 99.695 (99.695)
Epoch: [163][64/153]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.5684 (0.5591)	Acc@1 87.500 (88.462)	Acc@5 99.695 (99.690)
Epoch: [163][128/153]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.5766 (0.5622)	Acc@1 89.024 (88.214)	Acc@5 99.390 (99.660)
Max memory in training epoch: 66.7718144
Drin!!
old memory: 662058496
new memory: 667718144
Faktor: 1.0085485618479246
New batch Size kleiner 330!!
lr: 0.08777747651430404
1

Epoch: [164 | 165] LR: 0.087777
batch Size 330
Epoch: [164][0/153]	Time 0.161 (0.161)	Data 0.319 (0.319)	Loss 0.5294 (0.5294)	Acc@1 91.159 (91.159)	Acc@5 99.695 (99.695)
Epoch: [164][64/153]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.5435 (0.5582)	Acc@1 89.634 (88.809)	Acc@5 99.390 (99.620)
Epoch: [164][128/153]	Time 0.129 (0.126)	Data 0.000 (0.003)	Loss 0.6260 (0.5661)	Acc@1 84.451 (88.311)	Acc@5 99.390 (99.593)
Max memory in training epoch: 66.7718144
lr: 0.08777747651430404
1

Epoch: [165 | 165] LR: 0.087777
batch Size 330
Epoch: [165][0/153]	Time 0.164 (0.164)	Data 0.282 (0.282)	Loss 0.5416 (0.5416)	Acc@1 90.244 (90.244)	Acc@5 100.000 (100.000)
Epoch: [165][64/153]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.5844 (0.5651)	Acc@1 89.329 (88.410)	Acc@5 99.085 (99.639)
Epoch: [165][128/153]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.5218 (0.5610)	Acc@1 89.024 (88.386)	Acc@5 100.000 (99.615)
Max memory in training epoch: 66.7718144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 312292 ; 315612 ; 0.9894807548508928
[INFO] Storing checkpoint...
  82.11
Max memory: 81.18912
 19.170s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7826
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1320448
lr: 0.11315065331922004
1

Epoch: [166 | 170] LR: 0.113151
batch Size 330
Epoch: [166][0/152]	Time 0.184 (0.184)	Data 0.287 (0.287)	Loss 0.6079 (0.6079)	Acc@1 87.273 (87.273)	Acc@5 99.091 (99.091)
Epoch: [166][64/152]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.5641 (0.5666)	Acc@1 89.091 (88.322)	Acc@5 99.697 (99.627)
Epoch: [166][128/152]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6107 (0.5941)	Acc@1 86.667 (87.393)	Acc@5 99.091 (99.565)
Max memory in training epoch: 67.1856128
lr: 0.11315065331922004
1

Epoch: [167 | 170] LR: 0.113151
batch Size 330
Epoch: [167][0/152]	Time 0.196 (0.196)	Data 0.328 (0.328)	Loss 0.6744 (0.6744)	Acc@1 81.818 (81.818)	Acc@5 99.697 (99.697)
Epoch: [167][64/152]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.6406 (0.6232)	Acc@1 85.455 (86.620)	Acc@5 99.697 (99.524)
Epoch: [167][128/152]	Time 0.125 (0.125)	Data 0.000 (0.003)	Loss 0.6726 (0.6222)	Acc@1 87.273 (86.725)	Acc@5 99.091 (99.518)
Max memory in training epoch: 67.1817216
lr: 0.11315065331922004
1

Epoch: [168 | 170] LR: 0.113151
batch Size 330
Epoch: [168][0/152]	Time 0.179 (0.179)	Data 0.341 (0.341)	Loss 0.5619 (0.5619)	Acc@1 87.273 (87.273)	Acc@5 100.000 (100.000)
Epoch: [168][64/152]	Time 0.126 (0.125)	Data 0.000 (0.005)	Loss 0.6575 (0.5996)	Acc@1 86.970 (87.455)	Acc@5 99.091 (99.618)
Epoch: [168][128/152]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.6400 (0.6044)	Acc@1 86.667 (87.273)	Acc@5 100.000 (99.577)
Max memory in training epoch: 67.099648
Drin!!
old memory: 667718144
new memory: 670996480
Faktor: 1.0049097602475814
New batch Size kleiner 331!!
lr: 0.11315065331922004
1

Epoch: [169 | 170] LR: 0.113151
batch Size 331
Epoch: [169][0/152]	Time 0.148 (0.148)	Data 0.292 (0.292)	Loss 0.6915 (0.6915)	Acc@1 82.424 (82.424)	Acc@5 99.697 (99.697)
Epoch: [169][64/152]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.5959 (0.5975)	Acc@1 88.485 (87.534)	Acc@5 99.697 (99.585)
Epoch: [169][128/152]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.5584 (0.6028)	Acc@1 88.182 (87.397)	Acc@5 100.000 (99.537)
Max memory in training epoch: 67.0723584
lr: 0.11315065331922004
1

Epoch: [170 | 170] LR: 0.113151
batch Size 331
Epoch: [170][0/152]	Time 0.158 (0.158)	Data 0.289 (0.289)	Loss 0.7328 (0.7328)	Acc@1 81.818 (81.818)	Acc@5 99.394 (99.394)
Epoch: [170][64/152]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.5850 (0.5963)	Acc@1 87.576 (87.753)	Acc@5 99.697 (99.618)
Epoch: [170][128/152]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6042 (0.6048)	Acc@1 87.879 (87.435)	Acc@5 100.000 (99.584)
Max memory in training epoch: 67.0723584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 311424 ; 312292 ; 0.9972205499980787
[INFO] Storing checkpoint...
  83.49
Max memory: 81.0737152
 19.354s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4901
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1316352
lr: 0.1463002587838353
1

Epoch: [171 | 175] LR: 0.146300
batch Size 331
Epoch: [171][0/152]	Time 0.213 (0.213)	Data 0.286 (0.286)	Loss 0.5552 (0.5552)	Acc@1 87.915 (87.915)	Acc@5 99.698 (99.698)
Epoch: [171][64/152]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.6490 (0.6343)	Acc@1 87.915 (86.656)	Acc@5 100.000 (99.447)
Epoch: [171][128/152]	Time 0.129 (0.125)	Data 0.000 (0.002)	Loss 0.6648 (0.6543)	Acc@1 83.384 (85.927)	Acc@5 99.396 (99.438)
Max memory in training epoch: 67.03232
lr: 0.1463002587838353
1

Epoch: [172 | 175] LR: 0.146300
batch Size 331
Epoch: [172][0/152]	Time 0.193 (0.193)	Data 0.366 (0.366)	Loss 0.6866 (0.6866)	Acc@1 83.988 (83.988)	Acc@5 99.698 (99.698)
Epoch: [172][64/152]	Time 0.128 (0.122)	Data 0.000 (0.006)	Loss 0.6504 (0.7160)	Acc@1 87.915 (84.271)	Acc@5 99.396 (99.349)
Epoch: [172][128/152]	Time 0.127 (0.122)	Data 0.000 (0.003)	Loss 0.6776 (0.6934)	Acc@1 84.290 (85.056)	Acc@5 99.698 (99.377)
Max memory in training epoch: 67.106304
lr: 0.1463002587838353
1

Epoch: [173 | 175] LR: 0.146300
batch Size 331
Epoch: [173][0/152]	Time 0.183 (0.183)	Data 0.295 (0.295)	Loss 0.6555 (0.6555)	Acc@1 85.196 (85.196)	Acc@5 99.396 (99.396)
Epoch: [173][64/152]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.6810 (0.7179)	Acc@1 86.103 (84.667)	Acc@5 99.698 (99.298)
Epoch: [173][128/152]	Time 0.121 (0.126)	Data 0.000 (0.003)	Loss 0.6543 (0.6874)	Acc@1 85.196 (85.527)	Acc@5 99.094 (99.375)
Max memory in training epoch: 67.0088192
Drin!!
old memory: 670723584
new memory: 670088192
Faktor: 0.9990526768177574
New batch Size größer 330!!
lr: 0.1463002587838353
1

Epoch: [174 | 175] LR: 0.146300
batch Size 330
Epoch: [174][0/152]	Time 0.155 (0.155)	Data 0.307 (0.307)	Loss 0.6501 (0.6501)	Acc@1 85.498 (85.498)	Acc@5 99.094 (99.094)
Epoch: [174][64/152]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.6663 (0.6894)	Acc@1 87.311 (85.559)	Acc@5 99.698 (99.400)
Epoch: [174][128/152]	Time 0.122 (0.126)	Data 0.000 (0.003)	Loss 0.6874 (0.6761)	Acc@1 84.894 (86.030)	Acc@5 98.792 (99.407)
Max memory in training epoch: 67.0088192
lr: 0.1463002587838353
1

Epoch: [175 | 175] LR: 0.146300
batch Size 330
Epoch: [175][0/152]	Time 0.176 (0.176)	Data 0.361 (0.361)	Loss 0.7631 (0.7631)	Acc@1 82.175 (82.175)	Acc@5 99.094 (99.094)
Epoch: [175][64/152]	Time 0.129 (0.127)	Data 0.000 (0.006)	Loss 0.6490 (0.7120)	Acc@1 87.311 (84.759)	Acc@5 99.396 (99.256)
Epoch: [175][128/152]	Time 0.126 (0.127)	Data 0.000 (0.003)	Loss 0.6783 (0.6948)	Acc@1 86.103 (85.358)	Acc@5 99.094 (99.295)
Max memory in training epoch: 67.0088192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 310844 ; 311424 ; 0.9981375873407317
[INFO] Storing checkpoint...
  78.11
Max memory: 80.7710208
 19.608s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1546
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1314304
lr: 0.18859017733853767
1

Epoch: [176 | 180] LR: 0.188590
batch Size 330
Epoch: [176][0/152]	Time 0.202 (0.202)	Data 0.275 (0.275)	Loss 0.7283 (0.7283)	Acc@1 85.152 (85.152)	Acc@5 99.091 (99.091)
Epoch: [176][64/152]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.6661 (0.6917)	Acc@1 86.061 (85.375)	Acc@5 100.000 (99.399)
Epoch: [176][128/152]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.7708 (0.7028)	Acc@1 85.152 (85.055)	Acc@5 100.000 (99.359)
Max memory in training epoch: 66.0936192
lr: 0.18859017733853767
1

Epoch: [177 | 180] LR: 0.188590
batch Size 330
Epoch: [177][0/152]	Time 0.182 (0.182)	Data 0.338 (0.338)	Loss 0.6892 (0.6892)	Acc@1 85.455 (85.455)	Acc@5 99.697 (99.697)
Epoch: [177][64/152]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.7095 (0.7109)	Acc@1 86.970 (85.002)	Acc@5 99.394 (99.347)
Epoch: [177][128/152]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.7478 (0.7140)	Acc@1 82.424 (84.872)	Acc@5 100.000 (99.377)
Max memory in training epoch: 66.1782016
lr: 0.18859017733853767
1

Epoch: [178 | 180] LR: 0.188590
batch Size 330
Epoch: [178][0/152]	Time 0.161 (0.161)	Data 0.336 (0.336)	Loss 0.6637 (0.6637)	Acc@1 85.758 (85.758)	Acc@5 99.394 (99.394)
Epoch: [178][64/152]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.7369 (0.7046)	Acc@1 83.939 (85.179)	Acc@5 99.697 (99.371)
Epoch: [178][128/152]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.6578 (0.7084)	Acc@1 87.273 (85.029)	Acc@5 100.000 (99.331)
Max memory in training epoch: 66.1782016
Drin!!
old memory: 670088192
new memory: 661782016
Faktor: 0.9876043540250893
New batch Size größer 334!!
lr: 0.18859017733853767
1

Epoch: [179 | 180] LR: 0.188590
batch Size 334
Epoch: [179][0/152]	Time 0.180 (0.180)	Data 0.313 (0.313)	Loss 0.6952 (0.6952)	Acc@1 85.758 (85.758)	Acc@5 99.697 (99.697)
Epoch: [179][64/152]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7617 (0.6976)	Acc@1 83.636 (85.268)	Acc@5 99.697 (99.413)
Epoch: [179][128/152]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.7445 (0.7033)	Acc@1 84.242 (85.048)	Acc@5 99.697 (99.370)
Max memory in training epoch: 66.1782016
lr: 0.18859017733853767
1

Epoch: [180 | 180] LR: 0.188590
batch Size 334
Epoch: [180][0/152]	Time 0.165 (0.165)	Data 0.321 (0.321)	Loss 0.7255 (0.7255)	Acc@1 85.455 (85.455)	Acc@5 99.091 (99.091)
Epoch: [180][64/152]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.6506 (0.7070)	Acc@1 87.576 (85.044)	Acc@5 99.394 (99.403)
Epoch: [180][128/152]	Time 0.130 (0.127)	Data 0.000 (0.003)	Loss 0.6689 (0.7085)	Acc@1 86.667 (84.987)	Acc@5 99.697 (99.368)
Max memory in training epoch: 66.1782016
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(42, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(42, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(57, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  77.64
Max memory: 80.6209024
 19.647s  