Thres 0.1 1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7858
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.177 (0.177)	Data 0.284 (0.284)	Loss 3.3895 (3.3895)	Acc@1 10.938 (10.938)	Acc@5 49.609 (49.609)
Epoch: [1][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 2.2988 (2.6666)	Acc@1 37.109 (25.835)	Acc@5 88.281 (79.339)
Epoch: [1][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 2.0728 (2.4708)	Acc@1 44.141 (32.210)	Acc@5 92.578 (84.275)
Epoch: [1][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 2.0703 (2.3542)	Acc@1 44.922 (36.263)	Acc@5 92.188 (86.798)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.153 (0.153)	Data 0.302 (0.302)	Loss 1.9996 (1.9996)	Acc@1 47.656 (47.656)	Acc@5 92.969 (92.969)
Epoch: [2][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 1.8637 (1.9262)	Acc@1 54.688 (51.460)	Acc@5 96.484 (93.666)
Epoch: [2][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 1.6923 (1.8553)	Acc@1 56.250 (53.304)	Acc@5 96.875 (94.422)
Epoch: [2][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 1.6577 (1.7898)	Acc@1 60.938 (55.683)	Acc@5 96.875 (94.944)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.165 (0.165)	Data 0.287 (0.287)	Loss 1.6653 (1.6653)	Acc@1 62.109 (62.109)	Acc@5 95.703 (95.703)
Epoch: [3][64/196]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 1.4073 (1.5493)	Acc@1 67.188 (63.185)	Acc@5 98.828 (96.532)
Epoch: [3][128/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 1.3618 (1.5096)	Acc@1 68.359 (64.153)	Acc@5 98.047 (96.751)
Epoch: [3][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 1.3359 (1.4682)	Acc@1 69.141 (65.524)	Acc@5 96.875 (96.938)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.157 (0.157)	Data 0.291 (0.291)	Loss 1.4419 (1.4419)	Acc@1 66.406 (66.406)	Acc@5 95.703 (95.703)
Epoch: [4][64/196]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 1.2592 (1.3039)	Acc@1 73.047 (70.727)	Acc@5 98.438 (97.819)
Epoch: [4][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 1.2030 (1.2836)	Acc@1 74.219 (71.142)	Acc@5 98.047 (97.895)
Epoch: [4][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 1.3391 (1.2677)	Acc@1 62.891 (71.294)	Acc@5 98.047 (97.958)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.159 (0.159)	Data 0.306 (0.306)	Loss 1.2021 (1.2021)	Acc@1 73.047 (73.047)	Acc@5 98.438 (98.438)
Epoch: [5][64/196]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 1.1941 (1.1672)	Acc@1 73.828 (73.834)	Acc@5 98.438 (98.257)
Epoch: [5][128/196]	Time 0.127 (0.127)	Data 0.000 (0.003)	Loss 1.1529 (1.1528)	Acc@1 70.312 (74.322)	Acc@5 98.438 (98.398)
Epoch: [5][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 1.0725 (1.1299)	Acc@1 75.781 (74.856)	Acc@5 98.047 (98.397)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 352074 ; 487386 ; 0.7223720008371188
[INFO] Storing checkpoint...
  57.44
Max memory: 103.3835008
 25.338s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4517
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1486336
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.192 (0.192)	Data 0.279 (0.279)	Loss 1.1060 (1.1060)	Acc@1 70.703 (70.703)	Acc@5 99.609 (99.609)
Epoch: [6][64/196]	Time 0.133 (0.131)	Data 0.000 (0.004)	Loss 0.9027 (1.0203)	Acc@1 79.297 (76.262)	Acc@5 99.609 (98.576)
Epoch: [6][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.9445 (1.0087)	Acc@1 78.906 (76.517)	Acc@5 99.609 (98.589)
Epoch: [6][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.9462 (0.9940)	Acc@1 78.516 (77.036)	Acc@5 98.828 (98.612)
Max memory in training epoch: 65.0811904
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.174 (0.174)	Data 0.294 (0.294)	Loss 0.9012 (0.9012)	Acc@1 77.734 (77.734)	Acc@5 99.219 (99.219)
Epoch: [7][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.9807 (0.9614)	Acc@1 76.172 (78.095)	Acc@5 98.438 (98.720)
Epoch: [7][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.8799 (0.9480)	Acc@1 82.031 (78.488)	Acc@5 98.438 (98.752)
Epoch: [7][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.9459 (0.9423)	Acc@1 75.000 (78.526)	Acc@5 98.828 (98.769)
Max memory in training epoch: 65.0156544
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.181 (0.181)	Data 0.287 (0.287)	Loss 0.9879 (0.9879)	Acc@1 78.125 (78.125)	Acc@5 97.656 (97.656)
Epoch: [8][64/196]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.9712 (0.9012)	Acc@1 78.516 (79.459)	Acc@5 98.438 (98.792)
Epoch: [8][128/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.8891 (0.8933)	Acc@1 80.469 (79.754)	Acc@5 99.609 (98.943)
Epoch: [8][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8787 (0.8912)	Acc@1 79.688 (79.805)	Acc@5 99.609 (98.950)
Max memory in training epoch: 64.9107968
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.174 (0.174)	Data 0.289 (0.289)	Loss 0.9441 (0.9441)	Acc@1 76.172 (76.172)	Acc@5 97.656 (97.656)
Epoch: [9][64/196]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.8508 (0.8451)	Acc@1 80.859 (80.931)	Acc@5 99.609 (99.069)
Epoch: [9][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7746 (0.8528)	Acc@1 84.766 (80.687)	Acc@5 98.438 (98.952)
Epoch: [9][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.8181 (0.8547)	Acc@1 78.516 (80.606)	Acc@5 98.047 (98.990)
Max memory in training epoch: 64.9107968
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.161 (0.161)	Data 0.286 (0.286)	Loss 0.7302 (0.7302)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.9129 (0.8304)	Acc@1 80.078 (81.454)	Acc@5 98.828 (99.050)
Epoch: [10][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7869 (0.8233)	Acc@1 82.812 (81.483)	Acc@5 99.609 (99.067)
Epoch: [10][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.8213 (0.8246)	Acc@1 78.906 (81.471)	Acc@5 99.609 (99.069)
Max memory in training epoch: 64.9107968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 252342 ; 352074 ; 0.7167300056238177
[INFO] Storing checkpoint...
  75.1
Max memory: 101.132032
 26.191s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8529
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.1089536
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.187 (0.187)	Data 0.265 (0.265)	Loss 1.0773 (1.0773)	Acc@1 73.047 (73.047)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.7584 (0.8118)	Acc@1 83.984 (80.691)	Acc@5 99.609 (99.117)
Epoch: [11][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8650 (0.8110)	Acc@1 76.953 (80.884)	Acc@5 99.609 (99.007)
Epoch: [11][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.8389 (0.8119)	Acc@1 80.859 (80.803)	Acc@5 98.828 (98.970)
Max memory in training epoch: 60.7042048
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.169 (0.169)	Data 0.273 (0.273)	Loss 0.7642 (0.7642)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.8192 (0.8001)	Acc@1 79.688 (81.184)	Acc@5 99.219 (99.135)
Epoch: [12][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.7835 (0.7959)	Acc@1 81.641 (81.474)	Acc@5 99.219 (99.104)
Epoch: [12][192/196]	Time 0.119 (0.129)	Data 0.000 (0.002)	Loss 0.8495 (0.7976)	Acc@1 80.078 (81.533)	Acc@5 98.828 (99.061)
Max memory in training epoch: 60.8723456
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.179 (0.179)	Data 0.308 (0.308)	Loss 0.8118 (0.8118)	Acc@1 78.125 (78.125)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.136 (0.132)	Data 0.000 (0.005)	Loss 0.7236 (0.7786)	Acc@1 82.031 (82.302)	Acc@5 99.609 (99.105)
Epoch: [13][128/196]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.8398 (0.7839)	Acc@1 76.953 (81.949)	Acc@5 98.438 (99.125)
Epoch: [13][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7633 (0.7856)	Acc@1 82.031 (81.881)	Acc@5 99.609 (99.097)
Max memory in training epoch: 60.8723456
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.175 (0.175)	Data 0.326 (0.326)	Loss 0.8480 (0.8480)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [14][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.8552 (0.7686)	Acc@1 80.078 (82.782)	Acc@5 98.047 (99.135)
Epoch: [14][128/196]	Time 0.130 (0.130)	Data 0.000 (0.003)	Loss 0.8815 (0.7693)	Acc@1 78.906 (82.628)	Acc@5 100.000 (99.164)
Epoch: [14][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6829 (0.7702)	Acc@1 84.766 (82.620)	Acc@5 99.219 (99.114)
Max memory in training epoch: 60.8723456
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.160 (0.160)	Data 0.279 (0.279)	Loss 0.8427 (0.8427)	Acc@1 80.078 (80.078)	Acc@5 98.828 (98.828)
Epoch: [15][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7132 (0.7637)	Acc@1 83.203 (82.758)	Acc@5 100.000 (99.195)
Epoch: [15][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.8190 (0.7646)	Acc@1 81.250 (82.816)	Acc@5 98.438 (99.167)
Epoch: [15][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7999 (0.7653)	Acc@1 80.078 (82.768)	Acc@5 98.438 (99.186)
Max memory in training epoch: 60.8723456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 243526 ; 252342 ; 0.9650632871262017
[INFO] Storing checkpoint...
  73.4
Max memory: 95.0656
 25.693s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8017
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1055232
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.187 (0.187)	Data 0.258 (0.258)	Loss 0.7297 (0.7297)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.126 (0.132)	Data 0.000 (0.004)	Loss 0.7471 (0.7298)	Acc@1 85.156 (83.756)	Acc@5 99.609 (99.249)
Epoch: [16][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7317 (0.7373)	Acc@1 83.594 (83.527)	Acc@5 99.219 (99.240)
Epoch: [16][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.7901 (0.7468)	Acc@1 83.984 (83.276)	Acc@5 98.828 (99.261)
Max memory in training epoch: 59.5439104
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.175 (0.175)	Data 0.270 (0.270)	Loss 0.7598 (0.7598)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [17][64/196]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 0.7408 (0.7494)	Acc@1 82.422 (83.215)	Acc@5 98.828 (99.195)
Epoch: [17][128/196]	Time 0.136 (0.132)	Data 0.000 (0.002)	Loss 0.8464 (0.7520)	Acc@1 80.859 (83.155)	Acc@5 98.438 (99.170)
Epoch: [17][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7301 (0.7530)	Acc@1 84.375 (83.122)	Acc@5 100.000 (99.180)
Max memory in training epoch: 59.482368
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.186 (0.186)	Data 0.287 (0.287)	Loss 0.7257 (0.7257)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.6889 (0.7369)	Acc@1 87.109 (83.558)	Acc@5 99.219 (99.243)
Epoch: [18][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7488 (0.7425)	Acc@1 82.422 (83.406)	Acc@5 98.047 (99.243)
Epoch: [18][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6694 (0.7458)	Acc@1 86.328 (83.329)	Acc@5 99.219 (99.233)
Max memory in training epoch: 59.482368
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.160 (0.160)	Data 0.303 (0.303)	Loss 0.7167 (0.7167)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.131 (0.133)	Data 0.000 (0.005)	Loss 0.6903 (0.7393)	Acc@1 85.156 (83.317)	Acc@5 99.609 (99.279)
Epoch: [19][128/196]	Time 0.134 (0.133)	Data 0.000 (0.003)	Loss 0.8125 (0.7448)	Acc@1 81.641 (83.279)	Acc@5 98.828 (99.270)
Epoch: [19][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7351 (0.7440)	Acc@1 84.766 (83.357)	Acc@5 99.219 (99.261)
Max memory in training epoch: 59.482368
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.161 (0.161)	Data 0.286 (0.286)	Loss 0.7033 (0.7033)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.134 (0.134)	Data 0.000 (0.005)	Loss 0.7118 (0.7154)	Acc@1 84.375 (84.669)	Acc@5 99.219 (99.375)
Epoch: [20][128/196]	Time 0.138 (0.133)	Data 0.000 (0.002)	Loss 0.6576 (0.7264)	Acc@1 84.766 (84.105)	Acc@5 100.000 (99.285)
Epoch: [20][192/196]	Time 0.126 (0.133)	Data 0.000 (0.002)	Loss 0.7391 (0.7261)	Acc@1 82.812 (84.021)	Acc@5 99.609 (99.298)
Max memory in training epoch: 59.482368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 234566 ; 243526 ; 0.9632072140141094
[INFO] Storing checkpoint...
  79.04
Max memory: 92.5149696
 26.374s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9470
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1020416
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.199 (0.199)	Data 0.268 (0.268)	Loss 0.7221 (0.7221)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.7333 (0.7038)	Acc@1 85.156 (84.597)	Acc@5 99.219 (99.255)
Epoch: [21][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7899 (0.7152)	Acc@1 82.031 (84.305)	Acc@5 98.828 (99.279)
Epoch: [21][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7302 (0.7217)	Acc@1 83.594 (84.167)	Acc@5 99.609 (99.255)
Max memory in training epoch: 58.3019008
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.157 (0.157)	Data 0.290 (0.290)	Loss 0.7275 (0.7275)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6372 (0.7298)	Acc@1 87.109 (83.900)	Acc@5 99.609 (99.243)
Epoch: [22][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7102 (0.7260)	Acc@1 86.328 (84.127)	Acc@5 99.609 (99.267)
Epoch: [22][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7307 (0.7264)	Acc@1 83.594 (84.144)	Acc@5 99.609 (99.277)
Max memory in training epoch: 58.1970432
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.179 (0.179)	Data 0.299 (0.299)	Loss 0.6733 (0.6733)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.130 (0.128)	Data 0.000 (0.005)	Loss 0.6794 (0.7095)	Acc@1 82.422 (84.736)	Acc@5 99.219 (99.321)
Epoch: [23][128/196]	Time 0.131 (0.129)	Data 0.000 (0.003)	Loss 0.7012 (0.7122)	Acc@1 82.812 (84.457)	Acc@5 99.219 (99.297)
Epoch: [23][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6698 (0.7144)	Acc@1 87.500 (84.337)	Acc@5 99.609 (99.290)
Max memory in training epoch: 58.1970432
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.180 (0.180)	Data 0.306 (0.306)	Loss 0.7643 (0.7643)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [24][64/196]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.6815 (0.7210)	Acc@1 84.766 (84.111)	Acc@5 100.000 (99.315)
Epoch: [24][128/196]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.7039 (0.7192)	Acc@1 85.938 (84.036)	Acc@5 99.219 (99.328)
Epoch: [24][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.8179 (0.7189)	Acc@1 82.422 (84.073)	Acc@5 99.219 (99.298)
Max memory in training epoch: 58.1970432
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.173 (0.173)	Data 0.283 (0.283)	Loss 0.6670 (0.6670)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.7529 (0.6889)	Acc@1 81.641 (85.367)	Acc@5 100.000 (99.387)
Epoch: [25][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6622 (0.7006)	Acc@1 87.109 (84.917)	Acc@5 98.828 (99.379)
Epoch: [25][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7920 (0.7123)	Acc@1 83.984 (84.533)	Acc@5 98.828 (99.318)
Max memory in training epoch: 58.1970432
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 228866 ; 234566 ; 0.9756998030405089
[INFO] Storing checkpoint...
  74.62
Max memory: 90.1394944
 25.668s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5285
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.099328
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.174 (0.174)	Data 0.274 (0.274)	Loss 0.7910 (0.7910)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.6550 (0.6875)	Acc@1 87.109 (85.108)	Acc@5 98.828 (99.333)
Epoch: [26][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.7031 (0.7045)	Acc@1 85.547 (84.551)	Acc@5 99.219 (99.373)
Epoch: [26][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6698 (0.7024)	Acc@1 86.328 (84.664)	Acc@5 100.000 (99.366)
Max memory in training epoch: 55.6312064
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.171 (0.171)	Data 0.267 (0.267)	Loss 0.7140 (0.7140)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [27][64/196]	Time 0.121 (0.124)	Data 0.000 (0.004)	Loss 0.7527 (0.7126)	Acc@1 81.641 (84.177)	Acc@5 99.609 (99.345)
Epoch: [27][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.6615 (0.7058)	Acc@1 86.719 (84.411)	Acc@5 99.609 (99.349)
Epoch: [27][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.7506 (0.7055)	Acc@1 82.812 (84.472)	Acc@5 100.000 (99.346)
Max memory in training epoch: 55.6312064
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.169 (0.169)	Data 0.296 (0.296)	Loss 0.6782 (0.6782)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.6589 (0.6756)	Acc@1 85.547 (85.703)	Acc@5 99.219 (99.315)
Epoch: [28][128/196]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 0.6569 (0.6927)	Acc@1 85.156 (85.087)	Acc@5 100.000 (99.310)
Epoch: [28][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6014 (0.6998)	Acc@1 88.281 (84.808)	Acc@5 99.609 (99.312)
Max memory in training epoch: 55.6312064
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.191 (0.191)	Data 0.309 (0.309)	Loss 0.6161 (0.6161)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.6323 (0.6990)	Acc@1 84.766 (84.471)	Acc@5 98.438 (99.435)
Epoch: [29][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.7418 (0.7003)	Acc@1 84.766 (84.629)	Acc@5 98.828 (99.397)
Epoch: [29][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6856 (0.7039)	Acc@1 84.766 (84.525)	Acc@5 99.219 (99.346)
Max memory in training epoch: 55.6312064
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.140 (0.140)	Data 0.318 (0.318)	Loss 0.6320 (0.6320)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.7532 (0.7038)	Acc@1 82.812 (84.405)	Acc@5 98.828 (99.267)
Epoch: [30][128/196]	Time 0.122 (0.125)	Data 0.000 (0.003)	Loss 0.7415 (0.7014)	Acc@1 84.375 (84.593)	Acc@5 98.828 (99.328)
Epoch: [30][192/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.7866 (0.6986)	Acc@1 80.469 (84.719)	Acc@5 98.828 (99.366)
Max memory in training epoch: 55.6312064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 224244 ; 228866 ; 0.9798047765941643
[INFO] Storing checkpoint...
  72.77
Max memory: 86.2399488
 24.859s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3828
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0973824
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.168 (0.168)	Data 0.271 (0.271)	Loss 0.8133 (0.8133)	Acc@1 78.125 (78.125)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.6584 (0.6693)	Acc@1 88.672 (85.625)	Acc@5 98.438 (99.405)
Epoch: [31][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6178 (0.6852)	Acc@1 87.500 (85.226)	Acc@5 100.000 (99.334)
Epoch: [31][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6734 (0.6862)	Acc@1 86.328 (85.136)	Acc@5 99.609 (99.326)
Max memory in training epoch: 54.8107776
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.171 (0.171)	Data 0.308 (0.308)	Loss 0.6931 (0.6931)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.6867 (0.6885)	Acc@1 87.109 (84.928)	Acc@5 100.000 (99.423)
Epoch: [32][128/196]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.7066 (0.6871)	Acc@1 83.984 (85.138)	Acc@5 99.219 (99.413)
Epoch: [32][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.7884 (0.6935)	Acc@1 82.422 (84.952)	Acc@5 98.438 (99.385)
Max memory in training epoch: 54.8238848
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.181 (0.181)	Data 0.295 (0.295)	Loss 0.6671 (0.6671)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.6367 (0.6857)	Acc@1 88.281 (85.120)	Acc@5 99.609 (99.405)
Epoch: [33][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.7809 (0.6878)	Acc@1 81.250 (85.105)	Acc@5 98.047 (99.291)
Epoch: [33][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.7375 (0.6918)	Acc@1 83.984 (84.930)	Acc@5 99.219 (99.304)
Max memory in training epoch: 54.8238848
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.146 (0.146)	Data 0.301 (0.301)	Loss 0.6769 (0.6769)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.7013 (0.6876)	Acc@1 83.984 (85.156)	Acc@5 99.609 (99.369)
Epoch: [34][128/196]	Time 0.120 (0.123)	Data 0.000 (0.003)	Loss 0.7380 (0.6870)	Acc@1 85.156 (85.123)	Acc@5 99.219 (99.385)
Epoch: [34][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.7111 (0.6866)	Acc@1 85.156 (85.142)	Acc@5 99.219 (99.387)
Max memory in training epoch: 54.8238848
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.137 (0.137)	Data 0.271 (0.271)	Loss 0.6206 (0.6206)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.6652 (0.6929)	Acc@1 85.547 (84.910)	Acc@5 99.609 (99.375)
Epoch: [35][128/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.7354 (0.6928)	Acc@1 86.328 (84.996)	Acc@5 98.438 (99.397)
Epoch: [35][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.7631 (0.6928)	Acc@1 82.812 (84.946)	Acc@5 99.609 (99.387)
Max memory in training epoch: 54.8238848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 221642 ; 224244 ; 0.9883965680241166
[INFO] Storing checkpoint...
  81.06
Max memory: 85.382144
 24.089s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8516
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.0964608
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.173 (0.173)	Data 0.270 (0.270)	Loss 0.6858 (0.6858)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.6474 (0.6609)	Acc@1 87.891 (86.094)	Acc@5 99.219 (99.339)
Epoch: [36][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6574 (0.6706)	Acc@1 88.281 (85.844)	Acc@5 100.000 (99.352)
Epoch: [36][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.6310 (0.6787)	Acc@1 87.891 (85.628)	Acc@5 99.609 (99.320)
Max memory in training epoch: 54.5056256
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.148 (0.148)	Data 0.323 (0.323)	Loss 0.7683 (0.7683)	Acc@1 85.156 (85.156)	Acc@5 98.047 (98.047)
Epoch: [37][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.6509 (0.6886)	Acc@1 87.891 (85.367)	Acc@5 100.000 (99.393)
Epoch: [37][128/196]	Time 0.123 (0.122)	Data 0.000 (0.003)	Loss 0.6796 (0.6861)	Acc@1 84.375 (85.277)	Acc@5 99.609 (99.376)
Epoch: [37][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.7253 (0.6832)	Acc@1 85.938 (85.308)	Acc@5 99.609 (99.397)
Max memory in training epoch: 54.3090176
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.141 (0.141)	Data 0.288 (0.288)	Loss 0.6394 (0.6394)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.6504 (0.6835)	Acc@1 85.547 (84.790)	Acc@5 100.000 (99.471)
Epoch: [38][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6620 (0.6864)	Acc@1 87.109 (84.972)	Acc@5 99.219 (99.410)
Epoch: [38][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6693 (0.6887)	Acc@1 87.500 (85.027)	Acc@5 100.000 (99.348)
Max memory in training epoch: 54.2565888
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.177 (0.177)	Data 0.292 (0.292)	Loss 0.6872 (0.6872)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [39][64/196]	Time 0.127 (0.123)	Data 0.000 (0.005)	Loss 0.6883 (0.6827)	Acc@1 86.719 (85.373)	Acc@5 99.609 (99.465)
Epoch: [39][128/196]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.6022 (0.6810)	Acc@1 88.281 (85.429)	Acc@5 99.219 (99.388)
Epoch: [39][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6982 (0.6821)	Acc@1 83.594 (85.363)	Acc@5 99.609 (99.389)
Max memory in training epoch: 54.2565888
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.171 (0.171)	Data 0.311 (0.311)	Loss 0.5645 (0.5645)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [40][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.7318 (0.6713)	Acc@1 81.641 (85.799)	Acc@5 100.000 (99.297)
Epoch: [40][128/196]	Time 0.125 (0.121)	Data 0.000 (0.003)	Loss 0.7397 (0.6758)	Acc@1 80.859 (85.517)	Acc@5 100.000 (99.343)
Epoch: [40][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6540 (0.6766)	Acc@1 86.719 (85.344)	Acc@5 99.219 (99.362)
Max memory in training epoch: 54.2565888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 220276 ; 221642 ; 0.9938369081672246
[INFO] Storing checkpoint...
  77.67
Max memory: 84.8444416
 24.182s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5882
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.0953344
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.174 (0.174)	Data 0.266 (0.266)	Loss 0.6646 (0.6646)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [41][64/196]	Time 0.116 (0.116)	Data 0.000 (0.004)	Loss 0.7183 (0.6508)	Acc@1 83.594 (85.757)	Acc@5 99.609 (99.561)
Epoch: [41][128/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.6509 (0.6673)	Acc@1 86.719 (85.377)	Acc@5 99.219 (99.488)
Epoch: [41][192/196]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.6700 (0.6687)	Acc@1 85.547 (85.456)	Acc@5 99.609 (99.460)
Max memory in training epoch: 52.7346176
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.149 (0.149)	Data 0.294 (0.294)	Loss 0.7193 (0.7193)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.116 (0.116)	Data 0.000 (0.005)	Loss 0.6227 (0.6814)	Acc@1 88.281 (85.276)	Acc@5 99.219 (99.435)
Epoch: [42][128/196]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.6880 (0.6817)	Acc@1 85.938 (85.238)	Acc@5 99.219 (99.382)
Epoch: [42][192/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.6123 (0.6817)	Acc@1 87.109 (85.197)	Acc@5 100.000 (99.397)
Max memory in training epoch: 52.49664
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.159 (0.159)	Data 0.296 (0.296)	Loss 0.6174 (0.6174)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [43][64/196]	Time 0.114 (0.115)	Data 0.000 (0.005)	Loss 0.6151 (0.6815)	Acc@1 88.672 (85.319)	Acc@5 100.000 (99.435)
Epoch: [43][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.6361 (0.6770)	Acc@1 85.938 (85.323)	Acc@5 100.000 (99.440)
Epoch: [43][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.7840 (0.6758)	Acc@1 82.422 (85.336)	Acc@5 98.438 (99.423)
Max memory in training epoch: 52.49664
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.145 (0.145)	Data 0.278 (0.278)	Loss 0.6653 (0.6653)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.114 (0.114)	Data 0.000 (0.004)	Loss 0.6786 (0.6706)	Acc@1 83.203 (85.571)	Acc@5 98.828 (99.357)
Epoch: [44][128/196]	Time 0.117 (0.113)	Data 0.000 (0.002)	Loss 0.7283 (0.6761)	Acc@1 86.328 (85.386)	Acc@5 98.828 (99.367)
Epoch: [44][192/196]	Time 0.107 (0.113)	Data 0.000 (0.002)	Loss 0.6302 (0.6786)	Acc@1 85.938 (85.405)	Acc@5 99.609 (99.344)
Max memory in training epoch: 52.49664
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.130 (0.130)	Data 0.264 (0.264)	Loss 0.6157 (0.6157)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [45][64/196]	Time 0.111 (0.113)	Data 0.000 (0.004)	Loss 0.6863 (0.6828)	Acc@1 83.594 (85.234)	Acc@5 99.219 (99.381)
Epoch: [45][128/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.7640 (0.6829)	Acc@1 83.984 (85.165)	Acc@5 98.047 (99.379)
Epoch: [45][192/196]	Time 0.114 (0.112)	Data 0.000 (0.002)	Loss 0.6775 (0.6735)	Acc@1 84.375 (85.504)	Acc@5 99.609 (99.425)
Max memory in training epoch: 52.49664
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 217968 ; 220276 ; 0.9895222357406163
[INFO] Storing checkpoint...
  79.67
Max memory: 81.545216
 22.352s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5232
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.0944128
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.165 (0.165)	Data 0.270 (0.270)	Loss 0.6916 (0.6916)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.115 (0.113)	Data 0.000 (0.004)	Loss 0.6739 (0.6345)	Acc@1 85.938 (86.707)	Acc@5 100.000 (99.543)
Epoch: [46][128/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.6290 (0.6486)	Acc@1 87.109 (86.128)	Acc@5 99.219 (99.437)
Epoch: [46][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.6132 (0.6612)	Acc@1 86.328 (85.715)	Acc@5 100.000 (99.385)
Max memory in training epoch: 52.70656
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.138 (0.138)	Data 0.281 (0.281)	Loss 0.5734 (0.5734)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.112 (0.115)	Data 0.000 (0.005)	Loss 0.6645 (0.6452)	Acc@1 87.500 (86.562)	Acc@5 99.609 (99.519)
Epoch: [47][128/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.8035 (0.6576)	Acc@1 78.906 (86.047)	Acc@5 99.609 (99.464)
Epoch: [47][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.6328 (0.6643)	Acc@1 88.672 (85.846)	Acc@5 99.609 (99.437)
Max memory in training epoch: 52.4667392
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.159 (0.159)	Data 0.309 (0.309)	Loss 0.7045 (0.7045)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.111 (0.115)	Data 0.000 (0.005)	Loss 0.6568 (0.6771)	Acc@1 85.547 (85.499)	Acc@5 99.609 (99.363)
Epoch: [48][128/196]	Time 0.114 (0.115)	Data 0.000 (0.003)	Loss 0.6589 (0.6655)	Acc@1 84.766 (85.698)	Acc@5 99.609 (99.413)
Epoch: [48][192/196]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.6715 (0.6659)	Acc@1 85.547 (85.699)	Acc@5 99.219 (99.425)
Max memory in training epoch: 52.4667392
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.152 (0.152)	Data 0.277 (0.277)	Loss 0.6958 (0.6958)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.114 (0.117)	Data 0.000 (0.004)	Loss 0.6215 (0.6717)	Acc@1 87.500 (85.469)	Acc@5 99.219 (99.417)
Epoch: [49][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.7211 (0.6683)	Acc@1 84.375 (85.623)	Acc@5 99.219 (99.419)
Epoch: [49][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.7262 (0.6707)	Acc@1 87.500 (85.514)	Acc@5 99.219 (99.411)
Max memory in training epoch: 52.4667392
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.140 (0.140)	Data 0.275 (0.275)	Loss 0.6680 (0.6680)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.135 (0.117)	Data 0.000 (0.004)	Loss 0.7253 (0.6652)	Acc@1 85.938 (85.901)	Acc@5 99.219 (99.297)
Epoch: [50][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.6155 (0.6605)	Acc@1 89.062 (86.001)	Acc@5 99.609 (99.397)
Epoch: [50][192/196]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.7615 (0.6646)	Acc@1 83.203 (85.875)	Acc@5 99.219 (99.415)
Max memory in training epoch: 52.4667392
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 215946 ; 217968 ; 0.9907234089407619
[INFO] Storing checkpoint...
  73.41
Max memory: 81.5014912
 23.056s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8858
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.0935936
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.189 (0.189)	Data 0.267 (0.267)	Loss 0.7164 (0.7164)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.114 (0.113)	Data 0.000 (0.004)	Loss 0.6937 (0.6423)	Acc@1 85.156 (86.286)	Acc@5 99.219 (99.423)
Epoch: [51][128/196]	Time 0.114 (0.112)	Data 0.000 (0.002)	Loss 0.6039 (0.6513)	Acc@1 86.719 (86.071)	Acc@5 98.828 (99.416)
Epoch: [51][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.6135 (0.6559)	Acc@1 86.719 (85.875)	Acc@5 99.219 (99.381)
Max memory in training epoch: 52.6207488
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.161 (0.161)	Data 0.267 (0.267)	Loss 0.6059 (0.6059)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.112 (0.113)	Data 0.000 (0.004)	Loss 0.6552 (0.6522)	Acc@1 84.375 (86.358)	Acc@5 99.219 (99.447)
Epoch: [52][128/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.6749 (0.6610)	Acc@1 84.375 (85.971)	Acc@5 99.219 (99.467)
Epoch: [52][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.7208 (0.6645)	Acc@1 85.156 (85.782)	Acc@5 99.219 (99.419)
Max memory in training epoch: 52.4503552
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.162 (0.162)	Data 0.294 (0.294)	Loss 0.5719 (0.5719)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.107 (0.115)	Data 0.000 (0.005)	Loss 0.6468 (0.6707)	Acc@1 84.766 (85.595)	Acc@5 99.609 (99.429)
Epoch: [53][128/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.5923 (0.6656)	Acc@1 87.109 (85.674)	Acc@5 99.609 (99.440)
Epoch: [53][192/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.6643 (0.6650)	Acc@1 86.719 (85.650)	Acc@5 99.609 (99.447)
Max memory in training epoch: 52.4503552
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.159 (0.159)	Data 0.265 (0.265)	Loss 0.6716 (0.6716)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [54][64/196]	Time 0.120 (0.115)	Data 0.000 (0.004)	Loss 0.5784 (0.6488)	Acc@1 87.500 (86.328)	Acc@5 98.828 (99.393)
Epoch: [54][128/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.5880 (0.6569)	Acc@1 87.500 (86.098)	Acc@5 100.000 (99.397)
Epoch: [54][192/196]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.6196 (0.6567)	Acc@1 86.328 (86.012)	Acc@5 100.000 (99.407)
Max memory in training epoch: 52.4503552
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.158 (0.158)	Data 0.292 (0.292)	Loss 0.5468 (0.5468)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.118 (0.115)	Data 0.000 (0.005)	Loss 0.6122 (0.6666)	Acc@1 87.109 (85.427)	Acc@5 100.000 (99.351)
Epoch: [55][128/196]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.5471 (0.6597)	Acc@1 90.234 (85.810)	Acc@5 99.609 (99.410)
Epoch: [55][192/196]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.6084 (0.6625)	Acc@1 87.109 (85.668)	Acc@5 99.219 (99.421)
Max memory in training epoch: 52.4503552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 214792 ; 215946 ; 0.9946560714252637
[INFO] Storing checkpoint...
  75.41
Max memory: 80.9460736
 22.807s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7725
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.093184
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.180 (0.180)	Data 0.262 (0.262)	Loss 0.5398 (0.5398)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [56][64/196]	Time 0.112 (0.114)	Data 0.000 (0.004)	Loss 0.5936 (0.6205)	Acc@1 88.281 (87.073)	Acc@5 99.609 (99.453)
Epoch: [56][128/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.6762 (0.6450)	Acc@1 85.547 (86.295)	Acc@5 99.609 (99.440)
Epoch: [56][192/196]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.7474 (0.6505)	Acc@1 82.812 (86.095)	Acc@5 99.219 (99.458)
Max memory in training epoch: 52.6060032
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.134 (0.134)	Data 0.312 (0.312)	Loss 0.6266 (0.6266)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.113 (0.111)	Data 0.000 (0.005)	Loss 0.7053 (0.6579)	Acc@1 83.203 (85.847)	Acc@5 99.219 (99.381)
Epoch: [57][128/196]	Time 0.113 (0.113)	Data 0.000 (0.003)	Loss 0.6779 (0.6629)	Acc@1 86.328 (85.595)	Acc@5 99.609 (99.419)
Epoch: [57][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.6983 (0.6654)	Acc@1 84.375 (85.488)	Acc@5 98.438 (99.405)
Max memory in training epoch: 52.4356096
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.144 (0.144)	Data 0.286 (0.286)	Loss 0.6144 (0.6144)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [58][64/196]	Time 0.112 (0.115)	Data 0.000 (0.005)	Loss 0.6361 (0.6380)	Acc@1 85.938 (86.749)	Acc@5 99.609 (99.471)
Epoch: [58][128/196]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.6886 (0.6533)	Acc@1 82.812 (86.128)	Acc@5 99.609 (99.434)
Epoch: [58][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.6916 (0.6570)	Acc@1 83.984 (85.998)	Acc@5 100.000 (99.429)
Max memory in training epoch: 52.4356096
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.158 (0.158)	Data 0.310 (0.310)	Loss 0.6405 (0.6405)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.114 (0.114)	Data 0.000 (0.005)	Loss 0.7404 (0.6460)	Acc@1 83.984 (86.382)	Acc@5 99.609 (99.423)
Epoch: [59][128/196]	Time 0.116 (0.115)	Data 0.000 (0.003)	Loss 0.6733 (0.6613)	Acc@1 85.547 (85.874)	Acc@5 99.609 (99.437)
Epoch: [59][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.6634 (0.6643)	Acc@1 82.422 (85.759)	Acc@5 100.000 (99.419)
Max memory in training epoch: 52.4356096
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.135 (0.135)	Data 0.298 (0.298)	Loss 0.6717 (0.6717)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.114 (0.118)	Data 0.000 (0.005)	Loss 0.6164 (0.6440)	Acc@1 84.766 (86.394)	Acc@5 99.609 (99.453)
Epoch: [60][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.6560 (0.6508)	Acc@1 84.766 (86.192)	Acc@5 98.828 (99.467)
Epoch: [60][192/196]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.6988 (0.6537)	Acc@1 82.422 (86.000)	Acc@5 99.609 (99.498)
Max memory in training epoch: 52.4356096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 214068 ; 214792 ; 0.9966292971805282
[INFO] Storing checkpoint...
  81.46
Max memory: 80.996864
 23.237s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8387
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.0928256
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.160 (0.160)	Data 0.259 (0.259)	Loss 0.6271 (0.6271)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.113 (0.116)	Data 0.000 (0.004)	Loss 0.6729 (0.6243)	Acc@1 83.984 (87.073)	Acc@5 99.219 (99.573)
Epoch: [61][128/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.7085 (0.6428)	Acc@1 82.422 (86.428)	Acc@5 99.219 (99.488)
Epoch: [61][192/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.6242 (0.6462)	Acc@1 86.328 (86.288)	Acc@5 99.609 (99.466)
Max memory in training epoch: 52.434176
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.163 (0.163)	Data 0.274 (0.274)	Loss 0.6711 (0.6711)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [62][64/196]	Time 0.111 (0.115)	Data 0.000 (0.004)	Loss 0.6775 (0.6633)	Acc@1 85.156 (85.793)	Acc@5 99.609 (99.423)
Epoch: [62][128/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.6588 (0.6579)	Acc@1 84.375 (85.844)	Acc@5 99.219 (99.406)
Epoch: [62][192/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.7210 (0.6557)	Acc@1 85.156 (86.014)	Acc@5 98.828 (99.423)
Max memory in training epoch: 52.172032
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.137 (0.137)	Data 0.285 (0.285)	Loss 0.5789 (0.5789)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.116 (0.116)	Data 0.000 (0.005)	Loss 0.6507 (0.6472)	Acc@1 83.984 (86.022)	Acc@5 99.219 (99.483)
Epoch: [63][128/196]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.7112 (0.6574)	Acc@1 83.594 (85.683)	Acc@5 99.219 (99.428)
Epoch: [63][192/196]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.5444 (0.6553)	Acc@1 91.016 (85.836)	Acc@5 100.000 (99.458)
Max memory in training epoch: 52.172032
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.135 (0.135)	Data 0.318 (0.318)	Loss 0.6724 (0.6724)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.110 (0.111)	Data 0.000 (0.005)	Loss 0.6640 (0.6414)	Acc@1 84.375 (86.178)	Acc@5 99.219 (99.549)
Epoch: [64][128/196]	Time 0.113 (0.112)	Data 0.000 (0.003)	Loss 0.6508 (0.6551)	Acc@1 87.109 (85.828)	Acc@5 99.609 (99.506)
Epoch: [64][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.6481 (0.6614)	Acc@1 84.766 (85.709)	Acc@5 100.000 (99.482)
Max memory in training epoch: 52.172032
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.155 (0.155)	Data 0.302 (0.302)	Loss 0.6613 (0.6613)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [65][64/196]	Time 0.110 (0.114)	Data 0.000 (0.005)	Loss 0.6570 (0.6437)	Acc@1 83.203 (86.430)	Acc@5 98.828 (99.459)
Epoch: [65][128/196]	Time 0.113 (0.114)	Data 0.000 (0.003)	Loss 0.5944 (0.6508)	Acc@1 88.281 (86.183)	Acc@5 100.000 (99.443)
Epoch: [65][192/196]	Time 0.114 (0.113)	Data 0.000 (0.002)	Loss 0.6520 (0.6531)	Acc@1 85.156 (86.047)	Acc@5 100.000 (99.452)
Max memory in training epoch: 52.172032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 213778 ; 214068 ; 0.9986452902815928
[INFO] Storing checkpoint...
  78.0
Max memory: 80.6201856
 22.606s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4230
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.0927232
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.162 (0.162)	Data 0.298 (0.298)	Loss 0.6574 (0.6574)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.114 (0.117)	Data 0.000 (0.005)	Loss 0.6157 (0.6320)	Acc@1 87.500 (86.605)	Acc@5 99.609 (99.405)
Epoch: [66][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.7503 (0.6467)	Acc@1 78.906 (86.210)	Acc@5 100.000 (99.437)
Epoch: [66][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.8008 (0.6477)	Acc@1 82.422 (86.160)	Acc@5 98.438 (99.421)
Max memory in training epoch: 52.079872
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.138 (0.138)	Data 0.300 (0.300)	Loss 0.7195 (0.7195)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.125 (0.117)	Data 0.000 (0.005)	Loss 0.6296 (0.6471)	Acc@1 88.281 (86.106)	Acc@5 100.000 (99.339)
Epoch: [67][128/196]	Time 0.119 (0.118)	Data 0.000 (0.003)	Loss 0.6524 (0.6538)	Acc@1 85.156 (85.953)	Acc@5 99.219 (99.388)
Epoch: [67][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.6032 (0.6546)	Acc@1 88.672 (85.885)	Acc@5 99.609 (99.419)
Max memory in training epoch: 52.1191936
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.158 (0.158)	Data 0.268 (0.268)	Loss 0.5634 (0.5634)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.115 (0.117)	Data 0.000 (0.004)	Loss 0.5651 (0.6543)	Acc@1 89.453 (85.715)	Acc@5 99.609 (99.405)
Epoch: [68][128/196]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.6098 (0.6500)	Acc@1 88.281 (85.919)	Acc@5 99.609 (99.440)
Epoch: [68][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.6332 (0.6525)	Acc@1 86.328 (85.923)	Acc@5 99.609 (99.449)
Max memory in training epoch: 52.1191936
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.157 (0.157)	Data 0.302 (0.302)	Loss 0.6944 (0.6944)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [69][64/196]	Time 0.122 (0.116)	Data 0.000 (0.005)	Loss 0.6790 (0.6606)	Acc@1 85.938 (85.619)	Acc@5 99.219 (99.495)
Epoch: [69][128/196]	Time 0.114 (0.116)	Data 0.000 (0.003)	Loss 0.7464 (0.6617)	Acc@1 83.594 (85.565)	Acc@5 98.047 (99.476)
Epoch: [69][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.6473 (0.6550)	Acc@1 87.891 (85.905)	Acc@5 98.828 (99.452)
Max memory in training epoch: 52.1191936
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.137 (0.137)	Data 0.280 (0.280)	Loss 0.6673 (0.6673)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [70][64/196]	Time 0.110 (0.117)	Data 0.000 (0.005)	Loss 0.6946 (0.6382)	Acc@1 83.984 (86.550)	Acc@5 98.828 (99.369)
Epoch: [70][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.5698 (0.6394)	Acc@1 89.062 (86.531)	Acc@5 99.609 (99.400)
Epoch: [70][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.6463 (0.6456)	Acc@1 87.109 (86.273)	Acc@5 99.609 (99.413)
Max memory in training epoch: 52.1191936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 213198 ; 213778 ; 0.9972869051071672
[INFO] Storing checkpoint...
  73.71
Max memory: 80.3511808
 23.127s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7438
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.0925184
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.156 (0.156)	Data 0.263 (0.263)	Loss 0.5945 (0.5945)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [71][64/196]	Time 0.113 (0.114)	Data 0.000 (0.004)	Loss 0.6759 (0.6202)	Acc@1 86.719 (87.103)	Acc@5 99.219 (99.501)
Epoch: [71][128/196]	Time 0.114 (0.113)	Data 0.000 (0.002)	Loss 0.6541 (0.6304)	Acc@1 85.547 (86.906)	Acc@5 99.609 (99.452)
Epoch: [71][192/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.6255 (0.6430)	Acc@1 87.109 (86.441)	Acc@5 99.219 (99.458)
Max memory in training epoch: 51.5154432
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.136 (0.136)	Data 0.286 (0.286)	Loss 0.5671 (0.5671)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.115 (0.113)	Data 0.000 (0.005)	Loss 0.5938 (0.6386)	Acc@1 88.672 (86.532)	Acc@5 100.000 (99.429)
Epoch: [72][128/196]	Time 0.117 (0.113)	Data 0.000 (0.002)	Loss 0.7118 (0.6509)	Acc@1 83.984 (86.152)	Acc@5 99.609 (99.443)
Epoch: [72][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.6444 (0.6510)	Acc@1 87.500 (86.186)	Acc@5 99.219 (99.425)
Max memory in training epoch: 51.698944
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.133 (0.133)	Data 0.288 (0.288)	Loss 0.6862 (0.6862)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.111 (0.116)	Data 0.000 (0.005)	Loss 0.6364 (0.6488)	Acc@1 87.500 (85.962)	Acc@5 100.000 (99.543)
Epoch: [73][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.6248 (0.6511)	Acc@1 87.891 (86.053)	Acc@5 99.219 (99.476)
Epoch: [73][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.6221 (0.6546)	Acc@1 86.328 (85.948)	Acc@5 99.609 (99.482)
Max memory in training epoch: 51.698944
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.132 (0.132)	Data 0.269 (0.269)	Loss 0.5753 (0.5753)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.106 (0.113)	Data 0.000 (0.004)	Loss 0.6306 (0.6424)	Acc@1 85.938 (86.406)	Acc@5 99.609 (99.489)
Epoch: [74][128/196]	Time 0.117 (0.113)	Data 0.000 (0.002)	Loss 0.6043 (0.6508)	Acc@1 86.328 (86.034)	Acc@5 99.609 (99.519)
Epoch: [74][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.7012 (0.6523)	Acc@1 81.250 (85.911)	Acc@5 99.609 (99.506)
Max memory in training epoch: 51.698944
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.143 (0.143)	Data 0.298 (0.298)	Loss 0.6273 (0.6273)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [75][64/196]	Time 0.114 (0.116)	Data 0.000 (0.005)	Loss 0.6788 (0.6417)	Acc@1 85.547 (85.980)	Acc@5 99.219 (99.507)
Epoch: [75][128/196]	Time 0.112 (0.115)	Data 0.000 (0.003)	Loss 0.7513 (0.6500)	Acc@1 82.031 (85.741)	Acc@5 98.828 (99.488)
Epoch: [75][192/196]	Time 0.104 (0.114)	Data 0.000 (0.002)	Loss 0.6799 (0.6481)	Acc@1 86.328 (85.946)	Acc@5 99.609 (99.472)
Max memory in training epoch: 51.698944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 212764 ; 213198 ; 0.9979643336241428
[INFO] Storing checkpoint...
  79.07
Max memory: 79.2827392
 22.815s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6329
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.0922624
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.163 (0.163)	Data 0.260 (0.260)	Loss 0.6754 (0.6754)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [76][64/196]	Time 0.108 (0.113)	Data 0.000 (0.004)	Loss 0.5961 (0.6185)	Acc@1 88.281 (87.218)	Acc@5 100.000 (99.501)
Epoch: [76][128/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.7129 (0.6350)	Acc@1 82.422 (86.652)	Acc@5 99.219 (99.485)
Epoch: [76][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.5873 (0.6367)	Acc@1 86.719 (86.609)	Acc@5 99.609 (99.488)
Max memory in training epoch: 51.5144192
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.160 (0.160)	Data 0.299 (0.299)	Loss 0.6565 (0.6565)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [77][64/196]	Time 0.112 (0.113)	Data 0.000 (0.005)	Loss 0.7389 (0.6486)	Acc@1 83.203 (86.292)	Acc@5 99.609 (99.459)
Epoch: [77][128/196]	Time 0.106 (0.112)	Data 0.000 (0.002)	Loss 0.6848 (0.6538)	Acc@1 84.766 (85.974)	Acc@5 99.609 (99.461)
Epoch: [77][192/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.7549 (0.6546)	Acc@1 85.938 (86.031)	Acc@5 99.219 (99.456)
Max memory in training epoch: 51.5144192
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.166 (0.166)	Data 0.275 (0.275)	Loss 0.6441 (0.6441)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [78][64/196]	Time 0.109 (0.112)	Data 0.000 (0.004)	Loss 0.6657 (0.6451)	Acc@1 85.938 (86.148)	Acc@5 99.219 (99.537)
Epoch: [78][128/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.6079 (0.6522)	Acc@1 89.844 (85.971)	Acc@5 99.609 (99.491)
Epoch: [78][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.6224 (0.6536)	Acc@1 85.156 (86.014)	Acc@5 100.000 (99.445)
Max memory in training epoch: 51.5144192
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.178 (0.178)	Data 0.269 (0.269)	Loss 0.6359 (0.6359)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.110 (0.111)	Data 0.000 (0.004)	Loss 0.6591 (0.6324)	Acc@1 85.938 (86.677)	Acc@5 98.828 (99.459)
Epoch: [79][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.6194 (0.6433)	Acc@1 87.891 (86.367)	Acc@5 99.609 (99.428)
Epoch: [79][192/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.6320 (0.6469)	Acc@1 87.109 (86.306)	Acc@5 98.828 (99.439)
Max memory in training epoch: 51.5144192
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.145 (0.145)	Data 0.300 (0.300)	Loss 0.5991 (0.5991)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.109 (0.112)	Data 0.000 (0.005)	Loss 0.6334 (0.6483)	Acc@1 87.500 (86.418)	Acc@5 98.438 (99.495)
Epoch: [80][128/196]	Time 0.109 (0.111)	Data 0.000 (0.003)	Loss 0.6276 (0.6428)	Acc@1 85.938 (86.486)	Acc@5 100.000 (99.479)
Epoch: [80][192/196]	Time 0.107 (0.112)	Data 0.000 (0.002)	Loss 0.5724 (0.6471)	Acc@1 89.062 (86.318)	Acc@5 100.000 (99.437)
Max memory in training epoch: 51.5144192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 211176 ; 212764 ; 0.9925363313342482
[INFO] Storing checkpoint...
  78.99
Max memory: 79.3765888
 22.249s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8939
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.0916992
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.162 (0.162)	Data 0.264 (0.264)	Loss 0.6281 (0.6281)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [81][64/196]	Time 0.110 (0.115)	Data 0.000 (0.004)	Loss 0.5845 (0.6235)	Acc@1 87.109 (87.061)	Acc@5 99.219 (99.543)
Epoch: [81][128/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.6740 (0.6353)	Acc@1 85.547 (86.616)	Acc@5 100.000 (99.546)
Epoch: [81][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.7131 (0.6433)	Acc@1 83.984 (86.348)	Acc@5 98.828 (99.498)
Max memory in training epoch: 51.3679872
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.158 (0.158)	Data 0.292 (0.292)	Loss 0.6321 (0.6321)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.122 (0.115)	Data 0.000 (0.005)	Loss 0.6752 (0.6567)	Acc@1 84.375 (85.889)	Acc@5 99.609 (99.495)
Epoch: [82][128/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.6528 (0.6482)	Acc@1 84.375 (85.938)	Acc@5 99.609 (99.485)
Epoch: [82][192/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.6386 (0.6519)	Acc@1 87.109 (85.899)	Acc@5 99.219 (99.449)
Max memory in training epoch: 51.4728448
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.159 (0.159)	Data 0.274 (0.274)	Loss 0.6313 (0.6313)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.119 (0.114)	Data 0.000 (0.004)	Loss 0.5675 (0.6293)	Acc@1 87.109 (86.839)	Acc@5 100.000 (99.501)
Epoch: [83][128/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.6560 (0.6373)	Acc@1 85.938 (86.528)	Acc@5 100.000 (99.516)
Epoch: [83][192/196]	Time 0.116 (0.113)	Data 0.000 (0.002)	Loss 0.7128 (0.6406)	Acc@1 82.422 (86.452)	Acc@5 98.438 (99.478)
Max memory in training epoch: 51.4728448
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.140 (0.140)	Data 0.289 (0.289)	Loss 0.5773 (0.5773)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.114 (0.115)	Data 0.000 (0.005)	Loss 0.6891 (0.6447)	Acc@1 85.547 (86.130)	Acc@5 99.609 (99.543)
Epoch: [84][128/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.6590 (0.6482)	Acc@1 85.156 (86.050)	Acc@5 99.609 (99.485)
Epoch: [84][192/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.6689 (0.6491)	Acc@1 88.281 (86.047)	Acc@5 99.609 (99.506)
Max memory in training epoch: 51.4728448
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.147 (0.147)	Data 0.257 (0.257)	Loss 0.6003 (0.6003)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.107 (0.115)	Data 0.000 (0.004)	Loss 0.5740 (0.6322)	Acc@1 89.844 (86.659)	Acc@5 100.000 (99.519)
Epoch: [85][128/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.5976 (0.6358)	Acc@1 86.328 (86.513)	Acc@5 98.828 (99.509)
Epoch: [85][192/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.6128 (0.6457)	Acc@1 85.938 (86.128)	Acc@5 99.609 (99.476)
Max memory in training epoch: 51.4728448
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 209732 ; 211176 ; 0.9931621017539872
[INFO] Storing checkpoint...
  79.42
Max memory: 78.9698048
 22.651s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5228
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.0910848
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.195 (0.195)	Data 0.256 (0.256)	Loss 0.7773 (0.7773)	Acc@1 80.078 (80.078)	Acc@5 99.219 (99.219)
Epoch: [86][64/196]	Time 0.116 (0.114)	Data 0.000 (0.004)	Loss 0.5326 (0.6046)	Acc@1 91.016 (87.566)	Acc@5 99.609 (99.639)
Epoch: [86][128/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.6083 (0.6235)	Acc@1 84.766 (86.903)	Acc@5 99.609 (99.525)
Epoch: [86][192/196]	Time 0.109 (0.113)	Data 0.000 (0.002)	Loss 0.6700 (0.6324)	Acc@1 85.938 (86.614)	Acc@5 98.828 (99.486)
Max memory in training epoch: 51.1794688
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.160 (0.160)	Data 0.295 (0.295)	Loss 0.6477 (0.6477)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [87][64/196]	Time 0.113 (0.113)	Data 0.000 (0.005)	Loss 0.6256 (0.6357)	Acc@1 86.719 (86.532)	Acc@5 100.000 (99.429)
Epoch: [87][128/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.6855 (0.6364)	Acc@1 85.547 (86.349)	Acc@5 99.219 (99.428)
Epoch: [87][192/196]	Time 0.115 (0.113)	Data 0.000 (0.002)	Loss 0.7043 (0.6412)	Acc@1 82.812 (86.180)	Acc@5 99.609 (99.443)
Max memory in training epoch: 51.2082432
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.130 (0.130)	Data 0.325 (0.325)	Loss 0.5867 (0.5867)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.110 (0.114)	Data 0.000 (0.005)	Loss 0.6829 (0.6295)	Acc@1 82.422 (86.689)	Acc@5 98.828 (99.435)
Epoch: [88][128/196]	Time 0.112 (0.114)	Data 0.000 (0.003)	Loss 0.5853 (0.6350)	Acc@1 87.109 (86.401)	Acc@5 99.219 (99.467)
Epoch: [88][192/196]	Time 0.109 (0.113)	Data 0.000 (0.002)	Loss 0.6487 (0.6447)	Acc@1 86.328 (86.174)	Acc@5 98.438 (99.429)
Max memory in training epoch: 51.2082432
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.161 (0.161)	Data 0.266 (0.266)	Loss 0.6838 (0.6838)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.116 (0.115)	Data 0.000 (0.004)	Loss 0.6785 (0.6429)	Acc@1 85.547 (86.430)	Acc@5 99.219 (99.537)
Epoch: [89][128/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.5409 (0.6455)	Acc@1 89.062 (86.255)	Acc@5 99.219 (99.506)
Epoch: [89][192/196]	Time 0.124 (0.113)	Data 0.000 (0.002)	Loss 0.7108 (0.6458)	Acc@1 84.766 (86.211)	Acc@5 99.219 (99.480)
Max memory in training epoch: 51.2082432
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.161 (0.161)	Data 0.261 (0.261)	Loss 0.6412 (0.6412)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [90][64/196]	Time 0.116 (0.113)	Data 0.000 (0.004)	Loss 0.6012 (0.6303)	Acc@1 88.281 (86.653)	Acc@5 98.828 (99.519)
Epoch: [90][128/196]	Time 0.118 (0.113)	Data 0.000 (0.002)	Loss 0.5751 (0.6314)	Acc@1 88.281 (86.670)	Acc@5 100.000 (99.528)
Epoch: [90][192/196]	Time 0.105 (0.113)	Data 0.000 (0.002)	Loss 0.5985 (0.6347)	Acc@1 88.281 (86.585)	Acc@5 99.219 (99.530)
Max memory in training epoch: 51.2082432
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 209442 ; 209732 ; 0.9986172830087922
[INFO] Storing checkpoint...
  78.68
Max memory: 79.2161792
 22.435s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4534
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.0909824
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.180 (0.180)	Data 0.272 (0.272)	Loss 0.5777 (0.5777)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.107 (0.114)	Data 0.000 (0.004)	Loss 0.5878 (0.6083)	Acc@1 88.281 (87.416)	Acc@5 99.609 (99.531)
Epoch: [91][128/196]	Time 0.117 (0.113)	Data 0.000 (0.002)	Loss 0.6554 (0.6225)	Acc@1 86.719 (86.828)	Acc@5 99.609 (99.546)
Epoch: [91][192/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.5793 (0.6324)	Acc@1 88.281 (86.419)	Acc@5 100.000 (99.502)
Max memory in training epoch: 51.0112256
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.151 (0.151)	Data 0.297 (0.297)	Loss 0.5945 (0.5945)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.105 (0.114)	Data 0.000 (0.005)	Loss 0.6670 (0.6273)	Acc@1 86.719 (86.833)	Acc@5 98.438 (99.525)
Epoch: [92][128/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.5580 (0.6376)	Acc@1 90.234 (86.446)	Acc@5 100.000 (99.443)
Epoch: [92][192/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.6438 (0.6479)	Acc@1 83.984 (86.020)	Acc@5 100.000 (99.437)
Max memory in training epoch: 50.7884032
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.149 (0.149)	Data 0.291 (0.291)	Loss 0.6175 (0.6175)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.110 (0.113)	Data 0.000 (0.005)	Loss 0.5201 (0.5572)	Acc@1 91.406 (89.375)	Acc@5 99.609 (99.627)
Epoch: [93][128/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.4311 (0.5290)	Acc@1 94.141 (90.362)	Acc@5 100.000 (99.697)
Epoch: [93][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.5313 (0.5147)	Acc@1 89.453 (90.842)	Acc@5 100.000 (99.713)
Max memory in training epoch: 50.7884032
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.160 (0.160)	Data 0.295 (0.295)	Loss 0.4399 (0.4399)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.114 (0.117)	Data 0.000 (0.005)	Loss 0.4526 (0.4642)	Acc@1 93.359 (92.470)	Acc@5 100.000 (99.844)
Epoch: [94][128/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.4457 (0.4605)	Acc@1 92.188 (92.487)	Acc@5 100.000 (99.840)
Epoch: [94][192/196]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.4117 (0.4615)	Acc@1 93.359 (92.465)	Acc@5 99.609 (99.810)
Max memory in training epoch: 50.7884032
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.128 (0.128)	Data 0.304 (0.304)	Loss 0.4493 (0.4493)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.107 (0.114)	Data 0.000 (0.005)	Loss 0.4087 (0.4418)	Acc@1 94.531 (93.101)	Acc@5 100.000 (99.850)
Epoch: [95][128/196]	Time 0.110 (0.113)	Data 0.000 (0.003)	Loss 0.3692 (0.4397)	Acc@1 94.922 (93.105)	Acc@5 100.000 (99.852)
Epoch: [95][192/196]	Time 0.106 (0.113)	Data 0.000 (0.002)	Loss 0.4084 (0.4384)	Acc@1 93.750 (93.090)	Acc@5 100.000 (99.828)
Max memory in training epoch: 50.7884032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 209152 ; 209442 ; 0.9986153684552287
[INFO] Storing checkpoint...
  90.82
Max memory: 78.8587008
 22.598s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2058
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.09088
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.180 (0.180)	Data 0.266 (0.266)	Loss 0.3647 (0.3647)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.112 (0.114)	Data 0.000 (0.004)	Loss 0.3674 (0.4216)	Acc@1 95.312 (93.528)	Acc@5 100.000 (99.868)
Epoch: [96][128/196]	Time 0.115 (0.113)	Data 0.000 (0.002)	Loss 0.3977 (0.4243)	Acc@1 93.359 (93.432)	Acc@5 100.000 (99.858)
Epoch: [96][192/196]	Time 0.117 (0.113)	Data 0.000 (0.002)	Loss 0.4565 (0.4246)	Acc@1 92.578 (93.355)	Acc@5 100.000 (99.854)
Max memory in training epoch: 50.552064
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.174 (0.174)	Data 0.260 (0.260)	Loss 0.4378 (0.4378)	Acc@1 92.188 (92.188)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.114 (0.115)	Data 0.000 (0.004)	Loss 0.3886 (0.4071)	Acc@1 94.922 (94.123)	Acc@5 99.609 (99.880)
Epoch: [97][128/196]	Time 0.105 (0.114)	Data 0.000 (0.002)	Loss 0.4180 (0.4107)	Acc@1 94.922 (93.808)	Acc@5 100.000 (99.882)
Epoch: [97][192/196]	Time 0.105 (0.114)	Data 0.000 (0.002)	Loss 0.3711 (0.4117)	Acc@1 95.312 (93.736)	Acc@5 100.000 (99.866)
Max memory in training epoch: 50.3685632
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.158 (0.158)	Data 0.278 (0.278)	Loss 0.4240 (0.4240)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.112 (0.115)	Data 0.000 (0.004)	Loss 0.3850 (0.4047)	Acc@1 94.141 (93.810)	Acc@5 100.000 (99.892)
Epoch: [98][128/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.4547 (0.4023)	Acc@1 91.797 (93.859)	Acc@5 100.000 (99.864)
Epoch: [98][192/196]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.4112 (0.4011)	Acc@1 94.141 (93.892)	Acc@5 100.000 (99.852)
Max memory in training epoch: 50.3685632
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.166 (0.166)	Data 0.268 (0.268)	Loss 0.3770 (0.3770)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.113 (0.113)	Data 0.000 (0.004)	Loss 0.3752 (0.3902)	Acc@1 94.531 (94.002)	Acc@5 100.000 (99.886)
Epoch: [99][128/196]	Time 0.115 (0.113)	Data 0.000 (0.002)	Loss 0.3403 (0.3932)	Acc@1 95.312 (93.883)	Acc@5 100.000 (99.870)
Epoch: [99][192/196]	Time 0.108 (0.113)	Data 0.000 (0.002)	Loss 0.3708 (0.3927)	Acc@1 94.922 (93.896)	Acc@5 100.000 (99.881)
Max memory in training epoch: 50.3685632
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.160 (0.160)	Data 0.277 (0.277)	Loss 0.3845 (0.3845)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.111 (0.116)	Data 0.000 (0.004)	Loss 0.4407 (0.3819)	Acc@1 92.188 (94.261)	Acc@5 100.000 (99.892)
Epoch: [100][128/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.3642 (0.3831)	Acc@1 93.359 (94.174)	Acc@5 100.000 (99.885)
Epoch: [100][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3873 (0.3809)	Acc@1 94.531 (94.282)	Acc@5 100.000 (99.875)
Max memory in training epoch: 50.3685632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.23
Max memory: 78.1100544
 23.193s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2305
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.09088
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.182 (0.182)	Data 0.261 (0.261)	Loss 0.3820 (0.3820)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.114 (0.113)	Data 0.000 (0.004)	Loss 0.3816 (0.3685)	Acc@1 94.922 (94.561)	Acc@5 100.000 (99.946)
Epoch: [101][128/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.3681 (0.3708)	Acc@1 95.312 (94.522)	Acc@5 100.000 (99.903)
Epoch: [101][192/196]	Time 0.107 (0.112)	Data 0.000 (0.002)	Loss 0.3487 (0.3724)	Acc@1 96.094 (94.392)	Acc@5 100.000 (99.899)
Max memory in training epoch: 50.552064
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.129 (0.129)	Data 0.300 (0.300)	Loss 0.3205 (0.3205)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.109 (0.111)	Data 0.000 (0.005)	Loss 0.3385 (0.3606)	Acc@1 94.922 (94.760)	Acc@5 100.000 (99.898)
Epoch: [102][128/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.3410 (0.3617)	Acc@1 96.094 (94.692)	Acc@5 100.000 (99.891)
Epoch: [102][192/196]	Time 0.116 (0.110)	Data 0.000 (0.002)	Loss 0.3314 (0.3613)	Acc@1 97.656 (94.651)	Acc@5 100.000 (99.895)
Max memory in training epoch: 50.3685632
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.154 (0.154)	Data 0.288 (0.288)	Loss 0.3088 (0.3088)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.113 (0.112)	Data 0.000 (0.005)	Loss 0.3505 (0.3578)	Acc@1 95.312 (94.820)	Acc@5 100.000 (99.928)
Epoch: [103][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.4001 (0.3577)	Acc@1 93.750 (94.773)	Acc@5 100.000 (99.930)
Epoch: [103][192/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.3595 (0.3575)	Acc@1 95.312 (94.774)	Acc@5 100.000 (99.913)
Max memory in training epoch: 50.3685632
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.164 (0.164)	Data 0.304 (0.304)	Loss 0.3347 (0.3347)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.102 (0.112)	Data 0.000 (0.005)	Loss 0.3345 (0.3504)	Acc@1 95.703 (94.766)	Acc@5 100.000 (99.934)
Epoch: [104][128/196]	Time 0.106 (0.112)	Data 0.000 (0.003)	Loss 0.3718 (0.3506)	Acc@1 93.359 (94.837)	Acc@5 100.000 (99.915)
Epoch: [104][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3315 (0.3508)	Acc@1 95.312 (94.764)	Acc@5 100.000 (99.919)
Max memory in training epoch: 50.3685632
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.165 (0.165)	Data 0.266 (0.266)	Loss 0.3234 (0.3234)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.111 (0.113)	Data 0.000 (0.004)	Loss 0.3272 (0.3419)	Acc@1 96.094 (95.066)	Acc@5 100.000 (99.934)
Epoch: [105][128/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3824 (0.3408)	Acc@1 93.359 (95.094)	Acc@5 100.000 (99.949)
Epoch: [105][192/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.2930 (0.3439)	Acc@1 96.094 (94.970)	Acc@5 100.000 (99.917)
Max memory in training epoch: 50.3685632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 206116 ; 209152 ; 0.985484241126071
[INFO] Storing checkpoint...
  91.17
Max memory: 78.1100544
 22.124s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4404
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.0897024
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.167 (0.167)	Data 0.266 (0.266)	Loss 0.3758 (0.3758)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [106][64/196]	Time 0.115 (0.117)	Data 0.000 (0.004)	Loss 0.3391 (0.3391)	Acc@1 93.359 (94.874)	Acc@5 100.000 (99.934)
Epoch: [106][128/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.3017 (0.3416)	Acc@1 96.875 (94.861)	Acc@5 100.000 (99.918)
Epoch: [106][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3920 (0.3412)	Acc@1 91.797 (94.873)	Acc@5 100.000 (99.919)
Max memory in training epoch: 49.5186432
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.163 (0.163)	Data 0.278 (0.278)	Loss 0.3693 (0.3693)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.114 (0.114)	Data 0.000 (0.004)	Loss 0.3494 (0.3373)	Acc@1 94.531 (94.910)	Acc@5 100.000 (99.928)
Epoch: [107][128/196]	Time 0.118 (0.113)	Data 0.000 (0.002)	Loss 0.2864 (0.3384)	Acc@1 96.875 (94.910)	Acc@5 100.000 (99.939)
Epoch: [107][192/196]	Time 0.121 (0.113)	Data 0.000 (0.002)	Loss 0.3620 (0.3404)	Acc@1 94.141 (94.796)	Acc@5 99.609 (99.925)
Max memory in training epoch: 49.3808128
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.150 (0.150)	Data 0.290 (0.290)	Loss 0.3106 (0.3106)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.110 (0.114)	Data 0.000 (0.005)	Loss 0.3049 (0.3207)	Acc@1 96.094 (95.553)	Acc@5 100.000 (99.952)
Epoch: [108][128/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.3500 (0.3239)	Acc@1 92.578 (95.331)	Acc@5 100.000 (99.949)
Epoch: [108][192/196]	Time 0.107 (0.113)	Data 0.000 (0.002)	Loss 0.3415 (0.3285)	Acc@1 94.922 (95.185)	Acc@5 100.000 (99.943)
Max memory in training epoch: 49.3808128
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.164 (0.164)	Data 0.264 (0.264)	Loss 0.3286 (0.3286)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.103 (0.114)	Data 0.000 (0.004)	Loss 0.3311 (0.3271)	Acc@1 94.141 (95.108)	Acc@5 99.609 (99.922)
Epoch: [109][128/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.3414 (0.3257)	Acc@1 93.359 (95.122)	Acc@5 100.000 (99.933)
Epoch: [109][192/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.2734 (0.3282)	Acc@1 96.875 (95.023)	Acc@5 100.000 (99.931)
Max memory in training epoch: 49.3808128
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.160 (0.160)	Data 0.269 (0.269)	Loss 0.2739 (0.2739)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.114 (0.113)	Data 0.000 (0.004)	Loss 0.2719 (0.3190)	Acc@1 97.266 (95.487)	Acc@5 100.000 (99.934)
Epoch: [110][128/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.3371 (0.3256)	Acc@1 96.094 (95.194)	Acc@5 100.000 (99.927)
Epoch: [110][192/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.3450 (0.3239)	Acc@1 95.312 (95.159)	Acc@5 100.000 (99.943)
Max memory in training epoch: 49.3808128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 199326 ; 206116 ; 0.9670573851617535
[INFO] Storing checkpoint...
  90.06
Max memory: 76.738048
 22.437s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4985
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.08704
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.201 (0.201)	Data 0.283 (0.283)	Loss 0.3256 (0.3256)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.116 (0.114)	Data 0.000 (0.005)	Loss 0.2757 (0.3190)	Acc@1 96.484 (94.988)	Acc@5 100.000 (99.964)
Epoch: [111][128/196]	Time 0.108 (0.113)	Data 0.000 (0.002)	Loss 0.2911 (0.3220)	Acc@1 95.312 (94.919)	Acc@5 100.000 (99.955)
Epoch: [111][192/196]	Time 0.109 (0.113)	Data 0.000 (0.002)	Loss 0.3665 (0.3272)	Acc@1 92.578 (94.722)	Acc@5 100.000 (99.941)
Max memory in training epoch: 48.6099456
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.173 (0.173)	Data 0.263 (0.263)	Loss 0.2838 (0.2838)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.110 (0.113)	Data 0.000 (0.004)	Loss 0.2561 (0.3137)	Acc@1 97.266 (95.174)	Acc@5 100.000 (99.928)
Epoch: [112][128/196]	Time 0.121 (0.113)	Data 0.000 (0.002)	Loss 0.3365 (0.3204)	Acc@1 93.750 (94.904)	Acc@5 100.000 (99.915)
Epoch: [112][192/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.3622 (0.3217)	Acc@1 94.141 (94.841)	Acc@5 100.000 (99.919)
Max memory in training epoch: 48.5313024
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.131 (0.131)	Data 0.279 (0.279)	Loss 0.2977 (0.2977)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.116 (0.115)	Data 0.000 (0.004)	Loss 0.3349 (0.3155)	Acc@1 95.312 (95.012)	Acc@5 100.000 (99.940)
Epoch: [113][128/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3072 (0.3166)	Acc@1 94.922 (94.952)	Acc@5 100.000 (99.939)
Epoch: [113][192/196]	Time 0.130 (0.114)	Data 0.000 (0.002)	Loss 0.3428 (0.3194)	Acc@1 94.531 (94.877)	Acc@5 100.000 (99.929)
Max memory in training epoch: 48.5313024
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.152 (0.152)	Data 0.266 (0.266)	Loss 0.3371 (0.3371)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.115 (0.115)	Data 0.000 (0.004)	Loss 0.3420 (0.3119)	Acc@1 93.359 (95.126)	Acc@5 100.000 (99.916)
Epoch: [114][128/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.3503 (0.3127)	Acc@1 92.578 (95.034)	Acc@5 100.000 (99.933)
Epoch: [114][192/196]	Time 0.115 (0.113)	Data 0.000 (0.002)	Loss 0.3414 (0.3142)	Acc@1 93.750 (95.021)	Acc@5 100.000 (99.937)
Max memory in training epoch: 48.5313024
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.148 (0.148)	Data 0.300 (0.300)	Loss 0.2846 (0.2846)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.106 (0.115)	Data 0.000 (0.005)	Loss 0.3045 (0.3035)	Acc@1 94.531 (95.234)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.3247 (0.3111)	Acc@1 94.922 (94.979)	Acc@5 99.609 (99.942)
Epoch: [115][192/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.2760 (0.3132)	Acc@1 96.484 (94.906)	Acc@5 100.000 (99.933)
Max memory in training epoch: 48.5313024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 194848 ; 199326 ; 0.9775342905591845
[INFO] Storing checkpoint...
  90.52
Max memory: 75.5549184
 22.471s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6716
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0851968
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.166 (0.166)	Data 0.291 (0.291)	Loss 0.3238 (0.3238)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.109 (0.111)	Data 0.000 (0.005)	Loss 0.3044 (0.3125)	Acc@1 94.141 (94.964)	Acc@5 100.000 (99.928)
Epoch: [116][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.2976 (0.3147)	Acc@1 94.531 (94.816)	Acc@5 100.000 (99.927)
Epoch: [116][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.3917 (0.3157)	Acc@1 92.188 (94.734)	Acc@5 100.000 (99.931)
Max memory in training epoch: 48.3142144
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.171 (0.171)	Data 0.304 (0.304)	Loss 0.3001 (0.3001)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.3172 (0.3157)	Acc@1 94.922 (94.790)	Acc@5 100.000 (99.940)
Epoch: [117][128/196]	Time 0.103 (0.111)	Data 0.000 (0.003)	Loss 0.2909 (0.3107)	Acc@1 95.703 (94.955)	Acc@5 100.000 (99.939)
Epoch: [117][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3168 (0.3134)	Acc@1 95.312 (94.790)	Acc@5 100.000 (99.937)
Max memory in training epoch: 48.0389632
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.161 (0.161)	Data 0.290 (0.290)	Loss 0.3392 (0.3392)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.117 (0.113)	Data 0.000 (0.005)	Loss 0.3561 (0.3111)	Acc@1 92.578 (94.700)	Acc@5 99.609 (99.916)
Epoch: [118][128/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.3763 (0.3113)	Acc@1 91.797 (94.689)	Acc@5 100.000 (99.933)
Epoch: [118][192/196]	Time 0.105 (0.114)	Data 0.000 (0.002)	Loss 0.3597 (0.3125)	Acc@1 92.969 (94.667)	Acc@5 99.609 (99.921)
Max memory in training epoch: 48.0389632
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.137 (0.137)	Data 0.268 (0.268)	Loss 0.2845 (0.2845)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.109 (0.113)	Data 0.000 (0.004)	Loss 0.3511 (0.3054)	Acc@1 93.359 (95.042)	Acc@5 100.000 (99.964)
Epoch: [119][128/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.3293 (0.3075)	Acc@1 92.969 (94.892)	Acc@5 100.000 (99.942)
Epoch: [119][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.2890 (0.3094)	Acc@1 95.312 (94.841)	Acc@5 100.000 (99.929)
Max memory in training epoch: 48.0389632
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.160 (0.160)	Data 0.299 (0.299)	Loss 0.3903 (0.3903)	Acc@1 94.141 (94.141)	Acc@5 99.219 (99.219)
Epoch: [120][64/196]	Time 0.110 (0.113)	Data 0.000 (0.005)	Loss 0.2874 (0.3041)	Acc@1 95.703 (95.048)	Acc@5 99.219 (99.940)
Epoch: [120][128/196]	Time 0.108 (0.112)	Data 0.000 (0.003)	Loss 0.3162 (0.3042)	Acc@1 95.703 (95.040)	Acc@5 100.000 (99.949)
Epoch: [120][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.3116 (0.3068)	Acc@1 93.359 (94.938)	Acc@5 100.000 (99.943)
Max memory in training epoch: 48.0389632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 184456 ; 194848 ; 0.9466661192314009
[INFO] Storing checkpoint...
  89.42
Max memory: 74.9087744
 22.264s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5456
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0812544
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.183 (0.183)	Data 0.264 (0.264)	Loss 0.3799 (0.3799)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [121][64/196]	Time 0.111 (0.113)	Data 0.000 (0.004)	Loss 0.2994 (0.3182)	Acc@1 94.922 (94.225)	Acc@5 100.000 (99.922)
Epoch: [121][128/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.2799 (0.3168)	Acc@1 95.703 (94.353)	Acc@5 100.000 (99.927)
Epoch: [121][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3539 (0.3201)	Acc@1 91.406 (94.211)	Acc@5 100.000 (99.925)
Max memory in training epoch: 48.0231936
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.138 (0.138)	Data 0.270 (0.270)	Loss 0.2977 (0.2977)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.105 (0.112)	Data 0.000 (0.004)	Loss 0.2535 (0.3094)	Acc@1 95.312 (94.663)	Acc@5 100.000 (99.916)
Epoch: [122][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.3584 (0.3139)	Acc@1 92.969 (94.368)	Acc@5 99.609 (99.936)
Epoch: [122][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3209 (0.3174)	Acc@1 94.141 (94.244)	Acc@5 100.000 (99.921)
Max memory in training epoch: 47.5709952
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.168 (0.168)	Data 0.267 (0.267)	Loss 0.3288 (0.3288)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.106 (0.111)	Data 0.000 (0.004)	Loss 0.3150 (0.3060)	Acc@1 95.703 (94.778)	Acc@5 99.609 (99.952)
Epoch: [123][128/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.2679 (0.3084)	Acc@1 96.094 (94.707)	Acc@5 100.000 (99.939)
Epoch: [123][192/196]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.2945 (0.3096)	Acc@1 95.312 (94.604)	Acc@5 100.000 (99.925)
Max memory in training epoch: 47.5709952
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.142 (0.142)	Data 0.311 (0.311)	Loss 0.3744 (0.3744)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.114 (0.115)	Data 0.000 (0.005)	Loss 0.2536 (0.2987)	Acc@1 97.656 (94.826)	Acc@5 99.609 (99.952)
Epoch: [124][128/196]	Time 0.118 (0.115)	Data 0.000 (0.003)	Loss 0.3589 (0.3006)	Acc@1 92.969 (94.861)	Acc@5 100.000 (99.949)
Epoch: [124][192/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.2891 (0.3075)	Acc@1 95.703 (94.659)	Acc@5 100.000 (99.933)
Max memory in training epoch: 47.5709952
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.150 (0.150)	Data 0.289 (0.289)	Loss 0.2979 (0.2979)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.109 (0.112)	Data 0.000 (0.005)	Loss 0.3094 (0.3010)	Acc@1 95.312 (94.868)	Acc@5 100.000 (99.940)
Epoch: [125][128/196]	Time 0.121 (0.111)	Data 0.000 (0.002)	Loss 0.2814 (0.3051)	Acc@1 94.141 (94.689)	Acc@5 100.000 (99.927)
Epoch: [125][192/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.3085 (0.3100)	Acc@1 94.922 (94.501)	Acc@5 100.000 (99.935)
Max memory in training epoch: 47.5709952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv28.weight

 RM:  module.conv29.weight
numoFStages: 3
Count: 174141 ; 184456 ; 0.9440788047013922
[INFO] Storing checkpoint...
  89.6
Max memory: 74.625792
 22.070s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5282
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0767488
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.180 (0.180)	Data 0.266 (0.266)	Loss 0.3814 (0.3814)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.107 (0.108)	Data 0.000 (0.004)	Loss 0.3443 (0.3179)	Acc@1 92.969 (94.207)	Acc@5 98.828 (99.928)
Epoch: [126][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3184 (0.3181)	Acc@1 94.922 (94.247)	Acc@5 100.000 (99.909)
Epoch: [126][192/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3099 (0.3232)	Acc@1 94.141 (93.979)	Acc@5 100.000 (99.905)
Max memory in training epoch: 46.0917248
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.147 (0.147)	Data 0.300 (0.300)	Loss 0.3228 (0.3228)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.101 (0.106)	Data 0.000 (0.005)	Loss 0.2979 (0.3122)	Acc@1 92.969 (94.363)	Acc@5 100.000 (99.928)
Epoch: [127][128/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.3439 (0.3147)	Acc@1 94.141 (94.295)	Acc@5 99.609 (99.921)
Epoch: [127][192/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.3245 (0.3176)	Acc@1 94.531 (94.232)	Acc@5 100.000 (99.909)
Max memory in training epoch: 46.0006912
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.152 (0.152)	Data 0.265 (0.265)	Loss 0.2795 (0.2795)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.116 (0.107)	Data 0.000 (0.004)	Loss 0.3767 (0.3064)	Acc@1 92.578 (94.441)	Acc@5 100.000 (99.922)
Epoch: [128][128/196]	Time 0.122 (0.108)	Data 0.000 (0.002)	Loss 0.3236 (0.3126)	Acc@1 94.141 (94.225)	Acc@5 100.000 (99.918)
Epoch: [128][192/196]	Time 0.103 (0.108)	Data 0.000 (0.002)	Loss 0.3401 (0.3141)	Acc@1 93.359 (94.135)	Acc@5 100.000 (99.925)
Max memory in training epoch: 46.0006912
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.140 (0.140)	Data 0.299 (0.299)	Loss 0.3000 (0.3000)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [129][64/196]	Time 0.108 (0.107)	Data 0.000 (0.005)	Loss 0.3018 (0.3045)	Acc@1 96.094 (94.549)	Acc@5 100.000 (99.916)
Epoch: [129][128/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.3024 (0.3083)	Acc@1 94.922 (94.310)	Acc@5 100.000 (99.897)
Epoch: [129][192/196]	Time 0.100 (0.106)	Data 0.000 (0.002)	Loss 0.3998 (0.3129)	Acc@1 93.750 (94.078)	Acc@5 99.609 (99.897)
Max memory in training epoch: 46.0006912
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.138 (0.138)	Data 0.287 (0.287)	Loss 0.2646 (0.2646)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.115 (0.110)	Data 0.000 (0.005)	Loss 0.3025 (0.3086)	Acc@1 93.359 (94.603)	Acc@5 100.000 (99.940)
Epoch: [130][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.2958 (0.3116)	Acc@1 94.922 (94.389)	Acc@5 100.000 (99.924)
Epoch: [130][192/196]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.2890 (0.3126)	Acc@1 95.703 (94.278)	Acc@5 100.000 (99.919)
Max memory in training epoch: 46.0006912
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 167222 ; 174141 ; 0.9602678289432127
[INFO] Storing checkpoint...
  89.42
Max memory: 72.3399168
 21.834s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9286
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.0738304
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.180 (0.180)	Data 0.267 (0.267)	Loss 0.3156 (0.3156)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.106 (0.108)	Data 0.000 (0.004)	Loss 0.3161 (0.3155)	Acc@1 95.703 (93.888)	Acc@5 99.609 (99.916)
Epoch: [131][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3036 (0.3194)	Acc@1 95.312 (93.862)	Acc@5 100.000 (99.915)
Epoch: [131][192/196]	Time 0.102 (0.106)	Data 0.000 (0.002)	Loss 0.3338 (0.3191)	Acc@1 92.969 (93.784)	Acc@5 100.000 (99.913)
Max memory in training epoch: 45.7793024
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.157 (0.157)	Data 0.283 (0.283)	Loss 0.2702 (0.2702)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.103 (0.106)	Data 0.000 (0.005)	Loss 0.2993 (0.3153)	Acc@1 93.750 (93.900)	Acc@5 100.000 (99.904)
Epoch: [132][128/196]	Time 0.117 (0.106)	Data 0.000 (0.002)	Loss 0.3528 (0.3165)	Acc@1 91.406 (93.817)	Acc@5 100.000 (99.921)
Epoch: [132][192/196]	Time 0.122 (0.106)	Data 0.000 (0.002)	Loss 0.3929 (0.3203)	Acc@1 92.188 (93.728)	Acc@5 100.000 (99.909)
Max memory in training epoch: 45.7793024
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.127 (0.127)	Data 0.279 (0.279)	Loss 0.2993 (0.2993)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.103 (0.106)	Data 0.000 (0.004)	Loss 0.3075 (0.3251)	Acc@1 93.359 (93.612)	Acc@5 100.000 (99.910)
Epoch: [133][128/196]	Time 0.126 (0.106)	Data 0.000 (0.002)	Loss 0.3642 (0.3212)	Acc@1 93.359 (93.774)	Acc@5 99.609 (99.903)
Epoch: [133][192/196]	Time 0.100 (0.106)	Data 0.000 (0.002)	Loss 0.3606 (0.3238)	Acc@1 93.750 (93.629)	Acc@5 100.000 (99.907)
Max memory in training epoch: 45.7793024
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.156 (0.156)	Data 0.273 (0.273)	Loss 0.3096 (0.3096)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [134][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.2757 (0.3160)	Acc@1 94.531 (93.756)	Acc@5 100.000 (99.922)
Epoch: [134][128/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.3314 (0.3180)	Acc@1 95.312 (93.792)	Acc@5 100.000 (99.909)
Epoch: [134][192/196]	Time 0.100 (0.106)	Data 0.000 (0.002)	Loss 0.3099 (0.3202)	Acc@1 94.922 (93.732)	Acc@5 100.000 (99.917)
Max memory in training epoch: 45.7793024
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.150 (0.150)	Data 0.263 (0.263)	Loss 0.2942 (0.2942)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [135][64/196]	Time 0.109 (0.106)	Data 0.000 (0.004)	Loss 0.3009 (0.3124)	Acc@1 94.531 (94.153)	Acc@5 100.000 (99.928)
Epoch: [135][128/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.2973 (0.3103)	Acc@1 92.969 (94.207)	Acc@5 100.000 (99.921)
Epoch: [135][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.3144 (0.3119)	Acc@1 92.578 (94.025)	Acc@5 99.609 (99.915)
Max memory in training epoch: 45.7793024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 166374 ; 167222 ; 0.9949288969154776
[INFO] Storing checkpoint...
  88.62
Max memory: 71.2270848
 21.086s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7969
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.073472
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.171 (0.171)	Data 0.268 (0.268)	Loss 0.2967 (0.2967)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.105 (0.109)	Data 0.000 (0.004)	Loss 0.2642 (0.3037)	Acc@1 96.875 (94.213)	Acc@5 100.000 (99.946)
Epoch: [136][128/196]	Time 0.101 (0.108)	Data 0.000 (0.002)	Loss 0.3379 (0.3048)	Acc@1 92.578 (94.244)	Acc@5 100.000 (99.918)
Epoch: [136][192/196]	Time 0.111 (0.108)	Data 0.000 (0.002)	Loss 0.3420 (0.3122)	Acc@1 93.359 (93.999)	Acc@5 100.000 (99.909)
Max memory in training epoch: 45.6664576
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.121 (0.121)	Data 0.278 (0.278)	Loss 0.2687 (0.2687)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.105 (0.106)	Data 0.000 (0.004)	Loss 0.2940 (0.3091)	Acc@1 94.141 (94.171)	Acc@5 100.000 (99.928)
Epoch: [137][128/196]	Time 0.107 (0.105)	Data 0.000 (0.002)	Loss 0.2891 (0.3126)	Acc@1 95.312 (93.938)	Acc@5 100.000 (99.927)
Epoch: [137][192/196]	Time 0.101 (0.105)	Data 0.000 (0.002)	Loss 0.3376 (0.3182)	Acc@1 92.188 (93.807)	Acc@5 99.609 (99.925)
Max memory in training epoch: 45.7778688
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.150 (0.150)	Data 0.276 (0.276)	Loss 0.2642 (0.2642)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.104 (0.107)	Data 0.000 (0.004)	Loss 0.3281 (0.3067)	Acc@1 93.359 (94.225)	Acc@5 100.000 (99.928)
Epoch: [138][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2979 (0.3122)	Acc@1 95.312 (94.150)	Acc@5 99.609 (99.930)
Epoch: [138][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.3124 (0.3177)	Acc@1 93.750 (93.940)	Acc@5 100.000 (99.923)
Max memory in training epoch: 45.7778688
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.133 (0.133)	Data 0.309 (0.309)	Loss 0.3077 (0.3077)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.104 (0.107)	Data 0.000 (0.005)	Loss 0.3184 (0.3107)	Acc@1 93.750 (93.894)	Acc@5 100.000 (99.910)
Epoch: [139][128/196]	Time 0.097 (0.106)	Data 0.000 (0.003)	Loss 0.3884 (0.3153)	Acc@1 90.234 (93.762)	Acc@5 100.000 (99.918)
Epoch: [139][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.3507 (0.3170)	Acc@1 92.188 (93.712)	Acc@5 100.000 (99.921)
Max memory in training epoch: 45.7778688
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.133 (0.133)	Data 0.262 (0.262)	Loss 0.2918 (0.2918)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.101 (0.106)	Data 0.000 (0.004)	Loss 0.2924 (0.3088)	Acc@1 96.094 (94.459)	Acc@5 99.609 (99.916)
Epoch: [140][128/196]	Time 0.101 (0.106)	Data 0.000 (0.002)	Loss 0.2734 (0.3075)	Acc@1 94.531 (94.353)	Acc@5 100.000 (99.918)
Epoch: [140][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.3439 (0.3098)	Acc@1 92.578 (94.250)	Acc@5 100.000 (99.915)
Max memory in training epoch: 45.7778688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 161844 ; 166374 ; 0.9727721879620613
[INFO] Storing checkpoint...
  89.23
Max memory: 71.06176
 21.198s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1036
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0717312
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.177 (0.177)	Data 0.258 (0.258)	Loss 0.2821 (0.2821)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [141][64/196]	Time 0.103 (0.107)	Data 0.000 (0.004)	Loss 0.3002 (0.3090)	Acc@1 93.359 (94.026)	Acc@5 100.000 (99.874)
Epoch: [141][128/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.3610 (0.3161)	Acc@1 91.797 (93.756)	Acc@5 100.000 (99.891)
Epoch: [141][192/196]	Time 0.104 (0.106)	Data 0.000 (0.002)	Loss 0.2942 (0.3201)	Acc@1 95.703 (93.606)	Acc@5 100.000 (99.911)
Max memory in training epoch: 45.4235648
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.123 (0.123)	Data 0.299 (0.299)	Loss 0.2891 (0.2891)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.108 (0.110)	Data 0.000 (0.005)	Loss 0.3220 (0.3167)	Acc@1 94.141 (93.660)	Acc@5 99.609 (99.904)
Epoch: [142][128/196]	Time 0.108 (0.109)	Data 0.000 (0.002)	Loss 0.3380 (0.3168)	Acc@1 93.750 (93.735)	Acc@5 100.000 (99.888)
Epoch: [142][192/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.2494 (0.3172)	Acc@1 97.656 (93.793)	Acc@5 100.000 (99.897)
Max memory in training epoch: 45.108992
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.162 (0.162)	Data 0.298 (0.298)	Loss 0.2841 (0.2841)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.100 (0.106)	Data 0.000 (0.005)	Loss 0.3248 (0.3065)	Acc@1 93.750 (94.213)	Acc@5 100.000 (99.934)
Epoch: [143][128/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2641 (0.3129)	Acc@1 95.703 (94.004)	Acc@5 100.000 (99.927)
Epoch: [143][192/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.3163 (0.3174)	Acc@1 93.750 (93.799)	Acc@5 100.000 (99.919)
Max memory in training epoch: 45.2007424
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.142 (0.142)	Data 0.287 (0.287)	Loss 0.3257 (0.3257)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.103 (0.105)	Data 0.000 (0.005)	Loss 0.3133 (0.3133)	Acc@1 93.359 (94.038)	Acc@5 100.000 (99.892)
Epoch: [144][128/196]	Time 0.102 (0.104)	Data 0.000 (0.002)	Loss 0.2886 (0.3178)	Acc@1 93.750 (93.850)	Acc@5 100.000 (99.900)
Epoch: [144][192/196]	Time 0.108 (0.104)	Data 0.000 (0.002)	Loss 0.2855 (0.3190)	Acc@1 95.312 (93.738)	Acc@5 99.609 (99.905)
Max memory in training epoch: 45.2007424
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.166 (0.166)	Data 0.272 (0.272)	Loss 0.3149 (0.3149)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.095 (0.106)	Data 0.000 (0.004)	Loss 0.3351 (0.3180)	Acc@1 92.578 (93.852)	Acc@5 99.609 (99.898)
Epoch: [145][128/196]	Time 0.103 (0.105)	Data 0.000 (0.002)	Loss 0.3517 (0.3180)	Acc@1 93.359 (93.868)	Acc@5 100.000 (99.891)
Epoch: [145][192/196]	Time 0.103 (0.105)	Data 0.000 (0.002)	Loss 0.3014 (0.3185)	Acc@1 94.531 (93.813)	Acc@5 100.000 (99.885)
Max memory in training epoch: 45.2007424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 159030 ; 161844 ; 0.9826128864832802
[INFO] Storing checkpoint...
  89.09
Max memory: 70.4716288
 20.969s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6161
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0705024
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.176 (0.176)	Data 0.278 (0.278)	Loss 0.3247 (0.3247)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.103 (0.108)	Data 0.000 (0.004)	Loss 0.3284 (0.3020)	Acc@1 93.750 (94.273)	Acc@5 99.609 (99.910)
Epoch: [146][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.3656 (0.3075)	Acc@1 92.578 (94.044)	Acc@5 100.000 (99.918)
Epoch: [146][192/196]	Time 0.101 (0.107)	Data 0.000 (0.002)	Loss 0.3924 (0.3132)	Acc@1 89.844 (93.835)	Acc@5 99.219 (99.911)
Max memory in training epoch: 45.412096
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.141 (0.141)	Data 0.279 (0.279)	Loss 0.3129 (0.3129)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [147][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.2771 (0.3020)	Acc@1 96.484 (94.405)	Acc@5 100.000 (99.898)
Epoch: [147][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.3400 (0.3066)	Acc@1 91.797 (94.101)	Acc@5 100.000 (99.924)
Epoch: [147][192/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.4032 (0.3156)	Acc@1 91.406 (93.809)	Acc@5 99.609 (99.905)
Max memory in training epoch: 45.1368448
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.129 (0.129)	Data 0.311 (0.311)	Loss 0.2989 (0.2989)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [148][64/196]	Time 0.106 (0.111)	Data 0.000 (0.005)	Loss 0.3070 (0.3163)	Acc@1 93.359 (93.906)	Acc@5 100.000 (99.886)
Epoch: [148][128/196]	Time 0.106 (0.109)	Data 0.000 (0.003)	Loss 0.3338 (0.3142)	Acc@1 93.750 (93.932)	Acc@5 100.000 (99.906)
Epoch: [148][192/196]	Time 0.100 (0.108)	Data 0.000 (0.002)	Loss 0.3590 (0.3162)	Acc@1 94.141 (93.855)	Acc@5 98.828 (99.901)
Max memory in training epoch: 45.1106304
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.159 (0.159)	Data 0.273 (0.273)	Loss 0.3136 (0.3136)	Acc@1 92.578 (92.578)	Acc@5 99.609 (99.609)
Epoch: [149][64/196]	Time 0.106 (0.108)	Data 0.000 (0.004)	Loss 0.3124 (0.3109)	Acc@1 94.141 (94.243)	Acc@5 100.000 (99.928)
Epoch: [149][128/196]	Time 0.124 (0.107)	Data 0.000 (0.002)	Loss 0.3325 (0.3119)	Acc@1 92.969 (94.089)	Acc@5 100.000 (99.921)
Epoch: [149][192/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.2943 (0.3165)	Acc@1 95.703 (93.886)	Acc@5 100.000 (99.911)
Max memory in training epoch: 45.1106304
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.124 (0.124)	Data 0.268 (0.268)	Loss 0.2851 (0.2851)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.116 (0.106)	Data 0.000 (0.004)	Loss 0.2941 (0.2815)	Acc@1 94.922 (95.102)	Acc@5 99.609 (99.928)
Epoch: [150][128/196]	Time 0.118 (0.106)	Data 0.000 (0.002)	Loss 0.2515 (0.2729)	Acc@1 95.703 (95.428)	Acc@5 100.000 (99.942)
Epoch: [150][192/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2193 (0.2676)	Acc@1 97.656 (95.663)	Acc@5 100.000 (99.945)
Max memory in training epoch: 45.1106304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 155782 ; 159030 ; 0.9795761805948563
[INFO] Storing checkpoint...
  91.33
Max memory: 70.7378688
 21.103s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3753
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0693248
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.170 (0.170)	Data 0.288 (0.288)	Loss 0.2381 (0.2381)	Acc@1 97.656 (97.656)	Acc@5 99.219 (99.219)
Epoch: [151][64/196]	Time 0.111 (0.109)	Data 0.000 (0.005)	Loss 0.2216 (0.2618)	Acc@1 96.875 (95.787)	Acc@5 100.000 (99.940)
Epoch: [151][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2512 (0.2581)	Acc@1 96.875 (95.961)	Acc@5 100.000 (99.952)
Epoch: [151][192/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.2349 (0.2555)	Acc@1 96.484 (96.033)	Acc@5 100.000 (99.941)
Max memory in training epoch: 45.3418496
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.141 (0.141)	Data 0.313 (0.313)	Loss 0.2147 (0.2147)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.107 (0.108)	Data 0.000 (0.005)	Loss 0.2744 (0.2452)	Acc@1 95.703 (96.364)	Acc@5 99.609 (99.958)
Epoch: [152][128/196]	Time 0.113 (0.107)	Data 0.000 (0.003)	Loss 0.2368 (0.2455)	Acc@1 97.266 (96.397)	Acc@5 100.000 (99.961)
Epoch: [152][192/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2085 (0.2452)	Acc@1 97.656 (96.420)	Acc@5 100.000 (99.962)
Max memory in training epoch: 45.1452416
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.152 (0.152)	Data 0.288 (0.288)	Loss 0.2603 (0.2603)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.104 (0.108)	Data 0.000 (0.005)	Loss 0.2877 (0.2404)	Acc@1 93.750 (96.520)	Acc@5 100.000 (99.964)
Epoch: [153][128/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2932 (0.2385)	Acc@1 94.922 (96.672)	Acc@5 100.000 (99.970)
Epoch: [153][192/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.2122 (0.2370)	Acc@1 96.484 (96.715)	Acc@5 100.000 (99.964)
Max memory in training epoch: 45.1452416
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.130 (0.130)	Data 0.305 (0.305)	Loss 0.2213 (0.2213)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.102 (0.106)	Data 0.000 (0.005)	Loss 0.2729 (0.2324)	Acc@1 95.312 (96.905)	Acc@5 100.000 (99.982)
Epoch: [154][128/196]	Time 0.106 (0.107)	Data 0.000 (0.003)	Loss 0.2294 (0.2336)	Acc@1 96.875 (96.878)	Acc@5 100.000 (99.973)
Epoch: [154][192/196]	Time 0.112 (0.107)	Data 0.000 (0.002)	Loss 0.2206 (0.2340)	Acc@1 97.266 (96.828)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.1452416
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.151 (0.151)	Data 0.272 (0.272)	Loss 0.2299 (0.2299)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.103 (0.108)	Data 0.000 (0.004)	Loss 0.2479 (0.2285)	Acc@1 95.312 (97.079)	Acc@5 100.000 (99.976)
Epoch: [155][128/196]	Time 0.110 (0.107)	Data 0.000 (0.002)	Loss 0.2373 (0.2309)	Acc@1 95.312 (96.893)	Acc@5 100.000 (99.985)
Epoch: [155][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.2464 (0.2309)	Acc@1 97.266 (96.847)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.1452416
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 152725 ; 155782 ; 0.980376423463558
[INFO] Storing checkpoint...
  91.68
Max memory: 70.296064
 21.268s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3028
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0681984
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.185 (0.185)	Data 0.276 (0.276)	Loss 0.2543 (0.2543)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.101 (0.107)	Data 0.000 (0.004)	Loss 0.2587 (0.2333)	Acc@1 94.922 (96.647)	Acc@5 100.000 (99.994)
Epoch: [156][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2479 (0.2348)	Acc@1 96.875 (96.630)	Acc@5 100.000 (99.985)
Epoch: [156][192/196]	Time 0.124 (0.108)	Data 0.000 (0.002)	Loss 0.2555 (0.2352)	Acc@1 96.875 (96.677)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.0457088
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.135 (0.135)	Data 0.301 (0.301)	Loss 0.2249 (0.2249)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.103 (0.108)	Data 0.000 (0.005)	Loss 0.2655 (0.2322)	Acc@1 94.922 (96.869)	Acc@5 100.000 (99.976)
Epoch: [157][128/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.2131 (0.2292)	Acc@1 97.266 (97.005)	Acc@5 100.000 (99.967)
Epoch: [157][192/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.2341 (0.2291)	Acc@1 96.484 (96.946)	Acc@5 99.609 (99.964)
Max memory in training epoch: 45.0162176
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.137 (0.137)	Data 0.303 (0.303)	Loss 0.2220 (0.2220)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.103 (0.107)	Data 0.000 (0.005)	Loss 0.2379 (0.2272)	Acc@1 95.703 (96.779)	Acc@5 100.000 (99.982)
Epoch: [158][128/196]	Time 0.102 (0.108)	Data 0.000 (0.003)	Loss 0.2509 (0.2271)	Acc@1 95.312 (96.887)	Acc@5 99.609 (99.979)
Epoch: [158][192/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2401 (0.2274)	Acc@1 97.656 (96.885)	Acc@5 99.609 (99.968)
Max memory in training epoch: 45.0162176
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.156 (0.156)	Data 0.269 (0.269)	Loss 0.2234 (0.2234)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.102 (0.108)	Data 0.000 (0.004)	Loss 0.2122 (0.2237)	Acc@1 96.484 (97.067)	Acc@5 100.000 (99.964)
Epoch: [159][128/196]	Time 0.113 (0.108)	Data 0.000 (0.002)	Loss 0.2278 (0.2240)	Acc@1 96.484 (97.081)	Acc@5 100.000 (99.970)
Epoch: [159][192/196]	Time 0.109 (0.108)	Data 0.000 (0.002)	Loss 0.1845 (0.2240)	Acc@1 99.609 (97.096)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.0162176
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.148 (0.148)	Data 0.272 (0.272)	Loss 0.2141 (0.2141)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.111 (0.109)	Data 0.000 (0.004)	Loss 0.2166 (0.2219)	Acc@1 98.047 (97.109)	Acc@5 100.000 (99.982)
Epoch: [160][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.1988 (0.2222)	Acc@1 97.656 (97.123)	Acc@5 100.000 (99.973)
Epoch: [160][192/196]	Time 0.105 (0.109)	Data 0.000 (0.002)	Loss 0.2385 (0.2227)	Acc@1 94.922 (97.114)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.0162176
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 151625 ; 152725 ; 0.9927975118677361
[INFO] Storing checkpoint...
  91.55
Max memory: 70.1805568
 21.654s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3254
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.0676864
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.184 (0.184)	Data 0.293 (0.293)	Loss 0.2033 (0.2033)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.104 (0.109)	Data 0.000 (0.005)	Loss 0.2504 (0.2241)	Acc@1 98.047 (97.085)	Acc@5 100.000 (99.994)
Epoch: [161][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.2795 (0.2239)	Acc@1 94.922 (97.075)	Acc@5 100.000 (99.988)
Epoch: [161][192/196]	Time 0.100 (0.107)	Data 0.000 (0.002)	Loss 0.2119 (0.2249)	Acc@1 98.047 (97.071)	Acc@5 100.000 (99.984)
Max memory in training epoch: 44.9857024
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.150 (0.150)	Data 0.302 (0.302)	Loss 0.2289 (0.2289)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.105 (0.108)	Data 0.000 (0.005)	Loss 0.2189 (0.2179)	Acc@1 98.047 (97.416)	Acc@5 100.000 (99.976)
Epoch: [162][128/196]	Time 0.105 (0.107)	Data 0.000 (0.003)	Loss 0.2057 (0.2214)	Acc@1 98.828 (97.260)	Acc@5 100.000 (99.958)
Epoch: [162][192/196]	Time 0.105 (0.107)	Data 0.000 (0.002)	Loss 0.2070 (0.2202)	Acc@1 97.656 (97.231)	Acc@5 100.000 (99.970)
Max memory in training epoch: 45.0141696
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.139 (0.139)	Data 0.292 (0.292)	Loss 0.2552 (0.2552)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.111 (0.108)	Data 0.000 (0.005)	Loss 0.2014 (0.2181)	Acc@1 98.438 (97.079)	Acc@5 100.000 (99.964)
Epoch: [163][128/196]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.2012 (0.2189)	Acc@1 98.438 (97.105)	Acc@5 100.000 (99.967)
Epoch: [163][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.2393 (0.2183)	Acc@1 96.094 (97.193)	Acc@5 100.000 (99.970)
Max memory in training epoch: 45.0141696
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.164 (0.164)	Data 0.279 (0.279)	Loss 0.2267 (0.2267)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [164][64/196]	Time 0.098 (0.107)	Data 0.000 (0.004)	Loss 0.2151 (0.2168)	Acc@1 98.047 (97.218)	Acc@5 100.000 (99.976)
Epoch: [164][128/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.2255 (0.2162)	Acc@1 97.266 (97.281)	Acc@5 100.000 (99.976)
Epoch: [164][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.2105 (0.2158)	Acc@1 96.484 (97.270)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.0141696
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.147 (0.147)	Data 0.265 (0.265)	Loss 0.2151 (0.2151)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.108 (0.106)	Data 0.000 (0.004)	Loss 0.2017 (0.2117)	Acc@1 98.047 (97.512)	Acc@5 100.000 (99.988)
Epoch: [165][128/196]	Time 0.102 (0.107)	Data 0.000 (0.002)	Loss 0.2164 (0.2121)	Acc@1 98.438 (97.435)	Acc@5 100.000 (99.976)
Epoch: [165][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.2106 (0.2127)	Acc@1 97.266 (97.426)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.0141696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 150525 ; 151625 ; 0.9927452596867271
[INFO] Storing checkpoint...
  91.35
Max memory: 70.2216192
 21.117s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9161
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0672768
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.179 (0.179)	Data 0.259 (0.259)	Loss 0.2335 (0.2335)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.109 (0.111)	Data 0.000 (0.004)	Loss 0.1936 (0.2176)	Acc@1 98.047 (97.115)	Acc@5 100.000 (99.964)
Epoch: [166][128/196]	Time 0.106 (0.109)	Data 0.000 (0.002)	Loss 0.2517 (0.2170)	Acc@1 96.094 (97.196)	Acc@5 99.609 (99.976)
Epoch: [166][192/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.1766 (0.2165)	Acc@1 98.828 (97.251)	Acc@5 100.000 (99.974)
Max memory in training epoch: 44.9848832
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.144 (0.144)	Data 0.279 (0.279)	Loss 0.1826 (0.1826)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.104 (0.109)	Data 0.000 (0.004)	Loss 0.1924 (0.2123)	Acc@1 98.438 (97.290)	Acc@5 100.000 (99.970)
Epoch: [167][128/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.2356 (0.2116)	Acc@1 96.484 (97.390)	Acc@5 100.000 (99.976)
Epoch: [167][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.1987 (0.2134)	Acc@1 98.828 (97.304)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.0125312
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.173 (0.173)	Data 0.295 (0.295)	Loss 0.1987 (0.1987)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.108 (0.108)	Data 0.000 (0.005)	Loss 0.1960 (0.2094)	Acc@1 98.438 (97.554)	Acc@5 100.000 (99.952)
Epoch: [168][128/196]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.2281 (0.2103)	Acc@1 95.703 (97.496)	Acc@5 100.000 (99.967)
Epoch: [168][192/196]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.2029 (0.2111)	Acc@1 98.438 (97.440)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.0125312
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.159 (0.159)	Data 0.265 (0.265)	Loss 0.1796 (0.1796)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.103 (0.109)	Data 0.000 (0.004)	Loss 0.1895 (0.2098)	Acc@1 98.828 (97.494)	Acc@5 100.000 (99.952)
Epoch: [169][128/196]	Time 0.109 (0.108)	Data 0.000 (0.002)	Loss 0.2058 (0.2100)	Acc@1 98.047 (97.462)	Acc@5 100.000 (99.958)
Epoch: [169][192/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.2162 (0.2090)	Acc@1 97.656 (97.531)	Acc@5 100.000 (99.966)
Max memory in training epoch: 45.0125312
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.125 (0.125)	Data 0.308 (0.308)	Loss 0.1890 (0.1890)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.099 (0.108)	Data 0.000 (0.005)	Loss 0.2100 (0.2046)	Acc@1 97.266 (97.584)	Acc@5 100.000 (99.988)
Epoch: [170][128/196]	Time 0.103 (0.107)	Data 0.000 (0.003)	Loss 0.2214 (0.2057)	Acc@1 96.875 (97.632)	Acc@5 100.000 (99.988)
Epoch: [170][192/196]	Time 0.105 (0.107)	Data 0.000 (0.002)	Loss 0.2063 (0.2061)	Acc@1 97.656 (97.628)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.0125312
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 147313 ; 150525 ; 0.9786613519348946
[INFO] Storing checkpoint...
  91.61
Max memory: 70.1999104
 21.331s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7251
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.066048
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.172 (0.172)	Data 0.291 (0.291)	Loss 0.2140 (0.2140)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.112 (0.109)	Data 0.000 (0.005)	Loss 0.2408 (0.2150)	Acc@1 95.312 (97.055)	Acc@5 100.000 (99.994)
Epoch: [171][128/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.2102 (0.2154)	Acc@1 97.656 (97.096)	Acc@5 100.000 (99.985)
Epoch: [171][192/196]	Time 0.104 (0.109)	Data 0.000 (0.002)	Loss 0.2333 (0.2155)	Acc@1 97.266 (97.110)	Acc@5 100.000 (99.984)
Max memory in training epoch: 44.9693184
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.149 (0.149)	Data 0.278 (0.278)	Loss 0.2521 (0.2521)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.104 (0.110)	Data 0.000 (0.004)	Loss 0.1774 (0.2125)	Acc@1 98.828 (97.266)	Acc@5 100.000 (99.970)
Epoch: [172][128/196]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.2037 (0.2121)	Acc@1 97.656 (97.247)	Acc@5 100.000 (99.970)
Epoch: [172][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.1977 (0.2125)	Acc@1 98.047 (97.211)	Acc@5 100.000 (99.970)
Max memory in training epoch: 45.007616
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.146 (0.146)	Data 0.291 (0.291)	Loss 0.1905 (0.1905)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.101 (0.107)	Data 0.000 (0.005)	Loss 0.2548 (0.2139)	Acc@1 95.312 (97.212)	Acc@5 100.000 (99.958)
Epoch: [173][128/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2083 (0.2119)	Acc@1 96.875 (97.284)	Acc@5 100.000 (99.970)
Epoch: [173][192/196]	Time 0.102 (0.107)	Data 0.000 (0.002)	Loss 0.2218 (0.2114)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.974)
Max memory in training epoch: 45.007616
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.145 (0.145)	Data 0.295 (0.295)	Loss 0.2425 (0.2425)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.103 (0.108)	Data 0.000 (0.005)	Loss 0.1879 (0.2068)	Acc@1 97.656 (97.422)	Acc@5 100.000 (99.982)
Epoch: [174][128/196]	Time 0.101 (0.107)	Data 0.000 (0.002)	Loss 0.2267 (0.2061)	Acc@1 96.875 (97.544)	Acc@5 100.000 (99.985)
Epoch: [174][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.1839 (0.2069)	Acc@1 98.828 (97.486)	Acc@5 100.000 (99.986)
Max memory in training epoch: 45.007616
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.130 (0.130)	Data 0.289 (0.289)	Loss 0.2253 (0.2253)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.115 (0.108)	Data 0.000 (0.005)	Loss 0.1776 (0.2015)	Acc@1 98.828 (97.662)	Acc@5 100.000 (99.988)
Epoch: [175][128/196]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.2315 (0.2047)	Acc@1 96.484 (97.523)	Acc@5 100.000 (99.994)
Epoch: [175][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.1917 (0.2060)	Acc@1 98.828 (97.482)	Acc@5 100.000 (99.988)
Max memory in training epoch: 45.007616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 138732 ; 147313 ; 0.941749879508258
[INFO] Storing checkpoint...
  91.32
Max memory: 69.9686912
 21.458s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8127
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.0625664
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.194 (0.194)	Data 0.267 (0.267)	Loss 0.2931 (0.2931)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.099 (0.109)	Data 0.000 (0.004)	Loss 0.2364 (0.2451)	Acc@1 96.875 (95.775)	Acc@5 100.000 (99.970)
Epoch: [176][128/196]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.2673 (0.2411)	Acc@1 95.312 (95.879)	Acc@5 100.000 (99.961)
Epoch: [176][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2567 (0.2387)	Acc@1 93.750 (95.932)	Acc@5 100.000 (99.960)
Max memory in training epoch: 44.6463488
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.134 (0.134)	Data 0.270 (0.270)	Loss 0.2242 (0.2242)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.104 (0.106)	Data 0.000 (0.004)	Loss 0.2207 (0.2257)	Acc@1 97.266 (96.460)	Acc@5 100.000 (99.958)
Epoch: [177][128/196]	Time 0.112 (0.108)	Data 0.000 (0.002)	Loss 0.2116 (0.2253)	Acc@1 95.703 (96.430)	Acc@5 100.000 (99.967)
Epoch: [177][192/196]	Time 0.111 (0.108)	Data 0.000 (0.002)	Loss 0.2087 (0.2244)	Acc@1 97.656 (96.484)	Acc@5 100.000 (99.968)
Max memory in training epoch: 44.626688
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.154 (0.154)	Data 0.266 (0.266)	Loss 0.2088 (0.2088)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.107 (0.110)	Data 0.000 (0.004)	Loss 0.2547 (0.2203)	Acc@1 93.750 (96.605)	Acc@5 100.000 (99.982)
Epoch: [178][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2122 (0.2196)	Acc@1 96.094 (96.736)	Acc@5 100.000 (99.961)
Epoch: [178][192/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2019 (0.2198)	Acc@1 96.875 (96.699)	Acc@5 100.000 (99.964)
Max memory in training epoch: 44.626688
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.153 (0.153)	Data 0.271 (0.271)	Loss 0.2215 (0.2215)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.107 (0.110)	Data 0.000 (0.004)	Loss 0.1971 (0.2163)	Acc@1 96.875 (96.749)	Acc@5 100.000 (99.958)
Epoch: [179][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.1622 (0.2161)	Acc@1 99.609 (96.699)	Acc@5 100.000 (99.961)
Epoch: [179][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.2277 (0.2187)	Acc@1 96.484 (96.622)	Acc@5 100.000 (99.955)
Max memory in training epoch: 44.626688
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.149 (0.149)	Data 0.265 (0.265)	Loss 0.2414 (0.2414)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.107 (0.110)	Data 0.000 (0.004)	Loss 0.2444 (0.2171)	Acc@1 94.141 (96.785)	Acc@5 100.000 (99.976)
Epoch: [180][128/196]	Time 0.100 (0.108)	Data 0.000 (0.002)	Loss 0.2219 (0.2177)	Acc@1 96.484 (96.745)	Acc@5 100.000 (99.973)
Epoch: [180][192/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.2357 (0.2167)	Acc@1 96.484 (96.810)	Acc@5 100.000 (99.972)
Max memory in training epoch: 44.626688
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(13, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(31, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(22, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(31, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(11, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(31, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(31, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(31, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(60, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(60, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(1, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(60, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(19, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): AdaptiveAvgPool2d(output_size=(1, 1))
    (55): Linear(in_features=60, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  90.97
Max memory: 69.4339584
 21.450s  6644.43user 803.45system 1:17:46elapsed 159%CPU (0avgtext+0avgdata 2588608maxresident)k
0inputs+85624outputs (0major+65646208minor)pagefaults 0swaps
Thres 0.1 2
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4707
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.192 (0.192)	Data 0.262 (0.262)	Loss 3.3121 (3.3121)	Acc@1 7.812 (7.812)	Acc@5 44.531 (44.531)
Epoch: [1][64/196]	Time 0.123 (0.130)	Data 0.000 (0.004)	Loss 2.4742 (2.6892)	Acc@1 28.906 (24.273)	Acc@5 83.594 (76.659)
Epoch: [1][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 2.2320 (2.5061)	Acc@1 35.156 (29.881)	Acc@5 87.891 (82.552)
Epoch: [1][192/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 2.0142 (2.3716)	Acc@1 46.484 (34.751)	Acc@5 92.188 (85.484)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.176 (0.176)	Data 0.289 (0.289)	Loss 1.9976 (1.9976)	Acc@1 43.750 (43.750)	Acc@5 93.750 (93.750)
Epoch: [2][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 1.9618 (1.9535)	Acc@1 50.781 (49.105)	Acc@5 93.750 (93.552)
Epoch: [2][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 1.6612 (1.8719)	Acc@1 62.109 (52.114)	Acc@5 94.141 (94.180)
Epoch: [2][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 1.7522 (1.8045)	Acc@1 51.562 (54.432)	Acc@5 95.312 (94.728)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.155 (0.155)	Data 0.306 (0.306)	Loss 1.6440 (1.6440)	Acc@1 59.375 (59.375)	Acc@5 95.703 (95.703)
Epoch: [3][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 1.6230 (1.5655)	Acc@1 61.719 (62.037)	Acc@5 97.266 (96.412)
Epoch: [3][128/196]	Time 0.132 (0.129)	Data 0.000 (0.003)	Loss 1.4223 (1.5107)	Acc@1 69.922 (63.754)	Acc@5 97.266 (96.799)
Epoch: [3][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 1.3805 (1.4704)	Acc@1 67.578 (64.955)	Acc@5 96.875 (97.033)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.178 (0.178)	Data 0.260 (0.260)	Loss 1.4273 (1.4273)	Acc@1 66.406 (66.406)	Acc@5 96.875 (96.875)
Epoch: [4][64/196]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 1.2247 (1.3025)	Acc@1 73.828 (70.264)	Acc@5 99.609 (97.921)
Epoch: [4][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 1.1414 (1.2672)	Acc@1 73.438 (71.185)	Acc@5 98.438 (98.038)
Epoch: [4][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 1.1920 (1.2455)	Acc@1 71.875 (71.865)	Acc@5 95.312 (98.067)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.174 (0.174)	Data 0.257 (0.257)	Loss 1.1143 (1.1143)	Acc@1 76.172 (76.172)	Acc@5 97.266 (97.266)
Epoch: [5][64/196]	Time 0.123 (0.130)	Data 0.000 (0.004)	Loss 1.0696 (1.1394)	Acc@1 78.516 (75.150)	Acc@5 98.828 (98.209)
Epoch: [5][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 1.1068 (1.1158)	Acc@1 74.609 (75.484)	Acc@5 98.047 (98.386)
Epoch: [5][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.0309 (1.0966)	Acc@1 78.906 (75.949)	Acc@5 99.219 (98.480)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 355538 ; 487386 ; 0.7294793038782402
[INFO] Storing checkpoint...
  70.32
Max memory: 103.3835008
 25.651s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 105
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1499648
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.211 (0.211)	Data 0.258 (0.258)	Loss 0.9946 (0.9946)	Acc@1 76.562 (76.562)	Acc@5 98.828 (98.828)
Epoch: [6][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 1.0491 (1.0034)	Acc@1 75.391 (76.977)	Acc@5 99.609 (98.696)
Epoch: [6][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 1.0605 (0.9943)	Acc@1 78.906 (77.253)	Acc@5 98.047 (98.749)
Epoch: [6][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8571 (0.9781)	Acc@1 82.422 (77.621)	Acc@5 99.219 (98.778)
Max memory in training epoch: 64.9488896
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.160 (0.160)	Data 0.302 (0.302)	Loss 0.9025 (0.9025)	Acc@1 80.469 (80.469)	Acc@5 98.047 (98.047)
Epoch: [7][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.9019 (0.9249)	Acc@1 82.812 (78.660)	Acc@5 98.438 (98.786)
Epoch: [7][128/196]	Time 0.129 (0.131)	Data 0.000 (0.003)	Loss 0.9841 (0.9305)	Acc@1 77.734 (78.561)	Acc@5 97.656 (98.828)
Epoch: [7][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8009 (0.9257)	Acc@1 83.984 (78.750)	Acc@5 99.219 (98.782)
Max memory in training epoch: 65.0537472
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.154 (0.154)	Data 0.308 (0.308)	Loss 0.9941 (0.9941)	Acc@1 75.391 (75.391)	Acc@5 98.047 (98.047)
Epoch: [8][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.8755 (0.8823)	Acc@1 80.859 (80.198)	Acc@5 99.219 (98.990)
Epoch: [8][128/196]	Time 0.136 (0.131)	Data 0.000 (0.003)	Loss 0.9000 (0.8841)	Acc@1 79.297 (79.975)	Acc@5 99.219 (98.949)
Epoch: [8][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 1.0196 (0.8775)	Acc@1 73.438 (80.147)	Acc@5 98.828 (98.915)
Max memory in training epoch: 65.0537472
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.171 (0.171)	Data 0.263 (0.263)	Loss 0.8304 (0.8304)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [9][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.8531 (0.8579)	Acc@1 80.859 (80.463)	Acc@5 98.828 (98.960)
Epoch: [9][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.8497 (0.8551)	Acc@1 81.641 (80.753)	Acc@5 98.438 (99.019)
Epoch: [9][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8214 (0.8512)	Acc@1 81.641 (80.776)	Acc@5 99.219 (98.990)
Max memory in training epoch: 65.0537472
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.181 (0.181)	Data 0.284 (0.284)	Loss 0.8194 (0.8194)	Acc@1 81.641 (81.641)	Acc@5 100.000 (100.000)
Epoch: [10][64/196]	Time 0.143 (0.132)	Data 0.000 (0.005)	Loss 0.7514 (0.8261)	Acc@1 84.766 (81.214)	Acc@5 99.609 (99.056)
Epoch: [10][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7760 (0.8270)	Acc@1 83.203 (81.150)	Acc@5 98.828 (99.052)
Epoch: [10][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8381 (0.8256)	Acc@1 79.688 (81.404)	Acc@5 98.828 (99.085)
Max memory in training epoch: 65.0537472
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 263892 ; 355538 ; 0.7422328977493263
[INFO] Storing checkpoint...
  72.62
Max memory: 100.9183232
 26.146s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9306
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.1136128
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.208 (0.208)	Data 0.262 (0.262)	Loss 1.0249 (1.0249)	Acc@1 74.609 (74.609)	Acc@5 98.438 (98.438)
Epoch: [11][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.8606 (0.8264)	Acc@1 79.688 (80.541)	Acc@5 97.656 (98.834)
Epoch: [11][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.8156 (0.8212)	Acc@1 80.469 (80.711)	Acc@5 99.219 (98.867)
Epoch: [11][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7197 (0.8184)	Acc@1 81.250 (80.782)	Acc@5 99.609 (98.887)
Max memory in training epoch: 62.1951488
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.154 (0.154)	Data 0.271 (0.271)	Loss 0.8370 (0.8370)	Acc@1 78.906 (78.906)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.8652 (0.7906)	Acc@1 77.734 (81.514)	Acc@5 98.438 (99.020)
Epoch: [12][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8597 (0.8020)	Acc@1 80.469 (81.174)	Acc@5 98.828 (99.019)
Epoch: [12][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.8067 (0.7976)	Acc@1 82.031 (81.321)	Acc@5 99.219 (99.087)
Max memory in training epoch: 62.0050944
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.203 (0.203)	Data 0.271 (0.271)	Loss 0.7820 (0.7820)	Acc@1 81.641 (81.641)	Acc@5 100.000 (100.000)
Epoch: [13][64/196]	Time 0.135 (0.127)	Data 0.000 (0.004)	Loss 0.7924 (0.7736)	Acc@1 81.250 (82.584)	Acc@5 99.609 (99.195)
Epoch: [13][128/196]	Time 0.136 (0.127)	Data 0.000 (0.002)	Loss 0.7526 (0.7714)	Acc@1 82.422 (82.355)	Acc@5 100.000 (99.143)
Epoch: [13][192/196]	Time 0.117 (0.126)	Data 0.000 (0.002)	Loss 0.7956 (0.7751)	Acc@1 82.031 (82.240)	Acc@5 98.828 (99.122)
Max memory in training epoch: 62.0050944
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.149 (0.149)	Data 0.293 (0.293)	Loss 0.7646 (0.7646)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [14][64/196]	Time 0.134 (0.128)	Data 0.000 (0.005)	Loss 0.9536 (0.7817)	Acc@1 77.734 (82.001)	Acc@5 98.828 (99.177)
Epoch: [14][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7419 (0.7762)	Acc@1 83.203 (82.228)	Acc@5 99.219 (99.134)
Epoch: [14][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.8426 (0.7764)	Acc@1 78.516 (82.215)	Acc@5 99.219 (99.116)
Max memory in training epoch: 62.0050944
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.156 (0.156)	Data 0.298 (0.298)	Loss 0.7859 (0.7859)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.7952 (0.7622)	Acc@1 80.078 (82.506)	Acc@5 99.609 (99.087)
Epoch: [15][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7711 (0.7656)	Acc@1 82.422 (82.476)	Acc@5 98.438 (99.167)
Epoch: [15][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6984 (0.7700)	Acc@1 87.109 (82.420)	Acc@5 100.000 (99.150)
Max memory in training epoch: 62.0050944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 253048 ; 263892 ; 0.9589074318281722
[INFO] Storing checkpoint...
  78.08
Max memory: 96.6835712
 25.236s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 657
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1094656
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.205 (0.205)	Data 0.276 (0.276)	Loss 0.6705 (0.6705)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.8885 (0.7269)	Acc@1 78.906 (83.774)	Acc@5 99.219 (99.159)
Epoch: [16][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8355 (0.7429)	Acc@1 80.078 (83.382)	Acc@5 99.219 (99.122)
Epoch: [16][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.8049 (0.7500)	Acc@1 79.688 (83.189)	Acc@5 98.438 (99.146)
Max memory in training epoch: 59.440384
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.177 (0.177)	Data 0.303 (0.303)	Loss 0.7524 (0.7524)	Acc@1 83.594 (83.594)	Acc@5 97.656 (97.656)
Epoch: [17][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.7364 (0.7599)	Acc@1 84.766 (83.059)	Acc@5 98.828 (99.069)
Epoch: [17][128/196]	Time 0.124 (0.128)	Data 0.000 (0.003)	Loss 0.6983 (0.7569)	Acc@1 85.156 (82.852)	Acc@5 98.828 (99.113)
Epoch: [17][192/196]	Time 0.132 (0.127)	Data 0.000 (0.002)	Loss 0.7267 (0.7542)	Acc@1 82.812 (82.934)	Acc@5 99.219 (99.138)
Max memory in training epoch: 59.655424
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.150 (0.150)	Data 0.264 (0.264)	Loss 0.6950 (0.6950)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.6353 (0.7653)	Acc@1 86.719 (82.698)	Acc@5 99.609 (99.171)
Epoch: [18][128/196]	Time 0.119 (0.129)	Data 0.000 (0.002)	Loss 0.7141 (0.7554)	Acc@1 82.422 (82.849)	Acc@5 99.609 (99.179)
Epoch: [18][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7175 (0.7501)	Acc@1 82.422 (83.021)	Acc@5 100.000 (99.199)
Max memory in training epoch: 59.655424
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.158 (0.158)	Data 0.262 (0.262)	Loss 0.6606 (0.6606)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.6770 (0.7380)	Acc@1 85.938 (83.492)	Acc@5 99.219 (99.297)
Epoch: [19][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6864 (0.7325)	Acc@1 84.766 (83.679)	Acc@5 99.609 (99.328)
Epoch: [19][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.8321 (0.7405)	Acc@1 81.641 (83.557)	Acc@5 99.219 (99.288)
Max memory in training epoch: 59.655424
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.160 (0.160)	Data 0.283 (0.283)	Loss 0.7312 (0.7312)	Acc@1 83.203 (83.203)	Acc@5 97.656 (97.656)
Epoch: [20][64/196]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.6939 (0.7245)	Acc@1 84.375 (84.081)	Acc@5 99.609 (99.321)
Epoch: [20][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7670 (0.7301)	Acc@1 81.641 (83.824)	Acc@5 99.609 (99.273)
Epoch: [20][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.8702 (0.7356)	Acc@1 80.078 (83.608)	Acc@5 98.438 (99.239)
Max memory in training epoch: 59.655424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 242792 ; 253048 ; 0.9594701400524802
[INFO] Storing checkpoint...
  70.56
Max memory: 92.2023936
 25.249s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2975
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1053696
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.203 (0.203)	Data 0.304 (0.304)	Loss 0.6969 (0.6969)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.7893 (0.7132)	Acc@1 84.375 (84.351)	Acc@5 98.438 (99.285)
Epoch: [21][128/196]	Time 0.134 (0.128)	Data 0.000 (0.003)	Loss 0.6585 (0.7303)	Acc@1 83.203 (83.645)	Acc@5 99.609 (99.270)
Epoch: [21][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7376 (0.7293)	Acc@1 83.203 (83.648)	Acc@5 99.609 (99.286)
Max memory in training epoch: 58.5736704
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.155 (0.155)	Data 0.306 (0.306)	Loss 0.7496 (0.7496)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [22][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.6324 (0.7380)	Acc@1 87.500 (83.612)	Acc@5 99.609 (99.327)
Epoch: [22][128/196]	Time 0.121 (0.125)	Data 0.000 (0.003)	Loss 0.8226 (0.7334)	Acc@1 79.688 (83.579)	Acc@5 97.656 (99.267)
Epoch: [22][192/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.8342 (0.7325)	Acc@1 78.906 (83.640)	Acc@5 99.219 (99.267)
Max memory in training epoch: 58.8919296
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.153 (0.153)	Data 0.267 (0.267)	Loss 0.7263 (0.7263)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.124 (0.128)	Data 0.000 (0.004)	Loss 0.8156 (0.7276)	Acc@1 81.250 (83.774)	Acc@5 99.609 (99.285)
Epoch: [23][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6774 (0.7296)	Acc@1 83.594 (83.600)	Acc@5 100.000 (99.322)
Epoch: [23][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6624 (0.7301)	Acc@1 85.547 (83.553)	Acc@5 99.609 (99.322)
Max memory in training epoch: 58.8919296
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.165 (0.165)	Data 0.294 (0.294)	Loss 0.7040 (0.7040)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.6762 (0.7182)	Acc@1 87.109 (84.381)	Acc@5 99.609 (99.303)
Epoch: [24][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7007 (0.7165)	Acc@1 84.375 (84.393)	Acc@5 99.219 (99.264)
Epoch: [24][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6496 (0.7201)	Acc@1 84.766 (84.233)	Acc@5 100.000 (99.231)
Max memory in training epoch: 58.8919296
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.184 (0.184)	Data 0.268 (0.268)	Loss 0.8978 (0.8978)	Acc@1 75.391 (75.391)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.7539 (0.7229)	Acc@1 82.812 (83.978)	Acc@5 100.000 (99.303)
Epoch: [25][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6526 (0.7182)	Acc@1 89.453 (84.172)	Acc@5 99.609 (99.334)
Epoch: [25][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7177 (0.7238)	Acc@1 82.812 (83.982)	Acc@5 99.219 (99.328)
Max memory in training epoch: 58.8919296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 237008 ; 242792 ; 0.9761771392797127
[INFO] Storing checkpoint...
  79.23
Max memory: 91.9443456
 25.128s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2169
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.103168
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.193 (0.193)	Data 0.272 (0.272)	Loss 0.7659 (0.7659)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.5981 (0.6868)	Acc@1 88.672 (85.042)	Acc@5 100.000 (99.441)
Epoch: [26][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7489 (0.7046)	Acc@1 82.422 (84.660)	Acc@5 99.609 (99.346)
Epoch: [26][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7465 (0.7083)	Acc@1 85.156 (84.523)	Acc@5 99.219 (99.300)
Max memory in training epoch: 57.2840448
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.188 (0.188)	Data 0.265 (0.265)	Loss 0.6908 (0.6908)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.7359 (0.6912)	Acc@1 83.594 (84.922)	Acc@5 99.609 (99.399)
Epoch: [27][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6933 (0.7068)	Acc@1 85.938 (84.605)	Acc@5 98.047 (99.322)
Epoch: [27][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7228 (0.7098)	Acc@1 82.812 (84.399)	Acc@5 99.609 (99.316)
Max memory in training epoch: 57.3889024
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.6775 (0.6775)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [28][64/196]	Time 0.119 (0.127)	Data 0.000 (0.005)	Loss 0.7213 (0.6965)	Acc@1 84.375 (84.904)	Acc@5 98.828 (99.297)
Epoch: [28][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7554 (0.7108)	Acc@1 81.250 (84.354)	Acc@5 99.609 (99.282)
Epoch: [28][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7640 (0.7090)	Acc@1 82.422 (84.505)	Acc@5 100.000 (99.310)
Max memory in training epoch: 57.3889024
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.182 (0.182)	Data 0.271 (0.271)	Loss 0.6291 (0.6291)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.139 (0.127)	Data 0.000 (0.004)	Loss 0.7343 (0.7139)	Acc@1 84.766 (84.321)	Acc@5 98.828 (99.381)
Epoch: [29][128/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.6683 (0.7145)	Acc@1 87.109 (84.311)	Acc@5 98.828 (99.361)
Epoch: [29][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.8048 (0.7129)	Acc@1 82.031 (84.357)	Acc@5 99.219 (99.316)
Max memory in training epoch: 57.3889024
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.173 (0.173)	Data 0.305 (0.305)	Loss 0.7348 (0.7348)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [30][64/196]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.6736 (0.7013)	Acc@1 84.766 (84.976)	Acc@5 99.219 (99.261)
Epoch: [30][128/196]	Time 0.131 (0.126)	Data 0.000 (0.003)	Loss 0.7292 (0.7002)	Acc@1 85.938 (84.917)	Acc@5 99.219 (99.346)
Epoch: [30][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.7279 (0.7007)	Acc@1 82.422 (84.877)	Acc@5 99.219 (99.334)
Max memory in training epoch: 57.3889024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 232962 ; 237008 ; 0.9829288462836697
[INFO] Storing checkpoint...
  78.92
Max memory: 89.7109504
 24.892s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3857
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1014272
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.196 (0.196)	Data 0.277 (0.277)	Loss 0.7501 (0.7501)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [31][64/196]	Time 0.123 (0.130)	Data 0.000 (0.004)	Loss 0.7377 (0.6713)	Acc@1 83.203 (85.619)	Acc@5 98.828 (99.417)
Epoch: [31][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7391 (0.6855)	Acc@1 82.422 (85.087)	Acc@5 99.219 (99.391)
Epoch: [31][192/196]	Time 0.117 (0.127)	Data 0.000 (0.002)	Loss 0.6687 (0.6993)	Acc@1 84.766 (84.670)	Acc@5 99.609 (99.352)
Max memory in training epoch: 56.4447744
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.170 (0.170)	Data 0.273 (0.273)	Loss 0.6004 (0.6004)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.7237 (0.6867)	Acc@1 84.375 (85.240)	Acc@5 98.828 (99.327)
Epoch: [32][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.8533 (0.6938)	Acc@1 79.297 (84.990)	Acc@5 99.219 (99.337)
Epoch: [32][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6869 (0.6970)	Acc@1 86.328 (84.851)	Acc@5 99.219 (99.318)
Max memory in training epoch: 56.3137024
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.163 (0.163)	Data 0.307 (0.307)	Loss 0.7076 (0.7076)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [33][64/196]	Time 0.118 (0.128)	Data 0.000 (0.005)	Loss 0.7441 (0.7011)	Acc@1 82.422 (84.597)	Acc@5 100.000 (99.339)
Epoch: [33][128/196]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.7261 (0.6969)	Acc@1 82.031 (84.929)	Acc@5 98.828 (99.304)
Epoch: [33][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6522 (0.6963)	Acc@1 86.328 (84.905)	Acc@5 99.219 (99.277)
Max memory in training epoch: 56.3137024
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.178 (0.178)	Data 0.295 (0.295)	Loss 0.6300 (0.6300)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.7413 (0.6881)	Acc@1 84.766 (85.355)	Acc@5 99.219 (99.393)
Epoch: [34][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.8140 (0.6931)	Acc@1 81.250 (85.011)	Acc@5 99.219 (99.370)
Epoch: [34][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.7188 (0.6965)	Acc@1 83.984 (84.834)	Acc@5 100.000 (99.397)
Max memory in training epoch: 56.3137024
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.167 (0.167)	Data 0.376 (0.376)	Loss 0.6682 (0.6682)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.126 (0.126)	Data 0.000 (0.006)	Loss 0.7413 (0.6970)	Acc@1 83.984 (84.790)	Acc@5 99.219 (99.363)
Epoch: [35][128/196]	Time 0.128 (0.126)	Data 0.000 (0.003)	Loss 0.6820 (0.6973)	Acc@1 84.375 (84.829)	Acc@5 99.609 (99.343)
Epoch: [35][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7140 (0.6963)	Acc@1 82.422 (84.873)	Acc@5 100.000 (99.364)
Max memory in training epoch: 56.3137024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 229640 ; 232962 ; 0.9857401636318369
[INFO] Storing checkpoint...
  68.36
Max memory: 87.9299072
 25.149s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5210
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1001472
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.187 (0.187)	Data 0.255 (0.255)	Loss 0.6150 (0.6150)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.7440 (0.6624)	Acc@1 83.984 (86.004)	Acc@5 99.219 (99.411)
Epoch: [36][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7179 (0.6787)	Acc@1 84.375 (85.380)	Acc@5 99.609 (99.434)
Epoch: [36][192/196]	Time 0.127 (0.126)	Data 0.000 (0.001)	Loss 0.6729 (0.6760)	Acc@1 85.156 (85.488)	Acc@5 99.609 (99.409)
Max memory in training epoch: 56.2561536
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.159 (0.159)	Data 0.305 (0.305)	Loss 0.6945 (0.6945)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.130 (0.127)	Data 0.000 (0.005)	Loss 0.6691 (0.6859)	Acc@1 83.594 (85.331)	Acc@5 99.609 (99.315)
Epoch: [37][128/196]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.6922 (0.6850)	Acc@1 84.375 (85.271)	Acc@5 99.219 (99.340)
Epoch: [37][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7253 (0.6881)	Acc@1 82.812 (85.183)	Acc@5 99.609 (99.336)
Max memory in training epoch: 56.2627072
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.176 (0.176)	Data 0.295 (0.295)	Loss 0.7903 (0.7903)	Acc@1 80.469 (80.469)	Acc@5 99.219 (99.219)
Epoch: [38][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.6942 (0.6799)	Acc@1 83.984 (85.174)	Acc@5 100.000 (99.453)
Epoch: [38][128/196]	Time 0.135 (0.126)	Data 0.000 (0.002)	Loss 0.6666 (0.6799)	Acc@1 85.156 (85.129)	Acc@5 99.219 (99.413)
Epoch: [38][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.7208 (0.6843)	Acc@1 84.375 (85.057)	Acc@5 99.609 (99.393)
Max memory in training epoch: 56.2627072
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.145 (0.145)	Data 0.346 (0.346)	Loss 0.6737 (0.6737)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.6803 (0.6790)	Acc@1 85.156 (85.415)	Acc@5 99.219 (99.399)
Epoch: [39][128/196]	Time 0.136 (0.125)	Data 0.000 (0.003)	Loss 0.6310 (0.6847)	Acc@1 87.891 (85.190)	Acc@5 99.609 (99.343)
Epoch: [39][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.7152 (0.6881)	Acc@1 86.328 (85.130)	Acc@5 98.828 (99.340)
Max memory in training epoch: 56.2627072
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.177 (0.177)	Data 0.291 (0.291)	Loss 0.6795 (0.6795)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [40][64/196]	Time 0.132 (0.125)	Data 0.000 (0.005)	Loss 0.6785 (0.6833)	Acc@1 84.766 (85.547)	Acc@5 99.219 (99.303)
Epoch: [40][128/196]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.7881 (0.6774)	Acc@1 82.422 (85.492)	Acc@5 99.219 (99.364)
Epoch: [40][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.6294 (0.6833)	Acc@1 87.109 (85.322)	Acc@5 100.000 (99.334)
Max memory in training epoch: 56.2627072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 228482 ; 229640 ; 0.9949573245079254
[INFO] Storing checkpoint...
  78.68
Max memory: 87.190016
 24.680s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6871
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.0997376
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.198 (0.198)	Data 0.258 (0.258)	Loss 0.7210 (0.7210)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [41][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.5964 (0.6447)	Acc@1 85.938 (86.472)	Acc@5 100.000 (99.513)
Epoch: [41][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6810 (0.6623)	Acc@1 86.328 (85.795)	Acc@5 99.609 (99.452)
Epoch: [41][192/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.7968 (0.6727)	Acc@1 80.469 (85.484)	Acc@5 99.219 (99.431)
Max memory in training epoch: 55.3632256
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.170 (0.170)	Data 0.267 (0.267)	Loss 0.6452 (0.6452)	Acc@1 86.719 (86.719)	Acc@5 98.828 (98.828)
Epoch: [42][64/196]	Time 0.119 (0.127)	Data 0.000 (0.004)	Loss 0.6426 (0.6812)	Acc@1 87.891 (85.457)	Acc@5 99.609 (99.435)
Epoch: [42][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.7363 (0.6784)	Acc@1 82.422 (85.504)	Acc@5 99.609 (99.400)
Epoch: [42][192/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.6386 (0.6781)	Acc@1 85.156 (85.413)	Acc@5 99.609 (99.413)
Max memory in training epoch: 55.7761024
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.167 (0.167)	Data 0.268 (0.268)	Loss 0.6644 (0.6644)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [43][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.6690 (0.6728)	Acc@1 86.328 (85.571)	Acc@5 99.219 (99.435)
Epoch: [43][128/196]	Time 0.117 (0.126)	Data 0.000 (0.002)	Loss 0.6602 (0.6835)	Acc@1 84.375 (85.199)	Acc@5 99.609 (99.425)
Epoch: [43][192/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.6590 (0.6841)	Acc@1 86.328 (85.207)	Acc@5 99.609 (99.395)
Max memory in training epoch: 55.7761024
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.159 (0.159)	Data 0.263 (0.263)	Loss 0.6166 (0.6166)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.120 (0.126)	Data 0.000 (0.004)	Loss 0.7188 (0.6692)	Acc@1 83.203 (85.619)	Acc@5 100.000 (99.447)
Epoch: [44][128/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.6245 (0.6728)	Acc@1 86.719 (85.405)	Acc@5 99.219 (99.452)
Epoch: [44][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.7651 (0.6793)	Acc@1 83.984 (85.316)	Acc@5 98.047 (99.415)
Max memory in training epoch: 55.7761024
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.160 (0.160)	Data 0.263 (0.263)	Loss 0.6424 (0.6424)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.124 (0.125)	Data 0.000 (0.004)	Loss 0.5710 (0.6603)	Acc@1 89.844 (85.841)	Acc@5 99.609 (99.435)
Epoch: [45][128/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.6255 (0.6655)	Acc@1 89.844 (85.950)	Acc@5 99.609 (99.400)
Epoch: [45][192/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.7159 (0.6698)	Acc@1 83.203 (85.691)	Acc@5 99.609 (99.381)
Max memory in training epoch: 55.7761024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 226746 ; 228482 ; 0.9924020272931785
[INFO] Storing checkpoint...
  81.79
Max memory: 86.1592576
 24.818s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9340
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.0990208
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.177 (0.177)	Data 0.269 (0.269)	Loss 0.6971 (0.6971)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.120 (0.129)	Data 0.000 (0.004)	Loss 0.7600 (0.6448)	Acc@1 83.203 (86.671)	Acc@5 99.219 (99.423)
Epoch: [46][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7695 (0.6595)	Acc@1 83.594 (86.146)	Acc@5 99.219 (99.406)
Epoch: [46][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.7075 (0.6643)	Acc@1 85.938 (86.027)	Acc@5 98.828 (99.395)
Max memory in training epoch: 55.137536
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.7408 (0.7408)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [47][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.6664 (0.6834)	Acc@1 85.938 (85.054)	Acc@5 100.000 (99.321)
Epoch: [47][128/196]	Time 0.114 (0.125)	Data 0.000 (0.002)	Loss 0.6609 (0.6747)	Acc@1 84.766 (85.429)	Acc@5 100.000 (99.373)
Epoch: [47][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.5938 (0.6765)	Acc@1 89.844 (85.504)	Acc@5 99.609 (99.377)
Max memory in training epoch: 55.3472512
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.168 (0.168)	Data 0.305 (0.305)	Loss 0.7435 (0.7435)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.7258 (0.6651)	Acc@1 84.766 (85.829)	Acc@5 98.828 (99.333)
Epoch: [48][128/196]	Time 0.117 (0.126)	Data 0.000 (0.003)	Loss 0.6938 (0.6684)	Acc@1 85.156 (85.674)	Acc@5 99.219 (99.328)
Epoch: [48][192/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.6977 (0.6715)	Acc@1 83.594 (85.579)	Acc@5 100.000 (99.379)
Max memory in training epoch: 55.3603584
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.175 (0.175)	Data 0.270 (0.270)	Loss 0.6847 (0.6847)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.127 (0.126)	Data 0.000 (0.004)	Loss 0.7433 (0.6699)	Acc@1 81.641 (85.673)	Acc@5 99.609 (99.477)
Epoch: [49][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.5495 (0.6702)	Acc@1 91.406 (85.750)	Acc@5 99.219 (99.403)
Epoch: [49][192/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.5964 (0.6749)	Acc@1 87.109 (85.480)	Acc@5 99.609 (99.381)
Max memory in training epoch: 55.3603584
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.194 (0.194)	Data 0.292 (0.292)	Loss 0.6508 (0.6508)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [50][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.5818 (0.6605)	Acc@1 87.500 (85.739)	Acc@5 99.219 (99.459)
Epoch: [50][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.6786 (0.6712)	Acc@1 83.984 (85.362)	Acc@5 99.609 (99.446)
Epoch: [50][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6703 (0.6736)	Acc@1 84.375 (85.480)	Acc@5 100.000 (99.423)
Max memory in training epoch: 55.3603584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 225590 ; 226746 ; 0.9949017843754686
[INFO] Storing checkpoint...
  79.16
Max memory: 85.5455744
 25.122s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5932
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.0986112
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.187 (0.187)	Data 0.261 (0.261)	Loss 0.6071 (0.6071)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.120 (0.125)	Data 0.000 (0.004)	Loss 0.8134 (0.6434)	Acc@1 79.297 (86.484)	Acc@5 99.219 (99.459)
Epoch: [51][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6318 (0.6584)	Acc@1 86.719 (85.871)	Acc@5 100.000 (99.464)
Epoch: [51][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6222 (0.6616)	Acc@1 86.328 (85.765)	Acc@5 99.609 (99.415)
Max memory in training epoch: 55.1358976
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.179 (0.179)	Data 0.290 (0.290)	Loss 0.6082 (0.6082)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.118 (0.124)	Data 0.000 (0.005)	Loss 0.6329 (0.6750)	Acc@1 87.891 (85.385)	Acc@5 99.219 (99.387)
Epoch: [52][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.7402 (0.6753)	Acc@1 82.812 (85.383)	Acc@5 98.828 (99.358)
Epoch: [52][192/196]	Time 0.115 (0.124)	Data 0.000 (0.002)	Loss 0.7877 (0.6768)	Acc@1 81.641 (85.383)	Acc@5 100.000 (99.371)
Max memory in training epoch: 55.3652736
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.163 (0.163)	Data 0.300 (0.300)	Loss 0.7227 (0.7227)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [53][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.6719 (0.6766)	Acc@1 87.109 (85.451)	Acc@5 98.828 (99.399)
Epoch: [53][128/196]	Time 0.126 (0.124)	Data 0.000 (0.003)	Loss 0.6896 (0.6750)	Acc@1 85.938 (85.368)	Acc@5 98.438 (99.422)
Epoch: [53][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.7295 (0.6728)	Acc@1 83.984 (85.429)	Acc@5 100.000 (99.435)
Max memory in training epoch: 55.3652736
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.150 (0.150)	Data 0.306 (0.306)	Loss 0.6262 (0.6262)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.6160 (0.6535)	Acc@1 88.281 (86.220)	Acc@5 99.219 (99.423)
Epoch: [54][128/196]	Time 0.121 (0.124)	Data 0.000 (0.003)	Loss 0.7147 (0.6629)	Acc@1 85.156 (85.835)	Acc@5 100.000 (99.428)
Epoch: [54][192/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.6588 (0.6658)	Acc@1 85.938 (85.693)	Acc@5 99.219 (99.419)
Max memory in training epoch: 55.3652736
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.164 (0.164)	Data 0.307 (0.307)	Loss 0.5600 (0.5600)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [55][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.7453 (0.6717)	Acc@1 82.031 (85.511)	Acc@5 99.609 (99.459)
Epoch: [55][128/196]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.7255 (0.6638)	Acc@1 85.156 (85.756)	Acc@5 99.219 (99.437)
Epoch: [55][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.6499 (0.6705)	Acc@1 85.156 (85.579)	Acc@5 99.219 (99.439)
Max memory in training epoch: 55.3652736
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 223566 ; 225590 ; 0.9910279710980097
[INFO] Storing checkpoint...
  80.37
Max memory: 85.4532096
 24.626s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9329
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.097792
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.205 (0.205)	Data 0.261 (0.261)	Loss 0.6282 (0.6282)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [56][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.6845 (0.6388)	Acc@1 82.812 (86.436)	Acc@5 99.219 (99.489)
Epoch: [56][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.7018 (0.6520)	Acc@1 87.109 (86.119)	Acc@5 99.219 (99.458)
Epoch: [56][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6102 (0.6587)	Acc@1 87.891 (85.877)	Acc@5 100.000 (99.468)
Max memory in training epoch: 54.7328512
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.179 (0.179)	Data 0.297 (0.297)	Loss 0.6229 (0.6229)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.6783 (0.6660)	Acc@1 83.594 (85.451)	Acc@5 98.828 (99.435)
Epoch: [57][128/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6036 (0.6657)	Acc@1 86.719 (85.562)	Acc@5 99.609 (99.410)
Epoch: [57][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.7028 (0.6726)	Acc@1 85.156 (85.371)	Acc@5 100.000 (99.411)
Max memory in training epoch: 54.9229056
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.181 (0.181)	Data 0.320 (0.320)	Loss 0.6646 (0.6646)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [58][64/196]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 0.6153 (0.6647)	Acc@1 88.281 (85.913)	Acc@5 99.219 (99.351)
Epoch: [58][128/196]	Time 0.130 (0.128)	Data 0.000 (0.003)	Loss 0.6379 (0.6628)	Acc@1 87.109 (85.886)	Acc@5 99.609 (99.410)
Epoch: [58][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6124 (0.6618)	Acc@1 88.672 (85.978)	Acc@5 99.609 (99.427)
Max memory in training epoch: 54.9229056
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.174 (0.174)	Data 0.280 (0.280)	Loss 0.6541 (0.6541)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.6019 (0.6639)	Acc@1 87.109 (85.859)	Acc@5 99.609 (99.345)
Epoch: [59][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7028 (0.6633)	Acc@1 84.375 (85.816)	Acc@5 99.219 (99.425)
Epoch: [59][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.6381 (0.6644)	Acc@1 85.938 (85.733)	Acc@5 100.000 (99.421)
Max memory in training epoch: 54.9229056
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.186 (0.186)	Data 0.265 (0.265)	Loss 0.6193 (0.6193)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [60][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.5781 (0.6697)	Acc@1 89.844 (85.481)	Acc@5 99.609 (99.429)
Epoch: [60][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7024 (0.6791)	Acc@1 83.984 (85.171)	Acc@5 99.609 (99.413)
Epoch: [60][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7637 (0.6731)	Acc@1 83.203 (85.399)	Acc@5 99.219 (99.407)
Max memory in training epoch: 54.9229056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 222410 ; 223566 ; 0.9948292674199118
[INFO] Storing checkpoint...
  67.41
Max memory: 84.7097856
 25.177s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7384
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.0973824
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.212 (0.212)	Data 0.263 (0.263)	Loss 0.6972 (0.6972)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.129 (0.126)	Data 0.000 (0.004)	Loss 0.6296 (0.6400)	Acc@1 85.938 (86.719)	Acc@5 99.219 (99.429)
Epoch: [61][128/196]	Time 0.139 (0.125)	Data 0.000 (0.002)	Loss 0.6737 (0.6521)	Acc@1 86.328 (86.198)	Acc@5 98.828 (99.416)
Epoch: [61][192/196]	Time 0.127 (0.125)	Data 0.000 (0.002)	Loss 0.6259 (0.6586)	Acc@1 86.719 (85.960)	Acc@5 99.219 (99.419)
Max memory in training epoch: 54.482176
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.172 (0.172)	Data 0.291 (0.291)	Loss 0.5610 (0.5610)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.126 (0.125)	Data 0.000 (0.005)	Loss 0.7011 (0.6576)	Acc@1 83.984 (85.763)	Acc@5 98.828 (99.495)
Epoch: [62][128/196]	Time 0.161 (0.125)	Data 0.000 (0.002)	Loss 0.6772 (0.6611)	Acc@1 84.766 (85.816)	Acc@5 99.609 (99.464)
Epoch: [62][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6972 (0.6604)	Acc@1 86.328 (85.895)	Acc@5 98.438 (99.431)
Max memory in training epoch: 54.8622848
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.184 (0.184)	Data 0.256 (0.256)	Loss 0.5573 (0.5573)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.152 (0.127)	Data 0.000 (0.004)	Loss 0.6285 (0.6583)	Acc@1 87.109 (86.148)	Acc@5 100.000 (99.399)
Epoch: [63][128/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.6591 (0.6625)	Acc@1 86.719 (85.844)	Acc@5 100.000 (99.437)
Epoch: [63][192/196]	Time 0.122 (0.126)	Data 0.000 (0.001)	Loss 0.6035 (0.6639)	Acc@1 87.891 (85.871)	Acc@5 99.609 (99.415)
Max memory in training epoch: 54.8688384
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.178 (0.178)	Data 0.265 (0.265)	Loss 0.7308 (0.7308)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [64][64/196]	Time 0.142 (0.126)	Data 0.000 (0.004)	Loss 0.6295 (0.6533)	Acc@1 86.719 (85.901)	Acc@5 99.609 (99.543)
Epoch: [64][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.6712 (0.6591)	Acc@1 84.766 (85.825)	Acc@5 99.609 (99.473)
Epoch: [64][192/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.6498 (0.6623)	Acc@1 87.891 (85.850)	Acc@5 99.219 (99.427)
Max memory in training epoch: 54.8688384
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.162 (0.162)	Data 0.282 (0.282)	Loss 0.6854 (0.6854)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.6654 (0.6564)	Acc@1 87.109 (86.016)	Acc@5 99.219 (99.417)
Epoch: [65][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.7330 (0.6538)	Acc@1 82.812 (86.071)	Acc@5 98.828 (99.464)
Epoch: [65][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7051 (0.6601)	Acc@1 83.984 (85.885)	Acc@5 98.828 (99.447)
Max memory in training epoch: 54.8688384
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 220388 ; 222410 ; 0.9909086821635718
[INFO] Storing checkpoint...
  78.58
Max memory: 84.7446016
 25.312s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 415
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.0964608
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.173 (0.173)	Data 0.271 (0.271)	Loss 0.6229 (0.6229)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.7250 (0.6275)	Acc@1 81.641 (87.175)	Acc@5 100.000 (99.525)
Epoch: [66][128/196]	Time 0.142 (0.124)	Data 0.000 (0.002)	Loss 0.6574 (0.6389)	Acc@1 85.938 (86.746)	Acc@5 99.609 (99.458)
Epoch: [66][192/196]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.6341 (0.6480)	Acc@1 86.719 (86.375)	Acc@5 99.609 (99.458)
Max memory in training epoch: 54.2632448
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.179 (0.179)	Data 0.273 (0.273)	Loss 0.7161 (0.7161)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.6006 (0.6666)	Acc@1 87.500 (85.445)	Acc@5 99.219 (99.447)
Epoch: [67][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.6687 (0.6739)	Acc@1 84.766 (85.232)	Acc@5 99.609 (99.400)
Epoch: [67][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.7726 (0.6720)	Acc@1 83.984 (85.340)	Acc@5 99.219 (99.401)
Max memory in training epoch: 54.6554368
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.152 (0.152)	Data 0.267 (0.267)	Loss 0.6366 (0.6366)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [68][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.6352 (0.6597)	Acc@1 85.938 (85.871)	Acc@5 99.609 (99.531)
Epoch: [68][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.7237 (0.6575)	Acc@1 82.812 (86.065)	Acc@5 98.828 (99.473)
Epoch: [68][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.6188 (0.6557)	Acc@1 86.719 (86.043)	Acc@5 99.219 (99.454)
Max memory in training epoch: 54.6554368
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.179 (0.179)	Data 0.294 (0.294)	Loss 0.6140 (0.6140)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.119 (0.126)	Data 0.000 (0.005)	Loss 0.6926 (0.6482)	Acc@1 83.984 (86.190)	Acc@5 99.609 (99.447)
Epoch: [69][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6019 (0.6541)	Acc@1 86.328 (86.062)	Acc@5 100.000 (99.509)
Epoch: [69][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.4987 (0.6568)	Acc@1 91.797 (85.968)	Acc@5 100.000 (99.492)
Max memory in training epoch: 54.6554368
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.165 (0.165)	Data 0.289 (0.289)	Loss 0.5546 (0.5546)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.7042 (0.6608)	Acc@1 83.984 (85.889)	Acc@5 99.609 (99.453)
Epoch: [70][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6551 (0.6583)	Acc@1 86.328 (86.098)	Acc@5 98.438 (99.422)
Epoch: [70][192/196]	Time 0.159 (0.124)	Data 0.000 (0.002)	Loss 0.6138 (0.6595)	Acc@1 86.328 (86.023)	Acc@5 99.219 (99.429)
Max memory in training epoch: 54.6554368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 220098 ; 220388 ; 0.9986841388823348
[INFO] Storing checkpoint...
  75.03
Max memory: 84.040192
 24.617s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 933
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.0963584
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.192 (0.192)	Data 0.267 (0.267)	Loss 0.6106 (0.6106)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [71][64/196]	Time 0.122 (0.125)	Data 0.000 (0.004)	Loss 0.6135 (0.6406)	Acc@1 86.719 (86.520)	Acc@5 100.000 (99.501)
Epoch: [71][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.6965 (0.6466)	Acc@1 84.375 (86.295)	Acc@5 99.219 (99.476)
Epoch: [71][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6283 (0.6570)	Acc@1 88.281 (85.948)	Acc@5 100.000 (99.415)
Max memory in training epoch: 54.2355968
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.178 (0.178)	Data 0.271 (0.271)	Loss 0.5555 (0.5555)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.119 (0.125)	Data 0.000 (0.004)	Loss 0.6161 (0.6548)	Acc@1 87.500 (86.142)	Acc@5 99.609 (99.435)
Epoch: [72][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.7517 (0.6552)	Acc@1 81.641 (86.140)	Acc@5 98.047 (99.391)
Epoch: [72][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6715 (0.6588)	Acc@1 84.375 (86.002)	Acc@5 99.609 (99.391)
Max memory in training epoch: 54.0455424
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.164 (0.164)	Data 0.282 (0.282)	Loss 0.6176 (0.6176)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [73][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.6457 (0.6431)	Acc@1 86.328 (86.424)	Acc@5 100.000 (99.495)
Epoch: [73][128/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.6560 (0.6467)	Acc@1 85.938 (86.265)	Acc@5 99.609 (99.467)
Epoch: [73][192/196]	Time 0.127 (0.125)	Data 0.000 (0.002)	Loss 0.6683 (0.6490)	Acc@1 84.766 (86.146)	Acc@5 98.438 (99.468)
Max memory in training epoch: 54.0455424
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.144 (0.144)	Data 0.299 (0.299)	Loss 0.6339 (0.6339)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.6386 (0.6442)	Acc@1 86.719 (86.088)	Acc@5 99.609 (99.561)
Epoch: [74][128/196]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.6433 (0.6508)	Acc@1 87.500 (86.010)	Acc@5 99.219 (99.534)
Epoch: [74][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.5962 (0.6521)	Acc@1 89.453 (86.020)	Acc@5 100.000 (99.496)
Max memory in training epoch: 54.0455424
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.188 (0.188)	Data 0.273 (0.273)	Loss 0.6764 (0.6764)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.124 (0.127)	Data 0.000 (0.004)	Loss 0.6589 (0.6597)	Acc@1 87.500 (85.865)	Acc@5 100.000 (99.453)
Epoch: [75][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6486 (0.6467)	Acc@1 84.375 (86.249)	Acc@5 99.609 (99.473)
Epoch: [75][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.6422 (0.6499)	Acc@1 86.719 (86.158)	Acc@5 100.000 (99.458)
Max memory in training epoch: 54.0455424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 218652 ; 220098 ; 0.9934301992748684
[INFO] Storing checkpoint...
  78.09
Max memory: 83.6237312
 25.164s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8251
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.095744
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.179 (0.179)	Data 0.286 (0.286)	Loss 0.5396 (0.5396)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.6448 (0.6195)	Acc@1 84.766 (87.200)	Acc@5 99.609 (99.555)
Epoch: [76][128/196]	Time 0.134 (0.126)	Data 0.000 (0.002)	Loss 0.7490 (0.6448)	Acc@1 82.812 (86.243)	Acc@5 99.219 (99.470)
Epoch: [76][192/196]	Time 0.136 (0.126)	Data 0.000 (0.002)	Loss 0.6753 (0.6521)	Acc@1 86.328 (86.000)	Acc@5 100.000 (99.437)
Max memory in training epoch: 53.7678336
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.160 (0.160)	Data 0.285 (0.285)	Loss 0.6715 (0.6715)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [77][64/196]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.6798 (0.6557)	Acc@1 82.812 (85.655)	Acc@5 99.219 (99.381)
Epoch: [77][128/196]	Time 0.134 (0.126)	Data 0.000 (0.002)	Loss 0.6056 (0.6558)	Acc@1 87.109 (85.768)	Acc@5 98.828 (99.416)
Epoch: [77][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.6892 (0.6583)	Acc@1 85.156 (85.737)	Acc@5 99.609 (99.409)
Max memory in training epoch: 53.7678336
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.178 (0.178)	Data 0.285 (0.285)	Loss 0.6638 (0.6638)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [78][64/196]	Time 0.118 (0.129)	Data 0.000 (0.005)	Loss 0.5647 (0.6453)	Acc@1 88.672 (86.118)	Acc@5 100.000 (99.387)
Epoch: [78][128/196]	Time 0.142 (0.127)	Data 0.000 (0.002)	Loss 0.5945 (0.6458)	Acc@1 86.328 (86.210)	Acc@5 99.609 (99.425)
Epoch: [78][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7641 (0.6521)	Acc@1 80.469 (85.982)	Acc@5 99.609 (99.447)
Max memory in training epoch: 53.7678336
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.169 (0.169)	Data 0.280 (0.280)	Loss 0.6500 (0.6500)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [79][64/196]	Time 0.146 (0.128)	Data 0.000 (0.004)	Loss 0.6111 (0.6497)	Acc@1 85.547 (86.040)	Acc@5 100.000 (99.465)
Epoch: [79][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6454 (0.6453)	Acc@1 89.062 (86.346)	Acc@5 99.219 (99.452)
Epoch: [79][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.6221 (0.6441)	Acc@1 87.109 (86.292)	Acc@5 99.219 (99.456)
Max memory in training epoch: 53.7678336
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.153 (0.153)	Data 0.302 (0.302)	Loss 0.5468 (0.5468)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [80][64/196]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.6043 (0.6381)	Acc@1 88.672 (86.184)	Acc@5 99.219 (99.501)
Epoch: [80][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.6234 (0.6530)	Acc@1 86.328 (85.789)	Acc@5 99.609 (99.464)
Epoch: [80][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6594 (0.6519)	Acc@1 85.938 (85.889)	Acc@5 100.000 (99.466)
Max memory in training epoch: 53.7678336
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 217784 ; 218652 ; 0.9960302215392496
[INFO] Storing checkpoint...
  80.88
Max memory: 83.4072576
 25.603s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8752
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.0954368
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.200 (0.200)	Data 0.277 (0.277)	Loss 0.6703 (0.6703)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.121 (0.125)	Data 0.000 (0.004)	Loss 0.5794 (0.6256)	Acc@1 89.062 (86.845)	Acc@5 100.000 (99.525)
Epoch: [81][128/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.6335 (0.6361)	Acc@1 88.281 (86.492)	Acc@5 99.609 (99.476)
Epoch: [81][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.5881 (0.6399)	Acc@1 87.891 (86.344)	Acc@5 99.609 (99.472)
Max memory in training epoch: 53.517568
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.180 (0.180)	Data 0.256 (0.256)	Loss 0.6805 (0.6805)	Acc@1 86.328 (86.328)	Acc@5 98.438 (98.438)
Epoch: [82][64/196]	Time 0.122 (0.125)	Data 0.000 (0.004)	Loss 0.6425 (0.6489)	Acc@1 85.547 (85.865)	Acc@5 99.609 (99.531)
Epoch: [82][128/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.6636 (0.6514)	Acc@1 87.109 (85.922)	Acc@5 98.828 (99.437)
Epoch: [82][192/196]	Time 0.142 (0.125)	Data 0.000 (0.001)	Loss 0.6132 (0.6549)	Acc@1 88.672 (85.774)	Acc@5 99.609 (99.409)
Max memory in training epoch: 53.4913536
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.180 (0.180)	Data 0.290 (0.290)	Loss 0.5759 (0.5759)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.6534 (0.6329)	Acc@1 85.547 (86.466)	Acc@5 99.219 (99.435)
Epoch: [83][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6816 (0.6384)	Acc@1 83.984 (86.425)	Acc@5 98.438 (99.467)
Epoch: [83][192/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.7690 (0.6433)	Acc@1 82.031 (86.269)	Acc@5 98.828 (99.456)
Max memory in training epoch: 53.7010688
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.176 (0.176)	Data 0.284 (0.284)	Loss 0.6714 (0.6714)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.128 (0.125)	Data 0.000 (0.005)	Loss 0.6185 (0.6407)	Acc@1 86.719 (86.436)	Acc@5 99.219 (99.459)
Epoch: [84][128/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.6606 (0.6360)	Acc@1 86.328 (86.704)	Acc@5 100.000 (99.500)
Epoch: [84][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6835 (0.6406)	Acc@1 85.547 (86.514)	Acc@5 99.219 (99.452)
Max memory in training epoch: 53.7010688
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.174 (0.174)	Data 0.283 (0.283)	Loss 0.6586 (0.6586)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6241 (0.6325)	Acc@1 85.547 (86.550)	Acc@5 100.000 (99.447)
Epoch: [85][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6391 (0.6390)	Acc@1 87.500 (86.334)	Acc@5 99.609 (99.419)
Epoch: [85][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6188 (0.6441)	Acc@1 87.500 (86.174)	Acc@5 99.609 (99.413)
Max memory in training epoch: 53.7010688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 217206 ; 217784 ; 0.9973459941960842
[INFO] Storing checkpoint...
  80.43
Max memory: 83.1491072
 25.461s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8588
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.095232
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.177 (0.177)	Data 0.285 (0.285)	Loss 0.5695 (0.5695)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.140 (0.127)	Data 0.000 (0.005)	Loss 0.6033 (0.6089)	Acc@1 87.891 (87.488)	Acc@5 99.609 (99.483)
Epoch: [86][128/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.6568 (0.6190)	Acc@1 86.719 (87.106)	Acc@5 99.219 (99.467)
Epoch: [86][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7269 (0.6321)	Acc@1 83.984 (86.719)	Acc@5 98.438 (99.425)
Max memory in training epoch: 53.46432
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.160 (0.160)	Data 0.251 (0.251)	Loss 0.5501 (0.5501)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.133 (0.126)	Data 0.000 (0.004)	Loss 0.5938 (0.6564)	Acc@1 89.453 (85.709)	Acc@5 100.000 (99.507)
Epoch: [87][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6726 (0.6503)	Acc@1 86.328 (86.004)	Acc@5 99.609 (99.500)
Epoch: [87][192/196]	Time 0.127 (0.124)	Data 0.000 (0.001)	Loss 0.5860 (0.6497)	Acc@1 86.328 (86.023)	Acc@5 99.609 (99.480)
Max memory in training epoch: 53.4381056
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.164 (0.164)	Data 0.289 (0.289)	Loss 0.7038 (0.7038)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [88][64/196]	Time 0.119 (0.126)	Data 0.000 (0.005)	Loss 0.6765 (0.6387)	Acc@1 84.375 (86.376)	Acc@5 99.219 (99.471)
Epoch: [88][128/196]	Time 0.129 (0.124)	Data 0.000 (0.002)	Loss 0.7039 (0.6411)	Acc@1 83.594 (86.222)	Acc@5 98.047 (99.467)
Epoch: [88][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6555 (0.6450)	Acc@1 85.547 (86.071)	Acc@5 100.000 (99.472)
Max memory in training epoch: 53.6478208
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.149 (0.149)	Data 0.282 (0.282)	Loss 0.5516 (0.5516)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.6543 (0.6521)	Acc@1 85.547 (86.052)	Acc@5 100.000 (99.387)
Epoch: [89][128/196]	Time 0.127 (0.125)	Data 0.000 (0.002)	Loss 0.6380 (0.6487)	Acc@1 83.594 (86.050)	Acc@5 99.609 (99.422)
Epoch: [89][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.6829 (0.6517)	Acc@1 84.375 (85.992)	Acc@5 99.609 (99.407)
Max memory in training epoch: 53.6478208
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.175 (0.175)	Data 0.268 (0.268)	Loss 0.6479 (0.6479)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.127 (0.126)	Data 0.000 (0.004)	Loss 0.7155 (0.6502)	Acc@1 82.812 (85.925)	Acc@5 100.000 (99.477)
Epoch: [90][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.6537 (0.6550)	Acc@1 83.984 (85.819)	Acc@5 99.609 (99.425)
Epoch: [90][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.5781 (0.6544)	Acc@1 90.234 (85.806)	Acc@5 100.000 (99.411)
Max memory in training epoch: 53.6478208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 215696 ; 217206 ; 0.9930480741784297
[INFO] Storing checkpoint...
  77.61
Max memory: 83.0665728
 24.970s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1963
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.0941056
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.194 (0.194)	Data 0.265 (0.265)	Loss 0.5538 (0.5538)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.121 (0.120)	Data 0.000 (0.004)	Loss 0.6214 (0.6187)	Acc@1 86.328 (86.977)	Acc@5 99.219 (99.405)
Epoch: [91][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.5700 (0.6312)	Acc@1 88.672 (86.507)	Acc@5 99.609 (99.419)
Epoch: [91][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6761 (0.6352)	Acc@1 84.766 (86.437)	Acc@5 99.609 (99.427)
Max memory in training epoch: 51.5143168
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.141 (0.141)	Data 0.260 (0.260)	Loss 0.7222 (0.7222)	Acc@1 81.250 (81.250)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.123 (0.118)	Data 0.000 (0.004)	Loss 0.6319 (0.6388)	Acc@1 86.719 (86.202)	Acc@5 98.828 (99.465)
Epoch: [92][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.5833 (0.6415)	Acc@1 87.500 (86.140)	Acc@5 100.000 (99.479)
Epoch: [92][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.7004 (0.6424)	Acc@1 84.766 (86.184)	Acc@5 99.219 (99.472)
Max memory in training epoch: 51.5012096
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.171 (0.171)	Data 0.255 (0.255)	Loss 0.6480 (0.6480)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [93][64/196]	Time 0.119 (0.119)	Data 0.000 (0.004)	Loss 0.5052 (0.5576)	Acc@1 90.625 (89.171)	Acc@5 100.000 (99.681)
Epoch: [93][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.5479 (0.5290)	Acc@1 88.281 (90.165)	Acc@5 100.000 (99.734)
Epoch: [93][192/196]	Time 0.122 (0.119)	Data 0.000 (0.001)	Loss 0.4982 (0.5166)	Acc@1 90.234 (90.562)	Acc@5 100.000 (99.757)
Max memory in training epoch: 51.5012096
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.152 (0.152)	Data 0.297 (0.297)	Loss 0.5135 (0.5135)	Acc@1 92.578 (92.578)	Acc@5 99.219 (99.219)
Epoch: [94][64/196]	Time 0.124 (0.118)	Data 0.000 (0.005)	Loss 0.5614 (0.4687)	Acc@1 88.281 (92.133)	Acc@5 100.000 (99.814)
Epoch: [94][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.4080 (0.4644)	Acc@1 94.141 (92.236)	Acc@5 100.000 (99.824)
Epoch: [94][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.4806 (0.4611)	Acc@1 92.969 (92.434)	Acc@5 100.000 (99.818)
Max memory in training epoch: 51.5012096
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.187 (0.187)	Data 0.284 (0.284)	Loss 0.5167 (0.5167)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.4541 (0.4479)	Acc@1 92.969 (92.704)	Acc@5 99.609 (99.850)
Epoch: [95][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3832 (0.4416)	Acc@1 94.922 (92.863)	Acc@5 100.000 (99.855)
Epoch: [95][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.4722 (0.4403)	Acc@1 92.188 (92.959)	Acc@5 99.609 (99.836)
Max memory in training epoch: 51.5012096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 215118 ; 215696 ; 0.9973203026481715
[INFO] Storing checkpoint...
  90.68
Max memory: 79.8803968
 24.170s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1615
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.0939008
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.182 (0.182)	Data 0.262 (0.262)	Loss 0.4094 (0.4094)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [96][64/196]	Time 0.121 (0.119)	Data 0.000 (0.004)	Loss 0.3893 (0.4251)	Acc@1 95.312 (93.383)	Acc@5 100.000 (99.820)
Epoch: [96][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.4259 (0.4241)	Acc@1 92.969 (93.462)	Acc@5 99.609 (99.821)
Epoch: [96][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.3558 (0.4232)	Acc@1 95.703 (93.388)	Acc@5 100.000 (99.828)
Max memory in training epoch: 51.4610688
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.172 (0.172)	Data 0.273 (0.273)	Loss 0.4420 (0.4420)	Acc@1 92.188 (92.188)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.119 (0.119)	Data 0.000 (0.004)	Loss 0.4260 (0.4229)	Acc@1 92.578 (93.275)	Acc@5 99.609 (99.778)
Epoch: [97][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.4226 (0.4171)	Acc@1 92.578 (93.396)	Acc@5 100.000 (99.836)
Epoch: [97][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3691 (0.4135)	Acc@1 94.531 (93.517)	Acc@5 100.000 (99.848)
Max memory in training epoch: 51.4479616
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.146 (0.146)	Data 0.253 (0.253)	Loss 0.3724 (0.3724)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.4555 (0.3964)	Acc@1 92.578 (94.183)	Acc@5 100.000 (99.862)
Epoch: [98][128/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.3836 (0.3992)	Acc@1 92.969 (93.920)	Acc@5 100.000 (99.846)
Epoch: [98][192/196]	Time 0.117 (0.118)	Data 0.000 (0.001)	Loss 0.4302 (0.4013)	Acc@1 93.750 (93.827)	Acc@5 100.000 (99.854)
Max memory in training epoch: 51.4479616
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.169 (0.169)	Data 0.296 (0.296)	Loss 0.3106 (0.3106)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.4400 (0.3902)	Acc@1 94.141 (94.141)	Acc@5 99.219 (99.892)
Epoch: [99][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.4090 (0.3908)	Acc@1 92.969 (94.032)	Acc@5 99.609 (99.906)
Epoch: [99][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3925 (0.3916)	Acc@1 93.359 (94.019)	Acc@5 100.000 (99.901)
Max memory in training epoch: 51.4479616
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.136 (0.136)	Data 0.290 (0.290)	Loss 0.3745 (0.3745)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.3411 (0.3749)	Acc@1 94.922 (94.567)	Acc@5 100.000 (99.898)
Epoch: [100][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.4084 (0.3823)	Acc@1 94.141 (94.207)	Acc@5 99.219 (99.885)
Epoch: [100][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3613 (0.3826)	Acc@1 94.922 (94.171)	Acc@5 100.000 (99.877)
Max memory in training epoch: 51.4479616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 214104 ; 215118 ; 0.9952863079798064
[INFO] Storing checkpoint...
  91.02
Max memory: 79.7978624
 23.602s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6268
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.0935424
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.196 (0.196)	Data 0.249 (0.249)	Loss 0.4496 (0.4496)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [101][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.3245 (0.3681)	Acc@1 95.703 (94.694)	Acc@5 100.000 (99.868)
Epoch: [101][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3445 (0.3728)	Acc@1 94.922 (94.507)	Acc@5 100.000 (99.876)
Epoch: [101][192/196]	Time 0.117 (0.122)	Data 0.000 (0.001)	Loss 0.3843 (0.3733)	Acc@1 93.750 (94.424)	Acc@5 99.609 (99.893)
Max memory in training epoch: 51.0402048
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.172 (0.172)	Data 0.333 (0.333)	Loss 0.3563 (0.3563)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.110 (0.119)	Data 0.000 (0.005)	Loss 0.3461 (0.3589)	Acc@1 95.312 (94.778)	Acc@5 100.000 (99.928)
Epoch: [102][128/196]	Time 0.116 (0.119)	Data 0.000 (0.003)	Loss 0.4072 (0.3638)	Acc@1 93.359 (94.664)	Acc@5 99.609 (99.894)
Epoch: [102][192/196]	Time 0.131 (0.119)	Data 0.000 (0.002)	Loss 0.3789 (0.3677)	Acc@1 93.359 (94.450)	Acc@5 100.000 (99.897)
Max memory in training epoch: 50.8370432
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.146 (0.146)	Data 0.284 (0.284)	Loss 0.3718 (0.3718)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.3344 (0.3567)	Acc@1 95.312 (94.880)	Acc@5 100.000 (99.916)
Epoch: [103][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3468 (0.3560)	Acc@1 96.875 (94.870)	Acc@5 100.000 (99.909)
Epoch: [103][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3814 (0.3582)	Acc@1 93.359 (94.719)	Acc@5 100.000 (99.895)
Max memory in training epoch: 50.8370432
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.151 (0.151)	Data 0.254 (0.254)	Loss 0.3471 (0.3471)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.3273 (0.3488)	Acc@1 96.094 (94.964)	Acc@5 100.000 (99.922)
Epoch: [104][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3301 (0.3488)	Acc@1 96.094 (94.992)	Acc@5 100.000 (99.915)
Epoch: [104][192/196]	Time 0.115 (0.118)	Data 0.000 (0.001)	Loss 0.3263 (0.3532)	Acc@1 96.094 (94.691)	Acc@5 100.000 (99.911)
Max memory in training epoch: 50.8370432
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.166 (0.166)	Data 0.264 (0.264)	Loss 0.2816 (0.2816)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.3902 (0.3373)	Acc@1 92.969 (95.168)	Acc@5 99.609 (99.898)
Epoch: [105][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3802 (0.3415)	Acc@1 93.359 (94.943)	Acc@5 100.000 (99.915)
Epoch: [105][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3636 (0.3448)	Acc@1 94.141 (94.859)	Acc@5 99.609 (99.927)
Max memory in training epoch: 50.8370432
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 211648 ; 214104 ; 0.9885289392071143
[INFO] Storing checkpoint...
  91.14
Max memory: 78.7531264
 23.618s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1599
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.0925696
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.190 (0.190)	Data 0.283 (0.283)	Loss 0.4310 (0.4310)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [106][64/196]	Time 0.118 (0.118)	Data 0.000 (0.005)	Loss 0.3809 (0.3464)	Acc@1 93.359 (94.802)	Acc@5 100.000 (99.922)
Epoch: [106][128/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3078 (0.3448)	Acc@1 94.922 (94.746)	Acc@5 100.000 (99.924)
Epoch: [106][192/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3728 (0.3429)	Acc@1 93.750 (94.813)	Acc@5 99.609 (99.925)
Max memory in training epoch: 50.5447936
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.173 (0.173)	Data 0.255 (0.255)	Loss 0.2965 (0.2965)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.116 (0.117)	Data 0.000 (0.004)	Loss 0.3102 (0.3273)	Acc@1 96.094 (95.517)	Acc@5 100.000 (99.928)
Epoch: [107][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.3604 (0.3293)	Acc@1 94.922 (95.355)	Acc@5 100.000 (99.936)
Epoch: [107][192/196]	Time 0.120 (0.118)	Data 0.000 (0.001)	Loss 0.4027 (0.3337)	Acc@1 92.969 (95.134)	Acc@5 99.609 (99.927)
Max memory in training epoch: 50.5579008
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.157 (0.157)	Data 0.299 (0.299)	Loss 0.3097 (0.3097)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.112 (0.121)	Data 0.000 (0.005)	Loss 0.3605 (0.3214)	Acc@1 93.359 (95.505)	Acc@5 100.000 (99.940)
Epoch: [108][128/196]	Time 0.121 (0.119)	Data 0.000 (0.003)	Loss 0.3588 (0.3273)	Acc@1 93.750 (95.297)	Acc@5 100.000 (99.933)
Epoch: [108][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3200 (0.3280)	Acc@1 96.484 (95.227)	Acc@5 100.000 (99.923)
Max memory in training epoch: 50.5579008
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.151 (0.151)	Data 0.256 (0.256)	Loss 0.3035 (0.3035)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.119 (0.119)	Data 0.000 (0.004)	Loss 0.2820 (0.3247)	Acc@1 96.875 (95.102)	Acc@5 100.000 (99.952)
Epoch: [109][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3671 (0.3220)	Acc@1 92.578 (95.240)	Acc@5 100.000 (99.942)
Epoch: [109][192/196]	Time 0.110 (0.117)	Data 0.000 (0.002)	Loss 0.3115 (0.3258)	Acc@1 96.094 (95.094)	Acc@5 100.000 (99.929)
Max memory in training epoch: 50.5579008
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.170 (0.170)	Data 0.252 (0.252)	Loss 0.2813 (0.2813)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.2749 (0.3184)	Acc@1 97.266 (95.246)	Acc@5 100.000 (99.946)
Epoch: [110][128/196]	Time 0.127 (0.118)	Data 0.000 (0.002)	Loss 0.2947 (0.3200)	Acc@1 96.094 (95.228)	Acc@5 100.000 (99.933)
Epoch: [110][192/196]	Time 0.114 (0.117)	Data 0.000 (0.001)	Loss 0.3732 (0.3238)	Acc@1 93.359 (95.096)	Acc@5 100.000 (99.935)
Max memory in training epoch: 50.5579008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 207028 ; 211648 ; 0.9781713032960387
[INFO] Storing checkpoint...
  90.62
Max memory: 78.4069632
 23.353s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9226
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.0908288
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.202 (0.202)	Data 0.262 (0.262)	Loss 0.3063 (0.3063)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [111][64/196]	Time 0.110 (0.118)	Data 0.000 (0.004)	Loss 0.3336 (0.3104)	Acc@1 94.141 (95.445)	Acc@5 100.000 (99.952)
Epoch: [111][128/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3222 (0.3154)	Acc@1 95.312 (95.237)	Acc@5 100.000 (99.952)
Epoch: [111][192/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.4010 (0.3232)	Acc@1 91.797 (94.885)	Acc@5 100.000 (99.933)
Max memory in training epoch: 50.1184
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.146 (0.146)	Data 0.255 (0.255)	Loss 0.3108 (0.3108)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [112][64/196]	Time 0.117 (0.118)	Data 0.000 (0.004)	Loss 0.3275 (0.3093)	Acc@1 96.094 (95.355)	Acc@5 100.000 (99.940)
Epoch: [112][128/196]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2923 (0.3152)	Acc@1 94.531 (95.155)	Acc@5 100.000 (99.949)
Epoch: [112][192/196]	Time 0.115 (0.117)	Data 0.000 (0.001)	Loss 0.3181 (0.3188)	Acc@1 94.922 (94.989)	Acc@5 100.000 (99.951)
Max memory in training epoch: 50.1708288
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.160 (0.160)	Data 0.293 (0.293)	Loss 0.2630 (0.2630)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.113 (0.117)	Data 0.000 (0.005)	Loss 0.3312 (0.3174)	Acc@1 94.531 (95.102)	Acc@5 100.000 (99.946)
Epoch: [113][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3065 (0.3186)	Acc@1 94.141 (95.076)	Acc@5 100.000 (99.936)
Epoch: [113][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.2828 (0.3184)	Acc@1 96.875 (95.023)	Acc@5 100.000 (99.939)
Max memory in training epoch: 50.1708288
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.170 (0.170)	Data 0.296 (0.296)	Loss 0.3153 (0.3153)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.2941 (0.3129)	Acc@1 94.531 (95.084)	Acc@5 100.000 (99.964)
Epoch: [114][128/196]	Time 0.135 (0.118)	Data 0.000 (0.002)	Loss 0.3178 (0.3142)	Acc@1 93.359 (95.028)	Acc@5 100.000 (99.945)
Epoch: [114][192/196]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.2999 (0.3166)	Acc@1 95.703 (94.962)	Acc@5 100.000 (99.939)
Max memory in training epoch: 50.1708288
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.169 (0.169)	Data 0.282 (0.282)	Loss 0.2825 (0.2825)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.111 (0.119)	Data 0.000 (0.005)	Loss 0.3011 (0.3032)	Acc@1 94.922 (95.523)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3112 (0.3072)	Acc@1 95.703 (95.340)	Acc@5 100.000 (99.964)
Epoch: [115][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2953 (0.3104)	Acc@1 96.484 (95.201)	Acc@5 100.000 (99.951)
Max memory in training epoch: 50.1708288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 202116 ; 207028 ; 0.9762737407500435
[INFO] Storing checkpoint...
  90.3
Max memory: 77.9200512
 23.349s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6333
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0887808
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.180 (0.180)	Data 0.283 (0.283)	Loss 0.3117 (0.3117)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [116][64/196]	Time 0.121 (0.119)	Data 0.000 (0.005)	Loss 0.3634 (0.3096)	Acc@1 94.922 (95.072)	Acc@5 100.000 (99.970)
Epoch: [116][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2977 (0.3084)	Acc@1 95.312 (95.091)	Acc@5 100.000 (99.976)
Epoch: [116][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3072 (0.3122)	Acc@1 96.094 (94.962)	Acc@5 100.000 (99.962)
Max memory in training epoch: 49.4050816
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.146 (0.146)	Data 0.261 (0.261)	Loss 0.2965 (0.2965)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.120 (0.118)	Data 0.000 (0.004)	Loss 0.2745 (0.3061)	Acc@1 96.484 (95.012)	Acc@5 100.000 (99.970)
Epoch: [117][128/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.3537 (0.3092)	Acc@1 93.750 (94.925)	Acc@5 100.000 (99.955)
Epoch: [117][192/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.2874 (0.3107)	Acc@1 95.703 (94.859)	Acc@5 100.000 (99.937)
Max memory in training epoch: 49.520384
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.182 (0.182)	Data 0.259 (0.259)	Loss 0.2829 (0.2829)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.3024 (0.3037)	Acc@1 96.094 (95.024)	Acc@5 100.000 (99.934)
Epoch: [118][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3179 (0.3039)	Acc@1 95.312 (95.098)	Acc@5 100.000 (99.936)
Epoch: [118][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.3197 (0.3055)	Acc@1 93.750 (95.007)	Acc@5 100.000 (99.933)
Max memory in training epoch: 49.520384
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.169 (0.169)	Data 0.262 (0.262)	Loss 0.2884 (0.2884)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.117 (0.116)	Data 0.000 (0.004)	Loss 0.2875 (0.3022)	Acc@1 94.922 (95.156)	Acc@5 100.000 (99.958)
Epoch: [119][128/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.2884 (0.3029)	Acc@1 96.484 (94.995)	Acc@5 100.000 (99.939)
Epoch: [119][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3291 (0.3078)	Acc@1 93.750 (94.831)	Acc@5 99.609 (99.911)
Max memory in training epoch: 49.520384
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.164 (0.164)	Data 0.276 (0.276)	Loss 0.2613 (0.2613)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.3258 (0.3031)	Acc@1 94.531 (95.192)	Acc@5 100.000 (99.940)
Epoch: [120][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.2581 (0.3026)	Acc@1 96.094 (95.082)	Acc@5 100.000 (99.930)
Epoch: [120][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.2788 (0.3064)	Acc@1 95.703 (94.948)	Acc@5 100.000 (99.927)
Max memory in training epoch: 49.520384
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv30.weight

 RM:  module.conv31.weight
numoFStages: 3
Count: 191736 ; 202116 ; 0.9486433533218548
[INFO] Storing checkpoint...
  89.72
Max memory: 76.5761536
 23.474s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 673
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0841728
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.184 (0.184)	Data 0.281 (0.281)	Loss 0.3598 (0.3598)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.114 (0.114)	Data 0.000 (0.004)	Loss 0.2797 (0.3144)	Acc@1 97.656 (94.393)	Acc@5 99.609 (99.940)
Epoch: [121][128/196]	Time 0.108 (0.113)	Data 0.000 (0.002)	Loss 0.3171 (0.3162)	Acc@1 94.531 (94.328)	Acc@5 100.000 (99.933)
Epoch: [121][192/196]	Time 0.116 (0.114)	Data 0.000 (0.002)	Loss 0.2951 (0.3167)	Acc@1 96.094 (94.359)	Acc@5 100.000 (99.925)
Max memory in training epoch: 47.8102016
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.156 (0.156)	Data 0.257 (0.257)	Loss 0.3075 (0.3075)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.107 (0.114)	Data 0.000 (0.004)	Loss 0.3158 (0.3093)	Acc@1 94.141 (94.694)	Acc@5 99.609 (99.952)
Epoch: [122][128/196]	Time 0.104 (0.114)	Data 0.000 (0.002)	Loss 0.3335 (0.3119)	Acc@1 94.141 (94.477)	Acc@5 100.000 (99.945)
Epoch: [122][192/196]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.3403 (0.3142)	Acc@1 94.922 (94.361)	Acc@5 99.609 (99.931)
Max memory in training epoch: 47.759616
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.160 (0.160)	Data 0.285 (0.285)	Loss 0.2702 (0.2702)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.108 (0.114)	Data 0.000 (0.005)	Loss 0.3419 (0.3089)	Acc@1 92.188 (94.561)	Acc@5 100.000 (99.922)
Epoch: [123][128/196]	Time 0.118 (0.114)	Data 0.000 (0.002)	Loss 0.3594 (0.3107)	Acc@1 93.750 (94.495)	Acc@5 98.828 (99.915)
Epoch: [123][192/196]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.3390 (0.3123)	Acc@1 91.406 (94.452)	Acc@5 100.000 (99.925)
Max memory in training epoch: 47.8317056
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.156 (0.156)	Data 0.285 (0.285)	Loss 0.2996 (0.2996)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.112 (0.115)	Data 0.000 (0.005)	Loss 0.2916 (0.3086)	Acc@1 95.703 (94.609)	Acc@5 100.000 (99.940)
Epoch: [124][128/196]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.3388 (0.3106)	Acc@1 93.359 (94.513)	Acc@5 99.219 (99.933)
Epoch: [124][192/196]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.3522 (0.3119)	Acc@1 93.750 (94.464)	Acc@5 99.609 (99.931)
Max memory in training epoch: 47.8317056
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.167 (0.167)	Data 0.285 (0.285)	Loss 0.3432 (0.3432)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.122 (0.119)	Data 0.000 (0.005)	Loss 0.3336 (0.3123)	Acc@1 93.359 (94.531)	Acc@5 100.000 (99.904)
Epoch: [125][128/196]	Time 0.123 (0.118)	Data 0.000 (0.002)	Loss 0.2839 (0.3119)	Acc@1 92.578 (94.440)	Acc@5 100.000 (99.912)
Epoch: [125][192/196]	Time 0.107 (0.118)	Data 0.000 (0.002)	Loss 0.3346 (0.3132)	Acc@1 95.312 (94.406)	Acc@5 99.609 (99.931)
Max memory in training epoch: 47.8317056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 183798 ; 191736 ; 0.9585993240705971
[INFO] Storing checkpoint...
  88.44
Max memory: 74.7430912
 23.394s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6840
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0809472
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.164 (0.164)	Data 0.258 (0.258)	Loss 0.3506 (0.3506)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.110 (0.115)	Data 0.000 (0.004)	Loss 0.2952 (0.3175)	Acc@1 94.922 (94.123)	Acc@5 100.000 (99.904)
Epoch: [126][128/196]	Time 0.118 (0.114)	Data 0.000 (0.002)	Loss 0.2885 (0.3195)	Acc@1 94.531 (94.086)	Acc@5 100.000 (99.879)
Epoch: [126][192/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.2696 (0.3195)	Acc@1 95.703 (94.011)	Acc@5 100.000 (99.885)
Max memory in training epoch: 47.5284992
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.154 (0.154)	Data 0.262 (0.262)	Loss 0.2970 (0.2970)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.121 (0.113)	Data 0.000 (0.004)	Loss 0.2774 (0.3013)	Acc@1 93.750 (94.730)	Acc@5 100.000 (99.940)
Epoch: [127][128/196]	Time 0.128 (0.113)	Data 0.000 (0.002)	Loss 0.2839 (0.3086)	Acc@1 95.703 (94.337)	Acc@5 100.000 (99.927)
Epoch: [127][192/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.3608 (0.3150)	Acc@1 91.797 (94.114)	Acc@5 99.219 (99.917)
Max memory in training epoch: 47.5828736
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.153 (0.153)	Data 0.252 (0.252)	Loss 0.3009 (0.3009)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.122 (0.113)	Data 0.000 (0.004)	Loss 0.3049 (0.3071)	Acc@1 95.312 (94.591)	Acc@5 100.000 (99.922)
Epoch: [128][128/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.2834 (0.3139)	Acc@1 94.531 (94.244)	Acc@5 100.000 (99.918)
Epoch: [128][192/196]	Time 0.112 (0.112)	Data 0.000 (0.001)	Loss 0.2697 (0.3151)	Acc@1 95.703 (94.193)	Acc@5 100.000 (99.915)
Max memory in training epoch: 47.5566592
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.140 (0.140)	Data 0.291 (0.291)	Loss 0.2967 (0.2967)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.105 (0.112)	Data 0.000 (0.005)	Loss 0.3269 (0.3224)	Acc@1 94.922 (93.816)	Acc@5 100.000 (99.904)
Epoch: [129][128/196]	Time 0.118 (0.112)	Data 0.000 (0.002)	Loss 0.2776 (0.3153)	Acc@1 96.484 (94.044)	Acc@5 100.000 (99.888)
Epoch: [129][192/196]	Time 0.119 (0.112)	Data 0.000 (0.002)	Loss 0.2802 (0.3179)	Acc@1 96.094 (93.902)	Acc@5 100.000 (99.897)
Max memory in training epoch: 47.5566592
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.159 (0.159)	Data 0.268 (0.268)	Loss 0.4039 (0.4039)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [130][64/196]	Time 0.107 (0.112)	Data 0.000 (0.004)	Loss 0.3225 (0.3066)	Acc@1 94.922 (94.621)	Acc@5 100.000 (99.904)
Epoch: [130][128/196]	Time 0.107 (0.112)	Data 0.000 (0.002)	Loss 0.3351 (0.3059)	Acc@1 93.750 (94.574)	Acc@5 100.000 (99.915)
Epoch: [130][192/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.3864 (0.3109)	Acc@1 93.750 (94.305)	Acc@5 99.609 (99.919)
Max memory in training epoch: 47.5566592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 176207 ; 183798 ; 0.9586992241482497
[INFO] Storing checkpoint...
  89.71
Max memory: 74.1929472
 22.143s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 193
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.0778752
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.186 (0.186)	Data 0.255 (0.255)	Loss 0.3384 (0.3384)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.112 (0.116)	Data 0.000 (0.004)	Loss 0.2827 (0.3132)	Acc@1 95.312 (93.966)	Acc@5 100.000 (99.928)
Epoch: [131][128/196]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.3238 (0.3179)	Acc@1 94.531 (93.868)	Acc@5 100.000 (99.903)
Epoch: [131][192/196]	Time 0.107 (0.113)	Data 0.000 (0.002)	Loss 0.3876 (0.3235)	Acc@1 89.844 (93.631)	Acc@5 100.000 (99.901)
Max memory in training epoch: 47.1619072
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.160 (0.160)	Data 0.294 (0.294)	Loss 0.2725 (0.2725)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.112 (0.112)	Data 0.000 (0.005)	Loss 0.3125 (0.3135)	Acc@1 93.750 (94.135)	Acc@5 99.609 (99.922)
Epoch: [132][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.3499 (0.3160)	Acc@1 93.750 (93.926)	Acc@5 100.000 (99.909)
Epoch: [132][192/196]	Time 0.102 (0.110)	Data 0.000 (0.002)	Loss 0.4376 (0.3184)	Acc@1 89.453 (93.839)	Acc@5 99.609 (99.909)
Max memory in training epoch: 47.3870848
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.130 (0.130)	Data 0.308 (0.308)	Loss 0.2792 (0.2792)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.114 (0.110)	Data 0.000 (0.005)	Loss 0.3316 (0.3068)	Acc@1 93.359 (94.291)	Acc@5 100.000 (99.940)
Epoch: [133][128/196]	Time 0.116 (0.111)	Data 0.000 (0.003)	Loss 0.2549 (0.3113)	Acc@1 96.094 (94.041)	Acc@5 100.000 (99.921)
Epoch: [133][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.3198 (0.3157)	Acc@1 92.969 (93.894)	Acc@5 100.000 (99.897)
Max memory in training epoch: 47.3870848
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.171 (0.171)	Data 0.269 (0.269)	Loss 0.3012 (0.3012)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.108 (0.111)	Data 0.000 (0.004)	Loss 0.2896 (0.3124)	Acc@1 95.703 (93.984)	Acc@5 100.000 (99.916)
Epoch: [134][128/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.2464 (0.3130)	Acc@1 96.484 (93.998)	Acc@5 100.000 (99.915)
Epoch: [134][192/196]	Time 0.105 (0.111)	Data 0.000 (0.002)	Loss 0.3013 (0.3138)	Acc@1 94.922 (94.054)	Acc@5 100.000 (99.913)
Max memory in training epoch: 47.3870848
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.134 (0.134)	Data 0.257 (0.257)	Loss 0.3137 (0.3137)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.107 (0.113)	Data 0.000 (0.004)	Loss 0.3241 (0.3082)	Acc@1 93.750 (94.309)	Acc@5 100.000 (99.952)
Epoch: [135][128/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3312 (0.3144)	Acc@1 92.969 (94.053)	Acc@5 100.000 (99.942)
Epoch: [135][192/196]	Time 0.105 (0.110)	Data 0.000 (0.001)	Loss 0.2981 (0.3160)	Acc@1 94.531 (94.011)	Acc@5 100.000 (99.919)
Max memory in training epoch: 47.3870848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 170329 ; 176207 ; 0.966641506864086
[INFO] Storing checkpoint...
  87.81
Max memory: 73.7778176
 21.917s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7445
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.0756736
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.195 (0.195)	Data 0.266 (0.266)	Loss 0.3159 (0.3159)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.110 (0.114)	Data 0.000 (0.004)	Loss 0.2690 (0.2996)	Acc@1 96.875 (94.483)	Acc@5 100.000 (99.952)
Epoch: [136][128/196]	Time 0.109 (0.113)	Data 0.000 (0.002)	Loss 0.3639 (0.3111)	Acc@1 92.578 (94.038)	Acc@5 100.000 (99.927)
Epoch: [136][192/196]	Time 0.116 (0.113)	Data 0.000 (0.002)	Loss 0.3463 (0.3170)	Acc@1 93.359 (93.863)	Acc@5 100.000 (99.927)
Max memory in training epoch: 47.1116288
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.140 (0.140)	Data 0.289 (0.289)	Loss 0.3150 (0.3150)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [137][64/196]	Time 0.116 (0.115)	Data 0.000 (0.005)	Loss 0.3831 (0.3212)	Acc@1 91.797 (93.798)	Acc@5 98.828 (99.886)
Epoch: [137][128/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3286 (0.3190)	Acc@1 92.188 (93.811)	Acc@5 100.000 (99.906)
Epoch: [137][192/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.2871 (0.3205)	Acc@1 96.094 (93.732)	Acc@5 100.000 (99.901)
Max memory in training epoch: 47.3258496
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.159 (0.159)	Data 0.292 (0.292)	Loss 0.3017 (0.3017)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [138][64/196]	Time 0.110 (0.114)	Data 0.000 (0.005)	Loss 0.3084 (0.3102)	Acc@1 94.141 (94.075)	Acc@5 100.000 (99.916)
Epoch: [138][128/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.2531 (0.3149)	Acc@1 96.484 (93.853)	Acc@5 100.000 (99.894)
Epoch: [138][192/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.3086 (0.3181)	Acc@1 94.922 (93.772)	Acc@5 100.000 (99.893)
Max memory in training epoch: 47.3258496
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.138 (0.138)	Data 0.297 (0.297)	Loss 0.3470 (0.3470)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.111 (0.114)	Data 0.000 (0.005)	Loss 0.3301 (0.3145)	Acc@1 93.359 (93.972)	Acc@5 100.000 (99.922)
Epoch: [139][128/196]	Time 0.107 (0.113)	Data 0.000 (0.002)	Loss 0.3158 (0.3170)	Acc@1 94.141 (93.786)	Acc@5 100.000 (99.927)
Epoch: [139][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.3390 (0.3211)	Acc@1 92.578 (93.612)	Acc@5 100.000 (99.931)
Max memory in training epoch: 47.3258496
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.145 (0.145)	Data 0.305 (0.305)	Loss 0.2557 (0.2557)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.123 (0.114)	Data 0.000 (0.005)	Loss 0.2937 (0.3089)	Acc@1 95.312 (93.960)	Acc@5 100.000 (99.940)
Epoch: [140][128/196]	Time 0.108 (0.114)	Data 0.000 (0.003)	Loss 0.2784 (0.3100)	Acc@1 95.312 (94.013)	Acc@5 100.000 (99.930)
Epoch: [140][192/196]	Time 0.108 (0.113)	Data 0.000 (0.002)	Loss 0.2920 (0.3144)	Acc@1 94.922 (93.892)	Acc@5 100.000 (99.917)
Max memory in training epoch: 47.3258496
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 169481 ; 170329 ; 0.9950213997616377
[INFO] Storing checkpoint...
  88.89
Max memory: 73.5978496
 22.628s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5773
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0753152
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.168 (0.168)	Data 0.287 (0.287)	Loss 0.3086 (0.3086)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.110 (0.112)	Data 0.000 (0.005)	Loss 0.2977 (0.3012)	Acc@1 95.312 (94.423)	Acc@5 100.000 (99.922)
Epoch: [141][128/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.2760 (0.3083)	Acc@1 95.703 (94.150)	Acc@5 100.000 (99.903)
Epoch: [141][192/196]	Time 0.115 (0.111)	Data 0.000 (0.002)	Loss 0.3867 (0.3117)	Acc@1 92.188 (94.031)	Acc@5 100.000 (99.911)
Max memory in training epoch: 47.110912
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.160 (0.160)	Data 0.256 (0.256)	Loss 0.2598 (0.2598)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.115 (0.113)	Data 0.000 (0.004)	Loss 0.2696 (0.3091)	Acc@1 95.703 (94.159)	Acc@5 100.000 (99.946)
Epoch: [142][128/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.2507 (0.3115)	Acc@1 96.484 (94.013)	Acc@5 100.000 (99.924)
Epoch: [142][192/196]	Time 0.106 (0.113)	Data 0.000 (0.001)	Loss 0.3756 (0.3147)	Acc@1 92.578 (93.906)	Acc@5 99.609 (99.911)
Max memory in training epoch: 47.3178624
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.152 (0.152)	Data 0.272 (0.272)	Loss 0.3388 (0.3388)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.112 (0.111)	Data 0.000 (0.004)	Loss 0.3096 (0.3100)	Acc@1 94.141 (94.177)	Acc@5 100.000 (99.940)
Epoch: [143][128/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.2652 (0.3106)	Acc@1 95.312 (94.047)	Acc@5 100.000 (99.924)
Epoch: [143][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.2795 (0.3121)	Acc@1 94.922 (94.017)	Acc@5 100.000 (99.921)
Max memory in training epoch: 47.3178624
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.143 (0.143)	Data 0.292 (0.292)	Loss 0.2888 (0.2888)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.110 (0.110)	Data 0.000 (0.005)	Loss 0.3001 (0.3042)	Acc@1 94.531 (94.261)	Acc@5 99.609 (99.928)
Epoch: [144][128/196]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.3051 (0.3071)	Acc@1 93.750 (94.256)	Acc@5 100.000 (99.924)
Epoch: [144][192/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.3101 (0.3109)	Acc@1 94.922 (94.114)	Acc@5 100.000 (99.921)
Max memory in training epoch: 47.3178624
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.134 (0.134)	Data 0.292 (0.292)	Loss 0.2942 (0.2942)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [145][64/196]	Time 0.116 (0.112)	Data 0.000 (0.005)	Loss 0.2894 (0.3048)	Acc@1 94.922 (94.183)	Acc@5 100.000 (99.904)
Epoch: [145][128/196]	Time 0.105 (0.112)	Data 0.000 (0.002)	Loss 0.3138 (0.3100)	Acc@1 94.531 (93.983)	Acc@5 100.000 (99.924)
Epoch: [145][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.4280 (0.3123)	Acc@1 91.797 (93.944)	Acc@5 99.609 (99.913)
Max memory in training epoch: 47.3178624
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 167072 ; 169481 ; 0.985786017311675
[INFO] Storing checkpoint...
  88.44
Max memory: 74.0076032
 22.228s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3066
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0743936
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.165 (0.165)	Data 0.288 (0.288)	Loss 0.2450 (0.2450)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.109 (0.113)	Data 0.000 (0.005)	Loss 0.2653 (0.3038)	Acc@1 96.094 (94.363)	Acc@5 100.000 (99.898)
Epoch: [146][128/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3734 (0.3126)	Acc@1 91.016 (94.104)	Acc@5 99.609 (99.903)
Epoch: [146][192/196]	Time 0.113 (0.111)	Data 0.000 (0.002)	Loss 0.3312 (0.3193)	Acc@1 94.141 (93.857)	Acc@5 100.000 (99.895)
Max memory in training epoch: 47.0959616
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.149 (0.149)	Data 0.267 (0.267)	Loss 0.2900 (0.2900)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.113 (0.113)	Data 0.000 (0.004)	Loss 0.2986 (0.3147)	Acc@1 93.750 (93.918)	Acc@5 100.000 (99.886)
Epoch: [147][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.3674 (0.3149)	Acc@1 93.359 (93.826)	Acc@5 99.219 (99.882)
Epoch: [147][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3087 (0.3157)	Acc@1 93.359 (93.799)	Acc@5 100.000 (99.887)
Max memory in training epoch: 47.3076224
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.155 (0.155)	Data 0.272 (0.272)	Loss 0.2822 (0.2822)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.109 (0.111)	Data 0.000 (0.004)	Loss 0.2891 (0.2983)	Acc@1 95.703 (94.501)	Acc@5 100.000 (99.946)
Epoch: [148][128/196]	Time 0.111 (0.110)	Data 0.000 (0.002)	Loss 0.3835 (0.3086)	Acc@1 90.625 (94.086)	Acc@5 100.000 (99.918)
Epoch: [148][192/196]	Time 0.116 (0.110)	Data 0.000 (0.002)	Loss 0.3642 (0.3128)	Acc@1 92.969 (93.948)	Acc@5 100.000 (99.921)
Max memory in training epoch: 47.2945152
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.161 (0.161)	Data 0.307 (0.307)	Loss 0.3247 (0.3247)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.113 (0.115)	Data 0.000 (0.005)	Loss 0.3048 (0.3017)	Acc@1 94.531 (94.411)	Acc@5 99.219 (99.874)
Epoch: [149][128/196]	Time 0.122 (0.113)	Data 0.000 (0.003)	Loss 0.2597 (0.3077)	Acc@1 95.312 (94.180)	Acc@5 100.000 (99.882)
Epoch: [149][192/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.3516 (0.3136)	Acc@1 92.578 (93.956)	Acc@5 100.000 (99.895)
Max memory in training epoch: 47.2945152
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.141 (0.141)	Data 0.268 (0.268)	Loss 0.3258 (0.3258)	Acc@1 92.578 (92.578)	Acc@5 99.219 (99.219)
Epoch: [150][64/196]	Time 0.115 (0.111)	Data 0.000 (0.004)	Loss 0.2605 (0.2864)	Acc@1 97.656 (95.018)	Acc@5 100.000 (99.910)
Epoch: [150][128/196]	Time 0.115 (0.109)	Data 0.000 (0.002)	Loss 0.2955 (0.2765)	Acc@1 94.922 (95.400)	Acc@5 100.000 (99.933)
Epoch: [150][192/196]	Time 0.109 (0.109)	Data 0.000 (0.002)	Loss 0.2458 (0.2712)	Acc@1 96.094 (95.559)	Acc@5 100.000 (99.945)
Max memory in training epoch: 47.2945152
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 166224 ; 167072 ; 0.9949243439954032
[INFO] Storing checkpoint...
  91.12
Max memory: 73.635584
 21.750s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1053
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0740352
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.189 (0.189)	Data 0.277 (0.277)	Loss 0.2364 (0.2364)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.108 (0.114)	Data 0.000 (0.004)	Loss 0.2817 (0.2462)	Acc@1 94.531 (96.550)	Acc@5 100.000 (99.976)
Epoch: [151][128/196]	Time 0.107 (0.112)	Data 0.000 (0.002)	Loss 0.2356 (0.2472)	Acc@1 97.266 (96.533)	Acc@5 99.609 (99.961)
Epoch: [151][192/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.2473 (0.2472)	Acc@1 96.875 (96.472)	Acc@5 100.000 (99.957)
Max memory in training epoch: 47.0952448
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.147 (0.147)	Data 0.279 (0.279)	Loss 0.2634 (0.2634)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.107 (0.115)	Data 0.000 (0.004)	Loss 0.2776 (0.2379)	Acc@1 94.922 (96.827)	Acc@5 100.000 (99.964)
Epoch: [152][128/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.1946 (0.2393)	Acc@1 98.828 (96.817)	Acc@5 100.000 (99.967)
Epoch: [152][192/196]	Time 0.106 (0.113)	Data 0.000 (0.002)	Loss 0.2390 (0.2386)	Acc@1 96.875 (96.839)	Acc@5 100.000 (99.964)
Max memory in training epoch: 47.2996352
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.166 (0.166)	Data 0.306 (0.306)	Loss 0.3013 (0.3013)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [153][64/196]	Time 0.117 (0.113)	Data 0.000 (0.005)	Loss 0.2241 (0.2336)	Acc@1 97.266 (96.893)	Acc@5 100.000 (99.970)
Epoch: [153][128/196]	Time 0.107 (0.112)	Data 0.000 (0.003)	Loss 0.2464 (0.2346)	Acc@1 96.094 (96.896)	Acc@5 100.000 (99.973)
Epoch: [153][192/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.2244 (0.2340)	Acc@1 97.656 (96.905)	Acc@5 100.000 (99.964)
Max memory in training epoch: 47.2996352
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.146 (0.146)	Data 0.323 (0.323)	Loss 0.2348 (0.2348)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.113 (0.113)	Data 0.000 (0.005)	Loss 0.2315 (0.2289)	Acc@1 96.875 (97.019)	Acc@5 100.000 (99.970)
Epoch: [154][128/196]	Time 0.115 (0.114)	Data 0.000 (0.003)	Loss 0.2251 (0.2313)	Acc@1 96.875 (96.987)	Acc@5 100.000 (99.967)
Epoch: [154][192/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.2551 (0.2310)	Acc@1 95.312 (96.980)	Acc@5 100.000 (99.970)
Max memory in training epoch: 47.2996352
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.135 (0.135)	Data 0.283 (0.283)	Loss 0.2305 (0.2305)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.105 (0.115)	Data 0.000 (0.005)	Loss 0.2267 (0.2256)	Acc@1 96.875 (97.206)	Acc@5 100.000 (99.982)
Epoch: [155][128/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.2133 (0.2269)	Acc@1 97.656 (97.163)	Acc@5 100.000 (99.973)
Epoch: [155][192/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.1957 (0.2258)	Acc@1 99.219 (97.219)	Acc@5 100.000 (99.978)
Max memory in training epoch: 47.2996352
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.74
Max memory: 73.327104
 22.385s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9565
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0740352
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.163 (0.163)	Data 0.296 (0.296)	Loss 0.2012 (0.2012)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.112 (0.113)	Data 0.000 (0.005)	Loss 0.2289 (0.2217)	Acc@1 96.484 (97.326)	Acc@5 100.000 (99.970)
Epoch: [156][128/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.2104 (0.2222)	Acc@1 97.266 (97.299)	Acc@5 100.000 (99.970)
Epoch: [156][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.2202 (0.2230)	Acc@1 97.656 (97.310)	Acc@5 100.000 (99.976)
Max memory in training epoch: 47.0952448
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.135 (0.135)	Data 0.286 (0.286)	Loss 0.2079 (0.2079)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.111 (0.114)	Data 0.000 (0.005)	Loss 0.2142 (0.2215)	Acc@1 97.656 (97.446)	Acc@5 100.000 (99.976)
Epoch: [157][128/196]	Time 0.105 (0.113)	Data 0.000 (0.002)	Loss 0.2227 (0.2220)	Acc@1 96.484 (97.405)	Acc@5 100.000 (99.970)
Epoch: [157][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.2529 (0.2208)	Acc@1 96.875 (97.389)	Acc@5 100.000 (99.978)
Max memory in training epoch: 47.2996352
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.138 (0.138)	Data 0.266 (0.266)	Loss 0.2301 (0.2301)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.115 (0.114)	Data 0.000 (0.004)	Loss 0.2587 (0.2175)	Acc@1 96.875 (97.560)	Acc@5 100.000 (99.976)
Epoch: [158][128/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.1801 (0.2177)	Acc@1 99.219 (97.481)	Acc@5 100.000 (99.982)
Epoch: [158][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.2132 (0.2182)	Acc@1 97.266 (97.452)	Acc@5 100.000 (99.974)
Max memory in training epoch: 47.2996352
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.140 (0.140)	Data 0.277 (0.277)	Loss 0.2375 (0.2375)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.108 (0.114)	Data 0.000 (0.004)	Loss 0.2254 (0.2158)	Acc@1 97.656 (97.614)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.2166 (0.2147)	Acc@1 96.875 (97.632)	Acc@5 100.000 (99.988)
Epoch: [159][192/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.2545 (0.2166)	Acc@1 96.875 (97.517)	Acc@5 100.000 (99.984)
Max memory in training epoch: 47.2996352
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.141 (0.141)	Data 0.278 (0.278)	Loss 0.2381 (0.2381)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.113 (0.113)	Data 0.000 (0.004)	Loss 0.2239 (0.2120)	Acc@1 96.094 (97.692)	Acc@5 100.000 (99.982)
Epoch: [160][128/196]	Time 0.119 (0.113)	Data 0.000 (0.002)	Loss 0.2227 (0.2124)	Acc@1 96.484 (97.614)	Acc@5 100.000 (99.988)
Epoch: [160][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.2214 (0.2127)	Acc@1 96.875 (97.632)	Acc@5 100.000 (99.992)
Max memory in training epoch: 47.2996352
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 165374 ; 166224 ; 0.9948864183270767
[INFO] Storing checkpoint...
  91.7
Max memory: 73.327104
 22.269s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8740
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.073728
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.193 (0.193)	Data 0.262 (0.262)	Loss 0.2371 (0.2371)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.104 (0.115)	Data 0.000 (0.004)	Loss 0.2106 (0.2198)	Acc@1 98.047 (97.386)	Acc@5 100.000 (99.982)
Epoch: [161][128/196]	Time 0.119 (0.112)	Data 0.000 (0.002)	Loss 0.2155 (0.2183)	Acc@1 98.438 (97.384)	Acc@5 100.000 (99.982)
Epoch: [161][192/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.2057 (0.2184)	Acc@1 97.656 (97.353)	Acc@5 100.000 (99.986)
Max memory in training epoch: 46.6752
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.134 (0.134)	Data 0.293 (0.293)	Loss 0.1751 (0.1751)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.112 (0.113)	Data 0.000 (0.005)	Loss 0.1957 (0.2137)	Acc@1 98.828 (97.506)	Acc@5 100.000 (99.994)
Epoch: [162][128/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.2162 (0.2144)	Acc@1 97.266 (97.514)	Acc@5 100.000 (99.982)
Epoch: [162][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.2026 (0.2137)	Acc@1 98.438 (97.549)	Acc@5 100.000 (99.982)
Max memory in training epoch: 46.7937792
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.162 (0.162)	Data 0.274 (0.274)	Loss 0.2447 (0.2447)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.123 (0.113)	Data 0.000 (0.004)	Loss 0.2122 (0.2082)	Acc@1 97.656 (97.734)	Acc@5 100.000 (99.988)
Epoch: [163][128/196]	Time 0.115 (0.112)	Data 0.000 (0.002)	Loss 0.2367 (0.2119)	Acc@1 96.094 (97.587)	Acc@5 100.000 (99.982)
Epoch: [163][192/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.2261 (0.2128)	Acc@1 96.484 (97.537)	Acc@5 100.000 (99.986)
Max memory in training epoch: 46.846208
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.167 (0.167)	Data 0.305 (0.305)	Loss 0.1939 (0.1939)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.112 (0.113)	Data 0.000 (0.005)	Loss 0.2168 (0.2079)	Acc@1 97.656 (97.686)	Acc@5 100.000 (99.988)
Epoch: [164][128/196]	Time 0.109 (0.112)	Data 0.000 (0.003)	Loss 0.2252 (0.2091)	Acc@1 96.875 (97.581)	Acc@5 100.000 (99.991)
Epoch: [164][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.2375 (0.2100)	Acc@1 96.875 (97.559)	Acc@5 100.000 (99.984)
Max memory in training epoch: 46.846208
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.161 (0.161)	Data 0.297 (0.297)	Loss 0.2392 (0.2392)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.111 (0.113)	Data 0.000 (0.005)	Loss 0.1974 (0.2054)	Acc@1 98.047 (97.806)	Acc@5 100.000 (99.982)
Epoch: [165][128/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.1885 (0.2067)	Acc@1 98.828 (97.756)	Acc@5 100.000 (99.979)
Epoch: [165][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.1999 (0.2076)	Acc@1 98.438 (97.733)	Acc@5 100.000 (99.978)
Max memory in training epoch: 46.846208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 163563 ; 165374 ; 0.989049064544608
[INFO] Storing checkpoint...
  91.41
Max memory: 73.407488
 22.577s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3400
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0730112
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.151 (0.151)	Data 0.287 (0.287)	Loss 0.2097 (0.2097)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.2010 (0.2060)	Acc@1 97.266 (97.788)	Acc@5 100.000 (99.988)
Epoch: [166][128/196]	Time 0.105 (0.111)	Data 0.000 (0.002)	Loss 0.1957 (0.2068)	Acc@1 98.828 (97.753)	Acc@5 100.000 (99.979)
Epoch: [166][192/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.2251 (0.2089)	Acc@1 97.266 (97.640)	Acc@5 100.000 (99.974)
Max memory in training epoch: 46.6467328
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.169 (0.169)	Data 0.262 (0.262)	Loss 0.2003 (0.2003)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.115 (0.113)	Data 0.000 (0.004)	Loss 0.2508 (0.2077)	Acc@1 94.922 (97.788)	Acc@5 100.000 (99.994)
Epoch: [167][128/196]	Time 0.126 (0.112)	Data 0.000 (0.002)	Loss 0.2320 (0.2097)	Acc@1 97.656 (97.614)	Acc@5 100.000 (99.985)
Epoch: [167][192/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.2238 (0.2077)	Acc@1 96.875 (97.703)	Acc@5 100.000 (99.986)
Max memory in training epoch: 46.7646976
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.151 (0.151)	Data 0.311 (0.311)	Loss 0.1837 (0.1837)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.103 (0.112)	Data 0.000 (0.005)	Loss 0.2136 (0.2049)	Acc@1 96.875 (97.716)	Acc@5 100.000 (99.994)
Epoch: [168][128/196]	Time 0.132 (0.112)	Data 0.000 (0.003)	Loss 0.2200 (0.2050)	Acc@1 97.656 (97.735)	Acc@5 100.000 (99.985)
Epoch: [168][192/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.1807 (0.2064)	Acc@1 98.438 (97.674)	Acc@5 100.000 (99.982)
Max memory in training epoch: 46.7646976
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.152 (0.152)	Data 0.309 (0.309)	Loss 0.1912 (0.1912)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.117 (0.113)	Data 0.000 (0.005)	Loss 0.1760 (0.1990)	Acc@1 100.000 (98.089)	Acc@5 100.000 (99.982)
Epoch: [169][128/196]	Time 0.113 (0.113)	Data 0.000 (0.003)	Loss 0.2266 (0.2022)	Acc@1 96.094 (97.959)	Acc@5 100.000 (99.988)
Epoch: [169][192/196]	Time 0.106 (0.112)	Data 0.000 (0.002)	Loss 0.2354 (0.2033)	Acc@1 97.266 (97.895)	Acc@5 100.000 (99.986)
Max memory in training epoch: 46.7646976
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.160 (0.160)	Data 0.279 (0.279)	Loss 0.1941 (0.1941)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.111 (0.113)	Data 0.000 (0.004)	Loss 0.2023 (0.1963)	Acc@1 98.047 (98.167)	Acc@5 100.000 (99.976)
Epoch: [170][128/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.2017 (0.2007)	Acc@1 98.047 (97.920)	Acc@5 100.000 (99.970)
Epoch: [170][192/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.2047 (0.2021)	Acc@1 98.438 (97.881)	Acc@5 100.000 (99.976)
Max memory in training epoch: 46.7646976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 160209 ; 163563 ; 0.9794941398727096
[INFO] Storing checkpoint...
  91.53
Max memory: 73.317888
 22.212s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8433
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.07168
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.194 (0.194)	Data 0.257 (0.257)	Loss 0.2544 (0.2544)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.116 (0.117)	Data 0.000 (0.004)	Loss 0.2055 (0.2128)	Acc@1 98.047 (97.428)	Acc@5 100.000 (99.976)
Epoch: [171][128/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2198 (0.2130)	Acc@1 96.484 (97.393)	Acc@5 100.000 (99.967)
Epoch: [171][192/196]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.2039 (0.2125)	Acc@1 97.266 (97.361)	Acc@5 100.000 (99.974)
Max memory in training epoch: 46.60864
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.158 (0.158)	Data 0.306 (0.306)	Loss 0.2164 (0.2164)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.112 (0.112)	Data 0.000 (0.005)	Loss 0.1789 (0.2039)	Acc@1 98.828 (97.704)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.106 (0.112)	Data 0.000 (0.003)	Loss 0.2340 (0.2037)	Acc@1 96.484 (97.699)	Acc@5 100.000 (99.994)
Epoch: [172][192/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.2099 (0.2052)	Acc@1 96.484 (97.628)	Acc@5 100.000 (99.992)
Max memory in training epoch: 46.7266048
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.148 (0.148)	Data 0.261 (0.261)	Loss 0.2131 (0.2131)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.117 (0.112)	Data 0.000 (0.004)	Loss 0.1925 (0.2073)	Acc@1 98.438 (97.524)	Acc@5 100.000 (99.982)
Epoch: [173][128/196]	Time 0.115 (0.112)	Data 0.000 (0.002)	Loss 0.2013 (0.2047)	Acc@1 98.047 (97.638)	Acc@5 100.000 (99.973)
Epoch: [173][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.2504 (0.2042)	Acc@1 96.094 (97.715)	Acc@5 99.609 (99.974)
Max memory in training epoch: 46.7266048
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.142 (0.142)	Data 0.291 (0.291)	Loss 0.2393 (0.2393)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.105 (0.113)	Data 0.000 (0.005)	Loss 0.1977 (0.2036)	Acc@1 98.047 (97.674)	Acc@5 100.000 (99.982)
Epoch: [174][128/196]	Time 0.115 (0.112)	Data 0.000 (0.002)	Loss 0.2400 (0.2030)	Acc@1 96.094 (97.690)	Acc@5 100.000 (99.982)
Epoch: [174][192/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.1673 (0.2019)	Acc@1 99.609 (97.735)	Acc@5 100.000 (99.980)
Max memory in training epoch: 46.7266048
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.150 (0.150)	Data 0.282 (0.282)	Loss 0.2105 (0.2105)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.118 (0.116)	Data 0.000 (0.005)	Loss 0.1851 (0.1996)	Acc@1 99.219 (97.819)	Acc@5 100.000 (99.982)
Epoch: [175][128/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.2275 (0.2011)	Acc@1 96.875 (97.768)	Acc@5 100.000 (99.985)
Epoch: [175][192/196]	Time 0.109 (0.113)	Data 0.000 (0.002)	Loss 0.1892 (0.2000)	Acc@1 97.656 (97.800)	Acc@5 100.000 (99.988)
Max memory in training epoch: 46.7266048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 157134 ; 160209 ; 0.9808063217422243
[INFO] Storing checkpoint...
  91.41
Max memory: 73.2729344
 22.477s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1504
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.0704512
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.170 (0.170)	Data 0.265 (0.265)	Loss 0.2087 (0.2087)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.107 (0.113)	Data 0.000 (0.004)	Loss 0.2046 (0.2079)	Acc@1 98.438 (97.554)	Acc@5 100.000 (99.988)
Epoch: [176][128/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.2077 (0.2103)	Acc@1 97.266 (97.366)	Acc@5 100.000 (99.979)
Epoch: [176][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.1951 (0.2090)	Acc@1 97.656 (97.440)	Acc@5 100.000 (99.972)
Max memory in training epoch: 46.584064
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.170 (0.170)	Data 0.281 (0.281)	Loss 0.2526 (0.2526)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.106 (0.113)	Data 0.000 (0.005)	Loss 0.2025 (0.2029)	Acc@1 98.438 (97.650)	Acc@5 100.000 (99.994)
Epoch: [177][128/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.2083 (0.2043)	Acc@1 96.875 (97.562)	Acc@5 100.000 (99.997)
Epoch: [177][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.2207 (0.2048)	Acc@1 96.094 (97.533)	Acc@5 100.000 (99.988)
Max memory in training epoch: 46.6954752
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.152 (0.152)	Data 0.295 (0.295)	Loss 0.2089 (0.2089)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.115 (0.112)	Data 0.000 (0.005)	Loss 0.2239 (0.2035)	Acc@1 97.266 (97.482)	Acc@5 100.000 (99.976)
Epoch: [178][128/196]	Time 0.135 (0.112)	Data 0.000 (0.002)	Loss 0.1834 (0.2030)	Acc@1 98.438 (97.523)	Acc@5 100.000 (99.988)
Epoch: [178][192/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.1768 (0.2023)	Acc@1 99.219 (97.565)	Acc@5 100.000 (99.984)
Max memory in training epoch: 46.6954752
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.165 (0.165)	Data 0.298 (0.298)	Loss 0.2076 (0.2076)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.115 (0.113)	Data 0.000 (0.005)	Loss 0.1798 (0.1991)	Acc@1 98.828 (97.734)	Acc@5 100.000 (99.982)
Epoch: [179][128/196]	Time 0.109 (0.112)	Data 0.000 (0.003)	Loss 0.2062 (0.1983)	Acc@1 97.656 (97.750)	Acc@5 99.609 (99.982)
Epoch: [179][192/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.2039 (0.1996)	Acc@1 98.047 (97.731)	Acc@5 100.000 (99.984)
Max memory in training epoch: 46.6954752
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.145 (0.145)	Data 0.298 (0.298)	Loss 0.1695 (0.1695)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.111 (0.112)	Data 0.000 (0.005)	Loss 0.2286 (0.1950)	Acc@1 96.094 (97.891)	Acc@5 100.000 (99.976)
Epoch: [180][128/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.2157 (0.1977)	Acc@1 96.094 (97.814)	Acc@5 100.000 (99.985)
Epoch: [180][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.2045 (0.1974)	Acc@1 98.828 (97.820)	Acc@5 99.609 (99.982)
Max memory in training epoch: 46.6954752
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 17, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(17, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(31, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(20, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(31, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(11, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(31, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(1, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(31, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(31, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(31, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(62, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(28, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(62, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(10, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(62, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(25, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=62, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  91.25
Max memory: 73.1164672
 22.172s  Thres 0.1 3
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6576
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.191 (0.191)	Data 0.273 (0.273)	Loss 3.0672 (3.0672)	Acc@1 9.766 (9.766)	Acc@5 49.609 (49.609)
Epoch: [1][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 2.2945 (2.6105)	Acc@1 32.031 (24.964)	Acc@5 87.891 (77.698)
Epoch: [1][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 2.1287 (2.4275)	Acc@1 42.188 (31.250)	Acc@5 90.234 (83.224)
Epoch: [1][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.8835 (2.2846)	Acc@1 46.484 (36.367)	Acc@5 96.484 (86.377)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.166 (0.166)	Data 0.290 (0.290)	Loss 1.8469 (1.8469)	Acc@1 53.906 (53.906)	Acc@5 93.359 (93.359)
Epoch: [2][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 1.7341 (1.8095)	Acc@1 57.812 (53.954)	Acc@5 95.703 (94.435)
Epoch: [2][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 1.5603 (1.7381)	Acc@1 63.672 (56.326)	Acc@5 96.484 (94.934)
Epoch: [2][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 1.5229 (1.6790)	Acc@1 61.328 (58.161)	Acc@5 96.094 (95.442)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.178 (0.178)	Data 0.299 (0.299)	Loss 1.5284 (1.5284)	Acc@1 57.422 (57.422)	Acc@5 98.828 (98.828)
Epoch: [3][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 1.3723 (1.4574)	Acc@1 70.312 (65.048)	Acc@5 98.828 (96.923)
Epoch: [3][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 1.2886 (1.4189)	Acc@1 73.828 (66.406)	Acc@5 98.438 (97.123)
Epoch: [3][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 1.3480 (1.3853)	Acc@1 70.312 (67.420)	Acc@5 97.266 (97.312)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.178 (0.178)	Data 0.322 (0.322)	Loss 1.2723 (1.2723)	Acc@1 71.094 (71.094)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.143 (0.129)	Data 0.000 (0.005)	Loss 1.2599 (1.2489)	Acc@1 70.703 (71.364)	Acc@5 97.266 (97.915)
Epoch: [4][128/196]	Time 0.126 (0.128)	Data 0.000 (0.003)	Loss 1.1259 (1.2246)	Acc@1 73.828 (71.984)	Acc@5 98.828 (98.110)
Epoch: [4][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 1.3321 (1.2070)	Acc@1 66.016 (72.660)	Acc@5 97.656 (98.104)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.186 (0.186)	Data 0.278 (0.278)	Loss 1.0605 (1.0605)	Acc@1 74.609 (74.609)	Acc@5 99.219 (99.219)
Epoch: [5][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.9817 (1.1018)	Acc@1 79.688 (75.385)	Acc@5 99.609 (98.582)
Epoch: [5][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 1.1243 (1.0884)	Acc@1 72.656 (75.924)	Acc@5 98.438 (98.537)
Epoch: [5][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 1.0714 (1.0777)	Acc@1 79.297 (76.218)	Acc@5 98.828 (98.547)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 360154 ; 487386 ; 0.7389502365681411
[INFO] Storing checkpoint...
  55.43
Max memory: 103.3835008
 25.665s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9868
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1519104
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.173 (0.173)	Data 0.292 (0.292)	Loss 1.0611 (1.0611)	Acc@1 75.781 (75.781)	Acc@5 98.438 (98.438)
Epoch: [6][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.9673 (1.0008)	Acc@1 78.516 (76.641)	Acc@5 98.828 (98.486)
Epoch: [6][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.9092 (0.9942)	Acc@1 78.125 (76.659)	Acc@5 99.609 (98.550)
Epoch: [6][192/196]	Time 0.140 (0.130)	Data 0.000 (0.002)	Loss 0.9015 (0.9841)	Acc@1 83.203 (77.038)	Acc@5 98.438 (98.579)
Max memory in training epoch: 65.186048
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.191 (0.191)	Data 0.277 (0.277)	Loss 0.8426 (0.8426)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.9654 (0.9284)	Acc@1 77.344 (78.690)	Acc@5 99.219 (98.720)
Epoch: [7][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8111 (0.9239)	Acc@1 81.641 (78.719)	Acc@5 98.828 (98.819)
Epoch: [7][192/196]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.8429 (0.9170)	Acc@1 82.031 (78.809)	Acc@5 98.047 (98.804)
Max memory in training epoch: 65.0811904
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.184 (0.184)	Data 0.304 (0.304)	Loss 0.8968 (0.8968)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.9386 (0.8609)	Acc@1 80.078 (80.457)	Acc@5 97.656 (99.099)
Epoch: [8][128/196]	Time 0.131 (0.131)	Data 0.000 (0.003)	Loss 0.8688 (0.8735)	Acc@1 78.906 (80.012)	Acc@5 99.609 (98.977)
Epoch: [8][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7124 (0.8708)	Acc@1 85.156 (80.030)	Acc@5 99.219 (98.939)
Max memory in training epoch: 65.0811904
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.188 (0.188)	Data 0.282 (0.282)	Loss 0.8606 (0.8606)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [9][64/196]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 0.8486 (0.8528)	Acc@1 81.250 (80.541)	Acc@5 97.656 (98.828)
Epoch: [9][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.8573 (0.8472)	Acc@1 78.516 (80.820)	Acc@5 99.219 (98.958)
Epoch: [9][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8776 (0.8421)	Acc@1 76.562 (80.823)	Acc@5 99.219 (98.980)
Max memory in training epoch: 65.0811904
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.187 (0.187)	Data 0.265 (0.265)	Loss 0.8634 (0.8634)	Acc@1 78.516 (78.516)	Acc@5 98.828 (98.828)
Epoch: [10][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.8772 (0.8362)	Acc@1 78.516 (80.823)	Acc@5 98.438 (98.900)
Epoch: [10][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7954 (0.8303)	Acc@1 81.250 (81.008)	Acc@5 99.219 (98.970)
Epoch: [10][192/196]	Time 0.136 (0.132)	Data 0.000 (0.002)	Loss 0.8209 (0.8276)	Acc@1 82.422 (81.094)	Acc@5 99.609 (98.956)
Max memory in training epoch: 65.0811904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 283964 ; 360154 ; 0.7884516068126413
[INFO] Storing checkpoint...
  71.56
Max memory: 101.422848
 26.198s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5693
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.1214464
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.186 (0.186)	Data 0.257 (0.257)	Loss 0.7437 (0.7437)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [11][64/196]	Time 0.124 (0.128)	Data 0.000 (0.004)	Loss 0.6875 (0.7959)	Acc@1 85.938 (80.907)	Acc@5 100.000 (99.020)
Epoch: [11][128/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.8767 (0.8126)	Acc@1 78.516 (80.496)	Acc@5 98.438 (98.904)
Epoch: [11][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.8098 (0.8095)	Acc@1 79.688 (80.677)	Acc@5 98.828 (98.899)
Max memory in training epoch: 63.2029696
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.163 (0.163)	Data 0.265 (0.265)	Loss 0.8148 (0.8148)	Acc@1 79.688 (79.688)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.7919 (0.8010)	Acc@1 78.125 (81.202)	Acc@5 100.000 (99.026)
Epoch: [12][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7303 (0.7959)	Acc@1 83.594 (81.480)	Acc@5 98.438 (98.937)
Epoch: [12][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7490 (0.7904)	Acc@1 83.203 (81.685)	Acc@5 99.609 (98.994)
Max memory in training epoch: 63.1374336
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.161 (0.161)	Data 0.283 (0.283)	Loss 0.7564 (0.7564)	Acc@1 83.203 (83.203)	Acc@5 98.438 (98.438)
Epoch: [13][64/196]	Time 0.119 (0.130)	Data 0.000 (0.005)	Loss 0.7753 (0.7697)	Acc@1 81.250 (82.506)	Acc@5 99.609 (99.153)
Epoch: [13][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7577 (0.7738)	Acc@1 83.203 (82.319)	Acc@5 100.000 (99.086)
Epoch: [13][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8860 (0.7745)	Acc@1 76.562 (82.201)	Acc@5 98.828 (99.069)
Max memory in training epoch: 63.1374336
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.166 (0.166)	Data 0.258 (0.258)	Loss 0.7571 (0.7571)	Acc@1 81.641 (81.641)	Acc@5 98.438 (98.438)
Epoch: [14][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7571 (0.7730)	Acc@1 82.031 (82.356)	Acc@5 99.219 (99.081)
Epoch: [14][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.7548 (0.7624)	Acc@1 84.766 (82.700)	Acc@5 98.828 (99.113)
Epoch: [14][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.7063 (0.7636)	Acc@1 84.375 (82.584)	Acc@5 99.219 (99.099)
Max memory in training epoch: 63.1374336
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.184 (0.184)	Data 0.294 (0.294)	Loss 0.7871 (0.7871)	Acc@1 82.422 (82.422)	Acc@5 98.438 (98.438)
Epoch: [15][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.7008 (0.7585)	Acc@1 86.328 (82.662)	Acc@5 98.828 (99.183)
Epoch: [15][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7041 (0.7583)	Acc@1 86.328 (82.758)	Acc@5 98.828 (99.110)
Epoch: [15][192/196]	Time 0.147 (0.130)	Data 0.000 (0.002)	Loss 0.7725 (0.7599)	Acc@1 85.156 (82.744)	Acc@5 98.438 (99.114)
Max memory in training epoch: 63.1374336
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 271822 ; 283964 ; 0.9572410587257539
[INFO] Storing checkpoint...
  67.83
Max memory: 98.4585216
 25.781s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5969
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1166848
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.197 (0.197)	Data 0.286 (0.286)	Loss 0.7638 (0.7638)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.7395 (0.7162)	Acc@1 81.641 (83.918)	Acc@5 100.000 (99.297)
Epoch: [16][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7990 (0.7340)	Acc@1 81.641 (83.318)	Acc@5 98.438 (99.216)
Epoch: [16][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.5904 (0.7382)	Acc@1 88.281 (83.310)	Acc@5 99.609 (99.190)
Max memory in training epoch: 61.8076672
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.174 (0.174)	Data 0.288 (0.288)	Loss 0.7706 (0.7706)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.7266 (0.7283)	Acc@1 82.031 (83.702)	Acc@5 98.438 (99.183)
Epoch: [17][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7509 (0.7457)	Acc@1 83.594 (83.082)	Acc@5 98.438 (99.134)
Epoch: [17][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.8084 (0.7478)	Acc@1 79.688 (83.068)	Acc@5 99.609 (99.130)
Max memory in training epoch: 61.7814528
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.160 (0.160)	Data 0.270 (0.270)	Loss 0.7530 (0.7530)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [18][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.7606 (0.7314)	Acc@1 79.688 (83.606)	Acc@5 99.219 (99.201)
Epoch: [18][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6480 (0.7337)	Acc@1 87.109 (83.642)	Acc@5 99.609 (99.201)
Epoch: [18][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.8389 (0.7403)	Acc@1 78.516 (83.262)	Acc@5 98.828 (99.164)
Max memory in training epoch: 61.7814528
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.171 (0.171)	Data 0.371 (0.371)	Loss 0.7287 (0.7287)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.148 (0.129)	Data 0.000 (0.006)	Loss 0.7092 (0.7330)	Acc@1 85.938 (83.534)	Acc@5 98.828 (99.249)
Epoch: [19][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.7785 (0.7399)	Acc@1 82.812 (83.321)	Acc@5 98.438 (99.188)
Epoch: [19][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6573 (0.7378)	Acc@1 85.938 (83.497)	Acc@5 99.609 (99.213)
Max memory in training epoch: 61.7814528
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.197 (0.197)	Data 0.292 (0.292)	Loss 0.8535 (0.8535)	Acc@1 78.906 (78.906)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.8298 (0.7197)	Acc@1 81.250 (84.026)	Acc@5 98.828 (99.213)
Epoch: [20][128/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.6790 (0.7221)	Acc@1 83.984 (83.951)	Acc@5 99.219 (99.285)
Epoch: [20][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7336 (0.7250)	Acc@1 84.766 (83.891)	Acc@5 98.438 (99.257)
Max memory in training epoch: 61.7814528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 267194 ; 271822 ; 0.9829741522025444
[INFO] Storing checkpoint...
  69.6
Max memory: 96.0546304
 25.793s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5787
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1150464
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.174 (0.174)	Data 0.280 (0.280)	Loss 0.7087 (0.7087)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [21][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.7199 (0.6890)	Acc@1 83.984 (85.030)	Acc@5 100.000 (99.363)
Epoch: [21][128/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6985 (0.7101)	Acc@1 82.812 (84.193)	Acc@5 100.000 (99.367)
Epoch: [21][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6836 (0.7164)	Acc@1 83.594 (84.077)	Acc@5 99.609 (99.312)
Max memory in training epoch: 60.29696
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.189 (0.189)	Data 0.282 (0.282)	Loss 0.6514 (0.6514)	Acc@1 88.672 (88.672)	Acc@5 98.438 (98.438)
Epoch: [22][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7866 (0.7196)	Acc@1 81.641 (83.840)	Acc@5 98.828 (99.189)
Epoch: [22][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6601 (0.7235)	Acc@1 84.375 (83.803)	Acc@5 99.219 (99.234)
Epoch: [22][192/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.7031 (0.7182)	Acc@1 83.984 (84.025)	Acc@5 99.609 (99.205)
Max memory in training epoch: 60.4641792
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.181 (0.181)	Data 0.286 (0.286)	Loss 0.7411 (0.7411)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [23][64/196]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.7116 (0.7098)	Acc@1 87.891 (84.303)	Acc@5 99.219 (99.285)
Epoch: [23][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7396 (0.7137)	Acc@1 82.812 (84.396)	Acc@5 99.219 (99.210)
Epoch: [23][192/196]	Time 0.144 (0.128)	Data 0.000 (0.002)	Loss 0.7984 (0.7185)	Acc@1 82.812 (84.227)	Acc@5 98.828 (99.209)
Max memory in training epoch: 60.4641792
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.176 (0.176)	Data 0.281 (0.281)	Loss 0.6889 (0.6889)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.8017 (0.6942)	Acc@1 82.812 (85.216)	Acc@5 98.828 (99.339)
Epoch: [24][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7046 (0.7115)	Acc@1 85.156 (84.405)	Acc@5 99.219 (99.304)
Epoch: [24][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7164 (0.7165)	Acc@1 83.984 (84.205)	Acc@5 99.219 (99.263)
Max memory in training epoch: 60.4641792
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.184 (0.184)	Data 0.282 (0.282)	Loss 0.7194 (0.7194)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6043 (0.7199)	Acc@1 89.062 (84.273)	Acc@5 100.000 (99.231)
Epoch: [25][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6886 (0.7168)	Acc@1 86.719 (84.236)	Acc@5 98.828 (99.279)
Epoch: [25][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6762 (0.7126)	Acc@1 84.375 (84.494)	Acc@5 99.609 (99.292)
Max memory in training epoch: 60.4641792
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 262282 ; 267194 ; 0.981616353660636
[INFO] Storing checkpoint...
  79.25
Max memory: 93.9492864
 25.460s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4506
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1132032
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.182 (0.182)	Data 0.259 (0.259)	Loss 0.7609 (0.7609)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6437 (0.6856)	Acc@1 86.719 (85.066)	Acc@5 100.000 (99.399)
Epoch: [26][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.8242 (0.6896)	Acc@1 80.859 (85.059)	Acc@5 98.828 (99.349)
Epoch: [26][192/196]	Time 0.125 (0.127)	Data 0.000 (0.001)	Loss 0.7602 (0.6988)	Acc@1 84.766 (84.782)	Acc@5 98.828 (99.324)
Max memory in training epoch: 60.0507904
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.197 (0.197)	Data 0.260 (0.260)	Loss 0.6063 (0.6063)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.7067 (0.6920)	Acc@1 82.422 (84.952)	Acc@5 98.828 (99.381)
Epoch: [27][128/196]	Time 0.118 (0.126)	Data 0.000 (0.002)	Loss 0.7064 (0.6982)	Acc@1 82.422 (84.608)	Acc@5 99.219 (99.304)
Epoch: [27][192/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6888 (0.7028)	Acc@1 84.766 (84.480)	Acc@5 99.219 (99.306)
Max memory in training epoch: 59.8931968
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.175 (0.175)	Data 0.264 (0.264)	Loss 0.6521 (0.6521)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.6647 (0.6932)	Acc@1 89.062 (84.856)	Acc@5 98.828 (99.381)
Epoch: [28][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6575 (0.7013)	Acc@1 87.500 (84.602)	Acc@5 98.438 (99.294)
Epoch: [28][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6117 (0.6979)	Acc@1 86.328 (84.717)	Acc@5 99.609 (99.300)
Max memory in training epoch: 59.8931968
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.154 (0.154)	Data 0.296 (0.296)	Loss 0.6786 (0.6786)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [29][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6295 (0.7085)	Acc@1 83.594 (84.153)	Acc@5 99.609 (99.321)
Epoch: [29][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6884 (0.6988)	Acc@1 84.375 (84.681)	Acc@5 100.000 (99.358)
Epoch: [29][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6802 (0.6990)	Acc@1 85.938 (84.604)	Acc@5 98.828 (99.342)
Max memory in training epoch: 59.8931968
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.170 (0.170)	Data 0.290 (0.290)	Loss 0.6798 (0.6798)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [30][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7123 (0.7267)	Acc@1 84.375 (83.726)	Acc@5 100.000 (99.267)
Epoch: [30][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6714 (0.7090)	Acc@1 86.719 (84.408)	Acc@5 99.609 (99.279)
Epoch: [30][192/196]	Time 0.134 (0.128)	Data 0.000 (0.002)	Loss 0.8362 (0.7033)	Acc@1 79.297 (84.640)	Acc@5 99.219 (99.332)
Max memory in training epoch: 59.8931968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 256218 ; 262282 ; 0.9768798468823633
[INFO] Storing checkpoint...
  70.24
Max memory: 93.1728896
 25.434s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5023
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1106432
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.197 (0.197)	Data 0.284 (0.284)	Loss 0.7471 (0.7471)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.7223 (0.6602)	Acc@1 83.203 (85.757)	Acc@5 99.609 (99.453)
Epoch: [31][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6495 (0.6764)	Acc@1 84.766 (85.256)	Acc@5 99.219 (99.385)
Epoch: [31][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6822 (0.6807)	Acc@1 82.812 (85.094)	Acc@5 99.219 (99.358)
Max memory in training epoch: 59.4504192
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.153 (0.153)	Data 0.259 (0.259)	Loss 0.6604 (0.6604)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.7068 (0.6929)	Acc@1 84.375 (84.820)	Acc@5 99.609 (99.333)
Epoch: [32][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.7312 (0.6937)	Acc@1 82.422 (84.750)	Acc@5 99.219 (99.367)
Epoch: [32][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6927 (0.6934)	Acc@1 85.547 (84.804)	Acc@5 99.609 (99.356)
Max memory in training epoch: 59.7387776
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.151 (0.151)	Data 0.275 (0.275)	Loss 0.6095 (0.6095)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.6635 (0.6791)	Acc@1 87.500 (85.703)	Acc@5 99.219 (99.273)
Epoch: [33][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.7668 (0.6849)	Acc@1 81.250 (85.289)	Acc@5 99.609 (99.313)
Epoch: [33][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7462 (0.6892)	Acc@1 82.812 (85.102)	Acc@5 99.609 (99.354)
Max memory in training epoch: 59.7387776
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.172 (0.172)	Data 0.285 (0.285)	Loss 0.6673 (0.6673)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.7133 (0.6951)	Acc@1 82.812 (84.802)	Acc@5 99.609 (99.309)
Epoch: [34][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.7152 (0.6951)	Acc@1 83.984 (84.972)	Acc@5 98.438 (99.301)
Epoch: [34][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6746 (0.6921)	Acc@1 87.109 (85.037)	Acc@5 98.438 (99.314)
Max memory in training epoch: 59.7387776
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.174 (0.174)	Data 0.267 (0.267)	Loss 0.7843 (0.7843)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [35][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.5881 (0.6799)	Acc@1 89.062 (85.535)	Acc@5 100.000 (99.339)
Epoch: [35][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.5941 (0.6902)	Acc@1 87.500 (85.153)	Acc@5 100.000 (99.349)
Epoch: [35][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7523 (0.6879)	Acc@1 83.594 (85.251)	Acc@5 98.828 (99.350)
Max memory in training epoch: 59.7387776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 251018 ; 256218 ; 0.979704782646028
[INFO] Storing checkpoint...
  73.93
Max memory: 92.9178112
 25.412s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2538
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1085952
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.197 (0.197)	Data 0.260 (0.260)	Loss 0.7124 (0.7124)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.7120 (0.6693)	Acc@1 85.156 (85.655)	Acc@5 99.609 (99.351)
Epoch: [36][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7014 (0.6778)	Acc@1 82.812 (85.299)	Acc@5 99.219 (99.346)
Epoch: [36][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7462 (0.6832)	Acc@1 82.422 (85.069)	Acc@5 99.219 (99.330)
Max memory in training epoch: 58.9441536
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.195 (0.195)	Data 0.257 (0.257)	Loss 0.6679 (0.6679)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.8242 (0.6880)	Acc@1 82.812 (85.222)	Acc@5 98.438 (99.261)
Epoch: [37][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6915 (0.6929)	Acc@1 84.766 (85.011)	Acc@5 98.828 (99.325)
Epoch: [37][192/196]	Time 0.127 (0.127)	Data 0.000 (0.001)	Loss 0.7250 (0.6947)	Acc@1 84.766 (84.972)	Acc@5 99.609 (99.257)
Max memory in training epoch: 58.6820096
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.147 (0.147)	Data 0.266 (0.266)	Loss 0.6813 (0.6813)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.124 (0.128)	Data 0.000 (0.004)	Loss 0.8141 (0.6520)	Acc@1 81.250 (86.232)	Acc@5 99.219 (99.453)
Epoch: [38][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7062 (0.6740)	Acc@1 85.547 (85.653)	Acc@5 100.000 (99.400)
Epoch: [38][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6954 (0.6778)	Acc@1 84.375 (85.628)	Acc@5 99.219 (99.375)
Max memory in training epoch: 58.6820096
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.180 (0.180)	Data 0.265 (0.265)	Loss 0.6686 (0.6686)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.7273 (0.6698)	Acc@1 84.766 (85.889)	Acc@5 98.047 (99.273)
Epoch: [39][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6181 (0.6693)	Acc@1 85.938 (85.889)	Acc@5 98.438 (99.325)
Epoch: [39][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7460 (0.6761)	Acc@1 85.156 (85.709)	Acc@5 99.219 (99.304)
Max memory in training epoch: 58.6820096
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.171 (0.171)	Data 0.291 (0.291)	Loss 0.6723 (0.6723)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.6862 (0.6972)	Acc@1 83.984 (84.856)	Acc@5 99.609 (99.375)
Epoch: [40][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.6885 (0.6997)	Acc@1 83.984 (84.766)	Acc@5 98.828 (99.340)
Epoch: [40][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7763 (0.7000)	Acc@1 82.031 (84.632)	Acc@5 99.609 (99.322)
Max memory in training epoch: 58.6820096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 247550 ; 251018 ; 0.9861842577026348
[INFO] Storing checkpoint...
  78.1
Max memory: 91.4993664
 25.340s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2422
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.107264
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.199 (0.199)	Data 0.287 (0.287)	Loss 0.6543 (0.6543)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [41][64/196]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.6962 (0.6590)	Acc@1 83.203 (86.400)	Acc@5 99.609 (99.423)
Epoch: [41][128/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.7089 (0.6719)	Acc@1 85.938 (85.841)	Acc@5 99.219 (99.422)
Epoch: [41][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.6522 (0.6815)	Acc@1 85.938 (85.466)	Acc@5 100.000 (99.375)
Max memory in training epoch: 58.3939584
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.181 (0.181)	Data 0.262 (0.262)	Loss 0.5999 (0.5999)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.121 (0.127)	Data 0.000 (0.004)	Loss 0.6616 (0.6766)	Acc@1 85.156 (85.385)	Acc@5 100.000 (99.507)
Epoch: [42][128/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.6415 (0.6826)	Acc@1 87.891 (85.244)	Acc@5 99.219 (99.400)
Epoch: [42][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6182 (0.6778)	Acc@1 85.547 (85.324)	Acc@5 100.000 (99.403)
Max memory in training epoch: 58.5652736
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.155 (0.155)	Data 0.286 (0.286)	Loss 0.6605 (0.6605)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.6776 (0.6700)	Acc@1 86.328 (85.445)	Acc@5 99.609 (99.381)
Epoch: [43][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.6279 (0.6783)	Acc@1 87.891 (85.362)	Acc@5 99.219 (99.352)
Epoch: [43][192/196]	Time 0.116 (0.126)	Data 0.000 (0.002)	Loss 0.7184 (0.6769)	Acc@1 83.594 (85.490)	Acc@5 99.219 (99.354)
Max memory in training epoch: 58.5652736
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.168 (0.168)	Data 0.282 (0.282)	Loss 0.7079 (0.7079)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.129 (0.127)	Data 0.000 (0.005)	Loss 0.6852 (0.6895)	Acc@1 84.766 (85.120)	Acc@5 99.219 (99.249)
Epoch: [44][128/196]	Time 0.135 (0.127)	Data 0.000 (0.002)	Loss 0.7121 (0.6832)	Acc@1 82.812 (85.398)	Acc@5 100.000 (99.325)
Epoch: [44][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7946 (0.6808)	Acc@1 80.859 (85.527)	Acc@5 99.609 (99.332)
Max memory in training epoch: 58.5652736
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.162 (0.162)	Data 0.291 (0.291)	Loss 0.6229 (0.6229)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [45][64/196]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.8717 (0.6722)	Acc@1 78.125 (85.433)	Acc@5 98.438 (99.333)
Epoch: [45][128/196]	Time 0.130 (0.124)	Data 0.000 (0.002)	Loss 0.6343 (0.6711)	Acc@1 83.984 (85.656)	Acc@5 99.609 (99.352)
Epoch: [45][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6565 (0.6670)	Acc@1 87.500 (85.725)	Acc@5 99.609 (99.373)
Max memory in training epoch: 58.5652736
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 244802 ; 247550 ; 0.9888992122803474
[INFO] Storing checkpoint...
  83.48
Max memory: 91.4904576
 24.745s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8770
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1062912
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.175 (0.175)	Data 0.293 (0.293)	Loss 0.7366 (0.7366)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.138 (0.129)	Data 0.000 (0.005)	Loss 0.6616 (0.6431)	Acc@1 85.938 (86.599)	Acc@5 99.609 (99.459)
Epoch: [46][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7450 (0.6507)	Acc@1 82.812 (86.343)	Acc@5 99.219 (99.446)
Epoch: [46][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.7414 (0.6628)	Acc@1 82.812 (85.891)	Acc@5 99.219 (99.403)
Max memory in training epoch: 57.9725824
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.172 (0.172)	Data 0.281 (0.281)	Loss 0.5436 (0.5436)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7302 (0.6851)	Acc@1 84.375 (85.090)	Acc@5 99.609 (99.309)
Epoch: [47][128/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.6659 (0.6752)	Acc@1 86.719 (85.511)	Acc@5 99.609 (99.355)
Epoch: [47][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.7024 (0.6762)	Acc@1 85.156 (85.514)	Acc@5 99.219 (99.379)
Max memory in training epoch: 57.912576
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.190 (0.190)	Data 0.263 (0.263)	Loss 0.7197 (0.7197)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [48][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.6789 (0.6745)	Acc@1 85.547 (85.607)	Acc@5 99.609 (99.267)
Epoch: [48][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6207 (0.6698)	Acc@1 86.719 (85.747)	Acc@5 100.000 (99.319)
Epoch: [48][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6628 (0.6748)	Acc@1 85.547 (85.563)	Acc@5 98.828 (99.350)
Max memory in training epoch: 57.912576
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.154 (0.154)	Data 0.289 (0.289)	Loss 0.6439 (0.6439)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [49][64/196]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.6081 (0.6693)	Acc@1 90.234 (85.980)	Acc@5 100.000 (99.315)
Epoch: [49][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7001 (0.6684)	Acc@1 83.203 (85.928)	Acc@5 99.219 (99.361)
Epoch: [49][192/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.7264 (0.6738)	Acc@1 83.984 (85.662)	Acc@5 99.219 (99.387)
Max memory in training epoch: 57.912576
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.182 (0.182)	Data 0.271 (0.271)	Loss 0.7009 (0.7009)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.7283 (0.6751)	Acc@1 86.328 (85.367)	Acc@5 99.219 (99.435)
Epoch: [50][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7316 (0.6660)	Acc@1 83.984 (85.707)	Acc@5 99.609 (99.422)
Epoch: [50][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6007 (0.6670)	Acc@1 87.891 (85.790)	Acc@5 99.219 (99.385)
Max memory in training epoch: 57.912576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 243934 ; 244802 ; 0.9964542773343356
[INFO] Storing checkpoint...
  70.79
Max memory: 90.2194176
 25.072s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 174
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1058816
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.184 (0.184)	Data 0.275 (0.275)	Loss 0.6892 (0.6892)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.120 (0.127)	Data 0.000 (0.004)	Loss 0.7761 (0.6400)	Acc@1 83.984 (86.725)	Acc@5 98.828 (99.483)
Epoch: [51][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6313 (0.6600)	Acc@1 85.156 (85.962)	Acc@5 100.000 (99.449)
Epoch: [51][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.6580 (0.6662)	Acc@1 84.375 (85.770)	Acc@5 100.000 (99.413)
Max memory in training epoch: 57.5261184
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.187 (0.187)	Data 0.312 (0.312)	Loss 0.6574 (0.6574)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.7680 (0.6652)	Acc@1 81.641 (85.655)	Acc@5 100.000 (99.375)
Epoch: [52][128/196]	Time 0.124 (0.125)	Data 0.000 (0.003)	Loss 0.6603 (0.6654)	Acc@1 85.547 (85.741)	Acc@5 99.609 (99.425)
Epoch: [52][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.5671 (0.6693)	Acc@1 91.406 (85.602)	Acc@5 98.828 (99.411)
Max memory in training epoch: 57.3669888
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.165 (0.165)	Data 0.273 (0.273)	Loss 0.6392 (0.6392)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 0.119 (0.125)	Data 0.000 (0.004)	Loss 0.7249 (0.6646)	Acc@1 85.156 (85.871)	Acc@5 98.828 (99.327)
Epoch: [53][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6511 (0.6643)	Acc@1 86.328 (86.056)	Acc@5 99.609 (99.355)
Epoch: [53][192/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.5746 (0.6629)	Acc@1 89.453 (86.065)	Acc@5 100.000 (99.389)
Max memory in training epoch: 57.3669888
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.156 (0.156)	Data 0.261 (0.261)	Loss 0.7081 (0.7081)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [54][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6593 (0.6526)	Acc@1 86.328 (86.382)	Acc@5 99.609 (99.345)
Epoch: [54][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.5744 (0.6644)	Acc@1 85.547 (85.980)	Acc@5 100.000 (99.331)
Epoch: [54][192/196]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.7031 (0.6672)	Acc@1 82.812 (85.855)	Acc@5 99.609 (99.294)
Max memory in training epoch: 57.3669888
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.169 (0.169)	Data 0.269 (0.269)	Loss 0.6234 (0.6234)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.6711 (0.6707)	Acc@1 85.938 (85.523)	Acc@5 99.219 (99.435)
Epoch: [55][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.6666 (0.6738)	Acc@1 86.328 (85.653)	Acc@5 99.219 (99.425)
Epoch: [55][192/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.5931 (0.6709)	Acc@1 89.453 (85.691)	Acc@5 100.000 (99.458)
Max memory in training epoch: 57.3669888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 241910 ; 243934 ; 0.9917026736740265
[INFO] Storing checkpoint...
  79.2
Max memory: 89.1917312
 24.929s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4904
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1051648
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.224 (0.224)	Data 0.272 (0.272)	Loss 0.5768 (0.5768)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [56][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7058 (0.6393)	Acc@1 83.984 (86.983)	Acc@5 98.438 (99.435)
Epoch: [56][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6227 (0.6435)	Acc@1 85.938 (86.625)	Acc@5 99.609 (99.503)
Epoch: [56][192/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.7306 (0.6551)	Acc@1 83.984 (86.190)	Acc@5 99.219 (99.458)
Max memory in training epoch: 57.210112
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.175 (0.175)	Data 0.257 (0.257)	Loss 0.7000 (0.7000)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [57][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.6725 (0.6589)	Acc@1 87.109 (85.974)	Acc@5 99.219 (99.417)
Epoch: [57][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7052 (0.6627)	Acc@1 85.156 (85.953)	Acc@5 98.828 (99.394)
Epoch: [57][192/196]	Time 0.124 (0.125)	Data 0.000 (0.001)	Loss 0.6054 (0.6650)	Acc@1 89.062 (85.770)	Acc@5 99.219 (99.371)
Max memory in training epoch: 57.2854784
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.180 (0.180)	Data 0.287 (0.287)	Loss 0.6650 (0.6650)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.7095 (0.6571)	Acc@1 84.766 (85.799)	Acc@5 99.609 (99.507)
Epoch: [58][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6299 (0.6616)	Acc@1 85.156 (85.813)	Acc@5 100.000 (99.476)
Epoch: [58][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.6238 (0.6642)	Acc@1 88.281 (85.751)	Acc@5 99.609 (99.449)
Max memory in training epoch: 57.2854784
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.151 (0.151)	Data 0.310 (0.310)	Loss 0.6362 (0.6362)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [59][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6646 (0.6441)	Acc@1 85.547 (86.599)	Acc@5 99.219 (99.375)
Epoch: [59][128/196]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.6092 (0.6531)	Acc@1 87.500 (86.243)	Acc@5 100.000 (99.416)
Epoch: [59][192/196]	Time 0.117 (0.127)	Data 0.000 (0.002)	Loss 0.6031 (0.6625)	Acc@1 88.281 (85.960)	Acc@5 99.609 (99.379)
Max memory in training epoch: 57.2854784
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.169 (0.169)	Data 0.263 (0.263)	Loss 0.7323 (0.7323)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.6099 (0.6595)	Acc@1 87.891 (85.998)	Acc@5 98.828 (99.483)
Epoch: [60][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6373 (0.6611)	Acc@1 85.156 (85.913)	Acc@5 99.609 (99.467)
Epoch: [60][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5983 (0.6639)	Acc@1 87.500 (85.782)	Acc@5 99.609 (99.433)
Max memory in training epoch: 57.2854784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 239310 ; 241910 ; 0.9892522012318631
[INFO] Storing checkpoint...
  71.48
Max memory: 88.8430592
 24.933s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9515
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1041408
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.177 (0.177)	Data 0.294 (0.294)	Loss 0.6422 (0.6422)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.7920 (0.6332)	Acc@1 81.641 (86.935)	Acc@5 98.828 (99.549)
Epoch: [61][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6626 (0.6479)	Acc@1 85.938 (86.434)	Acc@5 98.828 (99.440)
Epoch: [61][192/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.6392 (0.6554)	Acc@1 86.719 (86.154)	Acc@5 99.609 (99.419)
Max memory in training epoch: 57.306368
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.189 (0.189)	Data 0.253 (0.253)	Loss 0.6583 (0.6583)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.6211 (0.6656)	Acc@1 86.328 (85.457)	Acc@5 99.219 (99.495)
Epoch: [62][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6903 (0.6675)	Acc@1 82.422 (85.586)	Acc@5 98.828 (99.431)
Epoch: [62][192/196]	Time 0.126 (0.126)	Data 0.000 (0.001)	Loss 0.6349 (0.6688)	Acc@1 85.938 (85.529)	Acc@5 99.609 (99.431)
Max memory in training epoch: 57.2158464
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.175 (0.175)	Data 0.303 (0.303)	Loss 0.6265 (0.6265)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [63][64/196]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.6660 (0.6575)	Acc@1 84.766 (85.925)	Acc@5 99.219 (99.519)
Epoch: [63][128/196]	Time 0.125 (0.127)	Data 0.000 (0.003)	Loss 0.6805 (0.6652)	Acc@1 85.938 (85.656)	Acc@5 99.609 (99.416)
Epoch: [63][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7063 (0.6669)	Acc@1 85.938 (85.693)	Acc@5 99.219 (99.385)
Max memory in training epoch: 57.2158464
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.163 (0.163)	Data 0.318 (0.318)	Loss 0.6305 (0.6305)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.5375 (0.6451)	Acc@1 92.188 (86.749)	Acc@5 100.000 (99.501)
Epoch: [64][128/196]	Time 0.121 (0.128)	Data 0.000 (0.003)	Loss 0.6813 (0.6529)	Acc@1 83.984 (86.210)	Acc@5 100.000 (99.491)
Epoch: [64][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6306 (0.6601)	Acc@1 89.844 (85.998)	Acc@5 99.219 (99.427)
Max memory in training epoch: 57.2158464
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.176 (0.176)	Data 0.260 (0.260)	Loss 0.6812 (0.6812)	Acc@1 85.547 (85.547)	Acc@5 98.047 (98.047)
Epoch: [65][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6766 (0.6627)	Acc@1 85.156 (85.667)	Acc@5 99.609 (99.459)
Epoch: [65][128/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.6261 (0.6588)	Acc@1 86.719 (85.941)	Acc@5 99.609 (99.458)
Epoch: [65][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6323 (0.6659)	Acc@1 86.719 (85.676)	Acc@5 99.609 (99.435)
Max memory in training epoch: 57.2158464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 238442 ; 239310 ; 0.9963729054364632
[INFO] Storing checkpoint...
  78.31
Max memory: 88.9890816
 25.249s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 165
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1038336
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.197 (0.197)	Data 0.278 (0.278)	Loss 0.5653 (0.5653)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [66][64/196]	Time 0.128 (0.124)	Data 0.000 (0.004)	Loss 0.6775 (0.6342)	Acc@1 83.203 (86.647)	Acc@5 99.219 (99.501)
Epoch: [66][128/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.6688 (0.6498)	Acc@1 85.938 (86.201)	Acc@5 99.219 (99.419)
Epoch: [66][192/196]	Time 0.129 (0.124)	Data 0.000 (0.002)	Loss 0.6194 (0.6524)	Acc@1 88.281 (86.229)	Acc@5 100.000 (99.399)
Max memory in training epoch: 57.076992
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.174 (0.174)	Data 0.291 (0.291)	Loss 0.5975 (0.5975)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [67][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.7031 (0.6579)	Acc@1 84.766 (85.817)	Acc@5 98.047 (99.351)
Epoch: [67][128/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.6162 (0.6583)	Acc@1 87.891 (85.986)	Acc@5 98.438 (99.376)
Epoch: [67][192/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.6202 (0.6597)	Acc@1 87.891 (85.968)	Acc@5 99.219 (99.373)
Max memory in training epoch: 56.7230976
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.179 (0.179)	Data 0.263 (0.263)	Loss 0.6568 (0.6568)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [68][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.7133 (0.6396)	Acc@1 84.766 (86.526)	Acc@5 99.609 (99.471)
Epoch: [68][128/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.5299 (0.6523)	Acc@1 91.406 (86.231)	Acc@5 100.000 (99.382)
Epoch: [68][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6610 (0.6595)	Acc@1 85.547 (86.075)	Acc@5 99.609 (99.375)
Max memory in training epoch: 56.8934912
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.170 (0.170)	Data 0.312 (0.312)	Loss 0.7159 (0.7159)	Acc@1 87.500 (87.500)	Acc@5 98.047 (98.047)
Epoch: [69][64/196]	Time 0.137 (0.127)	Data 0.000 (0.005)	Loss 0.7482 (0.6436)	Acc@1 84.766 (86.334)	Acc@5 97.656 (99.441)
Epoch: [69][128/196]	Time 0.126 (0.125)	Data 0.000 (0.003)	Loss 0.5790 (0.6549)	Acc@1 88.281 (86.134)	Acc@5 100.000 (99.434)
Epoch: [69][192/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6677 (0.6564)	Acc@1 84.766 (86.110)	Acc@5 99.219 (99.395)
Max memory in training epoch: 56.8934912
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.176 (0.176)	Data 0.259 (0.259)	Loss 0.5835 (0.5835)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [70][64/196]	Time 0.119 (0.126)	Data 0.000 (0.004)	Loss 0.6989 (0.6501)	Acc@1 84.375 (86.058)	Acc@5 99.609 (99.345)
Epoch: [70][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5981 (0.6553)	Acc@1 88.672 (85.998)	Acc@5 99.219 (99.331)
Epoch: [70][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6419 (0.6512)	Acc@1 85.938 (86.081)	Acc@5 98.828 (99.358)
Max memory in training epoch: 56.8934912
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 236562 ; 238442 ; 0.9921154830105434
[INFO] Storing checkpoint...
  83.06
Max memory: 88.0313344
 24.905s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7870
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1030656
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.195 (0.195)	Data 0.265 (0.265)	Loss 0.6831 (0.6831)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.5934 (0.6279)	Acc@1 87.109 (86.875)	Acc@5 99.219 (99.501)
Epoch: [71][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6879 (0.6455)	Acc@1 85.156 (86.416)	Acc@5 99.609 (99.446)
Epoch: [71][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6874 (0.6520)	Acc@1 82.812 (86.160)	Acc@5 99.609 (99.462)
Max memory in training epoch: 56.4578816
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.154 (0.154)	Data 0.273 (0.273)	Loss 0.6352 (0.6352)	Acc@1 88.281 (88.281)	Acc@5 98.828 (98.828)
Epoch: [72][64/196]	Time 0.128 (0.126)	Data 0.000 (0.004)	Loss 0.6934 (0.6405)	Acc@1 84.766 (86.887)	Acc@5 99.219 (99.351)
Epoch: [72][128/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.6324 (0.6533)	Acc@1 89.062 (86.249)	Acc@5 99.219 (99.382)
Epoch: [72][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6562 (0.6505)	Acc@1 85.547 (86.346)	Acc@5 99.609 (99.395)
Max memory in training epoch: 56.1367552
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.182 (0.182)	Data 0.303 (0.303)	Loss 0.6908 (0.6908)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.6593 (0.6616)	Acc@1 85.547 (85.595)	Acc@5 99.609 (99.537)
Epoch: [73][128/196]	Time 0.120 (0.126)	Data 0.000 (0.003)	Loss 0.6829 (0.6582)	Acc@1 85.547 (85.874)	Acc@5 99.219 (99.500)
Epoch: [73][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6818 (0.6566)	Acc@1 84.766 (85.909)	Acc@5 98.828 (99.480)
Max memory in training epoch: 56.1367552
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.172 (0.172)	Data 0.305 (0.305)	Loss 0.6747 (0.6747)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [74][64/196]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.6554 (0.6510)	Acc@1 85.156 (86.250)	Acc@5 100.000 (99.417)
Epoch: [74][128/196]	Time 0.122 (0.125)	Data 0.000 (0.003)	Loss 0.7469 (0.6554)	Acc@1 80.859 (86.137)	Acc@5 99.219 (99.410)
Epoch: [74][192/196]	Time 0.127 (0.125)	Data 0.000 (0.002)	Loss 0.7186 (0.6578)	Acc@1 85.156 (86.016)	Acc@5 100.000 (99.403)
Max memory in training epoch: 56.1367552
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.183 (0.183)	Data 0.297 (0.297)	Loss 0.6459 (0.6459)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [75][64/196]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.5980 (0.6614)	Acc@1 89.062 (85.877)	Acc@5 100.000 (99.417)
Epoch: [75][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.5782 (0.6580)	Acc@1 87.500 (86.004)	Acc@5 100.000 (99.422)
Epoch: [75][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6690 (0.6537)	Acc@1 83.594 (86.227)	Acc@5 99.219 (99.435)
Max memory in training epoch: 56.1367552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 233386 ; 236562 ; 0.9865743441465662
[INFO] Storing checkpoint...
  68.71
Max memory: 87.3138688
 24.945s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6352
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1018368
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.197 (0.197)	Data 0.266 (0.266)	Loss 0.7174 (0.7174)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.121 (0.127)	Data 0.000 (0.004)	Loss 0.7156 (0.6202)	Acc@1 84.766 (87.145)	Acc@5 99.609 (99.603)
Epoch: [76][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6650 (0.6397)	Acc@1 86.719 (86.582)	Acc@5 99.609 (99.476)
Epoch: [76][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.5696 (0.6395)	Acc@1 87.891 (86.482)	Acc@5 99.609 (99.441)
Max memory in training epoch: 56.3874304
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.176 (0.176)	Data 0.268 (0.268)	Loss 0.6212 (0.6212)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.118 (0.128)	Data 0.000 (0.004)	Loss 0.6616 (0.6538)	Acc@1 85.156 (86.208)	Acc@5 99.609 (99.447)
Epoch: [77][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6029 (0.6487)	Acc@1 87.891 (86.271)	Acc@5 100.000 (99.452)
Epoch: [77][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.6208 (0.6506)	Acc@1 86.719 (86.213)	Acc@5 99.609 (99.433)
Max memory in training epoch: 56.0531968
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.152 (0.152)	Data 0.289 (0.289)	Loss 0.6421 (0.6421)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.6177 (0.6484)	Acc@1 88.281 (86.172)	Acc@5 99.609 (99.489)
Epoch: [78][128/196]	Time 0.128 (0.124)	Data 0.000 (0.002)	Loss 0.6431 (0.6506)	Acc@1 86.328 (86.137)	Acc@5 100.000 (99.497)
Epoch: [78][192/196]	Time 0.127 (0.125)	Data 0.000 (0.002)	Loss 0.6315 (0.6488)	Acc@1 84.375 (86.273)	Acc@5 99.609 (99.472)
Max memory in training epoch: 56.0531968
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.173 (0.173)	Data 0.278 (0.278)	Loss 0.5537 (0.5537)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.6039 (0.6465)	Acc@1 89.062 (86.304)	Acc@5 99.219 (99.453)
Epoch: [79][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6474 (0.6465)	Acc@1 85.156 (86.210)	Acc@5 99.609 (99.488)
Epoch: [79][192/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.7583 (0.6471)	Acc@1 84.375 (86.310)	Acc@5 98.828 (99.452)
Max memory in training epoch: 56.0531968
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.170 (0.170)	Data 0.295 (0.295)	Loss 0.6724 (0.6724)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [80][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.7203 (0.6564)	Acc@1 85.547 (86.064)	Acc@5 98.828 (99.429)
Epoch: [80][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7823 (0.6621)	Acc@1 81.250 (85.859)	Acc@5 99.219 (99.428)
Epoch: [80][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7112 (0.6537)	Acc@1 83.203 (86.180)	Acc@5 99.219 (99.449)
Max memory in training epoch: 56.0531968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  78.55
Max memory: 87.2077824
 25.038s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9751
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1018368
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.190 (0.190)	Data 0.266 (0.266)	Loss 0.6022 (0.6022)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.7046 (0.6074)	Acc@1 82.422 (87.584)	Acc@5 99.609 (99.447)
Epoch: [81][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6277 (0.6295)	Acc@1 85.938 (86.782)	Acc@5 99.219 (99.452)
Epoch: [81][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6169 (0.6434)	Acc@1 87.500 (86.395)	Acc@5 99.219 (99.409)
Max memory in training epoch: 56.3874304
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.183 (0.183)	Data 0.287 (0.287)	Loss 0.6784 (0.6784)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 0.6724 (0.6462)	Acc@1 86.719 (86.214)	Acc@5 100.000 (99.447)
Epoch: [82][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.5380 (0.6448)	Acc@1 90.234 (86.274)	Acc@5 99.609 (99.452)
Epoch: [82][192/196]	Time 0.118 (0.126)	Data 0.000 (0.002)	Loss 0.6960 (0.6479)	Acc@1 83.594 (86.186)	Acc@5 99.219 (99.415)
Max memory in training epoch: 56.0531968
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.188 (0.188)	Data 0.260 (0.260)	Loss 0.6099 (0.6099)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.6944 (0.6589)	Acc@1 85.156 (85.823)	Acc@5 99.609 (99.483)
Epoch: [83][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6885 (0.6549)	Acc@1 83.984 (85.968)	Acc@5 99.219 (99.470)
Epoch: [83][192/196]	Time 0.120 (0.129)	Data 0.000 (0.002)	Loss 0.7027 (0.6492)	Acc@1 87.500 (86.318)	Acc@5 100.000 (99.449)
Max memory in training epoch: 56.0531968
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.171 (0.171)	Data 0.302 (0.302)	Loss 0.5870 (0.5870)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.5868 (0.6402)	Acc@1 88.672 (86.352)	Acc@5 99.609 (99.453)
Epoch: [84][128/196]	Time 0.118 (0.127)	Data 0.000 (0.003)	Loss 0.7116 (0.6370)	Acc@1 87.109 (86.670)	Acc@5 100.000 (99.467)
Epoch: [84][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7091 (0.6455)	Acc@1 83.203 (86.395)	Acc@5 99.609 (99.437)
Max memory in training epoch: 56.0531968
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.149 (0.149)	Data 0.270 (0.270)	Loss 0.6753 (0.6753)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.127 (0.126)	Data 0.000 (0.004)	Loss 0.7372 (0.6461)	Acc@1 81.641 (86.424)	Acc@5 99.609 (99.471)
Epoch: [85][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7248 (0.6414)	Acc@1 84.766 (86.489)	Acc@5 98.828 (99.403)
Epoch: [85][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6763 (0.6452)	Acc@1 86.719 (86.314)	Acc@5 99.609 (99.366)
Max memory in training epoch: 56.0531968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 232518 ; 233386 ; 0.996280839467663
[INFO] Storing checkpoint...
  68.51
Max memory: 87.2077824
 25.055s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2240
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1015296
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.211 (0.211)	Data 0.259 (0.259)	Loss 0.6230 (0.6230)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [86][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.6082 (0.6240)	Acc@1 86.719 (86.845)	Acc@5 99.609 (99.495)
Epoch: [86][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6632 (0.6347)	Acc@1 85.547 (86.655)	Acc@5 99.219 (99.403)
Epoch: [86][192/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.5887 (0.6412)	Acc@1 86.328 (86.474)	Acc@5 100.000 (99.433)
Max memory in training epoch: 56.0231936
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.147 (0.147)	Data 0.289 (0.289)	Loss 0.6701 (0.6701)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.5570 (0.6495)	Acc@1 87.500 (86.244)	Acc@5 99.609 (99.339)
Epoch: [87][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7169 (0.6518)	Acc@1 82.812 (86.171)	Acc@5 99.609 (99.373)
Epoch: [87][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.7413 (0.6522)	Acc@1 82.422 (86.085)	Acc@5 99.219 (99.393)
Max memory in training epoch: 56.0060928
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.153 (0.153)	Data 0.285 (0.285)	Loss 0.5973 (0.5973)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [88][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.7577 (0.6412)	Acc@1 83.984 (86.400)	Acc@5 99.219 (99.405)
Epoch: [88][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.7467 (0.6455)	Acc@1 82.812 (86.319)	Acc@5 98.828 (99.434)
Epoch: [88][192/196]	Time 0.118 (0.129)	Data 0.000 (0.002)	Loss 0.5835 (0.6508)	Acc@1 89.453 (86.211)	Acc@5 99.609 (99.385)
Max memory in training epoch: 55.8619136
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.165 (0.165)	Data 0.287 (0.287)	Loss 0.5580 (0.5580)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [89][64/196]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.6832 (0.6495)	Acc@1 84.766 (86.064)	Acc@5 99.219 (99.411)
Epoch: [89][128/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.6687 (0.6457)	Acc@1 83.594 (86.216)	Acc@5 98.828 (99.388)
Epoch: [89][192/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6533 (0.6436)	Acc@1 86.719 (86.247)	Acc@5 99.219 (99.429)
Max memory in training epoch: 55.8619136
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.151 (0.151)	Data 0.301 (0.301)	Loss 0.5920 (0.5920)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.5863 (0.6595)	Acc@1 88.672 (85.715)	Acc@5 99.609 (99.453)
Epoch: [90][128/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.6419 (0.6456)	Acc@1 85.156 (86.331)	Acc@5 100.000 (99.422)
Epoch: [90][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.7408 (0.6449)	Acc@1 82.812 (86.276)	Acc@5 98.047 (99.419)
Max memory in training epoch: 55.8619136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 231876 ; 232518 ; 0.9972389234381854
[INFO] Storing checkpoint...
  82.17
Max memory: 86.789888
 24.947s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3215
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1007104
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.168 (0.168)	Data 0.306 (0.306)	Loss 0.5589 (0.5589)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.111 (0.118)	Data 0.000 (0.005)	Loss 0.6466 (0.6215)	Acc@1 85.938 (87.091)	Acc@5 100.000 (99.513)
Epoch: [91][128/196]	Time 0.119 (0.118)	Data 0.000 (0.003)	Loss 0.7207 (0.6339)	Acc@1 82.812 (86.807)	Acc@5 99.609 (99.458)
Epoch: [91][192/196]	Time 0.124 (0.118)	Data 0.000 (0.002)	Loss 0.6442 (0.6423)	Acc@1 85.156 (86.389)	Acc@5 99.609 (99.429)
Max memory in training epoch: 54.291712
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.163 (0.163)	Data 0.283 (0.283)	Loss 0.6182 (0.6182)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [92][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.6212 (0.6388)	Acc@1 87.500 (86.569)	Acc@5 99.219 (99.459)
Epoch: [92][128/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.6516 (0.6416)	Acc@1 86.719 (86.328)	Acc@5 99.609 (99.455)
Epoch: [92][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.7147 (0.6440)	Acc@1 82.812 (86.304)	Acc@5 99.609 (99.445)
Max memory in training epoch: 54.0573184
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.168 (0.168)	Data 0.259 (0.259)	Loss 0.5848 (0.5848)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [93][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.5527 (0.5444)	Acc@1 89.844 (89.904)	Acc@5 100.000 (99.597)
Epoch: [93][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.4827 (0.5230)	Acc@1 91.406 (90.652)	Acc@5 100.000 (99.676)
Epoch: [93][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.5062 (0.5096)	Acc@1 90.234 (91.042)	Acc@5 100.000 (99.707)
Max memory in training epoch: 54.0573184
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.159 (0.159)	Data 0.291 (0.291)	Loss 0.4895 (0.4895)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 0.4877 (0.4568)	Acc@1 91.016 (92.710)	Acc@5 99.609 (99.796)
Epoch: [94][128/196]	Time 0.127 (0.118)	Data 0.000 (0.002)	Loss 0.4781 (0.4578)	Acc@1 92.188 (92.669)	Acc@5 99.609 (99.806)
Epoch: [94][192/196]	Time 0.128 (0.118)	Data 0.000 (0.002)	Loss 0.4299 (0.4568)	Acc@1 94.531 (92.653)	Acc@5 100.000 (99.820)
Max memory in training epoch: 54.0573184
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.140 (0.140)	Data 0.260 (0.260)	Loss 0.4275 (0.4275)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.117 (0.117)	Data 0.000 (0.004)	Loss 0.4142 (0.4362)	Acc@1 94.922 (93.017)	Acc@5 99.609 (99.826)
Epoch: [95][128/196]	Time 0.130 (0.118)	Data 0.000 (0.002)	Loss 0.4246 (0.4343)	Acc@1 94.141 (93.247)	Acc@5 99.219 (99.840)
Epoch: [95][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.4879 (0.4350)	Acc@1 90.625 (93.218)	Acc@5 99.609 (99.832)
Max memory in training epoch: 54.0573184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 230432 ; 231876 ; 0.9937725335955424
[INFO] Storing checkpoint...
  90.48
Max memory: 84.0666624
 23.498s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3939
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.100096
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.180 (0.180)	Data 0.292 (0.292)	Loss 0.4540 (0.4540)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.4584 (0.4251)	Acc@1 92.969 (93.383)	Acc@5 99.609 (99.832)
Epoch: [96][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.4104 (0.4197)	Acc@1 93.750 (93.596)	Acc@5 99.609 (99.818)
Epoch: [96][192/196]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.4035 (0.4200)	Acc@1 93.750 (93.495)	Acc@5 100.000 (99.838)
Max memory in training epoch: 54.0745216
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.178 (0.178)	Data 0.308 (0.308)	Loss 0.4624 (0.4624)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.4273 (0.4081)	Acc@1 94.531 (93.900)	Acc@5 99.609 (99.886)
Epoch: [97][128/196]	Time 0.118 (0.118)	Data 0.000 (0.003)	Loss 0.4120 (0.4042)	Acc@1 92.188 (93.998)	Acc@5 100.000 (99.900)
Epoch: [97][192/196]	Time 0.147 (0.117)	Data 0.000 (0.002)	Loss 0.4203 (0.4038)	Acc@1 94.531 (93.981)	Acc@5 99.609 (99.881)
Max memory in training epoch: 53.8844672
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.140 (0.140)	Data 0.261 (0.261)	Loss 0.4634 (0.4634)	Acc@1 91.016 (91.016)	Acc@5 99.219 (99.219)
Epoch: [98][64/196]	Time 0.112 (0.119)	Data 0.000 (0.004)	Loss 0.3863 (0.3893)	Acc@1 94.141 (94.315)	Acc@5 100.000 (99.880)
Epoch: [98][128/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.3362 (0.3913)	Acc@1 96.875 (94.201)	Acc@5 100.000 (99.870)
Epoch: [98][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3851 (0.3927)	Acc@1 93.359 (94.128)	Acc@5 100.000 (99.879)
Max memory in training epoch: 53.8844672
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.167 (0.167)	Data 0.272 (0.272)	Loss 0.4030 (0.4030)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [99][64/196]	Time 0.123 (0.119)	Data 0.000 (0.004)	Loss 0.3938 (0.3889)	Acc@1 94.531 (94.081)	Acc@5 99.609 (99.874)
Epoch: [99][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.3587 (0.3826)	Acc@1 94.531 (94.371)	Acc@5 100.000 (99.885)
Epoch: [99][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3706 (0.3833)	Acc@1 94.922 (94.319)	Acc@5 100.000 (99.875)
Max memory in training epoch: 53.8844672
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.182 (0.182)	Data 0.266 (0.266)	Loss 0.3311 (0.3311)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.114 (0.118)	Data 0.000 (0.004)	Loss 0.3631 (0.3740)	Acc@1 94.141 (94.663)	Acc@5 100.000 (99.910)
Epoch: [100][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3716 (0.3734)	Acc@1 93.750 (94.680)	Acc@5 99.609 (99.897)
Epoch: [100][192/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3495 (0.3755)	Acc@1 95.312 (94.537)	Acc@5 100.000 (99.887)
Max memory in training epoch: 53.8844672
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 229854 ; 230432 ; 0.9974916678239133
[INFO] Storing checkpoint...
  91.21
Max memory: 83.5528192
 23.344s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4315
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.0998912
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.172 (0.172)	Data 0.282 (0.282)	Loss 0.3810 (0.3810)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [101][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.3847 (0.3627)	Acc@1 92.969 (94.832)	Acc@5 100.000 (99.892)
Epoch: [101][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3618 (0.3663)	Acc@1 94.531 (94.677)	Acc@5 100.000 (99.891)
Epoch: [101][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3702 (0.3677)	Acc@1 94.531 (94.634)	Acc@5 100.000 (99.895)
Max memory in training epoch: 54.0737024
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.168 (0.168)	Data 0.299 (0.299)	Loss 0.4033 (0.4033)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.126 (0.121)	Data 0.000 (0.005)	Loss 0.3884 (0.3601)	Acc@1 94.141 (94.802)	Acc@5 100.000 (99.850)
Epoch: [102][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3769 (0.3626)	Acc@1 92.578 (94.680)	Acc@5 100.000 (99.882)
Epoch: [102][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3875 (0.3616)	Acc@1 93.750 (94.655)	Acc@5 100.000 (99.887)
Max memory in training epoch: 53.883648
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.166 (0.166)	Data 0.289 (0.289)	Loss 0.3415 (0.3415)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.3621 (0.3505)	Acc@1 94.531 (95.096)	Acc@5 100.000 (99.898)
Epoch: [103][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3312 (0.3518)	Acc@1 94.922 (94.988)	Acc@5 100.000 (99.903)
Epoch: [103][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3418 (0.3538)	Acc@1 96.094 (94.956)	Acc@5 100.000 (99.893)
Max memory in training epoch: 53.883648
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.148 (0.148)	Data 0.274 (0.274)	Loss 0.3603 (0.3603)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.3718 (0.3352)	Acc@1 94.922 (95.445)	Acc@5 100.000 (99.928)
Epoch: [104][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.3424 (0.3436)	Acc@1 94.531 (95.167)	Acc@5 100.000 (99.909)
Epoch: [104][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3075 (0.3457)	Acc@1 95.312 (95.062)	Acc@5 100.000 (99.901)
Max memory in training epoch: 53.883648
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.167 (0.167)	Data 0.310 (0.310)	Loss 0.3658 (0.3658)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [105][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.3683 (0.3450)	Acc@1 95.312 (95.030)	Acc@5 100.000 (99.892)
Epoch: [105][128/196]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.3445 (0.3442)	Acc@1 95.312 (95.019)	Acc@5 100.000 (99.918)
Epoch: [105][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.2798 (0.3435)	Acc@1 96.484 (95.023)	Acc@5 100.000 (99.899)
Max memory in training epoch: 53.883648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 225376 ; 229854 ; 0.9805180679909856
[INFO] Storing checkpoint...
  91.17
Max memory: 83.5522048
 23.934s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7638
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.0978944
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 0.3805 (0.3805)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [106][64/196]	Time 0.113 (0.120)	Data 0.000 (0.004)	Loss 0.3847 (0.3358)	Acc@1 92.969 (95.072)	Acc@5 99.609 (99.916)
Epoch: [106][128/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.3157 (0.3394)	Acc@1 96.875 (94.943)	Acc@5 100.000 (99.918)
Epoch: [106][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2554 (0.3398)	Acc@1 98.438 (94.898)	Acc@5 100.000 (99.911)
Max memory in training epoch: 53.659392
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.184 (0.184)	Data 0.267 (0.267)	Loss 0.2948 (0.2948)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [107][64/196]	Time 0.133 (0.119)	Data 0.000 (0.004)	Loss 0.3337 (0.3265)	Acc@1 93.750 (95.379)	Acc@5 99.609 (99.910)
Epoch: [107][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3545 (0.3311)	Acc@1 93.750 (95.161)	Acc@5 100.000 (99.918)
Epoch: [107][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.3132 (0.3313)	Acc@1 94.922 (95.138)	Acc@5 100.000 (99.909)
Max memory in training epoch: 53.5021056
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.142 (0.142)	Data 0.271 (0.271)	Loss 0.3107 (0.3107)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [108][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.3635 (0.3323)	Acc@1 91.797 (94.814)	Acc@5 100.000 (99.904)
Epoch: [108][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3345 (0.3319)	Acc@1 95.312 (94.892)	Acc@5 100.000 (99.936)
Epoch: [108][192/196]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.3372 (0.3328)	Acc@1 94.922 (94.887)	Acc@5 100.000 (99.919)
Max memory in training epoch: 53.5021056
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.163 (0.163)	Data 0.292 (0.292)	Loss 0.3090 (0.3090)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.3218 (0.3201)	Acc@1 96.484 (95.457)	Acc@5 99.609 (99.940)
Epoch: [109][128/196]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.3694 (0.3228)	Acc@1 92.969 (95.267)	Acc@5 100.000 (99.930)
Epoch: [109][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.3296 (0.3243)	Acc@1 95.312 (95.191)	Acc@5 99.609 (99.933)
Max memory in training epoch: 53.5021056
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.144 (0.144)	Data 0.310 (0.310)	Loss 0.3216 (0.3216)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.2918 (0.3066)	Acc@1 96.484 (95.829)	Acc@5 100.000 (99.910)
Epoch: [110][128/196]	Time 0.137 (0.122)	Data 0.000 (0.003)	Loss 0.2947 (0.3137)	Acc@1 95.703 (95.549)	Acc@5 100.000 (99.903)
Epoch: [110][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3077 (0.3209)	Acc@1 94.531 (95.302)	Acc@5 99.609 (99.895)
Max memory in training epoch: 53.5021056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 222920 ; 225376 ; 0.9891026551185574
[INFO] Storing checkpoint...
  90.22
Max memory: 82.672128
 23.982s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 826
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.0968704
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.177 (0.177)	Data 0.263 (0.263)	Loss 0.2884 (0.2884)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.126 (0.123)	Data 0.000 (0.004)	Loss 0.3011 (0.3101)	Acc@1 95.312 (95.493)	Acc@5 100.000 (99.946)
Epoch: [111][128/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.3797 (0.3162)	Acc@1 92.578 (95.282)	Acc@5 99.609 (99.927)
Epoch: [111][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2885 (0.3176)	Acc@1 96.875 (95.213)	Acc@5 100.000 (99.929)
Max memory in training epoch: 53.0261504
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.176 (0.176)	Data 0.258 (0.258)	Loss 0.2926 (0.2926)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.128 (0.122)	Data 0.000 (0.004)	Loss 0.3028 (0.3113)	Acc@1 96.094 (95.427)	Acc@5 100.000 (99.958)
Epoch: [112][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3697 (0.3139)	Acc@1 94.141 (95.288)	Acc@5 100.000 (99.936)
Epoch: [112][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3268 (0.3178)	Acc@1 94.531 (95.122)	Acc@5 100.000 (99.937)
Max memory in training epoch: 53.2882944
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.145 (0.145)	Data 0.293 (0.293)	Loss 0.3225 (0.3225)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [113][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.3085 (0.3090)	Acc@1 96.094 (95.270)	Acc@5 100.000 (99.874)
Epoch: [113][128/196]	Time 0.138 (0.123)	Data 0.000 (0.002)	Loss 0.3152 (0.3117)	Acc@1 95.312 (95.270)	Acc@5 100.000 (99.897)
Epoch: [113][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3721 (0.3116)	Acc@1 94.531 (95.278)	Acc@5 99.609 (99.921)
Max memory in training epoch: 53.2882944
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.173 (0.173)	Data 0.271 (0.271)	Loss 0.2903 (0.2903)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.124 (0.122)	Data 0.000 (0.004)	Loss 0.3162 (0.3072)	Acc@1 96.484 (95.451)	Acc@5 100.000 (99.940)
Epoch: [114][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3951 (0.3098)	Acc@1 92.188 (95.282)	Acc@5 100.000 (99.927)
Epoch: [114][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3022 (0.3120)	Acc@1 96.094 (95.181)	Acc@5 100.000 (99.919)
Max memory in training epoch: 53.2882944
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.179 (0.179)	Data 0.289 (0.289)	Loss 0.3178 (0.3178)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.3061 (0.3047)	Acc@1 95.312 (95.391)	Acc@5 100.000 (99.946)
Epoch: [115][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3005 (0.3063)	Acc@1 95.312 (95.285)	Acc@5 100.000 (99.949)
Epoch: [115][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3256 (0.3071)	Acc@1 94.531 (95.282)	Acc@5 99.609 (99.941)
Max memory in training epoch: 53.2882944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 217288 ; 222920 ; 0.9747353310604702
[INFO] Storing checkpoint...
  90.57
Max memory: 82.8959744
 24.390s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 65
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0946176
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.195 (0.195)	Data 0.267 (0.267)	Loss 0.3172 (0.3172)	Acc@1 94.922 (94.922)	Acc@5 99.219 (99.219)
Epoch: [116][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3177 (0.3094)	Acc@1 94.141 (95.162)	Acc@5 99.609 (99.892)
Epoch: [116][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.2965 (0.3093)	Acc@1 96.094 (95.122)	Acc@5 99.609 (99.903)
Epoch: [116][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3260 (0.3095)	Acc@1 94.531 (95.072)	Acc@5 99.609 (99.899)
Max memory in training epoch: 52.48384
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.164 (0.164)	Data 0.288 (0.288)	Loss 0.2748 (0.2748)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.122 (0.119)	Data 0.000 (0.005)	Loss 0.2911 (0.3101)	Acc@1 96.094 (95.006)	Acc@5 100.000 (99.904)
Epoch: [117][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2672 (0.3116)	Acc@1 96.875 (94.910)	Acc@5 100.000 (99.915)
Epoch: [117][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.3791 (0.3124)	Acc@1 92.578 (94.873)	Acc@5 100.000 (99.913)
Max memory in training epoch: 52.3879936
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.162 (0.162)	Data 0.272 (0.272)	Loss 0.3034 (0.3034)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.116 (0.118)	Data 0.000 (0.004)	Loss 0.3325 (0.2995)	Acc@1 91.797 (95.240)	Acc@5 100.000 (99.946)
Epoch: [118][128/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3081 (0.3034)	Acc@1 95.312 (95.137)	Acc@5 100.000 (99.939)
Epoch: [118][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.3145 (0.3079)	Acc@1 95.312 (94.936)	Acc@5 99.609 (99.919)
Max memory in training epoch: 52.3879936
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.166 (0.166)	Data 0.267 (0.267)	Loss 0.2812 (0.2812)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.115 (0.120)	Data 0.000 (0.004)	Loss 0.2864 (0.2978)	Acc@1 95.703 (95.270)	Acc@5 100.000 (99.928)
Epoch: [119][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3262 (0.2987)	Acc@1 94.922 (95.200)	Acc@5 100.000 (99.945)
Epoch: [119][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3675 (0.3040)	Acc@1 92.578 (95.064)	Acc@5 100.000 (99.945)
Max memory in training epoch: 52.3879936
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.164 (0.164)	Data 0.298 (0.298)	Loss 0.2703 (0.2703)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.108 (0.120)	Data 0.000 (0.005)	Loss 0.2849 (0.3076)	Acc@1 96.094 (95.018)	Acc@5 100.000 (99.934)
Epoch: [120][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3094 (0.3061)	Acc@1 94.922 (94.988)	Acc@5 100.000 (99.927)
Epoch: [120][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2988 (0.3089)	Acc@1 95.312 (94.922)	Acc@5 100.000 (99.923)
Max memory in training epoch: 52.3879936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 209782 ; 217288 ; 0.9654559846839218
[INFO] Storing checkpoint...
  89.15
Max memory: 82.7311104
 23.542s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2360
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0915456
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.3130 (0.3130)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.112 (0.119)	Data 0.000 (0.004)	Loss 0.2942 (0.3142)	Acc@1 94.531 (94.748)	Acc@5 99.609 (99.910)
Epoch: [121][128/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2759 (0.3138)	Acc@1 96.094 (94.643)	Acc@5 100.000 (99.927)
Epoch: [121][192/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3427 (0.3163)	Acc@1 95.312 (94.531)	Acc@5 100.000 (99.913)
Max memory in training epoch: 52.0451584
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.167 (0.167)	Data 0.311 (0.311)	Loss 0.2958 (0.2958)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.3169 (0.3098)	Acc@1 93.359 (94.742)	Acc@5 100.000 (99.928)
Epoch: [122][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.2690 (0.3133)	Acc@1 96.484 (94.637)	Acc@5 100.000 (99.903)
Epoch: [122][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2958 (0.3144)	Acc@1 94.531 (94.592)	Acc@5 100.000 (99.903)
Max memory in training epoch: 52.0349184
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.172 (0.172)	Data 0.270 (0.270)	Loss 0.3236 (0.3236)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.115 (0.118)	Data 0.000 (0.004)	Loss 0.2860 (0.3134)	Acc@1 95.703 (94.651)	Acc@5 100.000 (99.952)
Epoch: [123][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3011 (0.3101)	Acc@1 94.922 (94.725)	Acc@5 100.000 (99.949)
Epoch: [123][192/196]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3284 (0.3117)	Acc@1 94.141 (94.661)	Acc@5 100.000 (99.939)
Max memory in training epoch: 52.0349184
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.147 (0.147)	Data 0.295 (0.295)	Loss 0.2731 (0.2731)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.2847 (0.3014)	Acc@1 94.531 (94.748)	Acc@5 100.000 (99.952)
Epoch: [124][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2887 (0.3017)	Acc@1 95.312 (94.940)	Acc@5 100.000 (99.927)
Epoch: [124][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3216 (0.3047)	Acc@1 94.531 (94.896)	Acc@5 100.000 (99.929)
Max memory in training epoch: 52.0349184
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.166 (0.166)	Data 0.279 (0.279)	Loss 0.2924 (0.2924)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.3196 (0.3093)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.928)
Epoch: [125][128/196]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.3353 (0.3097)	Acc@1 94.141 (94.637)	Acc@5 100.000 (99.936)
Epoch: [125][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.2555 (0.3092)	Acc@1 96.875 (94.649)	Acc@5 100.000 (99.929)
Max memory in training epoch: 52.0349184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 199964 ; 209782 ; 0.9531990351889104
[INFO] Storing checkpoint...
  88.7
Max memory: 81.8166784
 23.753s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7555
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.087808
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.176 (0.176)	Data 0.287 (0.287)	Loss 0.2860 (0.2860)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.119 (0.118)	Data 0.000 (0.005)	Loss 0.3072 (0.3104)	Acc@1 94.141 (94.597)	Acc@5 100.000 (99.952)
Epoch: [126][128/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.3664 (0.3111)	Acc@1 91.406 (94.465)	Acc@5 99.609 (99.930)
Epoch: [126][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2919 (0.3143)	Acc@1 93.359 (94.333)	Acc@5 100.000 (99.907)
Max memory in training epoch: 50.9563392
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.163 (0.163)	Data 0.272 (0.272)	Loss 0.2917 (0.2917)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.120 (0.119)	Data 0.000 (0.004)	Loss 0.2832 (0.3071)	Acc@1 96.484 (94.627)	Acc@5 99.609 (99.904)
Epoch: [127][128/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.2809 (0.3079)	Acc@1 96.094 (94.456)	Acc@5 100.000 (99.918)
Epoch: [127][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3425 (0.3101)	Acc@1 93.750 (94.373)	Acc@5 100.000 (99.915)
Max memory in training epoch: 51.3056256
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.162 (0.162)	Data 0.262 (0.262)	Loss 0.2916 (0.2916)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.110 (0.121)	Data 0.000 (0.004)	Loss 0.3239 (0.3121)	Acc@1 93.750 (94.357)	Acc@5 100.000 (99.910)
Epoch: [128][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.2843 (0.3127)	Acc@1 95.312 (94.419)	Acc@5 100.000 (99.918)
Epoch: [128][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3441 (0.3136)	Acc@1 92.969 (94.347)	Acc@5 99.609 (99.909)
Max memory in training epoch: 51.3056256
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.146 (0.146)	Data 0.277 (0.277)	Loss 0.3165 (0.3165)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.118 (0.118)	Data 0.000 (0.004)	Loss 0.2817 (0.3089)	Acc@1 95.703 (94.525)	Acc@5 100.000 (99.886)
Epoch: [129][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.2992 (0.3088)	Acc@1 94.531 (94.416)	Acc@5 99.609 (99.915)
Epoch: [129][192/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3080 (0.3103)	Acc@1 94.141 (94.361)	Acc@5 100.000 (99.923)
Max memory in training epoch: 51.3056256
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.153 (0.153)	Data 0.301 (0.301)	Loss 0.2375 (0.2375)	Acc@1 98.047 (98.047)	Acc@5 99.609 (99.609)
Epoch: [130][64/196]	Time 0.127 (0.119)	Data 0.000 (0.005)	Loss 0.2583 (0.2969)	Acc@1 96.875 (94.940)	Acc@5 100.000 (99.916)
Epoch: [130][128/196]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.3320 (0.3012)	Acc@1 92.578 (94.764)	Acc@5 99.609 (99.897)
Epoch: [130][192/196]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.3398 (0.3088)	Acc@1 94.141 (94.464)	Acc@5 100.000 (99.903)
Max memory in training epoch: 51.3056256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 190004 ; 199964 ; 0.9501910343861895
[INFO] Storing checkpoint...
  88.61
Max memory: 80.5479936
 23.551s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8348
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.083968
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.199 (0.199)	Data 0.270 (0.270)	Loss 0.2619 (0.2619)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.3429 (0.3054)	Acc@1 94.141 (94.477)	Acc@5 99.219 (99.898)
Epoch: [131][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3194 (0.3141)	Acc@1 93.750 (94.147)	Acc@5 99.609 (99.885)
Epoch: [131][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3094 (0.3164)	Acc@1 94.922 (94.045)	Acc@5 100.000 (99.883)
Max memory in training epoch: 50.9101568
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.137 (0.137)	Data 0.307 (0.307)	Loss 0.2571 (0.2571)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.3606 (0.3104)	Acc@1 91.016 (94.141)	Acc@5 100.000 (99.910)
Epoch: [132][128/196]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.3055 (0.3141)	Acc@1 94.141 (94.098)	Acc@5 100.000 (99.897)
Epoch: [132][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3636 (0.3179)	Acc@1 92.969 (93.983)	Acc@5 99.609 (99.897)
Max memory in training epoch: 50.9101568
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.164 (0.164)	Data 0.319 (0.319)	Loss 0.2681 (0.2681)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.129 (0.124)	Data 0.000 (0.005)	Loss 0.2596 (0.3111)	Acc@1 96.484 (94.153)	Acc@5 100.000 (99.952)
Epoch: [133][128/196]	Time 0.127 (0.124)	Data 0.000 (0.003)	Loss 0.3098 (0.3093)	Acc@1 93.359 (94.234)	Acc@5 100.000 (99.912)
Epoch: [133][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.3586 (0.3109)	Acc@1 92.188 (94.207)	Acc@5 100.000 (99.903)
Max memory in training epoch: 50.9101568
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.162 (0.162)	Data 0.276 (0.276)	Loss 0.3353 (0.3353)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.112 (0.121)	Data 0.000 (0.004)	Loss 0.3124 (0.3108)	Acc@1 93.750 (94.171)	Acc@5 99.609 (99.856)
Epoch: [134][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3275 (0.3129)	Acc@1 94.141 (94.086)	Acc@5 100.000 (99.870)
Epoch: [134][192/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.2721 (0.3159)	Acc@1 94.922 (94.054)	Acc@5 100.000 (99.870)
Max memory in training epoch: 50.9101568
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.146 (0.146)	Data 0.299 (0.299)	Loss 0.3217 (0.3217)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.3315 (0.3119)	Acc@1 94.141 (94.213)	Acc@5 100.000 (99.898)
Epoch: [135][128/196]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.3583 (0.3129)	Acc@1 93.359 (94.280)	Acc@5 99.609 (99.903)
Epoch: [135][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3599 (0.3158)	Acc@1 92.578 (94.222)	Acc@5 100.000 (99.887)
Max memory in training epoch: 50.9101568
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 188290 ; 190004 ; 0.9909791372813204
[INFO] Storing checkpoint...
  88.22
Max memory: 79.726592
 23.937s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2335
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.0833024
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.174 (0.174)	Data 0.299 (0.299)	Loss 0.2727 (0.2727)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.114 (0.117)	Data 0.000 (0.005)	Loss 0.2928 (0.2989)	Acc@1 96.094 (94.748)	Acc@5 100.000 (99.928)
Epoch: [136][128/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3327 (0.3051)	Acc@1 93.359 (94.437)	Acc@5 100.000 (99.915)
Epoch: [136][192/196]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.3227 (0.3077)	Acc@1 93.750 (94.331)	Acc@5 100.000 (99.919)
Max memory in training epoch: 50.88128
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.173 (0.173)	Data 0.272 (0.272)	Loss 0.2991 (0.2991)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.2672 (0.3072)	Acc@1 95.312 (94.273)	Acc@5 100.000 (99.940)
Epoch: [137][128/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3635 (0.3101)	Acc@1 92.188 (94.119)	Acc@5 99.609 (99.906)
Epoch: [137][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3990 (0.3129)	Acc@1 90.234 (94.035)	Acc@5 100.000 (99.909)
Max memory in training epoch: 50.8943872
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.162 (0.162)	Data 0.291 (0.291)	Loss 0.2715 (0.2715)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.112 (0.117)	Data 0.000 (0.005)	Loss 0.3017 (0.2980)	Acc@1 94.531 (94.718)	Acc@5 100.000 (99.928)
Epoch: [138][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.2759 (0.3072)	Acc@1 95.703 (94.416)	Acc@5 100.000 (99.912)
Epoch: [138][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.2919 (0.3151)	Acc@1 94.922 (94.116)	Acc@5 100.000 (99.911)
Max memory in training epoch: 50.8943872
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.148 (0.148)	Data 0.297 (0.297)	Loss 0.2804 (0.2804)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2485 (0.2976)	Acc@1 96.484 (94.657)	Acc@5 100.000 (99.886)
Epoch: [139][128/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.2721 (0.3074)	Acc@1 94.922 (94.271)	Acc@5 100.000 (99.888)
Epoch: [139][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.2618 (0.3111)	Acc@1 97.266 (94.169)	Acc@5 100.000 (99.899)
Max memory in training epoch: 50.8943872
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.139 (0.139)	Data 0.302 (0.302)	Loss 0.3441 (0.3441)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.124 (0.120)	Data 0.000 (0.005)	Loss 0.2897 (0.3116)	Acc@1 96.484 (94.165)	Acc@5 100.000 (99.946)
Epoch: [140][128/196]	Time 0.110 (0.118)	Data 0.000 (0.003)	Loss 0.3047 (0.3074)	Acc@1 95.312 (94.389)	Acc@5 100.000 (99.933)
Epoch: [140][192/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3087 (0.3079)	Acc@1 94.531 (94.371)	Acc@5 98.828 (99.911)
Max memory in training epoch: 50.8943872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 186131 ; 188290 ; 0.9885336449094482
[INFO] Storing checkpoint...
  87.64
Max memory: 79.1753216
 23.467s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9320
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0825344
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.169 (0.169)	Data 0.299 (0.299)	Loss 0.3411 (0.3411)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.2997 (0.2990)	Acc@1 94.141 (94.615)	Acc@5 100.000 (99.952)
Epoch: [141][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3199 (0.3089)	Acc@1 94.531 (94.244)	Acc@5 100.000 (99.930)
Epoch: [141][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3663 (0.3130)	Acc@1 92.969 (94.141)	Acc@5 100.000 (99.907)
Max memory in training epoch: 50.3670272
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.177 (0.177)	Data 0.279 (0.279)	Loss 0.3117 (0.3117)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.122 (0.122)	Data 0.000 (0.004)	Loss 0.3223 (0.3037)	Acc@1 93.359 (94.435)	Acc@5 99.609 (99.922)
Epoch: [142][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2966 (0.3075)	Acc@1 94.531 (94.234)	Acc@5 99.609 (99.906)
Epoch: [142][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2553 (0.3094)	Acc@1 96.484 (94.161)	Acc@5 100.000 (99.915)
Max memory in training epoch: 50.1769728
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.180 (0.180)	Data 0.268 (0.268)	Loss 0.2411 (0.2411)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.116 (0.120)	Data 0.000 (0.004)	Loss 0.3167 (0.2998)	Acc@1 94.531 (94.633)	Acc@5 100.000 (99.946)
Epoch: [143][128/196]	Time 0.128 (0.120)	Data 0.000 (0.002)	Loss 0.2785 (0.3015)	Acc@1 94.922 (94.552)	Acc@5 100.000 (99.933)
Epoch: [143][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3441 (0.3047)	Acc@1 94.531 (94.434)	Acc@5 100.000 (99.933)
Max memory in training epoch: 50.1769728
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.172 (0.172)	Data 0.284 (0.284)	Loss 0.2621 (0.2621)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.127 (0.123)	Data 0.000 (0.005)	Loss 0.3441 (0.3078)	Acc@1 91.797 (94.363)	Acc@5 100.000 (99.880)
Epoch: [144][128/196]	Time 0.136 (0.124)	Data 0.000 (0.002)	Loss 0.3586 (0.3081)	Acc@1 91.406 (94.122)	Acc@5 100.000 (99.894)
Epoch: [144][192/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.3661 (0.3140)	Acc@1 92.578 (93.991)	Acc@5 100.000 (99.905)
Max memory in training epoch: 50.1769728
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.156 (0.156)	Data 0.289 (0.289)	Loss 0.3102 (0.3102)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.116 (0.121)	Data 0.000 (0.005)	Loss 0.2740 (0.2973)	Acc@1 95.703 (94.748)	Acc@5 100.000 (99.946)
Epoch: [145][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3002 (0.3045)	Acc@1 94.922 (94.383)	Acc@5 100.000 (99.936)
Epoch: [145][192/196]	Time 0.132 (0.120)	Data 0.000 (0.002)	Loss 0.3147 (0.3075)	Acc@1 94.531 (94.262)	Acc@5 100.000 (99.933)
Max memory in training epoch: 50.1769728
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 185263 ; 186131 ; 0.9953366177584604
[INFO] Storing checkpoint...
  88.17
Max memory: 79.1113728
 23.878s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4499
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0821248
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.182 (0.182)	Data 0.258 (0.258)	Loss 0.3217 (0.3217)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [146][64/196]	Time 0.123 (0.121)	Data 0.000 (0.004)	Loss 0.2594 (0.2938)	Acc@1 96.094 (94.778)	Acc@5 100.000 (99.922)
Epoch: [146][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.2669 (0.3071)	Acc@1 95.703 (94.310)	Acc@5 100.000 (99.909)
Epoch: [146][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3496 (0.3099)	Acc@1 93.359 (94.234)	Acc@5 100.000 (99.909)
Max memory in training epoch: 50.1687808
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.172 (0.172)	Data 0.284 (0.284)	Loss 0.2907 (0.2907)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.114 (0.120)	Data 0.000 (0.005)	Loss 0.2408 (0.3059)	Acc@1 96.875 (94.303)	Acc@5 100.000 (99.898)
Epoch: [147][128/196]	Time 0.137 (0.120)	Data 0.000 (0.002)	Loss 0.3155 (0.3021)	Acc@1 94.531 (94.480)	Acc@5 100.000 (99.918)
Epoch: [147][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.2945 (0.3069)	Acc@1 94.141 (94.276)	Acc@5 100.000 (99.903)
Max memory in training epoch: 50.0377088
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.156 (0.156)	Data 0.291 (0.291)	Loss 0.2963 (0.2963)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [148][64/196]	Time 0.107 (0.120)	Data 0.000 (0.005)	Loss 0.2724 (0.3039)	Acc@1 94.922 (94.333)	Acc@5 100.000 (99.916)
Epoch: [148][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3004 (0.3050)	Acc@1 93.750 (94.225)	Acc@5 100.000 (99.909)
Epoch: [148][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3282 (0.3077)	Acc@1 94.531 (94.157)	Acc@5 100.000 (99.895)
Max memory in training epoch: 50.0377088
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.166 (0.166)	Data 0.290 (0.290)	Loss 0.3445 (0.3445)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 0.3449 (0.3083)	Acc@1 93.750 (94.381)	Acc@5 100.000 (99.922)
Epoch: [149][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3310 (0.3089)	Acc@1 93.750 (94.298)	Acc@5 100.000 (99.930)
Epoch: [149][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3000 (0.3111)	Acc@1 94.531 (94.209)	Acc@5 100.000 (99.925)
Max memory in training epoch: 50.0377088
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.147 (0.147)	Data 0.305 (0.305)	Loss 0.3565 (0.3565)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.2682 (0.2780)	Acc@1 96.094 (95.349)	Acc@5 100.000 (99.922)
Epoch: [150][128/196]	Time 0.129 (0.121)	Data 0.000 (0.003)	Loss 0.2709 (0.2641)	Acc@1 94.531 (95.900)	Acc@5 100.000 (99.930)
Epoch: [150][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2598 (0.2588)	Acc@1 95.703 (96.130)	Acc@5 100.000 (99.933)
Max memory in training epoch: 50.0377088
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 182413 ; 185263 ; 0.9846164641617592
[INFO] Storing checkpoint...
  91.52
Max memory: 78.1848576
 24.055s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1965
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.080896
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.182 (0.182)	Data 0.277 (0.277)	Loss 0.2618 (0.2618)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [151][64/196]	Time 0.125 (0.119)	Data 0.000 (0.004)	Loss 0.2301 (0.2448)	Acc@1 97.266 (96.599)	Acc@5 100.000 (99.934)
Epoch: [151][128/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2143 (0.2421)	Acc@1 97.266 (96.718)	Acc@5 100.000 (99.949)
Epoch: [151][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3018 (0.2421)	Acc@1 95.312 (96.695)	Acc@5 100.000 (99.939)
Max memory in training epoch: 50.1376512
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.168 (0.168)	Data 0.289 (0.289)	Loss 0.2325 (0.2325)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.120 (0.118)	Data 0.000 (0.005)	Loss 0.2186 (0.2336)	Acc@1 97.656 (97.013)	Acc@5 100.000 (99.946)
Epoch: [152][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2420 (0.2365)	Acc@1 95.703 (96.820)	Acc@5 100.000 (99.961)
Epoch: [152][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.1695 (0.2346)	Acc@1 99.609 (96.936)	Acc@5 100.000 (99.962)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.174 (0.174)	Data 0.285 (0.285)	Loss 0.2793 (0.2793)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.116 (0.117)	Data 0.000 (0.005)	Loss 0.2391 (0.2215)	Acc@1 97.656 (97.344)	Acc@5 99.609 (99.958)
Epoch: [153][128/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.2502 (0.2231)	Acc@1 95.703 (97.302)	Acc@5 100.000 (99.958)
Epoch: [153][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2358 (0.2257)	Acc@1 96.484 (97.207)	Acc@5 100.000 (99.955)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.134 (0.134)	Data 0.294 (0.294)	Loss 0.1906 (0.1906)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.108 (0.117)	Data 0.000 (0.005)	Loss 0.2336 (0.2268)	Acc@1 96.484 (97.200)	Acc@5 100.000 (99.976)
Epoch: [154][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.2334 (0.2248)	Acc@1 97.656 (97.257)	Acc@5 99.609 (99.973)
Epoch: [154][192/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.1964 (0.2224)	Acc@1 98.828 (97.310)	Acc@5 100.000 (99.974)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.146 (0.146)	Data 0.306 (0.306)	Loss 0.2239 (0.2239)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.120 (0.118)	Data 0.000 (0.005)	Loss 0.2662 (0.2196)	Acc@1 94.922 (97.422)	Acc@5 100.000 (99.976)
Epoch: [155][128/196]	Time 0.121 (0.119)	Data 0.000 (0.003)	Loss 0.1969 (0.2198)	Acc@1 98.438 (97.469)	Acc@5 100.000 (99.973)
Epoch: [155][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2062 (0.2178)	Acc@1 96.875 (97.509)	Acc@5 100.000 (99.976)
Max memory in training epoch: 50.0000256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.87
Max memory: 78.4535552
 23.602s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3646
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.080896
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.173 (0.173)	Data 0.294 (0.294)	Loss 0.2015 (0.2015)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.137 (0.121)	Data 0.000 (0.005)	Loss 0.2019 (0.2128)	Acc@1 98.438 (97.722)	Acc@5 100.000 (99.988)
Epoch: [156][128/196]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.2223 (0.2128)	Acc@1 97.266 (97.726)	Acc@5 100.000 (99.985)
Epoch: [156][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.2034 (0.2136)	Acc@1 97.266 (97.691)	Acc@5 100.000 (99.980)
Max memory in training epoch: 50.1376512
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.162 (0.162)	Data 0.296 (0.296)	Loss 0.2024 (0.2024)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.1975 (0.2127)	Acc@1 98.438 (97.776)	Acc@5 100.000 (99.988)
Epoch: [157][128/196]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.1950 (0.2130)	Acc@1 98.438 (97.705)	Acc@5 100.000 (99.982)
Epoch: [157][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1994 (0.2129)	Acc@1 98.047 (97.689)	Acc@5 100.000 (99.980)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.144 (0.144)	Data 0.294 (0.294)	Loss 0.2203 (0.2203)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.110 (0.121)	Data 0.000 (0.005)	Loss 0.2003 (0.2130)	Acc@1 98.828 (97.614)	Acc@5 100.000 (99.976)
Epoch: [158][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2006 (0.2133)	Acc@1 97.266 (97.635)	Acc@5 100.000 (99.970)
Epoch: [158][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.1966 (0.2123)	Acc@1 98.828 (97.654)	Acc@5 100.000 (99.966)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.186 (0.186)	Data 0.309 (0.309)	Loss 0.1962 (0.1962)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.111 (0.121)	Data 0.000 (0.005)	Loss 0.2383 (0.2099)	Acc@1 96.484 (97.788)	Acc@5 100.000 (99.958)
Epoch: [159][128/196]	Time 0.120 (0.120)	Data 0.000 (0.003)	Loss 0.2269 (0.2105)	Acc@1 96.484 (97.741)	Acc@5 100.000 (99.970)
Epoch: [159][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.1694 (0.2108)	Acc@1 99.219 (97.776)	Acc@5 100.000 (99.968)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.162 (0.162)	Data 0.300 (0.300)	Loss 0.1933 (0.1933)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 0.1999 (0.2092)	Acc@1 97.656 (97.674)	Acc@5 100.000 (99.982)
Epoch: [160][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.1952 (0.2075)	Acc@1 98.828 (97.786)	Acc@5 100.000 (99.982)
Epoch: [160][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2218 (0.2078)	Acc@1 96.875 (97.786)	Acc@5 100.000 (99.968)
Max memory in training epoch: 50.0000256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.65
Max memory: 78.4535552
 23.843s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 815
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.080896
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.188 (0.188)	Data 0.251 (0.251)	Loss 0.1896 (0.1896)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.139 (0.118)	Data 0.000 (0.004)	Loss 0.1623 (0.2043)	Acc@1 99.609 (97.800)	Acc@5 100.000 (99.982)
Epoch: [161][128/196]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.1906 (0.2040)	Acc@1 98.828 (97.856)	Acc@5 100.000 (99.973)
Epoch: [161][192/196]	Time 0.114 (0.117)	Data 0.000 (0.001)	Loss 0.2136 (0.2035)	Acc@1 97.266 (97.891)	Acc@5 100.000 (99.976)
Max memory in training epoch: 50.1376512
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.171 (0.171)	Data 0.296 (0.296)	Loss 0.2144 (0.2144)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.2005 (0.2069)	Acc@1 98.047 (97.716)	Acc@5 100.000 (99.982)
Epoch: [162][128/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1872 (0.2042)	Acc@1 98.438 (97.850)	Acc@5 100.000 (99.985)
Epoch: [162][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1992 (0.2042)	Acc@1 98.438 (97.849)	Acc@5 100.000 (99.986)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.145 (0.145)	Data 0.265 (0.265)	Loss 0.1959 (0.1959)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.111 (0.117)	Data 0.000 (0.004)	Loss 0.1840 (0.2007)	Acc@1 98.047 (97.903)	Acc@5 100.000 (99.976)
Epoch: [163][128/196]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.2014 (0.2003)	Acc@1 97.656 (97.989)	Acc@5 100.000 (99.976)
Epoch: [163][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.2220 (0.2003)	Acc@1 96.875 (97.982)	Acc@5 100.000 (99.980)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.164 (0.164)	Data 0.256 (0.256)	Loss 0.2107 (0.2107)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.119 (0.118)	Data 0.000 (0.004)	Loss 0.1749 (0.2001)	Acc@1 99.219 (98.029)	Acc@5 100.000 (99.982)
Epoch: [164][128/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.1713 (0.2005)	Acc@1 99.609 (98.077)	Acc@5 100.000 (99.970)
Epoch: [164][192/196]	Time 0.116 (0.117)	Data 0.000 (0.001)	Loss 0.2100 (0.1994)	Acc@1 97.266 (98.093)	Acc@5 100.000 (99.978)
Max memory in training epoch: 50.0000256
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.147 (0.147)	Data 0.258 (0.258)	Loss 0.2138 (0.2138)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.117 (0.118)	Data 0.000 (0.004)	Loss 0.2029 (0.1981)	Acc@1 96.875 (97.981)	Acc@5 100.000 (99.982)
Epoch: [165][128/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.1817 (0.1987)	Acc@1 99.219 (98.056)	Acc@5 100.000 (99.985)
Epoch: [165][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1721 (0.1982)	Acc@1 99.219 (98.077)	Acc@5 100.000 (99.984)
Max memory in training epoch: 50.0000256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 181401 ; 182413 ; 0.9944521497919556
[INFO] Storing checkpoint...
  91.78
Max memory: 78.4535552
 23.325s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1603
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0805376
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.180 (0.180)	Data 0.280 (0.280)	Loss 0.2122 (0.2122)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.1701 (0.1968)	Acc@1 99.219 (97.999)	Acc@5 100.000 (99.976)
Epoch: [166][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2100 (0.1977)	Acc@1 97.266 (97.938)	Acc@5 100.000 (99.973)
Epoch: [166][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2016 (0.1992)	Acc@1 98.047 (97.938)	Acc@5 100.000 (99.976)
Max memory in training epoch: 50.1362176
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.174 (0.174)	Data 0.268 (0.268)	Loss 0.1996 (0.1996)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.1766 (0.1938)	Acc@1 98.047 (98.161)	Acc@5 100.000 (99.964)
Epoch: [167][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.2017 (0.1948)	Acc@1 98.047 (98.110)	Acc@5 100.000 (99.982)
Epoch: [167][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2069 (0.1963)	Acc@1 97.656 (98.037)	Acc@5 100.000 (99.984)
Max memory in training epoch: 49.9068416
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.146 (0.146)	Data 0.269 (0.269)	Loss 0.2007 (0.2007)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.128 (0.117)	Data 0.000 (0.004)	Loss 0.1944 (0.1916)	Acc@1 98.438 (98.329)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.1752 (0.1927)	Acc@1 98.828 (98.271)	Acc@5 100.000 (99.994)
Epoch: [168][192/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.1784 (0.1936)	Acc@1 98.047 (98.209)	Acc@5 100.000 (99.996)
Max memory in training epoch: 49.9068416
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.154 (0.154)	Data 0.295 (0.295)	Loss 0.1685 (0.1685)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.133 (0.119)	Data 0.000 (0.005)	Loss 0.1780 (0.1939)	Acc@1 99.219 (98.137)	Acc@5 100.000 (99.988)
Epoch: [169][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.2226 (0.1947)	Acc@1 97.266 (98.132)	Acc@5 100.000 (99.979)
Epoch: [169][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1968 (0.1956)	Acc@1 98.828 (98.114)	Acc@5 100.000 (99.984)
Max memory in training epoch: 49.9068416
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.167 (0.167)	Data 0.260 (0.260)	Loss 0.1828 (0.1828)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.2066 (0.1917)	Acc@1 98.047 (98.155)	Acc@5 100.000 (99.958)
Epoch: [170][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.1981 (0.1923)	Acc@1 97.656 (98.162)	Acc@5 100.000 (99.970)
Epoch: [170][192/196]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.2070 (0.1925)	Acc@1 97.656 (98.146)	Acc@5 99.609 (99.970)
Max memory in training epoch: 49.9068416
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 179129 ; 181401 ; 0.9874752619886329
[INFO] Storing checkpoint...
  91.85
Max memory: 78.0498432
 23.541s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4348
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.079616
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.188 (0.188)	Data 0.282 (0.282)	Loss 0.2117 (0.2117)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.1947 (0.2083)	Acc@1 98.047 (97.728)	Acc@5 100.000 (99.964)
Epoch: [171][128/196]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.2301 (0.2085)	Acc@1 97.656 (97.696)	Acc@5 100.000 (99.970)
Epoch: [171][192/196]	Time 0.116 (0.124)	Data 0.000 (0.002)	Loss 0.1915 (0.2079)	Acc@1 98.438 (97.737)	Acc@5 100.000 (99.970)
Max memory in training epoch: 50.119424
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.171 (0.171)	Data 0.273 (0.273)	Loss 0.1967 (0.1967)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.137 (0.123)	Data 0.000 (0.004)	Loss 0.1900 (0.2007)	Acc@1 99.609 (98.041)	Acc@5 100.000 (99.982)
Epoch: [172][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.2042 (0.2016)	Acc@1 98.047 (97.944)	Acc@5 100.000 (99.985)
Epoch: [172][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2215 (0.2013)	Acc@1 97.266 (97.903)	Acc@5 100.000 (99.982)
Max memory in training epoch: 49.890048
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.166 (0.166)	Data 0.257 (0.257)	Loss 0.1901 (0.1901)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.1796 (0.1954)	Acc@1 98.047 (98.203)	Acc@5 100.000 (99.988)
Epoch: [173][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.1595 (0.1964)	Acc@1 99.609 (98.162)	Acc@5 100.000 (99.982)
Epoch: [173][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2154 (0.1968)	Acc@1 97.656 (98.136)	Acc@5 100.000 (99.986)
Max memory in training epoch: 49.890048
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.174 (0.174)	Data 0.268 (0.268)	Loss 0.2245 (0.2245)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [174][64/196]	Time 0.121 (0.120)	Data 0.000 (0.004)	Loss 0.2157 (0.1927)	Acc@1 96.875 (98.191)	Acc@5 100.000 (99.994)
Epoch: [174][128/196]	Time 0.138 (0.120)	Data 0.000 (0.002)	Loss 0.1990 (0.1935)	Acc@1 97.656 (98.192)	Acc@5 100.000 (99.991)
Epoch: [174][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2106 (0.1954)	Acc@1 96.875 (98.110)	Acc@5 100.000 (99.990)
Max memory in training epoch: 49.890048
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.167 (0.167)	Data 0.286 (0.286)	Loss 0.1798 (0.1798)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.1925 (0.1931)	Acc@1 97.656 (98.155)	Acc@5 100.000 (99.982)
Epoch: [175][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1979 (0.1953)	Acc@1 98.438 (98.132)	Acc@5 99.609 (99.976)
Epoch: [175][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1856 (0.1953)	Acc@1 97.656 (98.106)	Acc@5 100.000 (99.972)
Max memory in training epoch: 49.890048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.72
Max memory: 78.2873088
 23.821s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2744
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.079616
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.201 (0.201)	Data 0.294 (0.294)	Loss 0.1864 (0.1864)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.1880 (0.1918)	Acc@1 98.828 (98.203)	Acc@5 100.000 (99.970)
Epoch: [176][128/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.1814 (0.1913)	Acc@1 98.828 (98.219)	Acc@5 99.609 (99.976)
Epoch: [176][192/196]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.1996 (0.1925)	Acc@1 98.047 (98.170)	Acc@5 100.000 (99.976)
Max memory in training epoch: 50.119424
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.171 (0.171)	Data 0.281 (0.281)	Loss 0.1790 (0.1790)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.114 (0.121)	Data 0.000 (0.005)	Loss 0.2383 (0.1928)	Acc@1 96.094 (98.149)	Acc@5 100.000 (99.988)
Epoch: [177][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2347 (0.1918)	Acc@1 96.484 (98.207)	Acc@5 100.000 (99.985)
Epoch: [177][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.1698 (0.1920)	Acc@1 98.438 (98.174)	Acc@5 100.000 (99.976)
Max memory in training epoch: 49.890048
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.146 (0.146)	Data 0.298 (0.298)	Loss 0.1830 (0.1830)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.129 (0.120)	Data 0.000 (0.005)	Loss 0.1756 (0.1872)	Acc@1 98.438 (98.419)	Acc@5 100.000 (99.994)
Epoch: [178][128/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2267 (0.1898)	Acc@1 98.047 (98.313)	Acc@5 99.609 (99.985)
Epoch: [178][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2136 (0.1900)	Acc@1 97.656 (98.272)	Acc@5 100.000 (99.986)
Max memory in training epoch: 49.890048
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.152 (0.152)	Data 0.293 (0.293)	Loss 0.1908 (0.1908)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.116 (0.118)	Data 0.000 (0.005)	Loss 0.2191 (0.1923)	Acc@1 98.438 (98.095)	Acc@5 100.000 (99.982)
Epoch: [179][128/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.2132 (0.1877)	Acc@1 97.656 (98.268)	Acc@5 100.000 (99.985)
Epoch: [179][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2263 (0.1884)	Acc@1 96.875 (98.253)	Acc@5 100.000 (99.984)
Max memory in training epoch: 49.890048
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.170 (0.170)	Data 0.294 (0.294)	Loss 0.1732 (0.1732)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.2140 (0.1845)	Acc@1 97.656 (98.383)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.1814 (0.1854)	Acc@1 98.047 (98.344)	Acc@5 100.000 (99.994)
Epoch: [180][192/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.1855 (0.1858)	Acc@1 98.438 (98.342)	Acc@5 100.000 (99.994)
Max memory in training epoch: 49.890048
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(14, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(22, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(10, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(31, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(63, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(48, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(63, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(4, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(63, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(14, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(63, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(8, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=63, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  91.44
Max memory: 78.2873088
 23.462s  Thres 0.1 4
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4792
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.210 (0.210)	Data 0.262 (0.262)	Loss 3.4948 (3.4948)	Acc@1 12.109 (12.109)	Acc@5 50.000 (50.000)
Epoch: [1][64/196]	Time 0.131 (0.133)	Data 0.000 (0.004)	Loss 2.4794 (2.7818)	Acc@1 28.516 (20.775)	Acc@5 87.500 (73.804)
Epoch: [1][128/196]	Time 0.125 (0.133)	Data 0.000 (0.002)	Loss 2.1568 (2.5928)	Acc@1 41.016 (26.844)	Acc@5 91.016 (80.393)
Epoch: [1][192/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 2.1330 (2.4524)	Acc@1 41.797 (31.730)	Acc@5 92.969 (84.047)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.177 (0.177)	Data 0.296 (0.296)	Loss 2.1961 (2.1961)	Acc@1 39.453 (39.453)	Acc@5 90.234 (90.234)
Epoch: [2][64/196]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 1.8503 (1.9728)	Acc@1 53.125 (48.804)	Acc@5 96.875 (93.696)
Epoch: [2][128/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 1.8917 (1.8935)	Acc@1 53.516 (51.802)	Acc@5 94.531 (94.292)
Epoch: [2][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.6219 (1.8298)	Acc@1 59.766 (54.018)	Acc@5 96.875 (94.817)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.177 (0.177)	Data 0.294 (0.294)	Loss 1.6425 (1.6425)	Acc@1 60.156 (60.156)	Acc@5 95.703 (95.703)
Epoch: [3][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 1.5140 (1.6077)	Acc@1 66.406 (61.605)	Acc@5 97.656 (96.256)
Epoch: [3][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 1.5394 (1.5500)	Acc@1 61.719 (63.345)	Acc@5 97.266 (96.557)
Epoch: [3][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 1.5443 (1.5136)	Acc@1 64.844 (64.340)	Acc@5 94.922 (96.750)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.172 (0.172)	Data 0.287 (0.287)	Loss 1.5749 (1.5749)	Acc@1 60.938 (60.938)	Acc@5 97.656 (97.656)
Epoch: [4][64/196]	Time 0.123 (0.129)	Data 0.000 (0.005)	Loss 1.2790 (1.3591)	Acc@1 70.703 (69.014)	Acc@5 99.219 (97.530)
Epoch: [4][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 1.4102 (1.3244)	Acc@1 69.141 (69.898)	Acc@5 96.094 (97.680)
Epoch: [4][192/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 1.3740 (1.2959)	Acc@1 66.016 (70.711)	Acc@5 96.094 (97.755)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.164 (0.164)	Data 0.292 (0.292)	Loss 1.2523 (1.2523)	Acc@1 73.047 (73.047)	Acc@5 98.438 (98.438)
Epoch: [5][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 1.2137 (1.1768)	Acc@1 75.000 (73.768)	Acc@5 98.438 (98.179)
Epoch: [5][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.1584 (1.1627)	Acc@1 76.172 (74.164)	Acc@5 96.875 (98.186)
Epoch: [5][192/196]	Time 0.140 (0.130)	Data 0.000 (0.002)	Loss 1.0556 (1.1419)	Acc@1 77.734 (74.626)	Acc@5 98.828 (98.288)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 318030 ; 487386 ; 0.6525218204872524
[INFO] Storing checkpoint...
  69.16
Max memory: 103.3835008
 25.959s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4437
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1351168
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.181 (0.181)	Data 0.287 (0.287)	Loss 1.0682 (1.0682)	Acc@1 72.656 (72.656)	Acc@5 98.438 (98.438)
Epoch: [6][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.9754 (1.0105)	Acc@1 75.781 (76.424)	Acc@5 98.828 (98.600)
Epoch: [6][128/196]	Time 0.146 (0.131)	Data 0.000 (0.002)	Loss 0.9223 (1.0085)	Acc@1 80.859 (76.453)	Acc@5 98.828 (98.543)
Epoch: [6][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.9843 (1.0037)	Acc@1 78.906 (76.585)	Acc@5 98.438 (98.599)
Max memory in training epoch: 64.5814784
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.177 (0.177)	Data 0.267 (0.267)	Loss 0.9700 (0.9700)	Acc@1 77.344 (77.344)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.9340 (0.9564)	Acc@1 77.734 (77.692)	Acc@5 100.000 (98.732)
Epoch: [7][128/196]	Time 0.142 (0.130)	Data 0.000 (0.002)	Loss 0.8401 (0.9584)	Acc@1 82.422 (77.598)	Acc@5 99.219 (98.713)
Epoch: [7][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8032 (0.9433)	Acc@1 84.375 (78.026)	Acc@5 98.438 (98.751)
Max memory in training epoch: 64.7780864
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.175 (0.175)	Data 0.314 (0.314)	Loss 1.0181 (1.0181)	Acc@1 75.391 (75.391)	Acc@5 98.828 (98.828)
Epoch: [8][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8864 (0.9059)	Acc@1 80.469 (79.297)	Acc@5 99.219 (98.732)
Epoch: [8][128/196]	Time 0.122 (0.130)	Data 0.000 (0.003)	Loss 0.9733 (0.8967)	Acc@1 77.344 (79.442)	Acc@5 99.609 (98.810)
Epoch: [8][192/196]	Time 0.154 (0.129)	Data 0.000 (0.002)	Loss 0.8264 (0.8925)	Acc@1 82.031 (79.536)	Acc@5 100.000 (98.873)
Max memory in training epoch: 64.7780864
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.172 (0.172)	Data 0.299 (0.299)	Loss 0.8867 (0.8867)	Acc@1 80.469 (80.469)	Acc@5 97.656 (97.656)
Epoch: [9][64/196]	Time 0.121 (0.130)	Data 0.000 (0.005)	Loss 0.9001 (0.8695)	Acc@1 79.688 (80.222)	Acc@5 99.609 (98.924)
Epoch: [9][128/196]	Time 0.136 (0.129)	Data 0.000 (0.002)	Loss 0.7755 (0.8742)	Acc@1 84.375 (79.963)	Acc@5 98.828 (98.916)
Epoch: [9][192/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.8742 (0.8639)	Acc@1 80.469 (80.193)	Acc@5 99.219 (98.948)
Max memory in training epoch: 64.7780864
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.166 (0.166)	Data 0.270 (0.270)	Loss 0.9694 (0.9694)	Acc@1 78.125 (78.125)	Acc@5 97.266 (97.266)
Epoch: [10][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.8937 (0.8305)	Acc@1 77.344 (81.250)	Acc@5 99.219 (98.942)
Epoch: [10][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.8009 (0.8334)	Acc@1 82.422 (81.096)	Acc@5 99.219 (99.031)
Epoch: [10][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8687 (0.8354)	Acc@1 77.344 (81.066)	Acc@5 98.828 (99.010)
Max memory in training epoch: 64.7780864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 248134 ; 318030 ; 0.7802219916360091
[INFO] Storing checkpoint...
  66.5
Max memory: 100.4508672
 25.715s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3836
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.10752
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.198 (0.198)	Data 0.269 (0.269)	Loss 0.8807 (0.8807)	Acc@1 78.906 (78.906)	Acc@5 98.438 (98.438)
Epoch: [11][64/196]	Time 0.123 (0.131)	Data 0.000 (0.004)	Loss 0.8993 (0.8209)	Acc@1 77.734 (80.685)	Acc@5 98.438 (98.954)
Epoch: [11][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.8104 (0.8138)	Acc@1 81.641 (80.993)	Acc@5 98.828 (98.986)
Epoch: [11][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.8293 (0.8177)	Acc@1 80.078 (80.799)	Acc@5 99.219 (98.998)
Max memory in training epoch: 61.2911616
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.182 (0.182)	Data 0.293 (0.293)	Loss 0.7449 (0.7449)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.6985 (0.8028)	Acc@1 85.156 (81.370)	Acc@5 98.828 (98.954)
Epoch: [12][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8043 (0.8069)	Acc@1 80.469 (81.341)	Acc@5 98.828 (98.980)
Epoch: [12][192/196]	Time 0.158 (0.129)	Data 0.000 (0.002)	Loss 0.7892 (0.8054)	Acc@1 79.297 (81.388)	Acc@5 99.219 (99.008)
Max memory in training epoch: 61.2336128
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.178 (0.178)	Data 0.298 (0.298)	Loss 0.7910 (0.7910)	Acc@1 80.469 (80.469)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.9739 (0.7852)	Acc@1 75.000 (82.145)	Acc@5 98.828 (99.165)
Epoch: [13][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7858 (0.7924)	Acc@1 82.031 (81.874)	Acc@5 100.000 (99.179)
Epoch: [13][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8375 (0.7963)	Acc@1 79.688 (81.817)	Acc@5 98.828 (99.059)
Max memory in training epoch: 61.2336128
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.166 (0.166)	Data 0.300 (0.300)	Loss 0.9184 (0.9184)	Acc@1 77.734 (77.734)	Acc@5 99.219 (99.219)
Epoch: [14][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.7843 (0.7904)	Acc@1 82.031 (81.923)	Acc@5 100.000 (99.147)
Epoch: [14][128/196]	Time 0.124 (0.129)	Data 0.000 (0.003)	Loss 0.8780 (0.7813)	Acc@1 81.250 (82.498)	Acc@5 98.828 (99.143)
Epoch: [14][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7612 (0.7872)	Acc@1 81.250 (82.234)	Acc@5 99.219 (99.128)
Max memory in training epoch: 61.2336128
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.147 (0.147)	Data 0.307 (0.307)	Loss 0.8091 (0.8091)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [15][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.8380 (0.7920)	Acc@1 80.078 (82.037)	Acc@5 98.828 (99.093)
Epoch: [15][128/196]	Time 0.123 (0.128)	Data 0.000 (0.003)	Loss 0.8660 (0.7815)	Acc@1 81.250 (82.522)	Acc@5 98.828 (99.098)
Epoch: [15][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.8259 (0.7820)	Acc@1 81.250 (82.426)	Acc@5 99.219 (99.132)
Max memory in training epoch: 61.2336128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 237908 ; 248134 ; 0.9587883965921639
[INFO] Storing checkpoint...
  72.52
Max memory: 95.5041792
 25.514s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4006
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1033728
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.226 (0.226)	Data 0.252 (0.252)	Loss 0.7925 (0.7925)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.8316 (0.7623)	Acc@1 80.859 (82.855)	Acc@5 98.438 (99.279)
Epoch: [16][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.7675 (0.7683)	Acc@1 83.203 (82.682)	Acc@5 97.656 (99.191)
Epoch: [16][192/196]	Time 0.125 (0.127)	Data 0.000 (0.001)	Loss 0.7064 (0.7758)	Acc@1 84.766 (82.361)	Acc@5 99.609 (99.160)
Max memory in training epoch: 59.7490176
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.156 (0.156)	Data 0.309 (0.309)	Loss 0.7944 (0.7944)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.126 (0.126)	Data 0.000 (0.005)	Loss 0.7930 (0.7623)	Acc@1 79.297 (83.215)	Acc@5 99.219 (99.189)
Epoch: [17][128/196]	Time 0.119 (0.126)	Data 0.000 (0.003)	Loss 0.7922 (0.7682)	Acc@1 83.203 (82.779)	Acc@5 99.609 (99.158)
Epoch: [17][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7322 (0.7665)	Acc@1 82.422 (82.837)	Acc@5 99.609 (99.168)
Max memory in training epoch: 59.6638208
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.180 (0.180)	Data 0.264 (0.264)	Loss 0.8603 (0.8603)	Acc@1 79.297 (79.297)	Acc@5 98.828 (98.828)
Epoch: [18][64/196]	Time 0.131 (0.127)	Data 0.000 (0.004)	Loss 0.8268 (0.7673)	Acc@1 85.156 (82.969)	Acc@5 99.609 (99.225)
Epoch: [18][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7371 (0.7612)	Acc@1 82.422 (82.982)	Acc@5 98.828 (99.249)
Epoch: [18][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7628 (0.7634)	Acc@1 81.250 (82.934)	Acc@5 99.219 (99.213)
Max memory in training epoch: 59.6310528
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.187 (0.187)	Data 0.288 (0.288)	Loss 0.7769 (0.7769)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.130 (0.125)	Data 0.000 (0.005)	Loss 0.8159 (0.7574)	Acc@1 81.641 (83.431)	Acc@5 99.609 (99.195)
Epoch: [19][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7947 (0.7534)	Acc@1 83.984 (83.373)	Acc@5 99.609 (99.182)
Epoch: [19][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7198 (0.7546)	Acc@1 84.375 (83.339)	Acc@5 99.609 (99.190)
Max memory in training epoch: 59.6310528
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.179 (0.179)	Data 0.288 (0.288)	Loss 0.8118 (0.8118)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.8192 (0.7413)	Acc@1 81.250 (83.846)	Acc@5 99.219 (99.195)
Epoch: [20][128/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.7829 (0.7476)	Acc@1 81.641 (83.657)	Acc@5 98.828 (99.161)
Epoch: [20][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.8530 (0.7535)	Acc@1 77.734 (83.484)	Acc@5 98.047 (99.146)
Max memory in training epoch: 59.6310528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 230160 ; 237908 ; 0.9674327891453839
[INFO] Storing checkpoint...
  70.81
Max memory: 92.771584
 25.314s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5384
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1005056
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.179 (0.179)	Data 0.267 (0.267)	Loss 0.7463 (0.7463)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.128 (0.128)	Data 0.000 (0.004)	Loss 0.6571 (0.7227)	Acc@1 86.328 (84.303)	Acc@5 99.219 (99.273)
Epoch: [21][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7606 (0.7269)	Acc@1 83.203 (84.084)	Acc@5 100.000 (99.255)
Epoch: [21][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7565 (0.7397)	Acc@1 84.375 (83.677)	Acc@5 99.609 (99.253)
Max memory in training epoch: 58.2826496
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.174 (0.174)	Data 0.261 (0.261)	Loss 0.7891 (0.7891)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 0.129 (0.128)	Data 0.000 (0.004)	Loss 0.7371 (0.7370)	Acc@1 85.547 (84.171)	Acc@5 98.438 (99.231)
Epoch: [22][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.7066 (0.7335)	Acc@1 83.594 (84.118)	Acc@5 99.609 (99.237)
Epoch: [22][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6977 (0.7412)	Acc@1 84.766 (83.756)	Acc@5 99.609 (99.201)
Max memory in training epoch: 58.0270592
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.170 (0.170)	Data 0.297 (0.297)	Loss 0.6964 (0.6964)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.131 (0.127)	Data 0.000 (0.005)	Loss 0.7166 (0.7232)	Acc@1 83.594 (84.417)	Acc@5 99.609 (99.303)
Epoch: [23][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7694 (0.7325)	Acc@1 83.984 (84.139)	Acc@5 98.438 (99.249)
Epoch: [23][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.6697 (0.7374)	Acc@1 87.109 (83.942)	Acc@5 100.000 (99.263)
Max memory in training epoch: 58.0270592
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.165 (0.165)	Data 0.273 (0.273)	Loss 0.6711 (0.6711)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [24][64/196]	Time 0.124 (0.127)	Data 0.000 (0.004)	Loss 0.6747 (0.7206)	Acc@1 86.719 (84.519)	Acc@5 99.219 (99.291)
Epoch: [24][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6455 (0.7232)	Acc@1 86.328 (84.314)	Acc@5 100.000 (99.273)
Epoch: [24][192/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.6533 (0.7306)	Acc@1 86.328 (84.059)	Acc@5 99.609 (99.257)
Max memory in training epoch: 58.0270592
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.182 (0.182)	Data 0.291 (0.291)	Loss 0.7309 (0.7309)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.7658 (0.7130)	Acc@1 84.375 (84.742)	Acc@5 99.219 (99.339)
Epoch: [25][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.8248 (0.7238)	Acc@1 81.641 (84.393)	Acc@5 99.219 (99.270)
Epoch: [25][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.8255 (0.7313)	Acc@1 80.859 (84.118)	Acc@5 97.656 (99.243)
Max memory in training epoch: 58.0270592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 225428 ; 230160 ; 0.9794403892944039
[INFO] Storing checkpoint...
  73.78
Max memory: 90.2636032
 25.450s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1719
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.0987136
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.205 (0.205)	Data 0.258 (0.258)	Loss 0.8019 (0.8019)	Acc@1 82.422 (82.422)	Acc@5 98.438 (98.438)
Epoch: [26][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.6678 (0.7169)	Acc@1 85.547 (84.417)	Acc@5 99.219 (99.249)
Epoch: [26][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.7934 (0.7296)	Acc@1 80.469 (84.078)	Acc@5 100.000 (99.267)
Epoch: [26][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7643 (0.7329)	Acc@1 83.594 (84.023)	Acc@5 99.219 (99.253)
Max memory in training epoch: 57.4956032
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.181 (0.181)	Data 0.250 (0.250)	Loss 0.6917 (0.6917)	Acc@1 86.719 (86.719)	Acc@5 98.828 (98.828)
Epoch: [27][64/196]	Time 0.124 (0.127)	Data 0.000 (0.004)	Loss 0.6464 (0.7242)	Acc@1 86.719 (84.423)	Acc@5 99.609 (99.267)
Epoch: [27][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7436 (0.7242)	Acc@1 84.375 (84.478)	Acc@5 99.609 (99.252)
Epoch: [27][192/196]	Time 0.126 (0.127)	Data 0.000 (0.001)	Loss 0.7866 (0.7226)	Acc@1 83.203 (84.444)	Acc@5 98.828 (99.294)
Max memory in training epoch: 57.3972992
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.144 (0.144)	Data 0.299 (0.299)	Loss 0.6889 (0.6889)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.8141 (0.7289)	Acc@1 81.250 (83.876)	Acc@5 99.609 (99.255)
Epoch: [28][128/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.6191 (0.7232)	Acc@1 83.984 (84.084)	Acc@5 99.219 (99.301)
Epoch: [28][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7192 (0.7271)	Acc@1 82.422 (84.011)	Acc@5 99.609 (99.358)
Max memory in training epoch: 57.3972992
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.165 (0.165)	Data 0.260 (0.260)	Loss 0.7470 (0.7470)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [29][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7378 (0.7069)	Acc@1 83.594 (85.186)	Acc@5 99.219 (99.315)
Epoch: [29][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.8110 (0.7211)	Acc@1 82.031 (84.532)	Acc@5 98.438 (99.297)
Epoch: [29][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7366 (0.7224)	Acc@1 82.422 (84.430)	Acc@5 98.828 (99.330)
Max memory in training epoch: 57.3972992
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.165 (0.165)	Data 0.252 (0.252)	Loss 0.6785 (0.6785)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.132 (0.129)	Data 0.000 (0.004)	Loss 0.7348 (0.7246)	Acc@1 86.328 (84.207)	Acc@5 98.438 (99.231)
Epoch: [30][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6551 (0.7140)	Acc@1 86.328 (84.623)	Acc@5 100.000 (99.279)
Epoch: [30][192/196]	Time 0.124 (0.130)	Data 0.000 (0.001)	Loss 0.6799 (0.7186)	Acc@1 87.109 (84.468)	Acc@5 98.828 (99.269)
Max memory in training epoch: 57.3972992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 220844 ; 225428 ; 0.979665347694164
[INFO] Storing checkpoint...
  67.94
Max memory: 89.5039488
 25.726s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6682
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.096768
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.206 (0.206)	Data 0.284 (0.284)	Loss 0.7176 (0.7176)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.6481 (0.6819)	Acc@1 86.328 (85.757)	Acc@5 99.609 (99.411)
Epoch: [31][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7703 (0.7052)	Acc@1 82.812 (84.896)	Acc@5 98.828 (99.258)
Epoch: [31][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7211 (0.7117)	Acc@1 85.547 (84.802)	Acc@5 98.828 (99.267)
Max memory in training epoch: 57.1994624
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.155 (0.155)	Data 0.277 (0.277)	Loss 0.7174 (0.7174)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.7232 (0.7177)	Acc@1 84.375 (84.736)	Acc@5 99.219 (99.309)
Epoch: [32][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7392 (0.7164)	Acc@1 83.984 (84.617)	Acc@5 98.828 (99.328)
Epoch: [32][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7673 (0.7117)	Acc@1 82.422 (84.745)	Acc@5 99.609 (99.342)
Max memory in training epoch: 57.1208192
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.149 (0.149)	Data 0.258 (0.258)	Loss 0.7367 (0.7367)	Acc@1 81.250 (81.250)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.128 (0.126)	Data 0.000 (0.004)	Loss 0.6695 (0.7079)	Acc@1 86.328 (84.645)	Acc@5 98.828 (99.369)
Epoch: [33][128/196]	Time 0.132 (0.126)	Data 0.000 (0.002)	Loss 0.6887 (0.7100)	Acc@1 87.109 (84.735)	Acc@5 99.219 (99.394)
Epoch: [33][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7379 (0.7129)	Acc@1 85.156 (84.666)	Acc@5 99.609 (99.371)
Max memory in training epoch: 57.1208192
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.168 (0.168)	Data 0.289 (0.289)	Loss 0.7376 (0.7376)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [34][64/196]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.7139 (0.7035)	Acc@1 85.156 (85.036)	Acc@5 99.219 (99.303)
Epoch: [34][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6904 (0.7113)	Acc@1 84.766 (84.605)	Acc@5 100.000 (99.361)
Epoch: [34][192/196]	Time 0.134 (0.125)	Data 0.000 (0.002)	Loss 0.6555 (0.7120)	Acc@1 85.547 (84.695)	Acc@5 99.609 (99.334)
Max memory in training epoch: 57.1208192
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.175 (0.175)	Data 0.258 (0.258)	Loss 0.7419 (0.7419)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [35][64/196]	Time 0.129 (0.125)	Data 0.000 (0.004)	Loss 0.6704 (0.7050)	Acc@1 88.672 (84.934)	Acc@5 99.219 (99.381)
Epoch: [35][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.7314 (0.6986)	Acc@1 84.766 (85.293)	Acc@5 99.219 (99.367)
Epoch: [35][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7332 (0.7080)	Acc@1 82.812 (84.909)	Acc@5 98.438 (99.366)
Max memory in training epoch: 57.1208192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 216238 ; 220844 ; 0.9791436489105432
[INFO] Storing checkpoint...
  72.47
Max memory: 89.3279232
 25.045s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4909
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.0949248
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.190 (0.190)	Data 0.255 (0.255)	Loss 0.7698 (0.7698)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.122 (0.125)	Data 0.000 (0.004)	Loss 0.7113 (0.6765)	Acc@1 83.984 (85.727)	Acc@5 99.609 (99.405)
Epoch: [36][128/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.8080 (0.6965)	Acc@1 80.469 (84.956)	Acc@5 98.828 (99.373)
Epoch: [36][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6778 (0.6954)	Acc@1 85.156 (85.094)	Acc@5 99.219 (99.381)
Max memory in training epoch: 56.595712
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.154 (0.154)	Data 0.255 (0.255)	Loss 0.6322 (0.6322)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.128 (0.126)	Data 0.000 (0.004)	Loss 0.7948 (0.6861)	Acc@1 83.203 (85.667)	Acc@5 98.828 (99.501)
Epoch: [37][128/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.5399 (0.6963)	Acc@1 90.625 (85.226)	Acc@5 99.609 (99.406)
Epoch: [37][192/196]	Time 0.122 (0.125)	Data 0.000 (0.001)	Loss 0.7439 (0.7025)	Acc@1 83.203 (85.065)	Acc@5 99.609 (99.403)
Max memory in training epoch: 56.759552
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.169 (0.169)	Data 0.256 (0.256)	Loss 0.7088 (0.7088)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.124 (0.126)	Data 0.000 (0.004)	Loss 0.6039 (0.7027)	Acc@1 88.672 (85.090)	Acc@5 99.219 (99.351)
Epoch: [38][128/196]	Time 0.117 (0.125)	Data 0.000 (0.002)	Loss 0.7794 (0.6991)	Acc@1 80.078 (85.102)	Acc@5 99.609 (99.391)
Epoch: [38][192/196]	Time 0.120 (0.124)	Data 0.000 (0.001)	Loss 0.6526 (0.6994)	Acc@1 87.891 (84.923)	Acc@5 99.609 (99.401)
Max memory in training epoch: 56.759552
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.149 (0.149)	Data 0.289 (0.289)	Loss 0.5981 (0.5981)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [39][64/196]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.6849 (0.6897)	Acc@1 84.766 (85.499)	Acc@5 99.609 (99.435)
Epoch: [39][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.7420 (0.7004)	Acc@1 83.203 (85.002)	Acc@5 98.828 (99.364)
Epoch: [39][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.7726 (0.7042)	Acc@1 84.766 (84.915)	Acc@5 99.609 (99.352)
Max memory in training epoch: 56.759552
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.151 (0.151)	Data 0.283 (0.283)	Loss 0.7036 (0.7036)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.7008 (0.6943)	Acc@1 83.984 (85.180)	Acc@5 98.828 (99.447)
Epoch: [40][128/196]	Time 0.134 (0.127)	Data 0.000 (0.002)	Loss 0.7158 (0.7019)	Acc@1 84.375 (85.035)	Acc@5 99.219 (99.346)
Epoch: [40][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.7269 (0.7021)	Acc@1 85.156 (85.013)	Acc@5 98.828 (99.330)
Max memory in training epoch: 56.759552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 214214 ; 216238 ; 0.9906399430257402
[INFO] Storing checkpoint...
  80.25
Max memory: 88.47616
 25.216s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5116
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.094208
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.201 (0.201)	Data 0.253 (0.253)	Loss 0.7424 (0.7424)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [41][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.6655 (0.6751)	Acc@1 85.547 (85.769)	Acc@5 99.219 (99.411)
Epoch: [41][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6764 (0.6861)	Acc@1 84.375 (85.417)	Acc@5 99.609 (99.391)
Epoch: [41][192/196]	Time 0.123 (0.127)	Data 0.000 (0.001)	Loss 0.5810 (0.6908)	Acc@1 89.062 (85.347)	Acc@5 100.000 (99.342)
Max memory in training epoch: 56.3044864
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.162 (0.162)	Data 0.289 (0.289)	Loss 0.6327 (0.6327)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [42][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.7457 (0.6740)	Acc@1 86.719 (86.298)	Acc@5 98.438 (99.393)
Epoch: [42][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7247 (0.6912)	Acc@1 83.984 (85.392)	Acc@5 99.219 (99.358)
Epoch: [42][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6072 (0.6921)	Acc@1 88.672 (85.340)	Acc@5 99.219 (99.383)
Max memory in training epoch: 56.2061824
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.174 (0.174)	Data 0.277 (0.277)	Loss 0.6451 (0.6451)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.5925 (0.6958)	Acc@1 88.281 (85.228)	Acc@5 100.000 (99.321)
Epoch: [43][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7503 (0.7004)	Acc@1 78.516 (84.996)	Acc@5 100.000 (99.322)
Epoch: [43][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7388 (0.7009)	Acc@1 85.547 (85.002)	Acc@5 98.047 (99.326)
Max memory in training epoch: 56.1603072
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.203 (0.203)	Data 0.336 (0.336)	Loss 0.6716 (0.6716)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.6564 (0.7056)	Acc@1 85.938 (84.700)	Acc@5 99.219 (99.381)
Epoch: [44][128/196]	Time 0.131 (0.126)	Data 0.000 (0.003)	Loss 0.8555 (0.6962)	Acc@1 79.688 (85.087)	Acc@5 96.875 (99.382)
Epoch: [44][192/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6655 (0.6953)	Acc@1 85.547 (85.118)	Acc@5 99.219 (99.381)
Max memory in training epoch: 56.1603072
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.171 (0.171)	Data 0.304 (0.304)	Loss 0.6808 (0.6808)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 0.6182 (0.6979)	Acc@1 87.500 (85.042)	Acc@5 100.000 (99.363)
Epoch: [45][128/196]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.7932 (0.6937)	Acc@1 82.422 (85.241)	Acc@5 99.219 (99.382)
Epoch: [45][192/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.6350 (0.6949)	Acc@1 87.109 (85.209)	Acc@5 99.609 (99.387)
Max memory in training epoch: 56.1603072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 212768 ; 214214 ; 0.9932497409132923
[INFO] Storing checkpoint...
  80.07
Max memory: 87.4416128
 25.776s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2391
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.0934912
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.198 (0.198)	Data 0.278 (0.278)	Loss 0.6154 (0.6154)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.135 (0.125)	Data 0.000 (0.004)	Loss 0.6762 (0.6614)	Acc@1 84.766 (86.376)	Acc@5 100.000 (99.531)
Epoch: [46][128/196]	Time 0.115 (0.124)	Data 0.000 (0.002)	Loss 0.7128 (0.6784)	Acc@1 82.812 (85.689)	Acc@5 100.000 (99.482)
Epoch: [46][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6620 (0.6873)	Acc@1 86.719 (85.365)	Acc@5 100.000 (99.449)
Max memory in training epoch: 55.7707776
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.180 (0.180)	Data 0.283 (0.283)	Loss 0.6112 (0.6112)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [47][64/196]	Time 0.116 (0.125)	Data 0.000 (0.005)	Loss 0.7292 (0.6915)	Acc@1 85.547 (85.144)	Acc@5 98.438 (99.309)
Epoch: [47][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6093 (0.6946)	Acc@1 87.500 (85.105)	Acc@5 99.609 (99.237)
Epoch: [47][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.7342 (0.6910)	Acc@1 83.203 (85.205)	Acc@5 98.828 (99.294)
Max memory in training epoch: 55.66592
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.162 (0.162)	Data 0.302 (0.302)	Loss 0.6397 (0.6397)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [48][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.6728 (0.6992)	Acc@1 85.938 (85.331)	Acc@5 98.828 (99.255)
Epoch: [48][128/196]	Time 0.121 (0.125)	Data 0.000 (0.003)	Loss 0.7692 (0.6918)	Acc@1 81.250 (85.508)	Acc@5 100.000 (99.367)
Epoch: [48][192/196]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 0.7073 (0.6977)	Acc@1 86.328 (85.294)	Acc@5 98.828 (99.356)
Max memory in training epoch: 55.66592
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.197 (0.197)	Data 0.258 (0.258)	Loss 0.6329 (0.6329)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.114 (0.125)	Data 0.000 (0.004)	Loss 0.6405 (0.6821)	Acc@1 87.500 (85.607)	Acc@5 99.219 (99.471)
Epoch: [49][128/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.5504 (0.6855)	Acc@1 89.844 (85.411)	Acc@5 100.000 (99.419)
Epoch: [49][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.6537 (0.6873)	Acc@1 87.109 (85.332)	Acc@5 99.219 (99.427)
Max memory in training epoch: 55.66592
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.179 (0.179)	Data 0.287 (0.287)	Loss 0.6041 (0.6041)	Acc@1 89.844 (89.844)	Acc@5 98.828 (98.828)
Epoch: [50][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.6192 (0.6817)	Acc@1 91.016 (85.673)	Acc@5 98.828 (99.405)
Epoch: [50][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.6315 (0.6859)	Acc@1 88.672 (85.589)	Acc@5 98.438 (99.425)
Epoch: [50][192/196]	Time 0.115 (0.127)	Data 0.000 (0.002)	Loss 0.5753 (0.6855)	Acc@1 88.281 (85.664)	Acc@5 99.609 (99.375)
Max memory in training epoch: 55.66592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv28.weight

 RM:  module.conv29.weight
numoFStages: 3
Count: 210928 ; 212768 ; 0.991352083020003
[INFO] Storing checkpoint...
  77.72
Max memory: 86.7212288
 25.147s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7759
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.0922624
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.165 (0.165)	Data 0.286 (0.286)	Loss 0.6186 (0.6186)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6197 (0.6508)	Acc@1 85.156 (86.659)	Acc@5 100.000 (99.573)
Epoch: [51][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7322 (0.6680)	Acc@1 83.984 (86.047)	Acc@5 99.219 (99.503)
Epoch: [51][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.7442 (0.6769)	Acc@1 83.203 (85.780)	Acc@5 98.438 (99.447)
Max memory in training epoch: 54.9279232
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.162 (0.162)	Data 0.276 (0.276)	Loss 0.6862 (0.6862)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.7123 (0.6832)	Acc@1 83.594 (85.252)	Acc@5 99.609 (99.477)
Epoch: [52][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.6818 (0.6871)	Acc@1 84.766 (85.293)	Acc@5 99.609 (99.473)
Epoch: [52][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.7449 (0.6845)	Acc@1 82.031 (85.456)	Acc@5 99.609 (99.429)
Max memory in training epoch: 54.816512
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.155 (0.155)	Data 0.292 (0.292)	Loss 0.6596 (0.6596)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [53][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.6381 (0.6832)	Acc@1 87.500 (85.433)	Acc@5 100.000 (99.447)
Epoch: [53][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.5772 (0.6872)	Acc@1 90.234 (85.293)	Acc@5 100.000 (99.443)
Epoch: [53][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7010 (0.6876)	Acc@1 84.766 (85.241)	Acc@5 98.828 (99.407)
Max memory in training epoch: 54.816512
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.170 (0.170)	Data 0.288 (0.288)	Loss 0.6951 (0.6951)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.6749 (0.6680)	Acc@1 85.938 (86.112)	Acc@5 99.609 (99.417)
Epoch: [54][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6497 (0.6803)	Acc@1 85.938 (85.589)	Acc@5 99.219 (99.413)
Epoch: [54][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.7262 (0.6785)	Acc@1 85.938 (85.634)	Acc@5 99.219 (99.407)
Max memory in training epoch: 54.816512
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.163 (0.163)	Data 0.256 (0.256)	Loss 0.6347 (0.6347)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.121 (0.124)	Data 0.000 (0.004)	Loss 0.6883 (0.6943)	Acc@1 85.547 (85.246)	Acc@5 99.219 (99.369)
Epoch: [55][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.6219 (0.6838)	Acc@1 90.234 (85.629)	Acc@5 99.609 (99.422)
Epoch: [55][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.7518 (0.6843)	Acc@1 83.594 (85.482)	Acc@5 98.828 (99.421)
Max memory in training epoch: 54.816512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 207602 ; 210928 ; 0.984231586133657
[INFO] Storing checkpoint...
  62.92
Max memory: 85.4742016
 24.668s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2476
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.0910336
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.195 (0.195)	Data 0.261 (0.261)	Loss 0.6667 (0.6667)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [56][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.7461 (0.6622)	Acc@1 83.984 (86.046)	Acc@5 99.219 (99.351)
Epoch: [56][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6517 (0.6679)	Acc@1 87.109 (85.983)	Acc@5 100.000 (99.391)
Epoch: [56][192/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.6473 (0.6695)	Acc@1 87.109 (85.889)	Acc@5 99.609 (99.409)
Max memory in training epoch: 54.2152192
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.141 (0.141)	Data 0.288 (0.288)	Loss 0.6458 (0.6458)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.7301 (0.6841)	Acc@1 83.984 (85.204)	Acc@5 99.609 (99.411)
Epoch: [57][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6410 (0.6756)	Acc@1 86.328 (85.719)	Acc@5 100.000 (99.416)
Epoch: [57][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6627 (0.6788)	Acc@1 87.500 (85.468)	Acc@5 98.438 (99.425)
Max memory in training epoch: 54.0644864
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.169 (0.169)	Data 0.287 (0.287)	Loss 0.6207 (0.6207)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [58][64/196]	Time 0.118 (0.124)	Data 0.000 (0.005)	Loss 0.6679 (0.6798)	Acc@1 85.938 (85.294)	Acc@5 100.000 (99.459)
Epoch: [58][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.6112 (0.6815)	Acc@1 87.500 (85.465)	Acc@5 99.219 (99.364)
Epoch: [58][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6840 (0.6813)	Acc@1 83.203 (85.480)	Acc@5 99.609 (99.403)
Max memory in training epoch: 54.0644864
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.157 (0.157)	Data 0.362 (0.362)	Loss 0.7106 (0.7106)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.116 (0.124)	Data 0.000 (0.006)	Loss 0.6958 (0.6743)	Acc@1 84.766 (85.811)	Acc@5 99.609 (99.507)
Epoch: [59][128/196]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.6880 (0.6741)	Acc@1 85.938 (85.798)	Acc@5 99.609 (99.452)
Epoch: [59][192/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.7038 (0.6756)	Acc@1 85.156 (85.778)	Acc@5 100.000 (99.447)
Max memory in training epoch: 54.0644864
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.173 (0.173)	Data 0.284 (0.284)	Loss 0.6689 (0.6689)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.6710 (0.6878)	Acc@1 85.156 (85.805)	Acc@5 98.828 (99.273)
Epoch: [60][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6833 (0.6748)	Acc@1 85.547 (86.050)	Acc@5 99.609 (99.410)
Epoch: [60][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6176 (0.6730)	Acc@1 88.672 (85.950)	Acc@5 98.828 (99.407)
Max memory in training epoch: 54.0644864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 204876 ; 207602 ; 0.9868691053072707
[INFO] Storing checkpoint...
  76.51
Max memory: 84.504064
 25.153s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 52
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.089856
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.163 (0.163)	Data 0.272 (0.272)	Loss 0.6320 (0.6320)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.117 (0.118)	Data 0.000 (0.004)	Loss 0.6843 (0.6634)	Acc@1 85.547 (85.781)	Acc@5 99.219 (99.489)
Epoch: [61][128/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.7129 (0.6690)	Acc@1 84.375 (85.626)	Acc@5 99.609 (99.449)
Epoch: [61][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.7320 (0.6745)	Acc@1 83.594 (85.523)	Acc@5 100.000 (99.447)
Max memory in training epoch: 54.0139008
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.183 (0.183)	Data 0.274 (0.274)	Loss 0.6507 (0.6507)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [62][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.6204 (0.6751)	Acc@1 89.062 (85.811)	Acc@5 100.000 (99.459)
Epoch: [62][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.5854 (0.6720)	Acc@1 89.453 (85.868)	Acc@5 99.219 (99.410)
Epoch: [62][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6676 (0.6754)	Acc@1 86.328 (85.707)	Acc@5 100.000 (99.409)
Max memory in training epoch: 53.9876864
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.145 (0.145)	Data 0.282 (0.282)	Loss 0.6299 (0.6299)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [63][64/196]	Time 0.135 (0.121)	Data 0.000 (0.005)	Loss 0.5962 (0.6754)	Acc@1 88.672 (85.751)	Acc@5 100.000 (99.459)
Epoch: [63][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.6314 (0.6768)	Acc@1 87.500 (85.671)	Acc@5 99.609 (99.473)
Epoch: [63][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.7510 (0.6757)	Acc@1 82.422 (85.709)	Acc@5 99.219 (99.429)
Max memory in training epoch: 53.9876864
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.182 (0.182)	Data 0.258 (0.258)	Loss 0.6159 (0.6159)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [64][64/196]	Time 0.130 (0.123)	Data 0.000 (0.004)	Loss 0.5491 (0.6689)	Acc@1 90.625 (85.799)	Acc@5 100.000 (99.441)
Epoch: [64][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6023 (0.6677)	Acc@1 88.281 (85.771)	Acc@5 100.000 (99.470)
Epoch: [64][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6791 (0.6775)	Acc@1 84.766 (85.423)	Acc@5 99.609 (99.454)
Max memory in training epoch: 53.9876864
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.174 (0.174)	Data 0.289 (0.289)	Loss 0.6816 (0.6816)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6904 (0.6715)	Acc@1 85.547 (86.028)	Acc@5 100.000 (99.387)
Epoch: [65][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.7017 (0.6708)	Acc@1 83.984 (85.950)	Acc@5 99.609 (99.410)
Epoch: [65][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6608 (0.6710)	Acc@1 85.547 (85.844)	Acc@5 100.000 (99.407)
Max memory in training epoch: 53.9876864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 204008 ; 204876 ; 0.9957632909662429
[INFO] Storing checkpoint...
  77.59
Max memory: 84.3168256
 24.261s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6456
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.0895488
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.165 (0.165)	Data 0.295 (0.295)	Loss 0.6200 (0.6200)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [66][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.7132 (0.6487)	Acc@1 82.812 (86.454)	Acc@5 99.219 (99.411)
Epoch: [66][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6280 (0.6585)	Acc@1 86.719 (86.234)	Acc@5 100.000 (99.437)
Epoch: [66][192/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.7145 (0.6664)	Acc@1 85.547 (85.946)	Acc@5 98.438 (99.413)
Max memory in training epoch: 53.5408128
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.140 (0.140)	Data 0.283 (0.283)	Loss 0.7156 (0.7156)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.6631 (0.6677)	Acc@1 85.547 (85.637)	Acc@5 98.047 (99.459)
Epoch: [67][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.5222 (0.6628)	Acc@1 91.797 (85.883)	Acc@5 99.609 (99.479)
Epoch: [67][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6282 (0.6669)	Acc@1 88.672 (85.786)	Acc@5 99.609 (99.468)
Max memory in training epoch: 53.5145984
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.187 (0.187)	Data 0.260 (0.260)	Loss 0.6023 (0.6023)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.136 (0.124)	Data 0.000 (0.004)	Loss 0.6762 (0.6747)	Acc@1 85.547 (85.727)	Acc@5 98.828 (99.327)
Epoch: [68][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.5983 (0.6774)	Acc@1 88.672 (85.517)	Acc@5 100.000 (99.376)
Epoch: [68][192/196]	Time 0.136 (0.123)	Data 0.000 (0.002)	Loss 0.6284 (0.6757)	Acc@1 85.938 (85.636)	Acc@5 99.609 (99.354)
Max memory in training epoch: 53.5145984
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.180 (0.180)	Data 0.275 (0.275)	Loss 0.6187 (0.6187)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.6751 (0.6676)	Acc@1 86.719 (86.286)	Acc@5 99.219 (99.429)
Epoch: [69][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.6495 (0.6697)	Acc@1 86.719 (85.889)	Acc@5 99.609 (99.452)
Epoch: [69][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7473 (0.6724)	Acc@1 81.641 (85.701)	Acc@5 99.609 (99.423)
Max memory in training epoch: 53.5145984
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.165 (0.165)	Data 0.277 (0.277)	Loss 0.6654 (0.6654)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [70][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.5731 (0.6756)	Acc@1 88.281 (85.775)	Acc@5 100.000 (99.429)
Epoch: [70][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.7052 (0.6681)	Acc@1 83.984 (85.989)	Acc@5 100.000 (99.500)
Epoch: [70][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.6609 (0.6696)	Acc@1 87.109 (85.954)	Acc@5 99.609 (99.466)
Max memory in training epoch: 53.5145984
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 203430 ; 204008 ; 0.9971667777734207
[INFO] Storing checkpoint...
  65.49
Max memory: 83.6091392
 24.630s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 900
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.089344
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.164 (0.164)	Data 0.272 (0.272)	Loss 0.5468 (0.5468)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [71][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.7437 (0.6369)	Acc@1 83.594 (87.037)	Acc@5 99.219 (99.627)
Epoch: [71][128/196]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.6622 (0.6613)	Acc@1 85.547 (86.040)	Acc@5 99.219 (99.494)
Epoch: [71][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.6448 (0.6680)	Acc@1 87.109 (85.883)	Acc@5 98.828 (99.470)
Max memory in training epoch: 53.5399936
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.179 (0.179)	Data 0.285 (0.285)	Loss 0.7828 (0.7828)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.7460 (0.6615)	Acc@1 83.594 (85.709)	Acc@5 98.438 (99.423)
Epoch: [72][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.6710 (0.6645)	Acc@1 85.156 (85.780)	Acc@5 99.609 (99.467)
Epoch: [72][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.5798 (0.6712)	Acc@1 90.625 (85.610)	Acc@5 99.609 (99.445)
Max memory in training epoch: 53.3564928
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.155 (0.155)	Data 0.288 (0.288)	Loss 0.6641 (0.6641)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.114 (0.120)	Data 0.000 (0.005)	Loss 0.7011 (0.6547)	Acc@1 84.375 (86.472)	Acc@5 99.609 (99.495)
Epoch: [73][128/196]	Time 0.125 (0.119)	Data 0.000 (0.002)	Loss 0.7004 (0.6655)	Acc@1 85.938 (86.125)	Acc@5 99.609 (99.400)
Epoch: [73][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.6895 (0.6645)	Acc@1 82.031 (85.998)	Acc@5 99.219 (99.447)
Max memory in training epoch: 53.3564928
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.152 (0.152)	Data 0.271 (0.271)	Loss 0.6314 (0.6314)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.116 (0.120)	Data 0.000 (0.004)	Loss 0.6622 (0.6625)	Acc@1 84.766 (86.058)	Acc@5 100.000 (99.411)
Epoch: [74][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6893 (0.6721)	Acc@1 86.328 (85.659)	Acc@5 98.828 (99.455)
Epoch: [74][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.7750 (0.6756)	Acc@1 83.594 (85.642)	Acc@5 98.047 (99.409)
Max memory in training epoch: 53.3564928
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.161 (0.161)	Data 0.265 (0.265)	Loss 0.6989 (0.6989)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [75][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.6637 (0.6672)	Acc@1 86.719 (86.064)	Acc@5 98.828 (99.435)
Epoch: [75][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6618 (0.6640)	Acc@1 86.328 (86.092)	Acc@5 99.219 (99.485)
Epoch: [75][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.7279 (0.6665)	Acc@1 82.812 (86.020)	Acc@5 99.219 (99.449)
Max memory in training epoch: 53.3564928
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 202274 ; 203430 ; 0.9943174556358453
[INFO] Storing checkpoint...
  82.82
Max memory: 83.3275392
 23.913s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 358
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.088832
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.170 (0.170)	Data 0.270 (0.270)	Loss 0.7384 (0.7384)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [76][64/196]	Time 0.115 (0.119)	Data 0.000 (0.004)	Loss 0.6583 (0.6371)	Acc@1 85.156 (86.731)	Acc@5 100.000 (99.519)
Epoch: [76][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.5940 (0.6559)	Acc@1 89.453 (86.071)	Acc@5 100.000 (99.482)
Epoch: [76][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6444 (0.6571)	Acc@1 87.500 (86.069)	Acc@5 99.219 (99.468)
Max memory in training epoch: 53.2758016
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.162 (0.162)	Data 0.278 (0.278)	Loss 0.5996 (0.5996)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.6346 (0.6741)	Acc@1 87.109 (85.895)	Acc@5 98.828 (99.417)
Epoch: [77][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.6547 (0.6729)	Acc@1 85.547 (85.750)	Acc@5 99.219 (99.385)
Epoch: [77][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6702 (0.6717)	Acc@1 85.547 (85.808)	Acc@5 99.219 (99.379)
Max memory in training epoch: 53.269248
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.159 (0.159)	Data 0.280 (0.280)	Loss 0.5605 (0.5605)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.117 (0.118)	Data 0.000 (0.004)	Loss 0.6865 (0.6546)	Acc@1 85.547 (86.130)	Acc@5 99.219 (99.513)
Epoch: [78][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6888 (0.6667)	Acc@1 83.984 (85.832)	Acc@5 98.828 (99.476)
Epoch: [78][192/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.7423 (0.6649)	Acc@1 81.641 (85.846)	Acc@5 99.609 (99.454)
Max memory in training epoch: 53.269248
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.170 (0.170)	Data 0.280 (0.280)	Loss 0.6647 (0.6647)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.6419 (0.6761)	Acc@1 89.844 (85.517)	Acc@5 98.828 (99.405)
Epoch: [79][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.6943 (0.6717)	Acc@1 85.156 (85.792)	Acc@5 98.828 (99.413)
Epoch: [79][192/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.5944 (0.6723)	Acc@1 89.844 (85.727)	Acc@5 100.000 (99.443)
Max memory in training epoch: 53.269248
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.159 (0.159)	Data 0.257 (0.257)	Loss 0.6353 (0.6353)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.5915 (0.6736)	Acc@1 88.281 (85.763)	Acc@5 99.609 (99.471)
Epoch: [80][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.7186 (0.6720)	Acc@1 84.375 (85.819)	Acc@5 99.219 (99.482)
Epoch: [80][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6450 (0.6708)	Acc@1 85.547 (85.842)	Acc@5 100.000 (99.456)
Max memory in training epoch: 53.269248
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 201118 ; 202274 ; 0.9942849797799025
[INFO] Storing checkpoint...
  78.98
Max memory: 83.1678976
 23.872s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6022
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.0884224
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.186 (0.186)	Data 0.281 (0.281)	Loss 0.7007 (0.7007)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.7306 (0.6439)	Acc@1 84.766 (86.659)	Acc@5 99.219 (99.489)
Epoch: [81][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6232 (0.6480)	Acc@1 86.328 (86.461)	Acc@5 100.000 (99.491)
Epoch: [81][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.7248 (0.6535)	Acc@1 83.984 (86.257)	Acc@5 98.438 (99.476)
Max memory in training epoch: 53.1693056
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.176 (0.176)	Data 0.286 (0.286)	Loss 0.7848 (0.7848)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [82][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.5751 (0.6614)	Acc@1 91.406 (86.100)	Acc@5 99.219 (99.453)
Epoch: [82][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6574 (0.6577)	Acc@1 85.547 (86.201)	Acc@5 99.609 (99.497)
Epoch: [82][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6515 (0.6640)	Acc@1 86.719 (85.909)	Acc@5 99.219 (99.466)
Max memory in training epoch: 53.162752
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.148 (0.148)	Data 0.285 (0.285)	Loss 0.7050 (0.7050)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.142 (0.121)	Data 0.000 (0.005)	Loss 0.5858 (0.6724)	Acc@1 89.062 (85.631)	Acc@5 100.000 (99.483)
Epoch: [83][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.7215 (0.6717)	Acc@1 84.766 (85.777)	Acc@5 98.828 (99.416)
Epoch: [83][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6905 (0.6689)	Acc@1 85.156 (85.873)	Acc@5 98.828 (99.439)
Max memory in training epoch: 53.162752
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.149 (0.149)	Data 0.305 (0.305)	Loss 0.7028 (0.7028)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.6388 (0.6696)	Acc@1 87.500 (85.769)	Acc@5 100.000 (99.435)
Epoch: [84][128/196]	Time 0.125 (0.121)	Data 0.000 (0.003)	Loss 0.6391 (0.6670)	Acc@1 87.109 (85.992)	Acc@5 99.609 (99.431)
Epoch: [84][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6445 (0.6670)	Acc@1 87.500 (85.881)	Acc@5 100.000 (99.452)
Max memory in training epoch: 53.162752
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.158 (0.158)	Data 0.261 (0.261)	Loss 0.5626 (0.5626)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.5939 (0.6621)	Acc@1 89.062 (86.052)	Acc@5 99.609 (99.495)
Epoch: [85][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.5924 (0.6623)	Acc@1 88.281 (85.965)	Acc@5 100.000 (99.467)
Epoch: [85][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6538 (0.6578)	Acc@1 86.328 (86.128)	Acc@5 99.219 (99.488)
Max memory in training epoch: 53.162752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 199962 ; 201118 ; 0.9942521305900018
[INFO] Storing checkpoint...
  70.56
Max memory: 83.0028288
 24.012s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5792
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.0880128
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.203 (0.203)	Data 0.281 (0.281)	Loss 0.6529 (0.6529)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [86][64/196]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.6977 (0.6353)	Acc@1 83.984 (87.067)	Acc@5 99.219 (99.585)
Epoch: [86][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6352 (0.6471)	Acc@1 85.156 (86.595)	Acc@5 99.609 (99.449)
Epoch: [86][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6827 (0.6525)	Acc@1 84.375 (86.318)	Acc@5 100.000 (99.466)
Max memory in training epoch: 53.0628096
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.167 (0.167)	Data 0.314 (0.314)	Loss 0.6011 (0.6011)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.6649 (0.6571)	Acc@1 86.328 (86.268)	Acc@5 99.219 (99.447)
Epoch: [87][128/196]	Time 0.124 (0.120)	Data 0.000 (0.003)	Loss 0.6657 (0.6617)	Acc@1 86.719 (86.022)	Acc@5 100.000 (99.497)
Epoch: [87][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6813 (0.6620)	Acc@1 84.375 (85.998)	Acc@5 99.219 (99.490)
Max memory in training epoch: 53.056256
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.144 (0.144)	Data 0.289 (0.289)	Loss 0.6786 (0.6786)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [88][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.6936 (0.6534)	Acc@1 85.547 (86.562)	Acc@5 99.609 (99.471)
Epoch: [88][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.7935 (0.6678)	Acc@1 83.984 (86.016)	Acc@5 98.438 (99.440)
Epoch: [88][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7168 (0.6642)	Acc@1 83.594 (86.075)	Acc@5 99.219 (99.462)
Max memory in training epoch: 53.056256
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.173 (0.173)	Data 0.269 (0.269)	Loss 0.7017 (0.7017)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [89][64/196]	Time 0.122 (0.120)	Data 0.000 (0.004)	Loss 0.6586 (0.6628)	Acc@1 87.109 (85.793)	Acc@5 100.000 (99.399)
Epoch: [89][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6689 (0.6618)	Acc@1 87.109 (85.874)	Acc@5 99.609 (99.419)
Epoch: [89][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.7398 (0.6623)	Acc@1 83.203 (86.039)	Acc@5 98.047 (99.423)
Max memory in training epoch: 53.056256
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.168 (0.168)	Data 0.293 (0.293)	Loss 0.5776 (0.5776)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.5760 (0.6461)	Acc@1 89.062 (86.641)	Acc@5 99.609 (99.465)
Epoch: [90][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6693 (0.6511)	Acc@1 86.719 (86.407)	Acc@5 100.000 (99.440)
Epoch: [90][192/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.6718 (0.6555)	Acc@1 85.547 (86.176)	Acc@5 98.828 (99.417)
Max memory in training epoch: 53.056256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  82.17
Max memory: 82.8320256
 23.756s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9914
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.0880128
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.177 (0.177)	Data 0.273 (0.273)	Loss 0.6718 (0.6718)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [91][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.6300 (0.6350)	Acc@1 87.500 (86.851)	Acc@5 99.219 (99.549)
Epoch: [91][128/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.6194 (0.6498)	Acc@1 89.844 (86.413)	Acc@5 99.219 (99.506)
Epoch: [91][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.7058 (0.6550)	Acc@1 85.156 (86.227)	Acc@5 100.000 (99.494)
Max memory in training epoch: 53.0628096
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.143 (0.143)	Data 0.292 (0.292)	Loss 0.6905 (0.6905)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.116 (0.119)	Data 0.000 (0.005)	Loss 0.6441 (0.6607)	Acc@1 84.375 (85.919)	Acc@5 99.609 (99.441)
Epoch: [92][128/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.7171 (0.6625)	Acc@1 83.203 (85.841)	Acc@5 99.609 (99.458)
Epoch: [92][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.5831 (0.6625)	Acc@1 88.672 (85.931)	Acc@5 100.000 (99.462)
Max memory in training epoch: 53.056256
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.147 (0.147)	Data 0.279 (0.279)	Loss 0.6652 (0.6652)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.117 (0.119)	Data 0.000 (0.004)	Loss 0.5202 (0.5672)	Acc@1 91.016 (89.291)	Acc@5 100.000 (99.760)
Epoch: [93][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.4567 (0.5390)	Acc@1 92.578 (90.210)	Acc@5 100.000 (99.791)
Epoch: [93][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.5112 (0.5262)	Acc@1 92.188 (90.597)	Acc@5 99.609 (99.783)
Max memory in training epoch: 53.056256
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.144 (0.144)	Data 0.294 (0.294)	Loss 0.4565 (0.4565)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [94][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.4854 (0.4796)	Acc@1 93.359 (92.326)	Acc@5 100.000 (99.784)
Epoch: [94][128/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.4763 (0.4802)	Acc@1 93.359 (92.169)	Acc@5 100.000 (99.776)
Epoch: [94][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.4912 (0.4753)	Acc@1 92.188 (92.254)	Acc@5 99.609 (99.794)
Max memory in training epoch: 53.056256
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.153 (0.153)	Data 0.268 (0.268)	Loss 0.4219 (0.4219)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.4671 (0.4552)	Acc@1 93.750 (92.897)	Acc@5 99.609 (99.874)
Epoch: [95][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.4323 (0.4556)	Acc@1 92.578 (92.842)	Acc@5 99.609 (99.855)
Epoch: [95][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.4173 (0.4568)	Acc@1 94.531 (92.752)	Acc@5 100.000 (99.854)
Max memory in training epoch: 53.056256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 199238 ; 199962 ; 0.9963793120692932
[INFO] Storing checkpoint...
  90.45
Max memory: 82.8320256
 23.634s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9889
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.0877568
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.170 (0.170)	Data 0.269 (0.269)	Loss 0.4061 (0.4061)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.117 (0.118)	Data 0.000 (0.004)	Loss 0.4737 (0.4413)	Acc@1 91.797 (93.179)	Acc@5 99.609 (99.826)
Epoch: [96][128/196]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.4298 (0.4413)	Acc@1 94.531 (93.120)	Acc@5 100.000 (99.824)
Epoch: [96][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.4432 (0.4383)	Acc@1 91.797 (93.157)	Acc@5 99.219 (99.828)
Max memory in training epoch: 53.0617856
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.167 (0.167)	Data 0.311 (0.311)	Loss 0.4262 (0.4262)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.124 (0.121)	Data 0.000 (0.005)	Loss 0.4047 (0.4226)	Acc@1 95.703 (93.726)	Acc@5 100.000 (99.856)
Epoch: [97][128/196]	Time 0.119 (0.120)	Data 0.000 (0.003)	Loss 0.4172 (0.4230)	Acc@1 93.359 (93.653)	Acc@5 100.000 (99.840)
Epoch: [97][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.4016 (0.4233)	Acc@1 93.750 (93.548)	Acc@5 100.000 (99.860)
Max memory in training epoch: 52.7144448
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.137 (0.137)	Data 0.296 (0.296)	Loss 0.3835 (0.3835)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.4598 (0.4156)	Acc@1 92.188 (93.744)	Acc@5 100.000 (99.844)
Epoch: [98][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3907 (0.4141)	Acc@1 92.969 (93.738)	Acc@5 100.000 (99.840)
Epoch: [98][192/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.3667 (0.4134)	Acc@1 93.359 (93.720)	Acc@5 100.000 (99.858)
Max memory in training epoch: 52.7144448
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.161 (0.161)	Data 0.296 (0.296)	Loss 0.4258 (0.4258)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [99][64/196]	Time 0.125 (0.121)	Data 0.000 (0.005)	Loss 0.4889 (0.4063)	Acc@1 90.234 (93.618)	Acc@5 100.000 (99.868)
Epoch: [99][128/196]	Time 0.128 (0.119)	Data 0.000 (0.002)	Loss 0.3275 (0.4045)	Acc@1 96.094 (93.747)	Acc@5 100.000 (99.873)
Epoch: [99][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3457 (0.4037)	Acc@1 95.312 (93.807)	Acc@5 100.000 (99.877)
Max memory in training epoch: 52.7144448
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.171 (0.171)	Data 0.291 (0.291)	Loss 0.4383 (0.4383)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [100][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.4704 (0.3926)	Acc@1 92.188 (94.285)	Acc@5 100.000 (99.874)
Epoch: [100][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3764 (0.3894)	Acc@1 94.141 (94.253)	Acc@5 100.000 (99.879)
Epoch: [100][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.3676 (0.3942)	Acc@1 94.531 (94.104)	Acc@5 100.000 (99.868)
Max memory in training epoch: 52.7144448
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 198102 ; 199238 ; 0.9942982764332106
[INFO] Storing checkpoint...
  90.72
Max memory: 82.4669184
 23.847s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2340
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.0872448
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.197 (0.197)	Data 0.260 (0.260)	Loss 0.4096 (0.4096)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.119 (0.124)	Data 0.000 (0.004)	Loss 0.3904 (0.3792)	Acc@1 94.141 (94.621)	Acc@5 99.609 (99.856)
Epoch: [101][128/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.4211 (0.3838)	Acc@1 92.578 (94.453)	Acc@5 100.000 (99.873)
Epoch: [101][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3801 (0.3861)	Acc@1 94.531 (94.349)	Acc@5 100.000 (99.879)
Max memory in training epoch: 53.0466304
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.156 (0.156)	Data 0.305 (0.305)	Loss 0.3435 (0.3435)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.4095 (0.3771)	Acc@1 92.969 (94.441)	Acc@5 100.000 (99.910)
Epoch: [102][128/196]	Time 0.116 (0.120)	Data 0.000 (0.003)	Loss 0.3452 (0.3773)	Acc@1 95.312 (94.428)	Acc@5 100.000 (99.915)
Epoch: [102][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3523 (0.3787)	Acc@1 96.484 (94.298)	Acc@5 99.609 (99.917)
Max memory in training epoch: 52.6992896
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.178 (0.178)	Data 0.278 (0.278)	Loss 0.4089 (0.4089)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.3536 (0.3740)	Acc@1 94.531 (94.531)	Acc@5 100.000 (99.922)
Epoch: [103][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3329 (0.3712)	Acc@1 95.703 (94.619)	Acc@5 100.000 (99.921)
Epoch: [103][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.3703 (0.3745)	Acc@1 95.703 (94.456)	Acc@5 99.609 (99.903)
Max memory in training epoch: 52.7123968
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.170 (0.170)	Data 0.278 (0.278)	Loss 0.3534 (0.3534)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.114 (0.120)	Data 0.000 (0.004)	Loss 0.3134 (0.3620)	Acc@1 97.266 (94.657)	Acc@5 100.000 (99.910)
Epoch: [104][128/196]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.3513 (0.3606)	Acc@1 96.094 (94.695)	Acc@5 100.000 (99.912)
Epoch: [104][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.4040 (0.3627)	Acc@1 92.188 (94.624)	Acc@5 100.000 (99.901)
Max memory in training epoch: 52.7123968
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.140 (0.140)	Data 0.298 (0.298)	Loss 0.3422 (0.3422)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.4275 (0.3563)	Acc@1 90.625 (94.826)	Acc@5 100.000 (99.928)
Epoch: [105][128/196]	Time 0.111 (0.120)	Data 0.000 (0.003)	Loss 0.3760 (0.3542)	Acc@1 93.750 (94.898)	Acc@5 100.000 (99.906)
Epoch: [105][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3131 (0.3564)	Acc@1 96.094 (94.790)	Acc@5 100.000 (99.901)
Max memory in training epoch: 52.7123968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 194019 ; 198102 ; 0.9793894054577945
[INFO] Storing checkpoint...
  90.85
Max memory: 82.4782848
 23.792s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3890
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.0850432
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.168 (0.168)	Data 0.252 (0.252)	Loss 0.3253 (0.3253)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.116 (0.114)	Data 0.000 (0.004)	Loss 0.3195 (0.3387)	Acc@1 96.484 (95.373)	Acc@5 99.609 (99.898)
Epoch: [106][128/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.3831 (0.3487)	Acc@1 93.359 (94.767)	Acc@5 100.000 (99.918)
Epoch: [106][192/196]	Time 0.111 (0.113)	Data 0.000 (0.001)	Loss 0.4108 (0.3529)	Acc@1 93.359 (94.634)	Acc@5 100.000 (99.921)
Max memory in training epoch: 50.3583232
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.152 (0.152)	Data 0.268 (0.268)	Loss 0.3764 (0.3764)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.113 (0.115)	Data 0.000 (0.004)	Loss 0.3765 (0.3459)	Acc@1 93.359 (94.778)	Acc@5 99.219 (99.922)
Epoch: [107][128/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.3298 (0.3469)	Acc@1 94.141 (94.801)	Acc@5 100.000 (99.912)
Epoch: [107][192/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.3685 (0.3496)	Acc@1 94.531 (94.717)	Acc@5 100.000 (99.915)
Max memory in training epoch: 50.3321088
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.159 (0.159)	Data 0.261 (0.261)	Loss 0.3539 (0.3539)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.130 (0.115)	Data 0.000 (0.004)	Loss 0.3657 (0.3458)	Acc@1 94.922 (94.808)	Acc@5 99.609 (99.916)
Epoch: [108][128/196]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.3934 (0.3452)	Acc@1 92.969 (94.798)	Acc@5 100.000 (99.903)
Epoch: [108][192/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.3654 (0.3445)	Acc@1 94.141 (94.738)	Acc@5 99.609 (99.909)
Max memory in training epoch: 50.3321088
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.178 (0.178)	Data 0.290 (0.290)	Loss 0.3582 (0.3582)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [109][64/196]	Time 0.112 (0.114)	Data 0.000 (0.005)	Loss 0.4228 (0.3351)	Acc@1 91.016 (95.048)	Acc@5 100.000 (99.898)
Epoch: [109][128/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.3203 (0.3379)	Acc@1 94.922 (94.955)	Acc@5 100.000 (99.918)
Epoch: [109][192/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.3602 (0.3413)	Acc@1 93.359 (94.792)	Acc@5 100.000 (99.913)
Max memory in training epoch: 50.3321088
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.157 (0.157)	Data 0.259 (0.259)	Loss 0.3313 (0.3313)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.108 (0.116)	Data 0.000 (0.004)	Loss 0.3479 (0.3370)	Acc@1 94.141 (95.006)	Acc@5 99.609 (99.946)
Epoch: [110][128/196]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.2869 (0.3361)	Acc@1 96.094 (94.970)	Acc@5 100.000 (99.900)
Epoch: [110][192/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.3725 (0.3367)	Acc@1 94.141 (94.865)	Acc@5 100.000 (99.919)
Max memory in training epoch: 50.3321088
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 189068 ; 194019 ; 0.9744818806405559
[INFO] Storing checkpoint...
  90.68
Max memory: 78.5124864
 22.678s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8860
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.0823808
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.156 (0.156)	Data 0.274 (0.274)	Loss 0.2810 (0.2810)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.112 (0.107)	Data 0.000 (0.004)	Loss 0.3212 (0.3421)	Acc@1 94.141 (94.429)	Acc@5 100.000 (99.916)
Epoch: [111][128/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.3805 (0.3402)	Acc@1 93.750 (94.504)	Acc@5 100.000 (99.900)
Epoch: [111][192/196]	Time 0.111 (0.107)	Data 0.000 (0.002)	Loss 0.3339 (0.3399)	Acc@1 94.922 (94.456)	Acc@5 99.609 (99.925)
Max memory in training epoch: 48.0297472
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.137 (0.137)	Data 0.311 (0.311)	Loss 0.3352 (0.3352)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.105 (0.108)	Data 0.000 (0.005)	Loss 0.3721 (0.3273)	Acc@1 94.141 (94.994)	Acc@5 100.000 (99.898)
Epoch: [112][128/196]	Time 0.107 (0.107)	Data 0.000 (0.003)	Loss 0.3329 (0.3342)	Acc@1 94.531 (94.749)	Acc@5 100.000 (99.894)
Epoch: [112][192/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.3368 (0.3361)	Acc@1 94.922 (94.606)	Acc@5 99.609 (99.893)
Max memory in training epoch: 48.0613888
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.151 (0.151)	Data 0.259 (0.259)	Loss 0.2774 (0.2774)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.100 (0.105)	Data 0.000 (0.004)	Loss 0.3802 (0.3233)	Acc@1 93.359 (95.120)	Acc@5 99.609 (99.892)
Epoch: [113][128/196]	Time 0.106 (0.104)	Data 0.000 (0.002)	Loss 0.3234 (0.3279)	Acc@1 94.922 (94.907)	Acc@5 100.000 (99.909)
Epoch: [113][192/196]	Time 0.105 (0.105)	Data 0.000 (0.002)	Loss 0.3444 (0.3285)	Acc@1 94.141 (94.871)	Acc@5 100.000 (99.915)
Max memory in training epoch: 48.0613888
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.159 (0.159)	Data 0.260 (0.260)	Loss 0.2978 (0.2978)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.127 (0.107)	Data 0.000 (0.004)	Loss 0.2803 (0.3296)	Acc@1 97.656 (94.952)	Acc@5 100.000 (99.940)
Epoch: [114][128/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.3222 (0.3307)	Acc@1 94.531 (94.849)	Acc@5 100.000 (99.942)
Epoch: [114][192/196]	Time 0.105 (0.105)	Data 0.000 (0.002)	Loss 0.3634 (0.3326)	Acc@1 92.969 (94.742)	Acc@5 99.609 (99.927)
Max memory in training epoch: 48.0613888
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.139 (0.139)	Data 0.295 (0.295)	Loss 0.2738 (0.2738)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.107 (0.107)	Data 0.000 (0.005)	Loss 0.2962 (0.3167)	Acc@1 95.312 (95.078)	Acc@5 100.000 (99.916)
Epoch: [115][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.3572 (0.3243)	Acc@1 93.750 (94.843)	Acc@5 100.000 (99.891)
Epoch: [115][192/196]	Time 0.101 (0.106)	Data 0.000 (0.002)	Loss 0.3286 (0.3261)	Acc@1 94.922 (94.703)	Acc@5 99.609 (99.909)
Max memory in training epoch: 48.0613888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 183337 ; 189068 ; 0.9696881545264138
[INFO] Storing checkpoint...
  89.76
Max memory: 74.751744
 21.119s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4437
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0802304
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.160 (0.160)	Data 0.284 (0.284)	Loss 0.4021 (0.4021)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.107 (0.108)	Data 0.000 (0.005)	Loss 0.3075 (0.3276)	Acc@1 95.703 (94.477)	Acc@5 100.000 (99.916)
Epoch: [116][128/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.3259 (0.3264)	Acc@1 94.531 (94.465)	Acc@5 100.000 (99.924)
Epoch: [116][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.2866 (0.3321)	Acc@1 96.484 (94.278)	Acc@5 99.609 (99.929)
Max memory in training epoch: 47.6584448
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.127 (0.127)	Data 0.323 (0.323)	Loss 0.3129 (0.3129)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.106 (0.107)	Data 0.000 (0.005)	Loss 0.2985 (0.3227)	Acc@1 95.312 (94.928)	Acc@5 99.609 (99.886)
Epoch: [117][128/196]	Time 0.110 (0.106)	Data 0.000 (0.003)	Loss 0.3239 (0.3283)	Acc@1 95.312 (94.468)	Acc@5 99.609 (99.897)
Epoch: [117][192/196]	Time 0.104 (0.105)	Data 0.000 (0.002)	Loss 0.2991 (0.3291)	Acc@1 96.094 (94.398)	Acc@5 100.000 (99.899)
Max memory in training epoch: 47.6333568
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.146 (0.146)	Data 0.268 (0.268)	Loss 0.4047 (0.4047)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.108 (0.108)	Data 0.000 (0.004)	Loss 0.3760 (0.3274)	Acc@1 92.969 (94.567)	Acc@5 100.000 (99.892)
Epoch: [118][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.3962 (0.3278)	Acc@1 92.578 (94.549)	Acc@5 100.000 (99.909)
Epoch: [118][192/196]	Time 0.111 (0.108)	Data 0.000 (0.002)	Loss 0.3526 (0.3287)	Acc@1 93.750 (94.448)	Acc@5 100.000 (99.913)
Max memory in training epoch: 47.6333568
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.153 (0.153)	Data 0.308 (0.308)	Loss 0.3444 (0.3444)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.2698 (0.3193)	Acc@1 96.094 (94.760)	Acc@5 100.000 (99.892)
Epoch: [119][128/196]	Time 0.116 (0.109)	Data 0.000 (0.003)	Loss 0.3088 (0.3245)	Acc@1 94.922 (94.540)	Acc@5 100.000 (99.909)
Epoch: [119][192/196]	Time 0.119 (0.108)	Data 0.000 (0.002)	Loss 0.3190 (0.3243)	Acc@1 94.141 (94.479)	Acc@5 100.000 (99.917)
Max memory in training epoch: 47.6333568
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.167 (0.167)	Data 0.253 (0.253)	Loss 0.3124 (0.3124)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.104 (0.107)	Data 0.000 (0.004)	Loss 0.3178 (0.3229)	Acc@1 94.922 (94.645)	Acc@5 100.000 (99.910)
Epoch: [120][128/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.3068 (0.3230)	Acc@1 95.312 (94.622)	Acc@5 100.000 (99.903)
Epoch: [120][192/196]	Time 0.103 (0.107)	Data 0.000 (0.001)	Loss 0.3583 (0.3265)	Acc@1 94.141 (94.493)	Acc@5 99.609 (99.919)
Max memory in training epoch: 47.6333568
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 175872 ; 183337 ; 0.9592826325291676
[INFO] Storing checkpoint...
  90.15
Max memory: 74.0950528
 21.291s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3814
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0774656
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.188 (0.188)	Data 0.284 (0.284)	Loss 0.3460 (0.3460)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.105 (0.107)	Data 0.000 (0.005)	Loss 0.3012 (0.3207)	Acc@1 94.141 (94.387)	Acc@5 100.000 (99.910)
Epoch: [121][128/196]	Time 0.100 (0.107)	Data 0.000 (0.002)	Loss 0.3159 (0.3278)	Acc@1 92.969 (94.119)	Acc@5 100.000 (99.894)
Epoch: [121][192/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3770 (0.3306)	Acc@1 93.359 (94.013)	Acc@5 100.000 (99.893)
Max memory in training epoch: 46.8030976
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.158 (0.158)	Data 0.281 (0.281)	Loss 0.3404 (0.3404)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.103 (0.107)	Data 0.000 (0.005)	Loss 0.3149 (0.3223)	Acc@1 94.141 (94.195)	Acc@5 100.000 (99.922)
Epoch: [122][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3363 (0.3280)	Acc@1 93.359 (94.041)	Acc@5 100.000 (99.903)
Epoch: [122][192/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.2879 (0.3311)	Acc@1 94.922 (94.013)	Acc@5 100.000 (99.895)
Max memory in training epoch: 46.86208
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.141 (0.141)	Data 0.298 (0.298)	Loss 0.3310 (0.3310)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [123][64/196]	Time 0.103 (0.106)	Data 0.000 (0.005)	Loss 0.2955 (0.3214)	Acc@1 95.312 (94.183)	Acc@5 100.000 (99.904)
Epoch: [123][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3743 (0.3270)	Acc@1 90.234 (94.074)	Acc@5 100.000 (99.921)
Epoch: [123][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.3265 (0.3268)	Acc@1 94.922 (94.094)	Acc@5 100.000 (99.913)
Max memory in training epoch: 46.86208
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.148 (0.148)	Data 0.268 (0.268)	Loss 0.3769 (0.3769)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.105 (0.107)	Data 0.000 (0.004)	Loss 0.3002 (0.3202)	Acc@1 95.703 (94.423)	Acc@5 100.000 (99.940)
Epoch: [124][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2481 (0.3230)	Acc@1 97.656 (94.219)	Acc@5 100.000 (99.909)
Epoch: [124][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.3247 (0.3249)	Acc@1 94.922 (94.151)	Acc@5 100.000 (99.913)
Max memory in training epoch: 46.86208
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.137 (0.137)	Data 0.296 (0.296)	Loss 0.3390 (0.3390)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.104 (0.105)	Data 0.000 (0.005)	Loss 0.3717 (0.3191)	Acc@1 91.016 (94.447)	Acc@5 100.000 (99.976)
Epoch: [125][128/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.3378 (0.3275)	Acc@1 93.359 (94.101)	Acc@5 100.000 (99.939)
Epoch: [125][192/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.2525 (0.3280)	Acc@1 96.875 (94.084)	Acc@5 99.609 (99.921)
Max memory in training epoch: 46.86208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 171216 ; 175872 ; 0.9735262008733624
[INFO] Storing checkpoint...
  89.92
Max memory: 73.4660096
 21.214s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8664
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0755712
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.149 (0.149)	Data 0.298 (0.298)	Loss 0.3403 (0.3403)	Acc@1 92.578 (92.578)	Acc@5 99.609 (99.609)
Epoch: [126][64/196]	Time 0.107 (0.108)	Data 0.000 (0.005)	Loss 0.2838 (0.3271)	Acc@1 95.703 (93.966)	Acc@5 100.000 (99.862)
Epoch: [126][128/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.3771 (0.3264)	Acc@1 93.359 (93.980)	Acc@5 99.609 (99.897)
Epoch: [126][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.3567 (0.3268)	Acc@1 93.750 (93.975)	Acc@5 99.609 (99.897)
Max memory in training epoch: 46.4285184
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.130 (0.130)	Data 0.283 (0.283)	Loss 0.3017 (0.3017)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.110 (0.110)	Data 0.000 (0.005)	Loss 0.3204 (0.3288)	Acc@1 95.312 (94.026)	Acc@5 100.000 (99.964)
Epoch: [127][128/196]	Time 0.114 (0.108)	Data 0.000 (0.002)	Loss 0.3398 (0.3279)	Acc@1 91.797 (93.935)	Acc@5 100.000 (99.930)
Epoch: [127][192/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.3352 (0.3266)	Acc@1 95.312 (94.003)	Acc@5 100.000 (99.933)
Max memory in training epoch: 46.5137152
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.128 (0.128)	Data 0.257 (0.257)	Loss 0.3139 (0.3139)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.108 (0.109)	Data 0.000 (0.004)	Loss 0.3112 (0.3146)	Acc@1 93.359 (94.609)	Acc@5 100.000 (99.928)
Epoch: [128][128/196]	Time 0.105 (0.109)	Data 0.000 (0.002)	Loss 0.3752 (0.3146)	Acc@1 92.969 (94.462)	Acc@5 100.000 (99.912)
Epoch: [128][192/196]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.3183 (0.3193)	Acc@1 95.703 (94.278)	Acc@5 100.000 (99.909)
Max memory in training epoch: 46.5137152
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.149 (0.149)	Data 0.257 (0.257)	Loss 0.3477 (0.3477)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.107 (0.107)	Data 0.000 (0.004)	Loss 0.2912 (0.3168)	Acc@1 96.094 (94.279)	Acc@5 100.000 (99.916)
Epoch: [129][128/196]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.3462 (0.3242)	Acc@1 92.578 (93.917)	Acc@5 100.000 (99.906)
Epoch: [129][192/196]	Time 0.106 (0.108)	Data 0.000 (0.001)	Loss 0.3871 (0.3258)	Acc@1 90.234 (93.865)	Acc@5 100.000 (99.911)
Max memory in training epoch: 46.5137152
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.138 (0.138)	Data 0.291 (0.291)	Loss 0.3166 (0.3166)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.106 (0.107)	Data 0.000 (0.005)	Loss 0.3264 (0.3105)	Acc@1 94.531 (94.387)	Acc@5 99.609 (99.928)
Epoch: [130][128/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2674 (0.3140)	Acc@1 96.094 (94.265)	Acc@5 100.000 (99.936)
Epoch: [130][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.2949 (0.3188)	Acc@1 94.531 (94.068)	Acc@5 100.000 (99.929)
Max memory in training epoch: 46.5137152
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 169210 ; 171216 ; 0.9882838052518457
[INFO] Storing checkpoint...
  89.93
Max memory: 72.394752
 21.252s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9097
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.074752
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.169 (0.169)	Data 0.266 (0.266)	Loss 0.3352 (0.3352)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.108 (0.109)	Data 0.000 (0.004)	Loss 0.3553 (0.3192)	Acc@1 93.359 (94.165)	Acc@5 99.609 (99.934)
Epoch: [131][128/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.3860 (0.3192)	Acc@1 92.188 (94.198)	Acc@5 99.609 (99.912)
Epoch: [131][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.2661 (0.3234)	Acc@1 96.875 (93.958)	Acc@5 100.000 (99.911)
Max memory in training epoch: 46.2941696
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.145 (0.145)	Data 0.318 (0.318)	Loss 0.2968 (0.2968)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.108 (0.109)	Data 0.000 (0.005)	Loss 0.3714 (0.3313)	Acc@1 92.188 (93.618)	Acc@5 100.000 (99.910)
Epoch: [132][128/196]	Time 0.113 (0.110)	Data 0.000 (0.003)	Loss 0.3399 (0.3297)	Acc@1 92.578 (93.677)	Acc@5 100.000 (99.894)
Epoch: [132][192/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.2926 (0.3293)	Acc@1 94.531 (93.732)	Acc@5 100.000 (99.875)
Max memory in training epoch: 46.1106688
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.120 (0.120)	Data 0.293 (0.293)	Loss 0.2962 (0.2962)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.109 (0.107)	Data 0.000 (0.005)	Loss 0.2751 (0.3124)	Acc@1 96.484 (94.447)	Acc@5 100.000 (99.922)
Epoch: [133][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3850 (0.3159)	Acc@1 92.578 (94.365)	Acc@5 99.609 (99.891)
Epoch: [133][192/196]	Time 0.115 (0.107)	Data 0.000 (0.002)	Loss 0.2944 (0.3187)	Acc@1 94.531 (94.209)	Acc@5 100.000 (99.887)
Max memory in training epoch: 46.2024192
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.157 (0.157)	Data 0.300 (0.300)	Loss 0.3179 (0.3179)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.109 (0.107)	Data 0.000 (0.005)	Loss 0.3697 (0.3182)	Acc@1 91.016 (94.081)	Acc@5 100.000 (99.910)
Epoch: [134][128/196]	Time 0.108 (0.107)	Data 0.000 (0.003)	Loss 0.3516 (0.3195)	Acc@1 91.797 (94.092)	Acc@5 99.609 (99.918)
Epoch: [134][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.3901 (0.3259)	Acc@1 91.016 (93.914)	Acc@5 100.000 (99.911)
Max memory in training epoch: 46.2024192
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.123 (0.123)	Data 0.288 (0.288)	Loss 0.2830 (0.2830)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.103 (0.107)	Data 0.000 (0.005)	Loss 0.3787 (0.3196)	Acc@1 91.406 (94.093)	Acc@5 100.000 (99.916)
Epoch: [135][128/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.3017 (0.3252)	Acc@1 94.531 (93.829)	Acc@5 100.000 (99.912)
Epoch: [135][192/196]	Time 0.100 (0.107)	Data 0.000 (0.002)	Loss 0.3778 (0.3299)	Acc@1 91.797 (93.622)	Acc@5 100.000 (99.909)
Max memory in training epoch: 46.2024192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 164430 ; 169210 ; 0.9717510785414574
[INFO] Storing checkpoint...
  87.14
Max memory: 71.9489024
 21.222s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9277
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.0728064
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.172 (0.172)	Data 0.298 (0.298)	Loss 0.2898 (0.2898)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [136][64/196]	Time 0.108 (0.108)	Data 0.000 (0.005)	Loss 0.2772 (0.3128)	Acc@1 95.312 (94.357)	Acc@5 100.000 (99.934)
Epoch: [136][128/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.3155 (0.3232)	Acc@1 94.141 (93.929)	Acc@5 100.000 (99.891)
Epoch: [136][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.3517 (0.3269)	Acc@1 92.578 (93.746)	Acc@5 100.000 (99.893)
Max memory in training epoch: 46.2470656
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.145 (0.145)	Data 0.293 (0.293)	Loss 0.2707 (0.2707)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.107 (0.109)	Data 0.000 (0.005)	Loss 0.3445 (0.3197)	Acc@1 91.406 (94.093)	Acc@5 100.000 (99.904)
Epoch: [137][128/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.3280 (0.3274)	Acc@1 93.750 (93.780)	Acc@5 99.609 (99.894)
Epoch: [137][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.3503 (0.3261)	Acc@1 92.969 (93.805)	Acc@5 100.000 (99.901)
Max memory in training epoch: 46.0635648
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.154 (0.154)	Data 0.274 (0.274)	Loss 0.2901 (0.2901)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.2788 (0.3203)	Acc@1 96.484 (93.750)	Acc@5 100.000 (99.934)
Epoch: [138][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.3313 (0.3231)	Acc@1 91.406 (93.759)	Acc@5 100.000 (99.930)
Epoch: [138][192/196]	Time 0.109 (0.108)	Data 0.000 (0.002)	Loss 0.3471 (0.3295)	Acc@1 94.141 (93.564)	Acc@5 99.609 (99.907)
Max memory in training epoch: 46.0635648
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.153 (0.153)	Data 0.310 (0.310)	Loss 0.3142 (0.3142)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.101 (0.106)	Data 0.000 (0.005)	Loss 0.3394 (0.3157)	Acc@1 90.625 (94.177)	Acc@5 100.000 (99.910)
Epoch: [139][128/196]	Time 0.101 (0.107)	Data 0.000 (0.003)	Loss 0.3274 (0.3219)	Acc@1 93.359 (93.826)	Acc@5 100.000 (99.909)
Epoch: [139][192/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2958 (0.3243)	Acc@1 94.141 (93.722)	Acc@5 100.000 (99.907)
Max memory in training epoch: 46.0635648
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.140 (0.140)	Data 0.297 (0.297)	Loss 0.3278 (0.3278)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.108 (0.107)	Data 0.000 (0.005)	Loss 0.2967 (0.3142)	Acc@1 95.703 (94.249)	Acc@5 100.000 (99.934)
Epoch: [140][128/196]	Time 0.101 (0.106)	Data 0.000 (0.002)	Loss 0.3420 (0.3205)	Acc@1 91.797 (93.971)	Acc@5 100.000 (99.909)
Epoch: [140][192/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.3158 (0.3228)	Acc@1 94.922 (93.932)	Acc@5 99.609 (99.907)
Max memory in training epoch: 46.0635648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 163004 ; 164430 ; 0.9913276166149729
[INFO] Storing checkpoint...
  88.43
Max memory: 71.623168
 21.286s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1306
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0722432
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.165 (0.165)	Data 0.259 (0.259)	Loss 0.3539 (0.3539)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.109 (0.109)	Data 0.000 (0.004)	Loss 0.2888 (0.3108)	Acc@1 93.750 (94.165)	Acc@5 100.000 (99.964)
Epoch: [141][128/196]	Time 0.103 (0.108)	Data 0.000 (0.002)	Loss 0.3532 (0.3242)	Acc@1 93.359 (93.747)	Acc@5 100.000 (99.909)
Epoch: [141][192/196]	Time 0.110 (0.107)	Data 0.000 (0.002)	Loss 0.2909 (0.3263)	Acc@1 95.312 (93.661)	Acc@5 99.609 (99.917)
Max memory in training epoch: 46.2317056
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.161 (0.161)	Data 0.255 (0.255)	Loss 0.3071 (0.3071)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [142][64/196]	Time 0.102 (0.106)	Data 0.000 (0.004)	Loss 0.3031 (0.3243)	Acc@1 94.922 (93.924)	Acc@5 100.000 (99.904)
Epoch: [142][128/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.2806 (0.3248)	Acc@1 96.094 (93.868)	Acc@5 100.000 (99.912)
Epoch: [142][192/196]	Time 0.104 (0.106)	Data 0.000 (0.001)	Loss 0.3308 (0.3301)	Acc@1 92.969 (93.740)	Acc@5 99.219 (99.899)
Max memory in training epoch: 46.028544
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.152 (0.152)	Data 0.284 (0.284)	Loss 0.3099 (0.3099)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.126 (0.107)	Data 0.000 (0.005)	Loss 0.3707 (0.3144)	Acc@1 89.844 (94.219)	Acc@5 100.000 (99.910)
Epoch: [143][128/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.2502 (0.3206)	Acc@1 95.312 (93.953)	Acc@5 100.000 (99.894)
Epoch: [143][192/196]	Time 0.124 (0.106)	Data 0.000 (0.002)	Loss 0.3809 (0.3237)	Acc@1 91.797 (93.857)	Acc@5 100.000 (99.881)
Max memory in training epoch: 46.028544
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.127 (0.127)	Data 0.294 (0.294)	Loss 0.2565 (0.2565)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.104 (0.105)	Data 0.000 (0.005)	Loss 0.3256 (0.3053)	Acc@1 93.359 (94.381)	Acc@5 100.000 (99.886)
Epoch: [144][128/196]	Time 0.103 (0.104)	Data 0.000 (0.002)	Loss 0.2873 (0.3179)	Acc@1 94.141 (93.956)	Acc@5 100.000 (99.900)
Epoch: [144][192/196]	Time 0.101 (0.104)	Data 0.000 (0.002)	Loss 0.2903 (0.3217)	Acc@1 94.531 (93.894)	Acc@5 100.000 (99.907)
Max memory in training epoch: 46.028544
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.154 (0.154)	Data 0.262 (0.262)	Loss 0.3107 (0.3107)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.105 (0.107)	Data 0.000 (0.004)	Loss 0.3246 (0.3252)	Acc@1 93.750 (93.738)	Acc@5 100.000 (99.874)
Epoch: [145][128/196]	Time 0.106 (0.109)	Data 0.000 (0.002)	Loss 0.3063 (0.3279)	Acc@1 95.312 (93.702)	Acc@5 100.000 (99.888)
Epoch: [145][192/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.3353 (0.3274)	Acc@1 92.969 (93.718)	Acc@5 100.000 (99.905)
Max memory in training epoch: 46.028544
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 160584 ; 163004 ; 0.985153738558563
[INFO] Storing checkpoint...
  87.34
Max memory: 71.5616768
 21.576s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 169
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0712704
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.176 (0.176)	Data 0.264 (0.264)	Loss 0.3319 (0.3319)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [146][64/196]	Time 0.106 (0.107)	Data 0.000 (0.004)	Loss 0.3092 (0.3096)	Acc@1 95.312 (94.333)	Acc@5 99.609 (99.952)
Epoch: [146][128/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.2716 (0.3141)	Acc@1 96.484 (94.253)	Acc@5 100.000 (99.921)
Epoch: [146][192/196]	Time 0.107 (0.109)	Data 0.000 (0.002)	Loss 0.3951 (0.3215)	Acc@1 91.406 (93.932)	Acc@5 100.000 (99.913)
Max memory in training epoch: 45.9591168
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.155 (0.155)	Data 0.314 (0.314)	Loss 0.2816 (0.2816)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.106 (0.107)	Data 0.000 (0.005)	Loss 0.3473 (0.3188)	Acc@1 92.188 (93.972)	Acc@5 100.000 (99.940)
Epoch: [147][128/196]	Time 0.109 (0.106)	Data 0.000 (0.003)	Loss 0.3408 (0.3215)	Acc@1 93.750 (93.859)	Acc@5 100.000 (99.918)
Epoch: [147][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.3178 (0.3262)	Acc@1 94.922 (93.738)	Acc@5 100.000 (99.907)
Max memory in training epoch: 45.7362944
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.167 (0.167)	Data 0.288 (0.288)	Loss 0.3460 (0.3460)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [148][64/196]	Time 0.105 (0.107)	Data 0.000 (0.005)	Loss 0.3197 (0.3143)	Acc@1 92.969 (94.315)	Acc@5 100.000 (99.880)
Epoch: [148][128/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2700 (0.3161)	Acc@1 95.312 (94.180)	Acc@5 99.609 (99.891)
Epoch: [148][192/196]	Time 0.102 (0.105)	Data 0.000 (0.002)	Loss 0.3684 (0.3223)	Acc@1 91.797 (93.936)	Acc@5 100.000 (99.893)
Max memory in training epoch: 45.7362944
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.143 (0.143)	Data 0.289 (0.289)	Loss 0.3429 (0.3429)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.104 (0.106)	Data 0.000 (0.005)	Loss 0.3277 (0.3180)	Acc@1 93.750 (94.099)	Acc@5 100.000 (99.904)
Epoch: [149][128/196]	Time 0.098 (0.105)	Data 0.000 (0.002)	Loss 0.3065 (0.3242)	Acc@1 94.922 (93.859)	Acc@5 100.000 (99.894)
Epoch: [149][192/196]	Time 0.102 (0.105)	Data 0.000 (0.002)	Loss 0.3473 (0.3259)	Acc@1 93.359 (93.782)	Acc@5 100.000 (99.893)
Max memory in training epoch: 45.7362944
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.149 (0.149)	Data 0.255 (0.255)	Loss 0.2875 (0.2875)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [150][64/196]	Time 0.096 (0.107)	Data 0.000 (0.004)	Loss 0.2763 (0.2921)	Acc@1 95.312 (95.036)	Acc@5 100.000 (99.922)
Epoch: [150][128/196]	Time 0.100 (0.106)	Data 0.000 (0.002)	Loss 0.2655 (0.2850)	Acc@1 94.922 (95.340)	Acc@5 100.000 (99.921)
Epoch: [150][192/196]	Time 0.110 (0.105)	Data 0.000 (0.001)	Loss 0.2255 (0.2769)	Acc@1 98.438 (95.638)	Acc@5 100.000 (99.943)
Max memory in training epoch: 45.7362944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.5
Max memory: 71.5853824
 20.927s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 829
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0712704
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.175 (0.175)	Data 0.272 (0.272)	Loss 0.2674 (0.2674)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.107 (0.108)	Data 0.000 (0.004)	Loss 0.2154 (0.2557)	Acc@1 98.047 (96.484)	Acc@5 100.000 (99.940)
Epoch: [151][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2767 (0.2557)	Acc@1 95.312 (96.415)	Acc@5 100.000 (99.942)
Epoch: [151][192/196]	Time 0.109 (0.109)	Data 0.000 (0.002)	Loss 0.2252 (0.2537)	Acc@1 98.438 (96.513)	Acc@5 100.000 (99.939)
Max memory in training epoch: 45.9591168
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.146 (0.146)	Data 0.291 (0.291)	Loss 0.2773 (0.2773)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.101 (0.107)	Data 0.000 (0.005)	Loss 0.2388 (0.2443)	Acc@1 96.094 (96.791)	Acc@5 100.000 (99.952)
Epoch: [152][128/196]	Time 0.110 (0.106)	Data 0.000 (0.002)	Loss 0.2341 (0.2451)	Acc@1 97.266 (96.778)	Acc@5 100.000 (99.970)
Epoch: [152][192/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2918 (0.2472)	Acc@1 95.312 (96.713)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.7362944
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.157 (0.157)	Data 0.287 (0.287)	Loss 0.2679 (0.2679)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [153][64/196]	Time 0.101 (0.106)	Data 0.000 (0.005)	Loss 0.2679 (0.2405)	Acc@1 96.094 (96.899)	Acc@5 100.000 (99.958)
Epoch: [153][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.2330 (0.2424)	Acc@1 95.703 (96.808)	Acc@5 100.000 (99.961)
Epoch: [153][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.2311 (0.2413)	Acc@1 97.266 (96.832)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.7362944
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.164 (0.164)	Data 0.258 (0.258)	Loss 0.2101 (0.2101)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.103 (0.108)	Data 0.000 (0.004)	Loss 0.2274 (0.2362)	Acc@1 96.484 (97.103)	Acc@5 100.000 (99.976)
Epoch: [154][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2674 (0.2343)	Acc@1 96.484 (97.111)	Acc@5 100.000 (99.973)
Epoch: [154][192/196]	Time 0.102 (0.106)	Data 0.000 (0.002)	Loss 0.2426 (0.2362)	Acc@1 97.656 (97.031)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.7362944
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.161 (0.161)	Data 0.301 (0.301)	Loss 0.2254 (0.2254)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.109 (0.107)	Data 0.000 (0.005)	Loss 0.2439 (0.2348)	Acc@1 97.266 (97.061)	Acc@5 100.000 (99.946)
Epoch: [155][128/196]	Time 0.108 (0.107)	Data 0.000 (0.003)	Loss 0.2375 (0.2348)	Acc@1 96.484 (97.054)	Acc@5 100.000 (99.955)
Epoch: [155][192/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2347 (0.2345)	Acc@1 97.266 (97.128)	Acc@5 100.000 (99.960)
Max memory in training epoch: 45.7362944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 159012 ; 160584 ; 0.9902107308324615
[INFO] Storing checkpoint...
  91.81
Max memory: 71.5853824
 21.138s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1372
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0706048
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.214 (0.214)	Data 0.292 (0.292)	Loss 0.2417 (0.2417)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.098 (0.107)	Data 0.000 (0.005)	Loss 0.2561 (0.2326)	Acc@1 96.484 (97.145)	Acc@5 100.000 (99.982)
Epoch: [156][128/196]	Time 0.112 (0.106)	Data 0.000 (0.002)	Loss 0.2555 (0.2341)	Acc@1 96.484 (97.054)	Acc@5 100.000 (99.970)
Epoch: [156][192/196]	Time 0.103 (0.105)	Data 0.000 (0.002)	Loss 0.2498 (0.2340)	Acc@1 96.875 (97.059)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.6877568
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.142 (0.142)	Data 0.282 (0.282)	Loss 0.2353 (0.2353)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.105 (0.106)	Data 0.000 (0.005)	Loss 0.2191 (0.2283)	Acc@1 96.875 (97.302)	Acc@5 100.000 (99.958)
Epoch: [157][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2263 (0.2313)	Acc@1 97.266 (97.193)	Acc@5 100.000 (99.976)
Epoch: [157][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2272 (0.2320)	Acc@1 97.656 (97.177)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.4911488
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.156 (0.156)	Data 0.290 (0.290)	Loss 0.2245 (0.2245)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.104 (0.109)	Data 0.000 (0.005)	Loss 0.1987 (0.2272)	Acc@1 98.828 (97.254)	Acc@5 100.000 (99.964)
Epoch: [158][128/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.2196 (0.2268)	Acc@1 97.656 (97.305)	Acc@5 100.000 (99.964)
Epoch: [158][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2434 (0.2272)	Acc@1 96.094 (97.296)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.4911488
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.149 (0.149)	Data 0.263 (0.263)	Loss 0.2287 (0.2287)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.128 (0.105)	Data 0.000 (0.004)	Loss 0.2428 (0.2234)	Acc@1 96.094 (97.386)	Acc@5 100.000 (99.952)
Epoch: [159][128/196]	Time 0.121 (0.105)	Data 0.000 (0.002)	Loss 0.2235 (0.2259)	Acc@1 97.656 (97.308)	Acc@5 100.000 (99.949)
Epoch: [159][192/196]	Time 0.107 (0.104)	Data 0.000 (0.002)	Loss 0.2213 (0.2259)	Acc@1 97.656 (97.343)	Acc@5 100.000 (99.960)
Max memory in training epoch: 45.4911488
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.160 (0.160)	Data 0.255 (0.255)	Loss 0.2106 (0.2106)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.106 (0.107)	Data 0.000 (0.004)	Loss 0.2132 (0.2233)	Acc@1 98.828 (97.434)	Acc@5 100.000 (99.970)
Epoch: [160][128/196]	Time 0.105 (0.107)	Data 0.000 (0.002)	Loss 0.1888 (0.2228)	Acc@1 99.219 (97.405)	Acc@5 100.000 (99.964)
Epoch: [160][192/196]	Time 0.103 (0.106)	Data 0.000 (0.001)	Loss 0.2044 (0.2224)	Acc@1 98.047 (97.401)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.4911488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 157874 ; 159012 ; 0.9928433074233391
[INFO] Storing checkpoint...
  91.81
Max memory: 71.0476288
 21.012s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2262
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.0701952
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.156 (0.156)	Data 0.277 (0.277)	Loss 0.2464 (0.2464)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.105 (0.109)	Data 0.000 (0.004)	Loss 0.2193 (0.2261)	Acc@1 96.484 (97.320)	Acc@5 100.000 (99.976)
Epoch: [161][128/196]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.2900 (0.2238)	Acc@1 94.141 (97.353)	Acc@5 100.000 (99.973)
Epoch: [161][192/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2149 (0.2251)	Acc@1 97.656 (97.276)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.3315072
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.160 (0.160)	Data 0.288 (0.288)	Loss 0.2246 (0.2246)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.101 (0.110)	Data 0.000 (0.005)	Loss 0.2154 (0.2189)	Acc@1 97.266 (97.482)	Acc@5 100.000 (99.970)
Epoch: [162][128/196]	Time 0.110 (0.108)	Data 0.000 (0.002)	Loss 0.1956 (0.2183)	Acc@1 98.828 (97.562)	Acc@5 100.000 (99.970)
Epoch: [162][192/196]	Time 0.112 (0.108)	Data 0.000 (0.002)	Loss 0.2089 (0.2206)	Acc@1 98.047 (97.454)	Acc@5 100.000 (99.966)
Max memory in training epoch: 45.5026176
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.149 (0.149)	Data 0.273 (0.273)	Loss 0.2202 (0.2202)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.107 (0.107)	Data 0.000 (0.004)	Loss 0.2444 (0.2146)	Acc@1 96.875 (97.740)	Acc@5 100.000 (99.964)
Epoch: [163][128/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.2213 (0.2185)	Acc@1 97.656 (97.590)	Acc@5 100.000 (99.967)
Epoch: [163][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2481 (0.2180)	Acc@1 96.094 (97.569)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.5026176
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.160 (0.160)	Data 0.283 (0.283)	Loss 0.2177 (0.2177)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.107 (0.112)	Data 0.000 (0.005)	Loss 0.1993 (0.2140)	Acc@1 98.438 (97.752)	Acc@5 100.000 (99.970)
Epoch: [164][128/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.1771 (0.2156)	Acc@1 98.828 (97.632)	Acc@5 100.000 (99.973)
Epoch: [164][192/196]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.2207 (0.2175)	Acc@1 98.438 (97.527)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.5026176
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.134 (0.134)	Data 0.283 (0.283)	Loss 0.2064 (0.2064)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.1910 (0.2124)	Acc@1 98.828 (97.758)	Acc@5 100.000 (99.946)
Epoch: [165][128/196]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.2263 (0.2145)	Acc@1 97.266 (97.596)	Acc@5 100.000 (99.958)
Epoch: [165][192/196]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2369 (0.2141)	Acc@1 96.875 (97.557)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.5026176
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 157296 ; 157874 ; 0.9963388525026287
[INFO] Storing checkpoint...
  91.53
Max memory: 70.7437056
 21.830s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1263
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0699904
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.155 (0.155)	Data 0.282 (0.282)	Loss 0.1795 (0.1795)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.107 (0.107)	Data 0.000 (0.005)	Loss 0.2063 (0.2160)	Acc@1 98.047 (97.404)	Acc@5 100.000 (99.958)
Epoch: [166][128/196]	Time 0.100 (0.107)	Data 0.000 (0.002)	Loss 0.2283 (0.2164)	Acc@1 97.266 (97.499)	Acc@5 100.000 (99.973)
Epoch: [166][192/196]	Time 0.110 (0.107)	Data 0.000 (0.002)	Loss 0.1943 (0.2167)	Acc@1 98.828 (97.557)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.3310976
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.158 (0.158)	Data 0.254 (0.254)	Loss 0.2507 (0.2507)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.105 (0.109)	Data 0.000 (0.004)	Loss 0.1882 (0.2123)	Acc@1 98.047 (97.728)	Acc@5 100.000 (99.988)
Epoch: [167][128/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.2145 (0.2124)	Acc@1 98.047 (97.711)	Acc@5 100.000 (99.973)
Epoch: [167][192/196]	Time 0.104 (0.108)	Data 0.000 (0.001)	Loss 0.2233 (0.2130)	Acc@1 97.266 (97.658)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.5017984
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.129 (0.129)	Data 0.294 (0.294)	Loss 0.1957 (0.1957)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.108 (0.108)	Data 0.000 (0.005)	Loss 0.2107 (0.2117)	Acc@1 97.266 (97.596)	Acc@5 100.000 (99.970)
Epoch: [168][128/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.1957 (0.2101)	Acc@1 98.828 (97.674)	Acc@5 100.000 (99.979)
Epoch: [168][192/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.2105 (0.2118)	Acc@1 97.266 (97.630)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.3969408
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.161 (0.161)	Data 0.253 (0.253)	Loss 0.2243 (0.2243)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.104 (0.109)	Data 0.000 (0.004)	Loss 0.1970 (0.2112)	Acc@1 97.656 (97.644)	Acc@5 100.000 (99.976)
Epoch: [169][128/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.1997 (0.2113)	Acc@1 98.438 (97.641)	Acc@5 100.000 (99.973)
Epoch: [169][192/196]	Time 0.109 (0.106)	Data 0.000 (0.001)	Loss 0.1932 (0.2118)	Acc@1 98.047 (97.638)	Acc@5 100.000 (99.964)
Max memory in training epoch: 45.3969408
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.157 (0.157)	Data 0.288 (0.288)	Loss 0.2127 (0.2127)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.107 (0.110)	Data 0.000 (0.005)	Loss 0.1933 (0.2047)	Acc@1 98.438 (97.921)	Acc@5 100.000 (99.970)
Epoch: [170][128/196]	Time 0.109 (0.109)	Data 0.000 (0.002)	Loss 0.2092 (0.2087)	Acc@1 97.656 (97.744)	Acc@5 100.000 (99.979)
Epoch: [170][192/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.2191 (0.2092)	Acc@1 98.047 (97.711)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.3969408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 155060 ; 157296 ; 0.9857847624860137
[INFO] Storing checkpoint...
  91.68
Max memory: 70.6005504
 21.439s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3123
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.0690688
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.171 (0.171)	Data 0.267 (0.267)	Loss 0.2404 (0.2404)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.102 (0.108)	Data 0.000 (0.004)	Loss 0.2152 (0.2213)	Acc@1 98.438 (97.248)	Acc@5 99.609 (99.958)
Epoch: [171][128/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2350 (0.2202)	Acc@1 96.484 (97.347)	Acc@5 100.000 (99.973)
Epoch: [171][192/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.2132 (0.2190)	Acc@1 97.266 (97.365)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.30304
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.159 (0.159)	Data 0.258 (0.258)	Loss 0.1805 (0.1805)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.105 (0.108)	Data 0.000 (0.004)	Loss 0.2465 (0.2122)	Acc@1 95.703 (97.638)	Acc@5 100.000 (99.964)
Epoch: [172][128/196]	Time 0.102 (0.107)	Data 0.000 (0.002)	Loss 0.1916 (0.2118)	Acc@1 98.047 (97.553)	Acc@5 100.000 (99.967)
Epoch: [172][192/196]	Time 0.104 (0.106)	Data 0.000 (0.001)	Loss 0.2091 (0.2112)	Acc@1 98.828 (97.579)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.4718976
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.125 (0.125)	Data 0.266 (0.266)	Loss 0.2363 (0.2363)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.106 (0.107)	Data 0.000 (0.004)	Loss 0.1927 (0.2054)	Acc@1 98.828 (97.782)	Acc@5 100.000 (99.994)
Epoch: [173][128/196]	Time 0.099 (0.107)	Data 0.000 (0.002)	Loss 0.2260 (0.2071)	Acc@1 96.094 (97.750)	Acc@5 100.000 (99.991)
Epoch: [173][192/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2146 (0.2084)	Acc@1 96.875 (97.705)	Acc@5 100.000 (99.988)
Max memory in training epoch: 45.36704
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.154 (0.154)	Data 0.293 (0.293)	Loss 0.1905 (0.1905)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.102 (0.108)	Data 0.000 (0.005)	Loss 0.2255 (0.2067)	Acc@1 96.484 (97.861)	Acc@5 100.000 (99.976)
Epoch: [174][128/196]	Time 0.101 (0.106)	Data 0.000 (0.002)	Loss 0.2161 (0.2064)	Acc@1 97.656 (97.853)	Acc@5 100.000 (99.973)
Epoch: [174][192/196]	Time 0.099 (0.106)	Data 0.000 (0.002)	Loss 0.1893 (0.2070)	Acc@1 98.047 (97.780)	Acc@5 100.000 (99.978)
Max memory in training epoch: 45.36704
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.152 (0.152)	Data 0.289 (0.289)	Loss 0.2041 (0.2041)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.107 (0.108)	Data 0.000 (0.005)	Loss 0.2231 (0.2052)	Acc@1 96.484 (97.794)	Acc@5 100.000 (99.988)
Epoch: [175][128/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.1904 (0.2040)	Acc@1 97.656 (97.805)	Acc@5 100.000 (99.985)
Epoch: [175][192/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.1812 (0.2035)	Acc@1 99.219 (97.840)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.36704
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 151220 ; 155060 ; 0.9752353927511931
[INFO] Storing checkpoint...
  91.19
Max memory: 70.5568256
 21.554s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5476
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.067584
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.169 (0.169)	Data 0.288 (0.288)	Loss 0.2352 (0.2352)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.101 (0.106)	Data 0.000 (0.005)	Loss 0.2106 (0.2331)	Acc@1 96.875 (96.809)	Acc@5 100.000 (99.970)
Epoch: [176][128/196]	Time 0.098 (0.105)	Data 0.000 (0.002)	Loss 0.2355 (0.2284)	Acc@1 96.875 (96.911)	Acc@5 100.000 (99.961)
Epoch: [176][192/196]	Time 0.105 (0.105)	Data 0.000 (0.002)	Loss 0.2023 (0.2253)	Acc@1 98.047 (97.025)	Acc@5 100.000 (99.962)
Max memory in training epoch: 45.2476416
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.122 (0.122)	Data 0.263 (0.263)	Loss 0.2074 (0.2074)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.104 (0.107)	Data 0.000 (0.004)	Loss 0.2228 (0.2094)	Acc@1 96.094 (97.494)	Acc@5 100.000 (99.976)
Epoch: [177][128/196]	Time 0.098 (0.106)	Data 0.000 (0.002)	Loss 0.1780 (0.2124)	Acc@1 98.828 (97.384)	Acc@5 100.000 (99.961)
Epoch: [177][192/196]	Time 0.099 (0.106)	Data 0.000 (0.002)	Loss 0.2066 (0.2129)	Acc@1 97.656 (97.383)	Acc@5 100.000 (99.966)
Max memory in training epoch: 45.4266368
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.133 (0.133)	Data 0.291 (0.291)	Loss 0.2097 (0.2097)	Acc@1 98.047 (98.047)	Acc@5 99.609 (99.609)
Epoch: [178][64/196]	Time 0.100 (0.106)	Data 0.000 (0.005)	Loss 0.2181 (0.2106)	Acc@1 97.656 (97.578)	Acc@5 100.000 (99.982)
Epoch: [178][128/196]	Time 0.104 (0.105)	Data 0.000 (0.002)	Loss 0.1867 (0.2096)	Acc@1 98.047 (97.556)	Acc@5 99.609 (99.973)
Epoch: [178][192/196]	Time 0.104 (0.105)	Data 0.000 (0.002)	Loss 0.1963 (0.2105)	Acc@1 98.438 (97.541)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.4266368
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.133 (0.133)	Data 0.297 (0.297)	Loss 0.1907 (0.1907)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.122 (0.105)	Data 0.000 (0.005)	Loss 0.1952 (0.2065)	Acc@1 98.047 (97.698)	Acc@5 100.000 (99.982)
Epoch: [179][128/196]	Time 0.106 (0.105)	Data 0.000 (0.002)	Loss 0.2215 (0.2078)	Acc@1 96.484 (97.599)	Acc@5 100.000 (99.979)
Epoch: [179][192/196]	Time 0.107 (0.105)	Data 0.000 (0.002)	Loss 0.1905 (0.2083)	Acc@1 98.047 (97.561)	Acc@5 100.000 (99.984)
Max memory in training epoch: 45.4266368
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.156 (0.156)	Data 0.261 (0.261)	Loss 0.1874 (0.1874)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.105 (0.106)	Data 0.000 (0.004)	Loss 0.1999 (0.2068)	Acc@1 96.875 (97.500)	Acc@5 100.000 (99.976)
Epoch: [180][128/196]	Time 0.104 (0.106)	Data 0.000 (0.002)	Loss 0.2110 (0.2078)	Acc@1 96.875 (97.462)	Acc@5 100.000 (99.985)
Epoch: [180][192/196]	Time 0.104 (0.105)	Data 0.000 (0.002)	Loss 0.2140 (0.2089)	Acc@1 97.656 (97.397)	Acc@5 100.000 (99.984)
Max memory in training epoch: 45.4266368
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 14, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(14, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(21, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(13, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 34, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(34, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(61, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(36, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(61, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(7, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(61, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(12, 61, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(61, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): AdaptiveAvgPool2d(output_size=(1, 1))
    (55): Linear(in_features=61, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  91.28
Max memory: 70.4959488
 20.969s  Thres 0.1 5
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8068
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.204 (0.204)	Data 0.282 (0.282)	Loss 3.1843 (3.1843)	Acc@1 8.594 (8.594)	Acc@5 47.266 (47.266)
Epoch: [1][64/196]	Time 0.129 (0.133)	Data 0.000 (0.005)	Loss 2.3129 (2.5987)	Acc@1 32.812 (25.901)	Acc@5 87.109 (79.904)
Epoch: [1][128/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 2.1709 (2.4297)	Acc@1 42.578 (31.946)	Acc@5 89.062 (84.317)
Epoch: [1][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.9857 (2.3088)	Acc@1 48.047 (36.276)	Acc@5 92.188 (86.885)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.179 (0.179)	Data 0.276 (0.276)	Loss 1.8196 (1.8196)	Acc@1 50.000 (50.000)	Acc@5 96.484 (96.484)
Epoch: [2][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 1.7807 (1.8693)	Acc@1 55.859 (51.352)	Acc@5 93.750 (94.123)
Epoch: [2][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 1.6560 (1.7922)	Acc@1 60.547 (54.479)	Acc@5 96.875 (94.749)
Epoch: [2][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.4887 (1.7265)	Acc@1 65.234 (56.936)	Acc@5 96.094 (95.211)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.206 (0.206)	Data 0.289 (0.289)	Loss 1.5997 (1.5997)	Acc@1 58.984 (58.984)	Acc@5 94.922 (94.922)
Epoch: [3][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 1.4962 (1.4711)	Acc@1 65.234 (65.355)	Acc@5 97.266 (96.899)
Epoch: [3][128/196]	Time 0.135 (0.129)	Data 0.000 (0.002)	Loss 1.4563 (1.4367)	Acc@1 64.453 (66.182)	Acc@5 97.656 (97.145)
Epoch: [3][192/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 1.3025 (1.4055)	Acc@1 71.094 (67.260)	Acc@5 98.438 (97.322)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.194 (0.194)	Data 0.265 (0.265)	Loss 1.2950 (1.2950)	Acc@1 67.969 (67.969)	Acc@5 99.219 (99.219)
Epoch: [4][64/196]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 1.1817 (1.2582)	Acc@1 75.391 (71.154)	Acc@5 97.656 (97.879)
Epoch: [4][128/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 1.1932 (1.2273)	Acc@1 74.219 (72.226)	Acc@5 95.703 (98.001)
Epoch: [4][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.2279 (1.2074)	Acc@1 72.266 (72.606)	Acc@5 95.703 (98.031)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.222 (0.222)	Data 0.310 (0.310)	Loss 1.1110 (1.1110)	Acc@1 75.781 (75.781)	Acc@5 97.656 (97.656)
Epoch: [5][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.9918 (1.1170)	Acc@1 76.562 (74.874)	Acc@5 100.000 (98.540)
Epoch: [5][128/196]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.9682 (1.0932)	Acc@1 79.297 (75.824)	Acc@5 99.609 (98.528)
Epoch: [5][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.0379 (1.0811)	Acc@1 79.297 (76.101)	Acc@5 98.438 (98.553)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 368232 ; 487386 ; 0.7555243687754675
[INFO] Storing checkpoint...
  65.26
Max memory: 103.3835008
 25.775s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2382
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1552384
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.173 (0.173)	Data 0.255 (0.255)	Loss 1.0881 (1.0881)	Acc@1 73.047 (73.047)	Acc@5 99.219 (99.219)
Epoch: [6][64/196]	Time 0.125 (0.126)	Data 0.000 (0.004)	Loss 0.9767 (0.9898)	Acc@1 78.125 (77.151)	Acc@5 96.875 (98.714)
Epoch: [6][128/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 1.0632 (0.9766)	Acc@1 76.562 (77.592)	Acc@5 98.828 (98.728)
Epoch: [6][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 1.0093 (0.9716)	Acc@1 76.172 (77.597)	Acc@5 98.438 (98.719)
Max memory in training epoch: 65.2780032
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.163 (0.163)	Data 0.298 (0.298)	Loss 0.8938 (0.8938)	Acc@1 83.203 (83.203)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.8855 (0.9245)	Acc@1 80.469 (79.038)	Acc@5 99.609 (98.822)
Epoch: [7][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.9258 (0.9279)	Acc@1 78.906 (78.955)	Acc@5 98.828 (98.774)
Epoch: [7][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.8662 (0.9155)	Acc@1 82.812 (79.242)	Acc@5 99.219 (98.780)
Max memory in training epoch: 65.2190208
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.196 (0.196)	Data 0.262 (0.262)	Loss 0.8732 (0.8732)	Acc@1 80.859 (80.859)	Acc@5 100.000 (100.000)
Epoch: [8][64/196]	Time 0.138 (0.131)	Data 0.000 (0.004)	Loss 0.8476 (0.8929)	Acc@1 83.594 (79.694)	Acc@5 98.828 (98.900)
Epoch: [8][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8529 (0.8843)	Acc@1 82.031 (79.878)	Acc@5 98.828 (98.937)
Epoch: [8][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8306 (0.8826)	Acc@1 82.031 (79.928)	Acc@5 98.828 (98.923)
Max memory in training epoch: 65.2190208
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.181 (0.181)	Data 0.279 (0.279)	Loss 0.7929 (0.7929)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 0.134 (0.130)	Data 0.000 (0.004)	Loss 0.7275 (0.8398)	Acc@1 86.719 (81.208)	Acc@5 99.219 (98.912)
Epoch: [9][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7953 (0.8431)	Acc@1 83.984 (80.965)	Acc@5 99.609 (98.910)
Epoch: [9][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.9318 (0.8431)	Acc@1 77.344 (80.963)	Acc@5 98.047 (98.968)
Max memory in training epoch: 65.2190208
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.184 (0.184)	Data 0.329 (0.329)	Loss 0.7722 (0.7722)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.8763 (0.8279)	Acc@1 78.516 (81.148)	Acc@5 100.000 (99.129)
Epoch: [10][128/196]	Time 0.131 (0.129)	Data 0.000 (0.003)	Loss 0.9481 (0.8184)	Acc@1 76.172 (81.374)	Acc@5 98.828 (99.104)
Epoch: [10][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7286 (0.8241)	Acc@1 84.375 (81.127)	Acc@5 100.000 (99.045)
Max memory in training epoch: 65.2190208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 259850 ; 368232 ; 0.7056692519933085
[INFO] Storing checkpoint...
  76.38
Max memory: 101.4610944
 25.666s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3847
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.1119744
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.176 (0.176)	Data 0.265 (0.265)	Loss 1.1040 (1.1040)	Acc@1 69.141 (69.141)	Acc@5 97.266 (97.266)
Epoch: [11][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.7879 (0.8137)	Acc@1 80.859 (80.883)	Acc@5 99.219 (98.960)
Epoch: [11][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.7895 (0.8070)	Acc@1 82.031 (80.974)	Acc@5 98.047 (98.949)
Epoch: [11][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.8494 (0.8033)	Acc@1 78.125 (81.033)	Acc@5 99.219 (98.941)
Max memory in training epoch: 62.077184
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.173 (0.173)	Data 0.300 (0.300)	Loss 0.7157 (0.7157)	Acc@1 82.422 (82.422)	Acc@5 98.438 (98.438)
Epoch: [12][64/196]	Time 0.122 (0.128)	Data 0.000 (0.005)	Loss 0.7956 (0.7808)	Acc@1 82.812 (81.929)	Acc@5 99.219 (98.930)
Epoch: [12][128/196]	Time 0.126 (0.128)	Data 0.000 (0.003)	Loss 0.7241 (0.7839)	Acc@1 82.812 (81.668)	Acc@5 99.609 (99.067)
Epoch: [12][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7290 (0.7853)	Acc@1 85.156 (81.681)	Acc@5 99.609 (99.037)
Max memory in training epoch: 61.6577536
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.200 (0.200)	Data 0.263 (0.263)	Loss 0.7532 (0.7532)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [13][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.7909 (0.7798)	Acc@1 81.641 (81.581)	Acc@5 98.828 (99.117)
Epoch: [13][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8363 (0.7737)	Acc@1 79.688 (82.016)	Acc@5 99.219 (99.073)
Epoch: [13][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8865 (0.7701)	Acc@1 77.344 (82.171)	Acc@5 98.828 (99.065)
Max memory in training epoch: 61.6577536
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.173 (0.173)	Data 0.268 (0.268)	Loss 0.7669 (0.7669)	Acc@1 80.078 (80.078)	Acc@5 99.219 (99.219)
Epoch: [14][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7138 (0.7649)	Acc@1 85.156 (82.404)	Acc@5 99.219 (99.171)
Epoch: [14][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.8228 (0.7684)	Acc@1 80.859 (82.216)	Acc@5 99.609 (99.179)
Epoch: [14][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7162 (0.7634)	Acc@1 85.547 (82.389)	Acc@5 100.000 (99.188)
Max memory in training epoch: 61.6577536
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.162 (0.162)	Data 0.277 (0.277)	Loss 0.5930 (0.5930)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [15][64/196]	Time 0.128 (0.128)	Data 0.000 (0.004)	Loss 0.7861 (0.7517)	Acc@1 79.688 (82.981)	Acc@5 99.219 (99.105)
Epoch: [15][128/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.7339 (0.7565)	Acc@1 83.203 (82.722)	Acc@5 98.438 (99.137)
Epoch: [15][192/196]	Time 0.118 (0.127)	Data 0.000 (0.002)	Loss 0.6840 (0.7562)	Acc@1 85.156 (82.555)	Acc@5 98.828 (99.160)
Max memory in training epoch: 61.6577536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 248716 ; 259850 ; 0.9571522031941505
[INFO] Storing checkpoint...
  74.17
Max memory: 96.4853248
 25.264s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1453
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1076736
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.214 (0.214)	Data 0.263 (0.263)	Loss 0.8178 (0.8178)	Acc@1 79.297 (79.297)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.125 (0.131)	Data 0.000 (0.004)	Loss 0.7498 (0.7168)	Acc@1 81.641 (83.936)	Acc@5 99.219 (99.195)
Epoch: [16][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7199 (0.7354)	Acc@1 83.984 (83.282)	Acc@5 98.828 (99.167)
Epoch: [16][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7869 (0.7406)	Acc@1 80.078 (82.906)	Acc@5 98.828 (99.162)
Max memory in training epoch: 59.4909696
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.177 (0.177)	Data 0.290 (0.290)	Loss 0.8198 (0.8198)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [17][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.6664 (0.7428)	Acc@1 84.766 (82.800)	Acc@5 99.219 (99.267)
Epoch: [17][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7664 (0.7467)	Acc@1 81.250 (82.743)	Acc@5 99.609 (99.213)
Epoch: [17][192/196]	Time 0.135 (0.128)	Data 0.000 (0.002)	Loss 0.7156 (0.7439)	Acc@1 86.719 (82.908)	Acc@5 99.219 (99.211)
Max memory in training epoch: 59.3467904
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.154 (0.154)	Data 0.294 (0.294)	Loss 0.7076 (0.7076)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.7717 (0.7208)	Acc@1 79.297 (83.576)	Acc@5 99.219 (99.219)
Epoch: [18][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7038 (0.7295)	Acc@1 82.812 (83.527)	Acc@5 98.438 (99.161)
Epoch: [18][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6821 (0.7302)	Acc@1 85.547 (83.515)	Acc@5 99.219 (99.176)
Max memory in training epoch: 59.3467904
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.171 (0.171)	Data 0.305 (0.305)	Loss 0.6806 (0.6806)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.6786 (0.7348)	Acc@1 85.938 (83.444)	Acc@5 99.219 (99.141)
Epoch: [19][128/196]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.7650 (0.7341)	Acc@1 78.906 (83.324)	Acc@5 99.219 (99.149)
Epoch: [19][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6781 (0.7316)	Acc@1 84.766 (83.412)	Acc@5 99.609 (99.166)
Max memory in training epoch: 59.3467904
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.191 (0.191)	Data 0.277 (0.277)	Loss 0.5889 (0.5889)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6722 (0.7212)	Acc@1 84.766 (83.744)	Acc@5 99.609 (99.267)
Epoch: [20][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.6729 (0.7275)	Acc@1 84.375 (83.603)	Acc@5 100.000 (99.222)
Epoch: [20][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7225 (0.7276)	Acc@1 84.375 (83.511)	Acc@5 98.438 (99.251)
Max memory in training epoch: 59.3467904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 244380 ; 248716 ; 0.9825664613454703
[INFO] Storing checkpoint...
  61.33
Max memory: 92.4395008
 25.771s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7938
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1059328
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.209 (0.209)	Data 0.253 (0.253)	Loss 0.7820 (0.7820)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [21][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.8569 (0.6999)	Acc@1 76.953 (84.519)	Acc@5 98.828 (99.249)
Epoch: [21][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7065 (0.7093)	Acc@1 85.156 (84.145)	Acc@5 99.609 (99.240)
Epoch: [21][192/196]	Time 0.127 (0.126)	Data 0.000 (0.001)	Loss 0.6582 (0.7178)	Acc@1 84.766 (83.881)	Acc@5 99.609 (99.247)
Max memory in training epoch: 58.5533952
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.156 (0.156)	Data 0.257 (0.257)	Loss 0.6853 (0.6853)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.7199 (0.7157)	Acc@1 83.203 (83.918)	Acc@5 98.828 (99.231)
Epoch: [22][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7713 (0.7191)	Acc@1 80.469 (83.727)	Acc@5 98.438 (99.225)
Epoch: [22][192/196]	Time 0.121 (0.127)	Data 0.000 (0.001)	Loss 0.5925 (0.7162)	Acc@1 90.234 (83.865)	Acc@5 99.219 (99.233)
Max memory in training epoch: 58.2388224
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.172 (0.172)	Data 0.273 (0.273)	Loss 0.6702 (0.6702)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.6830 (0.7090)	Acc@1 87.109 (84.411)	Acc@5 98.828 (99.309)
Epoch: [23][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7160 (0.7150)	Acc@1 86.328 (84.030)	Acc@5 98.047 (99.337)
Epoch: [23][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.6763 (0.7199)	Acc@1 86.328 (83.926)	Acc@5 99.219 (99.312)
Max memory in training epoch: 58.2388224
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.185 (0.185)	Data 0.264 (0.264)	Loss 0.7290 (0.7290)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [24][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.7545 (0.7052)	Acc@1 82.812 (84.291)	Acc@5 97.656 (99.201)
Epoch: [24][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6185 (0.7071)	Acc@1 89.062 (84.248)	Acc@5 98.438 (99.258)
Epoch: [24][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7003 (0.7101)	Acc@1 83.984 (84.084)	Acc@5 99.609 (99.294)
Max memory in training epoch: 58.2388224
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.164 (0.164)	Data 0.279 (0.279)	Loss 0.7673 (0.7673)	Acc@1 83.203 (83.203)	Acc@5 97.656 (97.656)
Epoch: [25][64/196]	Time 0.122 (0.125)	Data 0.000 (0.004)	Loss 0.6043 (0.7110)	Acc@1 88.281 (84.507)	Acc@5 100.000 (99.231)
Epoch: [25][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6318 (0.7077)	Acc@1 86.719 (84.336)	Acc@5 99.609 (99.270)
Epoch: [25][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.7554 (0.7109)	Acc@1 84.766 (84.225)	Acc@5 99.609 (99.298)
Max memory in training epoch: 58.2388224
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 240622 ; 244380 ; 0.9846223095179638
[INFO] Storing checkpoint...
  72.15
Max memory: 91.0023168
 24.922s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8091
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1046016
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.182 (0.182)	Data 0.250 (0.250)	Loss 0.7037 (0.7037)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [26][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.7908 (0.6957)	Acc@1 80.078 (84.339)	Acc@5 99.219 (99.357)
Epoch: [26][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.6745 (0.7009)	Acc@1 85.938 (84.402)	Acc@5 99.609 (99.316)
Epoch: [26][192/196]	Time 0.120 (0.126)	Data 0.000 (0.001)	Loss 0.6761 (0.7043)	Acc@1 85.938 (84.424)	Acc@5 99.609 (99.271)
Max memory in training epoch: 57.7005056
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.146 (0.146)	Data 0.259 (0.259)	Loss 0.7306 (0.7306)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [27][64/196]	Time 0.116 (0.127)	Data 0.000 (0.004)	Loss 0.6779 (0.6926)	Acc@1 86.328 (84.880)	Acc@5 99.609 (99.267)
Epoch: [27][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6514 (0.7021)	Acc@1 85.156 (84.575)	Acc@5 99.219 (99.258)
Epoch: [27][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.6433 (0.7062)	Acc@1 87.891 (84.381)	Acc@5 98.828 (99.273)
Max memory in training epoch: 57.7747456
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.186 (0.186)	Data 0.261 (0.261)	Loss 0.7573 (0.7573)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [28][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.6786 (0.6942)	Acc@1 86.328 (84.838)	Acc@5 99.609 (99.249)
Epoch: [28][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6888 (0.6967)	Acc@1 82.812 (84.532)	Acc@5 99.609 (99.297)
Epoch: [28][192/196]	Time 0.130 (0.126)	Data 0.000 (0.002)	Loss 0.6100 (0.6970)	Acc@1 87.891 (84.541)	Acc@5 98.828 (99.286)
Max memory in training epoch: 57.7747456
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.180 (0.180)	Data 0.255 (0.255)	Loss 0.6889 (0.6889)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.7855 (0.6879)	Acc@1 81.641 (85.144)	Acc@5 99.219 (99.363)
Epoch: [29][128/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.7731 (0.6941)	Acc@1 83.203 (84.932)	Acc@5 98.438 (99.367)
Epoch: [29][192/196]	Time 0.121 (0.126)	Data 0.000 (0.001)	Loss 0.8449 (0.6990)	Acc@1 80.859 (84.727)	Acc@5 98.438 (99.330)
Max memory in training epoch: 57.7747456
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.157 (0.157)	Data 0.290 (0.290)	Loss 0.7387 (0.7387)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [30][64/196]	Time 0.141 (0.130)	Data 0.000 (0.005)	Loss 0.6443 (0.7023)	Acc@1 86.328 (84.615)	Acc@5 98.828 (99.291)
Epoch: [30][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7684 (0.6963)	Acc@1 82.422 (84.853)	Acc@5 98.047 (99.307)
Epoch: [30][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7923 (0.6945)	Acc@1 82.422 (84.832)	Acc@5 99.609 (99.320)
Max memory in training epoch: 57.7747456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 239112 ; 240622 ; 0.9937245970858858
[INFO] Storing checkpoint...
  76.61
Max memory: 89.4590464
 25.528s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6236
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1034752
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.196 (0.196)	Data 0.249 (0.249)	Loss 0.6021 (0.6021)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [31][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.6893 (0.6947)	Acc@1 85.547 (84.784)	Acc@5 98.828 (99.381)
Epoch: [31][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.6645 (0.6946)	Acc@1 85.547 (84.775)	Acc@5 99.219 (99.367)
Epoch: [31][192/196]	Time 0.128 (0.120)	Data 0.000 (0.001)	Loss 0.6734 (0.6938)	Acc@1 85.156 (84.760)	Acc@5 99.219 (99.338)
Max memory in training epoch: 55.7526528
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.172 (0.172)	Data 0.282 (0.282)	Loss 0.7147 (0.7147)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.126 (0.120)	Data 0.000 (0.005)	Loss 0.6944 (0.7009)	Acc@1 84.766 (84.663)	Acc@5 100.000 (99.333)
Epoch: [32][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.6409 (0.6993)	Acc@1 84.766 (84.614)	Acc@5 100.000 (99.361)
Epoch: [32][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6845 (0.6963)	Acc@1 84.375 (84.703)	Acc@5 99.219 (99.350)
Max memory in training epoch: 55.6084736
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.166 (0.166)	Data 0.282 (0.282)	Loss 0.7106 (0.7106)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [33][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.6650 (0.7069)	Acc@1 87.500 (84.495)	Acc@5 99.609 (99.303)
Epoch: [33][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6823 (0.7025)	Acc@1 84.375 (84.593)	Acc@5 98.828 (99.258)
Epoch: [33][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.7108 (0.7036)	Acc@1 85.547 (84.452)	Acc@5 98.828 (99.277)
Max memory in training epoch: 55.6084736
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.138 (0.138)	Data 0.282 (0.282)	Loss 0.6192 (0.6192)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.6887 (0.6984)	Acc@1 83.984 (84.952)	Acc@5 99.219 (99.231)
Epoch: [34][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.7174 (0.6938)	Acc@1 80.859 (84.917)	Acc@5 99.609 (99.264)
Epoch: [34][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6512 (0.6946)	Acc@1 85.156 (84.841)	Acc@5 99.609 (99.277)
Max memory in training epoch: 55.6084736
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.146 (0.146)	Data 0.282 (0.282)	Loss 0.6007 (0.6007)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [35][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.7209 (0.6836)	Acc@1 83.984 (85.252)	Acc@5 98.438 (99.243)
Epoch: [35][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.7248 (0.6826)	Acc@1 82.812 (85.162)	Acc@5 100.000 (99.285)
Epoch: [35][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.5245 (0.6824)	Acc@1 91.016 (85.140)	Acc@5 100.000 (99.263)
Max memory in training epoch: 55.6084736
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 236508 ; 239112 ; 0.989109705911874
[INFO] Storing checkpoint...
  77.9
Max memory: 86.5956352
 24.338s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3957
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1024512
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.182 (0.182)	Data 0.262 (0.262)	Loss 0.6620 (0.6620)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.6451 (0.6459)	Acc@1 85.156 (86.166)	Acc@5 99.219 (99.519)
Epoch: [36][128/196]	Time 0.126 (0.119)	Data 0.000 (0.002)	Loss 0.6355 (0.6713)	Acc@1 87.109 (85.535)	Acc@5 100.000 (99.403)
Epoch: [36][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.7305 (0.6773)	Acc@1 82.031 (85.126)	Acc@5 99.609 (99.364)
Max memory in training epoch: 54.9555712
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.180 (0.180)	Data 0.266 (0.266)	Loss 0.6588 (0.6588)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.7315 (0.6807)	Acc@1 83.984 (85.000)	Acc@5 98.828 (99.339)
Epoch: [37][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.7479 (0.6874)	Acc@1 82.812 (84.875)	Acc@5 99.219 (99.325)
Epoch: [37][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6957 (0.6835)	Acc@1 83.984 (85.120)	Acc@5 99.609 (99.346)
Max memory in training epoch: 54.8310528
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.159 (0.159)	Data 0.265 (0.265)	Loss 0.6115 (0.6115)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [38][64/196]	Time 0.134 (0.121)	Data 0.000 (0.004)	Loss 0.6538 (0.6779)	Acc@1 86.328 (85.409)	Acc@5 98.828 (99.417)
Epoch: [38][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.7263 (0.6812)	Acc@1 83.984 (85.268)	Acc@5 99.219 (99.385)
Epoch: [38][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.6866 (0.6832)	Acc@1 86.328 (85.152)	Acc@5 100.000 (99.401)
Max memory in training epoch: 54.8310528
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.185 (0.185)	Data 0.290 (0.290)	Loss 0.7134 (0.7134)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [39][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.6708 (0.6709)	Acc@1 86.719 (85.649)	Acc@5 99.609 (99.435)
Epoch: [39][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.8027 (0.6770)	Acc@1 81.641 (85.323)	Acc@5 99.609 (99.400)
Epoch: [39][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6589 (0.6872)	Acc@1 86.719 (84.936)	Acc@5 100.000 (99.381)
Max memory in training epoch: 54.8310528
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.154 (0.154)	Data 0.294 (0.294)	Loss 0.6883 (0.6883)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [40][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.6725 (0.6769)	Acc@1 83.984 (85.084)	Acc@5 99.609 (99.411)
Epoch: [40][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.5781 (0.6854)	Acc@1 89.062 (84.893)	Acc@5 99.219 (99.373)
Epoch: [40][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.6187 (0.6801)	Acc@1 87.891 (85.243)	Acc@5 98.438 (99.350)
Max memory in training epoch: 54.8310528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 235062 ; 236508 ; 0.9938860419097874
[INFO] Storing checkpoint...
  73.88
Max memory: 85.7242112
 23.893s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9296
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1018368
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.190 (0.190)	Data 0.261 (0.261)	Loss 0.6784 (0.6784)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [41][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.5964 (0.6431)	Acc@1 89.844 (86.412)	Acc@5 99.609 (99.423)
Epoch: [41][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.7522 (0.6613)	Acc@1 82.812 (85.719)	Acc@5 99.609 (99.370)
Epoch: [41][192/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.6580 (0.6719)	Acc@1 83.594 (85.466)	Acc@5 100.000 (99.334)
Max memory in training epoch: 54.848256
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.169 (0.169)	Data 0.256 (0.256)	Loss 0.7312 (0.7312)	Acc@1 86.328 (86.328)	Acc@5 98.438 (98.438)
Epoch: [42][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.6586 (0.6629)	Acc@1 85.547 (85.889)	Acc@5 100.000 (99.477)
Epoch: [42][128/196]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.6617 (0.6762)	Acc@1 84.766 (85.353)	Acc@5 100.000 (99.394)
Epoch: [42][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6221 (0.6779)	Acc@1 89.062 (85.415)	Acc@5 99.609 (99.362)
Max memory in training epoch: 54.815488
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.148 (0.148)	Data 0.287 (0.287)	Loss 0.6931 (0.6931)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [43][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6450 (0.6667)	Acc@1 86.328 (85.625)	Acc@5 99.609 (99.369)
Epoch: [43][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6825 (0.6736)	Acc@1 83.594 (85.383)	Acc@5 99.609 (99.304)
Epoch: [43][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.6854 (0.6743)	Acc@1 87.109 (85.322)	Acc@5 99.219 (99.326)
Max memory in training epoch: 54.6975232
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.173 (0.173)	Data 0.294 (0.294)	Loss 0.6733 (0.6733)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [44][64/196]	Time 0.112 (0.121)	Data 0.000 (0.005)	Loss 0.6095 (0.6692)	Acc@1 86.719 (85.685)	Acc@5 100.000 (99.447)
Epoch: [44][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.6499 (0.6764)	Acc@1 87.891 (85.483)	Acc@5 98.828 (99.428)
Epoch: [44][192/196]	Time 0.134 (0.121)	Data 0.000 (0.002)	Loss 0.7496 (0.6723)	Acc@1 82.812 (85.517)	Acc@5 98.047 (99.431)
Max memory in training epoch: 54.6975232
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.166 (0.166)	Data 0.284 (0.284)	Loss 0.6531 (0.6531)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.6984 (0.6758)	Acc@1 82.422 (85.319)	Acc@5 99.219 (99.369)
Epoch: [45][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.7462 (0.6747)	Acc@1 80.859 (85.347)	Acc@5 98.828 (99.331)
Epoch: [45][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.7672 (0.6778)	Acc@1 80.859 (85.318)	Acc@5 99.609 (99.322)
Max memory in training epoch: 54.6975232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 232890 ; 235062 ; 0.9907598846261837
[INFO] Storing checkpoint...
  78.89
Max memory: 85.0686464
 23.794s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3643
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.100864
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.201 (0.201)	Data 0.252 (0.252)	Loss 0.7529 (0.7529)	Acc@1 83.594 (83.594)	Acc@5 98.047 (98.047)
Epoch: [46][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.7180 (0.6460)	Acc@1 84.766 (86.034)	Acc@5 99.219 (99.507)
Epoch: [46][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6670 (0.6645)	Acc@1 86.328 (85.647)	Acc@5 98.828 (99.425)
Epoch: [46][192/196]	Time 0.117 (0.121)	Data 0.000 (0.001)	Loss 0.6090 (0.6682)	Acc@1 89.453 (85.537)	Acc@5 98.828 (99.389)
Max memory in training epoch: 53.7957888
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.177 (0.177)	Data 0.260 (0.260)	Loss 0.6635 (0.6635)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.131 (0.122)	Data 0.000 (0.004)	Loss 0.6806 (0.6627)	Acc@1 85.938 (85.847)	Acc@5 98.438 (99.453)
Epoch: [47][128/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.8063 (0.6746)	Acc@1 78.516 (85.417)	Acc@5 99.219 (99.343)
Epoch: [47][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6908 (0.6757)	Acc@1 85.938 (85.492)	Acc@5 98.828 (99.369)
Max memory in training epoch: 53.8154496
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.167 (0.167)	Data 0.287 (0.287)	Loss 0.6000 (0.6000)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.7221 (0.6697)	Acc@1 84.375 (85.565)	Acc@5 98.828 (99.303)
Epoch: [48][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.6589 (0.6654)	Acc@1 86.328 (85.765)	Acc@5 100.000 (99.379)
Epoch: [48][192/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.7424 (0.6679)	Acc@1 80.469 (85.691)	Acc@5 99.609 (99.403)
Max memory in training epoch: 53.8154496
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.175 (0.175)	Data 0.261 (0.261)	Loss 0.6430 (0.6430)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [49][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.6290 (0.6625)	Acc@1 86.719 (85.709)	Acc@5 100.000 (99.411)
Epoch: [49][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.6832 (0.6602)	Acc@1 84.375 (85.844)	Acc@5 99.609 (99.446)
Epoch: [49][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6013 (0.6597)	Acc@1 87.500 (85.859)	Acc@5 100.000 (99.401)
Max memory in training epoch: 53.8154496
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.163 (0.163)	Data 0.291 (0.291)	Loss 0.7349 (0.7349)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.7115 (0.6779)	Acc@1 82.812 (84.904)	Acc@5 98.828 (99.423)
Epoch: [50][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6477 (0.6796)	Acc@1 85.547 (85.087)	Acc@5 99.219 (99.376)
Epoch: [50][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.6665 (0.6800)	Acc@1 86.328 (85.112)	Acc@5 99.609 (99.362)
Max memory in training epoch: 53.8154496
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 232456 ; 232890 ; 0.998136459272618
[INFO] Storing checkpoint...
  80.02
Max memory: 83.7320704
 24.168s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4799
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.100608
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.162 (0.162)	Data 0.279 (0.279)	Loss 0.6727 (0.6727)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [51][64/196]	Time 0.121 (0.118)	Data 0.000 (0.004)	Loss 0.6254 (0.6425)	Acc@1 88.281 (86.466)	Acc@5 99.219 (99.507)
Epoch: [51][128/196]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.7179 (0.6550)	Acc@1 83.203 (86.050)	Acc@5 99.609 (99.428)
Epoch: [51][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.7207 (0.6627)	Acc@1 85.547 (85.790)	Acc@5 99.609 (99.419)
Max memory in training epoch: 53.7882112
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.144 (0.144)	Data 0.261 (0.261)	Loss 0.5405 (0.5405)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.119 (0.119)	Data 0.000 (0.004)	Loss 0.6902 (0.6615)	Acc@1 83.594 (85.931)	Acc@5 100.000 (99.483)
Epoch: [52][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.6816 (0.6671)	Acc@1 84.375 (85.732)	Acc@5 98.828 (99.434)
Epoch: [52][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.5894 (0.6677)	Acc@1 88.281 (85.648)	Acc@5 99.219 (99.429)
Max memory in training epoch: 53.8275328
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.164 (0.164)	Data 0.287 (0.287)	Loss 0.5980 (0.5980)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [53][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.6927 (0.6722)	Acc@1 83.594 (85.517)	Acc@5 100.000 (99.465)
Epoch: [53][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.8216 (0.6725)	Acc@1 81.641 (85.420)	Acc@5 99.609 (99.488)
Epoch: [53][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6690 (0.6730)	Acc@1 87.891 (85.436)	Acc@5 99.609 (99.470)
Max memory in training epoch: 53.8275328
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.169 (0.169)	Data 0.277 (0.277)	Loss 0.6550 (0.6550)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [54][64/196]	Time 0.113 (0.120)	Data 0.000 (0.004)	Loss 0.7244 (0.6615)	Acc@1 84.375 (85.775)	Acc@5 100.000 (99.357)
Epoch: [54][128/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.6568 (0.6608)	Acc@1 85.938 (85.931)	Acc@5 99.219 (99.388)
Epoch: [54][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.8439 (0.6687)	Acc@1 81.641 (85.658)	Acc@5 99.219 (99.393)
Max memory in training epoch: 53.8275328
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.176 (0.176)	Data 0.288 (0.288)	Loss 0.7193 (0.7193)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.130 (0.123)	Data 0.000 (0.005)	Loss 0.6368 (0.6571)	Acc@1 87.891 (85.817)	Acc@5 99.219 (99.483)
Epoch: [55][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6413 (0.6599)	Acc@1 86.328 (85.744)	Acc@5 99.609 (99.479)
Epoch: [55][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6153 (0.6604)	Acc@1 88.672 (85.790)	Acc@5 99.609 (99.447)
Max memory in training epoch: 53.8275328
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 231298 ; 232456 ; 0.9950184120865885
[INFO] Storing checkpoint...
  73.1
Max memory: 83.565824
 24.083s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4406
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1001984
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.200 (0.200)	Data 0.260 (0.260)	Loss 0.6958 (0.6958)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.119 (0.119)	Data 0.000 (0.004)	Loss 0.5981 (0.6314)	Acc@1 88.672 (86.923)	Acc@5 100.000 (99.555)
Epoch: [56][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.6692 (0.6419)	Acc@1 85.547 (86.528)	Acc@5 100.000 (99.488)
Epoch: [56][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.6725 (0.6579)	Acc@1 82.812 (85.974)	Acc@5 100.000 (99.423)
Max memory in training epoch: 53.5113216
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.160 (0.160)	Data 0.263 (0.263)	Loss 0.6335 (0.6335)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.121 (0.120)	Data 0.000 (0.004)	Loss 0.6729 (0.6623)	Acc@1 85.156 (85.853)	Acc@5 99.609 (99.387)
Epoch: [57][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6465 (0.6546)	Acc@1 83.984 (86.168)	Acc@5 98.828 (99.403)
Epoch: [57][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.6724 (0.6618)	Acc@1 85.156 (85.842)	Acc@5 98.828 (99.389)
Max memory in training epoch: 53.5637504
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.145 (0.145)	Data 0.254 (0.254)	Loss 0.6092 (0.6092)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [58][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.6878 (0.6568)	Acc@1 85.547 (85.811)	Acc@5 99.219 (99.441)
Epoch: [58][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6144 (0.6594)	Acc@1 87.891 (85.850)	Acc@5 98.828 (99.452)
Epoch: [58][192/196]	Time 0.120 (0.119)	Data 0.000 (0.001)	Loss 0.5805 (0.6598)	Acc@1 89.062 (85.889)	Acc@5 98.828 (99.425)
Max memory in training epoch: 53.5637504
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.136 (0.136)	Data 0.284 (0.284)	Loss 0.6869 (0.6869)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [59][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.6759 (0.6591)	Acc@1 85.156 (85.799)	Acc@5 99.219 (99.411)
Epoch: [59][128/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.6874 (0.6638)	Acc@1 83.984 (85.723)	Acc@5 99.219 (99.391)
Epoch: [59][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.7273 (0.6693)	Acc@1 83.984 (85.587)	Acc@5 98.828 (99.352)
Max memory in training epoch: 53.5637504
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.173 (0.173)	Data 0.271 (0.271)	Loss 0.7018 (0.7018)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [60][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.6254 (0.6428)	Acc@1 87.500 (86.286)	Acc@5 99.219 (99.393)
Epoch: [60][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.6358 (0.6537)	Acc@1 87.500 (86.037)	Acc@5 99.609 (99.428)
Epoch: [60][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.6853 (0.6576)	Acc@1 83.984 (85.846)	Acc@5 99.219 (99.411)
Max memory in training epoch: 53.5637504
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  75.69
Max memory: 82.5913856
 23.913s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6780
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1001984
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.174 (0.174)	Data 0.272 (0.272)	Loss 0.6245 (0.6245)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.5418 (0.6399)	Acc@1 91.016 (86.514)	Acc@5 99.609 (99.387)
Epoch: [61][128/196]	Time 0.129 (0.121)	Data 0.000 (0.002)	Loss 0.6579 (0.6432)	Acc@1 86.328 (86.452)	Acc@5 100.000 (99.416)
Epoch: [61][192/196]	Time 0.128 (0.120)	Data 0.000 (0.002)	Loss 0.7014 (0.6519)	Acc@1 84.375 (86.097)	Acc@5 99.609 (99.405)
Max memory in training epoch: 53.5113216
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.140 (0.140)	Data 0.292 (0.292)	Loss 0.5746 (0.5746)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.6196 (0.6670)	Acc@1 86.328 (85.625)	Acc@5 100.000 (99.429)
Epoch: [62][128/196]	Time 0.134 (0.119)	Data 0.000 (0.002)	Loss 0.6490 (0.6620)	Acc@1 84.375 (85.807)	Acc@5 98.828 (99.355)
Epoch: [62][192/196]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.7304 (0.6664)	Acc@1 83.203 (85.595)	Acc@5 99.219 (99.366)
Max memory in training epoch: 53.5637504
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.146 (0.146)	Data 0.270 (0.270)	Loss 0.5825 (0.5825)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.6601 (0.6554)	Acc@1 85.156 (85.739)	Acc@5 100.000 (99.441)
Epoch: [63][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.7360 (0.6550)	Acc@1 85.547 (85.801)	Acc@5 98.828 (99.440)
Epoch: [63][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.6201 (0.6566)	Acc@1 89.062 (85.782)	Acc@5 98.828 (99.413)
Max memory in training epoch: 53.5637504
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.165 (0.165)	Data 0.288 (0.288)	Loss 0.6144 (0.6144)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.7134 (0.6683)	Acc@1 80.859 (85.481)	Acc@5 99.609 (99.471)
Epoch: [64][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6459 (0.6651)	Acc@1 87.109 (85.671)	Acc@5 98.438 (99.443)
Epoch: [64][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.7438 (0.6637)	Acc@1 83.984 (85.800)	Acc@5 98.828 (99.421)
Max memory in training epoch: 53.5637504
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.169 (0.169)	Data 0.302 (0.302)	Loss 0.6573 (0.6573)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [65][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.7881 (0.6629)	Acc@1 81.641 (85.739)	Acc@5 98.828 (99.471)
Epoch: [65][128/196]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.6166 (0.6583)	Acc@1 85.547 (85.874)	Acc@5 99.609 (99.491)
Epoch: [65][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.7295 (0.6583)	Acc@1 82.812 (85.788)	Acc@5 99.609 (99.447)
Max memory in training epoch: 53.5637504
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 229996 ; 231298 ; 0.9943708981487086
[INFO] Storing checkpoint...
  72.83
Max memory: 82.5913856
 23.708s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4221
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.0997376
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.188 (0.188)	Data 0.260 (0.260)	Loss 0.6854 (0.6854)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.6739 (0.6221)	Acc@1 85.547 (87.109)	Acc@5 99.609 (99.477)
Epoch: [66][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6607 (0.6363)	Acc@1 85.547 (86.534)	Acc@5 99.609 (99.494)
Epoch: [66][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.5276 (0.6425)	Acc@1 90.234 (86.225)	Acc@5 100.000 (99.468)
Max memory in training epoch: 53.1232256
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.163 (0.163)	Data 0.274 (0.274)	Loss 0.6453 (0.6453)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [67][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.6055 (0.6591)	Acc@1 87.109 (85.925)	Acc@5 100.000 (99.393)
Epoch: [67][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6344 (0.6596)	Acc@1 84.766 (85.892)	Acc@5 99.609 (99.385)
Epoch: [67][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.7139 (0.6594)	Acc@1 86.328 (85.901)	Acc@5 98.828 (99.344)
Max memory in training epoch: 53.352192
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.6074 (0.6074)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.6297 (0.6466)	Acc@1 86.328 (86.358)	Acc@5 98.828 (99.489)
Epoch: [68][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.5961 (0.6539)	Acc@1 86.328 (85.980)	Acc@5 99.609 (99.458)
Epoch: [68][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.5732 (0.6559)	Acc@1 89.844 (85.980)	Acc@5 99.219 (99.449)
Max memory in training epoch: 53.352192
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.147 (0.147)	Data 0.282 (0.282)	Loss 0.6404 (0.6404)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [69][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.5922 (0.6575)	Acc@1 86.719 (85.901)	Acc@5 100.000 (99.387)
Epoch: [69][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.5792 (0.6550)	Acc@1 87.500 (85.986)	Acc@5 99.219 (99.431)
Epoch: [69][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6616 (0.6605)	Acc@1 85.547 (85.895)	Acc@5 99.609 (99.403)
Max memory in training epoch: 53.352192
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.161 (0.161)	Data 0.289 (0.289)	Loss 0.7579 (0.7579)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [70][64/196]	Time 0.135 (0.120)	Data 0.000 (0.005)	Loss 0.6712 (0.6565)	Acc@1 84.766 (86.106)	Acc@5 99.609 (99.417)
Epoch: [70][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.6235 (0.6609)	Acc@1 86.328 (85.780)	Acc@5 100.000 (99.406)
Epoch: [70][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6504 (0.6588)	Acc@1 85.156 (85.887)	Acc@5 100.000 (99.395)
Max memory in training epoch: 53.352192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 228984 ; 229996 ; 0.99559992347693
[INFO] Storing checkpoint...
  79.43
Max memory: 82.7544576
 23.900s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7539
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.099328
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.184 (0.184)	Data 0.290 (0.290)	Loss 0.6815 (0.6815)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.118 (0.124)	Data 0.000 (0.005)	Loss 0.6486 (0.6295)	Acc@1 86.719 (86.562)	Acc@5 98.438 (99.465)
Epoch: [71][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.5370 (0.6521)	Acc@1 89.453 (85.910)	Acc@5 99.609 (99.461)
Epoch: [71][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.6944 (0.6558)	Acc@1 84.766 (85.873)	Acc@5 99.609 (99.415)
Max memory in training epoch: 53.1224064
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.174 (0.174)	Data 0.265 (0.265)	Loss 0.6305 (0.6305)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [72][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.5964 (0.6406)	Acc@1 88.672 (86.623)	Acc@5 99.219 (99.405)
Epoch: [72][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.5700 (0.6458)	Acc@1 89.844 (86.243)	Acc@5 99.609 (99.446)
Epoch: [72][192/196]	Time 0.128 (0.119)	Data 0.000 (0.002)	Loss 0.6772 (0.6509)	Acc@1 85.547 (86.079)	Acc@5 99.219 (99.411)
Max memory in training epoch: 53.3505536
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.169 (0.169)	Data 0.310 (0.310)	Loss 0.6360 (0.6360)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [73][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.6568 (0.6514)	Acc@1 84.766 (86.094)	Acc@5 98.828 (99.345)
Epoch: [73][128/196]	Time 0.138 (0.120)	Data 0.000 (0.003)	Loss 0.6616 (0.6414)	Acc@1 84.375 (86.419)	Acc@5 99.219 (99.413)
Epoch: [73][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.6821 (0.6501)	Acc@1 82.812 (86.091)	Acc@5 99.219 (99.429)
Max memory in training epoch: 53.3505536
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.153 (0.153)	Data 0.271 (0.271)	Loss 0.6211 (0.6211)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [74][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.5398 (0.6478)	Acc@1 91.016 (86.424)	Acc@5 99.609 (99.453)
Epoch: [74][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.7343 (0.6494)	Acc@1 81.641 (86.289)	Acc@5 99.219 (99.440)
Epoch: [74][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.6049 (0.6554)	Acc@1 88.281 (86.057)	Acc@5 99.609 (99.415)
Max memory in training epoch: 53.3505536
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.164 (0.164)	Data 0.298 (0.298)	Loss 0.6034 (0.6034)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.7440 (0.6546)	Acc@1 85.547 (85.962)	Acc@5 99.219 (99.393)
Epoch: [75][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.6601 (0.6550)	Acc@1 83.984 (85.895)	Acc@5 99.219 (99.373)
Epoch: [75][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6435 (0.6591)	Acc@1 84.375 (85.759)	Acc@5 99.219 (99.354)
Max memory in training epoch: 53.3505536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 228404 ; 228984 ; 0.997467071935157
[INFO] Storing checkpoint...
  78.39
Max memory: 82.554368
 23.915s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 477
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.0991232
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.175 (0.175)	Data 0.281 (0.281)	Loss 0.5656 (0.5656)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [76][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.7397 (0.6177)	Acc@1 81.250 (87.218)	Acc@5 99.609 (99.477)
Epoch: [76][128/196]	Time 0.130 (0.122)	Data 0.000 (0.002)	Loss 0.6548 (0.6407)	Acc@1 85.938 (86.343)	Acc@5 100.000 (99.379)
Epoch: [76][192/196]	Time 0.132 (0.122)	Data 0.000 (0.002)	Loss 0.7156 (0.6454)	Acc@1 83.594 (86.257)	Acc@5 99.609 (99.356)
Max memory in training epoch: 52.4584448
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.160 (0.160)	Data 0.297 (0.297)	Loss 0.5819 (0.5819)	Acc@1 90.625 (90.625)	Acc@5 98.828 (98.828)
Epoch: [77][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.6503 (0.6577)	Acc@1 87.500 (85.968)	Acc@5 100.000 (99.381)
Epoch: [77][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6358 (0.6621)	Acc@1 84.766 (85.759)	Acc@5 99.609 (99.319)
Epoch: [77][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6920 (0.6616)	Acc@1 85.156 (85.733)	Acc@5 99.219 (99.354)
Max memory in training epoch: 52.4453376
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.149 (0.149)	Data 0.299 (0.299)	Loss 0.5950 (0.5950)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.5883 (0.6502)	Acc@1 87.891 (86.028)	Acc@5 100.000 (99.441)
Epoch: [78][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6729 (0.6444)	Acc@1 87.109 (86.286)	Acc@5 98.828 (99.488)
Epoch: [78][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6262 (0.6480)	Acc@1 88.281 (86.156)	Acc@5 99.609 (99.486)
Max memory in training epoch: 52.4453376
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.157 (0.157)	Data 0.258 (0.258)	Loss 0.6335 (0.6335)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [79][64/196]	Time 0.129 (0.124)	Data 0.000 (0.004)	Loss 0.6208 (0.6419)	Acc@1 88.281 (86.172)	Acc@5 100.000 (99.585)
Epoch: [79][128/196]	Time 0.131 (0.125)	Data 0.000 (0.002)	Loss 0.6405 (0.6428)	Acc@1 85.938 (86.231)	Acc@5 99.609 (99.482)
Epoch: [79][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6443 (0.6473)	Acc@1 85.547 (86.006)	Acc@5 99.219 (99.478)
Max memory in training epoch: 52.4453376
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.178 (0.178)	Data 0.274 (0.274)	Loss 0.5464 (0.5464)	Acc@1 90.234 (90.234)	Acc@5 99.219 (99.219)
Epoch: [80][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.5584 (0.6432)	Acc@1 89.844 (86.346)	Acc@5 99.219 (99.465)
Epoch: [80][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.6377 (0.6476)	Acc@1 88.672 (86.156)	Acc@5 99.609 (99.443)
Epoch: [80][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.5797 (0.6511)	Acc@1 87.891 (86.077)	Acc@5 99.609 (99.456)
Max memory in training epoch: 52.4453376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  81.22
Max memory: 81.6313344
 23.983s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2764
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.0991232
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.157 (0.157)	Data 0.283 (0.283)	Loss 0.6413 (0.6413)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.5919 (0.6360)	Acc@1 88.281 (86.538)	Acc@5 100.000 (99.501)
Epoch: [81][128/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.6745 (0.6389)	Acc@1 85.156 (86.534)	Acc@5 99.609 (99.449)
Epoch: [81][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6287 (0.6442)	Acc@1 87.109 (86.330)	Acc@5 99.609 (99.407)
Max memory in training epoch: 52.4584448
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.176 (0.176)	Data 0.258 (0.258)	Loss 0.6414 (0.6414)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [82][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.5890 (0.6497)	Acc@1 87.891 (86.214)	Acc@5 99.609 (99.357)
Epoch: [82][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.6733 (0.6557)	Acc@1 86.719 (86.019)	Acc@5 100.000 (99.370)
Epoch: [82][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.6197 (0.6555)	Acc@1 86.719 (86.073)	Acc@5 100.000 (99.405)
Max memory in training epoch: 52.4453376
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.148 (0.148)	Data 0.256 (0.256)	Loss 0.5566 (0.5566)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.6463 (0.6507)	Acc@1 86.328 (86.070)	Acc@5 99.219 (99.315)
Epoch: [83][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6143 (0.6479)	Acc@1 87.500 (86.262)	Acc@5 99.609 (99.379)
Epoch: [83][192/196]	Time 0.121 (0.121)	Data 0.000 (0.001)	Loss 0.6417 (0.6461)	Acc@1 85.156 (86.255)	Acc@5 99.609 (99.413)
Max memory in training epoch: 52.4453376
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.178 (0.178)	Data 0.284 (0.284)	Loss 0.6133 (0.6133)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.6521 (0.6517)	Acc@1 86.719 (85.986)	Acc@5 98.828 (99.399)
Epoch: [84][128/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.6271 (0.6498)	Acc@1 87.109 (86.134)	Acc@5 99.219 (99.434)
Epoch: [84][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6476 (0.6529)	Acc@1 84.766 (85.970)	Acc@5 100.000 (99.429)
Max memory in training epoch: 52.4453376
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.161 (0.161)	Data 0.300 (0.300)	Loss 0.6748 (0.6748)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [85][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.6227 (0.6455)	Acc@1 87.500 (86.196)	Acc@5 98.828 (99.345)
Epoch: [85][128/196]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.7903 (0.6507)	Acc@1 80.469 (86.107)	Acc@5 98.828 (99.385)
Epoch: [85][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.6325 (0.6541)	Acc@1 86.719 (85.879)	Acc@5 100.000 (99.391)
Max memory in training epoch: 52.4453376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 227392 ; 228404 ; 0.9955692544789058
[INFO] Storing checkpoint...
  72.45
Max memory: 81.6313344
 23.923s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5710
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.0987648
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.198 (0.198)	Data 0.265 (0.265)	Loss 0.6384 (0.6384)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [86][64/196]	Time 0.116 (0.120)	Data 0.000 (0.004)	Loss 0.6615 (0.6229)	Acc@1 86.719 (87.242)	Acc@5 99.609 (99.489)
Epoch: [86][128/196]	Time 0.109 (0.119)	Data 0.000 (0.002)	Loss 0.5863 (0.6326)	Acc@1 87.500 (86.716)	Acc@5 99.609 (99.485)
Epoch: [86][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.7221 (0.6375)	Acc@1 84.766 (86.500)	Acc@5 99.219 (99.474)
Max memory in training epoch: 52.4307968
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.178 (0.178)	Data 0.263 (0.263)	Loss 0.6810 (0.6810)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.123 (0.119)	Data 0.000 (0.004)	Loss 0.6556 (0.6511)	Acc@1 87.891 (85.895)	Acc@5 99.219 (99.357)
Epoch: [87][128/196]	Time 0.127 (0.120)	Data 0.000 (0.002)	Loss 0.5995 (0.6461)	Acc@1 87.500 (86.119)	Acc@5 99.609 (99.437)
Epoch: [87][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6430 (0.6494)	Acc@1 83.594 (85.940)	Acc@5 99.609 (99.399)
Max memory in training epoch: 52.2341888
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.151 (0.151)	Data 0.293 (0.293)	Loss 0.6975 (0.6975)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [88][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.6321 (0.6246)	Acc@1 89.062 (86.899)	Acc@5 99.219 (99.495)
Epoch: [88][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.6347 (0.6303)	Acc@1 87.500 (86.816)	Acc@5 99.219 (99.452)
Epoch: [88][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6776 (0.6391)	Acc@1 83.594 (86.446)	Acc@5 99.219 (99.411)
Max memory in training epoch: 52.2341888
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.172 (0.172)	Data 0.301 (0.301)	Loss 0.5690 (0.5690)	Acc@1 89.453 (89.453)	Acc@5 98.828 (98.828)
Epoch: [89][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.5812 (0.6469)	Acc@1 85.938 (86.046)	Acc@5 99.609 (99.423)
Epoch: [89][128/196]	Time 0.122 (0.122)	Data 0.000 (0.003)	Loss 0.6195 (0.6458)	Acc@1 89.844 (86.053)	Acc@5 99.219 (99.388)
Epoch: [89][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6990 (0.6511)	Acc@1 82.422 (85.919)	Acc@5 99.609 (99.373)
Max memory in training epoch: 52.2341888
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.154 (0.154)	Data 0.310 (0.310)	Loss 0.6053 (0.6053)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.135 (0.121)	Data 0.000 (0.005)	Loss 0.6333 (0.6373)	Acc@1 87.500 (86.214)	Acc@5 99.219 (99.471)
Epoch: [90][128/196]	Time 0.116 (0.120)	Data 0.000 (0.003)	Loss 0.5468 (0.6452)	Acc@1 89.844 (86.083)	Acc@5 99.609 (99.388)
Epoch: [90][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.5717 (0.6513)	Acc@1 90.234 (86.000)	Acc@5 99.609 (99.387)
Max memory in training epoch: 52.2341888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 226524 ; 227392 ; 0.9961828032648467
[INFO] Storing checkpoint...
  75.39
Max memory: 81.5647232
 23.851s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9059
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.0983552
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.164 (0.164)	Data 0.289 (0.289)	Loss 0.6348 (0.6348)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.5897 (0.6250)	Acc@1 88.281 (86.767)	Acc@5 100.000 (99.573)
Epoch: [91][128/196]	Time 0.123 (0.118)	Data 0.000 (0.002)	Loss 0.4961 (0.6367)	Acc@1 91.016 (86.564)	Acc@5 100.000 (99.485)
Epoch: [91][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.6688 (0.6353)	Acc@1 85.156 (86.607)	Acc@5 98.828 (99.454)
Max memory in training epoch: 51.9048704
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.150 (0.150)	Data 0.284 (0.284)	Loss 0.6633 (0.6633)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [92][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.5975 (0.6398)	Acc@1 86.719 (86.424)	Acc@5 99.219 (99.429)
Epoch: [92][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6421 (0.6419)	Acc@1 87.891 (86.389)	Acc@5 99.609 (99.410)
Epoch: [92][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.6768 (0.6451)	Acc@1 83.984 (86.233)	Acc@5 99.609 (99.413)
Max memory in training epoch: 51.6099584
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.172 (0.172)	Data 0.257 (0.257)	Loss 0.6304 (0.6304)	Acc@1 88.672 (88.672)	Acc@5 98.438 (98.438)
Epoch: [93][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.4883 (0.5369)	Acc@1 93.359 (90.096)	Acc@5 100.000 (99.603)
Epoch: [93][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.4605 (0.5202)	Acc@1 94.141 (90.749)	Acc@5 100.000 (99.688)
Epoch: [93][192/196]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.4696 (0.5120)	Acc@1 92.969 (90.957)	Acc@5 99.219 (99.705)
Max memory in training epoch: 51.6099584
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.166 (0.166)	Data 0.288 (0.288)	Loss 0.4768 (0.4768)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 0.4501 (0.4689)	Acc@1 90.625 (91.995)	Acc@5 100.000 (99.850)
Epoch: [94][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.4180 (0.4650)	Acc@1 94.141 (92.284)	Acc@5 100.000 (99.815)
Epoch: [94][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.4521 (0.4628)	Acc@1 92.188 (92.327)	Acc@5 100.000 (99.802)
Max memory in training epoch: 51.6099584
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.171 (0.171)	Data 0.296 (0.296)	Loss 0.4165 (0.4165)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.4065 (0.4377)	Acc@1 93.359 (93.269)	Acc@5 100.000 (99.808)
Epoch: [95][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4527 (0.4398)	Acc@1 92.578 (93.054)	Acc@5 100.000 (99.833)
Epoch: [95][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3997 (0.4410)	Acc@1 94.531 (92.946)	Acc@5 100.000 (99.838)
Max memory in training epoch: 51.6099584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 225946 ; 226524 ; 0.9974483939891579
[INFO] Storing checkpoint...
  90.26
Max memory: 80.8622592
 23.554s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6946
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.0981504
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.199 (0.199)	Data 0.271 (0.271)	Loss 0.4145 (0.4145)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.116 (0.118)	Data 0.000 (0.004)	Loss 0.4303 (0.4216)	Acc@1 92.578 (93.570)	Acc@5 100.000 (99.814)
Epoch: [96][128/196]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.3627 (0.4216)	Acc@1 95.312 (93.456)	Acc@5 100.000 (99.833)
Epoch: [96][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.4960 (0.4227)	Acc@1 90.625 (93.394)	Acc@5 100.000 (99.844)
Max memory in training epoch: 51.7729792
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.166 (0.166)	Data 0.299 (0.299)	Loss 0.3794 (0.3794)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.114 (0.119)	Data 0.000 (0.005)	Loss 0.4341 (0.4091)	Acc@1 92.969 (93.702)	Acc@5 100.000 (99.832)
Epoch: [97][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.3978 (0.4126)	Acc@1 92.578 (93.599)	Acc@5 99.609 (99.852)
Epoch: [97][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3960 (0.4126)	Acc@1 93.359 (93.558)	Acc@5 100.000 (99.846)
Max memory in training epoch: 51.6091392
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.179 (0.179)	Data 0.260 (0.260)	Loss 0.3899 (0.3899)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.121 (0.119)	Data 0.000 (0.004)	Loss 0.3463 (0.3992)	Acc@1 96.094 (93.930)	Acc@5 100.000 (99.904)
Epoch: [98][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3480 (0.4008)	Acc@1 95.312 (93.811)	Acc@5 100.000 (99.909)
Epoch: [98][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.4295 (0.4023)	Acc@1 92.578 (93.740)	Acc@5 100.000 (99.909)
Max memory in training epoch: 51.6091392
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.165 (0.165)	Data 0.288 (0.288)	Loss 0.3770 (0.3770)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.3771 (0.3925)	Acc@1 94.141 (94.050)	Acc@5 100.000 (99.880)
Epoch: [99][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.4106 (0.3918)	Acc@1 92.969 (94.147)	Acc@5 100.000 (99.873)
Epoch: [99][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3709 (0.3916)	Acc@1 94.531 (94.050)	Acc@5 99.609 (99.883)
Max memory in training epoch: 51.6091392
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.167 (0.167)	Data 0.276 (0.276)	Loss 0.3745 (0.3745)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.114 (0.120)	Data 0.000 (0.004)	Loss 0.3744 (0.3805)	Acc@1 94.922 (94.159)	Acc@5 99.609 (99.868)
Epoch: [100][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3603 (0.3813)	Acc@1 93.750 (94.192)	Acc@5 99.609 (99.876)
Epoch: [100][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3700 (0.3823)	Acc@1 94.922 (94.153)	Acc@5 100.000 (99.883)
Max memory in training epoch: 51.6091392
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 224214 ; 225946 ; 0.9923344515946289
[INFO] Storing checkpoint...
  90.78
Max memory: 80.7420416
 23.674s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2759
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.097536
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.187 (0.187)	Data 0.260 (0.260)	Loss 0.3831 (0.3831)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.122 (0.119)	Data 0.000 (0.004)	Loss 0.3380 (0.3715)	Acc@1 95.703 (94.489)	Acc@5 100.000 (99.862)
Epoch: [101][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3514 (0.3747)	Acc@1 95.312 (94.495)	Acc@5 100.000 (99.879)
Epoch: [101][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.3411 (0.3741)	Acc@1 95.703 (94.497)	Acc@5 100.000 (99.872)
Max memory in training epoch: 51.7574144
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.160 (0.160)	Data 0.266 (0.266)	Loss 0.3367 (0.3367)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.117 (0.119)	Data 0.000 (0.004)	Loss 0.3298 (0.3623)	Acc@1 96.875 (94.645)	Acc@5 100.000 (99.910)
Epoch: [102][128/196]	Time 0.131 (0.119)	Data 0.000 (0.002)	Loss 0.3429 (0.3630)	Acc@1 94.922 (94.643)	Acc@5 100.000 (99.900)
Epoch: [102][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3540 (0.3639)	Acc@1 96.094 (94.649)	Acc@5 100.000 (99.901)
Max memory in training epoch: 51.4887168
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.170 (0.170)	Data 0.279 (0.279)	Loss 0.3473 (0.3473)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.123 (0.118)	Data 0.000 (0.004)	Loss 0.3413 (0.3551)	Acc@1 94.531 (94.694)	Acc@5 100.000 (99.928)
Epoch: [103][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3635 (0.3568)	Acc@1 93.750 (94.740)	Acc@5 100.000 (99.888)
Epoch: [103][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3642 (0.3598)	Acc@1 94.922 (94.580)	Acc@5 100.000 (99.887)
Max memory in training epoch: 51.4887168
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.180 (0.180)	Data 0.280 (0.280)	Loss 0.2986 (0.2986)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.3166 (0.3470)	Acc@1 95.703 (94.934)	Acc@5 100.000 (99.910)
Epoch: [104][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3795 (0.3485)	Acc@1 92.969 (94.892)	Acc@5 99.609 (99.921)
Epoch: [104][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3919 (0.3534)	Acc@1 92.969 (94.742)	Acc@5 99.609 (99.893)
Max memory in training epoch: 51.4887168
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.176 (0.176)	Data 0.262 (0.262)	Loss 0.3564 (0.3564)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.135 (0.120)	Data 0.000 (0.004)	Loss 0.3382 (0.3419)	Acc@1 94.922 (95.114)	Acc@5 100.000 (99.910)
Epoch: [105][128/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3334 (0.3426)	Acc@1 95.703 (95.067)	Acc@5 100.000 (99.924)
Epoch: [105][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3841 (0.3461)	Acc@1 93.359 (94.944)	Acc@5 100.000 (99.915)
Max memory in training epoch: 51.4887168
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 221182 ; 224214 ; 0.9864772048132587
[INFO] Storing checkpoint...
  90.77
Max memory: 80.2781696
 23.530s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2178
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.096256
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.175 (0.175)	Data 0.285 (0.285)	Loss 0.3194 (0.3194)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.3290 (0.3364)	Acc@1 95.312 (95.174)	Acc@5 100.000 (99.922)
Epoch: [106][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3359 (0.3391)	Acc@1 94.141 (95.094)	Acc@5 100.000 (99.915)
Epoch: [106][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3499 (0.3396)	Acc@1 95.312 (95.076)	Acc@5 100.000 (99.899)
Max memory in training epoch: 51.5819008
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.146 (0.146)	Data 0.311 (0.311)	Loss 0.3196 (0.3196)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [107][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.3210 (0.3357)	Acc@1 96.094 (95.084)	Acc@5 100.000 (99.928)
Epoch: [107][128/196]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.3591 (0.3369)	Acc@1 92.578 (95.052)	Acc@5 100.000 (99.933)
Epoch: [107][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.3217 (0.3374)	Acc@1 95.703 (94.987)	Acc@5 99.609 (99.923)
Max memory in training epoch: 51.4049536
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.179 (0.179)	Data 0.259 (0.259)	Loss 0.3031 (0.3031)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.113 (0.119)	Data 0.000 (0.004)	Loss 0.3675 (0.3271)	Acc@1 93.359 (94.994)	Acc@5 99.609 (99.970)
Epoch: [108][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.3590 (0.3292)	Acc@1 93.750 (95.037)	Acc@5 100.000 (99.949)
Epoch: [108][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3167 (0.3318)	Acc@1 95.703 (94.972)	Acc@5 99.609 (99.935)
Max memory in training epoch: 51.4049536
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.162 (0.162)	Data 0.297 (0.297)	Loss 0.2850 (0.2850)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.3208 (0.3257)	Acc@1 94.531 (95.180)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2974 (0.3233)	Acc@1 96.094 (95.228)	Acc@5 100.000 (99.942)
Epoch: [109][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2680 (0.3249)	Acc@1 97.266 (95.173)	Acc@5 100.000 (99.925)
Max memory in training epoch: 51.4049536
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.160 (0.160)	Data 0.304 (0.304)	Loss 0.3112 (0.3112)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.3434 (0.3169)	Acc@1 94.141 (95.427)	Acc@5 100.000 (99.934)
Epoch: [110][128/196]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.2990 (0.3162)	Acc@1 96.484 (95.437)	Acc@5 100.000 (99.933)
Epoch: [110][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3213 (0.3201)	Acc@1 95.703 (95.248)	Acc@5 100.000 (99.933)
Max memory in training epoch: 51.4049536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 213096 ; 221182 ; 0.9634418714000235
[INFO] Storing checkpoint...
  90.15
Max memory: 80.4676608
 23.802s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2119
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.0930816
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.201 (0.201)	Data 0.255 (0.255)	Loss 0.4188 (0.4188)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [111][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.3346 (0.3327)	Acc@1 96.484 (95.174)	Acc@5 100.000 (99.922)
Epoch: [111][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3478 (0.3287)	Acc@1 93.750 (95.222)	Acc@5 100.000 (99.912)
Epoch: [111][192/196]	Time 0.120 (0.119)	Data 0.000 (0.001)	Loss 0.3410 (0.3277)	Acc@1 93.359 (95.177)	Acc@5 100.000 (99.917)
Max memory in training epoch: 51.0121472
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.154 (0.154)	Data 0.318 (0.318)	Loss 0.2943 (0.2943)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.3172 (0.3092)	Acc@1 95.312 (95.637)	Acc@5 100.000 (99.952)
Epoch: [112][128/196]	Time 0.118 (0.119)	Data 0.000 (0.003)	Loss 0.3036 (0.3126)	Acc@1 96.094 (95.412)	Acc@5 100.000 (99.930)
Epoch: [112][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3645 (0.3174)	Acc@1 93.359 (95.207)	Acc@5 100.000 (99.925)
Max memory in training epoch: 50.8286464
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.165 (0.165)	Data 0.290 (0.290)	Loss 0.2961 (0.2961)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.119 (0.118)	Data 0.000 (0.005)	Loss 0.2903 (0.3083)	Acc@1 96.875 (95.559)	Acc@5 100.000 (99.934)
Epoch: [113][128/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3046 (0.3113)	Acc@1 95.703 (95.361)	Acc@5 100.000 (99.912)
Epoch: [113][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.3605 (0.3126)	Acc@1 94.141 (95.258)	Acc@5 99.609 (99.911)
Max memory in training epoch: 50.8286464
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.149 (0.149)	Data 0.270 (0.270)	Loss 0.3028 (0.3028)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [114][64/196]	Time 0.116 (0.121)	Data 0.000 (0.004)	Loss 0.3103 (0.3121)	Acc@1 94.922 (95.210)	Acc@5 99.609 (99.910)
Epoch: [114][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2831 (0.3116)	Acc@1 96.875 (95.279)	Acc@5 99.609 (99.921)
Epoch: [114][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3003 (0.3129)	Acc@1 95.703 (95.227)	Acc@5 100.000 (99.919)
Max memory in training epoch: 50.8286464
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.148 (0.148)	Data 0.288 (0.288)	Loss 0.2878 (0.2878)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.3127 (0.2998)	Acc@1 94.922 (95.613)	Acc@5 100.000 (99.952)
Epoch: [115][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.3323 (0.3036)	Acc@1 93.359 (95.491)	Acc@5 100.000 (99.942)
Epoch: [115][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3064 (0.3071)	Acc@1 95.703 (95.371)	Acc@5 99.609 (99.937)
Max memory in training epoch: 50.8286464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv28.weight

 RM:  module.conv29.weight

 RM:  module.conv30.weight

 RM:  module.conv31.weight
numoFStages: 3
Count: 201053 ; 213096 ; 0.9434855651912752
[INFO] Storing checkpoint...
  90.37
Max memory: 79.1728128
 23.785s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8622
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.087296
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.153 (0.153)	Data 0.280 (0.280)	Loss 0.4258 (0.4258)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [116][64/196]	Time 0.109 (0.108)	Data 0.000 (0.004)	Loss 0.3113 (0.3380)	Acc@1 96.094 (94.832)	Acc@5 100.000 (99.898)
Epoch: [116][128/196]	Time 0.125 (0.107)	Data 0.000 (0.002)	Loss 0.3064 (0.3272)	Acc@1 95.312 (95.104)	Acc@5 100.000 (99.912)
Epoch: [116][192/196]	Time 0.110 (0.108)	Data 0.000 (0.002)	Loss 0.2669 (0.3227)	Acc@1 98.047 (95.136)	Acc@5 100.000 (99.927)
Max memory in training epoch: 48.6446592
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.125 (0.125)	Data 0.288 (0.288)	Loss 0.2571 (0.2571)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.104 (0.109)	Data 0.000 (0.005)	Loss 0.2953 (0.3035)	Acc@1 95.703 (95.547)	Acc@5 100.000 (99.946)
Epoch: [117][128/196]	Time 0.104 (0.109)	Data 0.000 (0.002)	Loss 0.2825 (0.3049)	Acc@1 97.266 (95.524)	Acc@5 100.000 (99.921)
Epoch: [117][192/196]	Time 0.110 (0.109)	Data 0.000 (0.002)	Loss 0.3484 (0.3053)	Acc@1 94.141 (95.450)	Acc@5 100.000 (99.925)
Max memory in training epoch: 48.6118912
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.141 (0.141)	Data 0.294 (0.294)	Loss 0.3194 (0.3194)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [118][64/196]	Time 0.105 (0.109)	Data 0.000 (0.005)	Loss 0.2472 (0.2932)	Acc@1 96.875 (95.745)	Acc@5 100.000 (99.940)
Epoch: [118][128/196]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.2946 (0.2996)	Acc@1 96.094 (95.415)	Acc@5 100.000 (99.933)
Epoch: [118][192/196]	Time 0.107 (0.109)	Data 0.000 (0.002)	Loss 0.2831 (0.3033)	Acc@1 97.656 (95.244)	Acc@5 100.000 (99.933)
Max memory in training epoch: 48.5135872
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.164 (0.164)	Data 0.279 (0.279)	Loss 0.2743 (0.2743)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.109 (0.109)	Data 0.000 (0.004)	Loss 0.3484 (0.2889)	Acc@1 94.141 (95.913)	Acc@5 99.609 (99.946)
Epoch: [119][128/196]	Time 0.105 (0.108)	Data 0.000 (0.002)	Loss 0.3133 (0.2965)	Acc@1 94.531 (95.470)	Acc@5 99.609 (99.942)
Epoch: [119][192/196]	Time 0.104 (0.108)	Data 0.000 (0.002)	Loss 0.3208 (0.2961)	Acc@1 94.141 (95.462)	Acc@5 100.000 (99.935)
Max memory in training epoch: 48.5135872
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.154 (0.154)	Data 0.339 (0.339)	Loss 0.3188 (0.3188)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.104 (0.109)	Data 0.000 (0.005)	Loss 0.2437 (0.2938)	Acc@1 97.656 (95.325)	Acc@5 100.000 (99.940)
Epoch: [120][128/196]	Time 0.105 (0.109)	Data 0.000 (0.003)	Loss 0.3102 (0.2967)	Acc@1 95.703 (95.203)	Acc@5 100.000 (99.942)
Epoch: [120][192/196]	Time 0.107 (0.109)	Data 0.000 (0.002)	Loss 0.3109 (0.3005)	Acc@1 94.531 (95.045)	Acc@5 100.000 (99.923)
Max memory in training epoch: 48.5135872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 191593 ; 201053 ; 0.9529477302004944
[INFO] Storing checkpoint...
  89.68
Max memory: 75.369216
 21.725s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7282
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0836096
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.177 (0.177)	Data 0.256 (0.256)	Loss 0.3730 (0.3730)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.104 (0.109)	Data 0.000 (0.004)	Loss 0.2750 (0.3003)	Acc@1 96.875 (94.868)	Acc@5 100.000 (99.928)
Epoch: [121][128/196]	Time 0.103 (0.108)	Data 0.000 (0.002)	Loss 0.2857 (0.3073)	Acc@1 94.922 (94.668)	Acc@5 100.000 (99.912)
Epoch: [121][192/196]	Time 0.109 (0.108)	Data 0.000 (0.001)	Loss 0.2956 (0.3101)	Acc@1 95.312 (94.529)	Acc@5 100.000 (99.915)
Max memory in training epoch: 47.8631424
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.153 (0.153)	Data 0.275 (0.275)	Loss 0.2907 (0.2907)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.110 (0.108)	Data 0.000 (0.004)	Loss 0.3095 (0.2971)	Acc@1 94.531 (95.144)	Acc@5 100.000 (99.922)
Epoch: [122][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.2970 (0.3003)	Acc@1 94.922 (95.007)	Acc@5 100.000 (99.921)
Epoch: [122][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.3269 (0.3048)	Acc@1 92.969 (94.768)	Acc@5 100.000 (99.923)
Max memory in training epoch: 48.0400896
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.166 (0.166)	Data 0.259 (0.259)	Loss 0.3036 (0.3036)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.107 (0.109)	Data 0.000 (0.004)	Loss 0.2476 (0.2933)	Acc@1 96.875 (95.096)	Acc@5 100.000 (99.976)
Epoch: [123][128/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.2533 (0.2970)	Acc@1 96.875 (94.943)	Acc@5 99.609 (99.949)
Epoch: [123][192/196]	Time 0.119 (0.107)	Data 0.000 (0.002)	Loss 0.3149 (0.3011)	Acc@1 94.141 (94.760)	Acc@5 100.000 (99.947)
Max memory in training epoch: 48.0400896
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.153 (0.153)	Data 0.261 (0.261)	Loss 0.2524 (0.2524)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.099 (0.108)	Data 0.000 (0.004)	Loss 0.2882 (0.3004)	Acc@1 94.922 (94.597)	Acc@5 100.000 (99.958)
Epoch: [124][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2847 (0.2990)	Acc@1 96.875 (94.707)	Acc@5 100.000 (99.952)
Epoch: [124][192/196]	Time 0.105 (0.107)	Data 0.000 (0.002)	Loss 0.3226 (0.3034)	Acc@1 94.141 (94.549)	Acc@5 99.609 (99.937)
Max memory in training epoch: 48.0400896
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.151 (0.151)	Data 0.293 (0.293)	Loss 0.3050 (0.3050)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.107 (0.110)	Data 0.000 (0.005)	Loss 0.3310 (0.2990)	Acc@1 94.141 (94.910)	Acc@5 100.000 (99.952)
Epoch: [125][128/196]	Time 0.118 (0.110)	Data 0.000 (0.002)	Loss 0.2896 (0.3005)	Acc@1 95.703 (94.783)	Acc@5 100.000 (99.958)
Epoch: [125][192/196]	Time 0.113 (0.109)	Data 0.000 (0.002)	Loss 0.2690 (0.3050)	Acc@1 94.922 (94.576)	Acc@5 100.000 (99.953)
Max memory in training epoch: 48.0400896
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 179938 ; 191593 ; 0.9391679236715329
[INFO] Storing checkpoint...
  87.85
Max memory: 75.2662016
 21.772s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7450
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0790528
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.171 (0.171)	Data 0.272 (0.272)	Loss 0.3250 (0.3250)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.107 (0.109)	Data 0.000 (0.004)	Loss 0.3582 (0.3139)	Acc@1 93.750 (94.249)	Acc@5 100.000 (99.946)
Epoch: [126][128/196]	Time 0.114 (0.108)	Data 0.000 (0.002)	Loss 0.3743 (0.3166)	Acc@1 91.797 (94.041)	Acc@5 100.000 (99.936)
Epoch: [126][192/196]	Time 0.119 (0.108)	Data 0.000 (0.002)	Loss 0.3115 (0.3192)	Acc@1 94.531 (93.924)	Acc@5 100.000 (99.929)
Max memory in training epoch: 47.0793728
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.131 (0.131)	Data 0.293 (0.293)	Loss 0.2853 (0.2853)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [127][64/196]	Time 0.106 (0.108)	Data 0.000 (0.005)	Loss 0.3320 (0.3135)	Acc@1 92.188 (94.135)	Acc@5 100.000 (99.928)
Epoch: [127][128/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.2998 (0.3126)	Acc@1 94.922 (94.110)	Acc@5 100.000 (99.915)
Epoch: [127][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2932 (0.3120)	Acc@1 94.922 (94.088)	Acc@5 100.000 (99.903)
Max memory in training epoch: 47.1174656
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.155 (0.155)	Data 0.263 (0.263)	Loss 0.2424 (0.2424)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.103 (0.108)	Data 0.000 (0.004)	Loss 0.3073 (0.3023)	Acc@1 94.531 (94.351)	Acc@5 100.000 (99.928)
Epoch: [128][128/196]	Time 0.109 (0.108)	Data 0.000 (0.002)	Loss 0.3231 (0.3079)	Acc@1 92.188 (94.247)	Acc@5 100.000 (99.909)
Epoch: [128][192/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.2851 (0.3133)	Acc@1 96.094 (93.985)	Acc@5 100.000 (99.917)
Max memory in training epoch: 47.1174656
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.139 (0.139)	Data 0.282 (0.282)	Loss 0.2925 (0.2925)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.104 (0.108)	Data 0.000 (0.005)	Loss 0.2486 (0.3001)	Acc@1 96.094 (94.531)	Acc@5 100.000 (99.940)
Epoch: [129][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.3069 (0.3034)	Acc@1 92.969 (94.371)	Acc@5 100.000 (99.930)
Epoch: [129][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.2887 (0.3074)	Acc@1 94.922 (94.240)	Acc@5 100.000 (99.917)
Max memory in training epoch: 47.1174656
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.131 (0.131)	Data 0.288 (0.288)	Loss 0.3056 (0.3056)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.100 (0.108)	Data 0.000 (0.005)	Loss 0.2690 (0.2991)	Acc@1 96.484 (94.688)	Acc@5 100.000 (99.940)
Epoch: [130][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.2963 (0.3008)	Acc@1 93.750 (94.583)	Acc@5 100.000 (99.915)
Epoch: [130][192/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.3361 (0.3064)	Acc@1 94.531 (94.404)	Acc@5 100.000 (99.907)
Max memory in training epoch: 47.1174656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 175559 ; 179938 ; 0.9756638397670309
[INFO] Storing checkpoint...
  87.94
Max memory: 73.5387648
 21.389s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6223
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.0772096
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.153 (0.153)	Data 0.249 (0.249)	Loss 0.2967 (0.2967)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.109 (0.108)	Data 0.000 (0.004)	Loss 0.3013 (0.2976)	Acc@1 93.359 (94.483)	Acc@5 99.609 (99.916)
Epoch: [131][128/196]	Time 0.109 (0.109)	Data 0.000 (0.002)	Loss 0.2754 (0.3058)	Acc@1 94.922 (94.204)	Acc@5 99.609 (99.915)
Epoch: [131][192/196]	Time 0.108 (0.109)	Data 0.000 (0.001)	Loss 0.3053 (0.3103)	Acc@1 92.969 (94.054)	Acc@5 100.000 (99.901)
Max memory in training epoch: 46.8921856
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.128 (0.128)	Data 0.286 (0.286)	Loss 0.2588 (0.2588)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [132][64/196]	Time 0.112 (0.108)	Data 0.000 (0.005)	Loss 0.3066 (0.3041)	Acc@1 93.750 (94.183)	Acc@5 100.000 (99.922)
Epoch: [132][128/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.3130 (0.3069)	Acc@1 94.531 (94.089)	Acc@5 100.000 (99.882)
Epoch: [132][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.3342 (0.3097)	Acc@1 93.750 (94.005)	Acc@5 100.000 (99.903)
Max memory in training epoch: 46.9855744
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.150 (0.150)	Data 0.284 (0.284)	Loss 0.3119 (0.3119)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.105 (0.108)	Data 0.000 (0.005)	Loss 0.2898 (0.3007)	Acc@1 95.312 (94.471)	Acc@5 100.000 (99.946)
Epoch: [133][128/196]	Time 0.109 (0.107)	Data 0.000 (0.002)	Loss 0.2822 (0.2986)	Acc@1 94.531 (94.486)	Acc@5 100.000 (99.949)
Epoch: [133][192/196]	Time 0.112 (0.107)	Data 0.000 (0.002)	Loss 0.3121 (0.3032)	Acc@1 93.359 (94.296)	Acc@5 100.000 (99.933)
Max memory in training epoch: 46.9855744
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.152 (0.152)	Data 0.261 (0.261)	Loss 0.2692 (0.2692)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.110 (0.108)	Data 0.000 (0.004)	Loss 0.3208 (0.3072)	Acc@1 94.141 (94.123)	Acc@5 100.000 (99.928)
Epoch: [134][128/196]	Time 0.099 (0.107)	Data 0.000 (0.002)	Loss 0.3662 (0.3063)	Acc@1 90.625 (94.180)	Acc@5 99.609 (99.924)
Epoch: [134][192/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.4059 (0.3115)	Acc@1 90.625 (93.914)	Acc@5 99.609 (99.909)
Max memory in training epoch: 46.9855744
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.152 (0.152)	Data 0.278 (0.278)	Loss 0.2928 (0.2928)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.107 (0.108)	Data 0.000 (0.004)	Loss 0.2978 (0.2915)	Acc@1 97.656 (94.639)	Acc@5 100.000 (99.910)
Epoch: [135][128/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.3815 (0.2956)	Acc@1 91.406 (94.434)	Acc@5 100.000 (99.933)
Epoch: [135][192/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.3016 (0.3036)	Acc@1 92.578 (94.135)	Acc@5 100.000 (99.927)
Max memory in training epoch: 46.9855744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 171319 ; 175559 ; 0.9758485751228931
[INFO] Storing checkpoint...
  87.76
Max memory: 72.6462464
 21.466s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5078
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.0756224
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.186 (0.186)	Data 0.262 (0.262)	Loss 0.2955 (0.2955)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.107 (0.109)	Data 0.000 (0.004)	Loss 0.3150 (0.3061)	Acc@1 93.359 (94.105)	Acc@5 99.609 (99.910)
Epoch: [136][128/196]	Time 0.110 (0.109)	Data 0.000 (0.002)	Loss 0.2998 (0.3060)	Acc@1 93.750 (94.083)	Acc@5 99.609 (99.924)
Epoch: [136][192/196]	Time 0.102 (0.108)	Data 0.000 (0.002)	Loss 0.3354 (0.3099)	Acc@1 92.969 (93.981)	Acc@5 100.000 (99.919)
Max memory in training epoch: 46.7513856
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.133 (0.133)	Data 0.302 (0.302)	Loss 0.2842 (0.2842)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.105 (0.107)	Data 0.000 (0.005)	Loss 0.2664 (0.2990)	Acc@1 94.922 (94.429)	Acc@5 100.000 (99.910)
Epoch: [137][128/196]	Time 0.108 (0.107)	Data 0.000 (0.003)	Loss 0.3920 (0.3114)	Acc@1 90.234 (93.959)	Acc@5 100.000 (99.900)
Epoch: [137][192/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.2971 (0.3158)	Acc@1 94.141 (93.799)	Acc@5 100.000 (99.889)
Max memory in training epoch: 46.5335808
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.151 (0.151)	Data 0.298 (0.298)	Loss 0.2732 (0.2732)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [138][64/196]	Time 0.110 (0.111)	Data 0.000 (0.005)	Loss 0.3022 (0.3128)	Acc@1 93.750 (93.846)	Acc@5 100.000 (99.934)
Epoch: [138][128/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.3126 (0.3114)	Acc@1 93.750 (93.904)	Acc@5 99.609 (99.909)
Epoch: [138][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3413 (0.3134)	Acc@1 93.359 (93.878)	Acc@5 100.000 (99.913)
Max memory in training epoch: 46.5335808
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.159 (0.159)	Data 0.291 (0.291)	Loss 0.2587 (0.2587)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.108 (0.108)	Data 0.000 (0.005)	Loss 0.2982 (0.3042)	Acc@1 94.531 (94.231)	Acc@5 100.000 (99.922)
Epoch: [139][128/196]	Time 0.111 (0.107)	Data 0.000 (0.002)	Loss 0.3274 (0.3047)	Acc@1 92.188 (94.213)	Acc@5 100.000 (99.918)
Epoch: [139][192/196]	Time 0.107 (0.107)	Data 0.000 (0.002)	Loss 0.2897 (0.3053)	Acc@1 95.312 (94.171)	Acc@5 100.000 (99.907)
Max memory in training epoch: 46.5335808
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.131 (0.131)	Data 0.298 (0.298)	Loss 0.2692 (0.2692)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.108 (0.107)	Data 0.000 (0.005)	Loss 0.3120 (0.2971)	Acc@1 93.359 (94.561)	Acc@5 100.000 (99.928)
Epoch: [140][128/196]	Time 0.108 (0.107)	Data 0.000 (0.002)	Loss 0.3255 (0.3018)	Acc@1 92.969 (94.416)	Acc@5 99.609 (99.915)
Epoch: [140][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2620 (0.3095)	Acc@1 94.531 (94.048)	Acc@5 100.000 (99.905)
Max memory in training epoch: 46.5335808
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 162341 ; 171319 ; 0.9475948377004302
[INFO] Storing checkpoint...
  87.84
Max memory: 71.9140352
 21.419s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2601
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0720384
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.210 (0.210)	Data 0.323 (0.323)	Loss 0.3412 (0.3412)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.107 (0.107)	Data 0.000 (0.005)	Loss 0.3223 (0.3156)	Acc@1 91.797 (93.546)	Acc@5 100.000 (99.904)
Epoch: [141][128/196]	Time 0.106 (0.107)	Data 0.000 (0.003)	Loss 0.3361 (0.3213)	Acc@1 92.188 (93.371)	Acc@5 100.000 (99.882)
Epoch: [141][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.3459 (0.3232)	Acc@1 94.531 (93.361)	Acc@5 99.219 (99.870)
Max memory in training epoch: 46.0670464
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.165 (0.165)	Data 0.286 (0.286)	Loss 0.3327 (0.3327)	Acc@1 92.188 (92.188)	Acc@5 99.609 (99.609)
Epoch: [142][64/196]	Time 0.105 (0.109)	Data 0.000 (0.005)	Loss 0.3555 (0.3133)	Acc@1 94.141 (93.696)	Acc@5 99.219 (99.880)
Epoch: [142][128/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.3382 (0.3174)	Acc@1 92.969 (93.565)	Acc@5 100.000 (99.918)
Epoch: [142][192/196]	Time 0.113 (0.107)	Data 0.000 (0.002)	Loss 0.3622 (0.3197)	Acc@1 92.188 (93.531)	Acc@5 99.219 (99.903)
Max memory in training epoch: 45.9359744
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.152 (0.152)	Data 0.259 (0.259)	Loss 0.2883 (0.2883)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.3930 (0.3190)	Acc@1 92.188 (93.546)	Acc@5 99.609 (99.898)
Epoch: [143][128/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.3384 (0.3189)	Acc@1 93.359 (93.547)	Acc@5 100.000 (99.894)
Epoch: [143][192/196]	Time 0.103 (0.107)	Data 0.000 (0.002)	Loss 0.2426 (0.3189)	Acc@1 97.266 (93.562)	Acc@5 99.609 (99.903)
Max memory in training epoch: 45.9359744
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.142 (0.142)	Data 0.280 (0.280)	Loss 0.2508 (0.2508)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.103 (0.109)	Data 0.000 (0.004)	Loss 0.2905 (0.3135)	Acc@1 94.531 (93.696)	Acc@5 100.000 (99.910)
Epoch: [144][128/196]	Time 0.115 (0.108)	Data 0.000 (0.002)	Loss 0.2983 (0.3091)	Acc@1 94.922 (93.895)	Acc@5 100.000 (99.891)
Epoch: [144][192/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.3647 (0.3134)	Acc@1 93.750 (93.736)	Acc@5 98.828 (99.891)
Max memory in training epoch: 45.9359744
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.129 (0.129)	Data 0.281 (0.281)	Loss 0.3060 (0.3060)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [145][64/196]	Time 0.106 (0.110)	Data 0.000 (0.005)	Loss 0.3640 (0.3035)	Acc@1 91.797 (94.297)	Acc@5 100.000 (99.904)
Epoch: [145][128/196]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.3205 (0.3072)	Acc@1 92.188 (94.023)	Acc@5 100.000 (99.903)
Epoch: [145][192/196]	Time 0.103 (0.109)	Data 0.000 (0.002)	Loss 0.2941 (0.3122)	Acc@1 93.750 (93.807)	Acc@5 100.000 (99.895)
Max memory in training epoch: 45.9359744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.2
Max memory: 71.1377408
 21.729s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8460
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0720384
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.179 (0.179)	Data 0.263 (0.263)	Loss 0.3040 (0.3040)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.102 (0.109)	Data 0.000 (0.004)	Loss 0.2930 (0.2951)	Acc@1 94.141 (94.435)	Acc@5 100.000 (99.922)
Epoch: [146][128/196]	Time 0.116 (0.108)	Data 0.000 (0.002)	Loss 0.3110 (0.3010)	Acc@1 93.750 (94.195)	Acc@5 99.609 (99.912)
Epoch: [146][192/196]	Time 0.110 (0.108)	Data 0.000 (0.002)	Loss 0.3365 (0.3065)	Acc@1 92.578 (93.981)	Acc@5 99.609 (99.903)
Max memory in training epoch: 46.0670464
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.127 (0.127)	Data 0.292 (0.292)	Loss 0.3062 (0.3062)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.106 (0.108)	Data 0.000 (0.005)	Loss 0.2862 (0.3191)	Acc@1 94.141 (93.395)	Acc@5 100.000 (99.922)
Epoch: [147][128/196]	Time 0.110 (0.108)	Data 0.000 (0.002)	Loss 0.2338 (0.3161)	Acc@1 96.094 (93.641)	Acc@5 100.000 (99.915)
Epoch: [147][192/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.3639 (0.3175)	Acc@1 92.188 (93.673)	Acc@5 99.609 (99.907)
Max memory in training epoch: 45.9359744
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.155 (0.155)	Data 0.261 (0.261)	Loss 0.3082 (0.3082)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.100 (0.109)	Data 0.000 (0.004)	Loss 0.2717 (0.3047)	Acc@1 94.531 (94.357)	Acc@5 100.000 (99.910)
Epoch: [148][128/196]	Time 0.110 (0.108)	Data 0.000 (0.002)	Loss 0.3045 (0.3061)	Acc@1 95.703 (94.262)	Acc@5 99.609 (99.915)
Epoch: [148][192/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.3740 (0.3115)	Acc@1 91.406 (93.956)	Acc@5 100.000 (99.903)
Max memory in training epoch: 45.9359744
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.154 (0.154)	Data 0.289 (0.289)	Loss 0.2847 (0.2847)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.107 (0.108)	Data 0.000 (0.005)	Loss 0.3039 (0.3164)	Acc@1 93.750 (93.600)	Acc@5 100.000 (99.922)
Epoch: [149][128/196]	Time 0.109 (0.108)	Data 0.000 (0.002)	Loss 0.4103 (0.3120)	Acc@1 91.406 (93.820)	Acc@5 99.609 (99.879)
Epoch: [149][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2887 (0.3121)	Acc@1 94.531 (93.803)	Acc@5 100.000 (99.891)
Max memory in training epoch: 45.9359744
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.142 (0.142)	Data 0.263 (0.263)	Loss 0.2820 (0.2820)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.105 (0.111)	Data 0.000 (0.004)	Loss 0.2712 (0.2771)	Acc@1 95.703 (94.898)	Acc@5 100.000 (99.934)
Epoch: [150][128/196]	Time 0.116 (0.109)	Data 0.000 (0.002)	Loss 0.2529 (0.2666)	Acc@1 96.484 (95.412)	Acc@5 99.609 (99.945)
Epoch: [150][192/196]	Time 0.108 (0.109)	Data 0.000 (0.002)	Loss 0.2694 (0.2625)	Acc@1 94.922 (95.620)	Acc@5 100.000 (99.951)
Max memory in training epoch: 45.9359744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 160069 ; 162341 ; 0.9860047677419752
[INFO] Storing checkpoint...
  91.02
Max memory: 71.1266816
 21.625s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3057
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0711168
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.155 (0.155)	Data 0.279 (0.279)	Loss 0.2665 (0.2665)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.112 (0.110)	Data 0.000 (0.004)	Loss 0.2990 (0.2560)	Acc@1 93.359 (95.944)	Acc@5 100.000 (99.982)
Epoch: [151][128/196]	Time 0.101 (0.108)	Data 0.000 (0.002)	Loss 0.2828 (0.2507)	Acc@1 94.141 (96.130)	Acc@5 100.000 (99.970)
Epoch: [151][192/196]	Time 0.108 (0.108)	Data 0.000 (0.002)	Loss 0.2930 (0.2484)	Acc@1 95.703 (96.272)	Acc@5 100.000 (99.953)
Max memory in training epoch: 45.9519488
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.143 (0.143)	Data 0.274 (0.274)	Loss 0.2732 (0.2732)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.108 (0.108)	Data 0.000 (0.004)	Loss 0.2576 (0.2390)	Acc@1 95.312 (96.484)	Acc@5 100.000 (99.976)
Epoch: [152][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2406 (0.2379)	Acc@1 96.094 (96.590)	Acc@5 100.000 (99.970)
Epoch: [152][192/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2490 (0.2380)	Acc@1 96.484 (96.644)	Acc@5 100.000 (99.970)
Max memory in training epoch: 45.7946624
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.154 (0.154)	Data 0.266 (0.266)	Loss 0.2297 (0.2297)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.108 (0.108)	Data 0.000 (0.004)	Loss 0.2352 (0.2271)	Acc@1 98.047 (97.085)	Acc@5 100.000 (99.976)
Epoch: [153][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.2435 (0.2301)	Acc@1 96.875 (96.948)	Acc@5 100.000 (99.964)
Epoch: [153][192/196]	Time 0.104 (0.106)	Data 0.000 (0.002)	Loss 0.2343 (0.2307)	Acc@1 96.875 (96.903)	Acc@5 100.000 (99.968)
Max memory in training epoch: 45.7946624
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.150 (0.150)	Data 0.271 (0.271)	Loss 0.2074 (0.2074)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.100 (0.106)	Data 0.000 (0.004)	Loss 0.2146 (0.2253)	Acc@1 97.266 (97.109)	Acc@5 100.000 (99.988)
Epoch: [154][128/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.2230 (0.2287)	Acc@1 97.266 (96.987)	Acc@5 100.000 (99.961)
Epoch: [154][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.2330 (0.2266)	Acc@1 95.703 (97.059)	Acc@5 99.609 (99.964)
Max memory in training epoch: 45.7946624
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.156 (0.156)	Data 0.280 (0.280)	Loss 0.2037 (0.2037)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.105 (0.105)	Data 0.000 (0.004)	Loss 0.2397 (0.2243)	Acc@1 95.703 (97.121)	Acc@5 100.000 (99.958)
Epoch: [155][128/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.2449 (0.2248)	Acc@1 96.875 (97.072)	Acc@5 100.000 (99.970)
Epoch: [155][192/196]	Time 0.102 (0.106)	Data 0.000 (0.002)	Loss 0.1968 (0.2243)	Acc@1 98.828 (97.079)	Acc@5 100.000 (99.966)
Max memory in training epoch: 45.7946624
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.08
Max memory: 71.3645568
 21.052s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9583
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0711168
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.163 (0.163)	Data 0.258 (0.258)	Loss 0.2226 (0.2226)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.1887 (0.2174)	Acc@1 97.266 (97.344)	Acc@5 100.000 (99.964)
Epoch: [156][128/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.2126 (0.2218)	Acc@1 96.484 (97.072)	Acc@5 100.000 (99.970)
Epoch: [156][192/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.1863 (0.2222)	Acc@1 97.656 (97.061)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.9519488
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.157 (0.157)	Data 0.267 (0.267)	Loss 0.2265 (0.2265)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.104 (0.107)	Data 0.000 (0.004)	Loss 0.2101 (0.2191)	Acc@1 98.438 (97.296)	Acc@5 100.000 (99.976)
Epoch: [157][128/196]	Time 0.107 (0.106)	Data 0.000 (0.002)	Loss 0.2393 (0.2191)	Acc@1 95.703 (97.293)	Acc@5 100.000 (99.967)
Epoch: [157][192/196]	Time 0.102 (0.106)	Data 0.000 (0.002)	Loss 0.2341 (0.2192)	Acc@1 97.266 (97.258)	Acc@5 100.000 (99.970)
Max memory in training epoch: 45.7946624
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.124 (0.124)	Data 0.272 (0.272)	Loss 0.2063 (0.2063)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.109 (0.109)	Data 0.000 (0.004)	Loss 0.2160 (0.2152)	Acc@1 97.656 (97.536)	Acc@5 100.000 (99.946)
Epoch: [158][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.2480 (0.2167)	Acc@1 95.312 (97.399)	Acc@5 99.609 (99.955)
Epoch: [158][192/196]	Time 0.103 (0.109)	Data 0.000 (0.002)	Loss 0.2122 (0.2163)	Acc@1 97.266 (97.373)	Acc@5 100.000 (99.966)
Max memory in training epoch: 45.7946624
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.138 (0.138)	Data 0.296 (0.296)	Loss 0.2102 (0.2102)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.107 (0.106)	Data 0.000 (0.005)	Loss 0.1843 (0.2107)	Acc@1 98.828 (97.650)	Acc@5 100.000 (99.976)
Epoch: [159][128/196]	Time 0.113 (0.106)	Data 0.000 (0.002)	Loss 0.2221 (0.2124)	Acc@1 97.266 (97.562)	Acc@5 100.000 (99.973)
Epoch: [159][192/196]	Time 0.102 (0.107)	Data 0.000 (0.002)	Loss 0.1917 (0.2130)	Acc@1 98.047 (97.511)	Acc@5 100.000 (99.978)
Max memory in training epoch: 45.7946624
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.148 (0.148)	Data 0.315 (0.315)	Loss 0.2273 (0.2273)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.104 (0.107)	Data 0.000 (0.005)	Loss 0.2273 (0.2132)	Acc@1 97.266 (97.470)	Acc@5 100.000 (99.970)
Epoch: [160][128/196]	Time 0.102 (0.107)	Data 0.000 (0.003)	Loss 0.2129 (0.2124)	Acc@1 98.438 (97.438)	Acc@5 100.000 (99.973)
Epoch: [160][192/196]	Time 0.111 (0.107)	Data 0.000 (0.002)	Loss 0.2070 (0.2123)	Acc@1 96.875 (97.434)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.7946624
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 158933 ; 160069 ; 0.9929030605551356
[INFO] Storing checkpoint...
  91.14
Max memory: 71.2146432
 21.272s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4404
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.0706048
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.186 (0.186)	Data 0.277 (0.277)	Loss 0.2416 (0.2416)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.105 (0.107)	Data 0.000 (0.004)	Loss 0.2214 (0.2170)	Acc@1 97.656 (97.296)	Acc@5 99.609 (99.988)
Epoch: [161][128/196]	Time 0.104 (0.106)	Data 0.000 (0.002)	Loss 0.1716 (0.2160)	Acc@1 98.828 (97.390)	Acc@5 100.000 (99.985)
Epoch: [161][192/196]	Time 0.104 (0.106)	Data 0.000 (0.002)	Loss 0.2212 (0.2149)	Acc@1 96.875 (97.417)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.9499008
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.147 (0.147)	Data 0.290 (0.290)	Loss 0.1923 (0.1923)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.106 (0.107)	Data 0.000 (0.005)	Loss 0.2213 (0.2108)	Acc@1 98.047 (97.566)	Acc@5 100.000 (99.976)
Epoch: [162][128/196]	Time 0.111 (0.106)	Data 0.000 (0.002)	Loss 0.2196 (0.2119)	Acc@1 97.656 (97.508)	Acc@5 100.000 (99.982)
Epoch: [162][192/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.1938 (0.2114)	Acc@1 99.219 (97.496)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.7926144
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.150 (0.150)	Data 0.268 (0.268)	Loss 0.2081 (0.2081)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.107 (0.105)	Data 0.000 (0.004)	Loss 0.1892 (0.2097)	Acc@1 98.047 (97.536)	Acc@5 100.000 (99.976)
Epoch: [163][128/196]	Time 0.106 (0.105)	Data 0.000 (0.002)	Loss 0.1904 (0.2094)	Acc@1 97.656 (97.478)	Acc@5 100.000 (99.976)
Epoch: [163][192/196]	Time 0.109 (0.105)	Data 0.000 (0.002)	Loss 0.1947 (0.2097)	Acc@1 98.047 (97.488)	Acc@5 100.000 (99.978)
Max memory in training epoch: 45.7926144
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.127 (0.127)	Data 0.279 (0.279)	Loss 0.2004 (0.2004)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.106 (0.108)	Data 0.000 (0.004)	Loss 0.2123 (0.2037)	Acc@1 98.047 (97.644)	Acc@5 99.609 (99.976)
Epoch: [164][128/196]	Time 0.108 (0.109)	Data 0.000 (0.002)	Loss 0.2690 (0.2079)	Acc@1 95.312 (97.517)	Acc@5 100.000 (99.964)
Epoch: [164][192/196]	Time 0.098 (0.108)	Data 0.000 (0.002)	Loss 0.1779 (0.2085)	Acc@1 99.219 (97.523)	Acc@5 100.000 (99.966)
Max memory in training epoch: 45.7926144
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.155 (0.155)	Data 0.296 (0.296)	Loss 0.1833 (0.1833)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.101 (0.106)	Data 0.000 (0.005)	Loss 0.1696 (0.2034)	Acc@1 99.609 (97.800)	Acc@5 100.000 (99.988)
Epoch: [165][128/196]	Time 0.105 (0.105)	Data 0.000 (0.002)	Loss 0.1951 (0.2052)	Acc@1 98.047 (97.653)	Acc@5 100.000 (99.988)
Epoch: [165][192/196]	Time 0.103 (0.105)	Data 0.000 (0.002)	Loss 0.2056 (0.2046)	Acc@1 97.656 (97.709)	Acc@5 100.000 (99.990)
Max memory in training epoch: 45.7926144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.48
Max memory: 71.1926272
 21.033s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2297
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0706048
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.166 (0.166)	Data 0.262 (0.262)	Loss 0.2342 (0.2342)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.106 (0.107)	Data 0.000 (0.004)	Loss 0.2089 (0.2050)	Acc@1 98.438 (97.764)	Acc@5 100.000 (99.982)
Epoch: [166][128/196]	Time 0.119 (0.107)	Data 0.000 (0.002)	Loss 0.2246 (0.2027)	Acc@1 96.094 (97.817)	Acc@5 100.000 (99.991)
Epoch: [166][192/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.2412 (0.2037)	Acc@1 96.094 (97.755)	Acc@5 100.000 (99.988)
Max memory in training epoch: 45.9499008
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.143 (0.143)	Data 0.284 (0.284)	Loss 0.2293 (0.2293)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.101 (0.105)	Data 0.000 (0.005)	Loss 0.2175 (0.2033)	Acc@1 96.484 (97.752)	Acc@5 100.000 (99.982)
Epoch: [167][128/196]	Time 0.107 (0.105)	Data 0.000 (0.002)	Loss 0.1928 (0.2032)	Acc@1 98.438 (97.696)	Acc@5 100.000 (99.988)
Epoch: [167][192/196]	Time 0.104 (0.105)	Data 0.000 (0.002)	Loss 0.2241 (0.2031)	Acc@1 97.656 (97.668)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.7926144
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.158 (0.158)	Data 0.282 (0.282)	Loss 0.1846 (0.1846)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.100 (0.106)	Data 0.000 (0.005)	Loss 0.1857 (0.1998)	Acc@1 98.438 (97.939)	Acc@5 100.000 (99.970)
Epoch: [168][128/196]	Time 0.101 (0.106)	Data 0.000 (0.002)	Loss 0.1909 (0.2007)	Acc@1 98.047 (97.862)	Acc@5 100.000 (99.970)
Epoch: [168][192/196]	Time 0.105 (0.105)	Data 0.000 (0.002)	Loss 0.1849 (0.2025)	Acc@1 98.828 (97.774)	Acc@5 100.000 (99.976)
Max memory in training epoch: 45.7926144
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.152 (0.152)	Data 0.279 (0.279)	Loss 0.2038 (0.2038)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.110 (0.106)	Data 0.000 (0.004)	Loss 0.1900 (0.2041)	Acc@1 98.438 (97.596)	Acc@5 100.000 (99.976)
Epoch: [169][128/196]	Time 0.103 (0.105)	Data 0.000 (0.002)	Loss 0.2098 (0.2032)	Acc@1 96.484 (97.632)	Acc@5 100.000 (99.976)
Epoch: [169][192/196]	Time 0.102 (0.105)	Data 0.000 (0.002)	Loss 0.2110 (0.2006)	Acc@1 97.656 (97.727)	Acc@5 100.000 (99.970)
Max memory in training epoch: 45.7926144
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.143 (0.143)	Data 0.299 (0.299)	Loss 0.2098 (0.2098)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.107 (0.108)	Data 0.000 (0.005)	Loss 0.1952 (0.1988)	Acc@1 98.047 (97.782)	Acc@5 100.000 (99.964)
Epoch: [170][128/196]	Time 0.110 (0.108)	Data 0.000 (0.002)	Loss 0.2021 (0.1987)	Acc@1 96.484 (97.774)	Acc@5 100.000 (99.973)
Epoch: [170][192/196]	Time 0.110 (0.109)	Data 0.000 (0.002)	Loss 0.1936 (0.1987)	Acc@1 97.266 (97.778)	Acc@5 100.000 (99.978)
Max memory in training epoch: 45.7926144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 156661 ; 158933 ; 0.9857046680047568
[INFO] Storing checkpoint...
  91.25
Max memory: 71.3425408
 21.674s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5478
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.0697856
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.142 (0.142)	Data 0.270 (0.270)	Loss 0.1931 (0.1931)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.1923 (0.2022)	Acc@1 98.047 (97.782)	Acc@5 100.000 (99.976)
Epoch: [171][128/196]	Time 0.106 (0.106)	Data 0.000 (0.002)	Loss 0.2213 (0.2014)	Acc@1 96.875 (97.780)	Acc@5 100.000 (99.988)
Epoch: [171][192/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.1893 (0.2019)	Acc@1 97.656 (97.707)	Acc@5 100.000 (99.986)
Max memory in training epoch: 45.9007488
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.151 (0.151)	Data 0.259 (0.259)	Loss 0.1676 (0.1676)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.1718 (0.1971)	Acc@1 99.219 (97.867)	Acc@5 100.000 (99.994)
Epoch: [172][128/196]	Time 0.101 (0.105)	Data 0.000 (0.002)	Loss 0.2211 (0.1999)	Acc@1 96.875 (97.750)	Acc@5 100.000 (99.988)
Epoch: [172][192/196]	Time 0.103 (0.105)	Data 0.000 (0.002)	Loss 0.1955 (0.2001)	Acc@1 98.047 (97.725)	Acc@5 100.000 (99.986)
Max memory in training epoch: 45.7762304
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.136 (0.136)	Data 0.295 (0.295)	Loss 0.2136 (0.2136)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.107 (0.106)	Data 0.000 (0.005)	Loss 0.1966 (0.1993)	Acc@1 98.047 (97.734)	Acc@5 100.000 (99.976)
Epoch: [173][128/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.1916 (0.1990)	Acc@1 97.266 (97.747)	Acc@5 100.000 (99.979)
Epoch: [173][192/196]	Time 0.104 (0.105)	Data 0.000 (0.002)	Loss 0.2173 (0.1992)	Acc@1 96.875 (97.737)	Acc@5 100.000 (99.982)
Max memory in training epoch: 45.7762304
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.146 (0.146)	Data 0.295 (0.295)	Loss 0.1692 (0.1692)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.107 (0.105)	Data 0.000 (0.005)	Loss 0.1981 (0.1975)	Acc@1 97.656 (97.800)	Acc@5 100.000 (99.964)
Epoch: [174][128/196]	Time 0.104 (0.106)	Data 0.000 (0.002)	Loss 0.1815 (0.1968)	Acc@1 98.828 (97.756)	Acc@5 100.000 (99.976)
Epoch: [174][192/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.1993 (0.1959)	Acc@1 97.266 (97.812)	Acc@5 100.000 (99.984)
Max memory in training epoch: 45.7762304
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.147 (0.147)	Data 0.282 (0.282)	Loss 0.1913 (0.1913)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.104 (0.105)	Data 0.000 (0.005)	Loss 0.1853 (0.1972)	Acc@1 98.438 (97.861)	Acc@5 100.000 (99.976)
Epoch: [175][128/196]	Time 0.105 (0.105)	Data 0.000 (0.002)	Loss 0.2009 (0.1968)	Acc@1 97.656 (97.859)	Acc@5 100.000 (99.973)
Epoch: [175][192/196]	Time 0.099 (0.104)	Data 0.000 (0.002)	Loss 0.2184 (0.1971)	Acc@1 98.047 (97.800)	Acc@5 100.000 (99.980)
Max memory in training epoch: 45.7762304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 153733 ; 156661 ; 0.9813099622752313
[INFO] Storing checkpoint...
  91.53
Max memory: 71.1770624
 20.798s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 978
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.0685056
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.146 (0.146)	Data 0.273 (0.273)	Loss 0.2306 (0.2306)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.102 (0.107)	Data 0.000 (0.004)	Loss 0.1991 (0.2133)	Acc@1 97.656 (97.139)	Acc@5 99.609 (99.982)
Epoch: [176][128/196]	Time 0.108 (0.106)	Data 0.000 (0.002)	Loss 0.1797 (0.2111)	Acc@1 98.828 (97.220)	Acc@5 100.000 (99.973)
Epoch: [176][192/196]	Time 0.104 (0.107)	Data 0.000 (0.002)	Loss 0.1703 (0.2093)	Acc@1 98.828 (97.294)	Acc@5 100.000 (99.972)
Max memory in training epoch: 45.3778944
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.136 (0.136)	Data 0.306 (0.306)	Loss 0.1942 (0.1942)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.104 (0.108)	Data 0.000 (0.005)	Loss 0.2083 (0.2065)	Acc@1 97.656 (97.278)	Acc@5 100.000 (99.988)
Epoch: [177][128/196]	Time 0.110 (0.107)	Data 0.000 (0.003)	Loss 0.1869 (0.2056)	Acc@1 97.656 (97.338)	Acc@5 100.000 (99.982)
Epoch: [177][192/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.1777 (0.2050)	Acc@1 98.438 (97.357)	Acc@5 100.000 (99.988)
Max memory in training epoch: 45.384448
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.135 (0.135)	Data 0.261 (0.261)	Loss 0.2218 (0.2218)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.111 (0.106)	Data 0.000 (0.004)	Loss 0.2131 (0.2038)	Acc@1 96.094 (97.422)	Acc@5 100.000 (99.988)
Epoch: [178][128/196]	Time 0.102 (0.106)	Data 0.000 (0.002)	Loss 0.2111 (0.2020)	Acc@1 96.484 (97.472)	Acc@5 100.000 (99.979)
Epoch: [178][192/196]	Time 0.105 (0.106)	Data 0.000 (0.002)	Loss 0.2167 (0.2029)	Acc@1 96.094 (97.391)	Acc@5 100.000 (99.986)
Max memory in training epoch: 45.384448
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.143 (0.143)	Data 0.284 (0.284)	Loss 0.1592 (0.1592)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.101 (0.105)	Data 0.000 (0.005)	Loss 0.2027 (0.1998)	Acc@1 97.656 (97.596)	Acc@5 100.000 (99.970)
Epoch: [179][128/196]	Time 0.109 (0.106)	Data 0.000 (0.002)	Loss 0.2646 (0.2010)	Acc@1 94.141 (97.502)	Acc@5 99.609 (99.979)
Epoch: [179][192/196]	Time 0.103 (0.106)	Data 0.000 (0.002)	Loss 0.2035 (0.1995)	Acc@1 96.875 (97.531)	Acc@5 100.000 (99.974)
Max memory in training epoch: 45.384448
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.156 (0.156)	Data 0.267 (0.267)	Loss 0.2306 (0.2306)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.104 (0.108)	Data 0.000 (0.004)	Loss 0.1782 (0.1973)	Acc@1 98.047 (97.644)	Acc@5 100.000 (99.970)
Epoch: [180][128/196]	Time 0.106 (0.107)	Data 0.000 (0.002)	Loss 0.1755 (0.1983)	Acc@1 98.828 (97.574)	Acc@5 100.000 (99.982)
Epoch: [180][192/196]	Time 0.101 (0.106)	Data 0.000 (0.002)	Loss 0.2165 (0.1981)	Acc@1 98.438 (97.585)	Acc@5 99.609 (99.982)
Max memory in training epoch: 45.384448
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(10, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 28, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(28, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(23, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(28, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(10, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(28, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(5, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(28, 33, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(33, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(28, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(63, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(44, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(63, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(17, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): AdaptiveAvgPool2d(output_size=(1, 1))
    (55): Linear(in_features=63, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  91.09
Max memory: 70.816256
 21.136s  Thres 0.01 1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 873
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.203 (0.203)	Data 0.270 (0.270)	Loss 3.2206 (3.2206)	Acc@1 10.156 (10.156)	Acc@5 48.438 (48.438)
Epoch: [1][64/196]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 2.4023 (2.6762)	Acc@1 29.688 (23.942)	Acc@5 84.766 (76.034)
Epoch: [1][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 2.1666 (2.4962)	Acc@1 39.844 (29.251)	Acc@5 89.844 (81.925)
Epoch: [1][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 2.0450 (2.3721)	Acc@1 44.531 (33.835)	Acc@5 89.844 (84.964)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.153 (0.153)	Data 0.309 (0.309)	Loss 2.0970 (2.0970)	Acc@1 41.406 (41.406)	Acc@5 91.797 (91.797)
Epoch: [2][64/196]	Time 0.130 (0.127)	Data 0.000 (0.005)	Loss 1.8746 (1.9296)	Acc@1 49.609 (49.423)	Acc@5 97.656 (93.468)
Epoch: [2][128/196]	Time 0.123 (0.128)	Data 0.000 (0.003)	Loss 1.5961 (1.8432)	Acc@1 58.203 (52.465)	Acc@5 96.484 (94.192)
Epoch: [2][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 1.5036 (1.7818)	Acc@1 66.406 (54.520)	Acc@5 95.703 (94.703)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.174 (0.174)	Data 0.273 (0.273)	Loss 1.4761 (1.4761)	Acc@1 63.281 (63.281)	Acc@5 96.484 (96.484)
Epoch: [3][64/196]	Time 0.129 (0.128)	Data 0.000 (0.004)	Loss 1.5134 (1.5531)	Acc@1 65.234 (61.659)	Acc@5 96.094 (96.286)
Epoch: [3][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.4318 (1.5153)	Acc@1 64.844 (63.075)	Acc@5 97.656 (96.557)
Epoch: [3][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 1.5786 (1.4660)	Acc@1 58.203 (64.826)	Acc@5 94.141 (96.808)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.167 (0.167)	Data 0.304 (0.304)	Loss 1.2949 (1.2949)	Acc@1 68.359 (68.359)	Acc@5 98.828 (98.828)
Epoch: [4][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 1.3079 (1.3107)	Acc@1 70.703 (69.597)	Acc@5 96.484 (97.626)
Epoch: [4][128/196]	Time 0.133 (0.129)	Data 0.000 (0.003)	Loss 1.1625 (1.2710)	Acc@1 72.656 (70.779)	Acc@5 98.828 (97.808)
Epoch: [4][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 1.1480 (1.2437)	Acc@1 72.266 (71.565)	Acc@5 98.047 (97.946)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.172 (0.172)	Data 0.281 (0.281)	Loss 1.1141 (1.1141)	Acc@1 76.172 (76.172)	Acc@5 99.219 (99.219)
Epoch: [5][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 1.0654 (1.1294)	Acc@1 78.516 (74.922)	Acc@5 98.438 (98.323)
Epoch: [5][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 1.2433 (1.1070)	Acc@1 68.359 (75.506)	Acc@5 97.266 (98.410)
Epoch: [5][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 1.0522 (1.0934)	Acc@1 75.391 (75.753)	Acc@5 100.000 (98.421)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  72.58
Max memory: 103.3835008
 25.766s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5014
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.209 (0.209)	Data 0.261 (0.261)	Loss 1.0419 (1.0419)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [6][64/196]	Time 0.132 (0.135)	Data 0.000 (0.004)	Loss 0.9584 (1.0008)	Acc@1 79.297 (78.365)	Acc@5 98.438 (98.840)
Epoch: [6][128/196]	Time 0.124 (0.133)	Data 0.000 (0.002)	Loss 1.1619 (1.0095)	Acc@1 73.047 (78.061)	Acc@5 97.266 (98.758)
Epoch: [6][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8865 (0.9986)	Acc@1 82.422 (78.180)	Acc@5 98.828 (98.749)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.190 (0.190)	Data 0.298 (0.298)	Loss 0.8837 (0.8837)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [7][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.9082 (0.9582)	Acc@1 81.250 (79.123)	Acc@5 98.047 (98.798)
Epoch: [7][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8342 (0.9478)	Acc@1 84.766 (79.200)	Acc@5 98.828 (98.831)
Epoch: [7][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8372 (0.9409)	Acc@1 85.156 (79.321)	Acc@5 98.047 (98.871)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.165 (0.165)	Data 0.267 (0.267)	Loss 0.8395 (0.8395)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [8][64/196]	Time 0.131 (0.132)	Data 0.000 (0.004)	Loss 0.9562 (0.8954)	Acc@1 82.031 (80.583)	Acc@5 98.047 (98.948)
Epoch: [8][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.9586 (0.8920)	Acc@1 77.344 (80.499)	Acc@5 99.219 (98.901)
Epoch: [8][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.8988 (0.8876)	Acc@1 79.297 (80.576)	Acc@5 99.219 (98.889)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.188 (0.188)	Data 0.271 (0.271)	Loss 0.9141 (0.9141)	Acc@1 78.516 (78.516)	Acc@5 99.219 (99.219)
Epoch: [9][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.8675 (0.8610)	Acc@1 80.859 (81.136)	Acc@5 99.219 (99.189)
Epoch: [9][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8703 (0.8612)	Acc@1 80.469 (80.974)	Acc@5 99.609 (99.110)
Epoch: [9][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.9104 (0.8557)	Acc@1 76.562 (81.035)	Acc@5 99.219 (99.089)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.172 (0.172)	Data 0.287 (0.287)	Loss 0.6965 (0.6965)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 0.7574 (0.8339)	Acc@1 83.984 (81.779)	Acc@5 100.000 (98.930)
Epoch: [10][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.8415 (0.8385)	Acc@1 80.078 (81.513)	Acc@5 99.609 (99.046)
Epoch: [10][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8372 (0.8339)	Acc@1 81.250 (81.635)	Acc@5 98.047 (99.071)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.93
Max memory: 103.3833984
 26.064s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4071
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.204 (0.204)	Data 0.259 (0.259)	Loss 0.9255 (0.9255)	Acc@1 78.906 (78.906)	Acc@5 98.438 (98.438)
Epoch: [11][64/196]	Time 0.131 (0.132)	Data 0.000 (0.004)	Loss 0.8846 (0.8004)	Acc@1 81.250 (82.524)	Acc@5 98.047 (99.105)
Epoch: [11][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7864 (0.8124)	Acc@1 83.984 (82.198)	Acc@5 98.438 (99.049)
Epoch: [11][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.8827 (0.8112)	Acc@1 79.688 (82.219)	Acc@5 98.828 (99.077)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.179 (0.179)	Data 0.263 (0.263)	Loss 0.8365 (0.8365)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.7776 (0.8102)	Acc@1 83.984 (82.266)	Acc@5 99.219 (99.056)
Epoch: [12][128/196]	Time 0.148 (0.128)	Data 0.000 (0.002)	Loss 0.8866 (0.8057)	Acc@1 77.734 (82.322)	Acc@5 98.828 (99.116)
Epoch: [12][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7241 (0.8030)	Acc@1 86.328 (82.375)	Acc@5 98.828 (99.114)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.174 (0.174)	Data 0.282 (0.282)	Loss 0.7228 (0.7228)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [13][64/196]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.8211 (0.7975)	Acc@1 82.031 (82.620)	Acc@5 98.438 (99.111)
Epoch: [13][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7850 (0.7999)	Acc@1 83.203 (82.413)	Acc@5 98.828 (99.155)
Epoch: [13][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8384 (0.7959)	Acc@1 78.906 (82.551)	Acc@5 99.219 (99.168)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.187 (0.187)	Data 0.266 (0.266)	Loss 0.8353 (0.8353)	Acc@1 80.078 (80.078)	Acc@5 98.828 (98.828)
Epoch: [14][64/196]	Time 0.121 (0.130)	Data 0.000 (0.004)	Loss 0.6984 (0.7926)	Acc@1 84.375 (82.861)	Acc@5 100.000 (99.207)
Epoch: [14][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8589 (0.7868)	Acc@1 77.734 (82.943)	Acc@5 99.609 (99.234)
Epoch: [14][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7586 (0.7816)	Acc@1 81.641 (83.080)	Acc@5 98.828 (99.257)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.178 (0.178)	Data 0.268 (0.268)	Loss 0.7655 (0.7655)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 0.121 (0.130)	Data 0.000 (0.004)	Loss 0.7573 (0.7820)	Acc@1 83.984 (83.233)	Acc@5 98.828 (99.038)
Epoch: [15][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7748 (0.7768)	Acc@1 82.422 (83.457)	Acc@5 98.828 (99.104)
Epoch: [15][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7613 (0.7805)	Acc@1 83.984 (83.207)	Acc@5 98.828 (99.120)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  80.73
Max memory: 103.3833984
 25.513s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8682
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.188 (0.188)	Data 0.281 (0.281)	Loss 0.8217 (0.8217)	Acc@1 80.859 (80.859)	Acc@5 97.656 (97.656)
Epoch: [16][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.8204 (0.7459)	Acc@1 80.859 (84.213)	Acc@5 98.828 (99.279)
Epoch: [16][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.8038 (0.7556)	Acc@1 81.641 (83.918)	Acc@5 98.047 (99.279)
Epoch: [16][192/196]	Time 0.136 (0.130)	Data 0.000 (0.002)	Loss 0.6335 (0.7602)	Acc@1 88.281 (83.865)	Acc@5 100.000 (99.243)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.162 (0.162)	Data 0.275 (0.275)	Loss 0.8039 (0.8039)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [17][64/196]	Time 0.123 (0.131)	Data 0.000 (0.004)	Loss 0.7949 (0.7632)	Acc@1 82.422 (83.774)	Acc@5 98.828 (99.303)
Epoch: [17][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7636 (0.7593)	Acc@1 83.984 (83.906)	Acc@5 99.609 (99.352)
Epoch: [17][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.6598 (0.7622)	Acc@1 86.719 (83.822)	Acc@5 100.000 (99.324)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.152 (0.152)	Data 0.289 (0.289)	Loss 0.8150 (0.8150)	Acc@1 80.469 (80.469)	Acc@5 98.828 (98.828)
Epoch: [18][64/196]	Time 0.139 (0.131)	Data 0.000 (0.005)	Loss 0.8304 (0.7448)	Acc@1 78.516 (84.483)	Acc@5 98.828 (99.213)
Epoch: [18][128/196]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.6373 (0.7521)	Acc@1 88.281 (84.202)	Acc@5 100.000 (99.204)
Epoch: [18][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.8816 (0.7561)	Acc@1 80.078 (84.045)	Acc@5 97.266 (99.186)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.159 (0.159)	Data 0.274 (0.274)	Loss 0.6983 (0.6983)	Acc@1 87.891 (87.891)	Acc@5 97.656 (97.656)
Epoch: [19][64/196]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.8158 (0.7516)	Acc@1 82.422 (84.195)	Acc@5 98.438 (99.267)
Epoch: [19][128/196]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.7836 (0.7445)	Acc@1 82.031 (84.411)	Acc@5 98.828 (99.279)
Epoch: [19][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7462 (0.7473)	Acc@1 84.766 (84.355)	Acc@5 99.609 (99.281)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.183 (0.183)	Data 0.299 (0.299)	Loss 0.7042 (0.7042)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.7730 (0.7631)	Acc@1 84.766 (83.714)	Acc@5 99.609 (99.291)
Epoch: [20][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7744 (0.7507)	Acc@1 84.375 (84.224)	Acc@5 100.000 (99.270)
Epoch: [20][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7127 (0.7532)	Acc@1 85.156 (84.191)	Acc@5 99.609 (99.271)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 482770 ; 487386 ; 0.9905290673100992
[INFO] Storing checkpoint...
  73.68
Max memory: 103.3833984
 26.180s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3225
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2006528
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.205 (0.205)	Data 0.277 (0.277)	Loss 0.8466 (0.8466)	Acc@1 79.688 (79.688)	Acc@5 98.828 (98.828)
Epoch: [21][64/196]	Time 0.128 (0.133)	Data 0.000 (0.004)	Loss 0.7654 (0.6996)	Acc@1 84.375 (85.835)	Acc@5 99.219 (99.411)
Epoch: [21][128/196]	Time 0.143 (0.133)	Data 0.000 (0.002)	Loss 0.7688 (0.7298)	Acc@1 82.031 (84.859)	Acc@5 99.609 (99.331)
Epoch: [21][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7185 (0.7377)	Acc@1 83.984 (84.537)	Acc@5 100.000 (99.356)
Max memory in training epoch: 66.6393088
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.191 (0.191)	Data 0.275 (0.275)	Loss 0.7068 (0.7068)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6724 (0.7410)	Acc@1 87.500 (84.585)	Acc@5 99.219 (99.345)
Epoch: [22][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7214 (0.7385)	Acc@1 85.547 (84.554)	Acc@5 99.609 (99.307)
Epoch: [22][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7839 (0.7373)	Acc@1 82.031 (84.608)	Acc@5 98.438 (99.294)
Max memory in training epoch: 66.5344512
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.187 (0.187)	Data 0.255 (0.255)	Loss 0.7799 (0.7799)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.7565 (0.7473)	Acc@1 85.938 (84.123)	Acc@5 98.828 (99.315)
Epoch: [23][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8033 (0.7447)	Acc@1 83.203 (84.423)	Acc@5 98.828 (99.343)
Epoch: [23][192/196]	Time 0.133 (0.131)	Data 0.000 (0.001)	Loss 0.7206 (0.7430)	Acc@1 83.203 (84.480)	Acc@5 99.609 (99.320)
Max memory in training epoch: 66.5344512
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.171 (0.171)	Data 0.283 (0.283)	Loss 0.7831 (0.7831)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.7021 (0.7395)	Acc@1 83.203 (84.603)	Acc@5 99.609 (99.423)
Epoch: [24][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.7745 (0.7375)	Acc@1 84.766 (84.805)	Acc@5 98.438 (99.304)
Epoch: [24][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7220 (0.7370)	Acc@1 84.375 (84.816)	Acc@5 99.609 (99.324)
Max memory in training epoch: 66.5344512
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.162 (0.162)	Data 0.301 (0.301)	Loss 0.6953 (0.6953)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.140 (0.134)	Data 0.000 (0.005)	Loss 0.7738 (0.7147)	Acc@1 85.156 (85.409)	Acc@5 99.609 (99.423)
Epoch: [25][128/196]	Time 0.138 (0.135)	Data 0.000 (0.003)	Loss 0.7080 (0.7190)	Acc@1 86.328 (85.311)	Acc@5 99.219 (99.349)
Epoch: [25][192/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7394 (0.7273)	Acc@1 86.328 (85.029)	Acc@5 99.609 (99.314)
Max memory in training epoch: 66.5344512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 475552 ; 482770 ; 0.9850487809930194
[INFO] Storing checkpoint...
  77.45
Max memory: 103.3778688
 26.563s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5819
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.197888
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.195 (0.195)	Data 0.267 (0.267)	Loss 0.6664 (0.6664)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.7583 (0.7130)	Acc@1 86.719 (85.529)	Acc@5 98.828 (99.435)
Epoch: [26][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7271 (0.7161)	Acc@1 84.766 (85.362)	Acc@5 99.219 (99.355)
Epoch: [26][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7173 (0.7239)	Acc@1 86.719 (85.061)	Acc@5 99.219 (99.332)
Max memory in training epoch: 66.6282496
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.187 (0.187)	Data 0.256 (0.256)	Loss 0.6102 (0.6102)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.7887 (0.7329)	Acc@1 81.250 (84.964)	Acc@5 98.438 (99.363)
Epoch: [27][128/196]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.6621 (0.7310)	Acc@1 87.891 (84.996)	Acc@5 99.609 (99.346)
Epoch: [27][192/196]	Time 0.127 (0.131)	Data 0.000 (0.001)	Loss 0.7074 (0.7324)	Acc@1 84.375 (84.867)	Acc@5 99.609 (99.330)
Max memory in training epoch: 66.4971776
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.182 (0.182)	Data 0.264 (0.264)	Loss 0.7086 (0.7086)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 0.7897 (0.7286)	Acc@1 80.469 (85.066)	Acc@5 98.828 (99.417)
Epoch: [28][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.7185 (0.7229)	Acc@1 88.672 (85.259)	Acc@5 98.828 (99.385)
Epoch: [28][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7570 (0.7235)	Acc@1 85.156 (85.251)	Acc@5 98.047 (99.371)
Max memory in training epoch: 66.4971776
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.151 (0.151)	Data 0.293 (0.293)	Loss 0.6687 (0.6687)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [29][64/196]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.6683 (0.7214)	Acc@1 87.109 (85.306)	Acc@5 100.000 (99.435)
Epoch: [29][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.6762 (0.7180)	Acc@1 85.938 (85.529)	Acc@5 100.000 (99.416)
Epoch: [29][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.8861 (0.7175)	Acc@1 82.422 (85.484)	Acc@5 98.438 (99.381)
Max memory in training epoch: 66.4971776
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.153 (0.153)	Data 0.285 (0.285)	Loss 0.7113 (0.7113)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 0.137 (0.135)	Data 0.000 (0.005)	Loss 0.7337 (0.7271)	Acc@1 84.375 (84.862)	Acc@5 100.000 (99.375)
Epoch: [30][128/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7219 (0.7239)	Acc@1 86.328 (84.959)	Acc@5 99.609 (99.373)
Epoch: [30][192/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7502 (0.7218)	Acc@1 83.594 (85.136)	Acc@5 99.609 (99.360)
Max memory in training epoch: 66.4971776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 455340 ; 475552 ; 0.9574978130677613
[INFO] Storing checkpoint...
  61.64
Max memory: 102.9280256
 26.450s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4516
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1899008
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.201 (0.201)	Data 0.283 (0.283)	Loss 0.7017 (0.7017)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.142 (0.131)	Data 0.000 (0.005)	Loss 0.7530 (0.6873)	Acc@1 83.984 (86.575)	Acc@5 99.609 (99.393)
Epoch: [31][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6897 (0.7008)	Acc@1 86.719 (86.047)	Acc@5 98.438 (99.391)
Epoch: [31][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7577 (0.7149)	Acc@1 84.766 (85.545)	Acc@5 99.609 (99.362)
Max memory in training epoch: 65.1282944
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.184 (0.184)	Data 0.251 (0.251)	Loss 0.7593 (0.7593)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [32][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.8112 (0.7180)	Acc@1 81.641 (85.469)	Acc@5 99.219 (99.399)
Epoch: [32][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7122 (0.7164)	Acc@1 85.547 (85.526)	Acc@5 100.000 (99.400)
Epoch: [32][192/196]	Time 0.128 (0.131)	Data 0.000 (0.001)	Loss 0.7643 (0.7209)	Acc@1 83.594 (85.336)	Acc@5 99.219 (99.358)
Max memory in training epoch: 65.2069376
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.171 (0.171)	Data 0.294 (0.294)	Loss 0.7683 (0.7683)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.7070 (0.7035)	Acc@1 85.938 (85.944)	Acc@5 98.828 (99.477)
Epoch: [33][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6537 (0.7108)	Acc@1 86.328 (85.716)	Acc@5 99.609 (99.406)
Epoch: [33][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7423 (0.7145)	Acc@1 84.375 (85.610)	Acc@5 98.828 (99.387)
Max memory in training epoch: 65.2069376
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.187 (0.187)	Data 0.257 (0.257)	Loss 0.6500 (0.6500)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [34][64/196]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.7366 (0.7135)	Acc@1 87.109 (85.757)	Acc@5 99.609 (99.435)
Epoch: [34][128/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7920 (0.7113)	Acc@1 84.375 (85.747)	Acc@5 100.000 (99.437)
Epoch: [34][192/196]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.7585 (0.7075)	Acc@1 85.547 (85.788)	Acc@5 98.828 (99.435)
Max memory in training epoch: 65.2069376
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.179 (0.179)	Data 0.285 (0.285)	Loss 0.6691 (0.6691)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6473 (0.7062)	Acc@1 88.672 (85.541)	Acc@5 99.609 (99.471)
Epoch: [35][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7202 (0.7128)	Acc@1 83.984 (85.598)	Acc@5 99.609 (99.376)
Epoch: [35][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6934 (0.7124)	Acc@1 86.328 (85.553)	Acc@5 98.438 (99.397)
Max memory in training epoch: 65.2069376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 435712 ; 455340 ; 0.9568937497254799
[INFO] Storing checkpoint...
  80.08
Max memory: 100.9940992
 25.887s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5377
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1821184
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.208 (0.208)	Data 0.278 (0.278)	Loss 0.6607 (0.6607)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [36][64/196]	Time 0.124 (0.131)	Data 0.000 (0.004)	Loss 0.6645 (0.6719)	Acc@1 87.891 (86.977)	Acc@5 99.219 (99.567)
Epoch: [36][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6322 (0.6942)	Acc@1 89.062 (86.183)	Acc@5 100.000 (99.449)
Epoch: [36][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.6755 (0.6996)	Acc@1 84.766 (85.950)	Acc@5 99.609 (99.447)
Max memory in training epoch: 64.6646272
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.172 (0.172)	Data 0.296 (0.296)	Loss 0.7205 (0.7205)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.6318 (0.6995)	Acc@1 87.109 (85.775)	Acc@5 100.000 (99.381)
Epoch: [37][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.7865 (0.7055)	Acc@1 83.984 (85.617)	Acc@5 99.219 (99.385)
Epoch: [37][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7583 (0.7094)	Acc@1 83.984 (85.533)	Acc@5 98.828 (99.375)
Max memory in training epoch: 64.4680192
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.157 (0.157)	Data 0.284 (0.284)	Loss 0.5734 (0.5734)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [38][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7321 (0.6955)	Acc@1 83.594 (86.052)	Acc@5 99.219 (99.369)
Epoch: [38][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7943 (0.6982)	Acc@1 83.984 (85.907)	Acc@5 98.047 (99.352)
Epoch: [38][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7680 (0.7038)	Acc@1 83.594 (85.751)	Acc@5 98.828 (99.362)
Max memory in training epoch: 64.4680192
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.180 (0.180)	Data 0.295 (0.295)	Loss 0.6984 (0.6984)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [39][64/196]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 0.6449 (0.7004)	Acc@1 88.672 (86.214)	Acc@5 100.000 (99.435)
Epoch: [39][128/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7628 (0.6943)	Acc@1 84.766 (86.389)	Acc@5 99.609 (99.434)
Epoch: [39][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6777 (0.6957)	Acc@1 86.719 (86.243)	Acc@5 99.609 (99.454)
Max memory in training epoch: 64.4680192
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.156 (0.156)	Data 0.286 (0.286)	Loss 0.7086 (0.7086)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [40][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.7038 (0.6773)	Acc@1 84.766 (86.671)	Acc@5 99.609 (99.501)
Epoch: [40][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7021 (0.6977)	Acc@1 86.328 (85.853)	Acc@5 98.828 (99.461)
Epoch: [40][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6366 (0.6961)	Acc@1 87.891 (85.970)	Acc@5 100.000 (99.456)
Max memory in training epoch: 64.4680192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 422718 ; 435712 ; 0.9701775484723855
[INFO] Storing checkpoint...
  78.57
Max memory: 100.3631104
 25.537s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1027
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1769984
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.192 (0.192)	Data 0.280 (0.280)	Loss 0.6201 (0.6201)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [41][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6550 (0.6627)	Acc@1 87.109 (86.917)	Acc@5 100.000 (99.525)
Epoch: [41][128/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.7076 (0.6837)	Acc@1 86.719 (86.537)	Acc@5 99.219 (99.434)
Epoch: [41][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6406 (0.6936)	Acc@1 87.891 (86.176)	Acc@5 99.609 (99.397)
Max memory in training epoch: 63.7659648
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.151 (0.151)	Data 0.292 (0.292)	Loss 0.5996 (0.5996)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [42][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.8064 (0.7004)	Acc@1 80.859 (85.865)	Acc@5 98.828 (99.453)
Epoch: [42][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7957 (0.6996)	Acc@1 83.594 (85.950)	Acc@5 98.438 (99.403)
Epoch: [42][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7463 (0.6951)	Acc@1 83.594 (85.935)	Acc@5 99.609 (99.447)
Max memory in training epoch: 63.8249472
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.161 (0.161)	Data 0.277 (0.277)	Loss 0.6866 (0.6866)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.6952 (0.6957)	Acc@1 83.594 (86.040)	Acc@5 100.000 (99.441)
Epoch: [43][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6738 (0.6985)	Acc@1 88.281 (85.889)	Acc@5 99.609 (99.406)
Epoch: [43][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6063 (0.6972)	Acc@1 87.891 (85.901)	Acc@5 100.000 (99.445)
Max memory in training epoch: 63.8249472
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.172 (0.172)	Data 0.307 (0.307)	Loss 0.6103 (0.6103)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.7824 (0.6697)	Acc@1 82.812 (87.001)	Acc@5 98.438 (99.453)
Epoch: [44][128/196]	Time 0.126 (0.132)	Data 0.000 (0.003)	Loss 0.6277 (0.6933)	Acc@1 87.109 (86.092)	Acc@5 99.609 (99.434)
Epoch: [44][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.6749 (0.6994)	Acc@1 86.719 (85.907)	Acc@5 100.000 (99.435)
Max memory in training epoch: 63.8249472
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.177 (0.177)	Data 0.279 (0.279)	Loss 0.6667 (0.6667)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6458 (0.6734)	Acc@1 88.672 (86.653)	Acc@5 99.609 (99.543)
Epoch: [45][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7379 (0.6885)	Acc@1 84.766 (85.998)	Acc@5 100.000 (99.491)
Epoch: [45][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6835 (0.6945)	Acc@1 87.109 (85.889)	Acc@5 99.609 (99.447)
Max memory in training epoch: 63.8249472
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 412034 ; 422718 ; 0.9747254670962675
[INFO] Storing checkpoint...
  80.05
Max memory: 98.626816
 25.582s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3575
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1726976
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.209 (0.209)	Data 0.253 (0.253)	Loss 0.7066 (0.7066)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6721 (0.6410)	Acc@1 86.328 (87.764)	Acc@5 99.219 (99.585)
Epoch: [46][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7467 (0.6629)	Acc@1 83.594 (87.028)	Acc@5 99.219 (99.546)
Epoch: [46][192/196]	Time 0.129 (0.130)	Data 0.000 (0.001)	Loss 0.7679 (0.6814)	Acc@1 83.203 (86.369)	Acc@5 98.828 (99.496)
Max memory in training epoch: 63.250688
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.189 (0.189)	Data 0.281 (0.281)	Loss 0.6952 (0.6952)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.5765 (0.6845)	Acc@1 90.625 (86.490)	Acc@5 99.609 (99.339)
Epoch: [47][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6318 (0.6888)	Acc@1 88.672 (86.207)	Acc@5 99.219 (99.400)
Epoch: [47][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8324 (0.6947)	Acc@1 82.422 (86.087)	Acc@5 99.609 (99.409)
Max memory in training epoch: 63.4931712
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.162 (0.162)	Data 0.314 (0.314)	Loss 0.6912 (0.6912)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.140 (0.131)	Data 0.000 (0.005)	Loss 0.7402 (0.6753)	Acc@1 82.812 (86.863)	Acc@5 100.000 (99.441)
Epoch: [48][128/196]	Time 0.129 (0.131)	Data 0.000 (0.003)	Loss 0.6660 (0.6861)	Acc@1 90.625 (86.540)	Acc@5 99.609 (99.413)
Epoch: [48][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6867 (0.6901)	Acc@1 86.719 (86.361)	Acc@5 99.219 (99.411)
Max memory in training epoch: 63.4604032
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.188 (0.188)	Data 0.258 (0.258)	Loss 0.7063 (0.7063)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.123 (0.131)	Data 0.000 (0.004)	Loss 0.5891 (0.6720)	Acc@1 89.844 (86.683)	Acc@5 100.000 (99.447)
Epoch: [49][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6497 (0.6758)	Acc@1 88.281 (86.464)	Acc@5 100.000 (99.455)
Epoch: [49][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7149 (0.6836)	Acc@1 87.109 (86.253)	Acc@5 99.609 (99.476)
Max memory in training epoch: 63.4604032
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.177 (0.177)	Data 0.268 (0.268)	Loss 0.6056 (0.6056)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [50][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.7375 (0.6799)	Acc@1 83.203 (86.286)	Acc@5 99.609 (99.537)
Epoch: [50][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7012 (0.6828)	Acc@1 85.547 (86.395)	Acc@5 99.219 (99.506)
Epoch: [50][192/196]	Time 0.135 (0.129)	Data 0.000 (0.002)	Loss 0.6624 (0.6863)	Acc@1 86.328 (86.314)	Acc@5 99.219 (99.482)
Max memory in training epoch: 63.4604032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 407416 ; 412034 ; 0.9887921870525248
[INFO] Storing checkpoint...
  81.87
Max memory: 97.8496
 25.713s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7166
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1709568
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.208 (0.208)	Data 0.281 (0.281)	Loss 0.6632 (0.6632)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [51][64/196]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.5797 (0.6499)	Acc@1 89.453 (87.488)	Acc@5 99.609 (99.435)
Epoch: [51][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7090 (0.6711)	Acc@1 84.375 (86.676)	Acc@5 98.828 (99.461)
Epoch: [51][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7588 (0.6794)	Acc@1 83.594 (86.433)	Acc@5 99.219 (99.433)
Max memory in training epoch: 63.0471168
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.179 (0.179)	Data 0.338 (0.338)	Loss 0.7433 (0.7433)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [52][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6357 (0.6884)	Acc@1 87.500 (86.635)	Acc@5 99.219 (99.537)
Epoch: [52][128/196]	Time 0.129 (0.129)	Data 0.000 (0.003)	Loss 0.7450 (0.6959)	Acc@1 84.766 (86.110)	Acc@5 99.609 (99.479)
Epoch: [52][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.6038 (0.6900)	Acc@1 89.453 (86.288)	Acc@5 100.000 (99.492)
Max memory in training epoch: 63.3747968
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.171 (0.171)	Data 0.298 (0.298)	Loss 0.6826 (0.6826)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [53][64/196]	Time 0.137 (0.133)	Data 0.000 (0.005)	Loss 0.6892 (0.6698)	Acc@1 86.719 (87.188)	Acc@5 100.000 (99.429)
Epoch: [53][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.6587 (0.6825)	Acc@1 87.500 (86.531)	Acc@5 99.609 (99.428)
Epoch: [53][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6777 (0.6844)	Acc@1 85.547 (86.413)	Acc@5 100.000 (99.417)
Max memory in training epoch: 63.3747968
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.192 (0.192)	Data 0.290 (0.290)	Loss 0.7371 (0.7371)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.7195 (0.6826)	Acc@1 85.547 (86.400)	Acc@5 99.609 (99.537)
Epoch: [54][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7053 (0.6812)	Acc@1 86.328 (86.389)	Acc@5 99.219 (99.482)
Epoch: [54][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.6728 (0.6768)	Acc@1 86.719 (86.561)	Acc@5 99.219 (99.488)
Max memory in training epoch: 63.3747968
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.177 (0.177)	Data 0.293 (0.293)	Loss 0.7358 (0.7358)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [55][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.6710 (0.6723)	Acc@1 86.719 (86.677)	Acc@5 98.828 (99.405)
Epoch: [55][128/196]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.6511 (0.6761)	Acc@1 86.719 (86.564)	Acc@5 100.000 (99.443)
Epoch: [55][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6568 (0.6783)	Acc@1 89.844 (86.448)	Acc@5 100.000 (99.458)
Max memory in training epoch: 63.3747968
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 396448 ; 407416 ; 0.9730791132405208
[INFO] Storing checkpoint...
  74.03
Max memory: 97.5445504
 25.638s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6229
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1665536
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.215 (0.215)	Data 0.259 (0.259)	Loss 0.7001 (0.7001)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.147 (0.130)	Data 0.000 (0.004)	Loss 0.6700 (0.6547)	Acc@1 87.891 (87.326)	Acc@5 99.609 (99.555)
Epoch: [56][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7182 (0.6690)	Acc@1 85.547 (86.586)	Acc@5 99.609 (99.512)
Epoch: [56][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6264 (0.6746)	Acc@1 87.891 (86.502)	Acc@5 99.609 (99.472)
Max memory in training epoch: 62.5641984
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.176 (0.176)	Data 0.255 (0.255)	Loss 0.6679 (0.6679)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [57][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.6345 (0.6625)	Acc@1 88.281 (86.755)	Acc@5 100.000 (99.447)
Epoch: [57][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7824 (0.6748)	Acc@1 85.156 (86.664)	Acc@5 99.219 (99.434)
Epoch: [57][192/196]	Time 0.133 (0.130)	Data 0.000 (0.001)	Loss 0.5958 (0.6754)	Acc@1 89.844 (86.694)	Acc@5 100.000 (99.419)
Max memory in training epoch: 63.1409152
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.179 (0.179)	Data 0.307 (0.307)	Loss 0.6484 (0.6484)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [58][64/196]	Time 0.132 (0.135)	Data 0.000 (0.005)	Loss 0.7551 (0.6616)	Acc@1 85.547 (87.290)	Acc@5 98.047 (99.297)
Epoch: [58][128/196]	Time 0.134 (0.132)	Data 0.000 (0.003)	Loss 0.6925 (0.6684)	Acc@1 84.766 (87.097)	Acc@5 99.609 (99.394)
Epoch: [58][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.6445 (0.6743)	Acc@1 89.844 (86.828)	Acc@5 98.828 (99.393)
Max memory in training epoch: 63.1409152
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.186 (0.186)	Data 0.269 (0.269)	Loss 0.5963 (0.5963)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [59][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.6616 (0.6715)	Acc@1 87.891 (86.851)	Acc@5 100.000 (99.495)
Epoch: [59][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7329 (0.6797)	Acc@1 86.719 (86.431)	Acc@5 99.219 (99.476)
Epoch: [59][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7048 (0.6843)	Acc@1 84.375 (86.346)	Acc@5 99.609 (99.437)
Max memory in training epoch: 63.1409152
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.172 (0.172)	Data 0.293 (0.293)	Loss 0.6454 (0.6454)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [60][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7255 (0.6775)	Acc@1 87.109 (86.556)	Acc@5 99.609 (99.519)
Epoch: [60][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6238 (0.6714)	Acc@1 87.891 (86.710)	Acc@5 100.000 (99.467)
Epoch: [60][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.5859 (0.6757)	Acc@1 90.234 (86.545)	Acc@5 100.000 (99.484)
Max memory in training epoch: 63.1409152
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 384612 ; 396448 ; 0.9701448865929454
[INFO] Storing checkpoint...
  80.18
Max memory: 97.2233216
 26.021s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7557
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1618432
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.185 (0.185)	Data 0.281 (0.281)	Loss 0.6758 (0.6758)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.6834 (0.6433)	Acc@1 85.156 (87.674)	Acc@5 99.609 (99.555)
Epoch: [61][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.6938 (0.6670)	Acc@1 85.156 (86.701)	Acc@5 99.219 (99.500)
Epoch: [61][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.5886 (0.6688)	Acc@1 90.234 (86.737)	Acc@5 100.000 (99.452)
Max memory in training epoch: 62.2045696
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.182 (0.182)	Data 0.284 (0.284)	Loss 0.6426 (0.6426)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.6098 (0.6647)	Acc@1 89.062 (87.242)	Acc@5 99.609 (99.423)
Epoch: [62][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6403 (0.6674)	Acc@1 90.625 (87.112)	Acc@5 99.609 (99.519)
Epoch: [62][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.5760 (0.6730)	Acc@1 88.672 (86.771)	Acc@5 100.000 (99.506)
Max memory in training epoch: 62.6371072
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.186 (0.186)	Data 0.264 (0.264)	Loss 0.7103 (0.7103)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.126 (0.133)	Data 0.000 (0.004)	Loss 0.7406 (0.6633)	Acc@1 83.984 (87.260)	Acc@5 99.609 (99.477)
Epoch: [63][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6191 (0.6643)	Acc@1 90.234 (86.961)	Acc@5 100.000 (99.482)
Epoch: [63][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7110 (0.6626)	Acc@1 85.938 (86.943)	Acc@5 98.828 (99.488)
Max memory in training epoch: 62.6371072
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.154 (0.154)	Data 0.286 (0.286)	Loss 0.6682 (0.6682)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [64][64/196]	Time 0.135 (0.130)	Data 0.000 (0.005)	Loss 0.6697 (0.6833)	Acc@1 85.547 (86.352)	Acc@5 99.609 (99.411)
Epoch: [64][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6470 (0.6741)	Acc@1 87.500 (86.570)	Acc@5 99.219 (99.446)
Epoch: [64][192/196]	Time 0.147 (0.130)	Data 0.000 (0.002)	Loss 0.6132 (0.6778)	Acc@1 88.281 (86.486)	Acc@5 100.000 (99.423)
Max memory in training epoch: 62.6371072
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.184 (0.184)	Data 0.281 (0.281)	Loss 0.7198 (0.7198)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [65][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.6756 (0.6614)	Acc@1 86.328 (87.224)	Acc@5 99.609 (99.501)
Epoch: [65][128/196]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.6520 (0.6658)	Acc@1 86.328 (86.970)	Acc@5 99.219 (99.497)
Epoch: [65][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.5892 (0.6644)	Acc@1 91.016 (87.032)	Acc@5 100.000 (99.508)
Max memory in training epoch: 62.6371072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 382302 ; 384612 ; 0.993993947146735
[INFO] Storing checkpoint...
  82.03
Max memory: 95.843584
 25.735s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 63
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1608192
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.203 (0.203)	Data 0.273 (0.273)	Loss 0.6572 (0.6572)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [66][64/196]	Time 0.124 (0.128)	Data 0.000 (0.004)	Loss 0.6783 (0.6512)	Acc@1 87.500 (87.049)	Acc@5 98.828 (99.597)
Epoch: [66][128/196]	Time 0.133 (0.127)	Data 0.000 (0.002)	Loss 0.7413 (0.6644)	Acc@1 82.031 (86.719)	Acc@5 99.609 (99.537)
Epoch: [66][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6026 (0.6658)	Acc@1 87.891 (86.652)	Acc@5 98.828 (99.516)
Max memory in training epoch: 62.128384
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.194 (0.194)	Data 0.299 (0.299)	Loss 0.6788 (0.6788)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [67][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6450 (0.6885)	Acc@1 87.891 (86.178)	Acc@5 99.609 (99.459)
Epoch: [67][128/196]	Time 0.129 (0.128)	Data 0.000 (0.003)	Loss 0.6339 (0.6792)	Acc@1 87.891 (86.516)	Acc@5 98.828 (99.500)
Epoch: [67][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6561 (0.6770)	Acc@1 87.109 (86.589)	Acc@5 99.609 (99.462)
Max memory in training epoch: 62.5805824
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.178 (0.178)	Data 0.286 (0.286)	Loss 0.7569 (0.7569)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.134 (0.128)	Data 0.000 (0.005)	Loss 0.6754 (0.6758)	Acc@1 85.156 (86.436)	Acc@5 99.219 (99.519)
Epoch: [68][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6011 (0.6670)	Acc@1 89.453 (86.873)	Acc@5 100.000 (99.570)
Epoch: [68][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6460 (0.6721)	Acc@1 87.891 (86.759)	Acc@5 99.219 (99.528)
Max memory in training epoch: 62.5805824
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.153 (0.153)	Data 0.299 (0.299)	Loss 0.7924 (0.7924)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [69][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6873 (0.6692)	Acc@1 85.938 (86.779)	Acc@5 100.000 (99.423)
Epoch: [69][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.6746 (0.6768)	Acc@1 85.938 (86.576)	Acc@5 99.219 (99.482)
Epoch: [69][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6473 (0.6733)	Acc@1 85.547 (86.731)	Acc@5 99.609 (99.486)
Max memory in training epoch: 62.5805824
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.179 (0.179)	Data 0.290 (0.290)	Loss 0.5950 (0.5950)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [70][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7462 (0.6598)	Acc@1 83.594 (86.815)	Acc@5 98.828 (99.531)
Epoch: [70][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6800 (0.6647)	Acc@1 85.547 (86.934)	Acc@5 99.219 (99.500)
Epoch: [70][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6965 (0.6671)	Acc@1 86.719 (86.875)	Acc@5 99.219 (99.480)
Max memory in training epoch: 62.5805824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 377682 ; 382302 ; 0.9879153130247814
[INFO] Storing checkpoint...
  79.37
Max memory: 95.738112
 25.402s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8794
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.158976
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.180 (0.180)	Data 0.262 (0.262)	Loss 0.5881 (0.5881)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [71][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.6513 (0.6414)	Acc@1 87.500 (87.626)	Acc@5 98.828 (99.525)
Epoch: [71][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.6698 (0.6554)	Acc@1 85.938 (87.103)	Acc@5 99.609 (99.528)
Epoch: [71][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.7287 (0.6577)	Acc@1 84.375 (87.028)	Acc@5 98.828 (99.512)
Max memory in training epoch: 61.911808
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.175 (0.175)	Data 0.279 (0.279)	Loss 0.6139 (0.6139)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.124 (0.129)	Data 0.000 (0.004)	Loss 0.6937 (0.6656)	Acc@1 88.672 (86.713)	Acc@5 99.219 (99.513)
Epoch: [72][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6548 (0.6615)	Acc@1 88.672 (86.988)	Acc@5 99.219 (99.509)
Epoch: [72][192/196]	Time 0.144 (0.130)	Data 0.000 (0.002)	Loss 0.6075 (0.6582)	Acc@1 87.891 (87.166)	Acc@5 100.000 (99.522)
Max memory in training epoch: 62.4749056
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.153 (0.153)	Data 0.287 (0.287)	Loss 0.6834 (0.6834)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.140 (0.129)	Data 0.000 (0.005)	Loss 0.7115 (0.6674)	Acc@1 85.938 (86.490)	Acc@5 99.609 (99.459)
Epoch: [73][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7088 (0.6686)	Acc@1 84.375 (86.567)	Acc@5 99.219 (99.449)
Epoch: [73][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6021 (0.6701)	Acc@1 88.672 (86.498)	Acc@5 99.219 (99.456)
Max memory in training epoch: 62.4749056
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.146 (0.146)	Data 0.293 (0.293)	Loss 0.5904 (0.5904)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.122 (0.128)	Data 0.000 (0.005)	Loss 0.6037 (0.6432)	Acc@1 86.328 (87.560)	Acc@5 100.000 (99.555)
Epoch: [74][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7048 (0.6450)	Acc@1 86.328 (87.415)	Acc@5 98.828 (99.519)
Epoch: [74][192/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.7395 (0.6583)	Acc@1 83.984 (87.018)	Acc@5 99.219 (99.530)
Max memory in training epoch: 62.4749056
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.162 (0.162)	Data 0.296 (0.296)	Loss 0.6889 (0.6889)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.149 (0.129)	Data 0.000 (0.005)	Loss 0.5718 (0.6536)	Acc@1 90.625 (87.169)	Acc@5 99.219 (99.483)
Epoch: [75][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7304 (0.6667)	Acc@1 87.500 (86.928)	Acc@5 99.609 (99.470)
Epoch: [75][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7117 (0.6637)	Acc@1 85.547 (87.037)	Acc@5 99.219 (99.496)
Max memory in training epoch: 62.4749056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 376236 ; 377682 ; 0.9961713822739765
[INFO] Storing checkpoint...
  82.16
Max memory: 95.8771712
 25.391s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6344
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.158464
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.178 (0.178)	Data 0.288 (0.288)	Loss 0.5609 (0.5609)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.6200 (0.6362)	Acc@1 88.281 (87.825)	Acc@5 100.000 (99.537)
Epoch: [76][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6661 (0.6545)	Acc@1 87.109 (87.152)	Acc@5 100.000 (99.525)
Epoch: [76][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6276 (0.6565)	Acc@1 85.938 (87.067)	Acc@5 99.609 (99.539)
Max memory in training epoch: 61.6208896
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.175 (0.175)	Data 0.283 (0.283)	Loss 0.6035 (0.6035)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.6688 (0.6562)	Acc@1 85.156 (87.236)	Acc@5 98.828 (99.495)
Epoch: [77][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.5842 (0.6610)	Acc@1 89.453 (87.088)	Acc@5 100.000 (99.470)
Epoch: [77][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.5836 (0.6573)	Acc@1 87.500 (87.136)	Acc@5 100.000 (99.458)
Max memory in training epoch: 61.6733184
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.166 (0.166)	Data 0.294 (0.294)	Loss 0.6276 (0.6276)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [78][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6352 (0.6605)	Acc@1 87.109 (86.785)	Acc@5 99.609 (99.531)
Epoch: [78][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.6705 (0.6574)	Acc@1 86.328 (87.064)	Acc@5 98.438 (99.497)
Epoch: [78][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7802 (0.6651)	Acc@1 82.812 (86.893)	Acc@5 98.047 (99.472)
Max memory in training epoch: 61.6733184
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.157 (0.157)	Data 0.330 (0.330)	Loss 0.6260 (0.6260)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.137 (0.131)	Data 0.000 (0.005)	Loss 0.6106 (0.6450)	Acc@1 89.062 (87.500)	Acc@5 99.609 (99.531)
Epoch: [79][128/196]	Time 0.130 (0.130)	Data 0.000 (0.003)	Loss 0.7063 (0.6509)	Acc@1 83.984 (87.240)	Acc@5 100.000 (99.516)
Epoch: [79][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6308 (0.6560)	Acc@1 87.500 (87.024)	Acc@5 100.000 (99.543)
Max memory in training epoch: 61.6733184
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.162 (0.162)	Data 0.311 (0.311)	Loss 0.5541 (0.5541)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.123 (0.129)	Data 0.000 (0.005)	Loss 0.7390 (0.6643)	Acc@1 85.938 (86.893)	Acc@5 98.828 (99.489)
Epoch: [80][128/196]	Time 0.130 (0.128)	Data 0.000 (0.003)	Loss 0.6073 (0.6622)	Acc@1 89.844 (86.891)	Acc@5 100.000 (99.522)
Epoch: [80][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6955 (0.6581)	Acc@1 87.500 (86.984)	Acc@5 98.438 (99.524)
Max memory in training epoch: 61.6733184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 371758 ; 376236 ; 0.9880978960014459
[INFO] Storing checkpoint...
  80.31
Max memory: 95.3775616
 25.508s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7418
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1567744
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.205 (0.205)	Data 0.254 (0.254)	Loss 0.5975 (0.5975)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.6665 (0.6285)	Acc@1 87.891 (88.137)	Acc@5 99.609 (99.597)
Epoch: [81][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6778 (0.6473)	Acc@1 85.938 (87.400)	Acc@5 99.219 (99.561)
Epoch: [81][192/196]	Time 0.126 (0.129)	Data 0.000 (0.001)	Loss 0.6964 (0.6500)	Acc@1 84.375 (87.296)	Acc@5 99.609 (99.534)
Max memory in training epoch: 60.7752704
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.189 (0.189)	Data 0.286 (0.286)	Loss 0.6265 (0.6265)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.136 (0.133)	Data 0.000 (0.005)	Loss 0.7075 (0.6573)	Acc@1 86.719 (86.953)	Acc@5 99.609 (99.459)
Epoch: [82][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6087 (0.6585)	Acc@1 87.891 (86.849)	Acc@5 100.000 (99.485)
Epoch: [82][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6601 (0.6608)	Acc@1 86.719 (86.881)	Acc@5 100.000 (99.490)
Max memory in training epoch: 60.749056
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.181 (0.181)	Data 0.291 (0.291)	Loss 0.6903 (0.6903)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [83][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6139 (0.6537)	Acc@1 89.453 (87.284)	Acc@5 99.219 (99.459)
Epoch: [83][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6323 (0.6577)	Acc@1 87.500 (87.085)	Acc@5 98.828 (99.461)
Epoch: [83][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7580 (0.6604)	Acc@1 82.422 (86.972)	Acc@5 99.219 (99.458)
Max memory in training epoch: 60.7359488
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.162 (0.162)	Data 0.290 (0.290)	Loss 0.5495 (0.5495)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.129 (0.127)	Data 0.000 (0.005)	Loss 0.6430 (0.6543)	Acc@1 87.109 (86.929)	Acc@5 100.000 (99.537)
Epoch: [84][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6273 (0.6580)	Acc@1 88.672 (86.858)	Acc@5 99.609 (99.546)
Epoch: [84][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6449 (0.6568)	Acc@1 87.109 (86.945)	Acc@5 99.609 (99.534)
Max memory in training epoch: 60.7359488
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.174 (0.174)	Data 0.260 (0.260)	Loss 0.6869 (0.6869)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.144 (0.128)	Data 0.000 (0.004)	Loss 0.6536 (0.6503)	Acc@1 88.672 (87.224)	Acc@5 98.828 (99.561)
Epoch: [85][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.6101 (0.6586)	Acc@1 88.672 (87.006)	Acc@5 99.609 (99.482)
Epoch: [85][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7326 (0.6586)	Acc@1 86.328 (87.006)	Acc@5 100.000 (99.488)
Max memory in training epoch: 60.7359488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 369448 ; 371758 ; 0.993786280322145
[INFO] Storing checkpoint...
  79.95
Max memory: 94.4611328
 25.276s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 535
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1558528
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.205 (0.205)	Data 0.258 (0.258)	Loss 0.6950 (0.6950)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.6081 (0.6207)	Acc@1 88.281 (88.203)	Acc@5 99.219 (99.585)
Epoch: [86][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.6174 (0.6417)	Acc@1 88.281 (87.445)	Acc@5 99.609 (99.516)
Epoch: [86][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.5290 (0.6488)	Acc@1 93.359 (87.287)	Acc@5 99.609 (99.504)
Max memory in training epoch: 60.6011904
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.173 (0.173)	Data 0.321 (0.321)	Loss 0.6987 (0.6987)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [87][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6555 (0.6487)	Acc@1 87.500 (87.157)	Acc@5 99.609 (99.423)
Epoch: [87][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.7412 (0.6522)	Acc@1 82.422 (86.970)	Acc@5 98.828 (99.446)
Epoch: [87][192/196]	Time 0.141 (0.128)	Data 0.000 (0.002)	Loss 0.6878 (0.6585)	Acc@1 86.328 (86.846)	Acc@5 99.609 (99.427)
Max memory in training epoch: 60.706048
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.188 (0.188)	Data 0.256 (0.256)	Loss 0.6478 (0.6478)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.7883 (0.6645)	Acc@1 84.766 (87.073)	Acc@5 98.438 (99.471)
Epoch: [88][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6182 (0.6568)	Acc@1 87.891 (87.167)	Acc@5 99.609 (99.497)
Epoch: [88][192/196]	Time 0.123 (0.126)	Data 0.000 (0.001)	Loss 0.6526 (0.6614)	Acc@1 89.453 (86.941)	Acc@5 99.609 (99.494)
Max memory in training epoch: 60.706048
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.170 (0.170)	Data 0.287 (0.287)	Loss 0.6852 (0.6852)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [89][64/196]	Time 0.139 (0.128)	Data 0.000 (0.005)	Loss 0.6097 (0.6511)	Acc@1 89.453 (87.194)	Acc@5 99.609 (99.543)
Epoch: [89][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6875 (0.6565)	Acc@1 84.375 (86.928)	Acc@5 99.219 (99.531)
Epoch: [89][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6522 (0.6577)	Acc@1 86.719 (86.889)	Acc@5 100.000 (99.551)
Max memory in training epoch: 60.706048
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.150 (0.150)	Data 0.294 (0.294)	Loss 0.6418 (0.6418)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.6049 (0.6601)	Acc@1 90.625 (87.019)	Acc@5 100.000 (99.591)
Epoch: [90][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7055 (0.6528)	Acc@1 86.719 (87.161)	Acc@5 100.000 (99.591)
Epoch: [90][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.7852 (0.6559)	Acc@1 82.031 (87.037)	Acc@5 98.438 (99.512)
Max memory in training epoch: 60.706048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 368516 ; 369448 ; 0.9974773175115307
[INFO] Storing checkpoint...
  83.69
Max memory: 94.3526912
 25.043s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7439
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1549312
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.195 (0.195)	Data 0.259 (0.259)	Loss 0.6288 (0.6288)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.6758 (0.6225)	Acc@1 86.719 (88.167)	Acc@5 99.609 (99.591)
Epoch: [91][128/196]	Time 0.130 (0.124)	Data 0.000 (0.002)	Loss 0.6662 (0.6376)	Acc@1 86.328 (87.742)	Acc@5 99.609 (99.567)
Epoch: [91][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.6707 (0.6437)	Acc@1 86.719 (87.427)	Acc@5 100.000 (99.549)
Max memory in training epoch: 58.5799168
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.169 (0.169)	Data 0.295 (0.295)	Loss 0.6515 (0.6515)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [92][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.7432 (0.6411)	Acc@1 84.766 (87.422)	Acc@5 99.609 (99.567)
Epoch: [92][128/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.6817 (0.6483)	Acc@1 86.328 (87.273)	Acc@5 99.609 (99.522)
Epoch: [92][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6262 (0.6559)	Acc@1 88.672 (87.032)	Acc@5 99.609 (99.468)
Max memory in training epoch: 58.4488448
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.6552 (0.6552)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [93][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.5472 (0.5604)	Acc@1 91.406 (90.571)	Acc@5 99.219 (99.802)
Epoch: [93][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.4826 (0.5323)	Acc@1 92.188 (91.455)	Acc@5 99.609 (99.797)
Epoch: [93][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.4655 (0.5211)	Acc@1 93.359 (91.833)	Acc@5 100.000 (99.783)
Max memory in training epoch: 58.4357376
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.4265 (0.4265)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.4637 (0.4721)	Acc@1 95.312 (93.209)	Acc@5 99.609 (99.826)
Epoch: [94][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.4686 (0.4694)	Acc@1 93.359 (93.250)	Acc@5 100.000 (99.840)
Epoch: [94][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.5068 (0.4683)	Acc@1 91.797 (93.293)	Acc@5 99.219 (99.852)
Max memory in training epoch: 58.4357376
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.151 (0.151)	Data 0.289 (0.289)	Loss 0.4545 (0.4545)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.3970 (0.4474)	Acc@1 96.094 (93.996)	Acc@5 99.609 (99.916)
Epoch: [95][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.4291 (0.4469)	Acc@1 94.531 (93.953)	Acc@5 99.609 (99.915)
Epoch: [95][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.4153 (0.4459)	Acc@1 96.094 (93.950)	Acc@5 99.609 (99.903)
Max memory in training epoch: 58.4357376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 367648 ; 368516 ; 0.9976446070184198
[INFO] Storing checkpoint...
  91.29
Max memory: 90.8312576
 24.361s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3229
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.154624
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.192 (0.192)	Data 0.260 (0.260)	Loss 0.3772 (0.3772)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.4152 (0.4254)	Acc@1 94.531 (94.645)	Acc@5 100.000 (99.862)
Epoch: [96][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.4130 (0.4277)	Acc@1 95.703 (94.519)	Acc@5 100.000 (99.885)
Epoch: [96][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.4418 (0.4278)	Acc@1 93.750 (94.420)	Acc@5 99.609 (99.891)
Max memory in training epoch: 58.3689728
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.170 (0.170)	Data 0.290 (0.290)	Loss 0.3896 (0.3896)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.4410 (0.4087)	Acc@1 94.531 (95.048)	Acc@5 100.000 (99.916)
Epoch: [97][128/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.4131 (0.4135)	Acc@1 95.703 (94.770)	Acc@5 100.000 (99.891)
Epoch: [97][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.4145 (0.4132)	Acc@1 94.141 (94.770)	Acc@5 100.000 (99.889)
Max memory in training epoch: 58.1789184
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.169 (0.169)	Data 0.287 (0.287)	Loss 0.4086 (0.4086)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.4024 (0.3907)	Acc@1 92.969 (95.331)	Acc@5 100.000 (99.898)
Epoch: [98][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3807 (0.3958)	Acc@1 94.531 (95.176)	Acc@5 100.000 (99.894)
Epoch: [98][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.4211 (0.3997)	Acc@1 94.531 (95.007)	Acc@5 99.609 (99.887)
Max memory in training epoch: 58.1789184
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.149 (0.149)	Data 0.265 (0.265)	Loss 0.3397 (0.3397)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.136 (0.121)	Data 0.000 (0.004)	Loss 0.3693 (0.3838)	Acc@1 96.094 (95.481)	Acc@5 100.000 (99.922)
Epoch: [99][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3712 (0.3845)	Acc@1 95.703 (95.418)	Acc@5 100.000 (99.921)
Epoch: [99][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.3499 (0.3863)	Acc@1 95.312 (95.280)	Acc@5 100.000 (99.923)
Max memory in training epoch: 58.1789184
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.142 (0.142)	Data 0.294 (0.294)	Loss 0.3593 (0.3593)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.3888 (0.3730)	Acc@1 94.141 (95.607)	Acc@5 100.000 (99.940)
Epoch: [100][128/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.4159 (0.3748)	Acc@1 93.750 (95.534)	Acc@5 100.000 (99.942)
Epoch: [100][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3401 (0.3770)	Acc@1 96.094 (95.440)	Acc@5 100.000 (99.937)
Max memory in training epoch: 58.1789184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.23
Max memory: 90.5329664
 23.917s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6932
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.154624
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.199 (0.199)	Data 0.256 (0.256)	Loss 0.3837 (0.3837)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.3354 (0.3649)	Acc@1 96.484 (95.763)	Acc@5 100.000 (99.916)
Epoch: [101][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.3571 (0.3659)	Acc@1 93.359 (95.749)	Acc@5 100.000 (99.918)
Epoch: [101][192/196]	Time 0.118 (0.124)	Data 0.000 (0.001)	Loss 0.3680 (0.3685)	Acc@1 96.875 (95.596)	Acc@5 100.000 (99.927)
Max memory in training epoch: 58.3689728
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.174 (0.174)	Data 0.296 (0.296)	Loss 0.3648 (0.3648)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.3330 (0.3623)	Acc@1 96.484 (95.763)	Acc@5 100.000 (99.910)
Epoch: [102][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3533 (0.3592)	Acc@1 96.094 (95.700)	Acc@5 100.000 (99.933)
Epoch: [102][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.3263 (0.3603)	Acc@1 98.047 (95.659)	Acc@5 100.000 (99.939)
Max memory in training epoch: 58.1789184
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.168 (0.168)	Data 0.274 (0.274)	Loss 0.3361 (0.3361)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.3331 (0.3448)	Acc@1 97.266 (96.196)	Acc@5 100.000 (99.958)
Epoch: [103][128/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3402 (0.3458)	Acc@1 96.484 (96.127)	Acc@5 99.609 (99.949)
Epoch: [103][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.3882 (0.3496)	Acc@1 93.750 (95.857)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.1789184
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.161 (0.161)	Data 0.262 (0.262)	Loss 0.3401 (0.3401)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.3853 (0.3458)	Acc@1 94.922 (96.052)	Acc@5 100.000 (99.928)
Epoch: [104][128/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.3054 (0.3433)	Acc@1 97.266 (96.115)	Acc@5 100.000 (99.945)
Epoch: [104][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3357 (0.3445)	Acc@1 96.094 (96.045)	Acc@5 100.000 (99.953)
Max memory in training epoch: 58.1789184
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.142 (0.142)	Data 0.278 (0.278)	Loss 0.3442 (0.3442)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.3223 (0.3332)	Acc@1 96.484 (96.442)	Acc@5 100.000 (99.958)
Epoch: [105][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3444 (0.3351)	Acc@1 94.531 (96.260)	Acc@5 100.000 (99.955)
Epoch: [105][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3302 (0.3376)	Acc@1 95.703 (96.116)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.1789184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 367358 ; 367648 ; 0.9992112020193228
[INFO] Storing checkpoint...
  91.31
Max memory: 90.5329664
 24.301s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1886
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.200 (0.200)	Data 0.253 (0.253)	Loss 0.3049 (0.3049)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.3542 (0.3216)	Acc@1 95.703 (96.575)	Acc@5 99.609 (99.946)
Epoch: [106][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3766 (0.3262)	Acc@1 93.750 (96.375)	Acc@5 100.000 (99.939)
Epoch: [106][192/196]	Time 0.120 (0.124)	Data 0.000 (0.001)	Loss 0.3726 (0.3286)	Acc@1 94.141 (96.314)	Acc@5 100.000 (99.949)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.177 (0.177)	Data 0.262 (0.262)	Loss 0.3255 (0.3255)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.4068 (0.3244)	Acc@1 94.141 (96.430)	Acc@5 100.000 (99.976)
Epoch: [107][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2971 (0.3250)	Acc@1 97.266 (96.391)	Acc@5 100.000 (99.958)
Epoch: [107][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2864 (0.3275)	Acc@1 98.047 (96.231)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.171 (0.171)	Data 0.289 (0.289)	Loss 0.3115 (0.3115)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [108][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.2764 (0.3131)	Acc@1 98.438 (96.593)	Acc@5 100.000 (99.958)
Epoch: [108][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2983 (0.3143)	Acc@1 96.875 (96.515)	Acc@5 100.000 (99.952)
Epoch: [108][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.3179 (0.3161)	Acc@1 96.094 (96.486)	Acc@5 100.000 (99.955)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.171 (0.171)	Data 0.310 (0.310)	Loss 0.2967 (0.2967)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.3281 (0.3106)	Acc@1 97.656 (96.611)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.127 (0.121)	Data 0.000 (0.003)	Loss 0.3639 (0.3141)	Acc@1 92.578 (96.415)	Acc@5 99.609 (99.964)
Epoch: [109][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3576 (0.3172)	Acc@1 95.312 (96.296)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.186 (0.186)	Data 0.260 (0.260)	Loss 0.2921 (0.2921)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.3273 (0.3119)	Acc@1 96.094 (96.460)	Acc@5 100.000 (99.940)
Epoch: [110][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2738 (0.3110)	Acc@1 97.656 (96.433)	Acc@5 100.000 (99.964)
Epoch: [110][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2779 (0.3117)	Acc@1 97.656 (96.434)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.82
Max memory: 90.0112384
 24.058s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4588
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.184 (0.184)	Data 0.294 (0.294)	Loss 0.2923 (0.2923)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.3415 (0.2989)	Acc@1 95.312 (96.869)	Acc@5 100.000 (99.952)
Epoch: [111][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3014 (0.3023)	Acc@1 96.875 (96.693)	Acc@5 100.000 (99.958)
Epoch: [111][192/196]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.3147 (0.3060)	Acc@1 96.094 (96.531)	Acc@5 100.000 (99.960)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.159 (0.159)	Data 0.296 (0.296)	Loss 0.2734 (0.2734)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2895 (0.3065)	Acc@1 97.266 (96.454)	Acc@5 100.000 (99.964)
Epoch: [112][128/196]	Time 0.131 (0.123)	Data 0.000 (0.002)	Loss 0.2751 (0.3074)	Acc@1 98.047 (96.315)	Acc@5 100.000 (99.970)
Epoch: [112][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.2960 (0.3068)	Acc@1 96.875 (96.329)	Acc@5 100.000 (99.957)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.144 (0.144)	Data 0.271 (0.271)	Loss 0.3177 (0.3177)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.125 (0.122)	Data 0.000 (0.004)	Loss 0.3306 (0.2950)	Acc@1 96.094 (96.851)	Acc@5 100.000 (99.970)
Epoch: [113][128/196]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.3420 (0.2989)	Acc@1 94.531 (96.557)	Acc@5 99.609 (99.970)
Epoch: [113][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3334 (0.3005)	Acc@1 96.094 (96.501)	Acc@5 99.609 (99.968)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.150 (0.150)	Data 0.294 (0.294)	Loss 0.2898 (0.2898)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.2719 (0.2978)	Acc@1 97.656 (96.538)	Acc@5 100.000 (99.982)
Epoch: [114][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2688 (0.2994)	Acc@1 98.047 (96.442)	Acc@5 100.000 (99.976)
Epoch: [114][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3260 (0.2998)	Acc@1 95.703 (96.403)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.153 (0.153)	Data 0.265 (0.265)	Loss 0.3555 (0.3555)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [115][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.3028 (0.2953)	Acc@1 97.266 (96.635)	Acc@5 100.000 (99.976)
Epoch: [115][128/196]	Time 0.128 (0.121)	Data 0.000 (0.002)	Loss 0.2571 (0.2952)	Acc@1 97.656 (96.545)	Acc@5 100.000 (99.976)
Epoch: [115][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.2949 (0.2977)	Acc@1 94.922 (96.428)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.86
Max memory: 90.0112384
 24.166s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4325
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.194 (0.194)	Data 0.354 (0.354)	Loss 0.2998 (0.2998)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.123 (0.125)	Data 0.000 (0.006)	Loss 0.3182 (0.2869)	Acc@1 95.703 (96.767)	Acc@5 100.000 (99.970)
Epoch: [116][128/196]	Time 0.123 (0.125)	Data 0.000 (0.003)	Loss 0.2815 (0.2918)	Acc@1 96.094 (96.657)	Acc@5 100.000 (99.970)
Epoch: [116][192/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.2779 (0.2948)	Acc@1 96.484 (96.497)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.144 (0.144)	Data 0.266 (0.266)	Loss 0.2879 (0.2879)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.125 (0.122)	Data 0.000 (0.004)	Loss 0.2841 (0.2921)	Acc@1 96.875 (96.713)	Acc@5 100.000 (99.988)
Epoch: [117][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2898 (0.2926)	Acc@1 96.094 (96.624)	Acc@5 100.000 (99.979)
Epoch: [117][192/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.2660 (0.2958)	Acc@1 98.047 (96.428)	Acc@5 100.000 (99.978)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.158 (0.158)	Data 0.265 (0.265)	Loss 0.2657 (0.2657)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.2663 (0.2833)	Acc@1 97.266 (96.725)	Acc@5 100.000 (99.982)
Epoch: [118][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2663 (0.2870)	Acc@1 97.656 (96.578)	Acc@5 100.000 (99.967)
Epoch: [118][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2896 (0.2896)	Acc@1 97.266 (96.533)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.167 (0.167)	Data 0.296 (0.296)	Loss 0.2554 (0.2554)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.2742 (0.2838)	Acc@1 98.047 (96.617)	Acc@5 100.000 (99.988)
Epoch: [119][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2557 (0.2876)	Acc@1 98.047 (96.484)	Acc@5 100.000 (99.985)
Epoch: [119][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.3211 (0.2909)	Acc@1 94.531 (96.361)	Acc@5 99.609 (99.976)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.173 (0.173)	Data 0.276 (0.276)	Loss 0.2723 (0.2723)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.135 (0.123)	Data 0.000 (0.004)	Loss 0.3080 (0.2904)	Acc@1 94.922 (96.406)	Acc@5 100.000 (99.982)
Epoch: [120][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2915 (0.2899)	Acc@1 96.094 (96.394)	Acc@5 100.000 (99.979)
Epoch: [120][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.3032 (0.2936)	Acc@1 95.703 (96.209)	Acc@5 100.000 (99.978)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.78
Max memory: 90.0112384
 24.346s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1093
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.193 (0.193)	Data 0.298 (0.298)	Loss 0.3112 (0.3112)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2854 (0.2772)	Acc@1 96.484 (96.917)	Acc@5 100.000 (99.964)
Epoch: [121][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.3085 (0.2818)	Acc@1 95.312 (96.739)	Acc@5 100.000 (99.958)
Epoch: [121][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.2827 (0.2870)	Acc@1 96.875 (96.517)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.173 (0.173)	Data 0.288 (0.288)	Loss 0.2633 (0.2633)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.2501 (0.2815)	Acc@1 96.094 (96.629)	Acc@5 100.000 (99.976)
Epoch: [122][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.3370 (0.2844)	Acc@1 93.750 (96.500)	Acc@5 100.000 (99.982)
Epoch: [122][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2726 (0.2886)	Acc@1 96.484 (96.335)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.199 (0.199)	Data 0.295 (0.295)	Loss 0.2710 (0.2710)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.3225 (0.2877)	Acc@1 94.922 (96.454)	Acc@5 100.000 (99.952)
Epoch: [123][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2879 (0.2898)	Acc@1 95.703 (96.230)	Acc@5 100.000 (99.961)
Epoch: [123][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3092 (0.2910)	Acc@1 96.094 (96.217)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.167 (0.167)	Data 0.267 (0.267)	Loss 0.2952 (0.2952)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.3280 (0.2880)	Acc@1 94.922 (96.328)	Acc@5 99.609 (99.958)
Epoch: [124][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3366 (0.2910)	Acc@1 94.922 (96.200)	Acc@5 100.000 (99.961)
Epoch: [124][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2530 (0.2916)	Acc@1 97.656 (96.144)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.138 (0.138)	Data 0.302 (0.302)	Loss 0.3048 (0.3048)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.2769 (0.2852)	Acc@1 96.484 (96.310)	Acc@5 100.000 (99.994)
Epoch: [125][128/196]	Time 0.119 (0.120)	Data 0.000 (0.003)	Loss 0.2964 (0.2864)	Acc@1 95.703 (96.236)	Acc@5 99.609 (99.988)
Epoch: [125][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2991 (0.2872)	Acc@1 93.750 (96.201)	Acc@5 100.000 (99.990)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.68
Max memory: 90.0112384
 23.977s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7195
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.184 (0.184)	Data 0.279 (0.279)	Loss 0.2806 (0.2806)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.2982 (0.2793)	Acc@1 95.703 (96.442)	Acc@5 100.000 (99.964)
Epoch: [126][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2862 (0.2834)	Acc@1 97.266 (96.321)	Acc@5 100.000 (99.979)
Epoch: [126][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2812 (0.2839)	Acc@1 96.094 (96.296)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.172 (0.172)	Data 0.300 (0.300)	Loss 0.2452 (0.2452)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2752 (0.2828)	Acc@1 96.875 (96.364)	Acc@5 100.000 (99.976)
Epoch: [127][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.2925 (0.2876)	Acc@1 95.703 (96.154)	Acc@5 100.000 (99.976)
Epoch: [127][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3570 (0.2909)	Acc@1 94.531 (96.013)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.178 (0.178)	Data 0.270 (0.270)	Loss 0.2930 (0.2930)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.3035 (0.2780)	Acc@1 96.094 (96.508)	Acc@5 100.000 (99.976)
Epoch: [128][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2772 (0.2824)	Acc@1 96.875 (96.315)	Acc@5 100.000 (99.982)
Epoch: [128][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3663 (0.2873)	Acc@1 92.578 (96.201)	Acc@5 100.000 (99.980)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.166 (0.166)	Data 0.310 (0.310)	Loss 0.2664 (0.2664)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.2661 (0.2820)	Acc@1 97.656 (96.346)	Acc@5 100.000 (99.976)
Epoch: [129][128/196]	Time 0.128 (0.121)	Data 0.000 (0.003)	Loss 0.2940 (0.2824)	Acc@1 95.703 (96.245)	Acc@5 99.609 (99.970)
Epoch: [129][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3745 (0.2878)	Acc@1 91.406 (96.090)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.178 (0.178)	Data 0.297 (0.297)	Loss 0.2725 (0.2725)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.3121 (0.2901)	Acc@1 94.922 (96.100)	Acc@5 100.000 (99.940)
Epoch: [130][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.2864 (0.2897)	Acc@1 95.703 (96.109)	Acc@5 100.000 (99.958)
Epoch: [130][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3320 (0.2904)	Acc@1 95.312 (96.076)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.26
Max memory: 90.0112384
 24.164s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1316
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.198 (0.198)	Data 0.294 (0.294)	Loss 0.2753 (0.2753)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.131 (0.125)	Data 0.000 (0.005)	Loss 0.2670 (0.2729)	Acc@1 96.875 (96.587)	Acc@5 100.000 (99.976)
Epoch: [131][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.2340 (0.2727)	Acc@1 98.047 (96.612)	Acc@5 100.000 (99.976)
Epoch: [131][192/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.2391 (0.2783)	Acc@1 98.438 (96.428)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.158 (0.158)	Data 0.282 (0.282)	Loss 0.2582 (0.2582)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.122 (0.125)	Data 0.000 (0.004)	Loss 0.2543 (0.2770)	Acc@1 96.484 (96.538)	Acc@5 100.000 (99.958)
Epoch: [132][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.2858 (0.2823)	Acc@1 96.484 (96.303)	Acc@5 100.000 (99.970)
Epoch: [132][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.2924 (0.2852)	Acc@1 95.312 (96.098)	Acc@5 99.609 (99.968)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.168 (0.168)	Data 0.320 (0.320)	Loss 0.2455 (0.2455)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.2649 (0.2810)	Acc@1 96.484 (96.256)	Acc@5 100.000 (99.982)
Epoch: [133][128/196]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.2877 (0.2840)	Acc@1 94.922 (96.176)	Acc@5 100.000 (99.979)
Epoch: [133][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2874 (0.2909)	Acc@1 96.484 (96.031)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.187 (0.187)	Data 0.272 (0.272)	Loss 0.3055 (0.3055)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.2305 (0.2890)	Acc@1 98.047 (95.962)	Acc@5 100.000 (99.946)
Epoch: [134][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3091 (0.2827)	Acc@1 93.359 (96.218)	Acc@5 100.000 (99.961)
Epoch: [134][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.3353 (0.2881)	Acc@1 94.141 (95.974)	Acc@5 100.000 (99.960)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.171 (0.171)	Data 0.300 (0.300)	Loss 0.3080 (0.3080)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.2701 (0.2738)	Acc@1 97.266 (96.611)	Acc@5 100.000 (99.994)
Epoch: [135][128/196]	Time 0.116 (0.123)	Data 0.000 (0.003)	Loss 0.2586 (0.2787)	Acc@1 97.656 (96.363)	Acc@5 100.000 (99.991)
Epoch: [135][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.3268 (0.2858)	Acc@1 93.359 (96.118)	Acc@5 100.000 (99.986)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  86.8
Max memory: 90.0112384
 24.292s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 403
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.162 (0.162)	Data 0.303 (0.303)	Loss 0.2847 (0.2847)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2652 (0.2740)	Acc@1 96.094 (96.490)	Acc@5 100.000 (99.976)
Epoch: [136][128/196]	Time 0.136 (0.121)	Data 0.000 (0.003)	Loss 0.2828 (0.2768)	Acc@1 96.094 (96.436)	Acc@5 100.000 (99.967)
Epoch: [136][192/196]	Time 0.130 (0.121)	Data 0.000 (0.002)	Loss 0.2636 (0.2800)	Acc@1 96.094 (96.312)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.172 (0.172)	Data 0.270 (0.270)	Loss 0.2905 (0.2905)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2617 (0.2788)	Acc@1 96.875 (96.262)	Acc@5 100.000 (99.976)
Epoch: [137][128/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.2326 (0.2836)	Acc@1 98.047 (96.136)	Acc@5 100.000 (99.967)
Epoch: [137][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.2981 (0.2840)	Acc@1 93.359 (96.106)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.150 (0.150)	Data 0.290 (0.290)	Loss 0.2470 (0.2470)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.2702 (0.2809)	Acc@1 95.703 (96.232)	Acc@5 100.000 (99.964)
Epoch: [138][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.3574 (0.2818)	Acc@1 92.969 (96.179)	Acc@5 100.000 (99.970)
Epoch: [138][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.2844 (0.2872)	Acc@1 96.875 (96.013)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.183 (0.183)	Data 0.287 (0.287)	Loss 0.2998 (0.2998)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.2408 (0.2845)	Acc@1 98.438 (96.166)	Acc@5 100.000 (99.988)
Epoch: [139][128/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.3325 (0.2841)	Acc@1 93.359 (96.142)	Acc@5 100.000 (99.973)
Epoch: [139][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2654 (0.2877)	Acc@1 97.266 (95.944)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.159 (0.159)	Data 0.278 (0.278)	Loss 0.2396 (0.2396)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.2851 (0.2876)	Acc@1 94.922 (95.962)	Acc@5 100.000 (99.988)
Epoch: [140][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2678 (0.2903)	Acc@1 96.094 (95.855)	Acc@5 100.000 (99.985)
Epoch: [140][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2777 (0.2889)	Acc@1 95.703 (95.906)	Acc@5 100.000 (99.980)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.63
Max memory: 90.0112384
 24.213s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4829
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.198 (0.198)	Data 0.263 (0.263)	Loss 0.2680 (0.2680)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2382 (0.2678)	Acc@1 97.656 (96.665)	Acc@5 100.000 (99.976)
Epoch: [141][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3060 (0.2748)	Acc@1 95.703 (96.490)	Acc@5 100.000 (99.982)
Epoch: [141][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3060 (0.2806)	Acc@1 95.312 (96.237)	Acc@5 100.000 (99.978)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.140 (0.140)	Data 0.296 (0.296)	Loss 0.2559 (0.2559)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2838 (0.2827)	Acc@1 96.094 (96.112)	Acc@5 100.000 (99.982)
Epoch: [142][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3302 (0.2795)	Acc@1 93.359 (96.236)	Acc@5 100.000 (99.973)
Epoch: [142][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2981 (0.2827)	Acc@1 96.094 (96.104)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.174 (0.174)	Data 0.286 (0.286)	Loss 0.2952 (0.2952)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.124 (0.120)	Data 0.000 (0.005)	Loss 0.2821 (0.2792)	Acc@1 96.094 (96.202)	Acc@5 100.000 (99.964)
Epoch: [143][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.2572 (0.2835)	Acc@1 97.656 (96.097)	Acc@5 100.000 (99.967)
Epoch: [143][192/196]	Time 0.129 (0.121)	Data 0.000 (0.002)	Loss 0.3079 (0.2897)	Acc@1 94.922 (95.835)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.182 (0.182)	Data 0.262 (0.262)	Loss 0.2997 (0.2997)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [144][64/196]	Time 0.114 (0.126)	Data 0.000 (0.004)	Loss 0.2513 (0.2830)	Acc@1 96.875 (96.208)	Acc@5 100.000 (99.970)
Epoch: [144][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.2615 (0.2846)	Acc@1 97.266 (96.063)	Acc@5 100.000 (99.970)
Epoch: [144][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2667 (0.2845)	Acc@1 96.484 (96.096)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.148 (0.148)	Data 0.274 (0.274)	Loss 0.2535 (0.2535)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.2502 (0.2735)	Acc@1 96.875 (96.424)	Acc@5 100.000 (99.970)
Epoch: [145][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2474 (0.2777)	Acc@1 97.656 (96.294)	Acc@5 100.000 (99.970)
Epoch: [145][192/196]	Time 0.127 (0.120)	Data 0.000 (0.002)	Loss 0.2530 (0.2822)	Acc@1 97.656 (96.128)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.38
Max memory: 90.0112384
 23.914s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 387
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1545216
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.178 (0.178)	Data 0.270 (0.270)	Loss 0.2519 (0.2519)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2911 (0.2717)	Acc@1 96.094 (96.611)	Acc@5 100.000 (99.988)
Epoch: [146][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2766 (0.2747)	Acc@1 96.484 (96.509)	Acc@5 100.000 (99.982)
Epoch: [146][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2506 (0.2775)	Acc@1 96.875 (96.365)	Acc@5 100.000 (99.978)
Max memory in training epoch: 57.9491328
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.140 (0.140)	Data 0.297 (0.297)	Loss 0.2908 (0.2908)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [147][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2745 (0.2843)	Acc@1 96.094 (96.028)	Acc@5 100.000 (99.958)
Epoch: [147][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2540 (0.2820)	Acc@1 97.266 (96.182)	Acc@5 100.000 (99.955)
Epoch: [147][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3167 (0.2841)	Acc@1 96.094 (96.096)	Acc@5 99.609 (99.955)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.172 (0.172)	Data 0.260 (0.260)	Loss 0.2685 (0.2685)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.129 (0.121)	Data 0.000 (0.004)	Loss 0.2585 (0.2778)	Acc@1 96.875 (96.346)	Acc@5 100.000 (99.982)
Epoch: [148][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3079 (0.2812)	Acc@1 95.703 (96.148)	Acc@5 100.000 (99.979)
Epoch: [148][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2952 (0.2851)	Acc@1 96.875 (96.055)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.162 (0.162)	Data 0.299 (0.299)	Loss 0.2648 (0.2648)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.2399 (0.2835)	Acc@1 98.438 (96.124)	Acc@5 100.000 (99.976)
Epoch: [149][128/196]	Time 0.131 (0.120)	Data 0.000 (0.002)	Loss 0.2438 (0.2857)	Acc@1 98.828 (96.039)	Acc@5 100.000 (99.985)
Epoch: [149][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2922 (0.2871)	Acc@1 96.094 (95.950)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7590784
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.162 (0.162)	Data 0.312 (0.312)	Loss 0.2624 (0.2624)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.2385 (0.2592)	Acc@1 98.438 (96.965)	Acc@5 100.000 (99.994)
Epoch: [150][128/196]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.2412 (0.2495)	Acc@1 98.047 (97.375)	Acc@5 100.000 (99.994)
Epoch: [150][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2015 (0.2431)	Acc@1 99.609 (97.614)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.42
Max memory: 90.0112384
 24.154s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8442
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1545216
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.169 (0.169)	Data 0.290 (0.290)	Loss 0.2438 (0.2438)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.2057 (0.2269)	Acc@1 99.219 (98.371)	Acc@5 100.000 (99.994)
Epoch: [151][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2272 (0.2262)	Acc@1 98.047 (98.356)	Acc@5 100.000 (99.997)
Epoch: [151][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2105 (0.2251)	Acc@1 98.438 (98.375)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9491328
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.174 (0.174)	Data 0.276 (0.276)	Loss 0.2256 (0.2256)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.126 (0.124)	Data 0.000 (0.004)	Loss 0.2045 (0.2199)	Acc@1 99.219 (98.462)	Acc@5 100.000 (99.988)
Epoch: [152][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1970 (0.2170)	Acc@1 100.000 (98.601)	Acc@5 100.000 (99.994)
Epoch: [152][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2444 (0.2175)	Acc@1 97.266 (98.563)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.160 (0.160)	Data 0.317 (0.317)	Loss 0.2043 (0.2043)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.129 (0.123)	Data 0.000 (0.005)	Loss 0.2313 (0.2128)	Acc@1 98.438 (98.804)	Acc@5 100.000 (100.000)
Epoch: [153][128/196]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.1917 (0.2127)	Acc@1 100.000 (98.762)	Acc@5 100.000 (99.994)
Epoch: [153][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2254 (0.2131)	Acc@1 98.438 (98.729)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.178 (0.178)	Data 0.297 (0.297)	Loss 0.2131 (0.2131)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.2065 (0.2091)	Acc@1 98.828 (98.864)	Acc@5 100.000 (99.988)
Epoch: [154][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1878 (0.2084)	Acc@1 99.609 (98.895)	Acc@5 100.000 (99.994)
Epoch: [154][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.2135 (0.2084)	Acc@1 98.828 (98.891)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.162 (0.162)	Data 0.278 (0.278)	Loss 0.1958 (0.1958)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2167 (0.2039)	Acc@1 98.047 (99.069)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2058 (0.2046)	Acc@1 98.828 (98.995)	Acc@5 100.000 (100.000)
Epoch: [155][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.2126 (0.2045)	Acc@1 98.047 (98.990)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.58
Max memory: 90.0112384
 24.419s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 219
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1545216
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.184 (0.184)	Data 0.267 (0.267)	Loss 0.1928 (0.1928)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.1837 (0.2022)	Acc@1 100.000 (99.087)	Acc@5 100.000 (99.988)
Epoch: [156][128/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.1873 (0.2030)	Acc@1 99.609 (99.070)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.2081 (0.2030)	Acc@1 98.828 (99.053)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9491328
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.150 (0.150)	Data 0.297 (0.297)	Loss 0.1939 (0.1939)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.1988 (0.2032)	Acc@1 99.219 (98.996)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.115 (0.124)	Data 0.000 (0.002)	Loss 0.2032 (0.2025)	Acc@1 98.438 (98.995)	Acc@5 100.000 (100.000)
Epoch: [157][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.1922 (0.2026)	Acc@1 99.609 (98.984)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.157 (0.157)	Data 0.272 (0.272)	Loss 0.2024 (0.2024)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.127 (0.123)	Data 0.000 (0.004)	Loss 0.1959 (0.2004)	Acc@1 99.219 (99.111)	Acc@5 100.000 (99.994)
Epoch: [158][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2010 (0.1990)	Acc@1 99.219 (99.152)	Acc@5 100.000 (99.997)
Epoch: [158][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1984 (0.1992)	Acc@1 99.219 (99.122)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.161 (0.161)	Data 0.267 (0.267)	Loss 0.1838 (0.1838)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.154 (0.124)	Data 0.000 (0.004)	Loss 0.1994 (0.1980)	Acc@1 98.828 (99.213)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.1925 (0.1979)	Acc@1 99.609 (99.216)	Acc@5 100.000 (100.000)
Epoch: [159][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1940 (0.1976)	Acc@1 99.219 (99.201)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.151 (0.151)	Data 0.272 (0.272)	Loss 0.2046 (0.2046)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.132 (0.124)	Data 0.000 (0.004)	Loss 0.1890 (0.1966)	Acc@1 99.609 (99.237)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.2080 (0.1952)	Acc@1 98.438 (99.285)	Acc@5 100.000 (99.997)
Epoch: [160][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.1885 (0.1955)	Acc@1 99.609 (99.267)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.74
Max memory: 90.0112384
 24.421s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8803
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1545216
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.194 (0.194)	Data 0.269 (0.269)	Loss 0.1937 (0.1937)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.1971 (0.1932)	Acc@1 99.609 (99.273)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2091 (0.1935)	Acc@1 98.828 (99.273)	Acc@5 100.000 (100.000)
Epoch: [161][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1818 (0.1938)	Acc@1 100.000 (99.237)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9491328
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.154 (0.154)	Data 0.300 (0.300)	Loss 0.1977 (0.1977)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.113 (0.120)	Data 0.000 (0.005)	Loss 0.1883 (0.1928)	Acc@1 100.000 (99.339)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.1797 (0.1920)	Acc@1 100.000 (99.364)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.1850 (0.1924)	Acc@1 99.609 (99.304)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.143 (0.143)	Data 0.271 (0.271)	Loss 0.2025 (0.2025)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.1917 (0.1920)	Acc@1 99.609 (99.351)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1955 (0.1922)	Acc@1 99.219 (99.325)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1836 (0.1917)	Acc@1 100.000 (99.332)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.162 (0.162)	Data 0.293 (0.293)	Loss 0.1887 (0.1887)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.1904 (0.1886)	Acc@1 99.219 (99.453)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.1921 (0.1906)	Acc@1 99.219 (99.346)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.1966 (0.1905)	Acc@1 98.828 (99.358)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.141 (0.141)	Data 0.296 (0.296)	Loss 0.1781 (0.1781)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.1897 (0.1880)	Acc@1 99.219 (99.483)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.116 (0.120)	Data 0.000 (0.003)	Loss 0.1780 (0.1874)	Acc@1 99.609 (99.467)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1931 (0.1878)	Acc@1 99.219 (99.449)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.91
Max memory: 90.0112384
 23.860s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4626
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1545216
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.178 (0.178)	Data 0.289 (0.289)	Loss 0.1763 (0.1763)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.2022 (0.1884)	Acc@1 98.438 (99.321)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1772 (0.1879)	Acc@1 99.609 (99.394)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1932 (0.1884)	Acc@1 99.219 (99.377)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9491328
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.160 (0.160)	Data 0.291 (0.291)	Loss 0.1834 (0.1834)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.1872 (0.1864)	Acc@1 99.219 (99.423)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1800 (0.1864)	Acc@1 100.000 (99.446)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1820 (0.1863)	Acc@1 99.609 (99.466)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.178 (0.178)	Data 0.285 (0.285)	Loss 0.1837 (0.1837)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.1804 (0.1860)	Acc@1 99.609 (99.471)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1911 (0.1858)	Acc@1 99.219 (99.479)	Acc@5 100.000 (100.000)
Epoch: [168][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1927 (0.1859)	Acc@1 99.219 (99.464)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.178 (0.178)	Data 0.260 (0.260)	Loss 0.1746 (0.1746)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.125 (0.122)	Data 0.000 (0.004)	Loss 0.1813 (0.1842)	Acc@1 99.609 (99.537)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1817 (0.1852)	Acc@1 99.609 (99.488)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1958 (0.1849)	Acc@1 99.219 (99.474)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.162 (0.162)	Data 0.272 (0.272)	Loss 0.1757 (0.1757)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.1851 (0.1845)	Acc@1 99.219 (99.423)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1858 (0.1842)	Acc@1 99.219 (99.416)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.132 (0.121)	Data 0.000 (0.002)	Loss 0.1815 (0.1840)	Acc@1 99.609 (99.449)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.64
Max memory: 90.0112384
 24.145s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 672
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1545216
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.180 (0.180)	Data 0.286 (0.286)	Loss 0.1813 (0.1813)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.1941 (0.1829)	Acc@1 98.828 (99.495)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.1797 (0.1833)	Acc@1 99.219 (99.482)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.1822 (0.1828)	Acc@1 99.609 (99.508)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9491328
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.156 (0.156)	Data 0.292 (0.292)	Loss 0.1762 (0.1762)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.1799 (0.1827)	Acc@1 99.609 (99.531)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.1779 (0.1819)	Acc@1 99.219 (99.543)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1969 (0.1821)	Acc@1 98.828 (99.532)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.167 (0.167)	Data 0.294 (0.294)	Loss 0.1881 (0.1881)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.133 (0.125)	Data 0.000 (0.005)	Loss 0.1715 (0.1812)	Acc@1 100.000 (99.489)	Acc@5 100.000 (99.994)
Epoch: [173][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.1722 (0.1811)	Acc@1 100.000 (99.509)	Acc@5 100.000 (99.997)
Epoch: [173][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.1785 (0.1814)	Acc@1 100.000 (99.522)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.171 (0.171)	Data 0.277 (0.277)	Loss 0.1778 (0.1778)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.121 (0.124)	Data 0.000 (0.004)	Loss 0.1877 (0.1805)	Acc@1 99.219 (99.621)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.129 (0.123)	Data 0.000 (0.002)	Loss 0.1829 (0.1797)	Acc@1 99.609 (99.618)	Acc@5 100.000 (100.000)
Epoch: [174][192/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.1812 (0.1792)	Acc@1 99.219 (99.636)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.153 (0.153)	Data 0.282 (0.282)	Loss 0.1688 (0.1688)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.1677 (0.1780)	Acc@1 100.000 (99.615)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.131 (0.122)	Data 0.000 (0.002)	Loss 0.1773 (0.1787)	Acc@1 99.609 (99.579)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1821 (0.1793)	Acc@1 99.609 (99.559)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.92
Max memory: 90.0112384
 24.256s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4427
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1545216
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.181 (0.181)	Data 0.286 (0.286)	Loss 0.1710 (0.1710)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.1790 (0.1771)	Acc@1 100.000 (99.688)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.1809 (0.1776)	Acc@1 99.609 (99.637)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.1804 (0.1778)	Acc@1 100.000 (99.634)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.9491328
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.178 (0.178)	Data 0.266 (0.266)	Loss 0.1703 (0.1703)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.1799 (0.1765)	Acc@1 99.609 (99.663)	Acc@5 100.000 (99.994)
Epoch: [177][128/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.1789 (0.1775)	Acc@1 99.609 (99.588)	Acc@5 100.000 (99.994)
Epoch: [177][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1706 (0.1770)	Acc@1 100.000 (99.632)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.189 (0.189)	Data 0.263 (0.263)	Loss 0.1802 (0.1802)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.1681 (0.1778)	Acc@1 100.000 (99.621)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1792 (0.1776)	Acc@1 99.219 (99.582)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1690 (0.1775)	Acc@1 100.000 (99.589)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.167 (0.167)	Data 0.289 (0.289)	Loss 0.1838 (0.1838)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.125 (0.122)	Data 0.000 (0.005)	Loss 0.1749 (0.1759)	Acc@1 98.828 (99.657)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1752 (0.1763)	Acc@1 99.609 (99.640)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1938 (0.1760)	Acc@1 98.828 (99.652)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7590784
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.170 (0.170)	Data 0.335 (0.335)	Loss 0.1732 (0.1732)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.1720 (0.1767)	Acc@1 99.609 (99.579)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.1746 (0.1752)	Acc@1 100.000 (99.643)	Acc@5 100.000 (99.997)
Epoch: [180][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1854 (0.1750)	Acc@1 98.438 (99.626)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7590784
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(7, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(19, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(51, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(51, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(15, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.79
Max memory: 90.0112384
 24.537s  Thres 0.01 2
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3592
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.197 (0.197)	Data 0.270 (0.270)	Loss 3.3070 (3.3070)	Acc@1 12.891 (12.891)	Acc@5 53.125 (53.125)
Epoch: [1][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 2.4567 (2.6630)	Acc@1 34.766 (25.150)	Acc@5 85.156 (78.113)
Epoch: [1][128/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 2.2951 (2.4791)	Acc@1 35.938 (31.677)	Acc@5 88.672 (83.367)
Epoch: [1][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.9140 (2.3441)	Acc@1 51.562 (36.597)	Acc@5 95.703 (86.304)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.186 (0.186)	Data 0.268 (0.268)	Loss 1.8482 (1.8482)	Acc@1 52.344 (52.344)	Acc@5 95.312 (95.312)
Epoch: [2][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 1.7393 (1.8682)	Acc@1 58.203 (52.909)	Acc@5 94.531 (94.315)
Epoch: [2][128/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 1.7189 (1.8076)	Acc@1 59.766 (55.039)	Acc@5 92.188 (94.810)
Epoch: [2][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 1.5732 (1.7433)	Acc@1 62.109 (57.102)	Acc@5 96.484 (95.256)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 1.4968 (1.4968)	Acc@1 68.359 (68.359)	Acc@5 98.438 (98.438)
Epoch: [3][64/196]	Time 0.122 (0.130)	Data 0.000 (0.004)	Loss 1.4206 (1.4913)	Acc@1 62.109 (65.162)	Acc@5 98.438 (97.212)
Epoch: [3][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 1.4640 (1.4576)	Acc@1 64.062 (66.116)	Acc@5 97.266 (97.266)
Epoch: [3][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 1.2084 (1.4248)	Acc@1 73.438 (67.115)	Acc@5 98.438 (97.355)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.183 (0.183)	Data 0.281 (0.281)	Loss 1.3017 (1.3017)	Acc@1 68.359 (68.359)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 1.2027 (1.2807)	Acc@1 72.266 (71.184)	Acc@5 98.828 (97.837)
Epoch: [4][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 1.2560 (1.2584)	Acc@1 73.047 (71.830)	Acc@5 97.266 (97.917)
Epoch: [4][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.1542 (1.2357)	Acc@1 74.219 (72.460)	Acc@5 98.438 (98.083)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.171 (0.171)	Data 0.268 (0.268)	Loss 1.1823 (1.1823)	Acc@1 76.562 (76.562)	Acc@5 98.047 (98.047)
Epoch: [5][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 1.0666 (1.1359)	Acc@1 78.516 (75.379)	Acc@5 98.438 (98.395)
Epoch: [5][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.0586 (1.1193)	Acc@1 74.609 (75.548)	Acc@5 99.609 (98.501)
Epoch: [5][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 1.1577 (1.1089)	Acc@1 73.438 (75.631)	Acc@5 97.266 (98.470)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  68.82
Max memory: 103.3835008
 25.851s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8784
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.201 (0.201)	Data 0.272 (0.272)	Loss 1.0461 (1.0461)	Acc@1 76.172 (76.172)	Acc@5 98.828 (98.828)
Epoch: [6][64/196]	Time 0.136 (0.132)	Data 0.000 (0.004)	Loss 0.9584 (1.0246)	Acc@1 80.859 (77.704)	Acc@5 98.438 (98.726)
Epoch: [6][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.9459 (1.0159)	Acc@1 80.469 (78.043)	Acc@5 98.828 (98.680)
Epoch: [6][192/196]	Time 0.139 (0.131)	Data 0.000 (0.002)	Loss 1.1012 (1.0076)	Acc@1 75.781 (78.111)	Acc@5 99.219 (98.690)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.180 (0.180)	Data 0.266 (0.266)	Loss 0.9198 (0.9198)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [7][64/196]	Time 0.124 (0.130)	Data 0.000 (0.004)	Loss 0.8876 (0.9658)	Acc@1 82.031 (78.612)	Acc@5 100.000 (98.888)
Epoch: [7][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8826 (0.9590)	Acc@1 80.859 (78.930)	Acc@5 98.828 (98.819)
Epoch: [7][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8721 (0.9537)	Acc@1 80.469 (79.080)	Acc@5 98.828 (98.790)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.187 (0.187)	Data 0.268 (0.268)	Loss 1.0069 (1.0069)	Acc@1 76.562 (76.562)	Acc@5 97.656 (97.656)
Epoch: [8][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.8053 (0.9217)	Acc@1 83.203 (79.627)	Acc@5 99.609 (98.918)
Epoch: [8][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.9492 (0.9168)	Acc@1 80.469 (79.824)	Acc@5 98.438 (98.916)
Epoch: [8][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.9644 (0.9115)	Acc@1 77.734 (79.983)	Acc@5 99.219 (98.893)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.167 (0.167)	Data 0.313 (0.313)	Loss 0.9614 (0.9614)	Acc@1 77.344 (77.344)	Acc@5 98.047 (98.047)
Epoch: [9][64/196]	Time 0.125 (0.132)	Data 0.000 (0.005)	Loss 0.7857 (0.9018)	Acc@1 83.984 (80.120)	Acc@5 99.219 (98.942)
Epoch: [9][128/196]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.8713 (0.8869)	Acc@1 79.297 (80.445)	Acc@5 98.047 (98.940)
Epoch: [9][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8446 (0.8818)	Acc@1 79.688 (80.600)	Acc@5 99.609 (98.976)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.163 (0.163)	Data 0.299 (0.299)	Loss 0.8134 (0.8134)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [10][64/196]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.8275 (0.8569)	Acc@1 82.812 (81.502)	Acc@5 99.609 (99.044)
Epoch: [10][128/196]	Time 0.128 (0.132)	Data 0.000 (0.003)	Loss 0.8826 (0.8582)	Acc@1 79.297 (81.335)	Acc@5 99.219 (98.943)
Epoch: [10][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.9130 (0.8585)	Acc@1 78.516 (81.278)	Acc@5 98.047 (98.939)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  69.33
Max memory: 103.3833984
 26.129s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3332
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.189 (0.189)	Data 0.290 (0.290)	Loss 0.8444 (0.8444)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7886 (0.7913)	Acc@1 81.641 (83.125)	Acc@5 99.219 (99.273)
Epoch: [11][128/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.8310 (0.8150)	Acc@1 80.078 (82.267)	Acc@5 99.609 (99.137)
Epoch: [11][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7985 (0.8229)	Acc@1 86.328 (82.118)	Acc@5 98.047 (99.065)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.181 (0.181)	Data 0.301 (0.301)	Loss 0.9769 (0.9769)	Acc@1 78.125 (78.125)	Acc@5 98.047 (98.047)
Epoch: [12][64/196]	Time 0.136 (0.133)	Data 0.000 (0.005)	Loss 0.8056 (0.8313)	Acc@1 80.469 (81.550)	Acc@5 99.219 (99.002)
Epoch: [12][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.9315 (0.8211)	Acc@1 78.125 (81.931)	Acc@5 97.656 (99.064)
Epoch: [12][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.9056 (0.8183)	Acc@1 77.734 (82.039)	Acc@5 98.047 (99.061)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.179 (0.179)	Data 0.272 (0.272)	Loss 0.8354 (0.8354)	Acc@1 80.078 (80.078)	Acc@5 99.219 (99.219)
Epoch: [13][64/196]	Time 0.134 (0.132)	Data 0.000 (0.004)	Loss 0.8524 (0.8118)	Acc@1 82.812 (82.410)	Acc@5 98.828 (98.948)
Epoch: [13][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7448 (0.8127)	Acc@1 82.812 (82.346)	Acc@5 99.219 (99.040)
Epoch: [13][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6696 (0.8079)	Acc@1 86.719 (82.385)	Acc@5 98.828 (99.073)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.179 (0.179)	Data 0.271 (0.271)	Loss 0.7843 (0.7843)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [14][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.8658 (0.7885)	Acc@1 79.297 (82.752)	Acc@5 99.219 (99.201)
Epoch: [14][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.8183 (0.7921)	Acc@1 80.469 (82.664)	Acc@5 98.438 (99.198)
Epoch: [14][192/196]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.8327 (0.7938)	Acc@1 82.031 (82.689)	Acc@5 98.828 (99.154)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.188 (0.188)	Data 0.266 (0.266)	Loss 0.8976 (0.8976)	Acc@1 76.172 (76.172)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 0.128 (0.133)	Data 0.000 (0.004)	Loss 0.9014 (0.7907)	Acc@1 79.688 (82.849)	Acc@5 99.219 (99.225)
Epoch: [15][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7060 (0.7903)	Acc@1 85.938 (82.973)	Acc@5 99.219 (99.110)
Epoch: [15][192/196]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.8854 (0.7873)	Acc@1 81.641 (83.063)	Acc@5 98.047 (99.158)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 481616 ; 487386 ; 0.988161334137624
[INFO] Storing checkpoint...
  73.8
Max memory: 103.3833984
 26.606s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 932
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.2002432
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.202 (0.202)	Data 0.277 (0.277)	Loss 0.8313 (0.8313)	Acc@1 81.641 (81.641)	Acc@5 98.047 (98.047)
Epoch: [16][64/196]	Time 0.131 (0.132)	Data 0.000 (0.004)	Loss 0.8374 (0.7633)	Acc@1 82.031 (83.462)	Acc@5 99.219 (99.273)
Epoch: [16][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.6786 (0.7739)	Acc@1 85.156 (83.336)	Acc@5 100.000 (99.182)
Epoch: [16][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7958 (0.7785)	Acc@1 82.422 (83.207)	Acc@5 98.438 (99.162)
Max memory in training epoch: 66.6376704
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.167 (0.167)	Data 0.289 (0.289)	Loss 0.8288 (0.8288)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [17][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.7147 (0.7792)	Acc@1 88.672 (83.359)	Acc@5 100.000 (99.243)
Epoch: [17][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.8108 (0.7884)	Acc@1 82.031 (82.867)	Acc@5 99.609 (99.195)
Epoch: [17][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7996 (0.7824)	Acc@1 83.594 (83.161)	Acc@5 99.609 (99.158)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.179 (0.179)	Data 0.267 (0.267)	Loss 0.8038 (0.8038)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.8285 (0.7729)	Acc@1 80.469 (83.419)	Acc@5 98.438 (99.327)
Epoch: [18][128/196]	Time 0.136 (0.131)	Data 0.000 (0.002)	Loss 0.8130 (0.7771)	Acc@1 80.859 (83.479)	Acc@5 98.047 (99.270)
Epoch: [18][192/196]	Time 0.140 (0.131)	Data 0.000 (0.002)	Loss 0.7221 (0.7777)	Acc@1 85.156 (83.355)	Acc@5 99.219 (99.300)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.166 (0.166)	Data 0.259 (0.259)	Loss 0.7361 (0.7361)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.7395 (0.7698)	Acc@1 86.328 (83.564)	Acc@5 98.047 (99.291)
Epoch: [19][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7814 (0.7717)	Acc@1 83.984 (83.573)	Acc@5 98.828 (99.246)
Epoch: [19][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7716 (0.7694)	Acc@1 84.375 (83.565)	Acc@5 98.828 (99.231)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.171 (0.171)	Data 0.260 (0.260)	Loss 0.8974 (0.8974)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [20][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.7043 (0.7479)	Acc@1 88.672 (84.237)	Acc@5 98.828 (99.339)
Epoch: [20][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7950 (0.7570)	Acc@1 81.641 (83.987)	Acc@5 99.609 (99.285)
Epoch: [20][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.9033 (0.7651)	Acc@1 77.344 (83.707)	Acc@5 98.828 (99.221)
Max memory in training epoch: 66.5328128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 461998 ; 481616 ; 0.9592663034450682
[INFO] Storing checkpoint...
  69.58
Max memory: 103.37664
 25.956s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6499
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1924608
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.190 (0.190)	Data 0.271 (0.271)	Loss 0.7818 (0.7818)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 0.147 (0.132)	Data 0.000 (0.004)	Loss 0.7019 (0.7294)	Acc@1 84.766 (84.706)	Acc@5 99.219 (99.387)
Epoch: [21][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.9627 (0.7454)	Acc@1 80.859 (84.390)	Acc@5 98.438 (99.325)
Epoch: [21][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7117 (0.7509)	Acc@1 86.328 (84.175)	Acc@5 99.609 (99.265)
Max memory in training epoch: 66.3378432
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.192 (0.192)	Data 0.286 (0.286)	Loss 0.7455 (0.7455)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [22][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.6572 (0.7501)	Acc@1 87.891 (84.423)	Acc@5 99.219 (99.213)
Epoch: [22][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7662 (0.7567)	Acc@1 81.641 (84.084)	Acc@5 99.219 (99.231)
Epoch: [22][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6945 (0.7586)	Acc@1 86.719 (84.005)	Acc@5 99.609 (99.223)
Max memory in training epoch: 66.2329856
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.152 (0.152)	Data 0.284 (0.284)	Loss 0.8101 (0.8101)	Acc@1 80.859 (80.859)	Acc@5 98.438 (98.438)
Epoch: [23][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7997 (0.7486)	Acc@1 78.906 (84.543)	Acc@5 98.438 (99.213)
Epoch: [23][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7110 (0.7551)	Acc@1 84.375 (84.211)	Acc@5 98.828 (99.255)
Epoch: [23][192/196]	Time 0.137 (0.130)	Data 0.000 (0.002)	Loss 0.7849 (0.7548)	Acc@1 83.203 (84.181)	Acc@5 99.219 (99.286)
Max memory in training epoch: 66.2329856
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.169 (0.169)	Data 0.271 (0.271)	Loss 0.7668 (0.7668)	Acc@1 81.641 (81.641)	Acc@5 98.828 (98.828)
Epoch: [24][64/196]	Time 0.134 (0.130)	Data 0.000 (0.004)	Loss 0.7702 (0.7482)	Acc@1 83.594 (83.978)	Acc@5 100.000 (99.333)
Epoch: [24][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7802 (0.7464)	Acc@1 81.641 (84.178)	Acc@5 98.438 (99.294)
Epoch: [24][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7272 (0.7507)	Acc@1 80.078 (84.154)	Acc@5 99.219 (99.279)
Max memory in training epoch: 66.2329856
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.177 (0.177)	Data 0.294 (0.294)	Loss 0.7851 (0.7851)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.7529 (0.7387)	Acc@1 85.156 (84.724)	Acc@5 99.219 (99.315)
Epoch: [25][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7101 (0.7427)	Acc@1 85.547 (84.593)	Acc@5 99.609 (99.340)
Epoch: [25][192/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7422 (0.7477)	Acc@1 83.984 (84.391)	Acc@5 98.828 (99.330)
Max memory in training epoch: 66.2329856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 437186 ; 461998 ; 0.946294139801471
[INFO] Storing checkpoint...
  80.63
Max memory: 103.1040512
 26.088s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5361
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.182528
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.204 (0.204)	Data 0.264 (0.264)	Loss 0.6734 (0.6734)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 0.7010 (0.7047)	Acc@1 86.328 (85.745)	Acc@5 99.219 (99.375)
Epoch: [26][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.6810 (0.7248)	Acc@1 86.719 (84.981)	Acc@5 99.219 (99.313)
Epoch: [26][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.8273 (0.7349)	Acc@1 80.078 (84.733)	Acc@5 99.219 (99.284)
Max memory in training epoch: 66.1473792
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.158 (0.158)	Data 0.314 (0.314)	Loss 0.7203 (0.7203)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.8334 (0.7225)	Acc@1 78.906 (85.078)	Acc@5 98.828 (99.315)
Epoch: [27][128/196]	Time 0.128 (0.131)	Data 0.000 (0.003)	Loss 0.7697 (0.7398)	Acc@1 84.766 (84.623)	Acc@5 98.828 (99.288)
Epoch: [27][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7438 (0.7436)	Acc@1 81.641 (84.551)	Acc@5 99.219 (99.298)
Max memory in training epoch: 65.9114496
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.164 (0.164)	Data 0.299 (0.299)	Loss 0.7675 (0.7675)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [28][64/196]	Time 0.143 (0.130)	Data 0.000 (0.005)	Loss 0.7515 (0.7295)	Acc@1 85.156 (85.186)	Acc@5 99.609 (99.303)
Epoch: [28][128/196]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.7734 (0.7371)	Acc@1 83.203 (84.672)	Acc@5 98.828 (99.313)
Epoch: [28][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6688 (0.7319)	Acc@1 86.328 (84.869)	Acc@5 99.219 (99.296)
Max memory in training epoch: 65.9114496
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.190 (0.190)	Data 0.261 (0.261)	Loss 0.7439 (0.7439)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6959 (0.7303)	Acc@1 85.156 (84.898)	Acc@5 99.219 (99.213)
Epoch: [29][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7116 (0.7345)	Acc@1 87.891 (84.675)	Acc@5 99.219 (99.249)
Epoch: [29][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7323 (0.7346)	Acc@1 84.766 (84.719)	Acc@5 98.828 (99.253)
Max memory in training epoch: 65.9114496
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.170 (0.170)	Data 0.301 (0.301)	Loss 0.6838 (0.6838)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7664 (0.7141)	Acc@1 82.422 (85.373)	Acc@5 99.219 (99.405)
Epoch: [30][128/196]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.7170 (0.7195)	Acc@1 83.984 (85.265)	Acc@5 99.609 (99.376)
Epoch: [30][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7660 (0.7285)	Acc@1 87.109 (84.944)	Acc@5 99.609 (99.340)
Max memory in training epoch: 65.9114496
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 416410 ; 437186 ; 0.952477892704707
[INFO] Storing checkpoint...
  70.66
Max memory: 102.6157056
 26.072s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 115
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1742336
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.198 (0.198)	Data 0.284 (0.284)	Loss 0.7483 (0.7483)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.7806 (0.6878)	Acc@1 82.031 (86.370)	Acc@5 99.609 (99.441)
Epoch: [31][128/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.7264 (0.7111)	Acc@1 84.375 (85.568)	Acc@5 99.609 (99.364)
Epoch: [31][192/196]	Time 0.126 (0.133)	Data 0.000 (0.002)	Loss 0.7163 (0.7211)	Acc@1 83.203 (85.136)	Acc@5 99.609 (99.360)
Max memory in training epoch: 65.4981632
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.181 (0.181)	Data 0.268 (0.268)	Loss 0.6978 (0.6978)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.7559 (0.7235)	Acc@1 82.031 (85.042)	Acc@5 99.219 (99.321)
Epoch: [32][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7605 (0.7254)	Acc@1 85.938 (85.123)	Acc@5 99.609 (99.376)
Epoch: [32][192/196]	Time 0.136 (0.130)	Data 0.000 (0.002)	Loss 0.8073 (0.7321)	Acc@1 85.156 (84.863)	Acc@5 98.828 (99.350)
Max memory in training epoch: 65.5243776
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.172 (0.172)	Data 0.298 (0.298)	Loss 0.6422 (0.6422)	Acc@1 90.234 (90.234)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.7097 (0.7114)	Acc@1 85.938 (85.931)	Acc@5 100.000 (99.297)
Epoch: [33][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.8803 (0.7237)	Acc@1 79.297 (85.350)	Acc@5 98.438 (99.331)
Epoch: [33][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6775 (0.7187)	Acc@1 86.719 (85.492)	Acc@5 99.609 (99.348)
Max memory in training epoch: 65.5243776
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.161 (0.161)	Data 0.293 (0.293)	Loss 0.7182 (0.7182)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [34][64/196]	Time 0.133 (0.129)	Data 0.000 (0.005)	Loss 0.6702 (0.7207)	Acc@1 87.891 (85.499)	Acc@5 99.219 (99.417)
Epoch: [34][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7046 (0.7243)	Acc@1 85.938 (85.296)	Acc@5 99.219 (99.376)
Epoch: [34][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6105 (0.7247)	Acc@1 88.672 (85.280)	Acc@5 100.000 (99.332)
Max memory in training epoch: 65.5243776
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.165 (0.165)	Data 0.265 (0.265)	Loss 0.6597 (0.6597)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.6981 (0.7111)	Acc@1 86.328 (85.745)	Acc@5 98.828 (99.297)
Epoch: [35][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6809 (0.7196)	Acc@1 87.109 (85.196)	Acc@5 99.609 (99.346)
Epoch: [35][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6653 (0.7198)	Acc@1 86.328 (85.221)	Acc@5 100.000 (99.375)
Max memory in training epoch: 65.5243776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 402260 ; 416410 ; 0.9660190677457313
[INFO] Storing checkpoint...
  80.32
Max memory: 102.044416
 25.855s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4210
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1686016
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.194 (0.194)	Data 0.287 (0.287)	Loss 0.7452 (0.7452)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.6640 (0.6948)	Acc@1 85.938 (85.871)	Acc@5 100.000 (99.465)
Epoch: [36][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6725 (0.7083)	Acc@1 85.938 (85.620)	Acc@5 99.609 (99.361)
Epoch: [36][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7141 (0.7137)	Acc@1 85.156 (85.452)	Acc@5 99.219 (99.366)
Max memory in training epoch: 64.4663808
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.167 (0.167)	Data 0.293 (0.293)	Loss 0.6875 (0.6875)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.128 (0.133)	Data 0.000 (0.005)	Loss 0.6409 (0.6987)	Acc@1 87.109 (86.100)	Acc@5 99.609 (99.327)
Epoch: [37][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7702 (0.7108)	Acc@1 84.375 (85.710)	Acc@5 98.047 (99.343)
Epoch: [37][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6500 (0.7136)	Acc@1 87.500 (85.622)	Acc@5 99.219 (99.346)
Max memory in training epoch: 64.6892032
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.168 (0.168)	Data 0.295 (0.295)	Loss 0.7467 (0.7467)	Acc@1 82.422 (82.422)	Acc@5 98.047 (98.047)
Epoch: [38][64/196]	Time 0.123 (0.132)	Data 0.000 (0.005)	Loss 0.7054 (0.7131)	Acc@1 87.500 (85.595)	Acc@5 99.219 (99.333)
Epoch: [38][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.7870 (0.7172)	Acc@1 83.594 (85.311)	Acc@5 99.609 (99.334)
Epoch: [38][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6361 (0.7159)	Acc@1 87.109 (85.371)	Acc@5 99.609 (99.354)
Max memory in training epoch: 64.6892032
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.183 (0.183)	Data 0.290 (0.290)	Loss 0.8024 (0.8024)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [39][64/196]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7275 (0.7065)	Acc@1 87.109 (85.589)	Acc@5 98.438 (99.507)
Epoch: [39][128/196]	Time 0.139 (0.131)	Data 0.000 (0.002)	Loss 0.7534 (0.7070)	Acc@1 81.641 (85.495)	Acc@5 99.219 (99.419)
Epoch: [39][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7778 (0.7110)	Acc@1 82.422 (85.466)	Acc@5 99.219 (99.356)
Max memory in training epoch: 64.6892032
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.181 (0.181)	Data 0.300 (0.300)	Loss 0.8028 (0.8028)	Acc@1 82.422 (82.422)	Acc@5 97.656 (97.656)
Epoch: [40][64/196]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.6581 (0.7104)	Acc@1 85.547 (85.535)	Acc@5 99.609 (99.417)
Epoch: [40][128/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.8094 (0.7119)	Acc@1 82.812 (85.520)	Acc@5 99.609 (99.431)
Epoch: [40][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6651 (0.7087)	Acc@1 84.375 (85.689)	Acc@5 100.000 (99.423)
Max memory in training epoch: 64.6892032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 384938 ; 402260 ; 0.9569382986128375
[INFO] Storing checkpoint...
  79.81
Max memory: 99.940608
 26.145s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4983
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1619456
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.212 (0.212)	Data 0.302 (0.302)	Loss 0.6958 (0.6958)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [41][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.6974 (0.6832)	Acc@1 85.547 (86.274)	Acc@5 99.219 (99.513)
Epoch: [41][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.6891 (0.6931)	Acc@1 88.672 (85.977)	Acc@5 98.828 (99.440)
Epoch: [41][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6081 (0.7018)	Acc@1 90.234 (85.719)	Acc@5 100.000 (99.375)
Max memory in training epoch: 63.273216
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.183 (0.183)	Data 0.316 (0.316)	Loss 0.6665 (0.6665)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.136 (0.133)	Data 0.000 (0.005)	Loss 0.6358 (0.6895)	Acc@1 88.281 (86.142)	Acc@5 99.219 (99.453)
Epoch: [42][128/196]	Time 0.126 (0.133)	Data 0.000 (0.003)	Loss 0.7220 (0.7041)	Acc@1 85.156 (85.771)	Acc@5 100.000 (99.413)
Epoch: [42][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7156 (0.7032)	Acc@1 85.547 (85.678)	Acc@5 98.438 (99.415)
Max memory in training epoch: 63.4436096
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.174 (0.174)	Data 0.311 (0.311)	Loss 0.6363 (0.6363)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [43][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.7367 (0.6999)	Acc@1 85.547 (85.913)	Acc@5 98.438 (99.369)
Epoch: [43][128/196]	Time 0.121 (0.129)	Data 0.000 (0.003)	Loss 0.7207 (0.6977)	Acc@1 87.500 (86.004)	Acc@5 99.609 (99.394)
Epoch: [43][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7304 (0.7018)	Acc@1 85.156 (85.790)	Acc@5 100.000 (99.383)
Max memory in training epoch: 63.4436096
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.189 (0.189)	Data 0.271 (0.271)	Loss 0.6367 (0.6367)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6705 (0.6938)	Acc@1 85.547 (85.733)	Acc@5 100.000 (99.375)
Epoch: [44][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6262 (0.6972)	Acc@1 87.500 (85.819)	Acc@5 99.609 (99.397)
Epoch: [44][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7449 (0.6964)	Acc@1 85.547 (85.889)	Acc@5 99.609 (99.405)
Max memory in training epoch: 63.4436096
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.164 (0.164)	Data 0.295 (0.295)	Loss 0.6814 (0.6814)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [45][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.6832 (0.6947)	Acc@1 84.766 (85.847)	Acc@5 99.219 (99.435)
Epoch: [45][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6870 (0.6917)	Acc@1 84.375 (86.034)	Acc@5 99.219 (99.443)
Epoch: [45][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7656 (0.6934)	Acc@1 83.984 (86.035)	Acc@5 99.219 (99.441)
Max memory in training epoch: 63.4436096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 373678 ; 384938 ; 0.9707485361278959
[INFO] Storing checkpoint...
  78.97
Max memory: 98.5323008
 25.607s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7489
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1573376
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.208 (0.208)	Data 0.272 (0.272)	Loss 0.6733 (0.6733)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6415 (0.6756)	Acc@1 90.234 (86.641)	Acc@5 100.000 (99.513)
Epoch: [46][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7540 (0.6871)	Acc@1 87.109 (86.213)	Acc@5 99.219 (99.455)
Epoch: [46][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6475 (0.6896)	Acc@1 87.500 (86.061)	Acc@5 98.047 (99.413)
Max memory in training epoch: 62.7763712
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.171 (0.171)	Data 0.294 (0.294)	Loss 0.7723 (0.7723)	Acc@1 83.203 (83.203)	Acc@5 98.047 (98.047)
Epoch: [47][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.7061 (0.6958)	Acc@1 82.812 (86.094)	Acc@5 100.000 (99.339)
Epoch: [47][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7474 (0.6940)	Acc@1 84.766 (86.022)	Acc@5 98.828 (99.364)
Epoch: [47][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.6938 (0.6970)	Acc@1 84.766 (85.871)	Acc@5 99.219 (99.326)
Max memory in training epoch: 62.7239424
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.166 (0.166)	Data 0.269 (0.269)	Loss 0.6910 (0.6910)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [48][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.6631 (0.6839)	Acc@1 87.109 (86.148)	Acc@5 99.609 (99.549)
Epoch: [48][128/196]	Time 0.120 (0.131)	Data 0.000 (0.002)	Loss 0.6200 (0.6843)	Acc@1 90.234 (86.186)	Acc@5 99.609 (99.500)
Epoch: [48][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6672 (0.6925)	Acc@1 88.281 (85.962)	Acc@5 98.828 (99.458)
Max memory in training epoch: 62.7239424
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.152 (0.152)	Data 0.298 (0.298)	Loss 0.6776 (0.6776)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6582 (0.6971)	Acc@1 87.109 (85.853)	Acc@5 99.219 (99.375)
Epoch: [49][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6845 (0.6945)	Acc@1 87.109 (86.031)	Acc@5 99.219 (99.394)
Epoch: [49][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7182 (0.6956)	Acc@1 84.375 (85.840)	Acc@5 99.219 (99.421)
Max memory in training epoch: 62.7239424
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.151 (0.151)	Data 0.266 (0.266)	Loss 0.6618 (0.6618)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.7227 (0.7014)	Acc@1 85.156 (85.613)	Acc@5 98.828 (99.387)
Epoch: [50][128/196]	Time 0.146 (0.131)	Data 0.000 (0.002)	Loss 0.7198 (0.6994)	Acc@1 85.156 (85.774)	Acc@5 99.609 (99.413)
Epoch: [50][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7423 (0.6939)	Acc@1 84.766 (85.968)	Acc@5 99.609 (99.395)
Max memory in training epoch: 62.7239424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 363864 ; 373678 ; 0.9737367466107183
[INFO] Storing checkpoint...
  79.52
Max memory: 97.2319232
 25.971s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3165
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1535488
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.217 (0.217)	Data 0.272 (0.272)	Loss 0.6132 (0.6132)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.136 (0.128)	Data 0.000 (0.004)	Loss 0.6971 (0.6623)	Acc@1 85.547 (87.001)	Acc@5 99.219 (99.471)
Epoch: [51][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6284 (0.6789)	Acc@1 89.844 (86.531)	Acc@5 99.609 (99.373)
Epoch: [51][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7385 (0.6826)	Acc@1 87.109 (86.361)	Acc@5 98.828 (99.399)
Max memory in training epoch: 62.6760192
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.174 (0.174)	Data 0.305 (0.305)	Loss 0.6168 (0.6168)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.6857 (0.6885)	Acc@1 85.938 (85.913)	Acc@5 100.000 (99.459)
Epoch: [52][128/196]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.7482 (0.6977)	Acc@1 83.984 (85.504)	Acc@5 99.219 (99.403)
Epoch: [52][192/196]	Time 0.130 (0.126)	Data 0.000 (0.002)	Loss 0.7818 (0.6947)	Acc@1 85.156 (85.782)	Acc@5 100.000 (99.415)
Max memory in training epoch: 62.3614464
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.178 (0.178)	Data 0.280 (0.280)	Loss 0.6683 (0.6683)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [53][64/196]	Time 0.142 (0.130)	Data 0.000 (0.005)	Loss 0.6794 (0.6923)	Acc@1 87.500 (85.913)	Acc@5 98.438 (99.423)
Epoch: [53][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6503 (0.6927)	Acc@1 86.328 (85.947)	Acc@5 99.609 (99.452)
Epoch: [53][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7022 (0.6863)	Acc@1 83.984 (86.118)	Acc@5 99.609 (99.449)
Max memory in training epoch: 62.3614464
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.185 (0.185)	Data 0.297 (0.297)	Loss 0.6039 (0.6039)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6822 (0.6754)	Acc@1 87.500 (86.611)	Acc@5 98.438 (99.459)
Epoch: [54][128/196]	Time 0.141 (0.128)	Data 0.000 (0.002)	Loss 0.6619 (0.6838)	Acc@1 87.500 (86.086)	Acc@5 98.828 (99.431)
Epoch: [54][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6244 (0.6859)	Acc@1 87.891 (85.996)	Acc@5 99.219 (99.441)
Max memory in training epoch: 62.3614464
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.166 (0.166)	Data 0.273 (0.273)	Loss 0.6868 (0.6868)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [55][64/196]	Time 0.128 (0.128)	Data 0.000 (0.004)	Loss 0.6553 (0.6827)	Acc@1 86.719 (85.944)	Acc@5 100.000 (99.537)
Epoch: [55][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6741 (0.6810)	Acc@1 85.938 (86.122)	Acc@5 99.609 (99.512)
Epoch: [55][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.5889 (0.6801)	Acc@1 89.844 (86.182)	Acc@5 99.219 (99.468)
Max memory in training epoch: 62.3614464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 355204 ; 363864 ; 0.9761998988633116
[INFO] Storing checkpoint...
  79.01
Max memory: 97.3987328
 25.313s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1368
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1499648
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.194 (0.194)	Data 0.260 (0.260)	Loss 0.6406 (0.6406)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [56][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.7060 (0.6594)	Acc@1 85.547 (86.821)	Acc@5 99.219 (99.423)
Epoch: [56][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.6200 (0.6769)	Acc@1 88.281 (86.231)	Acc@5 99.219 (99.449)
Epoch: [56][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6709 (0.6767)	Acc@1 89.062 (86.233)	Acc@5 99.609 (99.437)
Max memory in training epoch: 61.9801088
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.180 (0.180)	Data 0.259 (0.259)	Loss 0.6287 (0.6287)	Acc@1 88.281 (88.281)	Acc@5 98.828 (98.828)
Epoch: [57][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.6442 (0.6818)	Acc@1 89.453 (86.274)	Acc@5 99.609 (99.345)
Epoch: [57][128/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.7154 (0.6840)	Acc@1 85.156 (86.074)	Acc@5 99.219 (99.413)
Epoch: [57][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7273 (0.6869)	Acc@1 86.328 (86.006)	Acc@5 100.000 (99.431)
Max memory in training epoch: 61.9801088
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.175 (0.175)	Data 0.279 (0.279)	Loss 0.7566 (0.7566)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.6085 (0.6860)	Acc@1 87.109 (86.220)	Acc@5 100.000 (99.411)
Epoch: [58][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6993 (0.6875)	Acc@1 85.547 (86.053)	Acc@5 98.438 (99.413)
Epoch: [58][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7678 (0.6878)	Acc@1 83.594 (85.919)	Acc@5 98.828 (99.419)
Max memory in training epoch: 61.9801088
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.177 (0.177)	Data 0.271 (0.271)	Loss 0.6240 (0.6240)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.7186 (0.6922)	Acc@1 83.594 (85.938)	Acc@5 99.609 (99.501)
Epoch: [59][128/196]	Time 0.156 (0.128)	Data 0.000 (0.002)	Loss 0.6553 (0.6878)	Acc@1 86.328 (85.950)	Acc@5 98.438 (99.413)
Epoch: [59][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7199 (0.6868)	Acc@1 84.766 (85.938)	Acc@5 99.219 (99.421)
Max memory in training epoch: 61.9801088
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.168 (0.168)	Data 0.293 (0.293)	Loss 0.6436 (0.6436)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.6872 (0.6807)	Acc@1 86.719 (86.112)	Acc@5 100.000 (99.519)
Epoch: [60][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6555 (0.6819)	Acc@1 89.844 (86.095)	Acc@5 100.000 (99.470)
Epoch: [60][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.8161 (0.6797)	Acc@1 80.859 (86.282)	Acc@5 99.219 (99.452)
Max memory in training epoch: 61.9801088
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 348558 ; 355204 ; 0.9812896251168343
[INFO] Storing checkpoint...
  71.94
Max memory: 96.4411904
 25.466s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1355
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1473024
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.197 (0.197)	Data 0.268 (0.268)	Loss 0.7289 (0.7289)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.6621 (0.6486)	Acc@1 86.328 (87.554)	Acc@5 99.219 (99.471)
Epoch: [61][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6817 (0.6583)	Acc@1 84.375 (87.106)	Acc@5 99.609 (99.437)
Epoch: [61][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6506 (0.6715)	Acc@1 85.938 (86.569)	Acc@5 100.000 (99.468)
Max memory in training epoch: 61.2092416
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.174 (0.174)	Data 0.274 (0.274)	Loss 0.6261 (0.6261)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6768 (0.6800)	Acc@1 85.547 (86.178)	Acc@5 99.609 (99.447)
Epoch: [62][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6898 (0.6723)	Acc@1 85.938 (86.492)	Acc@5 98.828 (99.485)
Epoch: [62][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6855 (0.6738)	Acc@1 84.375 (86.460)	Acc@5 99.609 (99.484)
Max memory in training epoch: 61.2616704
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.182 (0.182)	Data 0.306 (0.306)	Loss 0.7281 (0.7281)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.6574 (0.6701)	Acc@1 87.500 (86.304)	Acc@5 98.438 (99.507)
Epoch: [63][128/196]	Time 0.134 (0.129)	Data 0.000 (0.003)	Loss 0.6135 (0.6782)	Acc@1 89.062 (86.074)	Acc@5 99.219 (99.443)
Epoch: [63][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7271 (0.6837)	Acc@1 84.375 (86.002)	Acc@5 100.000 (99.433)
Max memory in training epoch: 61.2616704
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.156 (0.156)	Data 0.273 (0.273)	Loss 0.6346 (0.6346)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [64][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7891 (0.6774)	Acc@1 82.812 (86.274)	Acc@5 98.828 (99.489)
Epoch: [64][128/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6400 (0.6726)	Acc@1 84.766 (86.455)	Acc@5 100.000 (99.500)
Epoch: [64][192/196]	Time 0.140 (0.128)	Data 0.000 (0.002)	Loss 0.5897 (0.6735)	Acc@1 87.500 (86.253)	Acc@5 100.000 (99.500)
Max memory in training epoch: 61.2616704
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.173 (0.173)	Data 0.266 (0.266)	Loss 0.6696 (0.6696)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7008 (0.6831)	Acc@1 86.328 (85.721)	Acc@5 98.047 (99.405)
Epoch: [65][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6290 (0.6808)	Acc@1 88.672 (86.013)	Acc@5 99.219 (99.443)
Epoch: [65][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6333 (0.6755)	Acc@1 90.234 (86.259)	Acc@5 99.609 (99.445)
Max memory in training epoch: 61.2616704
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 341338 ; 348558 ; 0.9792860872509023
[INFO] Storing checkpoint...
  79.43
Max memory: 94.6768384
 25.369s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2309
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1444352
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.184 (0.184)	Data 0.283 (0.283)	Loss 0.5852 (0.5852)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.6181 (0.6405)	Acc@1 87.891 (87.356)	Acc@5 100.000 (99.561)
Epoch: [66][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7491 (0.6573)	Acc@1 85.938 (86.858)	Acc@5 99.609 (99.503)
Epoch: [66][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6705 (0.6618)	Acc@1 85.547 (86.666)	Acc@5 100.000 (99.462)
Max memory in training epoch: 60.5686272
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.183 (0.183)	Data 0.265 (0.265)	Loss 0.6524 (0.6524)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.6712 (0.6803)	Acc@1 86.719 (86.436)	Acc@5 100.000 (99.429)
Epoch: [67][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.5895 (0.6780)	Acc@1 88.672 (86.292)	Acc@5 100.000 (99.467)
Epoch: [67][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.7393 (0.6755)	Acc@1 85.547 (86.476)	Acc@5 98.828 (99.441)
Max memory in training epoch: 60.7783424
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.169 (0.169)	Data 0.289 (0.289)	Loss 0.6511 (0.6511)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.6488 (0.6619)	Acc@1 88.281 (86.478)	Acc@5 99.219 (99.477)
Epoch: [68][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6805 (0.6678)	Acc@1 84.375 (86.361)	Acc@5 99.219 (99.455)
Epoch: [68][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.7654 (0.6746)	Acc@1 83.594 (86.217)	Acc@5 99.609 (99.433)
Max memory in training epoch: 60.7783424
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.165 (0.165)	Data 0.316 (0.316)	Loss 0.5504 (0.5504)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6937 (0.6740)	Acc@1 85.938 (86.154)	Acc@5 98.828 (99.429)
Epoch: [69][128/196]	Time 0.127 (0.129)	Data 0.000 (0.003)	Loss 0.7416 (0.6717)	Acc@1 85.156 (86.374)	Acc@5 99.219 (99.385)
Epoch: [69][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.8071 (0.6754)	Acc@1 82.812 (86.223)	Acc@5 99.219 (99.393)
Max memory in training epoch: 60.7783424
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.167 (0.167)	Data 0.306 (0.306)	Loss 0.6829 (0.6829)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.6736 (0.6634)	Acc@1 87.891 (86.478)	Acc@5 99.609 (99.543)
Epoch: [70][128/196]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.6303 (0.6747)	Acc@1 85.938 (86.080)	Acc@5 100.000 (99.476)
Epoch: [70][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7514 (0.6742)	Acc@1 84.375 (86.146)	Acc@5 99.219 (99.480)
Max memory in training epoch: 60.7783424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 334404 ; 341338 ; 0.9796858246078667
[INFO] Storing checkpoint...
  77.54
Max memory: 93.0028032
 25.090s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8952
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1416704
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.204 (0.204)	Data 0.276 (0.276)	Loss 0.6566 (0.6566)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [71][64/196]	Time 0.128 (0.126)	Data 0.000 (0.004)	Loss 0.7852 (0.6492)	Acc@1 82.422 (87.049)	Acc@5 99.609 (99.489)
Epoch: [71][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.6895 (0.6579)	Acc@1 85.938 (86.746)	Acc@5 99.219 (99.516)
Epoch: [71][192/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.8399 (0.6632)	Acc@1 82.812 (86.518)	Acc@5 98.828 (99.496)
Max memory in training epoch: 59.5876352
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.181 (0.181)	Data 0.261 (0.261)	Loss 0.6380 (0.6380)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.6699 (0.6757)	Acc@1 87.109 (86.370)	Acc@5 98.828 (99.411)
Epoch: [72][128/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.6524 (0.6734)	Acc@1 87.109 (86.322)	Acc@5 100.000 (99.440)
Epoch: [72][192/196]	Time 0.130 (0.125)	Data 0.000 (0.002)	Loss 0.6319 (0.6725)	Acc@1 85.547 (86.365)	Acc@5 99.609 (99.464)
Max memory in training epoch: 59.6924928
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.171 (0.171)	Data 0.280 (0.280)	Loss 0.5843 (0.5843)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)
Epoch: [73][64/196]	Time 0.125 (0.126)	Data 0.000 (0.004)	Loss 0.7602 (0.6695)	Acc@1 82.031 (86.484)	Acc@5 99.609 (99.471)
Epoch: [73][128/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.6762 (0.6745)	Acc@1 86.328 (86.234)	Acc@5 99.609 (99.461)
Epoch: [73][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.5708 (0.6705)	Acc@1 89.062 (86.379)	Acc@5 99.609 (99.454)
Max memory in training epoch: 59.6924928
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.188 (0.188)	Data 0.266 (0.266)	Loss 0.6973 (0.6973)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.6558 (0.6667)	Acc@1 87.109 (86.478)	Acc@5 99.609 (99.447)
Epoch: [74][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6195 (0.6675)	Acc@1 88.672 (86.528)	Acc@5 99.609 (99.476)
Epoch: [74][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.5419 (0.6637)	Acc@1 89.844 (86.575)	Acc@5 100.000 (99.488)
Max memory in training epoch: 59.6924928
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.171 (0.171)	Data 0.302 (0.302)	Loss 0.6449 (0.6449)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.7645 (0.6656)	Acc@1 83.594 (86.809)	Acc@5 98.438 (99.447)
Epoch: [75][128/196]	Time 0.128 (0.126)	Data 0.000 (0.003)	Loss 0.6077 (0.6681)	Acc@1 87.500 (86.655)	Acc@5 99.609 (99.491)
Epoch: [75][192/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.6756 (0.6696)	Acc@1 86.328 (86.541)	Acc@5 100.000 (99.484)
Max memory in training epoch: 59.6924928
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 331802 ; 334404 ; 0.9922189925957824
[INFO] Storing checkpoint...
  78.76
Max memory: 92.0794624
 25.142s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2872
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1407488
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.202 (0.202)	Data 0.265 (0.265)	Loss 0.7029 (0.7029)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [76][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.5795 (0.6369)	Acc@1 91.016 (87.488)	Acc@5 100.000 (99.507)
Epoch: [76][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7371 (0.6542)	Acc@1 84.375 (86.840)	Acc@5 99.609 (99.458)
Epoch: [76][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7517 (0.6610)	Acc@1 83.984 (86.616)	Acc@5 98.438 (99.462)
Max memory in training epoch: 59.269376
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.166 (0.166)	Data 0.269 (0.269)	Loss 0.5929 (0.5929)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.135 (0.128)	Data 0.000 (0.004)	Loss 0.5846 (0.6711)	Acc@1 89.453 (86.382)	Acc@5 99.609 (99.471)
Epoch: [77][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.7186 (0.6654)	Acc@1 87.109 (86.616)	Acc@5 98.828 (99.458)
Epoch: [77][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7366 (0.6671)	Acc@1 83.594 (86.520)	Acc@5 99.609 (99.419)
Max memory in training epoch: 59.2431616
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.174 (0.174)	Data 0.257 (0.257)	Loss 0.6052 (0.6052)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.6663 (0.6520)	Acc@1 87.109 (86.983)	Acc@5 99.219 (99.507)
Epoch: [78][128/196]	Time 0.139 (0.128)	Data 0.000 (0.002)	Loss 0.7126 (0.6652)	Acc@1 84.375 (86.473)	Acc@5 99.609 (99.467)
Epoch: [78][192/196]	Time 0.121 (0.128)	Data 0.000 (0.001)	Loss 0.5982 (0.6652)	Acc@1 87.500 (86.551)	Acc@5 99.609 (99.466)
Max memory in training epoch: 59.2431616
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.169 (0.169)	Data 0.292 (0.292)	Loss 0.6196 (0.6196)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [79][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7169 (0.6767)	Acc@1 85.938 (86.082)	Acc@5 98.047 (99.507)
Epoch: [79][128/196]	Time 0.137 (0.128)	Data 0.000 (0.002)	Loss 0.7244 (0.6700)	Acc@1 86.719 (86.461)	Acc@5 100.000 (99.549)
Epoch: [79][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6419 (0.6706)	Acc@1 88.672 (86.417)	Acc@5 99.609 (99.516)
Max memory in training epoch: 59.2431616
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.187 (0.187)	Data 0.321 (0.321)	Loss 0.7468 (0.7468)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [80][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.6256 (0.6650)	Acc@1 85.156 (86.737)	Acc@5 99.219 (99.489)
Epoch: [80][128/196]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.6029 (0.6714)	Acc@1 89.453 (86.449)	Acc@5 99.609 (99.500)
Epoch: [80][192/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.6466 (0.6688)	Acc@1 87.109 (86.417)	Acc@5 99.219 (99.508)
Max memory in training epoch: 59.2431616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 329712 ; 331802 ; 0.9937010626819609
[INFO] Storing checkpoint...
  77.74
Max memory: 91.3238528
 25.790s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7335
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1394176
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.187 (0.187)	Data 0.285 (0.285)	Loss 0.6048 (0.6048)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.120 (0.118)	Data 0.000 (0.005)	Loss 0.6140 (0.6286)	Acc@1 87.500 (87.644)	Acc@5 99.609 (99.549)
Epoch: [81][128/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.7880 (0.6553)	Acc@1 84.766 (86.746)	Acc@5 98.047 (99.470)
Epoch: [81][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.7460 (0.6629)	Acc@1 85.938 (86.549)	Acc@5 98.438 (99.443)
Max memory in training epoch: 56.4862464
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.154 (0.154)	Data 0.292 (0.292)	Loss 0.5897 (0.5897)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.123 (0.118)	Data 0.000 (0.005)	Loss 0.6793 (0.6654)	Acc@1 85.547 (86.611)	Acc@5 99.609 (99.363)
Epoch: [82][128/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.7181 (0.6653)	Acc@1 86.719 (86.552)	Acc@5 99.219 (99.397)
Epoch: [82][192/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.5140 (0.6671)	Acc@1 92.578 (86.516)	Acc@5 100.000 (99.415)
Max memory in training epoch: 56.5386752
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.170 (0.170)	Data 0.270 (0.270)	Loss 0.6895 (0.6895)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.138 (0.121)	Data 0.000 (0.004)	Loss 0.7153 (0.6335)	Acc@1 86.719 (87.680)	Acc@5 100.000 (99.543)
Epoch: [83][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.6595 (0.6550)	Acc@1 85.156 (86.991)	Acc@5 98.828 (99.452)
Epoch: [83][192/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.6771 (0.6563)	Acc@1 86.328 (86.887)	Acc@5 98.828 (99.449)
Max memory in training epoch: 56.5386752
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.149 (0.149)	Data 0.299 (0.299)	Loss 0.6522 (0.6522)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.6010 (0.6639)	Acc@1 89.453 (86.412)	Acc@5 98.828 (99.507)
Epoch: [84][128/196]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.6210 (0.6622)	Acc@1 85.938 (86.428)	Acc@5 99.609 (99.519)
Epoch: [84][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.6376 (0.6657)	Acc@1 88.672 (86.350)	Acc@5 99.609 (99.514)
Max memory in training epoch: 56.5386752
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.140 (0.140)	Data 0.293 (0.293)	Loss 0.6699 (0.6699)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.6720 (0.6555)	Acc@1 86.719 (86.761)	Acc@5 99.609 (99.441)
Epoch: [85][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.7075 (0.6596)	Acc@1 84.766 (86.558)	Acc@5 99.609 (99.431)
Epoch: [85][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.6551 (0.6613)	Acc@1 87.891 (86.587)	Acc@5 98.828 (99.441)
Max memory in training epoch: 56.5386752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 328556 ; 329712 ; 0.9964939098364634
[INFO] Storing checkpoint...
  80.57
Max memory: 87.557888
 24.447s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7021
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1389056
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.208 (0.208)	Data 0.271 (0.271)	Loss 0.6549 (0.6549)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.5844 (0.6342)	Acc@1 89.453 (87.320)	Acc@5 99.609 (99.495)
Epoch: [86][128/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.6535 (0.6485)	Acc@1 87.109 (86.961)	Acc@5 99.609 (99.470)
Epoch: [86][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.7632 (0.6573)	Acc@1 82.812 (86.652)	Acc@5 99.609 (99.437)
Max memory in training epoch: 56.3793408
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.171 (0.171)	Data 0.267 (0.267)	Loss 0.7376 (0.7376)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [87][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.6204 (0.6451)	Acc@1 84.766 (87.296)	Acc@5 100.000 (99.507)
Epoch: [87][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.7535 (0.6578)	Acc@1 81.250 (86.685)	Acc@5 98.438 (99.509)
Epoch: [87][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.6949 (0.6611)	Acc@1 86.328 (86.559)	Acc@5 99.219 (99.470)
Max memory in training epoch: 56.4841984
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.172 (0.172)	Data 0.266 (0.266)	Loss 0.6581 (0.6581)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.6728 (0.6477)	Acc@1 87.891 (87.230)	Acc@5 99.609 (99.513)
Epoch: [88][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6594 (0.6579)	Acc@1 87.891 (86.804)	Acc@5 98.828 (99.467)
Epoch: [88][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6674 (0.6586)	Acc@1 86.328 (86.624)	Acc@5 98.438 (99.466)
Max memory in training epoch: 56.4841984
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.146 (0.146)	Data 0.308 (0.308)	Loss 0.6102 (0.6102)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [89][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.6210 (0.6558)	Acc@1 86.328 (86.569)	Acc@5 100.000 (99.471)
Epoch: [89][128/196]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.6465 (0.6536)	Acc@1 85.547 (86.616)	Acc@5 99.609 (99.528)
Epoch: [89][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.6233 (0.6592)	Acc@1 90.234 (86.539)	Acc@5 98.438 (99.480)
Max memory in training epoch: 56.4841984
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.176 (0.176)	Data 0.285 (0.285)	Loss 0.6770 (0.6770)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [90][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.5781 (0.6544)	Acc@1 89.844 (86.845)	Acc@5 100.000 (99.459)
Epoch: [90][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6624 (0.6553)	Acc@1 86.328 (86.691)	Acc@5 100.000 (99.488)
Epoch: [90][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.6933 (0.6647)	Acc@1 82.422 (86.383)	Acc@5 99.609 (99.454)
Max memory in training epoch: 56.4841984
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 326388 ; 328556 ; 0.9934014292845056
[INFO] Storing checkpoint...
  74.08
Max memory: 87.560448
 23.771s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3373
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1381376
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.183 (0.183)	Data 0.282 (0.282)	Loss 0.6040 (0.6040)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.6668 (0.6389)	Acc@1 84.766 (87.434)	Acc@5 100.000 (99.495)
Epoch: [91][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.6124 (0.6438)	Acc@1 87.109 (87.128)	Acc@5 100.000 (99.470)
Epoch: [91][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6741 (0.6506)	Acc@1 88.672 (86.899)	Acc@5 99.609 (99.462)
Max memory in training epoch: 56.192768
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.140 (0.140)	Data 0.300 (0.300)	Loss 0.6969 (0.6969)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.6215 (0.6489)	Acc@1 87.891 (87.115)	Acc@5 98.828 (99.489)
Epoch: [92][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6112 (0.6571)	Acc@1 87.109 (86.746)	Acc@5 99.609 (99.491)
Epoch: [92][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6827 (0.6605)	Acc@1 85.547 (86.622)	Acc@5 99.219 (99.484)
Max memory in training epoch: 56.0354816
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.165 (0.165)	Data 0.291 (0.291)	Loss 0.6006 (0.6006)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [93][64/196]	Time 0.137 (0.122)	Data 0.000 (0.005)	Loss 0.5520 (0.5692)	Acc@1 89.844 (89.736)	Acc@5 100.000 (99.706)
Epoch: [93][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.5214 (0.5397)	Acc@1 92.578 (90.686)	Acc@5 99.609 (99.788)
Epoch: [93][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.5332 (0.5257)	Acc@1 88.672 (91.176)	Acc@5 99.609 (99.773)
Max memory in training epoch: 56.0354816
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.167 (0.167)	Data 0.266 (0.266)	Loss 0.4529 (0.4529)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.4896 (0.4796)	Acc@1 91.406 (92.722)	Acc@5 100.000 (99.844)
Epoch: [94][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.4691 (0.4742)	Acc@1 91.797 (92.829)	Acc@5 100.000 (99.849)
Epoch: [94][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.4813 (0.4705)	Acc@1 91.797 (92.930)	Acc@5 99.609 (99.850)
Max memory in training epoch: 56.0354816
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.160 (0.160)	Data 0.298 (0.298)	Loss 0.4476 (0.4476)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.4322 (0.4514)	Acc@1 94.531 (93.510)	Acc@5 100.000 (99.850)
Epoch: [95][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.4028 (0.4481)	Acc@1 94.922 (93.623)	Acc@5 100.000 (99.858)
Epoch: [95][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.4649 (0.4488)	Acc@1 92.578 (93.485)	Acc@5 100.000 (99.868)
Max memory in training epoch: 56.0354816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 325954 ; 326388 ; 0.9986702942510142
[INFO] Storing checkpoint...
  90.98
Max memory: 87.1059456
 23.977s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2074
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.194 (0.194)	Data 0.255 (0.255)	Loss 0.4299 (0.4299)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [96][64/196]	Time 0.116 (0.120)	Data 0.000 (0.004)	Loss 0.4303 (0.4363)	Acc@1 94.922 (93.768)	Acc@5 100.000 (99.916)
Epoch: [96][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3721 (0.4355)	Acc@1 95.703 (93.817)	Acc@5 100.000 (99.903)
Epoch: [96][192/196]	Time 0.119 (0.121)	Data 0.000 (0.001)	Loss 0.4106 (0.4314)	Acc@1 94.531 (93.902)	Acc@5 100.000 (99.893)
Max memory in training epoch: 56.0610816
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.148 (0.148)	Data 0.293 (0.293)	Loss 0.3880 (0.3880)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.4742 (0.4232)	Acc@1 91.016 (94.093)	Acc@5 99.609 (99.856)
Epoch: [97][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3921 (0.4222)	Acc@1 96.094 (94.110)	Acc@5 100.000 (99.867)
Epoch: [97][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.4535 (0.4212)	Acc@1 93.359 (94.175)	Acc@5 100.000 (99.866)
Max memory in training epoch: 55.9037952
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.181 (0.181)	Data 0.317 (0.317)	Loss 0.3620 (0.3620)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.4320 (0.3978)	Acc@1 92.969 (94.718)	Acc@5 100.000 (99.946)
Epoch: [98][128/196]	Time 0.111 (0.121)	Data 0.000 (0.003)	Loss 0.3930 (0.4014)	Acc@1 94.531 (94.549)	Acc@5 100.000 (99.918)
Epoch: [98][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.4210 (0.4046)	Acc@1 94.531 (94.460)	Acc@5 98.828 (99.903)
Max memory in training epoch: 55.9037952
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.185 (0.185)	Data 0.307 (0.307)	Loss 0.3691 (0.3691)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.3737 (0.3924)	Acc@1 96.094 (94.748)	Acc@5 100.000 (99.868)
Epoch: [99][128/196]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.4286 (0.3946)	Acc@1 93.359 (94.698)	Acc@5 100.000 (99.900)
Epoch: [99][192/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.3916 (0.3941)	Acc@1 93.359 (94.740)	Acc@5 99.609 (99.907)
Max memory in training epoch: 55.9037952
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.166 (0.166)	Data 0.271 (0.271)	Loss 0.3925 (0.3925)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.3698 (0.3854)	Acc@1 96.094 (95.030)	Acc@5 100.000 (99.916)
Epoch: [100][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3986 (0.3840)	Acc@1 94.922 (94.988)	Acc@5 100.000 (99.912)
Epoch: [100][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3713 (0.3842)	Acc@1 94.531 (94.922)	Acc@5 100.000 (99.915)
Max memory in training epoch: 55.9037952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 325376 ; 325954 ; 0.9982267436509447
[INFO] Storing checkpoint...
  91.44
Max memory: 87.159552
 24.127s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 485
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1376768
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.202 (0.202)	Data 0.262 (0.262)	Loss 0.3464 (0.3464)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.3737 (0.3690)	Acc@1 95.312 (95.337)	Acc@5 99.609 (99.916)
Epoch: [101][128/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.3709 (0.3727)	Acc@1 94.922 (95.137)	Acc@5 100.000 (99.933)
Epoch: [101][192/196]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.3440 (0.3745)	Acc@1 96.875 (95.037)	Acc@5 100.000 (99.935)
Max memory in training epoch: 56.007424
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.171 (0.171)	Data 0.293 (0.293)	Loss 0.3679 (0.3679)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.3840 (0.3608)	Acc@1 94.922 (95.361)	Acc@5 100.000 (99.952)
Epoch: [102][128/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.3210 (0.3670)	Acc@1 96.094 (95.213)	Acc@5 100.000 (99.936)
Epoch: [102][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.4176 (0.3672)	Acc@1 92.578 (95.173)	Acc@5 99.609 (99.923)
Max memory in training epoch: 55.876352
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.159 (0.159)	Data 0.301 (0.301)	Loss 0.3493 (0.3493)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.113 (0.122)	Data 0.000 (0.005)	Loss 0.3950 (0.3543)	Acc@1 94.531 (95.637)	Acc@5 100.000 (99.952)
Epoch: [103][128/196]	Time 0.124 (0.121)	Data 0.000 (0.003)	Loss 0.3484 (0.3582)	Acc@1 95.703 (95.440)	Acc@5 100.000 (99.945)
Epoch: [103][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3429 (0.3597)	Acc@1 94.531 (95.359)	Acc@5 100.000 (99.949)
Max memory in training epoch: 55.876352
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.171 (0.171)	Data 0.291 (0.291)	Loss 0.3359 (0.3359)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.128 (0.123)	Data 0.000 (0.005)	Loss 0.3254 (0.3452)	Acc@1 96.875 (95.757)	Acc@5 100.000 (99.946)
Epoch: [104][128/196]	Time 0.132 (0.122)	Data 0.000 (0.002)	Loss 0.3561 (0.3501)	Acc@1 95.703 (95.503)	Acc@5 100.000 (99.945)
Epoch: [104][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3711 (0.3519)	Acc@1 94.531 (95.406)	Acc@5 100.000 (99.943)
Max memory in training epoch: 55.876352
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.180 (0.180)	Data 0.274 (0.274)	Loss 0.3742 (0.3742)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [105][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.3423 (0.3417)	Acc@1 94.922 (95.769)	Acc@5 99.609 (99.928)
Epoch: [105][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3204 (0.3428)	Acc@1 96.484 (95.621)	Acc@5 100.000 (99.936)
Epoch: [105][192/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.3504 (0.3440)	Acc@1 96.484 (95.572)	Acc@5 99.219 (99.931)
Max memory in training epoch: 55.876352
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 323932 ; 325376 ; 0.9955620574350905
[INFO] Storing checkpoint...
  91.23
Max memory: 87.0824448
 24.151s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 845
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1371648
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.211 (0.211)	Data 0.262 (0.262)	Loss 0.3363 (0.3363)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [106][64/196]	Time 0.126 (0.122)	Data 0.000 (0.004)	Loss 0.3524 (0.3321)	Acc@1 95.312 (95.998)	Acc@5 100.000 (99.964)
Epoch: [106][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3292 (0.3321)	Acc@1 96.484 (95.964)	Acc@5 100.000 (99.955)
Epoch: [106][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3711 (0.3357)	Acc@1 95.312 (95.782)	Acc@5 100.000 (99.935)
Max memory in training epoch: 55.7956608
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.160 (0.160)	Data 0.297 (0.297)	Loss 0.3428 (0.3428)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.3430 (0.3314)	Acc@1 93.750 (95.859)	Acc@5 99.609 (99.964)
Epoch: [107][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3454 (0.3326)	Acc@1 95.312 (95.758)	Acc@5 100.000 (99.952)
Epoch: [107][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3068 (0.3333)	Acc@1 96.484 (95.691)	Acc@5 100.000 (99.945)
Max memory in training epoch: 55.874304
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.144 (0.144)	Data 0.288 (0.288)	Loss 0.2911 (0.2911)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.124 (0.125)	Data 0.000 (0.005)	Loss 0.3160 (0.3188)	Acc@1 96.094 (96.244)	Acc@5 100.000 (99.976)
Epoch: [108][128/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.3043 (0.3236)	Acc@1 97.266 (95.979)	Acc@5 100.000 (99.967)
Epoch: [108][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2775 (0.3271)	Acc@1 97.656 (95.806)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.874304
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.147 (0.147)	Data 0.261 (0.261)	Loss 0.3021 (0.3021)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.132 (0.121)	Data 0.000 (0.004)	Loss 0.3499 (0.3194)	Acc@1 95.703 (95.950)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3159 (0.3219)	Acc@1 96.484 (95.852)	Acc@5 99.609 (99.979)
Epoch: [109][192/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.3331 (0.3254)	Acc@1 96.094 (95.782)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.874304
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.163 (0.163)	Data 0.331 (0.331)	Loss 0.3164 (0.3164)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.146 (0.122)	Data 0.000 (0.005)	Loss 0.2796 (0.3107)	Acc@1 98.438 (96.322)	Acc@5 100.000 (99.964)
Epoch: [110][128/196]	Time 0.122 (0.121)	Data 0.000 (0.003)	Loss 0.2823 (0.3174)	Acc@1 97.656 (95.991)	Acc@5 100.000 (99.942)
Epoch: [110][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3072 (0.3192)	Acc@1 96.484 (95.906)	Acc@5 100.000 (99.945)
Max memory in training epoch: 55.874304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.95
Max memory: 87.012096
 24.078s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5241
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1371648
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.175 (0.175)	Data 0.283 (0.283)	Loss 0.2708 (0.2708)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 0.3645 (0.3050)	Acc@1 94.531 (96.466)	Acc@5 100.000 (99.970)
Epoch: [111][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.3271 (0.3109)	Acc@1 95.703 (96.142)	Acc@5 100.000 (99.964)
Epoch: [111][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.2918 (0.3146)	Acc@1 96.875 (95.918)	Acc@5 100.000 (99.955)
Max memory in training epoch: 55.7956608
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.165 (0.165)	Data 0.290 (0.290)	Loss 0.2749 (0.2749)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.3261 (0.3076)	Acc@1 95.312 (96.160)	Acc@5 100.000 (99.976)
Epoch: [112][128/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.2946 (0.3091)	Acc@1 97.266 (96.085)	Acc@5 100.000 (99.970)
Epoch: [112][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3385 (0.3121)	Acc@1 95.312 (95.960)	Acc@5 100.000 (99.962)
Max memory in training epoch: 55.874304
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.171 (0.171)	Data 0.289 (0.289)	Loss 0.2954 (0.2954)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.124 (0.119)	Data 0.000 (0.005)	Loss 0.2743 (0.3018)	Acc@1 96.484 (96.118)	Acc@5 100.000 (99.970)
Epoch: [113][128/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.3008 (0.3058)	Acc@1 96.094 (95.988)	Acc@5 100.000 (99.961)
Epoch: [113][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3647 (0.3083)	Acc@1 92.578 (95.948)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.874304
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.167 (0.167)	Data 0.265 (0.265)	Loss 0.2786 (0.2786)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.124 (0.122)	Data 0.000 (0.004)	Loss 0.3248 (0.3074)	Acc@1 95.703 (95.998)	Acc@5 100.000 (99.976)
Epoch: [114][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3011 (0.3093)	Acc@1 96.484 (95.842)	Acc@5 100.000 (99.970)
Epoch: [114][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3422 (0.3119)	Acc@1 94.922 (95.758)	Acc@5 100.000 (99.957)
Max memory in training epoch: 55.874304
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.152 (0.152)	Data 0.269 (0.269)	Loss 0.2838 (0.2838)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.3185 (0.3102)	Acc@1 94.922 (95.679)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3332 (0.3086)	Acc@1 95.312 (95.758)	Acc@5 100.000 (99.961)
Epoch: [115][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2971 (0.3097)	Acc@1 96.484 (95.778)	Acc@5 100.000 (99.955)
Max memory in training epoch: 55.874304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 323642 ; 323932 ; 0.9991047503797094
[INFO] Storing checkpoint...
  90.21
Max memory: 87.012096
 23.785s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7186
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1370624
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.178 (0.178)	Data 0.270 (0.270)	Loss 0.3090 (0.3090)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.115 (0.119)	Data 0.000 (0.004)	Loss 0.3410 (0.2924)	Acc@1 94.531 (96.310)	Acc@5 100.000 (99.976)
Epoch: [116][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.3288 (0.2986)	Acc@1 95.312 (96.142)	Acc@5 100.000 (99.964)
Epoch: [116][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3215 (0.3003)	Acc@1 94.922 (96.057)	Acc@5 100.000 (99.962)
Max memory in training epoch: 55.740672
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.172 (0.172)	Data 0.292 (0.292)	Loss 0.2623 (0.2623)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.3240 (0.2970)	Acc@1 95.703 (96.076)	Acc@5 100.000 (99.964)
Epoch: [117][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3021 (0.2995)	Acc@1 95.312 (95.903)	Acc@5 100.000 (99.967)
Epoch: [117][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.3276 (0.3008)	Acc@1 94.922 (95.899)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.176 (0.176)	Data 0.268 (0.268)	Loss 0.2802 (0.2802)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.3006 (0.3021)	Acc@1 96.875 (95.799)	Acc@5 100.000 (99.940)
Epoch: [118][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2922 (0.3023)	Acc@1 94.922 (95.791)	Acc@5 100.000 (99.952)
Epoch: [118][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2946 (0.3039)	Acc@1 95.312 (95.721)	Acc@5 100.000 (99.947)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.154 (0.154)	Data 0.298 (0.298)	Loss 0.2927 (0.2927)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2992 (0.3027)	Acc@1 96.484 (95.727)	Acc@5 100.000 (99.970)
Epoch: [119][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2540 (0.3033)	Acc@1 98.047 (95.739)	Acc@5 100.000 (99.961)
Epoch: [119][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3370 (0.3042)	Acc@1 94.922 (95.669)	Acc@5 99.609 (99.951)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.174 (0.174)	Data 0.260 (0.260)	Loss 0.2720 (0.2720)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.3157 (0.2931)	Acc@1 94.922 (96.094)	Acc@5 99.609 (99.952)
Epoch: [120][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.3169 (0.2951)	Acc@1 95.312 (95.985)	Acc@5 100.000 (99.961)
Epoch: [120][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2952 (0.2987)	Acc@1 95.703 (95.806)	Acc@5 100.000 (99.953)
Max memory in training epoch: 55.8738944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.9
Max memory: 86.4416256
 23.865s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4127
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1370624
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.171 (0.171)	Data 0.262 (0.262)	Loss 0.3169 (0.3169)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.113 (0.118)	Data 0.000 (0.004)	Loss 0.2763 (0.2855)	Acc@1 96.094 (96.376)	Acc@5 100.000 (99.982)
Epoch: [121][128/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.2607 (0.2925)	Acc@1 97.266 (96.127)	Acc@5 100.000 (99.970)
Epoch: [121][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.3176 (0.2944)	Acc@1 94.531 (96.001)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.740672
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.159 (0.159)	Data 0.295 (0.295)	Loss 0.2889 (0.2889)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.124 (0.119)	Data 0.000 (0.005)	Loss 0.3361 (0.2841)	Acc@1 93.750 (96.364)	Acc@5 100.000 (99.958)
Epoch: [122][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2845 (0.2938)	Acc@1 95.703 (95.961)	Acc@5 99.609 (99.955)
Epoch: [122][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2904 (0.2971)	Acc@1 96.094 (95.821)	Acc@5 100.000 (99.957)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.169 (0.169)	Data 0.322 (0.322)	Loss 0.3004 (0.3004)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [123][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.3044 (0.2894)	Acc@1 94.531 (96.088)	Acc@5 100.000 (99.970)
Epoch: [123][128/196]	Time 0.120 (0.119)	Data 0.000 (0.003)	Loss 0.2557 (0.2922)	Acc@1 96.484 (95.985)	Acc@5 100.000 (99.961)
Epoch: [123][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2702 (0.2943)	Acc@1 96.875 (95.893)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.149 (0.149)	Data 0.297 (0.297)	Loss 0.2582 (0.2582)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.109 (0.119)	Data 0.000 (0.005)	Loss 0.3379 (0.2934)	Acc@1 93.359 (95.974)	Acc@5 100.000 (99.952)
Epoch: [124][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3312 (0.2957)	Acc@1 92.578 (95.864)	Acc@5 99.609 (99.949)
Epoch: [124][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2959 (0.2958)	Acc@1 97.266 (95.865)	Acc@5 99.609 (99.947)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.176 (0.176)	Data 0.314 (0.314)	Loss 0.2478 (0.2478)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.2443 (0.2862)	Acc@1 98.438 (96.112)	Acc@5 100.000 (99.976)
Epoch: [125][128/196]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.3053 (0.2918)	Acc@1 94.531 (95.879)	Acc@5 100.000 (99.970)
Epoch: [125][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2870 (0.2961)	Acc@1 96.094 (95.705)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.8738944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.12
Max memory: 86.4416256
 24.200s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1504
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1370624
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.185 (0.185)	Data 0.263 (0.263)	Loss 0.2827 (0.2827)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.116 (0.121)	Data 0.000 (0.004)	Loss 0.2993 (0.2783)	Acc@1 94.922 (96.430)	Acc@5 100.000 (99.982)
Epoch: [126][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2982 (0.2874)	Acc@1 95.312 (96.106)	Acc@5 99.609 (99.967)
Epoch: [126][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.3462 (0.2924)	Acc@1 96.094 (95.908)	Acc@5 100.000 (99.957)
Max memory in training epoch: 55.740672
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.143 (0.143)	Data 0.297 (0.297)	Loss 0.3166 (0.3166)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2576 (0.2860)	Acc@1 97.656 (96.076)	Acc@5 100.000 (99.970)
Epoch: [127][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3861 (0.2917)	Acc@1 93.359 (95.830)	Acc@5 100.000 (99.970)
Epoch: [127][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2798 (0.2967)	Acc@1 95.703 (95.604)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.172 (0.172)	Data 0.290 (0.290)	Loss 0.2606 (0.2606)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.110 (0.121)	Data 0.000 (0.005)	Loss 0.2897 (0.2868)	Acc@1 95.703 (95.986)	Acc@5 100.000 (99.958)
Epoch: [128][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3077 (0.2917)	Acc@1 95.312 (95.824)	Acc@5 100.000 (99.961)
Epoch: [128][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2684 (0.2945)	Acc@1 97.266 (95.681)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.165 (0.165)	Data 0.288 (0.288)	Loss 0.3309 (0.3309)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2893 (0.2911)	Acc@1 95.703 (95.751)	Acc@5 100.000 (99.958)
Epoch: [129][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3176 (0.2896)	Acc@1 95.312 (95.818)	Acc@5 99.609 (99.952)
Epoch: [129][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.2579 (0.2921)	Acc@1 96.875 (95.723)	Acc@5 99.609 (99.953)
Max memory in training epoch: 55.8738944
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.170 (0.170)	Data 0.262 (0.262)	Loss 0.2556 (0.2556)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.128 (0.122)	Data 0.000 (0.004)	Loss 0.3012 (0.2942)	Acc@1 96.484 (95.739)	Acc@5 100.000 (99.964)
Epoch: [130][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2871 (0.2959)	Acc@1 96.094 (95.615)	Acc@5 100.000 (99.958)
Epoch: [130][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3162 (0.2980)	Acc@1 94.531 (95.505)	Acc@5 100.000 (99.955)
Max memory in training epoch: 55.8738944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 323064 ; 323642 ; 0.9982140760469902
[INFO] Storing checkpoint...
  89.58
Max memory: 86.4416256
 23.877s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3053
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1368576
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.169 (0.169)	Data 0.299 (0.299)	Loss 0.2979 (0.2979)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.2753 (0.2778)	Acc@1 97.266 (96.220)	Acc@5 100.000 (99.964)
Epoch: [131][128/196]	Time 0.112 (0.121)	Data 0.000 (0.003)	Loss 0.3109 (0.2837)	Acc@1 94.922 (95.997)	Acc@5 100.000 (99.961)
Epoch: [131][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3420 (0.2900)	Acc@1 93.750 (95.764)	Acc@5 99.609 (99.953)
Max memory in training epoch: 55.6091904
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.187 (0.187)	Data 0.311 (0.311)	Loss 0.3005 (0.3005)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.2602 (0.2852)	Acc@1 97.266 (96.094)	Acc@5 99.609 (99.976)
Epoch: [132][128/196]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.3932 (0.2977)	Acc@1 92.188 (95.603)	Acc@5 100.000 (99.976)
Epoch: [132][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3105 (0.2983)	Acc@1 94.141 (95.521)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.165 (0.165)	Data 0.298 (0.298)	Loss 0.3503 (0.3503)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.2911 (0.2891)	Acc@1 96.094 (95.817)	Acc@5 100.000 (99.964)
Epoch: [133][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2857 (0.2895)	Acc@1 95.703 (95.794)	Acc@5 99.609 (99.958)
Epoch: [133][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3007 (0.2937)	Acc@1 95.703 (95.606)	Acc@5 100.000 (99.953)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.174 (0.174)	Data 0.279 (0.279)	Loss 0.2782 (0.2782)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.2738 (0.2858)	Acc@1 96.875 (95.835)	Acc@5 100.000 (99.988)
Epoch: [134][128/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.2931 (0.2892)	Acc@1 94.922 (95.670)	Acc@5 100.000 (99.970)
Epoch: [134][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2961 (0.2921)	Acc@1 95.312 (95.594)	Acc@5 100.000 (99.962)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.209 (0.209)	Data 0.310 (0.310)	Loss 0.2516 (0.2516)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.3210 (0.2846)	Acc@1 94.922 (95.998)	Acc@5 100.000 (99.952)
Epoch: [135][128/196]	Time 0.117 (0.121)	Data 0.000 (0.003)	Loss 0.3146 (0.2893)	Acc@1 95.703 (95.770)	Acc@5 99.609 (99.958)
Epoch: [135][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2548 (0.2953)	Acc@1 96.875 (95.553)	Acc@5 100.000 (99.955)
Max memory in training epoch: 55.8730752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.11
Max memory: 86.731008
 23.997s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9618
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1368576
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.195 (0.195)	Data 0.258 (0.258)	Loss 0.2856 (0.2856)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.2827 (0.2808)	Acc@1 95.312 (95.931)	Acc@5 100.000 (99.964)
Epoch: [136][128/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.3211 (0.2818)	Acc@1 95.312 (95.954)	Acc@5 100.000 (99.976)
Epoch: [136][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3001 (0.2912)	Acc@1 92.969 (95.610)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.6091904
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.182 (0.182)	Data 0.261 (0.261)	Loss 0.2993 (0.2993)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.3690 (0.2953)	Acc@1 92.969 (95.607)	Acc@5 99.219 (99.946)
Epoch: [137][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2788 (0.2958)	Acc@1 96.484 (95.494)	Acc@5 100.000 (99.933)
Epoch: [137][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3168 (0.2960)	Acc@1 95.312 (95.495)	Acc@5 100.000 (99.945)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.154 (0.154)	Data 0.299 (0.299)	Loss 0.2902 (0.2902)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.2557 (0.3058)	Acc@1 96.875 (95.066)	Acc@5 100.000 (99.928)
Epoch: [138][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.2938 (0.2980)	Acc@1 95.703 (95.376)	Acc@5 100.000 (99.949)
Epoch: [138][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2687 (0.2965)	Acc@1 96.875 (95.476)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.165 (0.165)	Data 0.295 (0.295)	Loss 0.2584 (0.2584)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.2873 (0.2866)	Acc@1 94.922 (95.805)	Acc@5 100.000 (99.970)
Epoch: [139][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2728 (0.2900)	Acc@1 95.703 (95.679)	Acc@5 100.000 (99.973)
Epoch: [139][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3289 (0.2935)	Acc@1 94.531 (95.535)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.144 (0.144)	Data 0.306 (0.306)	Loss 0.3203 (0.3203)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [140][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.3406 (0.2893)	Acc@1 94.531 (95.727)	Acc@5 100.000 (99.958)
Epoch: [140][128/196]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.3132 (0.2903)	Acc@1 92.969 (95.664)	Acc@5 100.000 (99.964)
Epoch: [140][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3315 (0.2942)	Acc@1 93.750 (95.525)	Acc@5 100.000 (99.949)
Max memory in training epoch: 55.8730752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.35
Max memory: 86.731008
 24.005s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4266
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1368576
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.186 (0.186)	Data 0.262 (0.262)	Loss 0.2733 (0.2733)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.2876 (0.2764)	Acc@1 94.531 (96.004)	Acc@5 100.000 (99.958)
Epoch: [141][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2442 (0.2796)	Acc@1 96.094 (95.988)	Acc@5 100.000 (99.967)
Epoch: [141][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.2795 (0.2869)	Acc@1 97.266 (95.764)	Acc@5 100.000 (99.972)
Max memory in training epoch: 55.6091904
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.172 (0.172)	Data 0.306 (0.306)	Loss 0.2893 (0.2893)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.3440 (0.2890)	Acc@1 92.969 (95.739)	Acc@5 100.000 (99.940)
Epoch: [142][128/196]	Time 0.116 (0.120)	Data 0.000 (0.003)	Loss 0.2653 (0.2858)	Acc@1 95.312 (95.827)	Acc@5 100.000 (99.945)
Epoch: [142][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2473 (0.2911)	Acc@1 98.047 (95.667)	Acc@5 100.000 (99.943)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.164 (0.164)	Data 0.268 (0.268)	Loss 0.3167 (0.3167)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.117 (0.119)	Data 0.000 (0.004)	Loss 0.2703 (0.2849)	Acc@1 96.875 (95.901)	Acc@5 100.000 (99.988)
Epoch: [143][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.2589 (0.2890)	Acc@1 97.266 (95.709)	Acc@5 100.000 (99.967)
Epoch: [143][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.2999 (0.2913)	Acc@1 96.094 (95.689)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.169 (0.169)	Data 0.311 (0.311)	Loss 0.2914 (0.2914)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.2868 (0.2815)	Acc@1 96.094 (96.004)	Acc@5 100.000 (99.940)
Epoch: [144][128/196]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.2997 (0.2843)	Acc@1 95.312 (95.861)	Acc@5 100.000 (99.942)
Epoch: [144][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3057 (0.2944)	Acc@1 94.922 (95.464)	Acc@5 100.000 (99.949)
Max memory in training epoch: 55.8730752
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.160 (0.160)	Data 0.311 (0.311)	Loss 0.3188 (0.3188)	Acc@1 94.922 (94.922)	Acc@5 99.219 (99.219)
Epoch: [145][64/196]	Time 0.111 (0.120)	Data 0.000 (0.005)	Loss 0.2712 (0.2808)	Acc@1 96.094 (96.130)	Acc@5 100.000 (99.922)
Epoch: [145][128/196]	Time 0.115 (0.119)	Data 0.000 (0.003)	Loss 0.2475 (0.2904)	Acc@1 97.266 (95.697)	Acc@5 100.000 (99.936)
Epoch: [145][192/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.2393 (0.2943)	Acc@1 97.656 (95.497)	Acc@5 100.000 (99.949)
Max memory in training epoch: 55.8730752
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 322486 ; 323064 ; 0.998210880816185
[INFO] Storing checkpoint...
  89.14
Max memory: 86.731008
 23.798s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5891
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1366528
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.195 (0.195)	Data 0.290 (0.290)	Loss 0.2929 (0.2929)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.3171 (0.2827)	Acc@1 94.141 (95.793)	Acc@5 99.609 (99.976)
Epoch: [146][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.3031 (0.2873)	Acc@1 96.484 (95.682)	Acc@5 100.000 (99.970)
Epoch: [146][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.2862 (0.2914)	Acc@1 96.094 (95.519)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.5838976
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.188 (0.188)	Data 0.339 (0.339)	Loss 0.3035 (0.3035)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.148 (0.125)	Data 0.000 (0.005)	Loss 0.2960 (0.2915)	Acc@1 95.703 (95.451)	Acc@5 100.000 (99.952)
Epoch: [147][128/196]	Time 0.118 (0.124)	Data 0.000 (0.003)	Loss 0.2625 (0.2875)	Acc@1 98.047 (95.712)	Acc@5 100.000 (99.945)
Epoch: [147][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.2837 (0.2957)	Acc@1 96.875 (95.428)	Acc@5 100.000 (99.951)
Max memory in training epoch: 55.8198272
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.156 (0.156)	Data 0.309 (0.309)	Loss 0.2284 (0.2284)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.2559 (0.2820)	Acc@1 96.094 (96.058)	Acc@5 100.000 (99.970)
Epoch: [148][128/196]	Time 0.125 (0.124)	Data 0.000 (0.003)	Loss 0.3126 (0.2884)	Acc@1 94.531 (95.800)	Acc@5 100.000 (99.955)
Epoch: [148][192/196]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.2927 (0.2945)	Acc@1 94.531 (95.533)	Acc@5 100.000 (99.941)
Max memory in training epoch: 55.8198272
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.145 (0.145)	Data 0.307 (0.307)	Loss 0.2443 (0.2443)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.2710 (0.2871)	Acc@1 96.094 (95.763)	Acc@5 100.000 (99.982)
Epoch: [149][128/196]	Time 0.122 (0.122)	Data 0.000 (0.003)	Loss 0.2818 (0.2916)	Acc@1 96.484 (95.549)	Acc@5 100.000 (99.973)
Epoch: [149][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2695 (0.2953)	Acc@1 96.875 (95.408)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.8198272
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.167 (0.167)	Data 0.280 (0.280)	Loss 0.3314 (0.3314)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.2627 (0.2613)	Acc@1 96.875 (96.749)	Acc@5 100.000 (99.982)
Epoch: [150][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2394 (0.2542)	Acc@1 97.266 (97.020)	Acc@5 100.000 (99.982)
Epoch: [150][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2303 (0.2500)	Acc@1 98.047 (97.177)	Acc@5 100.000 (99.982)
Max memory in training epoch: 55.8198272
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.19
Max memory: 86.5305088
 24.192s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6512
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1366528
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.176 (0.176)	Data 0.285 (0.285)	Loss 0.2399 (0.2399)	Acc@1 98.047 (98.047)	Acc@5 99.609 (99.609)
Epoch: [151][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.2511 (0.2367)	Acc@1 96.875 (97.656)	Acc@5 100.000 (99.970)
Epoch: [151][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2353 (0.2337)	Acc@1 98.047 (97.796)	Acc@5 100.000 (99.982)
Epoch: [151][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2345 (0.2332)	Acc@1 98.438 (97.832)	Acc@5 100.000 (99.978)
Max memory in training epoch: 55.5838976
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.140 (0.140)	Data 0.302 (0.302)	Loss 0.2189 (0.2189)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.126 (0.122)	Data 0.000 (0.005)	Loss 0.2166 (0.2238)	Acc@1 97.656 (98.113)	Acc@5 100.000 (99.994)
Epoch: [152][128/196]	Time 0.123 (0.122)	Data 0.000 (0.003)	Loss 0.2196 (0.2248)	Acc@1 98.438 (98.050)	Acc@5 100.000 (99.985)
Epoch: [152][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.2283 (0.2239)	Acc@1 98.047 (98.071)	Acc@5 100.000 (99.986)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.151 (0.151)	Data 0.274 (0.274)	Loss 0.2279 (0.2279)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.118 (0.124)	Data 0.000 (0.004)	Loss 0.2260 (0.2168)	Acc@1 97.266 (98.359)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2241 (0.2191)	Acc@1 98.047 (98.295)	Acc@5 100.000 (99.985)
Epoch: [153][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2334 (0.2173)	Acc@1 97.266 (98.359)	Acc@5 100.000 (99.990)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.171 (0.171)	Data 0.267 (0.267)	Loss 0.2052 (0.2052)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.2225 (0.2105)	Acc@1 97.656 (98.606)	Acc@5 100.000 (100.000)
Epoch: [154][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1958 (0.2128)	Acc@1 99.219 (98.562)	Acc@5 100.000 (99.994)
Epoch: [154][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1994 (0.2132)	Acc@1 99.219 (98.543)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.154 (0.154)	Data 0.272 (0.272)	Loss 0.1907 (0.1907)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.2189 (0.2077)	Acc@1 98.438 (98.762)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2345 (0.2078)	Acc@1 97.266 (98.722)	Acc@5 100.000 (100.000)
Epoch: [155][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2227 (0.2091)	Acc@1 98.047 (98.664)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.33
Max memory: 86.4977408
 23.938s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2995
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1366528
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.172 (0.172)	Data 0.264 (0.264)	Loss 0.2013 (0.2013)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.1980 (0.2065)	Acc@1 98.828 (98.672)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1993 (0.2091)	Acc@1 98.828 (98.622)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.2099 (0.2093)	Acc@1 99.609 (98.628)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.5838976
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.170 (0.170)	Data 0.265 (0.265)	Loss 0.2240 (0.2240)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.123 (0.121)	Data 0.000 (0.004)	Loss 0.1925 (0.2030)	Acc@1 99.609 (98.888)	Acc@5 100.000 (99.994)
Epoch: [157][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2131 (0.2043)	Acc@1 98.438 (98.858)	Acc@5 100.000 (99.997)
Epoch: [157][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2111 (0.2044)	Acc@1 99.219 (98.834)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.166 (0.166)	Data 0.298 (0.298)	Loss 0.2020 (0.2020)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.2011 (0.2016)	Acc@1 99.219 (98.852)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.2031 (0.2022)	Acc@1 98.438 (98.849)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2189 (0.2021)	Acc@1 97.656 (98.820)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.171 (0.171)	Data 0.292 (0.292)	Loss 0.2131 (0.2131)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.118 (0.124)	Data 0.000 (0.005)	Loss 0.1863 (0.1991)	Acc@1 99.609 (98.948)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1897 (0.1997)	Acc@1 98.828 (98.892)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.2154 (0.2002)	Acc@1 98.438 (98.893)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.160 (0.160)	Data 0.289 (0.289)	Loss 0.1965 (0.1965)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.2305 (0.1968)	Acc@1 98.047 (98.990)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1988 (0.1985)	Acc@1 99.219 (98.949)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2044 (0.1996)	Acc@1 98.828 (98.867)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.8198272
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.46
Max memory: 86.3994368
 23.944s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9061
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1366528
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.164 (0.164)	Data 0.301 (0.301)	Loss 0.2197 (0.2197)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.131 (0.120)	Data 0.000 (0.005)	Loss 0.2063 (0.1980)	Acc@1 98.438 (98.912)	Acc@5 100.000 (99.994)
Epoch: [161][128/196]	Time 0.120 (0.119)	Data 0.000 (0.003)	Loss 0.2014 (0.1986)	Acc@1 98.438 (98.928)	Acc@5 100.000 (99.994)
Epoch: [161][192/196]	Time 0.111 (0.119)	Data 0.000 (0.002)	Loss 0.2109 (0.1982)	Acc@1 97.656 (98.913)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.5838976
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.167 (0.167)	Data 0.294 (0.294)	Loss 0.1927 (0.1927)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.2115 (0.1960)	Acc@1 98.438 (98.978)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.1914 (0.1955)	Acc@1 98.438 (99.013)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2162 (0.1956)	Acc@1 98.047 (99.041)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.169 (0.169)	Data 0.310 (0.310)	Loss 0.1873 (0.1873)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.1821 (0.1923)	Acc@1 100.000 (99.135)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.124 (0.119)	Data 0.000 (0.003)	Loss 0.1889 (0.1933)	Acc@1 98.828 (99.040)	Acc@5 100.000 (100.000)
Epoch: [163][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2017 (0.1937)	Acc@1 98.438 (99.035)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.159 (0.159)	Data 0.291 (0.291)	Loss 0.1852 (0.1852)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.1992 (0.1940)	Acc@1 98.438 (99.002)	Acc@5 100.000 (99.994)
Epoch: [164][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.1888 (0.1928)	Acc@1 98.828 (99.092)	Acc@5 100.000 (99.997)
Epoch: [164][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.1960 (0.1935)	Acc@1 98.828 (99.045)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.172 (0.172)	Data 0.286 (0.286)	Loss 0.1835 (0.1835)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.1883 (0.1922)	Acc@1 99.609 (99.062)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1856 (0.1919)	Acc@1 98.828 (99.089)	Acc@5 100.000 (99.994)
Epoch: [165][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1768 (0.1916)	Acc@1 100.000 (99.124)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.8198272
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.59
Max memory: 86.5305088
 24.095s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1343
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1366528
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.184 (0.184)	Data 0.261 (0.261)	Loss 0.1950 (0.1950)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.113 (0.119)	Data 0.000 (0.004)	Loss 0.1885 (0.1891)	Acc@1 98.438 (99.159)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.1898 (0.1894)	Acc@1 99.609 (99.191)	Acc@5 100.000 (99.994)
Epoch: [166][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.2097 (0.1895)	Acc@1 98.438 (99.194)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.5838976
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.153 (0.153)	Data 0.294 (0.294)	Loss 0.1862 (0.1862)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.122 (0.118)	Data 0.000 (0.005)	Loss 0.1807 (0.1903)	Acc@1 99.609 (99.171)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.1850 (0.1901)	Acc@1 99.219 (99.131)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2062 (0.1899)	Acc@1 98.828 (99.148)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.159 (0.159)	Data 0.274 (0.274)	Loss 0.1862 (0.1862)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.115 (0.118)	Data 0.000 (0.004)	Loss 0.1933 (0.1900)	Acc@1 99.219 (99.147)	Acc@5 100.000 (99.988)
Epoch: [168][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.1888 (0.1892)	Acc@1 98.438 (99.179)	Acc@5 100.000 (99.994)
Epoch: [168][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2081 (0.1895)	Acc@1 98.438 (99.154)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.151 (0.151)	Data 0.264 (0.264)	Loss 0.1948 (0.1948)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.120 (0.119)	Data 0.000 (0.004)	Loss 0.1837 (0.1859)	Acc@1 99.219 (99.261)	Acc@5 100.000 (99.994)
Epoch: [169][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.1987 (0.1867)	Acc@1 98.438 (99.264)	Acc@5 100.000 (99.994)
Epoch: [169][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.1787 (0.1868)	Acc@1 100.000 (99.253)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.180 (0.180)	Data 0.258 (0.258)	Loss 0.1842 (0.1842)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.120 (0.119)	Data 0.000 (0.004)	Loss 0.1833 (0.1849)	Acc@1 99.219 (99.321)	Acc@5 100.000 (99.994)
Epoch: [170][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.1759 (0.1852)	Acc@1 100.000 (99.346)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1798 (0.1866)	Acc@1 100.000 (99.261)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.55
Max memory: 86.5305088
 23.645s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9290
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1366528
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.166 (0.166)	Data 0.265 (0.265)	Loss 0.2091 (0.2091)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.1882 (0.1849)	Acc@1 99.219 (99.333)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.1879 (0.1849)	Acc@1 99.609 (99.291)	Acc@5 100.000 (99.997)
Epoch: [171][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1762 (0.1851)	Acc@1 99.609 (99.304)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.5838976
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.168 (0.168)	Data 0.270 (0.270)	Loss 0.1896 (0.1896)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.1759 (0.1832)	Acc@1 99.609 (99.267)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.134 (0.120)	Data 0.000 (0.002)	Loss 0.1773 (0.1835)	Acc@1 99.219 (99.273)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1744 (0.1838)	Acc@1 99.609 (99.279)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.169 (0.169)	Data 0.293 (0.293)	Loss 0.1851 (0.1851)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.124 (0.120)	Data 0.000 (0.005)	Loss 0.1784 (0.1840)	Acc@1 100.000 (99.267)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.1732 (0.1841)	Acc@1 99.609 (99.285)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1853 (0.1836)	Acc@1 98.828 (99.292)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.167 (0.167)	Data 0.264 (0.264)	Loss 0.1718 (0.1718)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.121 (0.119)	Data 0.000 (0.004)	Loss 0.1725 (0.1839)	Acc@1 100.000 (99.249)	Acc@5 100.000 (99.994)
Epoch: [174][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.1856 (0.1826)	Acc@1 99.219 (99.301)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.1777 (0.1822)	Acc@1 99.609 (99.334)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.162 (0.162)	Data 0.283 (0.283)	Loss 0.1900 (0.1900)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.1830 (0.1820)	Acc@1 99.609 (99.273)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.143 (0.120)	Data 0.000 (0.002)	Loss 0.1754 (0.1817)	Acc@1 99.219 (99.282)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1974 (0.1819)	Acc@1 97.656 (99.255)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.8198272
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.54
Max memory: 86.4977408
 23.802s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4171
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1366528
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.204 (0.204)	Data 0.262 (0.262)	Loss 0.1746 (0.1746)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.138 (0.121)	Data 0.000 (0.004)	Loss 0.1862 (0.1822)	Acc@1 99.219 (99.213)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1952 (0.1814)	Acc@1 99.219 (99.255)	Acc@5 100.000 (99.997)
Epoch: [176][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1783 (0.1810)	Acc@1 99.219 (99.277)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.5838976
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.143 (0.143)	Data 0.309 (0.309)	Loss 0.1817 (0.1817)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.1713 (0.1800)	Acc@1 99.609 (99.345)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.126 (0.121)	Data 0.000 (0.003)	Loss 0.1745 (0.1803)	Acc@1 99.609 (99.343)	Acc@5 100.000 (99.997)
Epoch: [177][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.1720 (0.1804)	Acc@1 99.609 (99.324)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.166 (0.166)	Data 0.267 (0.267)	Loss 0.1738 (0.1738)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.1699 (0.1770)	Acc@1 100.000 (99.435)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.1668 (0.1785)	Acc@1 100.000 (99.382)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.1703 (0.1789)	Acc@1 99.609 (99.354)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.154 (0.154)	Data 0.302 (0.302)	Loss 0.2045 (0.2045)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.1793 (0.1797)	Acc@1 99.219 (99.363)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.1640 (0.1793)	Acc@1 100.000 (99.382)	Acc@5 100.000 (99.997)
Epoch: [179][192/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.1774 (0.1789)	Acc@1 100.000 (99.375)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8198272
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.144 (0.144)	Data 0.293 (0.293)	Loss 0.1690 (0.1690)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.1717 (0.1751)	Acc@1 99.609 (99.483)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.1784 (0.1754)	Acc@1 100.000 (99.497)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1825 (0.1762)	Acc@1 99.219 (99.449)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.8198272
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(5, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 30, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(21, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.56
Max memory: 86.5305088
 23.705s  Thres 0.01 3
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2254
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.200 (0.200)	Data 0.265 (0.265)	Loss 3.3693 (3.3693)	Acc@1 9.375 (9.375)	Acc@5 50.391 (50.391)
Epoch: [1][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 2.4572 (2.6923)	Acc@1 32.031 (23.438)	Acc@5 84.766 (76.298)
Epoch: [1][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 2.1666 (2.5054)	Acc@1 43.359 (29.775)	Acc@5 90.625 (82.204)
Epoch: [1][192/196]	Time 0.137 (0.131)	Data 0.000 (0.002)	Loss 1.9637 (2.3671)	Acc@1 53.125 (34.897)	Acc@5 92.188 (85.314)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.164 (0.164)	Data 0.307 (0.307)	Loss 2.0365 (2.0365)	Acc@1 47.266 (47.266)	Acc@5 94.531 (94.531)
Epoch: [2][64/196]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 1.8482 (1.8795)	Acc@1 56.250 (52.963)	Acc@5 92.969 (93.918)
Epoch: [2][128/196]	Time 0.130 (0.133)	Data 0.000 (0.003)	Loss 1.7593 (1.8086)	Acc@1 58.203 (55.054)	Acc@5 94.141 (94.562)
Epoch: [2][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 1.5783 (1.7387)	Acc@1 64.844 (57.315)	Acc@5 96.484 (95.185)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.158 (0.158)	Data 0.296 (0.296)	Loss 1.5304 (1.5304)	Acc@1 63.672 (63.672)	Acc@5 94.922 (94.922)
Epoch: [3][64/196]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 1.4965 (1.5125)	Acc@1 65.234 (64.681)	Acc@5 97.656 (96.983)
Epoch: [3][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 1.3056 (1.4768)	Acc@1 70.312 (65.670)	Acc@5 97.266 (97.023)
Epoch: [3][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 1.3116 (1.4375)	Acc@1 68.359 (66.775)	Acc@5 98.828 (97.227)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.159 (0.159)	Data 0.270 (0.270)	Loss 1.3938 (1.3938)	Acc@1 66.797 (66.797)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 1.2720 (1.2741)	Acc@1 73.047 (71.989)	Acc@5 96.875 (97.819)
Epoch: [4][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 1.1812 (1.2515)	Acc@1 72.656 (72.478)	Acc@5 98.828 (97.992)
Epoch: [4][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 1.2893 (1.2378)	Acc@1 67.969 (72.731)	Acc@5 98.438 (98.041)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.176 (0.176)	Data 0.268 (0.268)	Loss 1.1722 (1.1722)	Acc@1 73.047 (73.047)	Acc@5 98.438 (98.438)
Epoch: [5][64/196]	Time 0.146 (0.129)	Data 0.000 (0.004)	Loss 1.0652 (1.1262)	Acc@1 76.953 (75.427)	Acc@5 98.828 (98.546)
Epoch: [5][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.1192 (1.1137)	Acc@1 74.609 (75.648)	Acc@5 98.438 (98.559)
Epoch: [5][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.0864 (1.1007)	Acc@1 78.125 (75.935)	Acc@5 98.438 (98.569)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  63.08
Max memory: 103.3835008
 25.799s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9312
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.197 (0.197)	Data 0.281 (0.281)	Loss 0.9827 (0.9827)	Acc@1 80.859 (80.859)	Acc@5 98.828 (98.828)
Epoch: [6][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 1.0526 (1.0452)	Acc@1 74.609 (77.290)	Acc@5 98.828 (98.636)
Epoch: [6][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.1156 (1.0255)	Acc@1 76.953 (77.822)	Acc@5 98.047 (98.713)
Epoch: [6][192/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.9612 (1.0174)	Acc@1 78.125 (77.872)	Acc@5 99.609 (98.709)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.182 (0.182)	Data 0.272 (0.272)	Loss 0.8995 (0.8995)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [7][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.8808 (0.9673)	Acc@1 79.688 (78.888)	Acc@5 99.609 (98.906)
Epoch: [7][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 1.0120 (0.9646)	Acc@1 75.781 (78.767)	Acc@5 97.656 (98.874)
Epoch: [7][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.9948 (0.9620)	Acc@1 76.953 (78.864)	Acc@5 98.047 (98.820)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.189 (0.189)	Data 0.285 (0.285)	Loss 0.9714 (0.9714)	Acc@1 77.344 (77.344)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.152 (0.131)	Data 0.000 (0.005)	Loss 1.0460 (0.9278)	Acc@1 74.609 (79.423)	Acc@5 97.656 (98.984)
Epoch: [8][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.9080 (0.9146)	Acc@1 80.469 (80.054)	Acc@5 98.438 (98.980)
Epoch: [8][192/196]	Time 0.142 (0.130)	Data 0.000 (0.002)	Loss 0.8786 (0.9087)	Acc@1 81.250 (80.224)	Acc@5 100.000 (98.935)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.172 (0.172)	Data 0.296 (0.296)	Loss 0.8203 (0.8203)	Acc@1 83.203 (83.203)	Acc@5 98.047 (98.047)
Epoch: [9][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.8330 (0.8677)	Acc@1 81.250 (81.388)	Acc@5 98.828 (99.093)
Epoch: [9][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.8298 (0.8720)	Acc@1 83.203 (81.138)	Acc@5 97.266 (99.028)
Epoch: [9][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.9105 (0.8774)	Acc@1 82.812 (80.764)	Acc@5 99.219 (99.041)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.185 (0.185)	Data 0.267 (0.267)	Loss 0.9042 (0.9042)	Acc@1 78.125 (78.125)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.135 (0.131)	Data 0.000 (0.004)	Loss 0.8968 (0.8604)	Acc@1 80.078 (81.136)	Acc@5 99.219 (99.105)
Epoch: [10][128/196]	Time 0.139 (0.131)	Data 0.000 (0.002)	Loss 0.8727 (0.8603)	Acc@1 80.469 (81.114)	Acc@5 98.047 (98.986)
Epoch: [10][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.8097 (0.8568)	Acc@1 82.031 (81.143)	Acc@5 98.828 (99.002)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  71.67
Max memory: 103.3833984
 26.062s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8979
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.198 (0.198)	Data 0.289 (0.289)	Loss 0.8516 (0.8516)	Acc@1 80.469 (80.469)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.9632 (0.8171)	Acc@1 78.516 (82.584)	Acc@5 98.047 (99.183)
Epoch: [11][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8042 (0.8274)	Acc@1 82.031 (82.198)	Acc@5 100.000 (99.131)
Epoch: [11][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8477 (0.8260)	Acc@1 80.078 (82.155)	Acc@5 99.219 (99.095)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.184 (0.184)	Data 0.266 (0.266)	Loss 0.7807 (0.7807)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.8299 (0.8313)	Acc@1 85.156 (81.875)	Acc@5 99.219 (99.069)
Epoch: [12][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8145 (0.8315)	Acc@1 82.031 (81.916)	Acc@5 99.219 (99.043)
Epoch: [12][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8842 (0.8265)	Acc@1 79.688 (82.090)	Acc@5 99.219 (99.000)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.157 (0.157)	Data 0.257 (0.257)	Loss 0.7801 (0.7801)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.8428 (0.8149)	Acc@1 82.031 (82.338)	Acc@5 99.219 (99.165)
Epoch: [13][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8910 (0.8104)	Acc@1 83.203 (82.392)	Acc@5 98.438 (99.222)
Epoch: [13][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.8140 (0.8115)	Acc@1 80.859 (82.438)	Acc@5 98.047 (99.146)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.147 (0.147)	Data 0.294 (0.294)	Loss 0.7510 (0.7510)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.6953 (0.8157)	Acc@1 87.109 (82.188)	Acc@5 99.609 (99.093)
Epoch: [14][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7296 (0.8042)	Acc@1 85.938 (82.716)	Acc@5 99.219 (99.143)
Epoch: [14][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8569 (0.8029)	Acc@1 81.641 (82.673)	Acc@5 99.609 (99.134)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.164 (0.164)	Data 0.267 (0.267)	Loss 0.7314 (0.7314)	Acc@1 86.328 (86.328)	Acc@5 98.438 (98.438)
Epoch: [15][64/196]	Time 0.137 (0.130)	Data 0.000 (0.004)	Loss 0.8494 (0.7931)	Acc@1 80.859 (82.981)	Acc@5 97.656 (99.099)
Epoch: [15][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8128 (0.7983)	Acc@1 83.203 (82.879)	Acc@5 98.828 (99.146)
Epoch: [15][192/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7380 (0.7907)	Acc@1 84.766 (83.023)	Acc@5 98.828 (99.192)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  64.5
Max memory: 103.3833984
 25.943s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9666
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.2020864
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.185 (0.185)	Data 0.278 (0.278)	Loss 0.8001 (0.8001)	Acc@1 80.859 (80.859)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.132 (0.134)	Data 0.000 (0.004)	Loss 0.8213 (0.7827)	Acc@1 80.859 (83.185)	Acc@5 99.219 (99.195)
Epoch: [16][128/196]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.7189 (0.7805)	Acc@1 85.156 (83.312)	Acc@5 99.609 (99.231)
Epoch: [16][192/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.7864 (0.7864)	Acc@1 83.594 (83.142)	Acc@5 98.047 (99.194)
Max memory in training epoch: 66.6450432
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.187 (0.187)	Data 0.311 (0.311)	Loss 0.8657 (0.8657)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.134 (0.132)	Data 0.000 (0.005)	Loss 0.7895 (0.7720)	Acc@1 84.375 (83.720)	Acc@5 97.656 (99.261)
Epoch: [17][128/196]	Time 0.129 (0.131)	Data 0.000 (0.003)	Loss 0.7964 (0.7802)	Acc@1 84.375 (83.609)	Acc@5 98.828 (99.222)
Epoch: [17][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7739 (0.7822)	Acc@1 82.031 (83.497)	Acc@5 99.609 (99.221)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.163 (0.163)	Data 0.266 (0.266)	Loss 0.7564 (0.7564)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.129 (0.133)	Data 0.000 (0.004)	Loss 0.8281 (0.7735)	Acc@1 84.766 (83.660)	Acc@5 98.828 (99.231)
Epoch: [18][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.9017 (0.7744)	Acc@1 78.906 (83.497)	Acc@5 98.047 (99.264)
Epoch: [18][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.6419 (0.7762)	Acc@1 87.500 (83.422)	Acc@5 100.000 (99.284)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.196 (0.196)	Data 0.272 (0.272)	Loss 0.7986 (0.7986)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.131 (0.138)	Data 0.000 (0.004)	Loss 0.7983 (0.7670)	Acc@1 82.812 (84.081)	Acc@5 98.828 (99.267)
Epoch: [19][128/196]	Time 0.130 (0.135)	Data 0.000 (0.002)	Loss 0.8176 (0.7714)	Acc@1 83.984 (83.857)	Acc@5 99.609 (99.282)
Epoch: [19][192/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.8067 (0.7732)	Acc@1 81.250 (83.784)	Acc@5 99.609 (99.223)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.180 (0.180)	Data 0.272 (0.272)	Loss 0.7575 (0.7575)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.146 (0.132)	Data 0.000 (0.004)	Loss 0.7427 (0.7804)	Acc@1 83.594 (83.534)	Acc@5 100.000 (99.237)
Epoch: [20][128/196]	Time 0.136 (0.133)	Data 0.000 (0.002)	Loss 0.7665 (0.7719)	Acc@1 84.766 (83.785)	Acc@5 99.219 (99.231)
Epoch: [20][192/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.7529 (0.7694)	Acc@1 83.984 (83.899)	Acc@5 100.000 (99.247)
Max memory in training epoch: 66.5401856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 475846 ; 486232 ; 0.9786398262557792
[INFO] Storing checkpoint...
  71.73
Max memory: 103.3821696
 26.286s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2415
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.197888
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.228 (0.228)	Data 0.348 (0.348)	Loss 0.7330 (0.7330)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [21][64/196]	Time 0.131 (0.131)	Data 0.000 (0.006)	Loss 0.7732 (0.7389)	Acc@1 83.984 (85.066)	Acc@5 98.438 (99.315)
Epoch: [21][128/196]	Time 0.135 (0.130)	Data 0.000 (0.003)	Loss 0.8110 (0.7578)	Acc@1 83.984 (84.387)	Acc@5 99.219 (99.270)
Epoch: [21][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7429 (0.7588)	Acc@1 85.547 (84.324)	Acc@5 98.828 (99.261)
Max memory in training epoch: 66.6282496
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.159 (0.159)	Data 0.292 (0.292)	Loss 0.7668 (0.7668)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [22][64/196]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.7689 (0.7417)	Acc@1 85.156 (85.102)	Acc@5 98.828 (99.249)
Epoch: [22][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7677 (0.7560)	Acc@1 83.203 (84.454)	Acc@5 98.438 (99.313)
Epoch: [22][192/196]	Time 0.143 (0.130)	Data 0.000 (0.002)	Loss 0.8114 (0.7534)	Acc@1 80.859 (84.539)	Acc@5 98.047 (99.261)
Max memory in training epoch: 66.4971776
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.155 (0.155)	Data 0.268 (0.268)	Loss 0.7794 (0.7794)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [23][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.7685 (0.7585)	Acc@1 84.766 (84.351)	Acc@5 98.828 (99.237)
Epoch: [23][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8210 (0.7597)	Acc@1 80.469 (84.333)	Acc@5 99.219 (99.282)
Epoch: [23][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.8290 (0.7618)	Acc@1 83.984 (84.280)	Acc@5 99.219 (99.243)
Max memory in training epoch: 66.4971776
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.176 (0.176)	Data 0.281 (0.281)	Loss 0.7683 (0.7683)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.139 (0.135)	Data 0.000 (0.005)	Loss 0.7805 (0.7523)	Acc@1 83.984 (84.567)	Acc@5 99.219 (99.291)
Epoch: [24][128/196]	Time 0.137 (0.135)	Data 0.000 (0.002)	Loss 0.6890 (0.7556)	Acc@1 88.281 (84.387)	Acc@5 99.609 (99.307)
Epoch: [24][192/196]	Time 0.128 (0.135)	Data 0.000 (0.002)	Loss 0.7044 (0.7577)	Acc@1 86.328 (84.310)	Acc@5 98.828 (99.304)
Max memory in training epoch: 66.4971776
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.163 (0.163)	Data 0.292 (0.292)	Loss 0.7063 (0.7063)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.7168 (0.7382)	Acc@1 86.328 (85.012)	Acc@5 99.609 (99.375)
Epoch: [25][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7524 (0.7449)	Acc@1 82.422 (84.747)	Acc@5 99.609 (99.331)
Epoch: [25][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6539 (0.7475)	Acc@1 85.547 (84.577)	Acc@5 100.000 (99.312)
Max memory in training epoch: 66.4971776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 447572 ; 475846 ; 0.9405816167415508
[INFO] Storing checkpoint...
  77.59
Max memory: 103.3695744
 25.997s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7827
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.186624
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.216 (0.216)	Data 0.265 (0.265)	Loss 0.7203 (0.7203)	Acc@1 88.672 (88.672)	Acc@5 98.438 (98.438)
Epoch: [26][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.7867 (0.7165)	Acc@1 80.469 (85.475)	Acc@5 99.219 (99.345)
Epoch: [26][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.6996 (0.7272)	Acc@1 84.766 (85.314)	Acc@5 99.609 (99.346)
Epoch: [26][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7056 (0.7306)	Acc@1 83.594 (85.094)	Acc@5 99.609 (99.330)
Max memory in training epoch: 66.1899776
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.149 (0.149)	Data 0.295 (0.295)	Loss 0.7374 (0.7374)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [27][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7510 (0.7371)	Acc@1 84.375 (84.850)	Acc@5 98.438 (99.309)
Epoch: [27][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8856 (0.7366)	Acc@1 79.297 (84.899)	Acc@5 98.828 (99.255)
Epoch: [27][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6957 (0.7438)	Acc@1 87.500 (84.620)	Acc@5 98.438 (99.241)
Max memory in training epoch: 66.0064768
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.178 (0.178)	Data 0.301 (0.301)	Loss 0.7906 (0.7906)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7527 (0.7429)	Acc@1 85.156 (84.669)	Acc@5 99.609 (99.291)
Epoch: [28][128/196]	Time 0.126 (0.133)	Data 0.000 (0.002)	Loss 0.8243 (0.7480)	Acc@1 83.594 (84.505)	Acc@5 99.219 (99.282)
Epoch: [28][192/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7036 (0.7478)	Acc@1 86.719 (84.575)	Acc@5 100.000 (99.302)
Max memory in training epoch: 66.0064768
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.204 (0.204)	Data 0.265 (0.265)	Loss 0.7709 (0.7709)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.127 (0.133)	Data 0.000 (0.004)	Loss 0.7640 (0.7320)	Acc@1 82.812 (85.210)	Acc@5 99.609 (99.417)
Epoch: [29][128/196]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.7519 (0.7369)	Acc@1 85.938 (85.087)	Acc@5 99.219 (99.397)
Epoch: [29][192/196]	Time 0.135 (0.135)	Data 0.000 (0.002)	Loss 0.7674 (0.7401)	Acc@1 81.641 (84.885)	Acc@5 98.828 (99.383)
Max memory in training epoch: 66.0064768
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.169 (0.169)	Data 0.297 (0.297)	Loss 0.7814 (0.7814)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.136 (0.135)	Data 0.000 (0.005)	Loss 0.7095 (0.7247)	Acc@1 85.156 (85.517)	Acc@5 98.828 (99.345)
Epoch: [30][128/196]	Time 0.126 (0.134)	Data 0.000 (0.002)	Loss 0.7607 (0.7295)	Acc@1 83.984 (85.238)	Acc@5 98.828 (99.370)
Epoch: [30][192/196]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.7413 (0.7341)	Acc@1 85.938 (85.031)	Acc@5 99.609 (99.350)
Max memory in training epoch: 66.0064768
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423040 ; 447572 ; 0.94518870706836
[INFO] Storing checkpoint...
  69.53
Max memory: 102.7963392
 26.483s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6970
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1769984
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.191 (0.191)	Data 0.288 (0.288)	Loss 0.7085 (0.7085)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.7537 (0.7084)	Acc@1 85.547 (86.004)	Acc@5 99.219 (99.399)
Epoch: [31][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6836 (0.7174)	Acc@1 88.281 (85.550)	Acc@5 99.609 (99.400)
Epoch: [31][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7400 (0.7278)	Acc@1 87.109 (85.347)	Acc@5 98.828 (99.350)
Max memory in training epoch: 65.7189376
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.154 (0.154)	Data 0.301 (0.301)	Loss 0.5898 (0.5898)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [32][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.7097 (0.7079)	Acc@1 89.062 (86.004)	Acc@5 98.047 (99.231)
Epoch: [32][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6383 (0.7255)	Acc@1 87.891 (85.420)	Acc@5 100.000 (99.264)
Epoch: [32][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7169 (0.7266)	Acc@1 87.109 (85.320)	Acc@5 100.000 (99.312)
Max memory in training epoch: 65.548544
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.189 (0.189)	Data 0.262 (0.262)	Loss 0.6463 (0.6463)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.121 (0.130)	Data 0.000 (0.004)	Loss 0.7017 (0.7260)	Acc@1 82.812 (85.319)	Acc@5 99.609 (99.381)
Epoch: [33][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7711 (0.7320)	Acc@1 85.156 (85.196)	Acc@5 98.438 (99.385)
Epoch: [33][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6998 (0.7316)	Acc@1 87.500 (85.185)	Acc@5 98.828 (99.358)
Max memory in training epoch: 65.548544
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.7519 (0.7519)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [34][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.8453 (0.7324)	Acc@1 80.859 (85.132)	Acc@5 98.828 (99.321)
Epoch: [34][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6887 (0.7325)	Acc@1 87.891 (85.135)	Acc@5 99.609 (99.304)
Epoch: [34][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7061 (0.7333)	Acc@1 86.328 (85.049)	Acc@5 99.609 (99.322)
Max memory in training epoch: 65.548544
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.177 (0.177)	Data 0.273 (0.273)	Loss 0.6928 (0.6928)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.6827 (0.7300)	Acc@1 85.938 (85.258)	Acc@5 99.219 (99.351)
Epoch: [35][128/196]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.7865 (0.7299)	Acc@1 82.031 (85.217)	Acc@5 100.000 (99.370)
Epoch: [35][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.8211 (0.7284)	Acc@1 82.031 (85.213)	Acc@5 98.047 (99.332)
Max memory in training epoch: 65.548544
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 403124 ; 423040 ; 0.9529217095310136
[INFO] Storing checkpoint...
  75.14
Max memory: 101.4227456
 26.095s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8696
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1690112
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.197 (0.197)	Data 0.261 (0.261)	Loss 0.7283 (0.7283)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 0.6579 (0.7024)	Acc@1 89.062 (85.950)	Acc@5 98.438 (99.441)
Epoch: [36][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7054 (0.7139)	Acc@1 86.719 (85.501)	Acc@5 99.219 (99.434)
Epoch: [36][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7526 (0.7198)	Acc@1 83.984 (85.351)	Acc@5 98.438 (99.369)
Max memory in training epoch: 64.5728768
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.7158 (0.7158)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.7346 (0.7195)	Acc@1 84.766 (85.367)	Acc@5 99.609 (99.399)
Epoch: [37][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7660 (0.7260)	Acc@1 83.594 (85.147)	Acc@5 99.219 (99.291)
Epoch: [37][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7348 (0.7289)	Acc@1 85.547 (85.075)	Acc@5 99.609 (99.284)
Max memory in training epoch: 64.5794304
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.158 (0.158)	Data 0.263 (0.263)	Loss 0.6054 (0.6054)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.133 (0.129)	Data 0.000 (0.004)	Loss 0.7008 (0.7154)	Acc@1 87.500 (85.499)	Acc@5 98.438 (99.363)
Epoch: [38][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7133 (0.7272)	Acc@1 83.984 (85.168)	Acc@5 100.000 (99.346)
Epoch: [38][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7998 (0.7248)	Acc@1 83.984 (85.381)	Acc@5 99.609 (99.360)
Max memory in training epoch: 64.5794304
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.169 (0.169)	Data 0.274 (0.274)	Loss 0.7968 (0.7968)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.7588 (0.7123)	Acc@1 83.984 (85.715)	Acc@5 100.000 (99.537)
Epoch: [39][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6803 (0.7098)	Acc@1 87.500 (85.822)	Acc@5 99.219 (99.485)
Epoch: [39][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6671 (0.7134)	Acc@1 87.891 (85.537)	Acc@5 99.609 (99.454)
Max memory in training epoch: 64.5794304
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.180 (0.180)	Data 0.288 (0.288)	Loss 0.6936 (0.6936)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [40][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.7522 (0.7065)	Acc@1 84.375 (85.745)	Acc@5 99.609 (99.387)
Epoch: [40][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6691 (0.7114)	Acc@1 87.500 (85.680)	Acc@5 100.000 (99.355)
Epoch: [40][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7297 (0.7149)	Acc@1 80.859 (85.539)	Acc@5 99.609 (99.360)
Max memory in training epoch: 64.5794304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 388694 ; 403124 ; 0.9642045623679066
[INFO] Storing checkpoint...
  77.9
Max memory: 99.8775296
 25.676s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 86
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1632768
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.203 (0.203)	Data 0.270 (0.270)	Loss 0.6462 (0.6462)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.6523 (0.6711)	Acc@1 88.672 (87.031)	Acc@5 99.609 (99.465)
Epoch: [41][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7230 (0.6925)	Acc@1 85.547 (86.364)	Acc@5 99.219 (99.370)
Epoch: [41][192/196]	Time 0.140 (0.130)	Data 0.000 (0.002)	Loss 0.7652 (0.7051)	Acc@1 83.203 (85.808)	Acc@5 99.609 (99.346)
Max memory in training epoch: 64.3926528
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.186 (0.186)	Data 0.257 (0.257)	Loss 0.6293 (0.6293)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6750 (0.7077)	Acc@1 87.109 (85.805)	Acc@5 98.828 (99.405)
Epoch: [42][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7930 (0.7105)	Acc@1 81.641 (85.807)	Acc@5 100.000 (99.403)
Epoch: [42][192/196]	Time 0.126 (0.130)	Data 0.000 (0.001)	Loss 0.6839 (0.7141)	Acc@1 86.328 (85.650)	Acc@5 99.609 (99.358)
Max memory in training epoch: 64.602368
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.171 (0.171)	Data 0.274 (0.274)	Loss 0.7185 (0.7185)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.7705 (0.7013)	Acc@1 83.594 (85.907)	Acc@5 99.219 (99.357)
Epoch: [43][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6435 (0.7075)	Acc@1 87.891 (85.653)	Acc@5 99.609 (99.367)
Epoch: [43][192/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.6263 (0.7114)	Acc@1 88.672 (85.561)	Acc@5 100.000 (99.354)
Max memory in training epoch: 64.602368
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.160 (0.160)	Data 0.282 (0.282)	Loss 0.7738 (0.7738)	Acc@1 84.375 (84.375)	Acc@5 98.047 (98.047)
Epoch: [44][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.7296 (0.7181)	Acc@1 84.375 (85.018)	Acc@5 99.219 (99.381)
Epoch: [44][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.8355 (0.7134)	Acc@1 82.422 (85.359)	Acc@5 98.438 (99.391)
Epoch: [44][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7035 (0.7112)	Acc@1 85.547 (85.543)	Acc@5 99.219 (99.427)
Max memory in training epoch: 64.602368
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.150 (0.150)	Data 0.264 (0.264)	Loss 0.6659 (0.6659)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.6482 (0.7018)	Acc@1 89.062 (86.034)	Acc@5 100.000 (99.459)
Epoch: [45][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6908 (0.7043)	Acc@1 87.891 (85.871)	Acc@5 99.219 (99.452)
Epoch: [45][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7206 (0.7104)	Acc@1 84.766 (85.626)	Acc@5 100.000 (99.405)
Max memory in training epoch: 64.602368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 373820 ; 388694 ; 0.9617333943925042
[INFO] Storing checkpoint...
  82.65
Max memory: 99.1517184
 25.892s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4827
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1573888
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.204 (0.204)	Data 0.259 (0.259)	Loss 0.7236 (0.7236)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.137 (0.133)	Data 0.000 (0.004)	Loss 0.7047 (0.6794)	Acc@1 84.375 (86.641)	Acc@5 99.609 (99.393)
Epoch: [46][128/196]	Time 0.120 (0.132)	Data 0.000 (0.002)	Loss 0.7725 (0.6901)	Acc@1 83.594 (86.165)	Acc@5 99.219 (99.413)
Epoch: [46][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6671 (0.6961)	Acc@1 83.984 (85.931)	Acc@5 100.000 (99.429)
Max memory in training epoch: 62.9142016
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.201 (0.201)	Data 0.264 (0.264)	Loss 0.6499 (0.6499)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [47][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6373 (0.7056)	Acc@1 86.328 (85.775)	Acc@5 99.609 (99.435)
Epoch: [47][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6721 (0.7036)	Acc@1 88.672 (85.904)	Acc@5 99.609 (99.422)
Epoch: [47][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7325 (0.7063)	Acc@1 85.156 (85.776)	Acc@5 99.219 (99.381)
Max memory in training epoch: 62.8355584
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.171 (0.171)	Data 0.307 (0.307)	Loss 0.6528 (0.6528)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.7565 (0.7026)	Acc@1 82.422 (85.817)	Acc@5 98.438 (99.357)
Epoch: [48][128/196]	Time 0.126 (0.129)	Data 0.000 (0.003)	Loss 0.7400 (0.7052)	Acc@1 84.766 (85.735)	Acc@5 99.219 (99.334)
Epoch: [48][192/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.6112 (0.7067)	Acc@1 89.844 (85.733)	Acc@5 100.000 (99.330)
Max memory in training epoch: 62.8355584
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.184 (0.184)	Data 0.275 (0.275)	Loss 0.6736 (0.6736)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7822 (0.6979)	Acc@1 82.031 (85.847)	Acc@5 100.000 (99.435)
Epoch: [49][128/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.7165 (0.7030)	Acc@1 85.156 (85.571)	Acc@5 98.828 (99.434)
Epoch: [49][192/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.7180 (0.7018)	Acc@1 85.547 (85.737)	Acc@5 99.609 (99.452)
Max memory in training epoch: 62.8355584
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.171 (0.171)	Data 0.291 (0.291)	Loss 0.5831 (0.5831)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [50][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6749 (0.6945)	Acc@1 86.328 (85.871)	Acc@5 99.609 (99.471)
Epoch: [50][128/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.7261 (0.6990)	Acc@1 85.938 (85.804)	Acc@5 100.000 (99.458)
Epoch: [50][192/196]	Time 0.143 (0.130)	Data 0.000 (0.002)	Loss 0.6427 (0.6975)	Acc@1 89.062 (85.897)	Acc@5 98.828 (99.439)
Max memory in training epoch: 62.8355584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 363134 ; 373820 ; 0.9714140495425606
[INFO] Storing checkpoint...
  80.83
Max memory: 97.7872896
 25.809s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9950
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1531904
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.199 (0.199)	Data 0.288 (0.288)	Loss 0.6733 (0.6733)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.7069 (0.6726)	Acc@1 86.328 (86.821)	Acc@5 99.609 (99.507)
Epoch: [51][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6951 (0.6807)	Acc@1 86.328 (86.416)	Acc@5 98.828 (99.488)
Epoch: [51][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7410 (0.6933)	Acc@1 83.984 (86.033)	Acc@5 99.609 (99.433)
Max memory in training epoch: 61.9602432
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.149 (0.149)	Data 0.303 (0.303)	Loss 0.6384 (0.6384)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.7973 (0.6870)	Acc@1 85.938 (86.310)	Acc@5 98.047 (99.435)
Epoch: [52][128/196]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.6390 (0.6903)	Acc@1 87.109 (86.210)	Acc@5 99.219 (99.425)
Epoch: [52][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7311 (0.6920)	Acc@1 87.109 (86.091)	Acc@5 100.000 (99.437)
Max memory in training epoch: 61.8881536
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.198 (0.198)	Data 0.267 (0.267)	Loss 0.6835 (0.6835)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [53][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6933 (0.6953)	Acc@1 85.547 (86.028)	Acc@5 99.219 (99.459)
Epoch: [53][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.6714 (0.6947)	Acc@1 85.938 (85.983)	Acc@5 99.219 (99.428)
Epoch: [53][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.8061 (0.6996)	Acc@1 84.375 (85.824)	Acc@5 98.828 (99.421)
Max memory in training epoch: 61.8881536
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.179 (0.179)	Data 0.273 (0.273)	Loss 0.6296 (0.6296)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.6597 (0.6929)	Acc@1 89.453 (86.226)	Acc@5 100.000 (99.471)
Epoch: [54][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.7627 (0.6900)	Acc@1 80.078 (86.395)	Acc@5 100.000 (99.431)
Epoch: [54][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.7132 (0.6937)	Acc@1 83.594 (86.215)	Acc@5 99.609 (99.407)
Max memory in training epoch: 61.8881536
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.183 (0.183)	Data 0.314 (0.314)	Loss 0.7198 (0.7198)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.6006 (0.6931)	Acc@1 89.453 (86.190)	Acc@5 99.609 (99.381)
Epoch: [55][128/196]	Time 0.127 (0.126)	Data 0.000 (0.003)	Loss 0.6813 (0.6965)	Acc@1 87.500 (86.062)	Acc@5 98.438 (99.394)
Epoch: [55][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7321 (0.6972)	Acc@1 85.156 (86.023)	Acc@5 99.219 (99.371)
Max memory in training epoch: 61.8881536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356204 ; 363134 ; 0.9809161356413886
[INFO] Storing checkpoint...
  73.45
Max memory: 96.118272
 25.115s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4029
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1503232
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.208 (0.208)	Data 0.267 (0.267)	Loss 0.7226 (0.7226)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [56][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.7232 (0.6711)	Acc@1 83.203 (86.689)	Acc@5 100.000 (99.567)
Epoch: [56][128/196]	Time 0.137 (0.127)	Data 0.000 (0.002)	Loss 0.7170 (0.6880)	Acc@1 85.938 (86.186)	Acc@5 98.828 (99.455)
Epoch: [56][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7622 (0.6894)	Acc@1 84.375 (86.116)	Acc@5 98.047 (99.441)
Max memory in training epoch: 61.4048256
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.184 (0.184)	Data 0.295 (0.295)	Loss 0.6929 (0.6929)	Acc@1 87.109 (87.109)	Acc@5 98.438 (98.438)
Epoch: [57][64/196]	Time 0.124 (0.125)	Data 0.000 (0.005)	Loss 0.6763 (0.6755)	Acc@1 85.156 (86.725)	Acc@5 99.609 (99.357)
Epoch: [57][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6500 (0.6842)	Acc@1 89.453 (86.243)	Acc@5 99.219 (99.385)
Epoch: [57][192/196]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.6734 (0.6857)	Acc@1 87.500 (86.156)	Acc@5 100.000 (99.429)
Max memory in training epoch: 61.1557888
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.173 (0.173)	Data 0.293 (0.293)	Loss 0.5840 (0.5840)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [58][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.7000 (0.6921)	Acc@1 86.328 (86.076)	Acc@5 99.609 (99.387)
Epoch: [58][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6767 (0.6936)	Acc@1 86.719 (85.986)	Acc@5 99.609 (99.428)
Epoch: [58][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7642 (0.6992)	Acc@1 84.375 (85.816)	Acc@5 99.609 (99.397)
Max memory in training epoch: 61.1557888
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.160 (0.160)	Data 0.296 (0.296)	Loss 0.7189 (0.7189)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.7164 (0.6857)	Acc@1 85.938 (85.980)	Acc@5 99.219 (99.447)
Epoch: [59][128/196]	Time 0.135 (0.128)	Data 0.000 (0.002)	Loss 0.6349 (0.6870)	Acc@1 87.500 (85.965)	Acc@5 98.828 (99.446)
Epoch: [59][192/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.6300 (0.6834)	Acc@1 89.062 (86.063)	Acc@5 100.000 (99.443)
Max memory in training epoch: 61.1557888
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.162 (0.162)	Data 0.307 (0.307)	Loss 0.7397 (0.7397)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.119 (0.129)	Data 0.000 (0.005)	Loss 0.7374 (0.6930)	Acc@1 84.375 (85.901)	Acc@5 100.000 (99.417)
Epoch: [60][128/196]	Time 0.130 (0.129)	Data 0.000 (0.003)	Loss 0.5832 (0.6860)	Acc@1 89.062 (86.168)	Acc@5 99.609 (99.470)
Epoch: [60][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7226 (0.6915)	Acc@1 84.375 (85.976)	Acc@5 99.609 (99.462)
Max memory in training epoch: 61.1557888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 349274 ; 356204 ; 0.9805448563182895
[INFO] Storing checkpoint...
  81.77
Max memory: 95.2323072
 25.553s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3234
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1476608
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.207 (0.207)	Data 0.288 (0.288)	Loss 0.7294 (0.7294)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.6049 (0.6574)	Acc@1 91.016 (87.157)	Acc@5 100.000 (99.501)
Epoch: [61][128/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6953 (0.6670)	Acc@1 84.766 (86.704)	Acc@5 99.609 (99.500)
Epoch: [61][192/196]	Time 0.138 (0.127)	Data 0.000 (0.002)	Loss 0.6696 (0.6791)	Acc@1 87.500 (86.356)	Acc@5 100.000 (99.460)
Max memory in training epoch: 61.2762112
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.168 (0.168)	Data 0.274 (0.274)	Loss 0.6130 (0.6130)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.7650 (0.6722)	Acc@1 84.766 (86.653)	Acc@5 99.219 (99.393)
Epoch: [62][128/196]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.6739 (0.6731)	Acc@1 85.156 (86.522)	Acc@5 99.219 (99.440)
Epoch: [62][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.7060 (0.6777)	Acc@1 84.766 (86.336)	Acc@5 99.219 (99.441)
Max memory in training epoch: 60.7519232
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.168 (0.168)	Data 0.305 (0.305)	Loss 0.6346 (0.6346)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.6398 (0.6871)	Acc@1 87.500 (86.226)	Acc@5 100.000 (99.399)
Epoch: [63][128/196]	Time 0.120 (0.128)	Data 0.000 (0.003)	Loss 0.7064 (0.6872)	Acc@1 84.766 (86.013)	Acc@5 99.609 (99.446)
Epoch: [63][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6776 (0.6891)	Acc@1 88.672 (86.010)	Acc@5 99.219 (99.427)
Max memory in training epoch: 60.7519232
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.175 (0.175)	Data 0.317 (0.317)	Loss 0.6444 (0.6444)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [64][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.5918 (0.6710)	Acc@1 87.891 (86.538)	Acc@5 100.000 (99.495)
Epoch: [64][128/196]	Time 0.122 (0.128)	Data 0.000 (0.003)	Loss 0.7080 (0.6738)	Acc@1 85.938 (86.452)	Acc@5 99.609 (99.473)
Epoch: [64][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7128 (0.6812)	Acc@1 85.938 (86.253)	Acc@5 98.828 (99.433)
Max memory in training epoch: 60.7519232
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.183 (0.183)	Data 0.269 (0.269)	Loss 0.6201 (0.6201)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [65][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.6385 (0.6714)	Acc@1 86.719 (86.550)	Acc@5 100.000 (99.489)
Epoch: [65][128/196]	Time 0.117 (0.127)	Data 0.000 (0.002)	Loss 0.6383 (0.6738)	Acc@1 87.109 (86.434)	Acc@5 99.219 (99.519)
Epoch: [65][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7550 (0.6800)	Acc@1 85.156 (86.193)	Acc@5 98.828 (99.478)
Max memory in training epoch: 60.7519232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 340034 ; 349274 ; 0.9735451250307782
[INFO] Storing checkpoint...
  79.61
Max memory: 94.69184
 25.184s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9851
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1441792
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.201 (0.201)	Data 0.289 (0.289)	Loss 0.6906 (0.6906)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7465 (0.6451)	Acc@1 82.422 (87.428)	Acc@5 100.000 (99.597)
Epoch: [66][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7309 (0.6601)	Acc@1 85.547 (87.028)	Acc@5 98.828 (99.509)
Epoch: [66][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6620 (0.6691)	Acc@1 85.938 (86.690)	Acc@5 99.609 (99.478)
Max memory in training epoch: 60.3447808
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.161 (0.161)	Data 0.262 (0.262)	Loss 0.6000 (0.6000)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.124 (0.129)	Data 0.000 (0.004)	Loss 0.7030 (0.6741)	Acc@1 85.156 (86.436)	Acc@5 99.609 (99.567)
Epoch: [67][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6688 (0.6782)	Acc@1 85.938 (86.307)	Acc@5 99.609 (99.443)
Epoch: [67][192/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.6593 (0.6782)	Acc@1 87.500 (86.354)	Acc@5 99.219 (99.433)
Max memory in training epoch: 60.5020672
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.160 (0.160)	Data 0.289 (0.289)	Loss 0.6326 (0.6326)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.5812 (0.6680)	Acc@1 87.891 (86.683)	Acc@5 100.000 (99.513)
Epoch: [68][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6056 (0.6825)	Acc@1 89.453 (86.307)	Acc@5 100.000 (99.476)
Epoch: [68][192/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.5975 (0.6794)	Acc@1 89.844 (86.401)	Acc@5 100.000 (99.470)
Max memory in training epoch: 60.5020672
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.169 (0.169)	Data 0.321 (0.321)	Loss 0.6026 (0.6026)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [69][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6581 (0.6701)	Acc@1 86.328 (86.791)	Acc@5 99.609 (99.465)
Epoch: [69][128/196]	Time 0.130 (0.128)	Data 0.000 (0.003)	Loss 0.5884 (0.6723)	Acc@1 88.672 (86.704)	Acc@5 100.000 (99.506)
Epoch: [69][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6025 (0.6742)	Acc@1 88.672 (86.561)	Acc@5 100.000 (99.468)
Max memory in training epoch: 60.5020672
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.167 (0.167)	Data 0.273 (0.273)	Loss 0.7038 (0.7038)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [70][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6808 (0.6715)	Acc@1 83.984 (86.538)	Acc@5 100.000 (99.513)
Epoch: [70][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6867 (0.6775)	Acc@1 88.672 (86.298)	Acc@5 98.828 (99.434)
Epoch: [70][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7244 (0.6764)	Acc@1 85.156 (86.346)	Acc@5 98.828 (99.433)
Max memory in training epoch: 60.5020672
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 334260 ; 340034 ; 0.9830193451243111
[INFO] Storing checkpoint...
  77.05
Max memory: 93.87776
 25.554s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 30
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.141824
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.209 (0.209)	Data 0.266 (0.266)	Loss 0.6148 (0.6148)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.7424 (0.6425)	Acc@1 83.594 (87.350)	Acc@5 99.609 (99.483)
Epoch: [71][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7117 (0.6649)	Acc@1 85.547 (86.637)	Acc@5 98.828 (99.476)
Epoch: [71][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6838 (0.6696)	Acc@1 85.938 (86.458)	Acc@5 99.219 (99.427)
Max memory in training epoch: 60.1125376
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.157 (0.157)	Data 0.264 (0.264)	Loss 0.6368 (0.6368)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.5899 (0.6488)	Acc@1 87.500 (87.254)	Acc@5 99.609 (99.537)
Epoch: [72][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6940 (0.6656)	Acc@1 84.766 (86.773)	Acc@5 99.219 (99.491)
Epoch: [72][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6434 (0.6741)	Acc@1 87.500 (86.500)	Acc@5 98.828 (99.445)
Max memory in training epoch: 60.2894848
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.159 (0.159)	Data 0.263 (0.263)	Loss 0.6728 (0.6728)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.121 (0.129)	Data 0.000 (0.004)	Loss 0.7603 (0.6857)	Acc@1 83.984 (86.154)	Acc@5 100.000 (99.381)
Epoch: [73][128/196]	Time 0.142 (0.128)	Data 0.000 (0.002)	Loss 0.7369 (0.6808)	Acc@1 83.203 (86.310)	Acc@5 98.828 (99.419)
Epoch: [73][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7369 (0.6803)	Acc@1 84.375 (86.354)	Acc@5 99.219 (99.397)
Max memory in training epoch: 60.2894848
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.161 (0.161)	Data 0.277 (0.277)	Loss 0.7379 (0.7379)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.6771 (0.6714)	Acc@1 86.328 (86.707)	Acc@5 99.609 (99.387)
Epoch: [74][128/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.7404 (0.6709)	Acc@1 83.984 (86.788)	Acc@5 98.047 (99.476)
Epoch: [74][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.5949 (0.6729)	Acc@1 88.672 (86.668)	Acc@5 99.609 (99.484)
Max memory in training epoch: 60.2894848
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.173 (0.173)	Data 0.304 (0.304)	Loss 0.6962 (0.6962)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.141 (0.129)	Data 0.000 (0.005)	Loss 0.6830 (0.6655)	Acc@1 85.938 (86.514)	Acc@5 99.609 (99.465)
Epoch: [75][128/196]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.6966 (0.6697)	Acc@1 85.547 (86.510)	Acc@5 99.219 (99.488)
Epoch: [75][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6260 (0.6737)	Acc@1 89.062 (86.397)	Acc@5 99.609 (99.486)
Max memory in training epoch: 60.2894848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 331082 ; 334260 ; 0.990492431041704
[INFO] Storing checkpoint...
  79.26
Max memory: 93.410304
 25.359s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6981
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1404928
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.199 (0.199)	Data 0.283 (0.283)	Loss 0.6501 (0.6501)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.6953 (0.6488)	Acc@1 87.109 (87.332)	Acc@5 98.438 (99.507)
Epoch: [76][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.7190 (0.6660)	Acc@1 84.766 (86.794)	Acc@5 100.000 (99.455)
Epoch: [76][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.5853 (0.6681)	Acc@1 89.844 (86.678)	Acc@5 99.219 (99.419)
Max memory in training epoch: 59.7139968
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.182 (0.182)	Data 0.265 (0.265)	Loss 0.6433 (0.6433)	Acc@1 87.891 (87.891)	Acc@5 98.438 (98.438)
Epoch: [77][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.6390 (0.6758)	Acc@1 87.891 (86.058)	Acc@5 99.219 (99.423)
Epoch: [77][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.7467 (0.6615)	Acc@1 84.375 (86.807)	Acc@5 98.828 (99.491)
Epoch: [77][192/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6769 (0.6696)	Acc@1 86.328 (86.577)	Acc@5 99.609 (99.484)
Max memory in training epoch: 60.0023552
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.161 (0.161)	Data 0.265 (0.265)	Loss 0.6094 (0.6094)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.6617 (0.6917)	Acc@1 85.938 (85.799)	Acc@5 99.219 (99.477)
Epoch: [78][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6502 (0.6901)	Acc@1 87.500 (85.941)	Acc@5 99.609 (99.443)
Epoch: [78][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7635 (0.6841)	Acc@1 83.594 (86.122)	Acc@5 98.438 (99.447)
Max memory in training epoch: 60.0023552
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.162 (0.162)	Data 0.301 (0.301)	Loss 0.5457 (0.5457)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.7387 (0.6601)	Acc@1 83.203 (86.863)	Acc@5 100.000 (99.495)
Epoch: [79][128/196]	Time 0.120 (0.126)	Data 0.000 (0.003)	Loss 0.6974 (0.6733)	Acc@1 86.719 (86.425)	Acc@5 98.438 (99.443)
Epoch: [79][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6917 (0.6674)	Acc@1 88.672 (86.668)	Acc@5 98.828 (99.445)
Max memory in training epoch: 60.0023552
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.166 (0.166)	Data 0.291 (0.291)	Loss 0.6287 (0.6287)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.7243 (0.6540)	Acc@1 83.984 (87.169)	Acc@5 98.828 (99.555)
Epoch: [80][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7270 (0.6646)	Acc@1 85.547 (86.804)	Acc@5 99.609 (99.525)
Epoch: [80][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6617 (0.6672)	Acc@1 83.984 (86.628)	Acc@5 100.000 (99.492)
Max memory in training epoch: 60.0023552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 327040 ; 331082 ; 0.9877915440887756
[INFO] Storing checkpoint...
  78.34
Max memory: 93.019648
 25.337s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2253
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1388544
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.179 (0.179)	Data 0.291 (0.291)	Loss 0.6141 (0.6141)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6414 (0.6491)	Acc@1 87.891 (87.248)	Acc@5 99.219 (99.513)
Epoch: [81][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6566 (0.6586)	Acc@1 89.453 (86.940)	Acc@5 99.219 (99.464)
Epoch: [81][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6494 (0.6647)	Acc@1 87.109 (86.699)	Acc@5 98.828 (99.458)
Max memory in training epoch: 59.5239424
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.169 (0.169)	Data 0.287 (0.287)	Loss 0.7609 (0.7609)	Acc@1 83.203 (83.203)	Acc@5 98.438 (98.438)
Epoch: [82][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.6418 (0.6652)	Acc@1 86.328 (86.532)	Acc@5 99.219 (99.495)
Epoch: [82][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6535 (0.6589)	Acc@1 88.672 (86.813)	Acc@5 99.609 (99.543)
Epoch: [82][192/196]	Time 0.133 (0.127)	Data 0.000 (0.002)	Loss 0.6919 (0.6644)	Acc@1 82.422 (86.713)	Acc@5 99.219 (99.488)
Max memory in training epoch: 59.8385152
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.175 (0.175)	Data 0.271 (0.271)	Loss 0.6327 (0.6327)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [83][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.6700 (0.6682)	Acc@1 86.328 (86.635)	Acc@5 98.828 (99.423)
Epoch: [83][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6765 (0.6667)	Acc@1 86.719 (86.637)	Acc@5 99.609 (99.413)
Epoch: [83][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6851 (0.6731)	Acc@1 85.156 (86.458)	Acc@5 98.828 (99.433)
Max memory in training epoch: 59.825408
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.173 (0.173)	Data 0.268 (0.268)	Loss 0.6479 (0.6479)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [84][64/196]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 0.7197 (0.6686)	Acc@1 83.594 (86.484)	Acc@5 99.609 (99.429)
Epoch: [84][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6995 (0.6718)	Acc@1 86.719 (86.349)	Acc@5 99.609 (99.455)
Epoch: [84][192/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.6821 (0.6743)	Acc@1 86.328 (86.290)	Acc@5 99.609 (99.439)
Max memory in training epoch: 59.825408
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.164 (0.164)	Data 0.273 (0.273)	Loss 0.6440 (0.6440)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [85][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.6390 (0.6527)	Acc@1 87.500 (87.025)	Acc@5 98.828 (99.489)
Epoch: [85][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.5820 (0.6628)	Acc@1 89.844 (86.710)	Acc@5 99.219 (99.437)
Epoch: [85][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7705 (0.6685)	Acc@1 83.203 (86.417)	Acc@5 98.438 (99.462)
Max memory in training epoch: 59.825408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 325308 ; 327040 ; 0.994704011741683
[INFO] Storing checkpoint...
  79.45
Max memory: 92.6034944
 25.600s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2892
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1381376
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.209 (0.209)	Data 0.261 (0.261)	Loss 0.6959 (0.6959)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [86][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.7460 (0.6396)	Acc@1 85.156 (87.374)	Acc@5 99.219 (99.567)
Epoch: [86][128/196]	Time 0.130 (0.126)	Data 0.000 (0.002)	Loss 0.5796 (0.6531)	Acc@1 89.062 (86.973)	Acc@5 100.000 (99.546)
Epoch: [86][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6830 (0.6554)	Acc@1 85.938 (86.885)	Acc@5 98.047 (99.524)
Max memory in training epoch: 59.507968
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.180 (0.180)	Data 0.277 (0.277)	Loss 0.6210 (0.6210)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [87][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.6677 (0.6468)	Acc@1 86.328 (87.079)	Acc@5 99.219 (99.555)
Epoch: [87][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6589 (0.6556)	Acc@1 85.547 (86.779)	Acc@5 99.609 (99.543)
Epoch: [87][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6846 (0.6631)	Acc@1 85.547 (86.701)	Acc@5 99.609 (99.508)
Max memory in training epoch: 59.770112
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.158 (0.158)	Data 0.313 (0.313)	Loss 0.5570 (0.5570)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [88][64/196]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.7040 (0.6437)	Acc@1 85.547 (87.284)	Acc@5 99.219 (99.543)
Epoch: [88][128/196]	Time 0.122 (0.127)	Data 0.000 (0.003)	Loss 0.6780 (0.6589)	Acc@1 86.328 (86.758)	Acc@5 99.219 (99.531)
Epoch: [88][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.5978 (0.6632)	Acc@1 88.281 (86.524)	Acc@5 100.000 (99.510)
Max memory in training epoch: 59.7570048
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.153 (0.153)	Data 0.295 (0.295)	Loss 0.5874 (0.5874)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.7143 (0.6502)	Acc@1 86.328 (86.989)	Acc@5 99.609 (99.555)
Epoch: [89][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6724 (0.6602)	Acc@1 86.328 (86.519)	Acc@5 99.219 (99.531)
Epoch: [89][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7398 (0.6641)	Acc@1 85.156 (86.480)	Acc@5 99.609 (99.488)
Max memory in training epoch: 59.7570048
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.176 (0.176)	Data 0.259 (0.259)	Loss 0.6735 (0.6735)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [90][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.5640 (0.6556)	Acc@1 90.234 (86.719)	Acc@5 100.000 (99.555)
Epoch: [90][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7067 (0.6653)	Acc@1 87.109 (86.507)	Acc@5 98.438 (99.476)
Epoch: [90][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6423 (0.6665)	Acc@1 88.281 (86.456)	Acc@5 98.438 (99.502)
Max memory in training epoch: 59.7570048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 323576 ; 325308 ; 0.9946758149200142
[INFO] Storing checkpoint...
  79.76
Max memory: 92.4055552
 25.717s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5849
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1375232
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.198 (0.198)	Data 0.249 (0.249)	Loss 0.7127 (0.7127)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.133 (0.127)	Data 0.000 (0.004)	Loss 0.6313 (0.6452)	Acc@1 89.062 (87.392)	Acc@5 99.609 (99.519)
Epoch: [91][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7679 (0.6515)	Acc@1 83.594 (87.185)	Acc@5 98.828 (99.540)
Epoch: [91][192/196]	Time 0.122 (0.127)	Data 0.000 (0.001)	Loss 0.6147 (0.6611)	Acc@1 88.281 (86.737)	Acc@5 98.828 (99.494)
Max memory in training epoch: 59.4530816
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.160 (0.160)	Data 0.304 (0.304)	Loss 0.6007 (0.6007)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.6766 (0.6493)	Acc@1 85.156 (87.019)	Acc@5 99.609 (99.525)
Epoch: [92][128/196]	Time 0.126 (0.126)	Data 0.000 (0.003)	Loss 0.6568 (0.6688)	Acc@1 86.719 (86.377)	Acc@5 99.609 (99.452)
Epoch: [92][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7350 (0.6667)	Acc@1 82.812 (86.545)	Acc@5 100.000 (99.449)
Max memory in training epoch: 59.7152256
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.180 (0.180)	Data 0.253 (0.253)	Loss 0.7135 (0.7135)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [93][64/196]	Time 0.124 (0.127)	Data 0.000 (0.004)	Loss 0.5298 (0.5613)	Acc@1 91.016 (90.294)	Acc@5 99.609 (99.700)
Epoch: [93][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5160 (0.5436)	Acc@1 89.453 (90.776)	Acc@5 99.219 (99.694)
Epoch: [93][192/196]	Time 0.123 (0.126)	Data 0.000 (0.001)	Loss 0.4370 (0.5281)	Acc@1 94.531 (91.232)	Acc@5 100.000 (99.745)
Max memory in training epoch: 59.7152256
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.174 (0.174)	Data 0.254 (0.254)	Loss 0.5314 (0.5314)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.121 (0.126)	Data 0.000 (0.004)	Loss 0.5195 (0.4823)	Acc@1 90.625 (92.855)	Acc@5 100.000 (99.880)
Epoch: [94][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.4530 (0.4754)	Acc@1 93.359 (92.993)	Acc@5 99.609 (99.879)
Epoch: [94][192/196]	Time 0.128 (0.126)	Data 0.000 (0.001)	Loss 0.4844 (0.4709)	Acc@1 92.578 (93.064)	Acc@5 99.219 (99.858)
Max memory in training epoch: 59.7152256
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.177 (0.177)	Data 0.261 (0.261)	Loss 0.4007 (0.4007)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.125 (0.126)	Data 0.000 (0.004)	Loss 0.4078 (0.4501)	Acc@1 95.703 (93.774)	Acc@5 100.000 (99.826)
Epoch: [95][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.4356 (0.4515)	Acc@1 93.359 (93.668)	Acc@5 100.000 (99.840)
Epoch: [95][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.4380 (0.4512)	Acc@1 94.922 (93.578)	Acc@5 99.219 (99.844)
Max memory in training epoch: 59.7152256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 321410 ; 323576 ; 0.9933060548371944
[INFO] Storing checkpoint...
  90.96
Max memory: 92.2431488
 24.890s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7426
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1366528
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.179 (0.179)	Data 0.289 (0.289)	Loss 0.4021 (0.4021)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.4312 (0.4339)	Acc@1 94.531 (94.111)	Acc@5 99.609 (99.868)
Epoch: [96][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.4443 (0.4345)	Acc@1 92.188 (93.965)	Acc@5 100.000 (99.870)
Epoch: [96][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.4021 (0.4346)	Acc@1 95.312 (93.944)	Acc@5 100.000 (99.866)
Max memory in training epoch: 59.2923136
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.194 (0.194)	Data 0.263 (0.263)	Loss 0.3990 (0.3990)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.4172 (0.4142)	Acc@1 93.750 (94.447)	Acc@5 99.609 (99.862)
Epoch: [97][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.4448 (0.4185)	Acc@1 94.531 (94.313)	Acc@5 100.000 (99.873)
Epoch: [97][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.3902 (0.4187)	Acc@1 95.312 (94.290)	Acc@5 100.000 (99.872)
Max memory in training epoch: 59.6068864
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.189 (0.189)	Data 0.259 (0.259)	Loss 0.3981 (0.3981)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.121 (0.130)	Data 0.000 (0.004)	Loss 0.3612 (0.4104)	Acc@1 95.312 (94.441)	Acc@5 100.000 (99.880)
Epoch: [98][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.3733 (0.4120)	Acc@1 96.094 (94.353)	Acc@5 100.000 (99.873)
Epoch: [98][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.3795 (0.4109)	Acc@1 95.703 (94.345)	Acc@5 99.609 (99.877)
Max memory in training epoch: 59.6068864
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.183 (0.183)	Data 0.278 (0.278)	Loss 0.3663 (0.3663)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.129 (0.127)	Data 0.000 (0.004)	Loss 0.4174 (0.3957)	Acc@1 92.969 (94.778)	Acc@5 99.609 (99.910)
Epoch: [99][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.4417 (0.3993)	Acc@1 93.750 (94.695)	Acc@5 100.000 (99.879)
Epoch: [99][192/196]	Time 0.139 (0.127)	Data 0.000 (0.002)	Loss 0.3562 (0.3975)	Acc@1 94.922 (94.707)	Acc@5 100.000 (99.883)
Max memory in training epoch: 59.6068864
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.173 (0.173)	Data 0.327 (0.327)	Loss 0.3786 (0.3786)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.3869 (0.3886)	Acc@1 95.703 (94.916)	Acc@5 99.609 (99.898)
Epoch: [100][128/196]	Time 0.128 (0.127)	Data 0.000 (0.003)	Loss 0.3720 (0.3847)	Acc@1 95.312 (95.031)	Acc@5 99.609 (99.903)
Epoch: [100][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3787 (0.3871)	Acc@1 94.922 (94.952)	Acc@5 100.000 (99.899)
Max memory in training epoch: 59.6068864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.43
Max memory: 92.037376
 25.106s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3344
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1366528
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.207 (0.207)	Data 0.272 (0.272)	Loss 0.4007 (0.4007)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [101][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.3499 (0.3739)	Acc@1 96.875 (95.192)	Acc@5 100.000 (99.916)
Epoch: [101][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3798 (0.3767)	Acc@1 94.922 (95.085)	Acc@5 100.000 (99.909)
Epoch: [101][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.3280 (0.3766)	Acc@1 96.875 (95.041)	Acc@5 100.000 (99.909)
Max memory in training epoch: 59.2923136
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.154 (0.154)	Data 0.287 (0.287)	Loss 0.4418 (0.4418)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.3648 (0.3693)	Acc@1 95.703 (95.337)	Acc@5 100.000 (99.922)
Epoch: [102][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.3780 (0.3704)	Acc@1 94.922 (95.252)	Acc@5 100.000 (99.912)
Epoch: [102][192/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.3770 (0.3709)	Acc@1 94.141 (95.248)	Acc@5 99.609 (99.903)
Max memory in training epoch: 59.6068864
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.175 (0.175)	Data 0.290 (0.290)	Loss 0.3637 (0.3637)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.3276 (0.3560)	Acc@1 96.484 (95.439)	Acc@5 100.000 (99.952)
Epoch: [103][128/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.3728 (0.3588)	Acc@1 94.922 (95.455)	Acc@5 100.000 (99.939)
Epoch: [103][192/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.4123 (0.3593)	Acc@1 92.969 (95.363)	Acc@5 100.000 (99.935)
Max memory in training epoch: 59.6068864
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.183 (0.183)	Data 0.265 (0.265)	Loss 0.3016 (0.3016)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.116 (0.128)	Data 0.000 (0.004)	Loss 0.3803 (0.3498)	Acc@1 95.312 (95.811)	Acc@5 100.000 (99.940)
Epoch: [104][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.3263 (0.3506)	Acc@1 96.875 (95.712)	Acc@5 100.000 (99.927)
Epoch: [104][192/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.3894 (0.3539)	Acc@1 92.969 (95.503)	Acc@5 99.609 (99.927)
Max memory in training epoch: 59.6068864
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.187 (0.187)	Data 0.291 (0.291)	Loss 0.3392 (0.3392)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.119 (0.128)	Data 0.000 (0.005)	Loss 0.3805 (0.3475)	Acc@1 94.531 (95.499)	Acc@5 100.000 (99.964)
Epoch: [105][128/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.3860 (0.3446)	Acc@1 92.969 (95.658)	Acc@5 100.000 (99.952)
Epoch: [105][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.3807 (0.3471)	Acc@1 94.531 (95.523)	Acc@5 100.000 (99.927)
Max memory in training epoch: 59.6068864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 321120 ; 321410 ; 0.9990977256463707
[INFO] Storing checkpoint...
  91.37
Max memory: 92.037376
 25.065s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3692
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.136448
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.204 (0.204)	Data 0.264 (0.264)	Loss 0.3190 (0.3190)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.3505 (0.3432)	Acc@1 95.312 (95.613)	Acc@5 100.000 (99.934)
Epoch: [106][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.3614 (0.3401)	Acc@1 93.750 (95.640)	Acc@5 100.000 (99.949)
Epoch: [106][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.3258 (0.3417)	Acc@1 96.875 (95.539)	Acc@5 100.000 (99.957)
Max memory in training epoch: 59.0817792
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.165 (0.165)	Data 0.275 (0.275)	Loss 0.3215 (0.3215)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.3027 (0.3306)	Acc@1 96.484 (96.004)	Acc@5 100.000 (99.922)
Epoch: [107][128/196]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.3480 (0.3341)	Acc@1 96.094 (95.797)	Acc@5 100.000 (99.900)
Epoch: [107][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3180 (0.3368)	Acc@1 96.484 (95.671)	Acc@5 100.000 (99.905)
Max memory in training epoch: 59.658496
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.186 (0.186)	Data 0.292 (0.292)	Loss 0.3605 (0.3605)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [108][64/196]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.2872 (0.3225)	Acc@1 97.656 (96.136)	Acc@5 99.609 (99.958)
Epoch: [108][128/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.2987 (0.3217)	Acc@1 97.656 (96.070)	Acc@5 100.000 (99.952)
Epoch: [108][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.3538 (0.3256)	Acc@1 95.312 (95.962)	Acc@5 99.609 (99.945)
Max memory in training epoch: 59.6453888
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.166 (0.166)	Data 0.298 (0.298)	Loss 0.2918 (0.2918)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.2740 (0.3244)	Acc@1 98.438 (95.907)	Acc@5 100.000 (99.958)
Epoch: [109][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.2877 (0.3249)	Acc@1 97.266 (95.873)	Acc@5 100.000 (99.952)
Epoch: [109][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.3041 (0.3267)	Acc@1 96.484 (95.748)	Acc@5 100.000 (99.951)
Max memory in training epoch: 59.6453888
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.144 (0.144)	Data 0.305 (0.305)	Loss 0.3158 (0.3158)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.2929 (0.3214)	Acc@1 96.484 (95.913)	Acc@5 100.000 (99.934)
Epoch: [110][128/196]	Time 0.123 (0.127)	Data 0.000 (0.003)	Loss 0.3444 (0.3214)	Acc@1 93.359 (95.912)	Acc@5 100.000 (99.936)
Epoch: [110][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.3425 (0.3204)	Acc@1 94.922 (95.914)	Acc@5 100.000 (99.933)
Max memory in training epoch: 59.6453888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.14
Max memory: 91.6632064
 25.203s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8653
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.136448
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.184 (0.184)	Data 0.258 (0.258)	Loss 0.3170 (0.3170)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.117 (0.128)	Data 0.000 (0.004)	Loss 0.2708 (0.3059)	Acc@1 96.875 (96.484)	Acc@5 100.000 (99.946)
Epoch: [111][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.4248 (0.3140)	Acc@1 93.359 (96.057)	Acc@5 100.000 (99.961)
Epoch: [111][192/196]	Time 0.126 (0.127)	Data 0.000 (0.001)	Loss 0.3675 (0.3181)	Acc@1 92.969 (95.825)	Acc@5 100.000 (99.951)
Max memory in training epoch: 59.0817792
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.149 (0.149)	Data 0.293 (0.293)	Loss 0.3289 (0.3289)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.138 (0.126)	Data 0.000 (0.005)	Loss 0.2963 (0.3127)	Acc@1 96.484 (95.938)	Acc@5 100.000 (99.934)
Epoch: [112][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.3001 (0.3121)	Acc@1 96.875 (95.982)	Acc@5 100.000 (99.942)
Epoch: [112][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.3595 (0.3147)	Acc@1 93.750 (95.889)	Acc@5 100.000 (99.939)
Max memory in training epoch: 59.658496
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.183 (0.183)	Data 0.266 (0.266)	Loss 0.2706 (0.2706)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.146 (0.128)	Data 0.000 (0.004)	Loss 0.2918 (0.3010)	Acc@1 96.875 (96.340)	Acc@5 100.000 (99.946)
Epoch: [113][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.3139 (0.3088)	Acc@1 95.312 (96.012)	Acc@5 100.000 (99.949)
Epoch: [113][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.3408 (0.3103)	Acc@1 93.359 (95.958)	Acc@5 100.000 (99.951)
Max memory in training epoch: 59.6453888
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.189 (0.189)	Data 0.269 (0.269)	Loss 0.2919 (0.2919)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.2886 (0.3021)	Acc@1 96.875 (96.478)	Acc@5 100.000 (99.934)
Epoch: [114][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.3263 (0.3068)	Acc@1 95.703 (96.233)	Acc@5 99.609 (99.933)
Epoch: [114][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.3358 (0.3092)	Acc@1 94.922 (96.053)	Acc@5 100.000 (99.939)
Max memory in training epoch: 59.6453888
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.162 (0.162)	Data 0.301 (0.301)	Loss 0.2888 (0.2888)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.122 (0.128)	Data 0.000 (0.005)	Loss 0.3000 (0.2961)	Acc@1 96.484 (96.280)	Acc@5 100.000 (99.982)
Epoch: [115][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.3419 (0.3057)	Acc@1 96.094 (95.900)	Acc@5 99.609 (99.970)
Epoch: [115][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.3424 (0.3099)	Acc@1 94.922 (95.798)	Acc@5 100.000 (99.957)
Max memory in training epoch: 59.6453888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.71
Max memory: 91.6632064
 25.254s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9246
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.136448
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.194 (0.194)	Data 0.288 (0.288)	Loss 0.2673 (0.2673)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.122 (0.130)	Data 0.000 (0.005)	Loss 0.3242 (0.2939)	Acc@1 94.922 (96.274)	Acc@5 99.609 (99.964)
Epoch: [116][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.3229 (0.2985)	Acc@1 94.141 (96.166)	Acc@5 100.000 (99.955)
Epoch: [116][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3066 (0.3022)	Acc@1 95.703 (96.029)	Acc@5 100.000 (99.951)
Max memory in training epoch: 59.0817792
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.182 (0.182)	Data 0.260 (0.260)	Loss 0.2912 (0.2912)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 0.2583 (0.3008)	Acc@1 97.656 (95.992)	Acc@5 100.000 (99.982)
Epoch: [117][128/196]	Time 0.144 (0.127)	Data 0.000 (0.002)	Loss 0.3019 (0.3014)	Acc@1 94.922 (96.036)	Acc@5 100.000 (99.964)
Epoch: [117][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.3058 (0.3027)	Acc@1 95.703 (95.916)	Acc@5 100.000 (99.960)
Max memory in training epoch: 59.658496
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.150 (0.150)	Data 0.315 (0.315)	Loss 0.2424 (0.2424)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.2787 (0.3117)	Acc@1 96.875 (95.583)	Acc@5 100.000 (99.970)
Epoch: [118][128/196]	Time 0.124 (0.127)	Data 0.000 (0.003)	Loss 0.3125 (0.3045)	Acc@1 94.922 (95.803)	Acc@5 99.609 (99.961)
Epoch: [118][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.2545 (0.3067)	Acc@1 97.656 (95.731)	Acc@5 100.000 (99.962)
Max memory in training epoch: 59.6453888
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.176 (0.176)	Data 0.298 (0.298)	Loss 0.2969 (0.2969)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.3237 (0.2985)	Acc@1 94.922 (96.022)	Acc@5 100.000 (99.958)
Epoch: [119][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.2886 (0.3017)	Acc@1 95.703 (95.936)	Acc@5 100.000 (99.967)
Epoch: [119][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.3278 (0.3042)	Acc@1 94.531 (95.833)	Acc@5 99.609 (99.966)
Max memory in training epoch: 59.6453888
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.170 (0.170)	Data 0.290 (0.290)	Loss 0.2717 (0.2717)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.118 (0.130)	Data 0.000 (0.005)	Loss 0.3517 (0.3014)	Acc@1 94.922 (95.811)	Acc@5 100.000 (99.952)
Epoch: [120][128/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.2755 (0.2982)	Acc@1 96.875 (95.933)	Acc@5 100.000 (99.958)
Epoch: [120][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.2973 (0.3000)	Acc@1 96.484 (95.851)	Acc@5 100.000 (99.960)
Max memory in training epoch: 59.6453888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 320542 ; 321120 ; 0.9982000498256104
[INFO] Storing checkpoint...
  89.82
Max memory: 91.6632064
 25.362s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9200
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1362432
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.184 (0.184)	Data 0.283 (0.283)	Loss 0.2796 (0.2796)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.133 (0.129)	Data 0.000 (0.005)	Loss 0.3117 (0.2864)	Acc@1 95.312 (96.466)	Acc@5 100.000 (99.970)
Epoch: [121][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.2911 (0.2892)	Acc@1 95.703 (96.294)	Acc@5 100.000 (99.952)
Epoch: [121][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.3078 (0.2955)	Acc@1 96.094 (96.053)	Acc@5 100.000 (99.951)
Max memory in training epoch: 59.0285312
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.174 (0.174)	Data 0.290 (0.290)	Loss 0.2803 (0.2803)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.2488 (0.2914)	Acc@1 97.656 (95.992)	Acc@5 100.000 (99.964)
Epoch: [122][128/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.3172 (0.2938)	Acc@1 95.703 (95.891)	Acc@5 100.000 (99.964)
Epoch: [122][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.3045 (0.2965)	Acc@1 97.266 (95.786)	Acc@5 100.000 (99.972)
Max memory in training epoch: 59.605248
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.192 (0.192)	Data 0.266 (0.266)	Loss 0.2897 (0.2897)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.145 (0.129)	Data 0.000 (0.004)	Loss 0.2783 (0.2913)	Acc@1 96.094 (95.950)	Acc@5 100.000 (99.964)
Epoch: [123][128/196]	Time 0.145 (0.129)	Data 0.000 (0.002)	Loss 0.3328 (0.2964)	Acc@1 94.141 (95.767)	Acc@5 100.000 (99.970)
Epoch: [123][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.3674 (0.3008)	Acc@1 93.359 (95.634)	Acc@5 100.000 (99.966)
Max memory in training epoch: 59.5921408
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.184 (0.184)	Data 0.264 (0.264)	Loss 0.2475 (0.2475)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.3201 (0.2873)	Acc@1 94.922 (96.166)	Acc@5 100.000 (99.964)
Epoch: [124][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.2843 (0.2911)	Acc@1 96.875 (96.060)	Acc@5 100.000 (99.949)
Epoch: [124][192/196]	Time 0.136 (0.129)	Data 0.000 (0.002)	Loss 0.2659 (0.2956)	Acc@1 98.047 (95.889)	Acc@5 100.000 (99.953)
Max memory in training epoch: 59.5921408
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.151 (0.151)	Data 0.303 (0.303)	Loss 0.3436 (0.3436)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 0.3316 (0.2974)	Acc@1 94.531 (95.745)	Acc@5 99.609 (99.976)
Epoch: [125][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.2996 (0.2967)	Acc@1 96.484 (95.715)	Acc@5 100.000 (99.967)
Epoch: [125][192/196]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.3710 (0.2980)	Acc@1 92.969 (95.703)	Acc@5 100.000 (99.968)
Max memory in training epoch: 59.5921408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 319900 ; 320542 ; 0.9979971423401613
[INFO] Storing checkpoint...
  89.95
Max memory: 91.580672
 25.537s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 168
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.135424
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.175 (0.175)	Data 0.298 (0.298)	Loss 0.3015 (0.3015)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [126][64/196]	Time 0.139 (0.123)	Data 0.000 (0.005)	Loss 0.2356 (0.2791)	Acc@1 98.438 (96.406)	Acc@5 100.000 (99.982)
Epoch: [126][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3075 (0.2905)	Acc@1 95.703 (96.045)	Acc@5 100.000 (99.973)
Epoch: [126][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.3228 (0.2946)	Acc@1 94.531 (95.835)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.289472
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.175 (0.175)	Data 0.290 (0.290)	Loss 0.3050 (0.3050)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.118 (0.125)	Data 0.000 (0.005)	Loss 0.2800 (0.2952)	Acc@1 96.094 (95.835)	Acc@5 100.000 (99.952)
Epoch: [127][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.2860 (0.2976)	Acc@1 95.312 (95.746)	Acc@5 100.000 (99.949)
Epoch: [127][192/196]	Time 0.138 (0.123)	Data 0.000 (0.002)	Loss 0.3005 (0.2979)	Acc@1 95.703 (95.679)	Acc@5 100.000 (99.949)
Max memory in training epoch: 57.8727424
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.176 (0.176)	Data 0.298 (0.298)	Loss 0.2653 (0.2653)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.2640 (0.2972)	Acc@1 96.875 (95.637)	Acc@5 100.000 (99.952)
Epoch: [128][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.2788 (0.2994)	Acc@1 96.875 (95.524)	Acc@5 99.609 (99.952)
Epoch: [128][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.2941 (0.2998)	Acc@1 94.922 (95.533)	Acc@5 100.000 (99.951)
Max memory in training epoch: 57.8727424
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.187 (0.187)	Data 0.294 (0.294)	Loss 0.2495 (0.2495)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.144 (0.124)	Data 0.000 (0.005)	Loss 0.2726 (0.2883)	Acc@1 95.703 (95.889)	Acc@5 100.000 (99.970)
Epoch: [129][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2762 (0.2947)	Acc@1 96.094 (95.676)	Acc@5 100.000 (99.970)
Epoch: [129][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.2853 (0.2965)	Acc@1 95.703 (95.636)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.8727424
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.172 (0.172)	Data 0.288 (0.288)	Loss 0.2574 (0.2574)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.129 (0.126)	Data 0.000 (0.005)	Loss 0.2748 (0.2823)	Acc@1 96.484 (96.106)	Acc@5 100.000 (99.964)
Epoch: [130][128/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.3255 (0.2922)	Acc@1 94.922 (95.833)	Acc@5 100.000 (99.961)
Epoch: [130][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.4034 (0.2949)	Acc@1 92.578 (95.738)	Acc@5 100.000 (99.957)
Max memory in training epoch: 57.8727424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 318456 ; 319900 ; 0.9954860894029384
[INFO] Storing checkpoint...
  89.21
Max memory: 88.7149056
 24.727s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1407
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.134912
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.195 (0.195)	Data 0.290 (0.290)	Loss 0.3319 (0.3319)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.133 (0.123)	Data 0.000 (0.005)	Loss 0.2556 (0.2832)	Acc@1 97.266 (96.142)	Acc@5 100.000 (99.964)
Epoch: [131][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2805 (0.2902)	Acc@1 96.875 (95.842)	Acc@5 99.609 (99.955)
Epoch: [131][192/196]	Time 0.134 (0.122)	Data 0.000 (0.002)	Loss 0.3000 (0.2939)	Acc@1 94.922 (95.709)	Acc@5 100.000 (99.947)
Max memory in training epoch: 57.0318336
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.150 (0.150)	Data 0.259 (0.259)	Loss 0.2561 (0.2561)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.117 (0.124)	Data 0.000 (0.004)	Loss 0.2303 (0.2857)	Acc@1 98.438 (95.925)	Acc@5 100.000 (99.982)
Epoch: [132][128/196]	Time 0.134 (0.123)	Data 0.000 (0.002)	Loss 0.2457 (0.2874)	Acc@1 97.266 (95.909)	Acc@5 100.000 (99.976)
Epoch: [132][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.3299 (0.2945)	Acc@1 93.750 (95.592)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.143 (0.143)	Data 0.265 (0.265)	Loss 0.2894 (0.2894)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.118 (0.125)	Data 0.000 (0.004)	Loss 0.2987 (0.2945)	Acc@1 94.531 (95.613)	Acc@5 100.000 (99.952)
Epoch: [133][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3040 (0.2964)	Acc@1 95.312 (95.588)	Acc@5 100.000 (99.955)
Epoch: [133][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3617 (0.2988)	Acc@1 94.141 (95.539)	Acc@5 99.219 (99.949)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.195 (0.195)	Data 0.277 (0.277)	Loss 0.2719 (0.2719)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.118 (0.124)	Data 0.000 (0.004)	Loss 0.2806 (0.2988)	Acc@1 96.484 (95.463)	Acc@5 100.000 (99.952)
Epoch: [134][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.3323 (0.2943)	Acc@1 93.750 (95.600)	Acc@5 100.000 (99.936)
Epoch: [134][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3112 (0.2996)	Acc@1 94.922 (95.410)	Acc@5 100.000 (99.943)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.164 (0.164)	Data 0.261 (0.261)	Loss 0.2779 (0.2779)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.119 (0.124)	Data 0.000 (0.004)	Loss 0.2650 (0.2891)	Acc@1 97.266 (95.859)	Acc@5 100.000 (99.970)
Epoch: [135][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.2762 (0.2895)	Acc@1 96.484 (95.782)	Acc@5 100.000 (99.970)
Epoch: [135][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2973 (0.2939)	Acc@1 96.484 (95.683)	Acc@5 100.000 (99.957)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.23
Max memory: 88.6273536
 24.414s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1873
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.134912
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.194 (0.194)	Data 0.286 (0.286)	Loss 0.3344 (0.3344)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.129 (0.122)	Data 0.000 (0.005)	Loss 0.2723 (0.2860)	Acc@1 95.703 (95.859)	Acc@5 100.000 (99.982)
Epoch: [136][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3117 (0.2901)	Acc@1 94.922 (95.691)	Acc@5 100.000 (99.976)
Epoch: [136][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2751 (0.2928)	Acc@1 96.875 (95.608)	Acc@5 99.609 (99.966)
Max memory in training epoch: 57.0318336
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.168 (0.168)	Data 0.281 (0.281)	Loss 0.2819 (0.2819)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.3453 (0.2804)	Acc@1 93.750 (96.118)	Acc@5 99.609 (99.934)
Epoch: [137][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2562 (0.2871)	Acc@1 97.656 (95.818)	Acc@5 100.000 (99.949)
Epoch: [137][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3359 (0.2907)	Acc@1 94.922 (95.689)	Acc@5 100.000 (99.955)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.166 (0.166)	Data 0.278 (0.278)	Loss 0.2520 (0.2520)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.2644 (0.2837)	Acc@1 97.656 (96.070)	Acc@5 100.000 (99.958)
Epoch: [138][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2924 (0.2878)	Acc@1 95.703 (95.815)	Acc@5 100.000 (99.964)
Epoch: [138][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3041 (0.2928)	Acc@1 96.875 (95.646)	Acc@5 99.219 (99.962)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.176 (0.176)	Data 0.280 (0.280)	Loss 0.2940 (0.2940)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2674 (0.2939)	Acc@1 94.922 (95.685)	Acc@5 100.000 (99.952)
Epoch: [139][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3201 (0.2893)	Acc@1 95.703 (95.806)	Acc@5 100.000 (99.958)
Epoch: [139][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2596 (0.2931)	Acc@1 96.094 (95.689)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.147 (0.147)	Data 0.279 (0.279)	Loss 0.2615 (0.2615)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.2832 (0.2935)	Acc@1 95.312 (95.715)	Acc@5 100.000 (99.964)
Epoch: [140][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3122 (0.2932)	Acc@1 94.531 (95.633)	Acc@5 100.000 (99.964)
Epoch: [140][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2457 (0.2946)	Acc@1 98.047 (95.489)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.81
Max memory: 88.6273536
 24.148s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4480
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.134912
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.181 (0.181)	Data 0.284 (0.284)	Loss 0.3226 (0.3226)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [141][64/196]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.2709 (0.2727)	Acc@1 95.703 (96.520)	Acc@5 100.000 (99.970)
Epoch: [141][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.2736 (0.2804)	Acc@1 96.484 (96.194)	Acc@5 100.000 (99.973)
Epoch: [141][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3616 (0.2863)	Acc@1 92.578 (95.964)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.0318336
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.147 (0.147)	Data 0.259 (0.259)	Loss 0.3288 (0.3288)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.2943 (0.2967)	Acc@1 95.312 (95.469)	Acc@5 100.000 (99.946)
Epoch: [142][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2895 (0.2979)	Acc@1 96.094 (95.485)	Acc@5 100.000 (99.955)
Epoch: [142][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3291 (0.2978)	Acc@1 94.141 (95.489)	Acc@5 100.000 (99.951)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.162 (0.162)	Data 0.292 (0.292)	Loss 0.2809 (0.2809)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.112 (0.122)	Data 0.000 (0.005)	Loss 0.2676 (0.2931)	Acc@1 96.875 (95.559)	Acc@5 100.000 (99.976)
Epoch: [143][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2723 (0.2971)	Acc@1 96.484 (95.464)	Acc@5 100.000 (99.979)
Epoch: [143][192/196]	Time 0.133 (0.122)	Data 0.000 (0.002)	Loss 0.2875 (0.2981)	Acc@1 95.703 (95.428)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.159 (0.159)	Data 0.290 (0.290)	Loss 0.2751 (0.2751)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.2712 (0.2894)	Acc@1 95.703 (95.595)	Acc@5 100.000 (99.976)
Epoch: [144][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3027 (0.2901)	Acc@1 94.922 (95.649)	Acc@5 100.000 (99.970)
Epoch: [144][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2906 (0.2946)	Acc@1 95.312 (95.487)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.143 (0.143)	Data 0.314 (0.314)	Loss 0.3161 (0.3161)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.2504 (0.2884)	Acc@1 98.047 (95.895)	Acc@5 99.609 (99.958)
Epoch: [145][128/196]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.3006 (0.2877)	Acc@1 94.922 (95.836)	Acc@5 100.000 (99.961)
Epoch: [145][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3177 (0.2932)	Acc@1 94.531 (95.610)	Acc@5 99.609 (99.955)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.68
Max memory: 88.6273536
 23.951s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6201
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.134912
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.168 (0.168)	Data 0.300 (0.300)	Loss 0.2597 (0.2597)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.3006 (0.2775)	Acc@1 94.922 (96.076)	Acc@5 100.000 (99.964)
Epoch: [146][128/196]	Time 0.136 (0.121)	Data 0.000 (0.002)	Loss 0.2517 (0.2843)	Acc@1 97.656 (95.809)	Acc@5 100.000 (99.958)
Epoch: [146][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2821 (0.2902)	Acc@1 95.703 (95.661)	Acc@5 100.000 (99.951)
Max memory in training epoch: 57.0318336
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.168 (0.168)	Data 0.262 (0.262)	Loss 0.2668 (0.2668)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.124 (0.122)	Data 0.000 (0.004)	Loss 0.3070 (0.2812)	Acc@1 95.312 (95.950)	Acc@5 100.000 (99.964)
Epoch: [147][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2974 (0.2842)	Acc@1 96.094 (95.918)	Acc@5 100.000 (99.967)
Epoch: [147][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2744 (0.2893)	Acc@1 96.484 (95.721)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.152 (0.152)	Data 0.292 (0.292)	Loss 0.2831 (0.2831)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.2520 (0.2923)	Acc@1 96.484 (95.625)	Acc@5 100.000 (99.964)
Epoch: [148][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.3614 (0.2968)	Acc@1 93.359 (95.440)	Acc@5 99.609 (99.952)
Epoch: [148][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3188 (0.3019)	Acc@1 95.703 (95.244)	Acc@5 100.000 (99.955)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.154 (0.154)	Data 0.298 (0.298)	Loss 0.3126 (0.3126)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.2988 (0.2804)	Acc@1 94.531 (96.070)	Acc@5 100.000 (99.946)
Epoch: [149][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.3070 (0.2850)	Acc@1 94.922 (95.815)	Acc@5 100.000 (99.955)
Epoch: [149][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2922 (0.2912)	Acc@1 94.531 (95.576)	Acc@5 100.000 (99.951)
Max memory in training epoch: 57.5561216
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.142 (0.142)	Data 0.291 (0.291)	Loss 0.2740 (0.2740)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.110 (0.119)	Data 0.000 (0.005)	Loss 0.2629 (0.2635)	Acc@1 97.266 (96.815)	Acc@5 100.000 (99.964)
Epoch: [150][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2310 (0.2545)	Acc@1 98.047 (97.078)	Acc@5 100.000 (99.964)
Epoch: [150][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2680 (0.2505)	Acc@1 97.266 (97.278)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.19
Max memory: 88.6273536
 23.868s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4196
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.134912
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.203 (0.203)	Data 0.262 (0.262)	Loss 0.2362 (0.2362)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.126 (0.124)	Data 0.000 (0.004)	Loss 0.2102 (0.2323)	Acc@1 98.828 (97.909)	Acc@5 100.000 (99.994)
Epoch: [151][128/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.2189 (0.2292)	Acc@1 98.438 (98.017)	Acc@5 100.000 (99.988)
Epoch: [151][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.2106 (0.2278)	Acc@1 99.219 (98.059)	Acc@5 100.000 (99.988)
Max memory in training epoch: 57.0318336
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.172 (0.172)	Data 0.296 (0.296)	Loss 0.2206 (0.2206)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.2079 (0.2213)	Acc@1 98.828 (98.287)	Acc@5 100.000 (99.988)
Epoch: [152][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.2495 (0.2204)	Acc@1 97.266 (98.356)	Acc@5 100.000 (99.988)
Epoch: [152][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2223 (0.2206)	Acc@1 98.047 (98.342)	Acc@5 100.000 (99.988)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.154 (0.154)	Data 0.273 (0.273)	Loss 0.2097 (0.2097)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.2206 (0.2195)	Acc@1 98.438 (98.233)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.2217 (0.2190)	Acc@1 98.438 (98.310)	Acc@5 100.000 (99.994)
Epoch: [153][192/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.2129 (0.2192)	Acc@1 98.047 (98.310)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.160 (0.160)	Data 0.314 (0.314)	Loss 0.2009 (0.2009)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.117 (0.124)	Data 0.000 (0.005)	Loss 0.1994 (0.2109)	Acc@1 99.219 (98.594)	Acc@5 100.000 (99.994)
Epoch: [154][128/196]	Time 0.159 (0.124)	Data 0.000 (0.003)	Loss 0.2104 (0.2115)	Acc@1 99.219 (98.613)	Acc@5 100.000 (99.991)
Epoch: [154][192/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.2435 (0.2127)	Acc@1 97.656 (98.569)	Acc@5 100.000 (99.988)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.151 (0.151)	Data 0.276 (0.276)	Loss 0.2106 (0.2106)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.2349 (0.2118)	Acc@1 98.438 (98.642)	Acc@5 100.000 (99.994)
Epoch: [155][128/196]	Time 0.134 (0.124)	Data 0.000 (0.002)	Loss 0.2205 (0.2103)	Acc@1 98.438 (98.680)	Acc@5 100.000 (99.994)
Epoch: [155][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2057 (0.2117)	Acc@1 99.219 (98.601)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.6
Max memory: 88.6273536
 24.495s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1951
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.134912
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.174 (0.174)	Data 0.298 (0.298)	Loss 0.2062 (0.2062)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.2128 (0.2056)	Acc@1 98.047 (98.810)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.136 (0.121)	Data 0.000 (0.002)	Loss 0.2033 (0.2061)	Acc@1 98.828 (98.768)	Acc@5 100.000 (99.991)
Epoch: [156][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1970 (0.2064)	Acc@1 99.609 (98.780)	Acc@5 100.000 (99.990)
Max memory in training epoch: 57.0318336
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.158 (0.158)	Data 0.290 (0.290)	Loss 0.1937 (0.1937)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.1980 (0.2053)	Acc@1 98.828 (98.858)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2076 (0.2036)	Acc@1 98.828 (98.901)	Acc@5 100.000 (99.997)
Epoch: [157][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2225 (0.2044)	Acc@1 98.828 (98.838)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.170 (0.170)	Data 0.282 (0.282)	Loss 0.1969 (0.1969)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2071 (0.2026)	Acc@1 98.047 (98.864)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2035 (0.2023)	Acc@1 98.438 (98.846)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.2105 (0.2023)	Acc@1 98.828 (98.858)	Acc@5 99.609 (99.990)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.175 (0.175)	Data 0.260 (0.260)	Loss 0.1945 (0.1945)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.2273 (0.2005)	Acc@1 98.047 (98.924)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.113 (0.123)	Data 0.000 (0.002)	Loss 0.1883 (0.2006)	Acc@1 99.219 (98.925)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.1957 (0.2004)	Acc@1 99.219 (98.901)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.166 (0.166)	Data 0.303 (0.303)	Loss 0.1857 (0.1857)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.1951 (0.1991)	Acc@1 99.609 (98.978)	Acc@5 100.000 (99.994)
Epoch: [160][128/196]	Time 0.115 (0.122)	Data 0.000 (0.003)	Loss 0.2314 (0.1992)	Acc@1 97.656 (98.955)	Acc@5 99.609 (99.994)
Epoch: [160][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2153 (0.1982)	Acc@1 97.656 (98.990)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.81
Max memory: 88.6273536
 24.157s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3168
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.134912
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.192 (0.192)	Data 0.303 (0.303)	Loss 0.1924 (0.1924)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.118 (0.127)	Data 0.000 (0.005)	Loss 0.1957 (0.1941)	Acc@1 98.828 (99.165)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.124 (0.125)	Data 0.000 (0.003)	Loss 0.1893 (0.1957)	Acc@1 99.609 (99.089)	Acc@5 100.000 (99.997)
Epoch: [161][192/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.1912 (0.1964)	Acc@1 99.609 (99.043)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.0318336
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.178 (0.178)	Data 0.272 (0.272)	Loss 0.1999 (0.1999)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.125 (0.126)	Data 0.000 (0.004)	Loss 0.2075 (0.1941)	Acc@1 98.047 (99.093)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.1822 (0.1945)	Acc@1 99.609 (99.079)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.2003 (0.1960)	Acc@1 98.828 (98.982)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.168 (0.168)	Data 0.273 (0.273)	Loss 0.2038 (0.2038)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.117 (0.124)	Data 0.000 (0.004)	Loss 0.1992 (0.1955)	Acc@1 99.219 (98.996)	Acc@5 100.000 (99.988)
Epoch: [163][128/196]	Time 0.129 (0.124)	Data 0.000 (0.002)	Loss 0.1989 (0.1958)	Acc@1 99.219 (99.028)	Acc@5 100.000 (99.994)
Epoch: [163][192/196]	Time 0.116 (0.124)	Data 0.000 (0.002)	Loss 0.1912 (0.1953)	Acc@1 98.828 (99.049)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.163 (0.163)	Data 0.268 (0.268)	Loss 0.1799 (0.1799)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.119 (0.126)	Data 0.000 (0.004)	Loss 0.1851 (0.1918)	Acc@1 99.609 (99.093)	Acc@5 100.000 (99.994)
Epoch: [164][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.1961 (0.1923)	Acc@1 98.438 (99.043)	Acc@5 100.000 (99.997)
Epoch: [164][192/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.1885 (0.1923)	Acc@1 99.219 (99.069)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.162 (0.162)	Data 0.298 (0.298)	Loss 0.1776 (0.1776)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.121 (0.126)	Data 0.000 (0.005)	Loss 0.1948 (0.1915)	Acc@1 98.828 (99.165)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.1996 (0.1922)	Acc@1 98.438 (99.119)	Acc@5 100.000 (99.997)
Epoch: [165][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.1850 (0.1922)	Acc@1 99.609 (99.140)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.59
Max memory: 88.6273536
 24.782s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3484
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.134912
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.193 (0.193)	Data 0.271 (0.271)	Loss 0.1879 (0.1879)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.1951 (0.1908)	Acc@1 98.438 (99.153)	Acc@5 100.000 (99.994)
Epoch: [166][128/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.1804 (0.1904)	Acc@1 99.219 (99.158)	Acc@5 100.000 (99.997)
Epoch: [166][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1955 (0.1905)	Acc@1 98.438 (99.124)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.0318336
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.174 (0.174)	Data 0.295 (0.295)	Loss 0.1791 (0.1791)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2043 (0.1897)	Acc@1 98.828 (99.135)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1925 (0.1890)	Acc@1 98.828 (99.155)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1812 (0.1891)	Acc@1 99.219 (99.186)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.165 (0.165)	Data 0.259 (0.259)	Loss 0.1842 (0.1842)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.1721 (0.1887)	Acc@1 100.000 (99.165)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1945 (0.1886)	Acc@1 99.609 (99.176)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1812 (0.1892)	Acc@1 99.609 (99.132)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.169 (0.169)	Data 0.262 (0.262)	Loss 0.1963 (0.1963)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.1924 (0.1873)	Acc@1 99.219 (99.273)	Acc@5 100.000 (99.994)
Epoch: [169][128/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.2034 (0.1872)	Acc@1 99.219 (99.225)	Acc@5 100.000 (99.997)
Epoch: [169][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2065 (0.1874)	Acc@1 98.438 (99.213)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.166 (0.166)	Data 0.264 (0.264)	Loss 0.1924 (0.1924)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.1885 (0.1862)	Acc@1 99.219 (99.297)	Acc@5 100.000 (99.994)
Epoch: [170][128/196]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.1661 (0.1849)	Acc@1 100.000 (99.367)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1882 (0.1858)	Acc@1 98.828 (99.286)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.71
Max memory: 88.6273536
 24.337s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5838
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.134912
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.195 (0.195)	Data 0.297 (0.297)	Loss 0.1831 (0.1831)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.1780 (0.1837)	Acc@1 100.000 (99.369)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1687 (0.1836)	Acc@1 100.000 (99.319)	Acc@5 100.000 (99.997)
Epoch: [171][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1865 (0.1842)	Acc@1 98.828 (99.310)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.0318336
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.151 (0.151)	Data 0.315 (0.315)	Loss 0.1786 (0.1786)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.1715 (0.1832)	Acc@1 99.609 (99.417)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.1755 (0.1830)	Acc@1 100.000 (99.373)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.1866 (0.1826)	Acc@1 99.219 (99.366)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.160 (0.160)	Data 0.290 (0.290)	Loss 0.1788 (0.1788)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.1972 (0.1836)	Acc@1 99.219 (99.393)	Acc@5 100.000 (99.988)
Epoch: [173][128/196]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.1749 (0.1835)	Acc@1 99.609 (99.319)	Acc@5 100.000 (99.994)
Epoch: [173][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1728 (0.1831)	Acc@1 99.219 (99.336)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.163 (0.163)	Data 0.287 (0.287)	Loss 0.1726 (0.1726)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.2353 (0.1846)	Acc@1 97.656 (99.267)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1781 (0.1834)	Acc@1 99.609 (99.307)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.1727 (0.1835)	Acc@1 99.609 (99.284)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.156 (0.156)	Data 0.303 (0.303)	Loss 0.1769 (0.1769)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.1939 (0.1806)	Acc@1 99.219 (99.405)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.1719 (0.1814)	Acc@1 100.000 (99.364)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1856 (0.1811)	Acc@1 99.219 (99.389)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.72
Max memory: 88.6273536
 24.348s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6721
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.134912
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.202 (0.202)	Data 0.261 (0.261)	Loss 0.1729 (0.1729)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.1754 (0.1793)	Acc@1 99.609 (99.441)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1818 (0.1796)	Acc@1 98.828 (99.464)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.133 (0.122)	Data 0.000 (0.002)	Loss 0.1859 (0.1802)	Acc@1 99.219 (99.407)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.0318336
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.172 (0.172)	Data 0.308 (0.308)	Loss 0.1906 (0.1906)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.1819 (0.1791)	Acc@1 99.219 (99.405)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.139 (0.123)	Data 0.000 (0.003)	Loss 0.1744 (0.1789)	Acc@1 99.609 (99.400)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1724 (0.1791)	Acc@1 99.609 (99.405)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.178 (0.178)	Data 0.255 (0.255)	Loss 0.1672 (0.1672)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.128 (0.124)	Data 0.000 (0.004)	Loss 0.1655 (0.1774)	Acc@1 100.000 (99.405)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.1703 (0.1773)	Acc@1 99.609 (99.455)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1707 (0.1782)	Acc@1 99.609 (99.403)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.154 (0.154)	Data 0.294 (0.294)	Loss 0.1717 (0.1717)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.1688 (0.1776)	Acc@1 100.000 (99.495)	Acc@5 100.000 (99.994)
Epoch: [179][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1752 (0.1776)	Acc@1 99.219 (99.470)	Acc@5 100.000 (99.997)
Epoch: [179][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1712 (0.1773)	Acc@1 99.609 (99.460)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.5561216
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.173 (0.173)	Data 0.284 (0.284)	Loss 0.1784 (0.1784)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.117 (0.127)	Data 0.000 (0.005)	Loss 0.1756 (0.1770)	Acc@1 99.219 (99.393)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.1635 (0.1772)	Acc@1 100.000 (99.413)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.1962 (0.1771)	Acc@1 99.219 (99.401)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.5561216
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(7, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 30, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(7, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(19, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.6
Max memory: 88.6273536
 24.564s  Thres 0.01 4
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6620
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.177 (0.177)	Data 0.292 (0.292)	Loss 3.3466 (3.3466)	Acc@1 6.641 (6.641)	Acc@5 51.172 (51.172)
Epoch: [1][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 2.4225 (2.7117)	Acc@1 32.812 (23.642)	Acc@5 88.281 (76.905)
Epoch: [1][128/196]	Time 0.124 (0.132)	Data 0.000 (0.002)	Loss 2.1261 (2.5078)	Acc@1 46.484 (30.472)	Acc@5 94.141 (82.858)
Epoch: [1][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 2.0392 (2.3798)	Acc@1 44.922 (34.940)	Acc@5 94.531 (85.616)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.197 (0.197)	Data 0.288 (0.288)	Loss 1.9804 (1.9804)	Acc@1 47.656 (47.656)	Acc@5 96.094 (96.094)
Epoch: [2][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 1.8117 (1.9441)	Acc@1 55.078 (50.391)	Acc@5 95.312 (93.606)
Epoch: [2][128/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 1.6501 (1.8659)	Acc@1 60.547 (52.980)	Acc@5 95.312 (94.225)
Epoch: [2][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 1.5352 (1.8038)	Acc@1 62.109 (54.955)	Acc@5 97.266 (94.683)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.147 (0.147)	Data 0.298 (0.298)	Loss 1.5539 (1.5539)	Acc@1 63.281 (63.281)	Acc@5 98.438 (98.438)
Epoch: [3][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 1.5755 (1.5582)	Acc@1 65.625 (63.059)	Acc@5 95.703 (96.232)
Epoch: [3][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 1.4947 (1.5159)	Acc@1 63.281 (63.944)	Acc@5 95.703 (96.669)
Epoch: [3][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 1.5032 (1.4830)	Acc@1 65.234 (64.886)	Acc@5 96.875 (96.780)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.183 (0.183)	Data 0.292 (0.292)	Loss 1.3250 (1.3250)	Acc@1 68.359 (68.359)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 1.3701 (1.3440)	Acc@1 65.234 (68.828)	Acc@5 97.266 (97.650)
Epoch: [4][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 1.2799 (1.3210)	Acc@1 70.312 (69.522)	Acc@5 96.094 (97.699)
Epoch: [4][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.3338 (1.2852)	Acc@1 68.750 (70.555)	Acc@5 98.047 (97.808)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.189 (0.189)	Data 0.260 (0.260)	Loss 1.1327 (1.1327)	Acc@1 76.172 (76.172)	Acc@5 99.609 (99.609)
Epoch: [5][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 1.1320 (1.1723)	Acc@1 75.000 (73.498)	Acc@5 96.094 (98.143)
Epoch: [5][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 1.1985 (1.1570)	Acc@1 71.484 (73.940)	Acc@5 98.047 (98.186)
Epoch: [5][192/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.9496 (1.1362)	Acc@1 79.297 (74.421)	Acc@5 99.219 (98.288)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.05
Max memory: 103.3835008
 25.856s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1048
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.188 (0.188)	Data 0.288 (0.288)	Loss 0.9766 (0.9766)	Acc@1 78.516 (78.516)	Acc@5 99.609 (99.609)
Epoch: [6][64/196]	Time 0.129 (0.127)	Data 0.000 (0.005)	Loss 1.0504 (1.0382)	Acc@1 77.344 (77.416)	Acc@5 99.219 (98.630)
Epoch: [6][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 1.0251 (1.0345)	Acc@1 77.734 (77.102)	Acc@5 99.219 (98.649)
Epoch: [6][192/196]	Time 0.165 (0.128)	Data 0.000 (0.002)	Loss 0.9552 (1.0297)	Acc@1 80.859 (77.224)	Acc@5 98.047 (98.628)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.184 (0.184)	Data 0.263 (0.263)	Loss 1.0963 (1.0963)	Acc@1 77.344 (77.344)	Acc@5 99.219 (99.219)
Epoch: [7][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.9947 (0.9850)	Acc@1 75.781 (78.203)	Acc@5 98.438 (98.714)
Epoch: [7][128/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 1.0017 (0.9715)	Acc@1 78.125 (78.537)	Acc@5 99.219 (98.731)
Epoch: [7][192/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 1.0258 (0.9674)	Acc@1 76.562 (78.485)	Acc@5 100.000 (98.749)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.190 (0.190)	Data 0.272 (0.272)	Loss 0.9607 (0.9607)	Acc@1 75.781 (75.781)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.8015 (0.9171)	Acc@1 83.594 (79.898)	Acc@5 99.609 (98.948)
Epoch: [8][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.9942 (0.9200)	Acc@1 76.172 (79.627)	Acc@5 97.656 (98.895)
Epoch: [8][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8974 (0.9125)	Acc@1 83.594 (79.742)	Acc@5 98.828 (98.917)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.159 (0.159)	Data 0.287 (0.287)	Loss 0.8302 (0.8302)	Acc@1 81.250 (81.250)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 0.139 (0.129)	Data 0.000 (0.005)	Loss 0.8358 (0.8812)	Acc@1 82.031 (80.583)	Acc@5 99.219 (98.906)
Epoch: [9][128/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.8281 (0.8797)	Acc@1 82.422 (80.575)	Acc@5 98.828 (98.952)
Epoch: [9][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8836 (0.8770)	Acc@1 78.906 (80.568)	Acc@5 98.828 (98.970)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.188 (0.188)	Data 0.306 (0.306)	Loss 0.7782 (0.7782)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [10][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.8511 (0.8389)	Acc@1 81.641 (81.538)	Acc@5 99.219 (99.093)
Epoch: [10][128/196]	Time 0.131 (0.130)	Data 0.000 (0.003)	Loss 0.9086 (0.8527)	Acc@1 82.422 (81.114)	Acc@5 99.219 (99.031)
Epoch: [10][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8071 (0.8497)	Acc@1 80.859 (81.005)	Acc@5 100.000 (99.077)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.5
Max memory: 103.3833984
 25.849s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 572
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.213 (0.213)	Data 0.268 (0.268)	Loss 0.7454 (0.7454)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [11][64/196]	Time 0.128 (0.133)	Data 0.000 (0.004)	Loss 0.9595 (0.8266)	Acc@1 73.047 (81.731)	Acc@5 99.219 (98.996)
Epoch: [11][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.7884 (0.8199)	Acc@1 82.031 (81.995)	Acc@5 98.047 (99.019)
Epoch: [11][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.8153 (0.8239)	Acc@1 81.641 (81.780)	Acc@5 99.609 (99.081)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.161 (0.161)	Data 0.277 (0.277)	Loss 0.8757 (0.8757)	Acc@1 79.688 (79.688)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.136 (0.136)	Data 0.000 (0.004)	Loss 0.7801 (0.8091)	Acc@1 82.422 (82.422)	Acc@5 98.438 (99.105)
Epoch: [12][128/196]	Time 0.133 (0.136)	Data 0.000 (0.002)	Loss 0.8118 (0.8154)	Acc@1 82.031 (82.113)	Acc@5 99.609 (99.092)
Epoch: [12][192/196]	Time 0.133 (0.135)	Data 0.000 (0.002)	Loss 0.8427 (0.8141)	Acc@1 80.859 (82.189)	Acc@5 98.828 (99.085)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.166 (0.166)	Data 0.292 (0.292)	Loss 0.7882 (0.7882)	Acc@1 83.203 (83.203)	Acc@5 98.828 (98.828)
Epoch: [13][64/196]	Time 0.134 (0.134)	Data 0.000 (0.005)	Loss 0.8991 (0.8005)	Acc@1 77.734 (82.206)	Acc@5 98.828 (99.123)
Epoch: [13][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7807 (0.8054)	Acc@1 86.328 (82.264)	Acc@5 100.000 (99.131)
Epoch: [13][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7483 (0.8063)	Acc@1 83.984 (82.195)	Acc@5 99.219 (99.128)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.155 (0.155)	Data 0.302 (0.302)	Loss 0.9096 (0.9096)	Acc@1 77.344 (77.344)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.8192 (0.7937)	Acc@1 82.031 (82.506)	Acc@5 99.219 (99.189)
Epoch: [14][128/196]	Time 0.133 (0.132)	Data 0.000 (0.003)	Loss 0.7490 (0.7947)	Acc@1 86.328 (82.676)	Acc@5 98.438 (99.125)
Epoch: [14][192/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7240 (0.7966)	Acc@1 82.422 (82.624)	Acc@5 100.000 (99.138)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.157 (0.157)	Data 0.285 (0.285)	Loss 0.6550 (0.6550)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.8536 (0.7832)	Acc@1 82.031 (82.903)	Acc@5 98.438 (99.285)
Epoch: [15][128/196]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.9221 (0.7899)	Acc@1 80.078 (82.716)	Acc@5 98.828 (99.237)
Epoch: [15][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.9375 (0.7899)	Acc@1 77.734 (82.776)	Acc@5 98.438 (99.192)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  72.23
Max memory: 103.3833984
 26.505s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 774
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.2020864
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.191 (0.191)	Data 0.289 (0.289)	Loss 0.8192 (0.8192)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 0.7768 (0.7659)	Acc@1 82.812 (83.954)	Acc@5 98.828 (99.207)
Epoch: [16][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7921 (0.7741)	Acc@1 85.156 (83.657)	Acc@5 98.828 (99.216)
Epoch: [16][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6891 (0.7754)	Acc@1 85.547 (83.422)	Acc@5 99.219 (99.227)
Max memory in training epoch: 66.6450432
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.166 (0.166)	Data 0.296 (0.296)	Loss 0.7536 (0.7536)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [17][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.7386 (0.7819)	Acc@1 85.938 (83.305)	Acc@5 100.000 (99.225)
Epoch: [17][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.8003 (0.7808)	Acc@1 83.594 (83.330)	Acc@5 98.438 (99.179)
Epoch: [17][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8581 (0.7798)	Acc@1 80.469 (83.321)	Acc@5 97.656 (99.178)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.179 (0.179)	Data 0.263 (0.263)	Loss 0.7483 (0.7483)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [18][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.7128 (0.7643)	Acc@1 87.500 (83.510)	Acc@5 99.219 (99.195)
Epoch: [18][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7351 (0.7710)	Acc@1 85.938 (83.603)	Acc@5 99.219 (99.173)
Epoch: [18][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6678 (0.7745)	Acc@1 87.109 (83.484)	Acc@5 99.219 (99.223)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.166 (0.166)	Data 0.303 (0.303)	Loss 0.7258 (0.7258)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.7861 (0.7652)	Acc@1 83.594 (83.816)	Acc@5 98.438 (99.153)
Epoch: [19][128/196]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.8569 (0.7687)	Acc@1 80.469 (83.839)	Acc@5 98.828 (99.191)
Epoch: [19][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7406 (0.7674)	Acc@1 84.375 (83.873)	Acc@5 99.609 (99.201)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.168 (0.168)	Data 0.260 (0.260)	Loss 0.8135 (0.8135)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.7564 (0.7516)	Acc@1 87.109 (84.153)	Acc@5 99.219 (99.267)
Epoch: [20][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7371 (0.7596)	Acc@1 85.938 (84.024)	Acc@5 99.219 (99.279)
Epoch: [20][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7448 (0.7625)	Acc@1 83.984 (83.970)	Acc@5 98.828 (99.247)
Max memory in training epoch: 66.5401856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 481616 ; 486232 ; 0.990506589447013
[INFO] Storing checkpoint...
  74.37
Max memory: 103.3821696
 25.772s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7527
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2002432
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.204 (0.204)	Data 0.261 (0.261)	Loss 0.7564 (0.7564)	Acc@1 84.766 (84.766)	Acc@5 98.047 (98.047)
Epoch: [21][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.7922 (0.7397)	Acc@1 82.031 (84.772)	Acc@5 99.219 (99.141)
Epoch: [21][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.8568 (0.7539)	Acc@1 80.859 (84.263)	Acc@5 99.219 (99.225)
Epoch: [21][192/196]	Time 0.141 (0.129)	Data 0.000 (0.002)	Loss 0.8406 (0.7565)	Acc@1 83.594 (84.201)	Acc@5 98.828 (99.225)
Max memory in training epoch: 66.6376704
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.174 (0.174)	Data 0.273 (0.273)	Loss 0.7148 (0.7148)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.7535 (0.7401)	Acc@1 85.156 (84.627)	Acc@5 98.828 (99.393)
Epoch: [22][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7593 (0.7500)	Acc@1 85.156 (84.302)	Acc@5 98.828 (99.373)
Epoch: [22][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7765 (0.7546)	Acc@1 82.031 (84.169)	Acc@5 100.000 (99.304)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.189 (0.189)	Data 0.296 (0.296)	Loss 0.6821 (0.6821)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.136 (0.134)	Data 0.000 (0.005)	Loss 0.7006 (0.7515)	Acc@1 87.891 (84.363)	Acc@5 99.609 (99.375)
Epoch: [23][128/196]	Time 0.132 (0.135)	Data 0.000 (0.002)	Loss 0.7846 (0.7495)	Acc@1 83.984 (84.469)	Acc@5 99.219 (99.346)
Epoch: [23][192/196]	Time 0.126 (0.134)	Data 0.000 (0.002)	Loss 0.7522 (0.7509)	Acc@1 83.203 (84.341)	Acc@5 99.609 (99.330)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.186 (0.186)	Data 0.266 (0.266)	Loss 0.5781 (0.5781)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [24][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.7154 (0.7323)	Acc@1 86.719 (85.072)	Acc@5 99.609 (99.441)
Epoch: [24][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7268 (0.7386)	Acc@1 86.328 (84.796)	Acc@5 100.000 (99.410)
Epoch: [24][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6387 (0.7426)	Acc@1 86.719 (84.691)	Acc@5 100.000 (99.391)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.150 (0.150)	Data 0.261 (0.261)	Loss 0.6607 (0.6607)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.121 (0.129)	Data 0.000 (0.004)	Loss 0.5998 (0.7255)	Acc@1 91.016 (84.958)	Acc@5 99.609 (99.399)
Epoch: [25][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7025 (0.7302)	Acc@1 86.719 (84.953)	Acc@5 100.000 (99.410)
Epoch: [25][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7480 (0.7341)	Acc@1 82.812 (84.798)	Acc@5 98.828 (99.397)
Max memory in training epoch: 66.5328128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 458236 ; 481616 ; 0.9514551011594299
[INFO] Storing checkpoint...
  76.2
Max memory: 103.37664
 25.643s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2897
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1909248
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.192 (0.192)	Data 0.289 (0.289)	Loss 0.7725 (0.7725)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.135 (0.130)	Data 0.000 (0.005)	Loss 0.7172 (0.7126)	Acc@1 84.766 (85.475)	Acc@5 99.219 (99.381)
Epoch: [26][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7357 (0.7251)	Acc@1 85.547 (85.099)	Acc@5 99.609 (99.370)
Epoch: [26][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7747 (0.7295)	Acc@1 83.594 (84.828)	Acc@5 98.047 (99.373)
Max memory in training epoch: 65.7746432
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.186 (0.186)	Data 0.269 (0.269)	Loss 0.7661 (0.7661)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.6512 (0.7237)	Acc@1 86.328 (85.210)	Acc@5 99.609 (99.453)
Epoch: [27][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8288 (0.7351)	Acc@1 81.641 (84.902)	Acc@5 98.047 (99.364)
Epoch: [27][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7477 (0.7403)	Acc@1 84.766 (84.830)	Acc@5 99.219 (99.322)
Max memory in training epoch: 65.8663936
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.186 (0.186)	Data 0.290 (0.290)	Loss 0.6476 (0.6476)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.7483 (0.7388)	Acc@1 86.719 (84.706)	Acc@5 98.828 (99.441)
Epoch: [28][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7384 (0.7286)	Acc@1 85.156 (85.096)	Acc@5 99.219 (99.382)
Epoch: [28][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7261 (0.7325)	Acc@1 84.375 (84.962)	Acc@5 98.828 (99.346)
Max memory in training epoch: 65.8663936
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.187 (0.187)	Data 0.297 (0.297)	Loss 0.7636 (0.7636)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.133 (0.137)	Data 0.000 (0.005)	Loss 0.6832 (0.7334)	Acc@1 84.766 (84.778)	Acc@5 99.609 (99.297)
Epoch: [29][128/196]	Time 0.127 (0.134)	Data 0.000 (0.003)	Loss 0.6692 (0.7312)	Acc@1 85.547 (84.881)	Acc@5 99.609 (99.307)
Epoch: [29][192/196]	Time 0.135 (0.133)	Data 0.000 (0.002)	Loss 0.7326 (0.7295)	Acc@1 83.984 (84.986)	Acc@5 99.219 (99.304)
Max memory in training epoch: 65.8663936
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.163 (0.163)	Data 0.306 (0.306)	Loss 0.8249 (0.8249)	Acc@1 80.078 (80.078)	Acc@5 98.438 (98.438)
Epoch: [30][64/196]	Time 0.139 (0.129)	Data 0.000 (0.005)	Loss 0.6898 (0.7047)	Acc@1 85.938 (85.913)	Acc@5 99.609 (99.411)
Epoch: [30][128/196]	Time 0.132 (0.129)	Data 0.000 (0.003)	Loss 0.7209 (0.7202)	Acc@1 84.375 (85.435)	Acc@5 98.438 (99.403)
Epoch: [30][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7892 (0.7222)	Acc@1 81.641 (85.310)	Acc@5 98.047 (99.391)
Max memory in training epoch: 65.8663936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 440912 ; 458236 ; 0.9621941532310861
[INFO] Storing checkpoint...
  77.94
Max memory: 102.1194752
 25.679s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2358
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1841664
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.197 (0.197)	Data 0.281 (0.281)	Loss 0.6652 (0.6652)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [31][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7842 (0.7037)	Acc@1 84.375 (85.715)	Acc@5 98.438 (99.543)
Epoch: [31][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6977 (0.7136)	Acc@1 84.766 (85.347)	Acc@5 100.000 (99.437)
Epoch: [31][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7517 (0.7162)	Acc@1 84.375 (85.383)	Acc@5 99.219 (99.409)
Max memory in training epoch: 64.790784
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.188 (0.188)	Data 0.284 (0.284)	Loss 0.6761 (0.6761)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.127 (0.133)	Data 0.000 (0.005)	Loss 0.7693 (0.7302)	Acc@1 83.984 (85.078)	Acc@5 99.609 (99.315)
Epoch: [32][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7818 (0.7289)	Acc@1 83.203 (85.068)	Acc@5 99.609 (99.410)
Epoch: [32][192/196]	Time 0.141 (0.131)	Data 0.000 (0.002)	Loss 0.6737 (0.7243)	Acc@1 85.547 (85.298)	Acc@5 100.000 (99.407)
Max memory in training epoch: 64.7121408
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.188 (0.188)	Data 0.267 (0.267)	Loss 0.7794 (0.7794)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [33][64/196]	Time 0.138 (0.130)	Data 0.000 (0.004)	Loss 0.8370 (0.7099)	Acc@1 82.812 (85.571)	Acc@5 99.219 (99.369)
Epoch: [33][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6265 (0.7121)	Acc@1 88.281 (85.453)	Acc@5 100.000 (99.355)
Epoch: [33][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7212 (0.7185)	Acc@1 84.766 (85.320)	Acc@5 99.219 (99.346)
Max memory in training epoch: 64.7121408
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.159 (0.159)	Data 0.290 (0.290)	Loss 0.7860 (0.7860)	Acc@1 83.984 (83.984)	Acc@5 98.047 (98.047)
Epoch: [34][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.6348 (0.7116)	Acc@1 86.719 (85.433)	Acc@5 99.609 (99.447)
Epoch: [34][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.6701 (0.7134)	Acc@1 86.328 (85.426)	Acc@5 99.609 (99.397)
Epoch: [34][192/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.6591 (0.7158)	Acc@1 86.328 (85.336)	Acc@5 100.000 (99.385)
Max memory in training epoch: 64.7121408
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.179 (0.179)	Data 0.266 (0.266)	Loss 0.7572 (0.7572)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.135 (0.132)	Data 0.000 (0.004)	Loss 0.6481 (0.7124)	Acc@1 86.719 (85.361)	Acc@5 100.000 (99.363)
Epoch: [35][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7609 (0.7122)	Acc@1 85.156 (85.580)	Acc@5 99.219 (99.367)
Epoch: [35][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7058 (0.7213)	Acc@1 85.156 (85.342)	Acc@5 99.609 (99.354)
Max memory in training epoch: 64.7121408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 420124 ; 440912 ; 0.9528522698406938
[INFO] Storing checkpoint...
  76.69
Max memory: 100.5496832
 26.010s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3713
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.175872
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.181 (0.181)	Data 0.293 (0.293)	Loss 0.6010 (0.6010)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [36][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.6985 (0.6894)	Acc@1 85.547 (86.436)	Acc@5 100.000 (99.489)
Epoch: [36][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7488 (0.6972)	Acc@1 82.812 (86.059)	Acc@5 100.000 (99.443)
Epoch: [36][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7583 (0.7058)	Acc@1 82.031 (85.741)	Acc@5 98.438 (99.387)
Max memory in training epoch: 63.4993152
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.168 (0.168)	Data 0.264 (0.264)	Loss 0.5692 (0.5692)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6947 (0.7034)	Acc@1 86.719 (85.805)	Acc@5 99.609 (99.465)
Epoch: [37][128/196]	Time 0.145 (0.130)	Data 0.000 (0.002)	Loss 0.7221 (0.7050)	Acc@1 85.938 (85.928)	Acc@5 100.000 (99.410)
Epoch: [37][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7587 (0.7082)	Acc@1 85.156 (85.806)	Acc@5 98.828 (99.371)
Max memory in training epoch: 63.7417984
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.193 (0.193)	Data 0.306 (0.306)	Loss 0.6741 (0.6741)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.140 (0.131)	Data 0.000 (0.005)	Loss 0.7053 (0.7076)	Acc@1 87.109 (85.679)	Acc@5 98.438 (99.441)
Epoch: [38][128/196]	Time 0.124 (0.131)	Data 0.000 (0.003)	Loss 0.6290 (0.7097)	Acc@1 88.672 (85.662)	Acc@5 99.609 (99.388)
Epoch: [38][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6695 (0.7121)	Acc@1 86.719 (85.626)	Acc@5 100.000 (99.417)
Max memory in training epoch: 63.7417984
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.156 (0.156)	Data 0.261 (0.261)	Loss 0.7800 (0.7800)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.7202 (0.7154)	Acc@1 87.500 (85.595)	Acc@5 99.609 (99.339)
Epoch: [39][128/196]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.6840 (0.7124)	Acc@1 88.672 (85.656)	Acc@5 99.219 (99.394)
Epoch: [39][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.6984 (0.7091)	Acc@1 84.766 (85.842)	Acc@5 99.219 (99.415)
Max memory in training epoch: 63.7417984
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.180 (0.180)	Data 0.277 (0.277)	Loss 0.7285 (0.7285)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.130 (0.134)	Data 0.000 (0.004)	Loss 0.6618 (0.6847)	Acc@1 87.891 (86.575)	Acc@5 99.609 (99.519)
Epoch: [40][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7088 (0.6943)	Acc@1 86.328 (86.213)	Acc@5 98.828 (99.443)
Epoch: [40][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7090 (0.7017)	Acc@1 87.109 (85.931)	Acc@5 98.438 (99.421)
Max memory in training epoch: 63.7417984
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 410598 ; 420124 ; 0.9773257419238129
[INFO] Storing checkpoint...
  81.02
Max memory: 99.1092224
 26.362s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2422
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1720832
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.193 (0.193)	Data 0.290 (0.290)	Loss 0.7084 (0.7084)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [41][64/196]	Time 0.135 (0.132)	Data 0.000 (0.005)	Loss 0.7256 (0.6800)	Acc@1 83.984 (86.376)	Acc@5 100.000 (99.501)
Epoch: [41][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7005 (0.6971)	Acc@1 84.766 (85.941)	Acc@5 100.000 (99.467)
Epoch: [41][192/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.6682 (0.7002)	Acc@1 87.500 (85.877)	Acc@5 99.609 (99.441)
Max memory in training epoch: 63.3793024
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.182 (0.182)	Data 0.257 (0.257)	Loss 0.6814 (0.6814)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6923 (0.7016)	Acc@1 86.328 (86.034)	Acc@5 99.609 (99.375)
Epoch: [42][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6698 (0.7017)	Acc@1 89.062 (85.922)	Acc@5 98.438 (99.446)
Epoch: [42][192/196]	Time 0.131 (0.130)	Data 0.000 (0.001)	Loss 0.6738 (0.6992)	Acc@1 86.328 (85.942)	Acc@5 99.609 (99.458)
Max memory in training epoch: 63.549696
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.182 (0.182)	Data 0.274 (0.274)	Loss 0.6763 (0.6763)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.124 (0.130)	Data 0.000 (0.004)	Loss 0.6123 (0.6906)	Acc@1 87.500 (86.034)	Acc@5 99.609 (99.597)
Epoch: [43][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6175 (0.7037)	Acc@1 89.062 (85.644)	Acc@5 99.609 (99.461)
Epoch: [43][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7326 (0.6997)	Acc@1 85.938 (85.877)	Acc@5 99.609 (99.433)
Max memory in training epoch: 63.549696
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 0.6000 (0.6000)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [44][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.7055 (0.7113)	Acc@1 85.547 (85.583)	Acc@5 99.609 (99.291)
Epoch: [44][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7178 (0.7116)	Acc@1 83.984 (85.520)	Acc@5 99.609 (99.340)
Epoch: [44][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7381 (0.7114)	Acc@1 85.547 (85.517)	Acc@5 99.219 (99.354)
Max memory in training epoch: 63.549696
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.185 (0.185)	Data 0.300 (0.300)	Loss 0.6126 (0.6126)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.8211 (0.7016)	Acc@1 80.859 (85.805)	Acc@5 99.219 (99.381)
Epoch: [45][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.7428 (0.6959)	Acc@1 85.547 (86.040)	Acc@5 98.828 (99.394)
Epoch: [45][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6111 (0.6941)	Acc@1 87.500 (86.103)	Acc@5 99.609 (99.417)
Max memory in training epoch: 63.549696
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 399920 ; 410598 ; 0.9739940282222515
[INFO] Storing checkpoint...
  82.35
Max memory: 98.2802944
 26.212s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6081
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1678848
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.185 (0.185)	Data 0.264 (0.264)	Loss 0.6863 (0.6863)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.7440 (0.6627)	Acc@1 84.766 (86.839)	Acc@5 99.219 (99.555)
Epoch: [46][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7258 (0.6809)	Acc@1 87.500 (86.425)	Acc@5 99.219 (99.446)
Epoch: [46][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7884 (0.6952)	Acc@1 80.078 (86.010)	Acc@5 100.000 (99.443)
Max memory in training epoch: 62.971648
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.182 (0.182)	Data 0.277 (0.277)	Loss 0.7877 (0.7877)	Acc@1 81.641 (81.641)	Acc@5 98.828 (98.828)
Epoch: [47][64/196]	Time 0.122 (0.130)	Data 0.000 (0.004)	Loss 0.7350 (0.6892)	Acc@1 83.203 (86.136)	Acc@5 99.219 (99.495)
Epoch: [47][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6624 (0.6872)	Acc@1 86.328 (86.180)	Acc@5 100.000 (99.428)
Epoch: [47][192/196]	Time 0.136 (0.128)	Data 0.000 (0.002)	Loss 0.6739 (0.6869)	Acc@1 86.328 (86.229)	Acc@5 98.438 (99.397)
Max memory in training epoch: 63.4542592
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.169 (0.169)	Data 0.331 (0.331)	Loss 0.6375 (0.6375)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 0.7732 (0.7016)	Acc@1 87.109 (85.721)	Acc@5 98.047 (99.471)
Epoch: [48][128/196]	Time 0.131 (0.128)	Data 0.000 (0.003)	Loss 0.6296 (0.7045)	Acc@1 86.719 (85.692)	Acc@5 100.000 (99.425)
Epoch: [48][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6778 (0.7044)	Acc@1 85.938 (85.652)	Acc@5 100.000 (99.429)
Max memory in training epoch: 63.441152
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.167 (0.167)	Data 0.327 (0.327)	Loss 0.6128 (0.6128)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.6427 (0.6805)	Acc@1 88.281 (86.647)	Acc@5 99.609 (99.567)
Epoch: [49][128/196]	Time 0.128 (0.128)	Data 0.000 (0.003)	Loss 0.7649 (0.6843)	Acc@1 83.984 (86.622)	Acc@5 99.609 (99.494)
Epoch: [49][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7770 (0.6877)	Acc@1 83.984 (86.403)	Acc@5 98.047 (99.476)
Max memory in training epoch: 63.441152
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.156 (0.156)	Data 0.291 (0.291)	Loss 0.6394 (0.6394)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 0.145 (0.127)	Data 0.000 (0.005)	Loss 0.7216 (0.6839)	Acc@1 84.375 (86.220)	Acc@5 99.609 (99.471)
Epoch: [50][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6520 (0.6936)	Acc@1 88.672 (86.001)	Acc@5 99.219 (99.391)
Epoch: [50][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6204 (0.6963)	Acc@1 88.281 (85.923)	Acc@5 98.828 (99.417)
Max memory in training epoch: 63.441152
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 387220 ; 399920 ; 0.968243648729746
[INFO] Storing checkpoint...
  78.46
Max memory: 97.8540032
 25.544s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2006
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1627648
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.173 (0.173)	Data 0.266 (0.266)	Loss 0.6493 (0.6493)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.121 (0.128)	Data 0.000 (0.004)	Loss 0.6104 (0.6534)	Acc@1 89.453 (87.350)	Acc@5 99.609 (99.555)
Epoch: [51][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6380 (0.6667)	Acc@1 89.453 (86.864)	Acc@5 99.609 (99.525)
Epoch: [51][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6974 (0.6868)	Acc@1 85.938 (86.132)	Acc@5 99.219 (99.494)
Max memory in training epoch: 62.6080256
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.172 (0.172)	Data 0.295 (0.295)	Loss 0.6640 (0.6640)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.8047 (0.6960)	Acc@1 82.422 (85.793)	Acc@5 98.828 (99.333)
Epoch: [52][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6650 (0.6850)	Acc@1 86.328 (86.195)	Acc@5 99.609 (99.428)
Epoch: [52][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7555 (0.6907)	Acc@1 83.594 (86.170)	Acc@5 99.609 (99.417)
Max memory in training epoch: 62.7522048
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.168 (0.168)	Data 0.309 (0.309)	Loss 0.6943 (0.6943)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [53][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.6972 (0.6901)	Acc@1 84.375 (86.160)	Acc@5 98.828 (99.471)
Epoch: [53][128/196]	Time 0.120 (0.128)	Data 0.000 (0.003)	Loss 0.7534 (0.6950)	Acc@1 84.375 (86.043)	Acc@5 100.000 (99.431)
Epoch: [53][192/196]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.8130 (0.6953)	Acc@1 81.641 (85.988)	Acc@5 99.219 (99.441)
Max memory in training epoch: 62.7522048
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.153 (0.153)	Data 0.297 (0.297)	Loss 0.6696 (0.6696)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.7219 (0.6829)	Acc@1 83.594 (86.340)	Acc@5 100.000 (99.531)
Epoch: [54][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.6665 (0.6862)	Acc@1 86.719 (86.152)	Acc@5 99.219 (99.467)
Epoch: [54][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.8917 (0.6881)	Acc@1 79.688 (86.184)	Acc@5 98.828 (99.449)
Max memory in training epoch: 62.7522048
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.175 (0.175)	Data 0.265 (0.265)	Loss 0.6593 (0.6593)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.120 (0.128)	Data 0.000 (0.004)	Loss 0.6855 (0.6893)	Acc@1 84.375 (86.136)	Acc@5 100.000 (99.399)
Epoch: [55][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.6656 (0.6914)	Acc@1 87.109 (86.019)	Acc@5 99.609 (99.449)
Epoch: [55][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6288 (0.6913)	Acc@1 88.281 (86.041)	Acc@5 99.609 (99.437)
Max memory in training epoch: 62.7522048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 380516 ; 387220 ; 0.9826868446877743
[INFO] Storing checkpoint...
  82.0
Max memory: 97.538816
 25.354s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8695
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1595904
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.178 (0.178)	Data 0.354 (0.354)	Loss 0.5937 (0.5937)	Acc@1 91.797 (91.797)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.121 (0.121)	Data 0.000 (0.006)	Loss 0.7132 (0.6628)	Acc@1 85.938 (87.248)	Acc@5 100.000 (99.507)
Epoch: [56][128/196]	Time 0.123 (0.120)	Data 0.000 (0.003)	Loss 0.7085 (0.6716)	Acc@1 86.328 (86.897)	Acc@5 99.609 (99.482)
Epoch: [56][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.7293 (0.6781)	Acc@1 85.156 (86.624)	Acc@5 99.609 (99.441)
Max memory in training epoch: 60.3155968
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.148 (0.148)	Data 0.278 (0.278)	Loss 0.6866 (0.6866)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.6679 (0.6642)	Acc@1 85.938 (86.737)	Acc@5 100.000 (99.543)
Epoch: [57][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7654 (0.6747)	Acc@1 83.594 (86.601)	Acc@5 99.219 (99.509)
Epoch: [57][192/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.6773 (0.6815)	Acc@1 86.328 (86.381)	Acc@5 99.609 (99.488)
Max memory in training epoch: 60.5646336
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.170 (0.170)	Data 0.290 (0.290)	Loss 0.7020 (0.7020)	Acc@1 88.281 (88.281)	Acc@5 98.438 (98.438)
Epoch: [58][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.7742 (0.6960)	Acc@1 82.422 (86.016)	Acc@5 99.219 (99.435)
Epoch: [58][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.7055 (0.6818)	Acc@1 86.328 (86.416)	Acc@5 99.219 (99.425)
Epoch: [58][192/196]	Time 0.136 (0.121)	Data 0.000 (0.002)	Loss 0.7229 (0.6884)	Acc@1 87.891 (86.158)	Acc@5 98.828 (99.415)
Max memory in training epoch: 60.5646336
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.179 (0.179)	Data 0.257 (0.257)	Loss 0.6627 (0.6627)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.123 (0.121)	Data 0.000 (0.004)	Loss 0.7465 (0.6712)	Acc@1 83.594 (87.073)	Acc@5 99.609 (99.453)
Epoch: [59][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.6968 (0.6792)	Acc@1 83.984 (86.661)	Acc@5 99.609 (99.458)
Epoch: [59][192/196]	Time 0.122 (0.121)	Data 0.000 (0.001)	Loss 0.7358 (0.6813)	Acc@1 84.766 (86.510)	Acc@5 99.219 (99.464)
Max memory in training epoch: 60.5646336
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.146 (0.146)	Data 0.279 (0.279)	Loss 0.6972 (0.6972)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.6568 (0.6736)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.471)
Epoch: [60][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6870 (0.6835)	Acc@1 87.109 (86.401)	Acc@5 99.219 (99.482)
Epoch: [60][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6090 (0.6798)	Acc@1 88.672 (86.476)	Acc@5 99.609 (99.488)
Max memory in training epoch: 60.5646336
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 370126 ; 380516 ; 0.9726949720905297
[INFO] Storing checkpoint...
  79.0
Max memory: 93.4961664
 24.238s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3696
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1554944
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.185 (0.185)	Data 0.281 (0.281)	Loss 0.5485 (0.5485)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.7039 (0.6552)	Acc@1 83.984 (87.109)	Acc@5 99.219 (99.531)
Epoch: [61][128/196]	Time 0.116 (0.125)	Data 0.000 (0.002)	Loss 0.6673 (0.6780)	Acc@1 85.938 (86.380)	Acc@5 99.219 (99.500)
Epoch: [61][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.7432 (0.6750)	Acc@1 83.984 (86.516)	Acc@5 99.609 (99.557)
Max memory in training epoch: 60.0632832
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.144 (0.144)	Data 0.306 (0.306)	Loss 0.7397 (0.7397)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.6966 (0.6821)	Acc@1 88.281 (86.496)	Acc@5 99.219 (99.453)
Epoch: [62][128/196]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.6702 (0.6832)	Acc@1 87.500 (86.540)	Acc@5 99.219 (99.431)
Epoch: [62][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.7573 (0.6801)	Acc@1 85.938 (86.553)	Acc@5 99.219 (99.441)
Max memory in training epoch: 60.3844096
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.193 (0.193)	Data 0.263 (0.263)	Loss 0.6459 (0.6459)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.115 (0.122)	Data 0.000 (0.004)	Loss 0.6872 (0.6843)	Acc@1 86.328 (86.605)	Acc@5 100.000 (99.369)
Epoch: [63][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6721 (0.6815)	Acc@1 87.891 (86.531)	Acc@5 99.609 (99.388)
Epoch: [63][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.7355 (0.6804)	Acc@1 85.547 (86.488)	Acc@5 99.219 (99.393)
Max memory in training epoch: 60.3844096
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.6841 (0.6841)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [64][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.7251 (0.6727)	Acc@1 83.203 (86.845)	Acc@5 99.609 (99.471)
Epoch: [64][128/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.6990 (0.6769)	Acc@1 84.766 (86.586)	Acc@5 99.609 (99.491)
Epoch: [64][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.7352 (0.6776)	Acc@1 85.547 (86.573)	Acc@5 100.000 (99.482)
Max memory in training epoch: 60.3844096
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.173 (0.173)	Data 0.277 (0.277)	Loss 0.6835 (0.6835)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [65][64/196]	Time 0.120 (0.125)	Data 0.000 (0.004)	Loss 0.6876 (0.6700)	Acc@1 86.719 (86.550)	Acc@5 99.219 (99.501)
Epoch: [65][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.7624 (0.6751)	Acc@1 83.984 (86.498)	Acc@5 99.609 (99.443)
Epoch: [65][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.6625 (0.6781)	Acc@1 88.281 (86.413)	Acc@5 100.000 (99.441)
Max memory in training epoch: 60.3844096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 366664 ; 370126 ; 0.9906464285135332
[INFO] Storing checkpoint...
  79.88
Max memory: 93.1590656
 24.438s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4369
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1540608
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.192 (0.192)	Data 0.266 (0.266)	Loss 0.7314 (0.7314)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.6142 (0.6513)	Acc@1 86.719 (87.242)	Acc@5 100.000 (99.633)
Epoch: [66][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6173 (0.6641)	Acc@1 89.844 (86.919)	Acc@5 99.219 (99.576)
Epoch: [66][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7085 (0.6677)	Acc@1 86.719 (86.747)	Acc@5 98.828 (99.534)
Max memory in training epoch: 59.939584
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.174 (0.174)	Data 0.266 (0.266)	Loss 0.6223 (0.6223)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.5889 (0.6572)	Acc@1 89.844 (87.181)	Acc@5 100.000 (99.453)
Epoch: [67][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7449 (0.6653)	Acc@1 84.766 (87.003)	Acc@5 100.000 (99.461)
Epoch: [67][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.7232 (0.6735)	Acc@1 84.375 (86.644)	Acc@5 99.609 (99.435)
Max memory in training epoch: 60.201728
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.144 (0.144)	Data 0.287 (0.287)	Loss 0.7065 (0.7065)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.6592 (0.6821)	Acc@1 86.328 (86.238)	Acc@5 99.609 (99.441)
Epoch: [68][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6800 (0.6693)	Acc@1 87.109 (86.746)	Acc@5 100.000 (99.452)
Epoch: [68][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.6370 (0.6763)	Acc@1 86.719 (86.500)	Acc@5 99.609 (99.439)
Max memory in training epoch: 60.201728
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.171 (0.171)	Data 0.280 (0.280)	Loss 0.6692 (0.6692)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.6118 (0.6680)	Acc@1 88.281 (86.701)	Acc@5 99.219 (99.501)
Epoch: [69][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.6358 (0.6668)	Acc@1 87.500 (86.731)	Acc@5 99.609 (99.491)
Epoch: [69][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6780 (0.6675)	Acc@1 88.672 (86.763)	Acc@5 99.219 (99.488)
Max memory in training epoch: 60.201728
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.168 (0.168)	Data 0.305 (0.305)	Loss 0.6011 (0.6011)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [70][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.5978 (0.6690)	Acc@1 86.719 (86.599)	Acc@5 100.000 (99.501)
Epoch: [70][128/196]	Time 0.116 (0.122)	Data 0.000 (0.003)	Loss 0.7177 (0.6722)	Acc@1 83.984 (86.598)	Acc@5 99.609 (99.464)
Epoch: [70][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6438 (0.6726)	Acc@1 86.328 (86.638)	Acc@5 99.219 (99.441)
Max memory in training epoch: 60.201728
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 359734 ; 366664 ; 0.9810998625444549
[INFO] Storing checkpoint...
  79.83
Max memory: 93.1138048
 24.289s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5652
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.151296
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.195 (0.195)	Data 0.277 (0.277)	Loss 0.5550 (0.5550)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.7478 (0.6487)	Acc@1 84.766 (87.278)	Acc@5 98.438 (99.573)
Epoch: [71][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.5532 (0.6609)	Acc@1 91.797 (86.937)	Acc@5 99.609 (99.516)
Epoch: [71][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.7480 (0.6620)	Acc@1 83.203 (86.933)	Acc@5 99.609 (99.508)
Max memory in training epoch: 59.1486464
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.151 (0.151)	Data 0.273 (0.273)	Loss 0.6425 (0.6425)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.6585 (0.6758)	Acc@1 85.938 (86.406)	Acc@5 99.219 (99.393)
Epoch: [72][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6942 (0.6758)	Acc@1 84.375 (86.377)	Acc@5 98.828 (99.422)
Epoch: [72][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6673 (0.6754)	Acc@1 87.500 (86.468)	Acc@5 99.609 (99.431)
Max memory in training epoch: 59.613952
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.169 (0.169)	Data 0.267 (0.267)	Loss 0.5694 (0.5694)	Acc@1 91.016 (91.016)	Acc@5 98.828 (98.828)
Epoch: [73][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.6137 (0.6657)	Acc@1 87.109 (86.881)	Acc@5 99.219 (99.513)
Epoch: [73][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.5931 (0.6651)	Acc@1 89.062 (86.876)	Acc@5 99.609 (99.491)
Epoch: [73][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.7583 (0.6676)	Acc@1 83.984 (86.796)	Acc@5 99.219 (99.462)
Max memory in training epoch: 59.613952
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.166 (0.166)	Data 0.286 (0.286)	Loss 0.6021 (0.6021)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.6700 (0.6742)	Acc@1 84.375 (86.424)	Acc@5 100.000 (99.489)
Epoch: [74][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7554 (0.6752)	Acc@1 85.156 (86.358)	Acc@5 99.219 (99.452)
Epoch: [74][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6581 (0.6792)	Acc@1 87.109 (86.294)	Acc@5 99.219 (99.456)
Max memory in training epoch: 59.613952
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.164 (0.164)	Data 0.265 (0.265)	Loss 0.6265 (0.6265)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [75][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.6441 (0.6708)	Acc@1 87.109 (86.520)	Acc@5 99.609 (99.489)
Epoch: [75][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6757 (0.6701)	Acc@1 84.375 (86.567)	Acc@5 100.000 (99.467)
Epoch: [75][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6680 (0.6729)	Acc@1 86.719 (86.450)	Acc@5 98.438 (99.435)
Max memory in training epoch: 59.613952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353672 ; 359734 ; 0.9831486598431063
[INFO] Storing checkpoint...
  78.96
Max memory: 92.1683456
 24.140s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3971
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1488384
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.184 (0.184)	Data 0.259 (0.259)	Loss 0.7168 (0.7168)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [76][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.6471 (0.6421)	Acc@1 85.547 (87.428)	Acc@5 100.000 (99.543)
Epoch: [76][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.6712 (0.6539)	Acc@1 85.156 (87.055)	Acc@5 99.219 (99.516)
Epoch: [76][192/196]	Time 0.122 (0.121)	Data 0.000 (0.001)	Loss 0.5814 (0.6634)	Acc@1 91.016 (86.860)	Acc@5 99.219 (99.480)
Max memory in training epoch: 58.6341888
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.176 (0.176)	Data 0.266 (0.266)	Loss 0.6110 (0.6110)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.134 (0.122)	Data 0.000 (0.004)	Loss 0.5869 (0.6523)	Acc@1 89.062 (87.212)	Acc@5 100.000 (99.585)
Epoch: [77][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.7026 (0.6575)	Acc@1 85.938 (87.025)	Acc@5 99.219 (99.540)
Epoch: [77][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.6878 (0.6682)	Acc@1 85.938 (86.652)	Acc@5 99.609 (99.522)
Max memory in training epoch: 59.0274048
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.160 (0.160)	Data 0.309 (0.309)	Loss 0.6441 (0.6441)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.6125 (0.6569)	Acc@1 90.234 (87.169)	Acc@5 100.000 (99.525)
Epoch: [78][128/196]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.7040 (0.6671)	Acc@1 83.203 (86.731)	Acc@5 99.219 (99.525)
Epoch: [78][192/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.6194 (0.6687)	Acc@1 87.109 (86.703)	Acc@5 99.219 (99.480)
Max memory in training epoch: 59.0274048
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.168 (0.168)	Data 0.313 (0.313)	Loss 0.6087 (0.6087)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.6667 (0.6657)	Acc@1 87.109 (86.689)	Acc@5 99.219 (99.549)
Epoch: [79][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.6671 (0.6653)	Acc@1 84.375 (86.589)	Acc@5 99.609 (99.522)
Epoch: [79][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.6029 (0.6683)	Acc@1 87.891 (86.553)	Acc@5 99.219 (99.480)
Max memory in training epoch: 59.0274048
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.176 (0.176)	Data 0.276 (0.276)	Loss 0.6467 (0.6467)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.122 (0.122)	Data 0.000 (0.004)	Loss 0.7154 (0.6509)	Acc@1 83.594 (87.290)	Acc@5 99.609 (99.519)
Epoch: [80][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6621 (0.6616)	Acc@1 87.500 (86.864)	Acc@5 99.609 (99.491)
Epoch: [80][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.5811 (0.6673)	Acc@1 87.891 (86.670)	Acc@5 99.609 (99.494)
Max memory in training epoch: 59.0274048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 350786 ; 353672 ; 0.9918398968535819
[INFO] Storing checkpoint...
  78.77
Max memory: 91.4355712
 24.093s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 344
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.147712
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.194 (0.194)	Data 0.257 (0.257)	Loss 0.6790 (0.6790)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.6680 (0.6352)	Acc@1 86.328 (87.662)	Acc@5 98.828 (99.531)
Epoch: [81][128/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.7673 (0.6583)	Acc@1 83.984 (86.843)	Acc@5 98.828 (99.467)
Epoch: [81][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.5826 (0.6589)	Acc@1 89.062 (86.903)	Acc@5 99.609 (99.494)
Max memory in training epoch: 58.616576
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.171 (0.171)	Data 0.309 (0.309)	Loss 0.7841 (0.7841)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [82][64/196]	Time 0.120 (0.126)	Data 0.000 (0.005)	Loss 0.6804 (0.6731)	Acc@1 86.719 (86.322)	Acc@5 99.609 (99.507)
Epoch: [82][128/196]	Time 0.137 (0.123)	Data 0.000 (0.003)	Loss 0.6239 (0.6756)	Acc@1 88.672 (86.313)	Acc@5 99.609 (99.500)
Epoch: [82][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.5843 (0.6737)	Acc@1 90.625 (86.433)	Acc@5 99.609 (99.478)
Max memory in training epoch: 58.7607552
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.161 (0.161)	Data 0.292 (0.292)	Loss 0.5299 (0.5299)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.126 (0.122)	Data 0.000 (0.005)	Loss 0.6237 (0.6563)	Acc@1 86.719 (87.139)	Acc@5 100.000 (99.573)
Epoch: [83][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6964 (0.6684)	Acc@1 87.109 (86.701)	Acc@5 98.828 (99.546)
Epoch: [83][192/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.6691 (0.6655)	Acc@1 86.328 (86.737)	Acc@5 100.000 (99.530)
Max memory in training epoch: 58.7607552
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.150 (0.150)	Data 0.278 (0.278)	Loss 0.5400 (0.5400)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [84][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.6790 (0.6663)	Acc@1 84.766 (86.767)	Acc@5 100.000 (99.567)
Epoch: [84][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.5876 (0.6588)	Acc@1 90.625 (86.988)	Acc@5 99.609 (99.570)
Epoch: [84][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6020 (0.6641)	Acc@1 89.453 (86.771)	Acc@5 99.609 (99.528)
Max memory in training epoch: 58.7607552
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.143 (0.143)	Data 0.304 (0.304)	Loss 0.5900 (0.5900)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.113 (0.122)	Data 0.000 (0.005)	Loss 0.6435 (0.6617)	Acc@1 85.938 (86.989)	Acc@5 99.609 (99.537)
Epoch: [85][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.6656 (0.6582)	Acc@1 86.719 (87.037)	Acc@5 99.219 (99.482)
Epoch: [85][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.7987 (0.6658)	Acc@1 82.031 (86.699)	Acc@5 99.219 (99.470)
Max memory in training epoch: 58.7607552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 349054 ; 350786 ; 0.9950625167481029
[INFO] Storing checkpoint...
  70.46
Max memory: 91.4248192
 23.975s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9012
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1470976
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.178 (0.178)	Data 0.263 (0.263)	Loss 0.6218 (0.6218)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [86][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.6547 (0.6430)	Acc@1 87.891 (87.422)	Acc@5 100.000 (99.441)
Epoch: [86][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.6115 (0.6551)	Acc@1 88.672 (87.109)	Acc@5 99.609 (99.416)
Epoch: [86][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.7741 (0.6616)	Acc@1 82.422 (86.891)	Acc@5 98.828 (99.437)
Max memory in training epoch: 58.4961536
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.159 (0.159)	Data 0.277 (0.277)	Loss 0.7349 (0.7349)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.5913 (0.6515)	Acc@1 89.062 (87.121)	Acc@5 99.609 (99.543)
Epoch: [87][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.8121 (0.6576)	Acc@1 83.594 (86.973)	Acc@5 100.000 (99.485)
Epoch: [87][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.7028 (0.6610)	Acc@1 85.547 (86.822)	Acc@5 99.219 (99.492)
Max memory in training epoch: 58.7582976
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.171 (0.171)	Data 0.299 (0.299)	Loss 0.6041 (0.6041)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.110 (0.119)	Data 0.000 (0.005)	Loss 0.6796 (0.6627)	Acc@1 85.156 (86.569)	Acc@5 99.219 (99.477)
Epoch: [88][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.7212 (0.6677)	Acc@1 85.938 (86.682)	Acc@5 98.828 (99.488)
Epoch: [88][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6545 (0.6625)	Acc@1 88.281 (86.832)	Acc@5 99.609 (99.516)
Max memory in training epoch: 58.7582976
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.167 (0.167)	Data 0.294 (0.294)	Loss 0.6961 (0.6961)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [89][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.8125 (0.6524)	Acc@1 81.641 (87.163)	Acc@5 99.219 (99.537)
Epoch: [89][128/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.6129 (0.6584)	Acc@1 86.328 (86.867)	Acc@5 100.000 (99.528)
Epoch: [89][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.6728 (0.6654)	Acc@1 87.500 (86.694)	Acc@5 99.219 (99.486)
Max memory in training epoch: 58.7582976
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.167 (0.167)	Data 0.289 (0.289)	Loss 0.7075 (0.7075)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.6402 (0.6528)	Acc@1 88.281 (87.091)	Acc@5 99.609 (99.411)
Epoch: [90][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6565 (0.6536)	Acc@1 86.719 (87.100)	Acc@5 99.609 (99.449)
Epoch: [90][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6089 (0.6609)	Acc@1 88.672 (86.887)	Acc@5 99.609 (99.462)
Max memory in training epoch: 58.7582976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 347898 ; 349054 ; 0.996688191511915
[INFO] Storing checkpoint...
  76.45
Max memory: 91.460864
 24.024s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3330
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.146688
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.201 (0.201)	Data 0.269 (0.269)	Loss 0.7110 (0.7110)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.124 (0.126)	Data 0.000 (0.004)	Loss 0.6463 (0.6233)	Acc@1 88.281 (88.053)	Acc@5 99.219 (99.651)
Epoch: [91][128/196]	Time 0.129 (0.125)	Data 0.000 (0.002)	Loss 0.6838 (0.6351)	Acc@1 84.766 (87.657)	Acc@5 100.000 (99.600)
Epoch: [91][192/196]	Time 0.115 (0.124)	Data 0.000 (0.002)	Loss 0.6746 (0.6468)	Acc@1 83.594 (87.215)	Acc@5 99.609 (99.571)
Max memory in training epoch: 58.4945152
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.172 (0.172)	Data 0.310 (0.310)	Loss 0.5989 (0.5989)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.7237 (0.6701)	Acc@1 86.328 (86.761)	Acc@5 98.438 (99.417)
Epoch: [92][128/196]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.7860 (0.6640)	Acc@1 82.812 (86.801)	Acc@5 99.219 (99.449)
Epoch: [92][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.5680 (0.6620)	Acc@1 90.234 (86.899)	Acc@5 99.609 (99.445)
Max memory in training epoch: 58.7042304
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.154 (0.154)	Data 0.308 (0.308)	Loss 0.6805 (0.6805)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [93][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.5736 (0.5667)	Acc@1 89.844 (90.186)	Acc@5 99.219 (99.712)
Epoch: [93][128/196]	Time 0.129 (0.123)	Data 0.000 (0.003)	Loss 0.4872 (0.5382)	Acc@1 92.188 (91.100)	Acc@5 99.219 (99.767)
Epoch: [93][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.4660 (0.5239)	Acc@1 92.969 (91.590)	Acc@5 100.000 (99.767)
Max memory in training epoch: 58.7042304
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.162 (0.162)	Data 0.268 (0.268)	Loss 0.4346 (0.4346)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.5087 (0.4757)	Acc@1 91.797 (93.083)	Acc@5 99.609 (99.838)
Epoch: [94][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.4415 (0.4770)	Acc@1 92.969 (92.917)	Acc@5 100.000 (99.836)
Epoch: [94][192/196]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 0.4600 (0.4711)	Acc@1 94.141 (93.157)	Acc@5 100.000 (99.850)
Max memory in training epoch: 58.7042304
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.184 (0.184)	Data 0.288 (0.288)	Loss 0.4374 (0.4374)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.4251 (0.4453)	Acc@1 94.141 (93.912)	Acc@5 100.000 (99.916)
Epoch: [95][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.4530 (0.4463)	Acc@1 92.969 (93.904)	Acc@5 100.000 (99.891)
Epoch: [95][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.4657 (0.4475)	Acc@1 94.531 (93.837)	Acc@5 99.219 (99.885)
Max memory in training epoch: 58.7042304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 346166 ; 347898 ; 0.9950215292988175
[INFO] Storing checkpoint...
  91.05
Max memory: 91.3424896
 24.881s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5092
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1459712
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.202 (0.202)	Data 0.270 (0.270)	Loss 0.4137 (0.4137)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.3965 (0.4306)	Acc@1 94.531 (94.141)	Acc@5 100.000 (99.856)
Epoch: [96][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.4794 (0.4300)	Acc@1 91.406 (94.153)	Acc@5 100.000 (99.879)
Epoch: [96][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3551 (0.4308)	Acc@1 97.266 (94.082)	Acc@5 100.000 (99.879)
Max memory in training epoch: 58.340608
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.171 (0.171)	Data 0.303 (0.303)	Loss 0.3508 (0.3508)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.3669 (0.4113)	Acc@1 96.484 (94.790)	Acc@5 100.000 (99.940)
Epoch: [97][128/196]	Time 0.134 (0.121)	Data 0.000 (0.003)	Loss 0.4587 (0.4148)	Acc@1 92.578 (94.552)	Acc@5 99.609 (99.894)
Epoch: [97][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.5018 (0.4146)	Acc@1 94.922 (94.519)	Acc@5 98.828 (99.909)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.182 (0.182)	Data 0.275 (0.275)	Loss 0.3426 (0.3426)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.112 (0.121)	Data 0.000 (0.004)	Loss 0.3480 (0.3951)	Acc@1 96.094 (95.048)	Acc@5 100.000 (99.934)
Epoch: [98][128/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.3780 (0.4019)	Acc@1 96.094 (94.767)	Acc@5 100.000 (99.915)
Epoch: [98][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.4254 (0.4019)	Acc@1 92.969 (94.744)	Acc@5 100.000 (99.905)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.181 (0.181)	Data 0.280 (0.280)	Loss 0.3537 (0.3537)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.132 (0.121)	Data 0.000 (0.005)	Loss 0.3965 (0.3896)	Acc@1 93.359 (95.180)	Acc@5 100.000 (99.910)
Epoch: [99][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3504 (0.3905)	Acc@1 96.484 (95.052)	Acc@5 100.000 (99.930)
Epoch: [99][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3546 (0.3926)	Acc@1 96.484 (94.956)	Acc@5 100.000 (99.921)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.144 (0.144)	Data 0.293 (0.293)	Loss 0.3771 (0.3771)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [100][64/196]	Time 0.131 (0.123)	Data 0.000 (0.005)	Loss 0.3576 (0.3765)	Acc@1 96.484 (95.451)	Acc@5 100.000 (99.928)
Epoch: [100][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.3686 (0.3781)	Acc@1 95.312 (95.328)	Acc@5 100.000 (99.930)
Epoch: [100][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.3593 (0.3809)	Acc@1 95.703 (95.153)	Acc@5 100.000 (99.927)
Max memory in training epoch: 58.5965056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.2
Max memory: 90.7003392
 24.726s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6463
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1459712
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.221 (0.221)	Data 0.257 (0.257)	Loss 0.3110 (0.3110)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.3463 (0.3713)	Acc@1 95.703 (95.499)	Acc@5 100.000 (99.940)
Epoch: [101][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.3727 (0.3718)	Acc@1 94.141 (95.415)	Acc@5 100.000 (99.933)
Epoch: [101][192/196]	Time 0.124 (0.122)	Data 0.000 (0.001)	Loss 0.3329 (0.3696)	Acc@1 97.266 (95.466)	Acc@5 100.000 (99.937)
Max memory in training epoch: 58.340608
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.160 (0.160)	Data 0.296 (0.296)	Loss 0.3399 (0.3399)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.3912 (0.3642)	Acc@1 95.312 (95.541)	Acc@5 100.000 (99.910)
Epoch: [102][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3535 (0.3647)	Acc@1 96.094 (95.494)	Acc@5 100.000 (99.924)
Epoch: [102][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3348 (0.3651)	Acc@1 97.656 (95.497)	Acc@5 100.000 (99.931)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.169 (0.169)	Data 0.296 (0.296)	Loss 0.3591 (0.3591)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.3497 (0.3504)	Acc@1 96.484 (95.998)	Acc@5 100.000 (99.952)
Epoch: [103][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3355 (0.3530)	Acc@1 96.094 (95.864)	Acc@5 100.000 (99.945)
Epoch: [103][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3453 (0.3548)	Acc@1 95.703 (95.707)	Acc@5 100.000 (99.935)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.180 (0.180)	Data 0.278 (0.278)	Loss 0.3506 (0.3506)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.121 (0.120)	Data 0.000 (0.004)	Loss 0.3718 (0.3490)	Acc@1 93.750 (95.799)	Acc@5 100.000 (99.922)
Epoch: [104][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3386 (0.3520)	Acc@1 96.094 (95.612)	Acc@5 100.000 (99.924)
Epoch: [104][192/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3244 (0.3521)	Acc@1 98.047 (95.634)	Acc@5 100.000 (99.931)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.169 (0.169)	Data 0.299 (0.299)	Loss 0.3084 (0.3084)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.142 (0.123)	Data 0.000 (0.005)	Loss 0.3166 (0.3418)	Acc@1 97.266 (95.913)	Acc@5 100.000 (99.952)
Epoch: [105][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3347 (0.3421)	Acc@1 96.484 (95.827)	Acc@5 99.609 (99.936)
Epoch: [105][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2984 (0.3415)	Acc@1 97.656 (95.835)	Acc@5 100.000 (99.935)
Max memory in training epoch: 58.5965056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.47
Max memory: 90.6827264
 24.300s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2260
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1459712
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.193 (0.193)	Data 0.264 (0.264)	Loss 0.3465 (0.3465)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.3188 (0.3216)	Acc@1 96.484 (96.659)	Acc@5 100.000 (99.958)
Epoch: [106][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3940 (0.3293)	Acc@1 93.750 (96.239)	Acc@5 99.609 (99.967)
Epoch: [106][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3620 (0.3327)	Acc@1 94.922 (96.041)	Acc@5 99.609 (99.955)
Max memory in training epoch: 58.340608
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.170 (0.170)	Data 0.270 (0.270)	Loss 0.3283 (0.3283)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.3355 (0.3273)	Acc@1 96.094 (96.226)	Acc@5 100.000 (99.946)
Epoch: [107][128/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.3207 (0.3291)	Acc@1 96.484 (96.063)	Acc@5 100.000 (99.945)
Epoch: [107][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3672 (0.3308)	Acc@1 94.531 (95.958)	Acc@5 100.000 (99.951)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.177 (0.177)	Data 0.280 (0.280)	Loss 0.3139 (0.3139)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.3069 (0.3244)	Acc@1 96.484 (96.310)	Acc@5 100.000 (99.940)
Epoch: [108][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3398 (0.3253)	Acc@1 94.141 (96.212)	Acc@5 100.000 (99.939)
Epoch: [108][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3516 (0.3262)	Acc@1 95.312 (96.098)	Acc@5 99.609 (99.941)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.160 (0.160)	Data 0.290 (0.290)	Loss 0.3091 (0.3091)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.3518 (0.3152)	Acc@1 96.484 (96.478)	Acc@5 99.219 (99.928)
Epoch: [109][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3221 (0.3182)	Acc@1 95.312 (96.285)	Acc@5 100.000 (99.939)
Epoch: [109][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3178 (0.3203)	Acc@1 95.703 (96.096)	Acc@5 100.000 (99.949)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.147 (0.147)	Data 0.290 (0.290)	Loss 0.2915 (0.2915)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.2693 (0.3106)	Acc@1 98.047 (96.406)	Acc@5 100.000 (99.976)
Epoch: [110][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3057 (0.3155)	Acc@1 96.094 (96.215)	Acc@5 100.000 (99.961)
Epoch: [110][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3255 (0.3195)	Acc@1 96.094 (96.078)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.5965056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.47
Max memory: 90.7003392
 24.123s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2917
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1459712
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.178 (0.178)	Data 0.293 (0.293)	Loss 0.3301 (0.3301)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.2774 (0.3095)	Acc@1 98.438 (96.394)	Acc@5 99.609 (99.964)
Epoch: [111][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3081 (0.3097)	Acc@1 98.047 (96.318)	Acc@5 100.000 (99.970)
Epoch: [111][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3262 (0.3131)	Acc@1 96.094 (96.185)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.340608
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.184 (0.184)	Data 0.273 (0.273)	Loss 0.3873 (0.3873)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [112][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.3155 (0.3086)	Acc@1 97.656 (96.328)	Acc@5 99.609 (99.982)
Epoch: [112][128/196]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.3203 (0.3108)	Acc@1 96.484 (96.188)	Acc@5 100.000 (99.982)
Epoch: [112][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3233 (0.3135)	Acc@1 94.922 (96.074)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.141 (0.141)	Data 0.290 (0.290)	Loss 0.2549 (0.2549)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.2758 (0.3055)	Acc@1 97.266 (96.154)	Acc@5 100.000 (99.964)
Epoch: [113][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3072 (0.3062)	Acc@1 96.094 (96.169)	Acc@5 100.000 (99.967)
Epoch: [113][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2955 (0.3066)	Acc@1 94.922 (96.163)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.175 (0.175)	Data 0.320 (0.320)	Loss 0.3061 (0.3061)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.3210 (0.3073)	Acc@1 96.094 (96.274)	Acc@5 100.000 (99.970)
Epoch: [114][128/196]	Time 0.123 (0.120)	Data 0.000 (0.003)	Loss 0.3295 (0.3076)	Acc@1 95.312 (96.215)	Acc@5 100.000 (99.964)
Epoch: [114][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2695 (0.3079)	Acc@1 97.656 (96.169)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.5965056
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.158 (0.158)	Data 0.321 (0.321)	Loss 0.2927 (0.2927)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.3071 (0.3000)	Acc@1 95.312 (96.382)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.2962 (0.3007)	Acc@1 95.703 (96.324)	Acc@5 100.000 (99.979)
Epoch: [115][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2893 (0.3061)	Acc@1 96.094 (96.134)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.5965056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 345588 ; 346166 ; 0.9983302808479169
[INFO] Storing checkpoint...
  89.57
Max memory: 90.6827264
 23.985s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6349
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.193 (0.193)	Data 0.274 (0.274)	Loss 0.3258 (0.3258)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.3105 (0.2833)	Acc@1 95.312 (96.929)	Acc@5 100.000 (99.970)
Epoch: [116][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2871 (0.2948)	Acc@1 96.094 (96.421)	Acc@5 100.000 (99.979)
Epoch: [116][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3238 (0.2998)	Acc@1 94.922 (96.199)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.167 (0.167)	Data 0.288 (0.288)	Loss 0.3313 (0.3313)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.2962 (0.3002)	Acc@1 97.266 (96.268)	Acc@5 100.000 (99.952)
Epoch: [117][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2900 (0.3027)	Acc@1 95.703 (96.124)	Acc@5 100.000 (99.961)
Epoch: [117][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3107 (0.3030)	Acc@1 95.703 (96.080)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.170 (0.170)	Data 0.263 (0.263)	Loss 0.2954 (0.2954)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.3101 (0.2991)	Acc@1 96.875 (96.238)	Acc@5 99.609 (99.970)
Epoch: [118][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3204 (0.3015)	Acc@1 95.703 (96.188)	Acc@5 99.609 (99.961)
Epoch: [118][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3153 (0.3022)	Acc@1 96.484 (96.116)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.166 (0.166)	Data 0.307 (0.307)	Loss 0.2944 (0.2944)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.3028 (0.2905)	Acc@1 96.484 (96.130)	Acc@5 100.000 (99.964)
Epoch: [119][128/196]	Time 0.120 (0.119)	Data 0.000 (0.003)	Loss 0.2981 (0.2938)	Acc@1 96.094 (96.139)	Acc@5 100.000 (99.961)
Epoch: [119][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3129 (0.2958)	Acc@1 93.750 (96.110)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.3120 (0.3120)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.2687 (0.2910)	Acc@1 97.266 (96.208)	Acc@5 100.000 (99.982)
Epoch: [120][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2489 (0.2948)	Acc@1 98.047 (96.121)	Acc@5 100.000 (99.958)
Epoch: [120][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3113 (0.2965)	Acc@1 96.484 (96.084)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.27
Max memory: 90.6199552
 23.979s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7534
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.201 (0.201)	Data 0.264 (0.264)	Loss 0.3035 (0.3035)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.3455 (0.2820)	Acc@1 96.094 (96.605)	Acc@5 100.000 (99.976)
Epoch: [121][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.2921 (0.2901)	Acc@1 96.875 (96.281)	Acc@5 100.000 (99.976)
Epoch: [121][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2982 (0.2949)	Acc@1 96.094 (96.114)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.169 (0.169)	Data 0.269 (0.269)	Loss 0.2842 (0.2842)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.2809 (0.2927)	Acc@1 96.094 (96.190)	Acc@5 100.000 (99.970)
Epoch: [122][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.2983 (0.2910)	Acc@1 95.312 (96.209)	Acc@5 100.000 (99.976)
Epoch: [122][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.2942 (0.2962)	Acc@1 96.094 (96.023)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.171 (0.171)	Data 0.277 (0.277)	Loss 0.3274 (0.3274)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.127 (0.122)	Data 0.000 (0.004)	Loss 0.2841 (0.2904)	Acc@1 97.656 (96.286)	Acc@5 100.000 (99.976)
Epoch: [123][128/196]	Time 0.111 (0.122)	Data 0.000 (0.002)	Loss 0.3088 (0.2959)	Acc@1 93.359 (96.009)	Acc@5 100.000 (99.958)
Epoch: [123][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.2761 (0.3009)	Acc@1 97.266 (95.774)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.136 (0.136)	Data 0.289 (0.289)	Loss 0.2902 (0.2902)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.125 (0.121)	Data 0.000 (0.005)	Loss 0.2232 (0.2967)	Acc@1 99.219 (96.142)	Acc@5 100.000 (100.000)
Epoch: [124][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2912 (0.2992)	Acc@1 96.875 (95.951)	Acc@5 100.000 (99.994)
Epoch: [124][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2811 (0.2999)	Acc@1 96.484 (95.871)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.176 (0.176)	Data 0.308 (0.308)	Loss 0.2714 (0.2714)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2894 (0.2929)	Acc@1 96.094 (96.040)	Acc@5 100.000 (99.952)
Epoch: [125][128/196]	Time 0.121 (0.120)	Data 0.000 (0.003)	Loss 0.2660 (0.2925)	Acc@1 96.484 (96.124)	Acc@5 100.000 (99.970)
Epoch: [125][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2781 (0.2931)	Acc@1 95.312 (96.098)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.53
Max memory: 90.6199552
 24.024s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9261
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.200 (0.200)	Data 0.267 (0.267)	Loss 0.2633 (0.2633)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.130 (0.121)	Data 0.000 (0.004)	Loss 0.3117 (0.2803)	Acc@1 96.875 (96.502)	Acc@5 100.000 (99.976)
Epoch: [126][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2870 (0.2893)	Acc@1 96.094 (96.118)	Acc@5 100.000 (99.976)
Epoch: [126][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2955 (0.2938)	Acc@1 94.922 (95.912)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.147 (0.147)	Data 0.363 (0.363)	Loss 0.2742 (0.2742)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.115 (0.119)	Data 0.000 (0.006)	Loss 0.2930 (0.2939)	Acc@1 96.484 (96.040)	Acc@5 100.000 (99.946)
Epoch: [127][128/196]	Time 0.123 (0.119)	Data 0.000 (0.003)	Loss 0.2770 (0.2918)	Acc@1 96.875 (96.073)	Acc@5 100.000 (99.942)
Epoch: [127][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3162 (0.2957)	Acc@1 93.359 (95.908)	Acc@5 100.000 (99.951)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.147 (0.147)	Data 0.270 (0.270)	Loss 0.2897 (0.2897)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.2854 (0.2978)	Acc@1 96.484 (95.703)	Acc@5 100.000 (99.928)
Epoch: [128][128/196]	Time 0.130 (0.123)	Data 0.000 (0.002)	Loss 0.3009 (0.2972)	Acc@1 95.703 (95.758)	Acc@5 100.000 (99.942)
Epoch: [128][192/196]	Time 0.135 (0.123)	Data 0.000 (0.002)	Loss 0.3327 (0.2996)	Acc@1 94.922 (95.719)	Acc@5 100.000 (99.949)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.183 (0.183)	Data 0.278 (0.278)	Loss 0.3035 (0.3035)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.3055 (0.2979)	Acc@1 94.531 (95.757)	Acc@5 100.000 (99.988)
Epoch: [129][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3615 (0.2940)	Acc@1 92.188 (95.818)	Acc@5 100.000 (99.976)
Epoch: [129][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3263 (0.2952)	Acc@1 93.359 (95.839)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.185 (0.185)	Data 0.267 (0.267)	Loss 0.3315 (0.3315)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [130][64/196]	Time 0.117 (0.122)	Data 0.000 (0.004)	Loss 0.3457 (0.2917)	Acc@1 93.359 (95.998)	Acc@5 100.000 (99.964)
Epoch: [130][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3302 (0.2913)	Acc@1 95.312 (96.006)	Acc@5 100.000 (99.964)
Epoch: [130][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2809 (0.2953)	Acc@1 96.094 (95.891)	Acc@5 99.609 (99.955)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.18
Max memory: 90.6199552
 23.984s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2828
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.198 (0.198)	Data 0.268 (0.268)	Loss 0.2604 (0.2604)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.125 (0.122)	Data 0.000 (0.004)	Loss 0.2646 (0.2779)	Acc@1 97.266 (96.448)	Acc@5 100.000 (99.970)
Epoch: [131][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2931 (0.2800)	Acc@1 96.094 (96.303)	Acc@5 100.000 (99.964)
Epoch: [131][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3726 (0.2873)	Acc@1 94.141 (96.065)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.161 (0.161)	Data 0.311 (0.311)	Loss 0.2421 (0.2421)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.2812 (0.2856)	Acc@1 96.094 (96.106)	Acc@5 100.000 (99.976)
Epoch: [132][128/196]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.2996 (0.2893)	Acc@1 96.094 (95.930)	Acc@5 100.000 (99.973)
Epoch: [132][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3303 (0.2950)	Acc@1 94.922 (95.754)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.172 (0.172)	Data 0.284 (0.284)	Loss 0.2940 (0.2940)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2484 (0.2921)	Acc@1 97.266 (96.148)	Acc@5 100.000 (99.940)
Epoch: [133][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2851 (0.2905)	Acc@1 97.266 (96.139)	Acc@5 100.000 (99.955)
Epoch: [133][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2916 (0.2940)	Acc@1 96.484 (95.958)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.166 (0.166)	Data 0.318 (0.318)	Loss 0.2556 (0.2556)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.3276 (0.2903)	Acc@1 94.531 (95.799)	Acc@5 100.000 (99.964)
Epoch: [134][128/196]	Time 0.121 (0.124)	Data 0.000 (0.003)	Loss 0.3401 (0.2944)	Acc@1 94.922 (95.733)	Acc@5 100.000 (99.964)
Epoch: [134][192/196]	Time 0.130 (0.123)	Data 0.000 (0.002)	Loss 0.2987 (0.2968)	Acc@1 94.531 (95.638)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.177 (0.177)	Data 0.320 (0.320)	Loss 0.2724 (0.2724)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [135][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.2702 (0.2942)	Acc@1 96.484 (95.631)	Acc@5 100.000 (99.958)
Epoch: [135][128/196]	Time 0.114 (0.122)	Data 0.000 (0.003)	Loss 0.3274 (0.2976)	Acc@1 92.969 (95.600)	Acc@5 100.000 (99.967)
Epoch: [135][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2599 (0.2986)	Acc@1 97.656 (95.608)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.92
Max memory: 90.6199552
 24.295s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1819
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.182 (0.182)	Data 0.298 (0.298)	Loss 0.2934 (0.2934)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2858 (0.2754)	Acc@1 94.922 (96.581)	Acc@5 100.000 (99.976)
Epoch: [136][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3497 (0.2799)	Acc@1 95.312 (96.391)	Acc@5 100.000 (99.979)
Epoch: [136][192/196]	Time 0.126 (0.121)	Data 0.000 (0.002)	Loss 0.2756 (0.2866)	Acc@1 97.656 (96.116)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.159 (0.159)	Data 0.282 (0.282)	Loss 0.2263 (0.2263)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.3049 (0.2916)	Acc@1 96.094 (95.847)	Acc@5 100.000 (99.982)
Epoch: [137][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2443 (0.2876)	Acc@1 97.266 (96.054)	Acc@5 100.000 (99.979)
Epoch: [137][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3416 (0.2897)	Acc@1 95.703 (96.039)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.181 (0.181)	Data 0.269 (0.269)	Loss 0.2864 (0.2864)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.127 (0.124)	Data 0.000 (0.004)	Loss 0.2780 (0.2862)	Acc@1 96.484 (96.040)	Acc@5 100.000 (99.982)
Epoch: [138][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3244 (0.2882)	Acc@1 95.703 (95.979)	Acc@5 99.609 (99.979)
Epoch: [138][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3063 (0.2928)	Acc@1 95.312 (95.782)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.171 (0.171)	Data 0.286 (0.286)	Loss 0.2721 (0.2721)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.3663 (0.2934)	Acc@1 94.141 (95.751)	Acc@5 100.000 (99.958)
Epoch: [139][128/196]	Time 0.132 (0.122)	Data 0.000 (0.002)	Loss 0.3076 (0.2921)	Acc@1 93.750 (95.830)	Acc@5 100.000 (99.958)
Epoch: [139][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3649 (0.2977)	Acc@1 92.188 (95.610)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.149 (0.149)	Data 0.303 (0.303)	Loss 0.3178 (0.3178)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 0.3100 (0.2926)	Acc@1 96.094 (95.751)	Acc@5 100.000 (99.982)
Epoch: [140][128/196]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.2786 (0.2899)	Acc@1 96.484 (95.806)	Acc@5 100.000 (99.967)
Epoch: [140][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3377 (0.2932)	Acc@1 92.969 (95.701)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.7
Max memory: 90.6199552
 24.242s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4514
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.203 (0.203)	Data 0.265 (0.265)	Loss 0.3116 (0.3116)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.2381 (0.2791)	Acc@1 98.828 (96.280)	Acc@5 100.000 (99.976)
Epoch: [141][128/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.3520 (0.2874)	Acc@1 94.531 (95.976)	Acc@5 100.000 (99.967)
Epoch: [141][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3472 (0.2927)	Acc@1 94.141 (95.786)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.167 (0.167)	Data 0.261 (0.261)	Loss 0.3154 (0.3154)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [142][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.3118 (0.2934)	Acc@1 95.703 (95.697)	Acc@5 100.000 (99.940)
Epoch: [142][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.2691 (0.2914)	Acc@1 96.875 (95.830)	Acc@5 100.000 (99.952)
Epoch: [142][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2696 (0.2936)	Acc@1 97.266 (95.762)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.179 (0.179)	Data 0.266 (0.266)	Loss 0.3013 (0.3013)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.2596 (0.2892)	Acc@1 96.484 (95.938)	Acc@5 100.000 (99.988)
Epoch: [143][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.2713 (0.2919)	Acc@1 95.312 (95.827)	Acc@5 100.000 (99.979)
Epoch: [143][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2843 (0.2934)	Acc@1 94.922 (95.774)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.171 (0.171)	Data 0.291 (0.291)	Loss 0.2725 (0.2725)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.2906 (0.2819)	Acc@1 95.312 (96.238)	Acc@5 100.000 (99.970)
Epoch: [144][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3354 (0.2853)	Acc@1 94.141 (96.085)	Acc@5 100.000 (99.964)
Epoch: [144][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3269 (0.2907)	Acc@1 95.312 (95.875)	Acc@5 99.609 (99.970)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.149 (0.149)	Data 0.283 (0.283)	Loss 0.2648 (0.2648)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.3048 (0.2945)	Acc@1 96.875 (95.865)	Acc@5 100.000 (99.940)
Epoch: [145][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.2974 (0.2920)	Acc@1 94.922 (95.900)	Acc@5 100.000 (99.958)
Epoch: [145][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3301 (0.2942)	Acc@1 94.922 (95.812)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.81
Max memory: 90.6199552
 25.238s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3957
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.145664
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.175 (0.175)	Data 0.283 (0.283)	Loss 0.2588 (0.2588)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 0.2529 (0.2725)	Acc@1 96.875 (96.569)	Acc@5 100.000 (99.982)
Epoch: [146][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2660 (0.2822)	Acc@1 97.656 (96.100)	Acc@5 100.000 (99.982)
Epoch: [146][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2661 (0.2883)	Acc@1 96.484 (95.932)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.3137792
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.154 (0.154)	Data 0.303 (0.303)	Loss 0.3336 (0.3336)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.3078 (0.2878)	Acc@1 94.531 (96.016)	Acc@5 100.000 (99.964)
Epoch: [147][128/196]	Time 0.121 (0.120)	Data 0.000 (0.003)	Loss 0.2775 (0.2920)	Acc@1 97.266 (95.809)	Acc@5 100.000 (99.967)
Epoch: [147][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3334 (0.2962)	Acc@1 95.312 (95.687)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.168 (0.168)	Data 0.274 (0.274)	Loss 0.2452 (0.2452)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.3233 (0.2979)	Acc@1 93.750 (95.649)	Acc@5 99.219 (99.952)
Epoch: [148][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3200 (0.2937)	Acc@1 94.141 (95.782)	Acc@5 100.000 (99.961)
Epoch: [148][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2738 (0.2971)	Acc@1 96.094 (95.616)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.172 (0.172)	Data 0.290 (0.290)	Loss 0.3216 (0.3216)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.2797 (0.2976)	Acc@1 96.875 (95.577)	Acc@5 100.000 (99.940)
Epoch: [149][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3168 (0.2941)	Acc@1 94.922 (95.727)	Acc@5 100.000 (99.958)
Epoch: [149][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2791 (0.2956)	Acc@1 95.703 (95.642)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.542848
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.195 (0.195)	Data 0.270 (0.270)	Loss 0.3197 (0.3197)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.2454 (0.2670)	Acc@1 97.656 (96.707)	Acc@5 100.000 (99.988)
Epoch: [150][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2142 (0.2576)	Acc@1 99.219 (97.096)	Acc@5 100.000 (99.976)
Epoch: [150][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2352 (0.2497)	Acc@1 98.828 (97.426)	Acc@5 100.000 (99.982)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.2
Max memory: 90.6199552
 24.162s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6455
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.145664
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.195 (0.195)	Data 0.264 (0.264)	Loss 0.2528 (0.2528)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.115 (0.122)	Data 0.000 (0.004)	Loss 0.2279 (0.2316)	Acc@1 98.047 (98.161)	Acc@5 100.000 (99.970)
Epoch: [151][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2151 (0.2306)	Acc@1 98.438 (98.126)	Acc@5 100.000 (99.979)
Epoch: [151][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2166 (0.2305)	Acc@1 98.438 (98.108)	Acc@5 100.000 (99.984)
Max memory in training epoch: 58.3137792
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.165 (0.165)	Data 0.306 (0.306)	Loss 0.2103 (0.2103)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.125 (0.121)	Data 0.000 (0.005)	Loss 0.2221 (0.2225)	Acc@1 98.047 (98.462)	Acc@5 100.000 (100.000)
Epoch: [152][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.2188 (0.2219)	Acc@1 99.219 (98.468)	Acc@5 100.000 (99.991)
Epoch: [152][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2340 (0.2217)	Acc@1 96.875 (98.472)	Acc@5 100.000 (99.992)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.170 (0.170)	Data 0.264 (0.264)	Loss 0.2221 (0.2221)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.118 (0.124)	Data 0.000 (0.004)	Loss 0.2028 (0.2164)	Acc@1 98.438 (98.636)	Acc@5 100.000 (100.000)
Epoch: [153][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2242 (0.2166)	Acc@1 98.828 (98.683)	Acc@5 100.000 (100.000)
Epoch: [153][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.1989 (0.2162)	Acc@1 99.219 (98.682)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.169 (0.169)	Data 0.269 (0.269)	Loss 0.1947 (0.1947)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.2218 (0.2116)	Acc@1 97.656 (98.858)	Acc@5 100.000 (100.000)
Epoch: [154][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2271 (0.2121)	Acc@1 98.438 (98.840)	Acc@5 100.000 (100.000)
Epoch: [154][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2021 (0.2130)	Acc@1 99.219 (98.788)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.162 (0.162)	Data 0.286 (0.286)	Loss 0.2221 (0.2221)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2009 (0.2094)	Acc@1 99.219 (98.882)	Acc@5 100.000 (99.988)
Epoch: [155][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1991 (0.2086)	Acc@1 100.000 (98.910)	Acc@5 100.000 (99.988)
Epoch: [155][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2061 (0.2090)	Acc@1 99.219 (98.881)	Acc@5 100.000 (99.992)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.66
Max memory: 90.6199552
 24.046s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7576
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.145664
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.185 (0.185)	Data 0.319 (0.319)	Loss 0.1999 (0.1999)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.2023 (0.2048)	Acc@1 98.438 (99.044)	Acc@5 100.000 (99.988)
Epoch: [156][128/196]	Time 0.119 (0.126)	Data 0.000 (0.003)	Loss 0.1926 (0.2048)	Acc@1 99.219 (99.037)	Acc@5 100.000 (99.991)
Epoch: [156][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.2067 (0.2057)	Acc@1 99.219 (98.984)	Acc@5 100.000 (99.988)
Max memory in training epoch: 58.3137792
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.146 (0.146)	Data 0.289 (0.289)	Loss 0.2040 (0.2040)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.1966 (0.2029)	Acc@1 99.609 (99.081)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1866 (0.2057)	Acc@1 99.609 (98.964)	Acc@5 100.000 (99.991)
Epoch: [157][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2100 (0.2050)	Acc@1 99.219 (98.974)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.172 (0.172)	Data 0.298 (0.298)	Loss 0.2286 (0.2286)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.2203 (0.2035)	Acc@1 98.828 (98.972)	Acc@5 100.000 (99.994)
Epoch: [158][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2026 (0.2025)	Acc@1 99.219 (99.052)	Acc@5 100.000 (99.994)
Epoch: [158][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2107 (0.2034)	Acc@1 97.656 (99.010)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.175 (0.175)	Data 0.273 (0.273)	Loss 0.1998 (0.1998)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.2030 (0.1977)	Acc@1 98.828 (99.279)	Acc@5 100.000 (99.994)
Epoch: [159][128/196]	Time 0.129 (0.122)	Data 0.000 (0.002)	Loss 0.1909 (0.1984)	Acc@1 99.609 (99.216)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2036 (0.2003)	Acc@1 98.438 (99.132)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.176 (0.176)	Data 0.289 (0.289)	Loss 0.2069 (0.2069)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.1879 (0.1970)	Acc@1 99.609 (99.219)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.145 (0.122)	Data 0.000 (0.002)	Loss 0.1899 (0.1974)	Acc@1 99.609 (99.249)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.2045 (0.1980)	Acc@1 98.438 (99.215)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.78
Max memory: 90.6199552
 24.288s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7132
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.145664
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.184 (0.184)	Data 0.311 (0.311)	Loss 0.2028 (0.2028)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.1861 (0.1984)	Acc@1 99.609 (99.267)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.2019 (0.1994)	Acc@1 98.438 (99.116)	Acc@5 100.000 (99.997)
Epoch: [161][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.2240 (0.1994)	Acc@1 98.438 (99.107)	Acc@5 99.609 (99.994)
Max memory in training epoch: 58.3137792
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.171 (0.171)	Data 0.299 (0.299)	Loss 0.1981 (0.1981)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.2157 (0.1957)	Acc@1 99.219 (99.285)	Acc@5 100.000 (99.988)
Epoch: [162][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1872 (0.1969)	Acc@1 99.609 (99.201)	Acc@5 100.000 (99.994)
Epoch: [162][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.2087 (0.1964)	Acc@1 98.438 (99.209)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.159 (0.159)	Data 0.312 (0.312)	Loss 0.1893 (0.1893)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.1905 (0.1929)	Acc@1 99.219 (99.339)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.1892 (0.1943)	Acc@1 100.000 (99.273)	Acc@5 100.000 (99.994)
Epoch: [163][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2099 (0.1950)	Acc@1 98.828 (99.237)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.171 (0.171)	Data 0.292 (0.292)	Loss 0.1861 (0.1861)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.1901 (0.1926)	Acc@1 99.219 (99.309)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1836 (0.1922)	Acc@1 100.000 (99.352)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.1969 (0.1926)	Acc@1 98.828 (99.320)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.172 (0.172)	Data 0.296 (0.296)	Loss 0.1988 (0.1988)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.128 (0.122)	Data 0.000 (0.005)	Loss 0.2031 (0.1912)	Acc@1 98.438 (99.351)	Acc@5 100.000 (99.994)
Epoch: [165][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.1873 (0.1919)	Acc@1 99.219 (99.325)	Acc@5 100.000 (99.994)
Epoch: [165][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1827 (0.1924)	Acc@1 100.000 (99.298)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.75
Max memory: 90.6199552
 24.032s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6943
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.145664
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.206 (0.206)	Data 0.263 (0.263)	Loss 0.1906 (0.1906)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.115 (0.120)	Data 0.000 (0.004)	Loss 0.1857 (0.1879)	Acc@1 99.609 (99.471)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1778 (0.1894)	Acc@1 100.000 (99.385)	Acc@5 100.000 (99.997)
Epoch: [166][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1859 (0.1905)	Acc@1 99.609 (99.338)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.3137792
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.148 (0.148)	Data 0.297 (0.297)	Loss 0.1971 (0.1971)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.2024 (0.1889)	Acc@1 98.047 (99.363)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.1864 (0.1894)	Acc@1 99.609 (99.388)	Acc@5 100.000 (99.997)
Epoch: [167][192/196]	Time 0.140 (0.123)	Data 0.000 (0.002)	Loss 0.1833 (0.1897)	Acc@1 99.609 (99.360)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.168 (0.168)	Data 0.283 (0.283)	Loss 0.1709 (0.1709)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.1880 (0.1872)	Acc@1 98.828 (99.393)	Acc@5 100.000 (99.994)
Epoch: [168][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.1887 (0.1880)	Acc@1 99.609 (99.367)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.134 (0.120)	Data 0.000 (0.002)	Loss 0.1834 (0.1881)	Acc@1 99.609 (99.366)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.174 (0.174)	Data 0.310 (0.310)	Loss 0.1835 (0.1835)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.1747 (0.1871)	Acc@1 100.000 (99.471)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.120 (0.121)	Data 0.000 (0.003)	Loss 0.2053 (0.1871)	Acc@1 99.219 (99.437)	Acc@5 100.000 (99.997)
Epoch: [169][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1895 (0.1872)	Acc@1 99.219 (99.419)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.167 (0.167)	Data 0.289 (0.289)	Loss 0.1796 (0.1796)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.1820 (0.1891)	Acc@1 99.219 (99.267)	Acc@5 100.000 (99.994)
Epoch: [170][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1722 (0.1874)	Acc@1 100.000 (99.391)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1947 (0.1868)	Acc@1 98.828 (99.415)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.72
Max memory: 90.6199552
 24.015s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2719
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.145664
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.205 (0.205)	Data 0.273 (0.273)	Loss 0.1856 (0.1856)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.1810 (0.1851)	Acc@1 100.000 (99.477)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1801 (0.1864)	Acc@1 99.609 (99.403)	Acc@5 100.000 (99.994)
Epoch: [171][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1794 (0.1857)	Acc@1 100.000 (99.421)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.3137792
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.163 (0.163)	Data 0.260 (0.260)	Loss 0.1728 (0.1728)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.1888 (0.1855)	Acc@1 99.219 (99.363)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.1807 (0.1841)	Acc@1 99.609 (99.467)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1738 (0.1841)	Acc@1 100.000 (99.458)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.166 (0.166)	Data 0.299 (0.299)	Loss 0.1836 (0.1836)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.1772 (0.1840)	Acc@1 99.609 (99.507)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.1702 (0.1845)	Acc@1 100.000 (99.446)	Acc@5 100.000 (99.997)
Epoch: [173][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.1688 (0.1841)	Acc@1 100.000 (99.452)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.155 (0.155)	Data 0.279 (0.279)	Loss 0.1733 (0.1733)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.2169 (0.1841)	Acc@1 98.047 (99.429)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.1899 (0.1827)	Acc@1 99.219 (99.470)	Acc@5 100.000 (100.000)
Epoch: [174][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1869 (0.1830)	Acc@1 99.219 (99.464)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.148 (0.148)	Data 0.273 (0.273)	Loss 0.1771 (0.1771)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.1748 (0.1823)	Acc@1 99.609 (99.507)	Acc@5 100.000 (99.988)
Epoch: [175][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1770 (0.1821)	Acc@1 99.609 (99.531)	Acc@5 100.000 (99.988)
Epoch: [175][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1796 (0.1815)	Acc@1 99.609 (99.534)	Acc@5 100.000 (99.990)
Max memory in training epoch: 58.542848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.58
Max memory: 90.6199552
 24.072s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9135
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.145664
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.187 (0.187)	Data 0.288 (0.288)	Loss 0.1847 (0.1847)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.1759 (0.1812)	Acc@1 99.609 (99.489)	Acc@5 100.000 (99.988)
Epoch: [176][128/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.2145 (0.1816)	Acc@1 98.438 (99.467)	Acc@5 100.000 (99.994)
Epoch: [176][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1745 (0.1815)	Acc@1 99.609 (99.482)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.3137792
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.170 (0.170)	Data 0.337 (0.337)	Loss 0.1880 (0.1880)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.1780 (0.1807)	Acc@1 99.609 (99.495)	Acc@5 100.000 (99.994)
Epoch: [177][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.1825 (0.1813)	Acc@1 99.609 (99.494)	Acc@5 100.000 (99.997)
Epoch: [177][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.1760 (0.1806)	Acc@1 99.609 (99.510)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.173 (0.173)	Data 0.309 (0.309)	Loss 0.1689 (0.1689)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.1840 (0.1779)	Acc@1 99.219 (99.555)	Acc@5 100.000 (99.988)
Epoch: [178][128/196]	Time 0.124 (0.122)	Data 0.000 (0.003)	Loss 0.1688 (0.1786)	Acc@1 100.000 (99.522)	Acc@5 100.000 (99.994)
Epoch: [178][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1907 (0.1782)	Acc@1 99.219 (99.567)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.174 (0.174)	Data 0.275 (0.275)	Loss 0.1780 (0.1780)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.119 (0.125)	Data 0.000 (0.004)	Loss 0.2020 (0.1787)	Acc@1 98.438 (99.585)	Acc@5 100.000 (99.994)
Epoch: [179][128/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.1742 (0.1794)	Acc@1 100.000 (99.555)	Acc@5 100.000 (99.997)
Epoch: [179][192/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.1910 (0.1796)	Acc@1 98.828 (99.532)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.542848
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.166 (0.166)	Data 0.291 (0.291)	Loss 0.1714 (0.1714)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.1746 (0.1770)	Acc@1 100.000 (99.597)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.132 (0.124)	Data 0.000 (0.002)	Loss 0.1764 (0.1772)	Acc@1 99.609 (99.606)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.1763 (0.1769)	Acc@1 99.609 (99.607)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.542848
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(22, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(11, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.64
Max memory: 90.6199552
 24.551s  Thres 0.01 5
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7503
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.205 (0.205)	Data 0.290 (0.290)	Loss 3.3292 (3.3292)	Acc@1 12.109 (12.109)	Acc@5 50.391 (50.391)
Epoch: [1][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 2.4728 (2.6944)	Acc@1 33.203 (24.069)	Acc@5 84.766 (76.562)
Epoch: [1][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 2.2574 (2.4997)	Acc@1 39.062 (30.202)	Acc@5 88.281 (82.749)
Epoch: [1][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 2.0322 (2.3652)	Acc@1 43.750 (34.656)	Acc@5 92.969 (85.796)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.192 (0.192)	Data 0.268 (0.268)	Loss 1.9789 (1.9789)	Acc@1 48.828 (48.828)	Acc@5 94.531 (94.531)
Epoch: [2][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 1.7677 (1.9159)	Acc@1 55.469 (50.421)	Acc@5 96.875 (94.165)
Epoch: [2][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.6564 (1.8433)	Acc@1 57.031 (52.756)	Acc@5 95.312 (94.604)
Epoch: [2][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 1.4769 (1.7851)	Acc@1 61.719 (54.762)	Acc@5 97.656 (94.970)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.179 (0.179)	Data 0.264 (0.264)	Loss 1.7077 (1.7077)	Acc@1 58.203 (58.203)	Acc@5 96.484 (96.484)
Epoch: [3][64/196]	Time 0.134 (0.131)	Data 0.000 (0.004)	Loss 1.5052 (1.5618)	Acc@1 60.938 (62.031)	Acc@5 97.266 (96.430)
Epoch: [3][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 1.4337 (1.5299)	Acc@1 60.156 (62.988)	Acc@5 97.266 (96.657)
Epoch: [3][192/196]	Time 0.148 (0.131)	Data 0.000 (0.002)	Loss 1.2225 (1.4831)	Acc@1 69.141 (64.253)	Acc@5 99.219 (96.881)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.171 (0.171)	Data 0.269 (0.269)	Loss 1.2481 (1.2481)	Acc@1 69.922 (69.922)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 1.3348 (1.3447)	Acc@1 69.922 (68.576)	Acc@5 97.266 (97.494)
Epoch: [4][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 1.2162 (1.3193)	Acc@1 73.828 (69.222)	Acc@5 97.656 (97.596)
Epoch: [4][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.0832 (1.2867)	Acc@1 74.609 (70.076)	Acc@5 100.000 (97.814)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.152 (0.152)	Data 0.284 (0.284)	Loss 1.2629 (1.2629)	Acc@1 73.438 (73.438)	Acc@5 97.656 (97.656)
Epoch: [5][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 1.0466 (1.1695)	Acc@1 76.953 (73.383)	Acc@5 98.828 (98.191)
Epoch: [5][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 1.1894 (1.1546)	Acc@1 73.438 (73.952)	Acc@5 98.047 (98.216)
Epoch: [5][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 1.0499 (1.1373)	Acc@1 80.469 (74.401)	Acc@5 98.047 (98.312)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  62.83
Max memory: 103.3835008
 25.548s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4936
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.190 (0.190)	Data 0.283 (0.283)	Loss 1.1057 (1.1057)	Acc@1 78.516 (78.516)	Acc@5 98.438 (98.438)
Epoch: [6][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 1.0229 (1.0454)	Acc@1 77.734 (76.917)	Acc@5 98.438 (98.576)
Epoch: [6][128/196]	Time 0.139 (0.130)	Data 0.000 (0.002)	Loss 0.9625 (1.0419)	Acc@1 78.516 (76.965)	Acc@5 98.438 (98.598)
Epoch: [6][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.9342 (1.0317)	Acc@1 80.859 (77.127)	Acc@5 99.219 (98.622)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.187 (0.187)	Data 0.267 (0.267)	Loss 0.9839 (0.9839)	Acc@1 77.734 (77.734)	Acc@5 97.656 (97.656)
Epoch: [7][64/196]	Time 0.124 (0.131)	Data 0.000 (0.004)	Loss 0.9307 (0.9687)	Acc@1 78.516 (78.480)	Acc@5 99.609 (98.978)
Epoch: [7][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.9630 (0.9633)	Acc@1 76.953 (78.658)	Acc@5 99.219 (98.898)
Epoch: [7][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 1.0402 (0.9597)	Acc@1 76.562 (78.633)	Acc@5 98.438 (98.856)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.186 (0.186)	Data 0.270 (0.270)	Loss 0.8616 (0.8616)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.131 (0.133)	Data 0.000 (0.004)	Loss 0.9499 (0.9169)	Acc@1 78.906 (79.651)	Acc@5 98.438 (98.858)
Epoch: [8][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8760 (0.9137)	Acc@1 81.641 (79.715)	Acc@5 100.000 (98.852)
Epoch: [8][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 1.0385 (0.9064)	Acc@1 74.219 (79.855)	Acc@5 98.047 (98.889)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.170 (0.170)	Data 0.313 (0.313)	Loss 0.8008 (0.8008)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [9][64/196]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.8703 (0.8752)	Acc@1 81.641 (80.180)	Acc@5 98.438 (98.966)
Epoch: [9][128/196]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.8821 (0.8770)	Acc@1 78.906 (80.299)	Acc@5 98.828 (98.931)
Epoch: [9][192/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.9122 (0.8803)	Acc@1 76.172 (80.206)	Acc@5 98.828 (98.911)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.161 (0.161)	Data 0.272 (0.272)	Loss 0.8944 (0.8944)	Acc@1 80.078 (80.078)	Acc@5 98.047 (98.047)
Epoch: [10][64/196]	Time 0.127 (0.132)	Data 0.000 (0.004)	Loss 0.8069 (0.8472)	Acc@1 80.078 (81.034)	Acc@5 99.219 (99.014)
Epoch: [10][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.8723 (0.8373)	Acc@1 80.469 (81.441)	Acc@5 98.438 (99.007)
Epoch: [10][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.9033 (0.8408)	Acc@1 77.734 (81.319)	Acc@5 97.266 (99.000)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  72.85
Max memory: 103.3833984
 26.041s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5265
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.190 (0.190)	Data 0.285 (0.285)	Loss 0.9037 (0.9037)	Acc@1 77.344 (77.344)	Acc@5 98.828 (98.828)
Epoch: [11][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.8110 (0.8127)	Acc@1 83.203 (81.845)	Acc@5 100.000 (99.213)
Epoch: [11][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.8997 (0.8289)	Acc@1 80.469 (81.489)	Acc@5 98.047 (99.128)
Epoch: [11][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.8151 (0.8290)	Acc@1 81.250 (81.529)	Acc@5 98.438 (99.109)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.168 (0.168)	Data 0.282 (0.282)	Loss 0.7752 (0.7752)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [12][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.8098 (0.8233)	Acc@1 81.250 (81.304)	Acc@5 99.219 (99.105)
Epoch: [12][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.8521 (0.8197)	Acc@1 80.078 (81.622)	Acc@5 98.438 (99.161)
Epoch: [12][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7648 (0.8158)	Acc@1 84.375 (81.873)	Acc@5 99.219 (99.146)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.167 (0.167)	Data 0.259 (0.259)	Loss 0.7577 (0.7577)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [13][64/196]	Time 0.135 (0.130)	Data 0.000 (0.004)	Loss 0.8060 (0.8147)	Acc@1 81.641 (81.797)	Acc@5 99.219 (99.062)
Epoch: [13][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.8265 (0.8053)	Acc@1 82.031 (82.043)	Acc@5 98.438 (99.128)
Epoch: [13][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.8222 (0.8052)	Acc@1 81.250 (82.112)	Acc@5 98.438 (99.136)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.183 (0.183)	Data 0.271 (0.271)	Loss 0.8031 (0.8031)	Acc@1 80.469 (80.469)	Acc@5 100.000 (100.000)
Epoch: [14][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.7896 (0.7852)	Acc@1 82.812 (82.837)	Acc@5 99.219 (99.237)
Epoch: [14][128/196]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.8810 (0.7889)	Acc@1 77.734 (82.664)	Acc@5 98.828 (99.198)
Epoch: [14][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7658 (0.7924)	Acc@1 83.594 (82.604)	Acc@5 99.609 (99.168)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.195 (0.195)	Data 0.263 (0.263)	Loss 0.7582 (0.7582)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [15][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.8258 (0.7939)	Acc@1 81.250 (82.260)	Acc@5 98.047 (99.267)
Epoch: [15][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7797 (0.7839)	Acc@1 82.812 (82.697)	Acc@5 99.609 (99.201)
Epoch: [15][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7210 (0.7882)	Acc@1 84.375 (82.604)	Acc@5 99.219 (99.178)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 482770 ; 487386 ; 0.9905290673100992
[INFO] Storing checkpoint...
  67.46
Max memory: 103.3833984
 25.591s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3321
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.2006528
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.216 (0.216)	Data 0.264 (0.264)	Loss 0.7443 (0.7443)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.124 (0.130)	Data 0.000 (0.004)	Loss 0.8348 (0.7632)	Acc@1 82.422 (83.732)	Acc@5 99.219 (99.255)
Epoch: [16][128/196]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.8410 (0.7671)	Acc@1 80.078 (83.503)	Acc@5 99.609 (99.279)
Epoch: [16][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.8100 (0.7680)	Acc@1 81.641 (83.470)	Acc@5 98.828 (99.239)
Max memory in training epoch: 66.6393088
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.179 (0.179)	Data 0.273 (0.273)	Loss 0.8216 (0.8216)	Acc@1 79.688 (79.688)	Acc@5 98.047 (98.047)
Epoch: [17][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.6741 (0.7589)	Acc@1 85.547 (83.582)	Acc@5 99.609 (99.339)
Epoch: [17][128/196]	Time 0.120 (0.129)	Data 0.000 (0.002)	Loss 0.7537 (0.7593)	Acc@1 86.719 (83.591)	Acc@5 99.219 (99.297)
Epoch: [17][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8294 (0.7652)	Acc@1 82.422 (83.511)	Acc@5 98.828 (99.261)
Max memory in training epoch: 66.4820224
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.177 (0.177)	Data 0.268 (0.268)	Loss 0.7987 (0.7987)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.136 (0.129)	Data 0.000 (0.004)	Loss 0.7586 (0.7674)	Acc@1 84.375 (83.407)	Acc@5 99.219 (99.189)
Epoch: [18][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.8470 (0.7663)	Acc@1 81.641 (83.461)	Acc@5 99.219 (99.210)
Epoch: [18][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.8300 (0.7681)	Acc@1 81.250 (83.406)	Acc@5 98.828 (99.211)
Max memory in training epoch: 66.4820224
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.187 (0.187)	Data 0.305 (0.305)	Loss 0.7559 (0.7559)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.7547 (0.7548)	Acc@1 82.812 (84.032)	Acc@5 100.000 (99.309)
Epoch: [19][128/196]	Time 0.128 (0.133)	Data 0.000 (0.003)	Loss 0.7936 (0.7516)	Acc@1 82.422 (84.078)	Acc@5 99.219 (99.291)
Epoch: [19][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7330 (0.7564)	Acc@1 85.156 (83.772)	Acc@5 99.609 (99.279)
Max memory in training epoch: 66.4820224
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.158 (0.158)	Data 0.272 (0.272)	Loss 0.7206 (0.7206)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [20][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.8047 (0.7423)	Acc@1 83.203 (84.351)	Acc@5 99.609 (99.345)
Epoch: [20][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7626 (0.7435)	Acc@1 82.031 (84.151)	Acc@5 99.609 (99.310)
Epoch: [20][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.9224 (0.7456)	Acc@1 77.344 (84.152)	Acc@5 98.828 (99.279)
Max memory in training epoch: 66.4820224
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 434302 ; 482770 ; 0.8996043664685047
[INFO] Storing checkpoint...
  70.14
Max memory: 103.3778688
 25.571s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8362
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1814016
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.201 (0.201)	Data 0.263 (0.263)	Loss 0.7458 (0.7458)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 0.133 (0.130)	Data 0.000 (0.004)	Loss 0.6614 (0.7323)	Acc@1 87.891 (84.639)	Acc@5 100.000 (99.339)
Epoch: [21][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.8052 (0.7484)	Acc@1 80.859 (84.136)	Acc@5 99.219 (99.255)
Epoch: [21][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7392 (0.7436)	Acc@1 87.891 (84.373)	Acc@5 99.219 (99.275)
Max memory in training epoch: 65.9790336
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.195 (0.195)	Data 0.268 (0.268)	Loss 0.7215 (0.7215)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.6573 (0.7421)	Acc@1 89.453 (84.501)	Acc@5 99.219 (99.255)
Epoch: [22][128/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7288 (0.7407)	Acc@1 84.375 (84.487)	Acc@5 99.219 (99.276)
Epoch: [22][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7203 (0.7434)	Acc@1 84.375 (84.488)	Acc@5 99.609 (99.257)
Max memory in training epoch: 65.9986944
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.197 (0.197)	Data 0.270 (0.270)	Loss 0.7115 (0.7115)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.138 (0.131)	Data 0.000 (0.004)	Loss 0.7469 (0.7440)	Acc@1 83.203 (84.062)	Acc@5 99.219 (99.363)
Epoch: [23][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.7483 (0.7408)	Acc@1 85.547 (84.384)	Acc@5 99.219 (99.334)
Epoch: [23][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7250 (0.7455)	Acc@1 86.328 (84.270)	Acc@5 100.000 (99.294)
Max memory in training epoch: 65.9986944
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.187 (0.187)	Data 0.265 (0.265)	Loss 0.7186 (0.7186)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.134 (0.130)	Data 0.000 (0.004)	Loss 0.7286 (0.7216)	Acc@1 83.594 (85.102)	Acc@5 99.609 (99.381)
Epoch: [24][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6379 (0.7228)	Acc@1 88.672 (85.071)	Acc@5 99.219 (99.319)
Epoch: [24][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7150 (0.7300)	Acc@1 84.766 (84.812)	Acc@5 99.609 (99.300)
Max memory in training epoch: 65.9986944
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.172 (0.172)	Data 0.320 (0.320)	Loss 0.7195 (0.7195)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.7722 (0.7195)	Acc@1 81.250 (85.144)	Acc@5 99.609 (99.375)
Epoch: [25][128/196]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.6887 (0.7240)	Acc@1 87.109 (85.053)	Acc@5 100.000 (99.304)
Epoch: [25][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7216 (0.7242)	Acc@1 82.812 (85.006)	Acc@5 99.219 (99.334)
Max memory in training epoch: 65.9986944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 414684 ; 434302 ; 0.9548286676091752
[INFO] Storing checkpoint...
  72.03
Max memory: 102.5183232
 25.832s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7344
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1735168
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.194 (0.194)	Data 0.260 (0.260)	Loss 0.6979 (0.6979)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.132 (0.128)	Data 0.000 (0.004)	Loss 0.7329 (0.6864)	Acc@1 85.938 (86.304)	Acc@5 99.219 (99.411)
Epoch: [26][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7618 (0.7067)	Acc@1 85.156 (85.762)	Acc@5 99.609 (99.394)
Epoch: [26][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7405 (0.7209)	Acc@1 83.203 (85.122)	Acc@5 98.828 (99.391)
Max memory in training epoch: 65.822976
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.162 (0.162)	Data 0.289 (0.289)	Loss 0.7269 (0.7269)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.7885 (0.7077)	Acc@1 84.375 (85.475)	Acc@5 99.219 (99.435)
Epoch: [27][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7367 (0.7188)	Acc@1 82.422 (85.193)	Acc@5 100.000 (99.391)
Epoch: [27][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7450 (0.7293)	Acc@1 84.375 (84.948)	Acc@5 100.000 (99.344)
Max memory in training epoch: 65.6001536
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.165 (0.165)	Data 0.297 (0.297)	Loss 0.6933 (0.6933)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.8150 (0.7235)	Acc@1 79.688 (84.892)	Acc@5 99.609 (99.417)
Epoch: [28][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6585 (0.7215)	Acc@1 87.500 (85.244)	Acc@5 100.000 (99.319)
Epoch: [28][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7355 (0.7265)	Acc@1 83.984 (84.994)	Acc@5 100.000 (99.338)
Max memory in training epoch: 65.6001536
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.183 (0.183)	Data 0.270 (0.270)	Loss 0.7927 (0.7927)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [29][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.7293 (0.7184)	Acc@1 88.281 (85.174)	Acc@5 99.609 (99.399)
Epoch: [29][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7819 (0.7241)	Acc@1 83.984 (85.041)	Acc@5 98.828 (99.355)
Epoch: [29][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6478 (0.7207)	Acc@1 88.281 (85.132)	Acc@5 99.609 (99.385)
Max memory in training epoch: 65.6001536
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.183 (0.183)	Data 0.304 (0.304)	Loss 0.7186 (0.7186)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.6531 (0.7238)	Acc@1 88.281 (85.210)	Acc@5 98.828 (99.369)
Epoch: [30][128/196]	Time 0.136 (0.133)	Data 0.000 (0.003)	Loss 0.7778 (0.7256)	Acc@1 85.156 (85.029)	Acc@5 98.828 (99.319)
Epoch: [30][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.6851 (0.7219)	Acc@1 87.500 (85.144)	Acc@5 99.609 (99.381)
Max memory in training epoch: 65.6001536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 398234 ; 414684 ; 0.9603312401732403
[INFO] Storing checkpoint...
  73.38
Max memory: 102.1512192
 26.397s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4451
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1669632
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.202 (0.202)	Data 0.268 (0.268)	Loss 0.6990 (0.6990)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6526 (0.6849)	Acc@1 87.891 (86.274)	Acc@5 99.219 (99.423)
Epoch: [31][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7337 (0.7004)	Acc@1 85.938 (85.698)	Acc@5 98.828 (99.428)
Epoch: [31][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6908 (0.7088)	Acc@1 83.984 (85.427)	Acc@5 100.000 (99.423)
Max memory in training epoch: 65.691904
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.173 (0.173)	Data 0.282 (0.282)	Loss 0.6989 (0.6989)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [32][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6725 (0.7047)	Acc@1 86.328 (85.751)	Acc@5 100.000 (99.369)
Epoch: [32][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.8504 (0.7071)	Acc@1 82.812 (85.647)	Acc@5 99.219 (99.410)
Epoch: [32][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7401 (0.7127)	Acc@1 85.547 (85.468)	Acc@5 99.609 (99.393)
Max memory in training epoch: 65.4821888
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.173 (0.173)	Data 0.263 (0.263)	Loss 0.7452 (0.7452)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.7993 (0.7032)	Acc@1 84.375 (85.727)	Acc@5 98.828 (99.351)
Epoch: [33][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7539 (0.7078)	Acc@1 83.594 (85.553)	Acc@5 100.000 (99.410)
Epoch: [33][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7050 (0.7105)	Acc@1 86.328 (85.476)	Acc@5 98.828 (99.399)
Max memory in training epoch: 65.4821888
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.173 (0.173)	Data 0.280 (0.280)	Loss 0.6023 (0.6023)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.7449 (0.6834)	Acc@1 84.766 (86.406)	Acc@5 99.609 (99.483)
Epoch: [34][128/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6708 (0.7035)	Acc@1 84.375 (85.732)	Acc@5 100.000 (99.431)
Epoch: [34][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7380 (0.7025)	Acc@1 85.938 (85.822)	Acc@5 98.828 (99.423)
Max memory in training epoch: 65.4821888
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.184 (0.184)	Data 0.288 (0.288)	Loss 0.8014 (0.8014)	Acc@1 80.469 (80.469)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.6684 (0.7082)	Acc@1 85.938 (85.709)	Acc@5 99.609 (99.351)
Epoch: [35][128/196]	Time 0.137 (0.130)	Data 0.000 (0.002)	Loss 0.6200 (0.7074)	Acc@1 89.453 (85.701)	Acc@5 99.609 (99.334)
Epoch: [35][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7525 (0.7115)	Acc@1 85.547 (85.506)	Acc@5 98.828 (99.371)
Max memory in training epoch: 65.4821888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv30.weight

 RM:  module.conv31.weight
numoFStages: 3
Count: 387566 ; 398234 ; 0.9732117297870096
[INFO] Storing checkpoint...
  76.87
Max memory: 100.8323072
 26.078s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3656
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.162304
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.193 (0.193)	Data 0.284 (0.284)	Loss 0.6125 (0.6125)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.7235 (0.6844)	Acc@1 85.938 (86.472)	Acc@5 99.609 (99.387)
Epoch: [36][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.7181 (0.6951)	Acc@1 83.984 (86.022)	Acc@5 100.000 (99.410)
Epoch: [36][192/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.6677 (0.6985)	Acc@1 86.328 (85.891)	Acc@5 98.828 (99.411)
Max memory in training epoch: 63.6491264
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.171 (0.171)	Data 0.273 (0.273)	Loss 0.6793 (0.6793)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.124 (0.125)	Data 0.000 (0.004)	Loss 0.7260 (0.6883)	Acc@1 85.156 (86.004)	Acc@5 98.828 (99.489)
Epoch: [37][128/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.7640 (0.7010)	Acc@1 83.203 (85.704)	Acc@5 99.219 (99.431)
Epoch: [37][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.7631 (0.6998)	Acc@1 83.594 (85.782)	Acc@5 99.219 (99.433)
Max memory in training epoch: 63.6163584
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.183 (0.183)	Data 0.264 (0.264)	Loss 0.7315 (0.7315)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [38][64/196]	Time 0.123 (0.125)	Data 0.000 (0.004)	Loss 0.7036 (0.6900)	Acc@1 84.766 (86.010)	Acc@5 99.609 (99.363)
Epoch: [38][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.8113 (0.6990)	Acc@1 83.594 (85.819)	Acc@5 99.219 (99.285)
Epoch: [38][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.6332 (0.7063)	Acc@1 88.672 (85.504)	Acc@5 99.609 (99.306)
Max memory in training epoch: 63.6163584
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.148 (0.148)	Data 0.283 (0.283)	Loss 0.7087 (0.7087)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [39][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.6400 (0.6915)	Acc@1 88.281 (86.070)	Acc@5 98.438 (99.477)
Epoch: [39][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.7265 (0.7003)	Acc@1 85.156 (85.729)	Acc@5 99.219 (99.446)
Epoch: [39][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.6823 (0.7036)	Acc@1 86.719 (85.622)	Acc@5 99.609 (99.397)
Max memory in training epoch: 63.6163584
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.165 (0.165)	Data 0.268 (0.268)	Loss 0.7520 (0.7520)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.123 (0.125)	Data 0.000 (0.004)	Loss 0.7136 (0.6996)	Acc@1 83.984 (85.889)	Acc@5 99.609 (99.351)
Epoch: [40][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.7272 (0.6987)	Acc@1 84.766 (85.889)	Acc@5 100.000 (99.394)
Epoch: [40][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.7848 (0.7037)	Acc@1 83.594 (85.682)	Acc@5 99.219 (99.377)
Max memory in training epoch: 63.6163584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 380924 ; 387566 ; 0.9828622737804658
[INFO] Storing checkpoint...
  81.77
Max memory: 98.4563712
 24.641s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 547
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1596416
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.174 (0.174)	Data 0.274 (0.274)	Loss 0.6927 (0.6927)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.7304 (0.6685)	Acc@1 85.156 (86.406)	Acc@5 100.000 (99.627)
Epoch: [41][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7085 (0.6842)	Acc@1 83.984 (86.037)	Acc@5 99.219 (99.519)
Epoch: [41][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.7277 (0.6949)	Acc@1 83.594 (85.814)	Acc@5 98.828 (99.443)
Max memory in training epoch: 63.1993856
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.154 (0.154)	Data 0.294 (0.294)	Loss 0.6138 (0.6138)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.6260 (0.6766)	Acc@1 89.453 (86.791)	Acc@5 99.609 (99.543)
Epoch: [42][128/196]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.6030 (0.6873)	Acc@1 89.453 (86.262)	Acc@5 100.000 (99.555)
Epoch: [42][192/196]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.7239 (0.6939)	Acc@1 85.156 (86.051)	Acc@5 100.000 (99.520)
Max memory in training epoch: 63.5139584
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.153 (0.153)	Data 0.321 (0.321)	Loss 0.7703 (0.7703)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [43][64/196]	Time 0.125 (0.124)	Data 0.000 (0.005)	Loss 0.6372 (0.7074)	Acc@1 86.719 (85.559)	Acc@5 100.000 (99.477)
Epoch: [43][128/196]	Time 0.119 (0.124)	Data 0.000 (0.003)	Loss 0.6146 (0.6975)	Acc@1 87.891 (85.786)	Acc@5 100.000 (99.476)
Epoch: [43][192/196]	Time 0.129 (0.124)	Data 0.000 (0.002)	Loss 0.7996 (0.7002)	Acc@1 83.984 (85.680)	Acc@5 99.219 (99.449)
Max memory in training epoch: 63.5139584
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.183 (0.183)	Data 0.296 (0.296)	Loss 0.7294 (0.7294)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [44][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.7509 (0.6856)	Acc@1 84.766 (86.334)	Acc@5 99.609 (99.393)
Epoch: [44][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6356 (0.6915)	Acc@1 89.062 (86.249)	Acc@5 99.219 (99.419)
Epoch: [44][192/196]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.7112 (0.6942)	Acc@1 86.719 (86.178)	Acc@5 99.609 (99.421)
Max memory in training epoch: 63.5139584
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.173 (0.173)	Data 0.283 (0.283)	Loss 0.6627 (0.6627)	Acc@1 86.719 (86.719)	Acc@5 98.828 (98.828)
Epoch: [45][64/196]	Time 0.129 (0.124)	Data 0.000 (0.005)	Loss 0.6153 (0.6811)	Acc@1 89.844 (86.472)	Acc@5 100.000 (99.435)
Epoch: [45][128/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.7605 (0.6933)	Acc@1 83.594 (85.938)	Acc@5 99.219 (99.422)
Epoch: [45][192/196]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 0.8528 (0.6953)	Acc@1 83.594 (85.891)	Acc@5 99.219 (99.399)
Max memory in training epoch: 63.5139584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 377746 ; 380924 ; 0.99165712845607
[INFO] Storing checkpoint...
  77.06
Max memory: 98.0936704
 24.629s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1333
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1585152
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.204 (0.204)	Data 0.283 (0.283)	Loss 0.6366 (0.6366)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.118 (0.124)	Data 0.000 (0.005)	Loss 0.6743 (0.6572)	Acc@1 87.500 (87.218)	Acc@5 100.000 (99.531)
Epoch: [46][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.7470 (0.6817)	Acc@1 85.547 (86.383)	Acc@5 99.219 (99.482)
Epoch: [46][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.7438 (0.6845)	Acc@1 83.594 (86.361)	Acc@5 98.828 (99.462)
Max memory in training epoch: 62.8475392
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.161 (0.161)	Data 0.323 (0.323)	Loss 0.6561 (0.6561)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [47][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.7378 (0.7011)	Acc@1 84.766 (85.823)	Acc@5 100.000 (99.441)
Epoch: [47][128/196]	Time 0.122 (0.126)	Data 0.000 (0.003)	Loss 0.6396 (0.6889)	Acc@1 85.938 (86.183)	Acc@5 100.000 (99.464)
Epoch: [47][192/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.7117 (0.6955)	Acc@1 85.938 (85.940)	Acc@5 99.219 (99.437)
Max memory in training epoch: 62.736128
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.154 (0.154)	Data 0.296 (0.296)	Loss 0.6183 (0.6183)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.6831 (0.6887)	Acc@1 85.547 (86.046)	Acc@5 99.219 (99.471)
Epoch: [48][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.6466 (0.6845)	Acc@1 85.938 (86.222)	Acc@5 99.609 (99.446)
Epoch: [48][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6617 (0.6861)	Acc@1 87.500 (86.249)	Acc@5 99.609 (99.443)
Max memory in training epoch: 62.736128
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.197 (0.197)	Data 0.265 (0.265)	Loss 0.5818 (0.5818)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.6631 (0.6899)	Acc@1 88.672 (86.118)	Acc@5 99.609 (99.381)
Epoch: [49][128/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.8359 (0.6854)	Acc@1 79.688 (86.183)	Acc@5 98.438 (99.431)
Epoch: [49][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6029 (0.6890)	Acc@1 88.672 (86.081)	Acc@5 99.219 (99.447)
Max memory in training epoch: 62.736128
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.153 (0.153)	Data 0.303 (0.303)	Loss 0.6238 (0.6238)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.7476 (0.6857)	Acc@1 82.422 (86.172)	Acc@5 99.219 (99.441)
Epoch: [50][128/196]	Time 0.127 (0.123)	Data 0.000 (0.003)	Loss 0.6181 (0.6928)	Acc@1 89.453 (85.956)	Acc@5 100.000 (99.422)
Epoch: [50][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6509 (0.6873)	Acc@1 87.500 (86.170)	Acc@5 98.828 (99.415)
Max memory in training epoch: 62.736128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 372254 ; 377746 ; 0.9854611299656383
[INFO] Storing checkpoint...
  71.34
Max memory: 97.1963392
 24.493s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9831
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1563648
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.186 (0.186)	Data 0.271 (0.271)	Loss 0.7540 (0.7540)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.115 (0.124)	Data 0.000 (0.004)	Loss 0.6646 (0.6670)	Acc@1 87.109 (86.496)	Acc@5 99.609 (99.579)
Epoch: [51][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.6503 (0.6717)	Acc@1 89.062 (86.404)	Acc@5 98.438 (99.512)
Epoch: [51][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6765 (0.6827)	Acc@1 85.938 (86.160)	Acc@5 99.219 (99.504)
Max memory in training epoch: 62.2032384
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.152 (0.152)	Data 0.303 (0.303)	Loss 0.5922 (0.5922)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.128 (0.124)	Data 0.000 (0.005)	Loss 0.7838 (0.6893)	Acc@1 83.984 (86.112)	Acc@5 99.609 (99.471)
Epoch: [52][128/196]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.6463 (0.6861)	Acc@1 86.328 (86.137)	Acc@5 100.000 (99.470)
Epoch: [52][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6845 (0.6876)	Acc@1 85.156 (86.077)	Acc@5 99.609 (99.431)
Max memory in training epoch: 62.1377024
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.165 (0.165)	Data 0.270 (0.270)	Loss 0.6352 (0.6352)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [53][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.6341 (0.6731)	Acc@1 87.500 (86.400)	Acc@5 99.609 (99.441)
Epoch: [53][128/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.7288 (0.6771)	Acc@1 85.156 (86.531)	Acc@5 98.828 (99.434)
Epoch: [53][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6520 (0.6794)	Acc@1 87.500 (86.405)	Acc@5 100.000 (99.460)
Max memory in training epoch: 62.1377024
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.192 (0.192)	Data 0.271 (0.271)	Loss 0.6109 (0.6109)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [54][64/196]	Time 0.134 (0.125)	Data 0.000 (0.004)	Loss 0.6050 (0.6613)	Acc@1 89.844 (87.181)	Acc@5 100.000 (99.549)
Epoch: [54][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.6335 (0.6738)	Acc@1 89.062 (86.595)	Acc@5 100.000 (99.512)
Epoch: [54][192/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.6863 (0.6822)	Acc@1 87.109 (86.237)	Acc@5 98.828 (99.476)
Max memory in training epoch: 62.1377024
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.179 (0.179)	Data 0.306 (0.306)	Loss 0.6221 (0.6221)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.6465 (0.6751)	Acc@1 86.719 (86.569)	Acc@5 100.000 (99.345)
Epoch: [55][128/196]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.6325 (0.6798)	Acc@1 86.328 (86.428)	Acc@5 99.219 (99.379)
Epoch: [55][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.7321 (0.6868)	Acc@1 84.375 (86.154)	Acc@5 99.609 (99.360)
Max memory in training epoch: 62.1377024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 368498 ; 372254 ; 0.9899101151364391
[INFO] Storing checkpoint...
  78.61
Max memory: 95.81056
 25.029s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5897
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1549312
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.175 (0.175)	Data 0.262 (0.262)	Loss 0.6978 (0.6978)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.135 (0.125)	Data 0.000 (0.004)	Loss 0.6823 (0.6596)	Acc@1 87.109 (87.079)	Acc@5 99.609 (99.585)
Epoch: [56][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.6580 (0.6724)	Acc@1 87.500 (86.679)	Acc@5 100.000 (99.531)
Epoch: [56][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6542 (0.6787)	Acc@1 87.500 (86.452)	Acc@5 99.609 (99.510)
Max memory in training epoch: 61.8305024
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.172 (0.172)	Data 0.264 (0.264)	Loss 0.6191 (0.6191)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.127 (0.123)	Data 0.000 (0.004)	Loss 0.6479 (0.6798)	Acc@1 89.844 (86.010)	Acc@5 99.609 (99.579)
Epoch: [57][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6809 (0.6827)	Acc@1 85.938 (86.192)	Acc@5 100.000 (99.500)
Epoch: [57][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.5691 (0.6828)	Acc@1 90.234 (86.259)	Acc@5 100.000 (99.476)
Max memory in training epoch: 61.3979648
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.169 (0.169)	Data 0.273 (0.273)	Loss 0.7602 (0.7602)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [58][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.6448 (0.6811)	Acc@1 89.453 (86.376)	Acc@5 99.609 (99.447)
Epoch: [58][128/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.6323 (0.6798)	Acc@1 87.891 (86.392)	Acc@5 100.000 (99.461)
Epoch: [58][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.7364 (0.6778)	Acc@1 84.375 (86.520)	Acc@5 99.219 (99.447)
Max memory in training epoch: 61.345536
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.163 (0.163)	Data 0.286 (0.286)	Loss 0.7085 (0.7085)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [59][64/196]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.6806 (0.6874)	Acc@1 87.109 (86.250)	Acc@5 100.000 (99.477)
Epoch: [59][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.6218 (0.6847)	Acc@1 91.406 (86.255)	Acc@5 98.828 (99.485)
Epoch: [59][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6699 (0.6865)	Acc@1 87.109 (86.158)	Acc@5 99.609 (99.464)
Max memory in training epoch: 61.345536
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.190 (0.190)	Data 0.278 (0.278)	Loss 0.6585 (0.6585)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [60][64/196]	Time 0.138 (0.125)	Data 0.000 (0.004)	Loss 0.6814 (0.6755)	Acc@1 87.109 (86.334)	Acc@5 99.609 (99.489)
Epoch: [60][128/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.6931 (0.6716)	Acc@1 84.375 (86.561)	Acc@5 99.609 (99.503)
Epoch: [60][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7066 (0.6793)	Acc@1 85.938 (86.288)	Acc@5 100.000 (99.488)
Max memory in training epoch: 61.345536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 363728 ; 368498 ; 0.987055560681469
[INFO] Storing checkpoint...
  74.95
Max memory: 95.244288
 24.308s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9398
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1529344
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.196 (0.196)	Data 0.268 (0.268)	Loss 0.6905 (0.6905)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.6375 (0.6498)	Acc@1 87.109 (87.398)	Acc@5 99.609 (99.483)
Epoch: [61][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6453 (0.6599)	Acc@1 87.500 (86.952)	Acc@5 100.000 (99.528)
Epoch: [61][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.5814 (0.6683)	Acc@1 90.234 (86.755)	Acc@5 99.609 (99.486)
Max memory in training epoch: 60.62976
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.165 (0.165)	Data 0.327 (0.327)	Loss 0.6368 (0.6368)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.6656 (0.6813)	Acc@1 87.109 (86.154)	Acc@5 100.000 (99.477)
Epoch: [62][128/196]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.6944 (0.6832)	Acc@1 83.594 (86.210)	Acc@5 99.609 (99.455)
Epoch: [62][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.7520 (0.6784)	Acc@1 84.375 (86.401)	Acc@5 99.609 (99.460)
Max memory in training epoch: 60.4724736
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.159 (0.159)	Data 0.326 (0.326)	Loss 0.5794 (0.5794)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.7749 (0.6731)	Acc@1 84.375 (86.623)	Acc@5 99.219 (99.501)
Epoch: [63][128/196]	Time 0.113 (0.120)	Data 0.000 (0.003)	Loss 0.6438 (0.6774)	Acc@1 87.891 (86.371)	Acc@5 100.000 (99.491)
Epoch: [63][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.6559 (0.6816)	Acc@1 86.719 (86.243)	Acc@5 98.828 (99.468)
Max memory in training epoch: 60.4724736
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.160 (0.160)	Data 0.298 (0.298)	Loss 0.6735 (0.6735)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.6909 (0.6778)	Acc@1 87.109 (86.587)	Acc@5 100.000 (99.405)
Epoch: [64][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.7027 (0.6784)	Acc@1 84.375 (86.467)	Acc@5 99.609 (99.437)
Epoch: [64][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.7578 (0.6775)	Acc@1 86.719 (86.391)	Acc@5 99.219 (99.468)
Max memory in training epoch: 60.4724736
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.155 (0.155)	Data 0.290 (0.290)	Loss 0.6385 (0.6385)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.127 (0.122)	Data 0.000 (0.005)	Loss 0.6582 (0.6738)	Acc@1 87.891 (86.340)	Acc@5 99.219 (99.459)
Epoch: [65][128/196]	Time 0.135 (0.121)	Data 0.000 (0.002)	Loss 0.6385 (0.6750)	Acc@1 85.938 (86.358)	Acc@5 99.609 (99.482)
Epoch: [65][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.7035 (0.6748)	Acc@1 85.547 (86.464)	Acc@5 99.219 (99.490)
Max memory in training epoch: 60.4724736
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 360260 ; 363728 ; 0.9904654027185149
[INFO] Storing checkpoint...
  78.73
Max memory: 93.4245888
 23.936s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4075
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1516032
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.194 (0.194)	Data 0.253 (0.253)	Loss 0.6322 (0.6322)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [66][64/196]	Time 0.120 (0.125)	Data 0.000 (0.004)	Loss 0.7412 (0.6518)	Acc@1 82.812 (87.284)	Acc@5 99.609 (99.537)
Epoch: [66][128/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.6568 (0.6641)	Acc@1 86.719 (86.919)	Acc@5 99.609 (99.506)
Epoch: [66][192/196]	Time 0.120 (0.123)	Data 0.000 (0.001)	Loss 0.6079 (0.6689)	Acc@1 89.844 (86.721)	Acc@5 99.219 (99.480)
Max memory in training epoch: 59.890432
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.146 (0.146)	Data 0.299 (0.299)	Loss 0.7457 (0.7457)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 0.6594 (0.6835)	Acc@1 86.719 (86.088)	Acc@5 99.219 (99.375)
Epoch: [67][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.7027 (0.6724)	Acc@1 85.156 (86.498)	Acc@5 99.219 (99.355)
Epoch: [67][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.6702 (0.6750)	Acc@1 87.500 (86.524)	Acc@5 99.219 (99.389)
Max memory in training epoch: 59.75936
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.163 (0.163)	Data 0.271 (0.271)	Loss 0.6466 (0.6466)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.125 (0.124)	Data 0.000 (0.004)	Loss 0.7342 (0.6808)	Acc@1 82.422 (86.370)	Acc@5 98.438 (99.501)
Epoch: [68][128/196]	Time 0.134 (0.123)	Data 0.000 (0.002)	Loss 0.5638 (0.6719)	Acc@1 90.625 (86.486)	Acc@5 99.609 (99.497)
Epoch: [68][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6105 (0.6752)	Acc@1 87.891 (86.391)	Acc@5 99.609 (99.474)
Max memory in training epoch: 59.75936
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.149 (0.149)	Data 0.287 (0.287)	Loss 0.5753 (0.5753)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [69][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.6584 (0.6697)	Acc@1 87.891 (86.737)	Acc@5 99.609 (99.465)
Epoch: [69][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.5572 (0.6647)	Acc@1 88.672 (86.976)	Acc@5 99.609 (99.473)
Epoch: [69][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6568 (0.6700)	Acc@1 86.719 (86.814)	Acc@5 99.609 (99.494)
Max memory in training epoch: 59.75936
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.169 (0.169)	Data 0.265 (0.265)	Loss 0.6442 (0.6442)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [70][64/196]	Time 0.125 (0.125)	Data 0.000 (0.004)	Loss 0.6917 (0.6512)	Acc@1 85.938 (87.248)	Acc@5 99.219 (99.543)
Epoch: [70][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.6787 (0.6581)	Acc@1 87.891 (86.861)	Acc@5 99.609 (99.522)
Epoch: [70][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.5348 (0.6648)	Acc@1 90.625 (86.668)	Acc@5 99.609 (99.532)
Max memory in training epoch: 59.75936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356070 ; 360260 ; 0.9883695109087881
[INFO] Storing checkpoint...
  75.86
Max memory: 93.3886464
 25.049s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3532
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1501184
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.191 (0.191)	Data 0.284 (0.284)	Loss 0.7660 (0.7660)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [71][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.7615 (0.6481)	Acc@1 81.250 (87.061)	Acc@5 99.609 (99.519)
Epoch: [71][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6124 (0.6529)	Acc@1 87.891 (86.997)	Acc@5 98.828 (99.500)
Epoch: [71][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.7227 (0.6646)	Acc@1 84.375 (86.636)	Acc@5 98.828 (99.456)
Max memory in training epoch: 59.7140992
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.170 (0.170)	Data 0.258 (0.258)	Loss 0.6698 (0.6698)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.7091 (0.6578)	Acc@1 87.109 (86.941)	Acc@5 100.000 (99.531)
Epoch: [72][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7818 (0.6706)	Acc@1 80.859 (86.598)	Acc@5 98.828 (99.443)
Epoch: [72][192/196]	Time 0.122 (0.121)	Data 0.000 (0.001)	Loss 0.6794 (0.6665)	Acc@1 86.328 (86.723)	Acc@5 100.000 (99.466)
Max memory in training epoch: 59.56992
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.188 (0.188)	Data 0.299 (0.299)	Loss 0.7172 (0.7172)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [73][64/196]	Time 0.128 (0.122)	Data 0.000 (0.005)	Loss 0.5469 (0.6559)	Acc@1 89.844 (86.773)	Acc@5 100.000 (99.561)
Epoch: [73][128/196]	Time 0.122 (0.121)	Data 0.000 (0.003)	Loss 0.6992 (0.6622)	Acc@1 84.375 (86.640)	Acc@5 99.609 (99.516)
Epoch: [73][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.5889 (0.6672)	Acc@1 91.406 (86.504)	Acc@5 99.609 (99.478)
Max memory in training epoch: 59.56992
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.182 (0.182)	Data 0.267 (0.267)	Loss 0.5855 (0.5855)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.130 (0.122)	Data 0.000 (0.004)	Loss 0.7716 (0.6626)	Acc@1 82.031 (86.743)	Acc@5 100.000 (99.489)
Epoch: [74][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.7166 (0.6692)	Acc@1 84.766 (86.604)	Acc@5 99.609 (99.558)
Epoch: [74][192/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.6225 (0.6693)	Acc@1 87.500 (86.466)	Acc@5 100.000 (99.541)
Max memory in training epoch: 59.56992
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.147 (0.147)	Data 0.268 (0.268)	Loss 0.6361 (0.6361)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.6532 (0.6694)	Acc@1 88.672 (86.707)	Acc@5 99.219 (99.423)
Epoch: [75][128/196]	Time 0.140 (0.122)	Data 0.000 (0.002)	Loss 0.5928 (0.6660)	Acc@1 89.844 (86.701)	Acc@5 99.609 (99.494)
Epoch: [75][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.7292 (0.6710)	Acc@1 84.766 (86.437)	Acc@5 100.000 (99.464)
Max memory in training epoch: 59.56992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 348556 ; 356070 ; 0.9788974078130704
[INFO] Storing checkpoint...
  68.35
Max memory: 92.593664
 24.161s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5664
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1469952
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.194 (0.194)	Data 0.253 (0.253)	Loss 0.6746 (0.6746)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.6217 (0.6342)	Acc@1 88.281 (87.819)	Acc@5 99.609 (99.519)
Epoch: [76][128/196]	Time 0.116 (0.124)	Data 0.000 (0.002)	Loss 0.6651 (0.6463)	Acc@1 87.109 (87.433)	Acc@5 98.828 (99.494)
Epoch: [76][192/196]	Time 0.117 (0.123)	Data 0.000 (0.001)	Loss 0.6160 (0.6571)	Acc@1 89.062 (87.022)	Acc@5 99.219 (99.498)
Max memory in training epoch: 58.6792448
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.145 (0.145)	Data 0.306 (0.306)	Loss 0.5795 (0.5795)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.6709 (0.6573)	Acc@1 87.500 (86.875)	Acc@5 99.609 (99.447)
Epoch: [77][128/196]	Time 0.115 (0.122)	Data 0.000 (0.003)	Loss 0.7037 (0.6648)	Acc@1 85.156 (86.810)	Acc@5 98.828 (99.388)
Epoch: [77][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.6953 (0.6690)	Acc@1 85.547 (86.646)	Acc@5 98.828 (99.409)
Max memory in training epoch: 58.5874944
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.144 (0.144)	Data 0.295 (0.295)	Loss 0.6010 (0.6010)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.116 (0.121)	Data 0.000 (0.005)	Loss 0.7503 (0.6605)	Acc@1 84.375 (86.947)	Acc@5 100.000 (99.429)
Epoch: [78][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6263 (0.6645)	Acc@1 89.062 (86.761)	Acc@5 100.000 (99.488)
Epoch: [78][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.6294 (0.6661)	Acc@1 87.500 (86.701)	Acc@5 100.000 (99.496)
Max memory in training epoch: 58.5874944
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.155 (0.155)	Data 0.270 (0.270)	Loss 0.6481 (0.6481)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.7352 (0.6664)	Acc@1 81.250 (86.520)	Acc@5 99.609 (99.501)
Epoch: [79][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.7248 (0.6725)	Acc@1 83.203 (86.180)	Acc@5 99.609 (99.470)
Epoch: [79][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.5822 (0.6754)	Acc@1 87.891 (86.186)	Acc@5 99.609 (99.439)
Max memory in training epoch: 58.5874944
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.165 (0.165)	Data 0.269 (0.269)	Loss 0.6590 (0.6590)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.7392 (0.6548)	Acc@1 85.938 (87.001)	Acc@5 98.828 (99.447)
Epoch: [80][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.7636 (0.6594)	Acc@1 82.812 (86.816)	Acc@5 99.219 (99.461)
Epoch: [80][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6850 (0.6647)	Acc@1 84.375 (86.656)	Acc@5 99.609 (99.435)
Max memory in training epoch: 58.5874944
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 345604 ; 348556 ; 0.9915307726735446
[INFO] Storing checkpoint...
  82.96
Max memory: 91.2317952
 24.178s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3289
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1453568
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.173 (0.173)	Data 0.290 (0.290)	Loss 0.6270 (0.6270)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [81][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.6046 (0.6258)	Acc@1 89.844 (88.053)	Acc@5 100.000 (99.633)
Epoch: [81][128/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.6481 (0.6431)	Acc@1 84.375 (87.306)	Acc@5 99.609 (99.600)
Epoch: [81][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.6870 (0.6523)	Acc@1 84.766 (87.045)	Acc@5 99.219 (99.549)
Max memory in training epoch: 56.773376
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.161 (0.161)	Data 0.278 (0.278)	Loss 0.5901 (0.5901)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [82][64/196]	Time 0.123 (0.119)	Data 0.000 (0.004)	Loss 0.6982 (0.6595)	Acc@1 83.203 (86.899)	Acc@5 100.000 (99.531)
Epoch: [82][128/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.6893 (0.6589)	Acc@1 86.719 (86.979)	Acc@5 99.609 (99.537)
Epoch: [82][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.6729 (0.6604)	Acc@1 86.328 (86.939)	Acc@5 99.219 (99.526)
Max memory in training epoch: 56.7992832
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.166 (0.166)	Data 0.290 (0.290)	Loss 0.7073 (0.7073)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.114 (0.118)	Data 0.000 (0.005)	Loss 0.5866 (0.6624)	Acc@1 88.281 (86.484)	Acc@5 100.000 (99.495)
Epoch: [83][128/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.6930 (0.6628)	Acc@1 86.719 (86.652)	Acc@5 99.609 (99.491)
Epoch: [83][192/196]	Time 0.130 (0.117)	Data 0.000 (0.002)	Loss 0.6620 (0.6652)	Acc@1 88.281 (86.603)	Acc@5 99.219 (99.466)
Max memory in training epoch: 56.7992832
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.146 (0.146)	Data 0.311 (0.311)	Loss 0.7097 (0.7097)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.122 (0.119)	Data 0.000 (0.005)	Loss 0.6954 (0.6623)	Acc@1 84.375 (86.520)	Acc@5 99.609 (99.501)
Epoch: [84][128/196]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 0.6399 (0.6684)	Acc@1 87.891 (86.440)	Acc@5 99.609 (99.449)
Epoch: [84][192/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.7343 (0.6680)	Acc@1 83.594 (86.423)	Acc@5 99.609 (99.443)
Max memory in training epoch: 56.7992832
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.157 (0.157)	Data 0.306 (0.306)	Loss 0.6065 (0.6065)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [85][64/196]	Time 0.132 (0.119)	Data 0.000 (0.005)	Loss 0.6152 (0.6508)	Acc@1 88.672 (87.073)	Acc@5 99.219 (99.489)
Epoch: [85][128/196]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.6977 (0.6566)	Acc@1 87.500 (87.082)	Acc@5 99.219 (99.509)
Epoch: [85][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.6727 (0.6604)	Acc@1 85.156 (86.915)	Acc@5 100.000 (99.506)
Max memory in training epoch: 56.7992832
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 342714 ; 345604 ; 0.9916378282658765
[INFO] Storing checkpoint...
  80.04
Max memory: 88.5212672
 23.320s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2072
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1442304
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.199 (0.199)	Data 0.275 (0.275)	Loss 0.6426 (0.6426)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.113 (0.117)	Data 0.000 (0.004)	Loss 0.6674 (0.6276)	Acc@1 86.328 (87.770)	Acc@5 99.609 (99.543)
Epoch: [86][128/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.8378 (0.6423)	Acc@1 79.688 (87.346)	Acc@5 99.609 (99.525)
Epoch: [86][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.6103 (0.6508)	Acc@1 88.281 (87.107)	Acc@5 99.219 (99.498)
Max memory in training epoch: 56.4408832
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.146 (0.146)	Data 0.262 (0.262)	Loss 0.7349 (0.7349)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.114 (0.115)	Data 0.000 (0.004)	Loss 0.6000 (0.6547)	Acc@1 88.281 (86.977)	Acc@5 100.000 (99.513)
Epoch: [87][128/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.6941 (0.6599)	Acc@1 86.719 (86.788)	Acc@5 98.438 (99.485)
Epoch: [87][192/196]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.6741 (0.6663)	Acc@1 86.328 (86.607)	Acc@5 100.000 (99.484)
Max memory in training epoch: 56.5850624
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.159 (0.159)	Data 0.284 (0.284)	Loss 0.6617 (0.6617)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [88][64/196]	Time 0.116 (0.117)	Data 0.000 (0.005)	Loss 0.6801 (0.6358)	Acc@1 85.156 (87.728)	Acc@5 99.609 (99.549)
Epoch: [88][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.6771 (0.6387)	Acc@1 85.938 (87.639)	Acc@5 99.219 (99.549)
Epoch: [88][192/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.7010 (0.6519)	Acc@1 85.547 (87.138)	Acc@5 100.000 (99.520)
Max memory in training epoch: 56.5850624
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.158 (0.158)	Data 0.296 (0.296)	Loss 0.6002 (0.6002)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [89][64/196]	Time 0.106 (0.116)	Data 0.000 (0.005)	Loss 0.6073 (0.6502)	Acc@1 87.891 (87.410)	Acc@5 99.609 (99.513)
Epoch: [89][128/196]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.5814 (0.6521)	Acc@1 88.672 (87.164)	Acc@5 100.000 (99.476)
Epoch: [89][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.6503 (0.6596)	Acc@1 85.156 (86.850)	Acc@5 99.609 (99.435)
Max memory in training epoch: 56.5850624
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.156 (0.156)	Data 0.319 (0.319)	Loss 0.6083 (0.6083)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.115 (0.117)	Data 0.000 (0.005)	Loss 0.6974 (0.6426)	Acc@1 85.938 (87.272)	Acc@5 98.438 (99.507)
Epoch: [90][128/196]	Time 0.120 (0.117)	Data 0.000 (0.003)	Loss 0.6956 (0.6504)	Acc@1 84.766 (87.012)	Acc@5 99.609 (99.494)
Epoch: [90][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.7821 (0.6551)	Acc@1 83.594 (86.954)	Acc@5 99.609 (99.466)
Max memory in training epoch: 56.5850624
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 340982 ; 342714 ; 0.9949462233815951
[INFO] Storing checkpoint...
  73.77
Max memory: 87.6706304
 23.143s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3541
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1435136
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.183 (0.183)	Data 0.292 (0.292)	Loss 0.6133 (0.6133)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.115 (0.115)	Data 0.000 (0.005)	Loss 0.6541 (0.6279)	Acc@1 86.719 (87.704)	Acc@5 99.219 (99.573)
Epoch: [91][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.6034 (0.6526)	Acc@1 89.062 (86.861)	Acc@5 99.609 (99.476)
Epoch: [91][192/196]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.7616 (0.6554)	Acc@1 83.984 (86.864)	Acc@5 97.656 (99.472)
Max memory in training epoch: 56.4249088
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.160 (0.160)	Data 0.286 (0.286)	Loss 0.6150 (0.6150)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.116 (0.116)	Data 0.000 (0.005)	Loss 0.5895 (0.6546)	Acc@1 89.453 (87.055)	Acc@5 99.609 (99.501)
Epoch: [92][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.6200 (0.6518)	Acc@1 88.672 (87.043)	Acc@5 99.219 (99.537)
Epoch: [92][192/196]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.6701 (0.6603)	Acc@1 83.203 (86.755)	Acc@5 100.000 (99.510)
Max memory in training epoch: 56.4249088
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.140 (0.140)	Data 0.291 (0.291)	Loss 0.6483 (0.6483)	Acc@1 87.891 (87.891)	Acc@5 98.438 (98.438)
Epoch: [93][64/196]	Time 0.119 (0.116)	Data 0.000 (0.005)	Loss 0.4988 (0.5632)	Acc@1 92.969 (90.300)	Acc@5 99.609 (99.681)
Epoch: [93][128/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.5607 (0.5367)	Acc@1 89.062 (91.194)	Acc@5 99.219 (99.730)
Epoch: [93][192/196]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.4806 (0.5251)	Acc@1 93.750 (91.503)	Acc@5 100.000 (99.745)
Max memory in training epoch: 56.4249088
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.179 (0.179)	Data 0.265 (0.265)	Loss 0.4694 (0.4694)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.112 (0.117)	Data 0.000 (0.004)	Loss 0.4846 (0.4765)	Acc@1 92.188 (92.716)	Acc@5 99.609 (99.838)
Epoch: [94][128/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.4672 (0.4723)	Acc@1 93.750 (92.963)	Acc@5 100.000 (99.840)
Epoch: [94][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.4527 (0.4714)	Acc@1 93.750 (92.949)	Acc@5 99.609 (99.842)
Max memory in training epoch: 56.4249088
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.147 (0.147)	Data 0.270 (0.270)	Loss 0.4512 (0.4512)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.108 (0.116)	Data 0.000 (0.004)	Loss 0.4336 (0.4514)	Acc@1 95.312 (93.630)	Acc@5 100.000 (99.892)
Epoch: [95][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.4483 (0.4497)	Acc@1 92.578 (93.680)	Acc@5 100.000 (99.873)
Epoch: [95][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.4422 (0.4475)	Acc@1 93.750 (93.744)	Acc@5 100.000 (99.875)
Max memory in training epoch: 56.4249088
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.98
Max memory: 87.577344
 22.990s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3310
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1435136
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.195 (0.195)	Data 0.263 (0.263)	Loss 0.4389 (0.4389)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [96][64/196]	Time 0.115 (0.118)	Data 0.000 (0.004)	Loss 0.3917 (0.4278)	Acc@1 94.922 (94.333)	Acc@5 99.609 (99.868)
Epoch: [96][128/196]	Time 0.136 (0.117)	Data 0.000 (0.002)	Loss 0.3857 (0.4290)	Acc@1 95.703 (94.198)	Acc@5 100.000 (99.879)
Epoch: [96][192/196]	Time 0.108 (0.117)	Data 0.000 (0.002)	Loss 0.4131 (0.4292)	Acc@1 93.359 (94.137)	Acc@5 100.000 (99.889)
Max memory in training epoch: 56.4249088
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.159 (0.159)	Data 0.282 (0.282)	Loss 0.3878 (0.3878)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.116 (0.118)	Data 0.000 (0.005)	Loss 0.4363 (0.4029)	Acc@1 94.141 (95.012)	Acc@5 99.609 (99.892)
Epoch: [97][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.3900 (0.4104)	Acc@1 96.094 (94.683)	Acc@5 100.000 (99.903)
Epoch: [97][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3663 (0.4127)	Acc@1 96.094 (94.547)	Acc@5 100.000 (99.905)
Max memory in training epoch: 56.4249088
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.164 (0.164)	Data 0.269 (0.269)	Loss 0.4360 (0.4360)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.117 (0.118)	Data 0.000 (0.004)	Loss 0.3803 (0.4026)	Acc@1 94.922 (94.796)	Acc@5 100.000 (99.922)
Epoch: [98][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3838 (0.4052)	Acc@1 94.531 (94.628)	Acc@5 100.000 (99.906)
Epoch: [98][192/196]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.3962 (0.4036)	Acc@1 94.531 (94.673)	Acc@5 100.000 (99.897)
Max memory in training epoch: 56.4249088
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.159 (0.159)	Data 0.330 (0.330)	Loss 0.4277 (0.4277)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.117 (0.119)	Data 0.000 (0.005)	Loss 0.4109 (0.3946)	Acc@1 93.750 (94.952)	Acc@5 99.609 (99.910)
Epoch: [99][128/196]	Time 0.123 (0.118)	Data 0.000 (0.003)	Loss 0.3639 (0.3917)	Acc@1 95.703 (95.052)	Acc@5 100.000 (99.936)
Epoch: [99][192/196]	Time 0.122 (0.118)	Data 0.000 (0.002)	Loss 0.3813 (0.3922)	Acc@1 94.922 (94.985)	Acc@5 100.000 (99.917)
Max memory in training epoch: 56.4249088
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.138 (0.138)	Data 0.290 (0.290)	Loss 0.3814 (0.3814)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.117 (0.118)	Data 0.000 (0.005)	Loss 0.3728 (0.3846)	Acc@1 95.312 (95.174)	Acc@5 99.609 (99.886)
Epoch: [100][128/196]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.3980 (0.3838)	Acc@1 94.531 (95.185)	Acc@5 100.000 (99.912)
Epoch: [100][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3771 (0.3830)	Acc@1 94.531 (95.197)	Acc@5 100.000 (99.919)
Max memory in training epoch: 56.4249088
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 340548 ; 340982 ; 0.9987272055416415
[INFO] Storing checkpoint...
  91.29
Max memory: 87.577344
 23.357s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2482
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.14336
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.186 (0.186)	Data 0.279 (0.279)	Loss 0.4046 (0.4046)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.110 (0.115)	Data 0.000 (0.004)	Loss 0.3720 (0.3719)	Acc@1 96.094 (95.601)	Acc@5 100.000 (99.958)
Epoch: [101][128/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.3565 (0.3696)	Acc@1 95.703 (95.555)	Acc@5 100.000 (99.945)
Epoch: [101][192/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.3344 (0.3722)	Acc@1 96.875 (95.400)	Acc@5 100.000 (99.929)
Max memory in training epoch: 56.365312
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.147 (0.147)	Data 0.266 (0.266)	Loss 0.3386 (0.3386)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.112 (0.115)	Data 0.000 (0.004)	Loss 0.3716 (0.3619)	Acc@1 95.312 (95.487)	Acc@5 100.000 (99.940)
Epoch: [102][128/196]	Time 0.109 (0.114)	Data 0.000 (0.002)	Loss 0.3289 (0.3649)	Acc@1 98.438 (95.473)	Acc@5 99.609 (99.939)
Epoch: [102][192/196]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.4028 (0.3650)	Acc@1 94.141 (95.495)	Acc@5 100.000 (99.941)
Max memory in training epoch: 56.39808
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.161 (0.161)	Data 0.267 (0.267)	Loss 0.3681 (0.3681)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.112 (0.114)	Data 0.000 (0.004)	Loss 0.3054 (0.3489)	Acc@1 97.656 (95.787)	Acc@5 100.000 (99.958)
Epoch: [103][128/196]	Time 0.110 (0.114)	Data 0.000 (0.002)	Loss 0.3735 (0.3521)	Acc@1 96.094 (95.712)	Acc@5 99.609 (99.933)
Epoch: [103][192/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.3832 (0.3563)	Acc@1 93.359 (95.531)	Acc@5 100.000 (99.933)
Max memory in training epoch: 56.39808
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.162 (0.162)	Data 0.299 (0.299)	Loss 0.3227 (0.3227)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.118 (0.116)	Data 0.000 (0.005)	Loss 0.3758 (0.3455)	Acc@1 94.531 (95.823)	Acc@5 100.000 (99.946)
Epoch: [104][128/196]	Time 0.123 (0.118)	Data 0.000 (0.003)	Loss 0.3520 (0.3465)	Acc@1 94.922 (95.803)	Acc@5 100.000 (99.936)
Epoch: [104][192/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.3433 (0.3475)	Acc@1 94.922 (95.766)	Acc@5 100.000 (99.929)
Max memory in training epoch: 56.39808
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.167 (0.167)	Data 0.259 (0.259)	Loss 0.3551 (0.3551)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.117 (0.114)	Data 0.000 (0.004)	Loss 0.4045 (0.3406)	Acc@1 93.750 (95.865)	Acc@5 99.609 (99.970)
Epoch: [105][128/196]	Time 0.107 (0.114)	Data 0.000 (0.002)	Loss 0.3196 (0.3411)	Acc@1 97.266 (95.864)	Acc@5 100.000 (99.952)
Epoch: [105][192/196]	Time 0.111 (0.114)	Data 0.000 (0.002)	Loss 0.3081 (0.3423)	Acc@1 97.656 (95.752)	Acc@5 100.000 (99.945)
Max memory in training epoch: 56.39808
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 339970 ; 340548 ; 0.9983027355908712
[INFO] Storing checkpoint...
  91.02
Max memory: 87.4556416
 22.683s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9095
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1431552
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.178 (0.178)	Data 0.295 (0.295)	Loss 0.3265 (0.3265)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.126 (0.116)	Data 0.000 (0.005)	Loss 0.3058 (0.3287)	Acc@1 96.875 (96.196)	Acc@5 100.000 (99.976)
Epoch: [106][128/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.2989 (0.3301)	Acc@1 97.266 (96.163)	Acc@5 100.000 (99.964)
Epoch: [106][192/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.3698 (0.3332)	Acc@1 93.359 (95.993)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.3644928
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.139 (0.139)	Data 0.281 (0.281)	Loss 0.3711 (0.3711)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.112 (0.116)	Data 0.000 (0.005)	Loss 0.2999 (0.3282)	Acc@1 96.875 (96.316)	Acc@5 100.000 (99.964)
Epoch: [107][128/196]	Time 0.124 (0.116)	Data 0.000 (0.002)	Loss 0.3546 (0.3292)	Acc@1 95.312 (96.121)	Acc@5 100.000 (99.936)
Epoch: [107][192/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.3257 (0.3302)	Acc@1 97.266 (96.031)	Acc@5 99.609 (99.945)
Max memory in training epoch: 56.3972608
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.162 (0.162)	Data 0.282 (0.282)	Loss 0.3248 (0.3248)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.108 (0.116)	Data 0.000 (0.005)	Loss 0.3727 (0.3199)	Acc@1 95.312 (96.346)	Acc@5 100.000 (99.964)
Epoch: [108][128/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3133 (0.3248)	Acc@1 95.703 (96.163)	Acc@5 100.000 (99.942)
Epoch: [108][192/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3673 (0.3258)	Acc@1 96.094 (96.092)	Acc@5 100.000 (99.937)
Max memory in training epoch: 56.3972608
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.166 (0.166)	Data 0.272 (0.272)	Loss 0.2936 (0.2936)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.120 (0.117)	Data 0.000 (0.004)	Loss 0.3074 (0.3186)	Acc@1 96.875 (96.238)	Acc@5 100.000 (99.988)
Epoch: [109][128/196]	Time 0.122 (0.117)	Data 0.000 (0.002)	Loss 0.3196 (0.3200)	Acc@1 95.703 (96.191)	Acc@5 100.000 (99.964)
Epoch: [109][192/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.3094 (0.3240)	Acc@1 96.875 (96.009)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.3972608
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.150 (0.150)	Data 0.310 (0.310)	Loss 0.3180 (0.3180)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.3404 (0.3178)	Acc@1 94.922 (96.004)	Acc@5 100.000 (99.946)
Epoch: [110][128/196]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.3241 (0.3190)	Acc@1 95.703 (95.957)	Acc@5 100.000 (99.942)
Epoch: [110][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.3286 (0.3213)	Acc@1 95.312 (95.883)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.3972608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.76
Max memory: 87.6778496
 23.424s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9194
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1431552
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.165 (0.165)	Data 0.279 (0.279)	Loss 0.3078 (0.3078)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.117 (0.116)	Data 0.000 (0.004)	Loss 0.2670 (0.3042)	Acc@1 98.047 (96.653)	Acc@5 100.000 (99.934)
Epoch: [111][128/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2920 (0.3062)	Acc@1 96.484 (96.469)	Acc@5 100.000 (99.942)
Epoch: [111][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.2605 (0.3110)	Acc@1 98.047 (96.288)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.3644928
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.190 (0.190)	Data 0.274 (0.274)	Loss 0.3275 (0.3275)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.113 (0.117)	Data 0.000 (0.004)	Loss 0.3068 (0.3090)	Acc@1 96.094 (96.148)	Acc@5 100.000 (99.952)
Epoch: [112][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3226 (0.3082)	Acc@1 96.094 (96.309)	Acc@5 100.000 (99.952)
Epoch: [112][192/196]	Time 0.119 (0.115)	Data 0.000 (0.002)	Loss 0.4643 (0.3089)	Acc@1 91.406 (96.207)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.3972608
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.169 (0.169)	Data 0.297 (0.297)	Loss 0.2713 (0.2713)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.113 (0.116)	Data 0.000 (0.005)	Loss 0.3632 (0.3034)	Acc@1 93.750 (96.268)	Acc@5 99.609 (99.970)
Epoch: [113][128/196]	Time 0.121 (0.116)	Data 0.000 (0.002)	Loss 0.3080 (0.3042)	Acc@1 94.922 (96.260)	Acc@5 100.000 (99.967)
Epoch: [113][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3661 (0.3086)	Acc@1 93.359 (96.142)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.3972608
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.135 (0.135)	Data 0.264 (0.264)	Loss 0.3138 (0.3138)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.114 (0.115)	Data 0.000 (0.004)	Loss 0.2879 (0.2974)	Acc@1 96.875 (96.484)	Acc@5 100.000 (99.964)
Epoch: [114][128/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3162 (0.2996)	Acc@1 95.312 (96.294)	Acc@5 100.000 (99.958)
Epoch: [114][192/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.3165 (0.3041)	Acc@1 94.531 (96.165)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.3972608
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.142 (0.142)	Data 0.302 (0.302)	Loss 0.3468 (0.3468)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.118 (0.119)	Data 0.000 (0.005)	Loss 0.2877 (0.2979)	Acc@1 95.703 (96.202)	Acc@5 100.000 (99.964)
Epoch: [115][128/196]	Time 0.119 (0.119)	Data 0.000 (0.003)	Loss 0.2752 (0.2990)	Acc@1 98.438 (96.242)	Acc@5 100.000 (99.970)
Epoch: [115][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2771 (0.3026)	Acc@1 97.266 (96.110)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.3972608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 339680 ; 339970 ; 0.9991469835573727
[INFO] Storing checkpoint...
  89.85
Max memory: 87.6622848
 23.699s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4609
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1430528
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.164 (0.164)	Data 0.259 (0.259)	Loss 0.3417 (0.3417)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.117 (0.117)	Data 0.000 (0.004)	Loss 0.3282 (0.2876)	Acc@1 94.141 (96.707)	Acc@5 100.000 (99.970)
Epoch: [116][128/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.2804 (0.2927)	Acc@1 96.875 (96.487)	Acc@5 100.000 (99.967)
Epoch: [116][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.2630 (0.2983)	Acc@1 98.047 (96.264)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.1609216
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.151 (0.151)	Data 0.299 (0.299)	Loss 0.2658 (0.2658)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.112 (0.115)	Data 0.000 (0.005)	Loss 0.2772 (0.3044)	Acc@1 96.094 (96.016)	Acc@5 100.000 (99.970)
Epoch: [117][128/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2993 (0.3034)	Acc@1 96.094 (96.021)	Acc@5 99.609 (99.979)
Epoch: [117][192/196]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2829 (0.3027)	Acc@1 97.266 (96.049)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.143 (0.143)	Data 0.269 (0.269)	Loss 0.2859 (0.2859)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [118][64/196]	Time 0.132 (0.115)	Data 0.000 (0.004)	Loss 0.3143 (0.2892)	Acc@1 96.484 (96.460)	Acc@5 100.000 (99.952)
Epoch: [118][128/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.3332 (0.2974)	Acc@1 94.922 (96.151)	Acc@5 99.219 (99.952)
Epoch: [118][192/196]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.2656 (0.3017)	Acc@1 96.094 (95.993)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.143 (0.143)	Data 0.296 (0.296)	Loss 0.2986 (0.2986)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.128 (0.116)	Data 0.000 (0.005)	Loss 0.3137 (0.2950)	Acc@1 95.312 (96.136)	Acc@5 100.000 (99.976)
Epoch: [119][128/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.2514 (0.2984)	Acc@1 98.047 (96.088)	Acc@5 100.000 (99.967)
Epoch: [119][192/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.3105 (0.2965)	Acc@1 95.703 (96.088)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.157 (0.157)	Data 0.298 (0.298)	Loss 0.2668 (0.2668)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.116 (0.116)	Data 0.000 (0.005)	Loss 0.3174 (0.2880)	Acc@1 94.922 (96.262)	Acc@5 100.000 (99.976)
Epoch: [120][128/196]	Time 0.121 (0.115)	Data 0.000 (0.002)	Loss 0.3005 (0.2932)	Acc@1 96.094 (96.139)	Acc@5 99.609 (99.967)
Epoch: [120][192/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2844 (0.2952)	Acc@1 96.484 (96.092)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.2395648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.7
Max memory: 87.2556544
 22.889s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5988
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1430528
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.182 (0.182)	Data 0.281 (0.281)	Loss 0.2683 (0.2683)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.111 (0.118)	Data 0.000 (0.005)	Loss 0.3115 (0.2799)	Acc@1 95.703 (96.635)	Acc@5 100.000 (99.946)
Epoch: [121][128/196]	Time 0.128 (0.117)	Data 0.000 (0.002)	Loss 0.3258 (0.2883)	Acc@1 95.312 (96.306)	Acc@5 99.609 (99.964)
Epoch: [121][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3429 (0.2923)	Acc@1 94.141 (96.152)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.1609216
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.153 (0.153)	Data 0.294 (0.294)	Loss 0.2830 (0.2830)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.109 (0.117)	Data 0.000 (0.005)	Loss 0.2748 (0.2895)	Acc@1 96.484 (96.256)	Acc@5 100.000 (99.976)
Epoch: [122][128/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3343 (0.2934)	Acc@1 94.922 (96.063)	Acc@5 100.000 (99.970)
Epoch: [122][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3270 (0.2966)	Acc@1 94.922 (95.897)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.147 (0.147)	Data 0.300 (0.300)	Loss 0.3158 (0.3158)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.112 (0.117)	Data 0.000 (0.005)	Loss 0.3097 (0.2983)	Acc@1 96.094 (95.956)	Acc@5 100.000 (99.976)
Epoch: [123][128/196]	Time 0.118 (0.116)	Data 0.000 (0.003)	Loss 0.2862 (0.2978)	Acc@1 96.094 (96.006)	Acc@5 100.000 (99.961)
Epoch: [123][192/196]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.2754 (0.2982)	Acc@1 95.703 (95.883)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.161 (0.161)	Data 0.300 (0.300)	Loss 0.2602 (0.2602)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.110 (0.117)	Data 0.000 (0.005)	Loss 0.2468 (0.2848)	Acc@1 98.438 (96.382)	Acc@5 100.000 (99.958)
Epoch: [124][128/196]	Time 0.113 (0.116)	Data 0.000 (0.003)	Loss 0.2919 (0.2879)	Acc@1 94.922 (96.303)	Acc@5 100.000 (99.964)
Epoch: [124][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2732 (0.2915)	Acc@1 96.875 (96.138)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.163 (0.163)	Data 0.285 (0.285)	Loss 0.2636 (0.2636)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.2749 (0.2959)	Acc@1 96.484 (95.865)	Acc@5 100.000 (99.970)
Epoch: [125][128/196]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.2900 (0.2936)	Acc@1 94.141 (95.964)	Acc@5 100.000 (99.976)
Epoch: [125][192/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3054 (0.2947)	Acc@1 95.703 (95.879)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.2395648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.52
Max memory: 87.2556544
 23.375s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4337
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1430528
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.179 (0.179)	Data 0.260 (0.260)	Loss 0.2724 (0.2724)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.114 (0.119)	Data 0.000 (0.004)	Loss 0.2810 (0.2802)	Acc@1 96.484 (96.526)	Acc@5 100.000 (99.976)
Epoch: [126][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3236 (0.2879)	Acc@1 94.141 (96.236)	Acc@5 100.000 (99.970)
Epoch: [126][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3391 (0.2910)	Acc@1 92.969 (96.039)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.1609216
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.158 (0.158)	Data 0.260 (0.260)	Loss 0.3068 (0.3068)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [127][64/196]	Time 0.119 (0.116)	Data 0.000 (0.004)	Loss 0.3170 (0.2957)	Acc@1 95.703 (95.847)	Acc@5 100.000 (99.970)
Epoch: [127][128/196]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.2678 (0.2953)	Acc@1 97.266 (95.882)	Acc@5 100.000 (99.967)
Epoch: [127][192/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3023 (0.2968)	Acc@1 95.312 (95.812)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.174 (0.174)	Data 0.268 (0.268)	Loss 0.2816 (0.2816)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.116 (0.116)	Data 0.000 (0.004)	Loss 0.3171 (0.2812)	Acc@1 95.703 (96.280)	Acc@5 100.000 (99.988)
Epoch: [128][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2772 (0.2864)	Acc@1 96.094 (96.166)	Acc@5 100.000 (99.985)
Epoch: [128][192/196]	Time 0.119 (0.115)	Data 0.000 (0.002)	Loss 0.2977 (0.2927)	Acc@1 96.875 (95.883)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.145 (0.145)	Data 0.299 (0.299)	Loss 0.3300 (0.3300)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.119 (0.117)	Data 0.000 (0.005)	Loss 0.2756 (0.2879)	Acc@1 97.266 (96.118)	Acc@5 100.000 (99.946)
Epoch: [129][128/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2987 (0.2923)	Acc@1 95.703 (95.876)	Acc@5 100.000 (99.955)
Epoch: [129][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2605 (0.2934)	Acc@1 96.875 (95.867)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.2395648
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.165 (0.165)	Data 0.304 (0.304)	Loss 0.2624 (0.2624)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.114 (0.116)	Data 0.000 (0.005)	Loss 0.3006 (0.2933)	Acc@1 95.312 (95.817)	Acc@5 100.000 (99.952)
Epoch: [130][128/196]	Time 0.112 (0.116)	Data 0.000 (0.003)	Loss 0.2700 (0.2899)	Acc@1 96.484 (95.942)	Acc@5 100.000 (99.964)
Epoch: [130][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.2744 (0.2931)	Acc@1 94.922 (95.847)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.2395648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 339390 ; 339680 ; 0.9991462552991051
[INFO] Storing checkpoint...
  89.94
Max memory: 87.2556544
 23.042s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1308
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.142848
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.183 (0.183)	Data 0.288 (0.288)	Loss 0.2341 (0.2341)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.127 (0.116)	Data 0.000 (0.005)	Loss 0.3148 (0.2774)	Acc@1 94.531 (96.376)	Acc@5 100.000 (99.952)
Epoch: [131][128/196]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2724 (0.2838)	Acc@1 96.875 (96.091)	Acc@5 100.000 (99.964)
Epoch: [131][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3167 (0.2853)	Acc@1 94.922 (96.043)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.8651904
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.175 (0.175)	Data 0.267 (0.267)	Loss 0.2769 (0.2769)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [132][64/196]	Time 0.113 (0.116)	Data 0.000 (0.004)	Loss 0.2831 (0.2817)	Acc@1 98.047 (96.202)	Acc@5 100.000 (99.970)
Epoch: [132][128/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3355 (0.2864)	Acc@1 94.922 (96.042)	Acc@5 99.609 (99.961)
Epoch: [132][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.2995 (0.2933)	Acc@1 95.703 (95.814)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.1273344
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.166 (0.166)	Data 0.257 (0.257)	Loss 0.2850 (0.2850)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [133][64/196]	Time 0.117 (0.116)	Data 0.000 (0.004)	Loss 0.3101 (0.2815)	Acc@1 94.922 (96.238)	Acc@5 100.000 (99.982)
Epoch: [133][128/196]	Time 0.107 (0.116)	Data 0.000 (0.002)	Loss 0.2872 (0.2871)	Acc@1 96.094 (96.033)	Acc@5 100.000 (99.970)
Epoch: [133][192/196]	Time 0.110 (0.115)	Data 0.000 (0.001)	Loss 0.3370 (0.2937)	Acc@1 94.531 (95.812)	Acc@5 99.609 (99.968)
Max memory in training epoch: 56.1273344
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.149 (0.149)	Data 0.303 (0.303)	Loss 0.2574 (0.2574)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.113 (0.115)	Data 0.000 (0.005)	Loss 0.2869 (0.2927)	Acc@1 96.094 (95.877)	Acc@5 100.000 (99.958)
Epoch: [134][128/196]	Time 0.121 (0.114)	Data 0.000 (0.003)	Loss 0.3265 (0.2939)	Acc@1 93.750 (95.770)	Acc@5 100.000 (99.970)
Epoch: [134][192/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.3521 (0.2967)	Acc@1 93.359 (95.632)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.1273344
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.159 (0.159)	Data 0.282 (0.282)	Loss 0.2831 (0.2831)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.116 (0.116)	Data 0.000 (0.005)	Loss 0.3110 (0.2796)	Acc@1 94.141 (96.244)	Acc@5 100.000 (99.982)
Epoch: [135][128/196]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.3174 (0.2884)	Acc@1 94.531 (95.900)	Acc@5 100.000 (99.976)
Epoch: [135][192/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.3189 (0.2930)	Acc@1 95.703 (95.768)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.1273344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 338956 ; 339390 ; 0.9987212351571938
[INFO] Storing checkpoint...
  89.88
Max memory: 86.5314816
 22.938s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6161
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1426944
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.187 (0.187)	Data 0.284 (0.284)	Loss 0.2511 (0.2511)	Acc@1 97.656 (97.656)	Acc@5 99.609 (99.609)
Epoch: [136][64/196]	Time 0.113 (0.118)	Data 0.000 (0.005)	Loss 0.2302 (0.2726)	Acc@1 98.047 (96.647)	Acc@5 100.000 (99.970)
Epoch: [136][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3076 (0.2794)	Acc@1 95.312 (96.336)	Acc@5 100.000 (99.979)
Epoch: [136][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.2612 (0.2848)	Acc@1 96.484 (96.110)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.8121472
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.172 (0.172)	Data 0.277 (0.277)	Loss 0.2694 (0.2694)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.117 (0.117)	Data 0.000 (0.004)	Loss 0.2850 (0.2800)	Acc@1 95.703 (96.244)	Acc@5 100.000 (99.970)
Epoch: [137][128/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.2947 (0.2861)	Acc@1 95.703 (95.951)	Acc@5 100.000 (99.982)
Epoch: [137][192/196]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.3210 (0.2895)	Acc@1 94.531 (95.821)	Acc@5 100.000 (99.962)
Max memory in training epoch: 55.9759872
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.157 (0.157)	Data 0.287 (0.287)	Loss 0.2726 (0.2726)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.111 (0.116)	Data 0.000 (0.005)	Loss 0.2826 (0.2958)	Acc@1 95.703 (95.673)	Acc@5 100.000 (99.976)
Epoch: [138][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.2716 (0.2966)	Acc@1 96.094 (95.615)	Acc@5 100.000 (99.982)
Epoch: [138][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3354 (0.2964)	Acc@1 94.922 (95.559)	Acc@5 99.609 (99.980)
Max memory in training epoch: 55.9759872
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.171 (0.171)	Data 0.278 (0.278)	Loss 0.3077 (0.3077)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.114 (0.118)	Data 0.000 (0.004)	Loss 0.3123 (0.2903)	Acc@1 94.922 (95.877)	Acc@5 100.000 (99.982)
Epoch: [139][128/196]	Time 0.107 (0.117)	Data 0.000 (0.002)	Loss 0.3294 (0.2899)	Acc@1 94.141 (95.894)	Acc@5 100.000 (99.967)
Epoch: [139][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2596 (0.2918)	Acc@1 97.656 (95.782)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.9759872
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.163 (0.163)	Data 0.285 (0.285)	Loss 0.2775 (0.2775)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.117 (0.115)	Data 0.000 (0.005)	Loss 0.3154 (0.2862)	Acc@1 95.703 (95.925)	Acc@5 100.000 (99.982)
Epoch: [140][128/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.2984 (0.2914)	Acc@1 95.703 (95.855)	Acc@5 100.000 (99.979)
Epoch: [140][192/196]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.2627 (0.2950)	Acc@1 97.266 (95.701)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.9759872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 337802 ; 338956 ; 0.9965954283151796
[INFO] Storing checkpoint...
  90.53
Max memory: 87.0055424
 22.925s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6959
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1422848
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.184 (0.184)	Data 0.290 (0.290)	Loss 0.3161 (0.3161)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.113 (0.114)	Data 0.000 (0.005)	Loss 0.2445 (0.2743)	Acc@1 97.266 (96.520)	Acc@5 100.000 (99.976)
Epoch: [141][128/196]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.2515 (0.2779)	Acc@1 96.484 (96.324)	Acc@5 100.000 (99.976)
Epoch: [141][192/196]	Time 0.117 (0.114)	Data 0.000 (0.002)	Loss 0.3012 (0.2838)	Acc@1 94.922 (96.100)	Acc@5 100.000 (99.972)
Max memory in training epoch: 55.8105088
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.167 (0.167)	Data 0.314 (0.314)	Loss 0.2813 (0.2813)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.115 (0.116)	Data 0.000 (0.005)	Loss 0.2772 (0.2789)	Acc@1 97.266 (96.226)	Acc@5 100.000 (99.952)
Epoch: [142][128/196]	Time 0.131 (0.115)	Data 0.000 (0.003)	Loss 0.2802 (0.2848)	Acc@1 96.875 (95.982)	Acc@5 99.609 (99.961)
Epoch: [142][192/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.3457 (0.2902)	Acc@1 94.141 (95.800)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.9743488
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.161 (0.161)	Data 0.267 (0.267)	Loss 0.2794 (0.2794)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.114 (0.113)	Data 0.000 (0.004)	Loss 0.3264 (0.2956)	Acc@1 94.141 (95.679)	Acc@5 100.000 (99.958)
Epoch: [143][128/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.2748 (0.2907)	Acc@1 96.875 (95.836)	Acc@5 100.000 (99.955)
Epoch: [143][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3410 (0.2929)	Acc@1 94.531 (95.752)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.9743488
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.138 (0.138)	Data 0.264 (0.264)	Loss 0.2724 (0.2724)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.118 (0.115)	Data 0.000 (0.004)	Loss 0.3235 (0.2913)	Acc@1 95.312 (95.763)	Acc@5 100.000 (99.946)
Epoch: [144][128/196]	Time 0.120 (0.114)	Data 0.000 (0.002)	Loss 0.3184 (0.2921)	Acc@1 94.531 (95.703)	Acc@5 100.000 (99.955)
Epoch: [144][192/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.3710 (0.2985)	Acc@1 93.750 (95.505)	Acc@5 100.000 (99.951)
Max memory in training epoch: 55.9743488
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.156 (0.156)	Data 0.312 (0.312)	Loss 0.2782 (0.2782)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.111 (0.115)	Data 0.000 (0.005)	Loss 0.2990 (0.2881)	Acc@1 94.531 (95.956)	Acc@5 100.000 (99.976)
Epoch: [145][128/196]	Time 0.115 (0.114)	Data 0.000 (0.003)	Loss 0.2899 (0.2891)	Acc@1 94.922 (95.891)	Acc@5 100.000 (99.964)
Epoch: [145][192/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.2905 (0.2926)	Acc@1 94.922 (95.742)	Acc@5 100.000 (99.949)
Max memory in training epoch: 55.9743488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.95
Max memory: 86.7036672
 22.716s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6190
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1422848
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.201 (0.201)	Data 0.267 (0.267)	Loss 0.2823 (0.2823)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.112 (0.120)	Data 0.000 (0.004)	Loss 0.2913 (0.2731)	Acc@1 95.312 (96.472)	Acc@5 100.000 (99.964)
Epoch: [146][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3267 (0.2820)	Acc@1 93.750 (96.130)	Acc@5 100.000 (99.961)
Epoch: [146][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.2873 (0.2900)	Acc@1 96.484 (95.855)	Acc@5 100.000 (99.957)
Max memory in training epoch: 55.8105088
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.167 (0.167)	Data 0.267 (0.267)	Loss 0.2794 (0.2794)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [147][64/196]	Time 0.109 (0.120)	Data 0.000 (0.004)	Loss 0.2816 (0.2875)	Acc@1 95.312 (95.847)	Acc@5 100.000 (99.976)
Epoch: [147][128/196]	Time 0.135 (0.119)	Data 0.000 (0.002)	Loss 0.3056 (0.2897)	Acc@1 96.484 (95.809)	Acc@5 100.000 (99.973)
Epoch: [147][192/196]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.2719 (0.2888)	Acc@1 97.656 (95.853)	Acc@5 100.000 (99.972)
Max memory in training epoch: 55.9743488
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.159 (0.159)	Data 0.300 (0.300)	Loss 0.2859 (0.2859)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.117 (0.117)	Data 0.000 (0.005)	Loss 0.2994 (0.2799)	Acc@1 94.922 (96.178)	Acc@5 100.000 (99.958)
Epoch: [148][128/196]	Time 0.123 (0.118)	Data 0.000 (0.002)	Loss 0.3457 (0.2897)	Acc@1 93.359 (95.809)	Acc@5 99.609 (99.945)
Epoch: [148][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.2547 (0.2944)	Acc@1 98.047 (95.693)	Acc@5 100.000 (99.943)
Max memory in training epoch: 55.9743488
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.171 (0.171)	Data 0.296 (0.296)	Loss 0.3088 (0.3088)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 0.3042 (0.2852)	Acc@1 94.922 (96.028)	Acc@5 100.000 (99.958)
Epoch: [149][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.2892 (0.2842)	Acc@1 96.484 (96.097)	Acc@5 100.000 (99.961)
Epoch: [149][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.2704 (0.2901)	Acc@1 96.094 (95.841)	Acc@5 100.000 (99.957)
Max memory in training epoch: 55.9743488
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.140 (0.140)	Data 0.266 (0.266)	Loss 0.3204 (0.3204)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.110 (0.118)	Data 0.000 (0.004)	Loss 0.2396 (0.2641)	Acc@1 98.438 (96.761)	Acc@5 100.000 (99.970)
Epoch: [150][128/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.2144 (0.2541)	Acc@1 97.656 (97.141)	Acc@5 100.000 (99.979)
Epoch: [150][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2043 (0.2482)	Acc@1 99.609 (97.407)	Acc@5 100.000 (99.982)
Max memory in training epoch: 55.9743488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.83
Max memory: 86.6856448
 23.390s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4161
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1422848
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.194 (0.194)	Data 0.264 (0.264)	Loss 0.2172 (0.2172)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.116 (0.117)	Data 0.000 (0.004)	Loss 0.2425 (0.2296)	Acc@1 96.484 (98.119)	Acc@5 100.000 (99.988)
Epoch: [151][128/196]	Time 0.114 (0.115)	Data 0.000 (0.002)	Loss 0.2178 (0.2297)	Acc@1 97.656 (98.138)	Acc@5 100.000 (99.991)
Epoch: [151][192/196]	Time 0.108 (0.114)	Data 0.000 (0.002)	Loss 0.2144 (0.2284)	Acc@1 98.828 (98.180)	Acc@5 100.000 (99.988)
Max memory in training epoch: 55.8105088
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.165 (0.165)	Data 0.264 (0.264)	Loss 0.2070 (0.2070)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.115 (0.117)	Data 0.000 (0.004)	Loss 0.2044 (0.2159)	Acc@1 98.828 (98.624)	Acc@5 100.000 (99.994)
Epoch: [152][128/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.2233 (0.2175)	Acc@1 99.219 (98.531)	Acc@5 100.000 (99.997)
Epoch: [152][192/196]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.1882 (0.2179)	Acc@1 99.609 (98.527)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.9743488
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.165 (0.165)	Data 0.315 (0.315)	Loss 0.2267 (0.2267)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.114 (0.116)	Data 0.000 (0.005)	Loss 0.2064 (0.2149)	Acc@1 98.438 (98.588)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.112 (0.115)	Data 0.000 (0.003)	Loss 0.2336 (0.2147)	Acc@1 97.656 (98.595)	Acc@5 100.000 (99.988)
Epoch: [153][192/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.1882 (0.2149)	Acc@1 99.609 (98.601)	Acc@5 100.000 (99.982)
Max memory in training epoch: 55.9743488
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.157 (0.157)	Data 0.269 (0.269)	Loss 0.2125 (0.2125)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.111 (0.113)	Data 0.000 (0.004)	Loss 0.2395 (0.2119)	Acc@1 98.047 (98.744)	Acc@5 100.000 (100.000)
Epoch: [154][128/196]	Time 0.115 (0.113)	Data 0.000 (0.002)	Loss 0.2292 (0.2112)	Acc@1 98.047 (98.752)	Acc@5 100.000 (99.994)
Epoch: [154][192/196]	Time 0.115 (0.114)	Data 0.000 (0.002)	Loss 0.1931 (0.2108)	Acc@1 99.609 (98.792)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9743488
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.144 (0.144)	Data 0.287 (0.287)	Loss 0.1893 (0.1893)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.119 (0.115)	Data 0.000 (0.005)	Loss 0.2166 (0.2078)	Acc@1 98.438 (98.876)	Acc@5 100.000 (99.982)
Epoch: [155][128/196]	Time 0.108 (0.115)	Data 0.000 (0.002)	Loss 0.2317 (0.2081)	Acc@1 97.656 (98.840)	Acc@5 100.000 (99.991)
Epoch: [155][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.2033 (0.2084)	Acc@1 99.219 (98.820)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9743488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 336648 ; 337802 ; 0.9965837976092504
[INFO] Storing checkpoint...
  92.22
Max memory: 86.6856448
 22.801s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6907
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1417728
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.181 (0.181)	Data 0.327 (0.327)	Loss 0.1910 (0.1910)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.117 (0.116)	Data 0.000 (0.005)	Loss 0.2085 (0.2029)	Acc@1 99.219 (98.936)	Acc@5 100.000 (99.988)
Epoch: [156][128/196]	Time 0.112 (0.116)	Data 0.000 (0.003)	Loss 0.2109 (0.2062)	Acc@1 98.047 (98.861)	Acc@5 100.000 (99.988)
Epoch: [156][192/196]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.2029 (0.2066)	Acc@1 98.828 (98.850)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.8084608
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.162 (0.162)	Data 0.294 (0.294)	Loss 0.2092 (0.2092)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.117 (0.117)	Data 0.000 (0.005)	Loss 0.2287 (0.2038)	Acc@1 98.438 (98.954)	Acc@5 100.000 (99.994)
Epoch: [157][128/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.2047 (0.2046)	Acc@1 98.828 (98.877)	Acc@5 100.000 (99.994)
Epoch: [157][192/196]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.2274 (0.2037)	Acc@1 98.047 (98.901)	Acc@5 99.609 (99.990)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.167 (0.167)	Data 0.268 (0.268)	Loss 0.2038 (0.2038)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.113 (0.116)	Data 0.000 (0.004)	Loss 0.1904 (0.2007)	Acc@1 99.609 (99.075)	Acc@5 100.000 (99.982)
Epoch: [158][128/196]	Time 0.117 (0.115)	Data 0.000 (0.002)	Loss 0.1868 (0.2014)	Acc@1 100.000 (99.019)	Acc@5 100.000 (99.991)
Epoch: [158][192/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.1914 (0.2019)	Acc@1 99.219 (98.968)	Acc@5 100.000 (99.990)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.159 (0.159)	Data 0.260 (0.260)	Loss 0.1942 (0.1942)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.114 (0.114)	Data 0.000 (0.004)	Loss 0.1945 (0.1992)	Acc@1 98.828 (99.056)	Acc@5 100.000 (99.994)
Epoch: [159][128/196]	Time 0.114 (0.114)	Data 0.000 (0.002)	Loss 0.1860 (0.1999)	Acc@1 100.000 (99.028)	Acc@5 100.000 (99.994)
Epoch: [159][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.2227 (0.1992)	Acc@1 98.438 (99.035)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.143 (0.143)	Data 0.287 (0.287)	Loss 0.1974 (0.1974)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.111 (0.116)	Data 0.000 (0.005)	Loss 0.2036 (0.2008)	Acc@1 98.828 (99.044)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.1995 (0.1996)	Acc@1 98.828 (99.070)	Acc@5 100.000 (99.991)
Epoch: [160][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.1875 (0.1983)	Acc@1 99.219 (99.111)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.9723008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.43
Max memory: 86.9069312
 23.195s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1381
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1417728
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.184 (0.184)	Data 0.293 (0.293)	Loss 0.1916 (0.1916)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.129 (0.116)	Data 0.000 (0.005)	Loss 0.1850 (0.1943)	Acc@1 99.609 (99.207)	Acc@5 100.000 (99.994)
Epoch: [161][128/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2103 (0.1958)	Acc@1 98.828 (99.179)	Acc@5 100.000 (99.991)
Epoch: [161][192/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.2028 (0.1967)	Acc@1 98.828 (99.116)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.8084608
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.171 (0.171)	Data 0.278 (0.278)	Loss 0.2081 (0.2081)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.115 (0.116)	Data 0.000 (0.004)	Loss 0.2013 (0.1993)	Acc@1 98.438 (98.894)	Acc@5 100.000 (99.988)
Epoch: [162][128/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2009 (0.1968)	Acc@1 98.828 (99.046)	Acc@5 100.000 (99.994)
Epoch: [162][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2182 (0.1965)	Acc@1 98.438 (99.075)	Acc@5 100.000 (99.990)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.148 (0.148)	Data 0.302 (0.302)	Loss 0.1944 (0.1944)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.110 (0.116)	Data 0.000 (0.005)	Loss 0.1808 (0.1929)	Acc@1 99.609 (99.225)	Acc@5 100.000 (99.994)
Epoch: [163][128/196]	Time 0.113 (0.115)	Data 0.000 (0.003)	Loss 0.1875 (0.1930)	Acc@1 99.609 (99.191)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.128 (0.115)	Data 0.000 (0.002)	Loss 0.2051 (0.1933)	Acc@1 97.656 (99.182)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.160 (0.160)	Data 0.287 (0.287)	Loss 0.1948 (0.1948)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.106 (0.116)	Data 0.000 (0.005)	Loss 0.1851 (0.1909)	Acc@1 99.609 (99.315)	Acc@5 100.000 (99.994)
Epoch: [164][128/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.1946 (0.1905)	Acc@1 98.828 (99.310)	Acc@5 100.000 (99.994)
Epoch: [164][192/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1958 (0.1920)	Acc@1 99.609 (99.243)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.142 (0.142)	Data 0.300 (0.300)	Loss 0.1915 (0.1915)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.115 (0.116)	Data 0.000 (0.005)	Loss 0.1715 (0.1881)	Acc@1 100.000 (99.369)	Acc@5 100.000 (99.976)
Epoch: [165][128/196]	Time 0.114 (0.115)	Data 0.000 (0.003)	Loss 0.1887 (0.1898)	Acc@1 99.609 (99.349)	Acc@5 100.000 (99.985)
Epoch: [165][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2278 (0.1904)	Acc@1 97.266 (99.281)	Acc@5 100.000 (99.988)
Max memory in training epoch: 55.9723008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.43
Max memory: 87.0380032
 23.010s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5516
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1417728
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.175 (0.175)	Data 0.285 (0.285)	Loss 0.1838 (0.1838)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.116 (0.119)	Data 0.000 (0.005)	Loss 0.1782 (0.1874)	Acc@1 99.609 (99.411)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.1815 (0.1879)	Acc@1 99.609 (99.379)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.1861 (0.1889)	Acc@1 99.219 (99.330)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.8084608
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.160 (0.160)	Data 0.285 (0.285)	Loss 0.1726 (0.1726)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.118 (0.116)	Data 0.000 (0.005)	Loss 0.1790 (0.1883)	Acc@1 100.000 (99.327)	Acc@5 100.000 (99.994)
Epoch: [167][128/196]	Time 0.110 (0.115)	Data 0.000 (0.002)	Loss 0.1888 (0.1879)	Acc@1 98.438 (99.337)	Acc@5 100.000 (99.997)
Epoch: [167][192/196]	Time 0.112 (0.114)	Data 0.000 (0.002)	Loss 0.1796 (0.1874)	Acc@1 99.609 (99.377)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.136 (0.136)	Data 0.295 (0.295)	Loss 0.1860 (0.1860)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.115 (0.116)	Data 0.000 (0.005)	Loss 0.1947 (0.1858)	Acc@1 98.828 (99.453)	Acc@5 100.000 (99.994)
Epoch: [168][128/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1939 (0.1863)	Acc@1 99.219 (99.382)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.113 (0.115)	Data 0.000 (0.002)	Loss 0.2127 (0.1875)	Acc@1 98.047 (99.324)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.1956 (0.1956)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.122 (0.116)	Data 0.000 (0.005)	Loss 0.1786 (0.1872)	Acc@1 100.000 (99.345)	Acc@5 100.000 (99.994)
Epoch: [169][128/196]	Time 0.116 (0.115)	Data 0.000 (0.002)	Loss 0.1746 (0.1868)	Acc@1 100.000 (99.364)	Acc@5 100.000 (99.994)
Epoch: [169][192/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.1863 (0.1869)	Acc@1 98.828 (99.350)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.143 (0.143)	Data 0.266 (0.266)	Loss 0.1841 (0.1841)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.115 (0.116)	Data 0.000 (0.004)	Loss 0.1827 (0.1852)	Acc@1 99.609 (99.393)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.1783 (0.1853)	Acc@1 99.609 (99.358)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.2027 (0.1851)	Acc@1 98.438 (99.381)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.44
Max memory: 86.9069312
 23.149s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2483
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1417728
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.180 (0.180)	Data 0.276 (0.276)	Loss 0.2063 (0.2063)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.115 (0.118)	Data 0.000 (0.004)	Loss 0.1709 (0.1843)	Acc@1 100.000 (99.447)	Acc@5 100.000 (99.988)
Epoch: [171][128/196]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.1798 (0.1844)	Acc@1 99.609 (99.419)	Acc@5 100.000 (99.994)
Epoch: [171][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.1815 (0.1838)	Acc@1 99.609 (99.423)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.8084608
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.146 (0.146)	Data 0.297 (0.297)	Loss 0.1837 (0.1837)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.111 (0.114)	Data 0.000 (0.005)	Loss 0.2005 (0.1821)	Acc@1 99.219 (99.501)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.1829 (0.1824)	Acc@1 99.219 (99.467)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.1740 (0.1833)	Acc@1 99.609 (99.413)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.185 (0.185)	Data 0.277 (0.277)	Loss 0.1768 (0.1768)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.108 (0.115)	Data 0.000 (0.004)	Loss 0.1752 (0.1808)	Acc@1 99.609 (99.471)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.118 (0.114)	Data 0.000 (0.002)	Loss 0.1770 (0.1816)	Acc@1 99.609 (99.431)	Acc@5 100.000 (99.994)
Epoch: [173][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1838 (0.1817)	Acc@1 98.828 (99.425)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.145 (0.145)	Data 0.304 (0.304)	Loss 0.1720 (0.1720)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.116 (0.116)	Data 0.000 (0.005)	Loss 0.1771 (0.1806)	Acc@1 100.000 (99.579)	Acc@5 100.000 (99.994)
Epoch: [174][128/196]	Time 0.116 (0.115)	Data 0.000 (0.003)	Loss 0.1732 (0.1804)	Acc@1 100.000 (99.552)	Acc@5 100.000 (99.994)
Epoch: [174][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1845 (0.1811)	Acc@1 99.219 (99.492)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.183 (0.183)	Data 0.304 (0.304)	Loss 0.1759 (0.1759)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.111 (0.117)	Data 0.000 (0.005)	Loss 0.1817 (0.1795)	Acc@1 99.609 (99.531)	Acc@5 100.000 (99.994)
Epoch: [175][128/196]	Time 0.115 (0.115)	Data 0.000 (0.003)	Loss 0.1929 (0.1802)	Acc@1 99.219 (99.482)	Acc@5 100.000 (99.997)
Epoch: [175][192/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.1656 (0.1803)	Acc@1 100.000 (99.494)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9723008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.48
Max memory: 86.9069312
 22.788s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1404
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1417728
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.166 (0.166)	Data 0.281 (0.281)	Loss 0.1694 (0.1694)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.115 (0.115)	Data 0.000 (0.004)	Loss 0.1677 (0.1784)	Acc@1 100.000 (99.531)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.1750 (0.1783)	Acc@1 99.609 (99.512)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.1836 (0.1792)	Acc@1 99.219 (99.476)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.8084608
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.152 (0.152)	Data 0.287 (0.287)	Loss 0.1904 (0.1904)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.116 (0.118)	Data 0.000 (0.005)	Loss 0.1801 (0.1771)	Acc@1 99.609 (99.609)	Acc@5 100.000 (99.994)
Epoch: [177][128/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.1756 (0.1780)	Acc@1 99.609 (99.570)	Acc@5 100.000 (99.994)
Epoch: [177][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1680 (0.1784)	Acc@1 99.609 (99.547)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.165 (0.165)	Data 0.272 (0.272)	Loss 0.1775 (0.1775)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.118 (0.116)	Data 0.000 (0.004)	Loss 0.1916 (0.1774)	Acc@1 98.828 (99.591)	Acc@5 100.000 (99.994)
Epoch: [178][128/196]	Time 0.130 (0.115)	Data 0.000 (0.002)	Loss 0.1746 (0.1780)	Acc@1 100.000 (99.531)	Acc@5 100.000 (99.997)
Epoch: [178][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.1661 (0.1781)	Acc@1 100.000 (99.524)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.156 (0.156)	Data 0.308 (0.308)	Loss 0.1762 (0.1762)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.113 (0.116)	Data 0.000 (0.005)	Loss 0.1708 (0.1792)	Acc@1 99.609 (99.399)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.111 (0.116)	Data 0.000 (0.003)	Loss 0.2027 (0.1785)	Acc@1 98.438 (99.449)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.1676 (0.1780)	Acc@1 100.000 (99.480)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.132 (0.132)	Data 0.298 (0.298)	Loss 0.1723 (0.1723)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.116 (0.117)	Data 0.000 (0.005)	Loss 0.1744 (0.1780)	Acc@1 99.609 (99.471)	Acc@5 100.000 (99.994)
Epoch: [180][128/196]	Time 0.106 (0.116)	Data 0.000 (0.002)	Loss 0.1684 (0.1775)	Acc@1 100.000 (99.479)	Acc@5 100.000 (99.997)
Epoch: [180][192/196]	Time 0.121 (0.116)	Data 0.000 (0.002)	Loss 0.1792 (0.1767)	Acc@1 99.219 (99.514)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9723008
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(25, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(21, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(34, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.45
Max memory: 86.9069312
 23.152s  Thres 0.001 1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8430
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.200 (0.200)	Data 0.291 (0.291)	Loss 3.3017 (3.3017)	Acc@1 10.547 (10.547)	Acc@5 50.000 (50.000)
Epoch: [1][64/196]	Time 0.120 (0.129)	Data 0.000 (0.005)	Loss 2.3261 (2.6304)	Acc@1 32.422 (26.040)	Acc@5 89.062 (79.459)
Epoch: [1][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 1.9891 (2.4322)	Acc@1 51.562 (32.952)	Acc@5 93.359 (84.681)
Epoch: [1][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 2.1340 (2.2980)	Acc@1 45.703 (37.856)	Acc@5 92.578 (87.401)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.160 (0.160)	Data 0.286 (0.286)	Loss 1.8665 (1.8665)	Acc@1 54.297 (54.297)	Acc@5 92.969 (92.969)
Epoch: [2][64/196]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 1.7724 (1.8245)	Acc@1 57.422 (54.675)	Acc@5 95.703 (95.096)
Epoch: [2][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 1.5703 (1.7526)	Acc@1 61.328 (56.871)	Acc@5 96.875 (95.497)
Epoch: [2][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 1.5296 (1.6966)	Acc@1 62.500 (58.857)	Acc@5 97.656 (95.721)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.185 (0.185)	Data 0.277 (0.277)	Loss 1.6426 (1.6426)	Acc@1 60.938 (60.938)	Acc@5 95.703 (95.703)
Epoch: [3][64/196]	Time 0.139 (0.131)	Data 0.000 (0.004)	Loss 1.3633 (1.4768)	Acc@1 71.484 (65.889)	Acc@5 96.484 (97.079)
Epoch: [3][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 1.4203 (1.4274)	Acc@1 68.359 (67.621)	Acc@5 96.875 (97.305)
Epoch: [3][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 1.3380 (1.3931)	Acc@1 68.750 (68.564)	Acc@5 97.266 (97.466)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.162 (0.162)	Data 0.292 (0.292)	Loss 1.3229 (1.3229)	Acc@1 72.656 (72.656)	Acc@5 97.266 (97.266)
Epoch: [4][64/196]	Time 0.143 (0.129)	Data 0.000 (0.005)	Loss 1.3144 (1.2695)	Acc@1 70.312 (71.364)	Acc@5 97.266 (97.897)
Epoch: [4][128/196]	Time 0.136 (0.129)	Data 0.000 (0.002)	Loss 1.1282 (1.2408)	Acc@1 75.781 (72.456)	Acc@5 98.438 (98.147)
Epoch: [4][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.0960 (1.2161)	Acc@1 76.953 (73.191)	Acc@5 98.047 (98.217)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.153 (0.153)	Data 0.319 (0.319)	Loss 1.0695 (1.0695)	Acc@1 81.250 (81.250)	Acc@5 97.266 (97.266)
Epoch: [5][64/196]	Time 0.122 (0.130)	Data 0.000 (0.005)	Loss 1.1506 (1.1069)	Acc@1 71.875 (76.058)	Acc@5 98.047 (98.546)
Epoch: [5][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 1.0584 (1.0851)	Acc@1 76.562 (76.865)	Acc@5 98.047 (98.562)
Epoch: [5][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.9968 (1.0799)	Acc@1 75.391 (76.793)	Acc@5 99.609 (98.565)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  68.1
Max memory: 103.3835008
 25.738s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2202
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.213 (0.213)	Data 0.267 (0.267)	Loss 1.1388 (1.1388)	Acc@1 75.781 (75.781)	Acc@5 98.828 (98.828)
Epoch: [6][64/196]	Time 0.147 (0.131)	Data 0.000 (0.004)	Loss 0.9847 (1.0083)	Acc@1 78.906 (78.750)	Acc@5 99.219 (98.774)
Epoch: [6][128/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.9958 (1.0080)	Acc@1 81.641 (78.413)	Acc@5 100.000 (98.783)
Epoch: [6][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.9227 (0.9989)	Acc@1 80.078 (78.435)	Acc@5 99.609 (98.782)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.180 (0.180)	Data 0.301 (0.301)	Loss 0.9768 (0.9768)	Acc@1 80.078 (80.078)	Acc@5 97.656 (97.656)
Epoch: [7][64/196]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.9136 (0.9661)	Acc@1 80.078 (79.303)	Acc@5 98.828 (98.822)
Epoch: [7][128/196]	Time 0.130 (0.133)	Data 0.000 (0.003)	Loss 0.9604 (0.9533)	Acc@1 80.469 (79.463)	Acc@5 98.438 (98.807)
Epoch: [7][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 1.0364 (0.9421)	Acc@1 77.734 (79.762)	Acc@5 97.266 (98.806)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.157 (0.157)	Data 0.277 (0.277)	Loss 0.9748 (0.9748)	Acc@1 78.125 (78.125)	Acc@5 99.219 (99.219)
Epoch: [8][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.8281 (0.8984)	Acc@1 83.984 (80.781)	Acc@5 99.219 (98.918)
Epoch: [8][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7920 (0.8871)	Acc@1 83.984 (81.144)	Acc@5 99.609 (98.986)
Epoch: [8][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.9693 (0.8881)	Acc@1 80.078 (81.042)	Acc@5 98.828 (98.948)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.189 (0.189)	Data 0.311 (0.311)	Loss 0.8319 (0.8319)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [9][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.9807 (0.8651)	Acc@1 77.734 (81.196)	Acc@5 97.656 (98.966)
Epoch: [9][128/196]	Time 0.132 (0.130)	Data 0.000 (0.003)	Loss 0.8256 (0.8625)	Acc@1 82.812 (81.238)	Acc@5 99.219 (98.964)
Epoch: [9][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.9378 (0.8606)	Acc@1 78.906 (81.313)	Acc@5 98.438 (98.994)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.177 (0.177)	Data 0.269 (0.269)	Loss 0.8229 (0.8229)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [10][64/196]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 0.8293 (0.8540)	Acc@1 80.859 (81.352)	Acc@5 99.609 (98.888)
Epoch: [10][128/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.8192 (0.8415)	Acc@1 83.203 (81.783)	Acc@5 98.828 (98.995)
Epoch: [10][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8102 (0.8332)	Acc@1 80.859 (82.082)	Acc@5 100.000 (99.077)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  67.28
Max memory: 103.3833984
 25.976s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3436
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.201 (0.201)	Data 0.281 (0.281)	Loss 0.7815 (0.7815)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.8525 (0.8109)	Acc@1 82.812 (82.644)	Acc@5 99.609 (99.249)
Epoch: [11][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.8013 (0.8215)	Acc@1 84.375 (82.298)	Acc@5 98.828 (99.140)
Epoch: [11][192/196]	Time 0.136 (0.131)	Data 0.000 (0.002)	Loss 0.7815 (0.8189)	Acc@1 83.594 (82.242)	Acc@5 99.219 (99.130)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.178 (0.178)	Data 0.307 (0.307)	Loss 0.8096 (0.8096)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [12][64/196]	Time 0.149 (0.132)	Data 0.000 (0.005)	Loss 0.6941 (0.7995)	Acc@1 86.719 (83.053)	Acc@5 99.219 (99.141)
Epoch: [12][128/196]	Time 0.127 (0.132)	Data 0.000 (0.003)	Loss 0.8774 (0.8055)	Acc@1 80.469 (82.682)	Acc@5 99.219 (99.173)
Epoch: [12][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7906 (0.8066)	Acc@1 83.984 (82.586)	Acc@5 99.219 (99.186)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.192 (0.192)	Data 0.293 (0.293)	Loss 0.7739 (0.7739)	Acc@1 80.859 (80.859)	Acc@5 98.828 (98.828)
Epoch: [13][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.8703 (0.8018)	Acc@1 81.641 (82.740)	Acc@5 99.219 (99.093)
Epoch: [13][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7103 (0.7975)	Acc@1 87.891 (82.879)	Acc@5 99.219 (99.089)
Epoch: [13][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.8584 (0.7958)	Acc@1 81.641 (82.944)	Acc@5 97.656 (99.148)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.188 (0.188)	Data 0.273 (0.273)	Loss 0.7788 (0.7788)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [14][64/196]	Time 0.133 (0.130)	Data 0.000 (0.004)	Loss 0.8649 (0.7847)	Acc@1 79.297 (82.885)	Acc@5 98.828 (99.183)
Epoch: [14][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7399 (0.7842)	Acc@1 86.719 (83.058)	Acc@5 98.438 (99.182)
Epoch: [14][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7525 (0.7884)	Acc@1 83.594 (82.942)	Acc@5 99.219 (99.176)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.153 (0.153)	Data 0.284 (0.284)	Loss 0.7148 (0.7148)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.6835 (0.7821)	Acc@1 88.281 (83.371)	Acc@5 98.438 (99.165)
Epoch: [15][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7387 (0.7890)	Acc@1 83.594 (83.055)	Acc@5 99.609 (99.191)
Epoch: [15][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.8612 (0.7841)	Acc@1 80.859 (83.238)	Acc@5 98.828 (99.194)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  76.55
Max memory: 103.3833984
 25.990s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8725
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.2020864
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.187 (0.187)	Data 0.294 (0.294)	Loss 0.7244 (0.7244)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.7491 (0.7415)	Acc@1 82.422 (85.012)	Acc@5 99.219 (99.267)
Epoch: [16][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7181 (0.7543)	Acc@1 86.328 (84.251)	Acc@5 100.000 (99.270)
Epoch: [16][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8624 (0.7598)	Acc@1 82.031 (84.102)	Acc@5 97.656 (99.247)
Max memory in training epoch: 66.6450432
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.171 (0.171)	Data 0.302 (0.302)	Loss 0.7839 (0.7839)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [17][64/196]	Time 0.133 (0.134)	Data 0.000 (0.005)	Loss 0.7635 (0.7737)	Acc@1 83.203 (83.323)	Acc@5 99.609 (99.315)
Epoch: [17][128/196]	Time 0.136 (0.133)	Data 0.000 (0.003)	Loss 0.7794 (0.7708)	Acc@1 85.156 (83.633)	Acc@5 98.828 (99.313)
Epoch: [17][192/196]	Time 0.139 (0.131)	Data 0.000 (0.002)	Loss 0.8175 (0.7718)	Acc@1 79.297 (83.622)	Acc@5 99.609 (99.288)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.188 (0.188)	Data 0.287 (0.287)	Loss 0.7091 (0.7091)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.146 (0.131)	Data 0.000 (0.005)	Loss 0.7334 (0.7648)	Acc@1 84.375 (83.912)	Acc@5 99.609 (99.285)
Epoch: [18][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7282 (0.7631)	Acc@1 85.938 (83.921)	Acc@5 100.000 (99.304)
Epoch: [18][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7716 (0.7640)	Acc@1 80.859 (83.867)	Acc@5 99.219 (99.261)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.177 (0.177)	Data 0.279 (0.279)	Loss 0.8531 (0.8531)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.7901 (0.7622)	Acc@1 82.031 (84.183)	Acc@5 99.219 (99.243)
Epoch: [19][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7258 (0.7512)	Acc@1 85.547 (84.569)	Acc@5 99.609 (99.307)
Epoch: [19][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7635 (0.7550)	Acc@1 85.547 (84.395)	Acc@5 99.609 (99.314)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.175 (0.175)	Data 0.295 (0.295)	Loss 0.7574 (0.7574)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [20][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7542 (0.7571)	Acc@1 85.938 (84.213)	Acc@5 98.828 (99.315)
Epoch: [20][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7505 (0.7501)	Acc@1 85.547 (84.342)	Acc@5 99.609 (99.304)
Epoch: [20][192/196]	Time 0.146 (0.131)	Data 0.000 (0.002)	Loss 0.8179 (0.7490)	Acc@1 82.422 (84.397)	Acc@5 100.000 (99.304)
Max memory in training epoch: 66.5401856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 480462 ; 486232 ; 0.9881332368087662
[INFO] Storing checkpoint...
  76.92
Max memory: 103.3821696
 25.964s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5305
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1997312
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.218 (0.218)	Data 0.268 (0.268)	Loss 0.7096 (0.7096)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [21][64/196]	Time 0.134 (0.131)	Data 0.000 (0.004)	Loss 0.7956 (0.7086)	Acc@1 83.594 (85.925)	Acc@5 98.438 (99.447)
Epoch: [21][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7747 (0.7297)	Acc@1 82.812 (85.250)	Acc@5 98.828 (99.361)
Epoch: [21][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.8741 (0.7400)	Acc@1 79.297 (84.978)	Acc@5 98.438 (99.306)
Max memory in training epoch: 66.6356224
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.194 (0.194)	Data 0.289 (0.289)	Loss 0.7675 (0.7675)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.135 (0.135)	Data 0.000 (0.005)	Loss 0.8437 (0.7359)	Acc@1 79.688 (85.012)	Acc@5 98.438 (99.345)
Epoch: [22][128/196]	Time 0.128 (0.134)	Data 0.000 (0.002)	Loss 0.7609 (0.7334)	Acc@1 83.594 (85.026)	Acc@5 99.609 (99.337)
Epoch: [22][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7009 (0.7466)	Acc@1 85.938 (84.513)	Acc@5 99.609 (99.306)
Max memory in training epoch: 66.5307648
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.169 (0.169)	Data 0.297 (0.297)	Loss 0.7309 (0.7309)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [23][64/196]	Time 0.139 (0.131)	Data 0.000 (0.005)	Loss 0.7545 (0.7338)	Acc@1 83.984 (84.820)	Acc@5 100.000 (99.303)
Epoch: [23][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7016 (0.7342)	Acc@1 88.672 (84.947)	Acc@5 99.219 (99.313)
Epoch: [23][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7420 (0.7428)	Acc@1 83.203 (84.648)	Acc@5 100.000 (99.340)
Max memory in training epoch: 66.5307648
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.191 (0.191)	Data 0.313 (0.313)	Loss 0.7630 (0.7630)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [24][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.6152 (0.7374)	Acc@1 87.891 (84.856)	Acc@5 100.000 (99.249)
Epoch: [24][128/196]	Time 0.145 (0.131)	Data 0.000 (0.003)	Loss 0.6725 (0.7423)	Acc@1 87.109 (84.623)	Acc@5 99.219 (99.304)
Epoch: [24][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7069 (0.7346)	Acc@1 84.375 (84.921)	Acc@5 99.219 (99.330)
Max memory in training epoch: 66.5307648
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.181 (0.181)	Data 0.326 (0.326)	Loss 0.6533 (0.6533)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.140 (0.132)	Data 0.000 (0.005)	Loss 0.7709 (0.7250)	Acc@1 83.594 (85.264)	Acc@5 99.219 (99.399)
Epoch: [25][128/196]	Time 0.123 (0.131)	Data 0.000 (0.003)	Loss 0.7482 (0.7348)	Acc@1 85.156 (84.990)	Acc@5 98.828 (99.322)
Epoch: [25][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7176 (0.7364)	Acc@1 87.500 (84.901)	Acc@5 98.828 (99.310)
Max memory in training epoch: 66.5307648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 455074 ; 480462 ; 0.9471591926104458
[INFO] Storing checkpoint...
  73.6
Max memory: 103.375104
 26.089s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 83
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1895936
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.198 (0.198)	Data 0.287 (0.287)	Loss 0.7415 (0.7415)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [26][64/196]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.6905 (0.7090)	Acc@1 88.672 (86.064)	Acc@5 99.609 (99.333)
Epoch: [26][128/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7264 (0.7191)	Acc@1 84.766 (85.741)	Acc@5 98.828 (99.334)
Epoch: [26][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.7048 (0.7287)	Acc@1 87.500 (85.351)	Acc@5 99.219 (99.332)
Max memory in training epoch: 66.2280704
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.162 (0.162)	Data 0.302 (0.302)	Loss 0.7276 (0.7276)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.7497 (0.7198)	Acc@1 86.328 (85.475)	Acc@5 99.609 (99.351)
Epoch: [27][128/196]	Time 0.130 (0.134)	Data 0.000 (0.003)	Loss 0.7658 (0.7235)	Acc@1 80.469 (85.356)	Acc@5 99.219 (99.328)
Epoch: [27][192/196]	Time 0.133 (0.134)	Data 0.000 (0.002)	Loss 0.6846 (0.7260)	Acc@1 86.328 (85.249)	Acc@5 99.219 (99.348)
Max memory in training epoch: 66.201856
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.173 (0.173)	Data 0.268 (0.268)	Loss 0.6660 (0.6660)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.148 (0.133)	Data 0.000 (0.004)	Loss 0.6303 (0.7406)	Acc@1 86.328 (84.669)	Acc@5 99.609 (99.333)
Epoch: [28][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.6734 (0.7257)	Acc@1 85.938 (85.141)	Acc@5 99.609 (99.367)
Epoch: [28][192/196]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.8352 (0.7304)	Acc@1 81.641 (85.027)	Acc@5 99.219 (99.352)
Max memory in training epoch: 66.201856
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.188 (0.188)	Data 0.276 (0.276)	Loss 0.8044 (0.8044)	Acc@1 80.469 (80.469)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.129 (0.133)	Data 0.000 (0.004)	Loss 0.7130 (0.7168)	Acc@1 84.766 (85.649)	Acc@5 99.219 (99.321)
Epoch: [29][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7319 (0.7215)	Acc@1 85.156 (85.317)	Acc@5 100.000 (99.331)
Epoch: [29][192/196]	Time 0.128 (0.133)	Data 0.000 (0.002)	Loss 0.7037 (0.7278)	Acc@1 84.766 (85.130)	Acc@5 99.219 (99.324)
Max memory in training epoch: 66.201856
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.188 (0.188)	Data 0.265 (0.265)	Loss 0.6747 (0.6747)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.135 (0.132)	Data 0.000 (0.004)	Loss 0.7916 (0.7362)	Acc@1 80.078 (84.844)	Acc@5 98.438 (99.393)
Epoch: [30][128/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.6555 (0.7279)	Acc@1 87.109 (85.196)	Acc@5 99.609 (99.385)
Epoch: [30][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6537 (0.7273)	Acc@1 87.891 (85.081)	Acc@5 100.000 (99.362)
Max memory in training epoch: 66.201856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 445264 ; 455074 ; 0.9784430664023873
[INFO] Storing checkpoint...
  77.94
Max memory: 102.872832
 26.235s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 652
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1858048
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.202 (0.202)	Data 0.268 (0.268)	Loss 0.6921 (0.6921)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.7510 (0.6874)	Acc@1 85.547 (86.629)	Acc@5 99.609 (99.417)
Epoch: [31][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.8321 (0.7062)	Acc@1 85.547 (85.768)	Acc@5 99.609 (99.361)
Epoch: [31][192/196]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.6023 (0.7110)	Acc@1 90.625 (85.610)	Acc@5 100.000 (99.344)
Max memory in training epoch: 66.1604864
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.157 (0.157)	Data 0.307 (0.307)	Loss 0.6808 (0.6808)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [32][64/196]	Time 0.133 (0.135)	Data 0.000 (0.005)	Loss 0.6340 (0.7080)	Acc@1 89.453 (85.811)	Acc@5 98.828 (99.387)
Epoch: [32][128/196]	Time 0.130 (0.133)	Data 0.000 (0.003)	Loss 0.7536 (0.7140)	Acc@1 84.766 (85.626)	Acc@5 98.438 (99.346)
Epoch: [32][192/196]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.7377 (0.7135)	Acc@1 84.766 (85.668)	Acc@5 99.219 (99.336)
Max memory in training epoch: 66.0163072
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.159 (0.159)	Data 0.293 (0.293)	Loss 0.7516 (0.7516)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.6482 (0.7058)	Acc@1 89.844 (86.010)	Acc@5 99.219 (99.411)
Epoch: [33][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6971 (0.7115)	Acc@1 88.281 (85.683)	Acc@5 98.828 (99.413)
Epoch: [33][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.7807 (0.7176)	Acc@1 83.594 (85.460)	Acc@5 99.219 (99.405)
Max memory in training epoch: 66.0163072
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.194 (0.194)	Data 0.273 (0.273)	Loss 0.6702 (0.6702)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.7692 (0.7080)	Acc@1 83.203 (85.505)	Acc@5 99.219 (99.477)
Epoch: [34][128/196]	Time 0.146 (0.133)	Data 0.000 (0.002)	Loss 0.7334 (0.7142)	Acc@1 85.156 (85.529)	Acc@5 99.609 (99.403)
Epoch: [34][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7599 (0.7161)	Acc@1 81.250 (85.466)	Acc@5 100.000 (99.399)
Max memory in training epoch: 66.0163072
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.176 (0.176)	Data 0.304 (0.304)	Loss 0.7414 (0.7414)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.131 (0.134)	Data 0.000 (0.005)	Loss 0.6822 (0.7182)	Acc@1 88.672 (85.367)	Acc@5 99.219 (99.333)
Epoch: [35][128/196]	Time 0.132 (0.133)	Data 0.000 (0.003)	Loss 0.7976 (0.7147)	Acc@1 83.984 (85.617)	Acc@5 98.828 (99.340)
Epoch: [35][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7413 (0.7153)	Acc@1 84.766 (85.606)	Acc@5 100.000 (99.342)
Max memory in training epoch: 66.0163072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423326 ; 445264 ; 0.9507303532286464
[INFO] Storing checkpoint...
  74.32
Max memory: 102.625536
 26.536s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7843
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1772032
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.214 (0.214)	Data 0.264 (0.264)	Loss 0.5896 (0.5896)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [36][64/196]	Time 0.138 (0.133)	Data 0.000 (0.004)	Loss 0.6947 (0.6776)	Acc@1 85.547 (86.785)	Acc@5 100.000 (99.495)
Epoch: [36][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.6877 (0.6994)	Acc@1 85.938 (85.871)	Acc@5 99.609 (99.449)
Epoch: [36][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6884 (0.7042)	Acc@1 85.156 (85.723)	Acc@5 99.219 (99.415)
Max memory in training epoch: 65.1823616
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.158 (0.158)	Data 0.301 (0.301)	Loss 0.7260 (0.7260)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.137 (0.129)	Data 0.000 (0.005)	Loss 0.6578 (0.7094)	Acc@1 88.672 (85.589)	Acc@5 99.609 (99.363)
Epoch: [37][128/196]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.6491 (0.7038)	Acc@1 87.891 (85.847)	Acc@5 99.609 (99.400)
Epoch: [37][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.6993 (0.7105)	Acc@1 87.109 (85.650)	Acc@5 99.609 (99.429)
Max memory in training epoch: 65.2544512
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.159 (0.159)	Data 0.308 (0.308)	Loss 0.6964 (0.6964)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [38][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.5948 (0.6885)	Acc@1 89.844 (86.412)	Acc@5 99.219 (99.471)
Epoch: [38][128/196]	Time 0.125 (0.131)	Data 0.000 (0.003)	Loss 0.6274 (0.6976)	Acc@1 85.938 (86.083)	Acc@5 99.609 (99.425)
Epoch: [38][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7650 (0.7020)	Acc@1 84.375 (85.950)	Acc@5 99.219 (99.393)
Max memory in training epoch: 65.1495936
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.182 (0.182)	Data 0.292 (0.292)	Loss 0.6497 (0.6497)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [39][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7260 (0.6969)	Acc@1 83.984 (86.034)	Acc@5 100.000 (99.417)
Epoch: [39][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7666 (0.7014)	Acc@1 83.203 (85.877)	Acc@5 99.219 (99.410)
Epoch: [39][192/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.6193 (0.7000)	Acc@1 88.672 (85.960)	Acc@5 100.000 (99.401)
Max memory in training epoch: 65.1495936
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.183 (0.183)	Data 0.278 (0.278)	Loss 0.6912 (0.6912)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.152 (0.132)	Data 0.000 (0.004)	Loss 0.6536 (0.7047)	Acc@1 87.109 (85.841)	Acc@5 99.609 (99.387)
Epoch: [40][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7162 (0.7074)	Acc@1 84.375 (85.719)	Acc@5 99.609 (99.410)
Epoch: [40][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7341 (0.7044)	Acc@1 82.031 (85.794)	Acc@5 99.609 (99.439)
Max memory in training epoch: 65.1495936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 406296 ; 423326 ; 0.9597709566622414
[INFO] Storing checkpoint...
  74.71
Max memory: 101.0133504
 26.048s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8017
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1703424
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.209 (0.209)	Data 0.271 (0.271)	Loss 0.7323 (0.7323)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.6489 (0.6861)	Acc@1 89.062 (86.394)	Acc@5 99.609 (99.489)
Epoch: [41][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6528 (0.6932)	Acc@1 87.500 (86.137)	Acc@5 98.828 (99.431)
Epoch: [41][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7232 (0.7009)	Acc@1 87.109 (85.933)	Acc@5 99.609 (99.427)
Max memory in training epoch: 64.6961664
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.189 (0.189)	Data 0.289 (0.289)	Loss 0.7133 (0.7133)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.147 (0.130)	Data 0.000 (0.005)	Loss 0.6639 (0.6920)	Acc@1 86.719 (86.328)	Acc@5 99.609 (99.417)
Epoch: [42][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7703 (0.7022)	Acc@1 84.766 (86.062)	Acc@5 98.828 (99.397)
Epoch: [42][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7170 (0.7049)	Acc@1 84.766 (85.871)	Acc@5 98.438 (99.419)
Max memory in training epoch: 64.6830592
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.181 (0.181)	Data 0.289 (0.289)	Loss 0.6797 (0.6797)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [43][64/196]	Time 0.129 (0.133)	Data 0.000 (0.005)	Loss 0.6661 (0.7005)	Acc@1 86.719 (85.775)	Acc@5 100.000 (99.459)
Epoch: [43][128/196]	Time 0.139 (0.133)	Data 0.000 (0.002)	Loss 0.7515 (0.7017)	Acc@1 85.547 (85.868)	Acc@5 99.219 (99.428)
Epoch: [43][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6875 (0.7023)	Acc@1 87.891 (85.942)	Acc@5 99.219 (99.421)
Max memory in training epoch: 64.6830592
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.203 (0.203)	Data 0.296 (0.296)	Loss 0.6470 (0.6470)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.6424 (0.6998)	Acc@1 87.891 (85.956)	Acc@5 100.000 (99.477)
Epoch: [44][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8035 (0.7014)	Acc@1 82.812 (86.025)	Acc@5 99.219 (99.452)
Epoch: [44][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6996 (0.6991)	Acc@1 84.766 (86.077)	Acc@5 100.000 (99.452)
Max memory in training epoch: 64.6830592
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.177 (0.177)	Data 0.271 (0.271)	Loss 0.6191 (0.6191)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.131 (0.128)	Data 0.000 (0.004)	Loss 0.6555 (0.6962)	Acc@1 87.109 (86.268)	Acc@5 99.609 (99.459)
Epoch: [45][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6640 (0.6960)	Acc@1 86.328 (86.137)	Acc@5 99.609 (99.425)
Epoch: [45][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7059 (0.6952)	Acc@1 85.938 (86.059)	Acc@5 100.000 (99.449)
Max memory in training epoch: 64.6830592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 395616 ; 406296 ; 0.9737137456435702
[INFO] Storing checkpoint...
  78.86
Max memory: 99.8848
 25.437s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2894
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.166144
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.187 (0.187)	Data 0.268 (0.268)	Loss 0.5460 (0.5460)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.7036 (0.6876)	Acc@1 86.328 (86.526)	Acc@5 98.438 (99.381)
Epoch: [46][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.6705 (0.6902)	Acc@1 85.156 (86.419)	Acc@5 99.609 (99.464)
Epoch: [46][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7371 (0.6946)	Acc@1 85.938 (86.284)	Acc@5 99.609 (99.443)
Max memory in training epoch: 64.0764416
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.177 (0.177)	Data 0.302 (0.302)	Loss 0.6791 (0.6791)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.125 (0.131)	Data 0.000 (0.005)	Loss 0.7459 (0.6822)	Acc@1 82.812 (86.472)	Acc@5 100.000 (99.465)
Epoch: [47][128/196]	Time 0.137 (0.130)	Data 0.000 (0.003)	Loss 0.7292 (0.6903)	Acc@1 84.766 (86.316)	Acc@5 99.609 (99.403)
Epoch: [47][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7056 (0.6942)	Acc@1 82.422 (86.108)	Acc@5 99.609 (99.417)
Max memory in training epoch: 64.2599424
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.189 (0.189)	Data 0.287 (0.287)	Loss 0.6617 (0.6617)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.133 (0.129)	Data 0.000 (0.005)	Loss 0.7328 (0.6875)	Acc@1 83.984 (86.466)	Acc@5 99.609 (99.501)
Epoch: [48][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7992 (0.6919)	Acc@1 79.688 (86.258)	Acc@5 99.609 (99.446)
Epoch: [48][192/196]	Time 0.136 (0.132)	Data 0.000 (0.002)	Loss 0.6396 (0.6903)	Acc@1 90.234 (86.253)	Acc@5 99.609 (99.439)
Max memory in training epoch: 64.1747456
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.161 (0.161)	Data 0.299 (0.299)	Loss 0.5962 (0.5962)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [49][64/196]	Time 0.134 (0.129)	Data 0.000 (0.005)	Loss 0.7030 (0.6910)	Acc@1 85.938 (85.925)	Acc@5 99.219 (99.459)
Epoch: [49][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6533 (0.6956)	Acc@1 86.719 (85.832)	Acc@5 99.609 (99.443)
Epoch: [49][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6705 (0.6983)	Acc@1 85.547 (85.749)	Acc@5 100.000 (99.435)
Max memory in training epoch: 64.1747456
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.191 (0.191)	Data 0.303 (0.303)	Loss 0.6948 (0.6948)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.7651 (0.6883)	Acc@1 83.203 (86.310)	Acc@5 99.609 (99.537)
Epoch: [50][128/196]	Time 0.121 (0.130)	Data 0.000 (0.003)	Loss 0.7776 (0.6902)	Acc@1 82.812 (86.225)	Acc@5 99.609 (99.494)
Epoch: [50][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7128 (0.6932)	Acc@1 84.375 (86.027)	Acc@5 100.000 (99.482)
Max memory in training epoch: 64.1747456
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 392436 ; 395616 ; 0.9919619024508615
[INFO] Storing checkpoint...
  80.36
Max memory: 99.434752
 25.848s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6177
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1648128
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.212 (0.212)	Data 0.260 (0.260)	Loss 0.8223 (0.8223)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6884 (0.6593)	Acc@1 86.719 (87.326)	Acc@5 99.219 (99.585)
Epoch: [51][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6318 (0.6788)	Acc@1 87.891 (86.713)	Acc@5 99.609 (99.540)
Epoch: [51][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6858 (0.6842)	Acc@1 87.891 (86.504)	Acc@5 97.656 (99.486)
Max memory in training epoch: 63.887616
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.169 (0.169)	Data 0.290 (0.290)	Loss 0.6467 (0.6467)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.8024 (0.6813)	Acc@1 82.422 (86.316)	Acc@5 98.828 (99.537)
Epoch: [52][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7575 (0.6883)	Acc@1 84.375 (86.237)	Acc@5 99.219 (99.500)
Epoch: [52][192/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.7464 (0.6896)	Acc@1 84.766 (86.245)	Acc@5 99.219 (99.476)
Max memory in training epoch: 64.0973312
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.154 (0.154)	Data 0.302 (0.302)	Loss 0.6142 (0.6142)	Acc@1 88.281 (88.281)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.6985 (0.6734)	Acc@1 85.938 (86.731)	Acc@5 99.609 (99.555)
Epoch: [53][128/196]	Time 0.126 (0.129)	Data 0.000 (0.003)	Loss 0.6456 (0.6813)	Acc@1 87.891 (86.595)	Acc@5 99.219 (99.503)
Epoch: [53][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7799 (0.6839)	Acc@1 83.594 (86.605)	Acc@5 99.219 (99.470)
Max memory in training epoch: 64.0973312
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.153 (0.153)	Data 0.300 (0.300)	Loss 0.7988 (0.7988)	Acc@1 80.078 (80.078)	Acc@5 100.000 (100.000)
Epoch: [54][64/196]	Time 0.136 (0.134)	Data 0.000 (0.005)	Loss 0.6231 (0.6902)	Acc@1 89.844 (86.172)	Acc@5 99.609 (99.429)
Epoch: [54][128/196]	Time 0.128 (0.134)	Data 0.000 (0.002)	Loss 0.7187 (0.6921)	Acc@1 84.375 (86.159)	Acc@5 99.609 (99.434)
Epoch: [54][192/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7198 (0.6896)	Acc@1 84.375 (86.276)	Acc@5 99.219 (99.425)
Max memory in training epoch: 64.0973312
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.161 (0.161)	Data 0.269 (0.269)	Loss 0.6943 (0.6943)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [55][64/196]	Time 0.143 (0.130)	Data 0.000 (0.004)	Loss 0.7111 (0.6789)	Acc@1 86.328 (86.815)	Acc@5 99.219 (99.441)
Epoch: [55][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6727 (0.6788)	Acc@1 88.281 (86.685)	Acc@5 99.609 (99.452)
Epoch: [55][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6348 (0.6825)	Acc@1 87.500 (86.545)	Acc@5 99.609 (99.429)
Max memory in training epoch: 64.0973312
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 385792 ; 392436 ; 0.9830698508801435
[INFO] Storing checkpoint...
  74.97
Max memory: 98.5009664
 25.722s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6392
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1621504
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.212 (0.212)	Data 0.269 (0.269)	Loss 0.5945 (0.5945)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.6345 (0.6485)	Acc@1 87.109 (87.512)	Acc@5 100.000 (99.597)
Epoch: [56][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.7197 (0.6662)	Acc@1 83.203 (86.925)	Acc@5 99.609 (99.512)
Epoch: [56][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7674 (0.6735)	Acc@1 80.469 (86.672)	Acc@5 99.219 (99.508)
Max memory in training epoch: 62.9732864
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.176 (0.176)	Data 0.269 (0.269)	Loss 0.6740 (0.6740)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.120 (0.129)	Data 0.000 (0.004)	Loss 0.7403 (0.6813)	Acc@1 86.719 (86.520)	Acc@5 98.828 (99.507)
Epoch: [57][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7260 (0.6892)	Acc@1 86.328 (86.231)	Acc@5 99.219 (99.470)
Epoch: [57][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6096 (0.6901)	Acc@1 89.453 (86.217)	Acc@5 99.609 (99.452)
Max memory in training epoch: 63.392
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.169 (0.169)	Data 0.268 (0.268)	Loss 0.7327 (0.7327)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [58][64/196]	Time 0.151 (0.130)	Data 0.000 (0.004)	Loss 0.6728 (0.6915)	Acc@1 87.109 (86.352)	Acc@5 100.000 (99.501)
Epoch: [58][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6925 (0.6898)	Acc@1 89.062 (86.280)	Acc@5 100.000 (99.461)
Epoch: [58][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6685 (0.6828)	Acc@1 86.328 (86.460)	Acc@5 99.609 (99.474)
Max memory in training epoch: 63.392
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.166 (0.166)	Data 0.308 (0.308)	Loss 0.6688 (0.6688)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [59][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6230 (0.6856)	Acc@1 87.500 (86.244)	Acc@5 100.000 (99.495)
Epoch: [59][128/196]	Time 0.125 (0.128)	Data 0.000 (0.003)	Loss 0.6246 (0.6862)	Acc@1 88.672 (86.204)	Acc@5 99.609 (99.509)
Epoch: [59][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7159 (0.6893)	Acc@1 83.984 (86.132)	Acc@5 99.609 (99.456)
Max memory in training epoch: 63.392
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.156 (0.156)	Data 0.324 (0.324)	Loss 0.5878 (0.5878)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [60][64/196]	Time 0.131 (0.133)	Data 0.000 (0.005)	Loss 0.7377 (0.6789)	Acc@1 85.938 (86.388)	Acc@5 98.438 (99.483)
Epoch: [60][128/196]	Time 0.126 (0.131)	Data 0.000 (0.003)	Loss 0.5830 (0.6785)	Acc@1 90.625 (86.416)	Acc@5 99.219 (99.452)
Epoch: [60][192/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.7002 (0.6812)	Acc@1 84.375 (86.427)	Acc@5 99.609 (99.452)
Max memory in training epoch: 63.392
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 378568 ; 385792 ; 0.9812748838752489
[INFO] Storing checkpoint...
  79.3
Max memory: 97.7532416
 25.811s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4805
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1593856
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.196 (0.196)	Data 0.290 (0.290)	Loss 0.6638 (0.6638)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.6387 (0.6482)	Acc@1 87.891 (87.650)	Acc@5 99.609 (99.543)
Epoch: [61][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6372 (0.6666)	Acc@1 88.672 (86.825)	Acc@5 99.609 (99.528)
Epoch: [61][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.7037 (0.6717)	Acc@1 82.812 (86.674)	Acc@5 99.609 (99.498)
Max memory in training epoch: 62.5158656
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.176 (0.176)	Data 0.312 (0.312)	Loss 0.6068 (0.6068)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [62][64/196]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.7135 (0.6783)	Acc@1 86.719 (86.677)	Acc@5 98.828 (99.399)
Epoch: [62][128/196]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.6307 (0.6776)	Acc@1 88.281 (86.604)	Acc@5 99.219 (99.413)
Epoch: [62][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7798 (0.6751)	Acc@1 81.641 (86.729)	Acc@5 99.609 (99.405)
Max memory in training epoch: 62.804224
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.170 (0.170)	Data 0.286 (0.286)	Loss 0.6403 (0.6403)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [63][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6376 (0.6956)	Acc@1 87.500 (86.142)	Acc@5 100.000 (99.477)
Epoch: [63][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6684 (0.6877)	Acc@1 88.672 (86.507)	Acc@5 99.609 (99.458)
Epoch: [63][192/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6911 (0.6835)	Acc@1 84.766 (86.551)	Acc@5 100.000 (99.468)
Max memory in training epoch: 62.804224
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.186 (0.186)	Data 0.320 (0.320)	Loss 0.7285 (0.7285)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.128 (0.127)	Data 0.000 (0.005)	Loss 0.5899 (0.6731)	Acc@1 91.406 (86.719)	Acc@5 100.000 (99.411)
Epoch: [64][128/196]	Time 0.128 (0.126)	Data 0.000 (0.003)	Loss 0.6368 (0.6770)	Acc@1 89.062 (86.628)	Acc@5 99.609 (99.440)
Epoch: [64][192/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.6863 (0.6791)	Acc@1 85.156 (86.563)	Acc@5 99.609 (99.474)
Max memory in training epoch: 62.804224
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.171 (0.171)	Data 0.354 (0.354)	Loss 0.7586 (0.7586)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [65][64/196]	Time 0.123 (0.129)	Data 0.000 (0.006)	Loss 0.6773 (0.6713)	Acc@1 85.938 (86.983)	Acc@5 99.609 (99.345)
Epoch: [65][128/196]	Time 0.129 (0.129)	Data 0.000 (0.003)	Loss 0.7555 (0.6725)	Acc@1 84.766 (86.858)	Acc@5 98.828 (99.410)
Epoch: [65][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6649 (0.6773)	Acc@1 85.938 (86.684)	Acc@5 99.219 (99.439)
Max memory in training epoch: 62.804224
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 375390 ; 378568 ; 0.9916052069905539
[INFO] Storing checkpoint...
  79.32
Max memory: 96.5925376
 25.485s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1029
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1581568
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.212 (0.212)	Data 0.268 (0.268)	Loss 0.7548 (0.7548)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.6416 (0.6561)	Acc@1 88.672 (87.236)	Acc@5 99.609 (99.471)
Epoch: [66][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6216 (0.6621)	Acc@1 87.500 (87.058)	Acc@5 99.219 (99.522)
Epoch: [66][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.6529 (0.6674)	Acc@1 87.500 (86.798)	Acc@5 99.219 (99.502)
Max memory in training epoch: 62.1832704
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.173 (0.173)	Data 0.297 (0.297)	Loss 0.6012 (0.6012)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.7539 (0.6759)	Acc@1 83.203 (86.641)	Acc@5 99.609 (99.483)
Epoch: [67][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7677 (0.6756)	Acc@1 82.031 (86.522)	Acc@5 99.609 (99.467)
Epoch: [67][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5777 (0.6793)	Acc@1 91.797 (86.425)	Acc@5 100.000 (99.478)
Max memory in training epoch: 62.4716288
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.150 (0.150)	Data 0.274 (0.274)	Loss 0.6519 (0.6519)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7277 (0.6858)	Acc@1 87.500 (86.142)	Acc@5 99.609 (99.465)
Epoch: [68][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6073 (0.6719)	Acc@1 88.672 (86.655)	Acc@5 100.000 (99.476)
Epoch: [68][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6484 (0.6771)	Acc@1 89.844 (86.520)	Acc@5 99.609 (99.458)
Max memory in training epoch: 62.4716288
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.173 (0.173)	Data 0.268 (0.268)	Loss 0.7175 (0.7175)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [69][64/196]	Time 0.118 (0.127)	Data 0.000 (0.004)	Loss 0.6709 (0.6645)	Acc@1 86.719 (86.983)	Acc@5 99.609 (99.483)
Epoch: [69][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6862 (0.6659)	Acc@1 85.938 (87.006)	Acc@5 98.828 (99.485)
Epoch: [69][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6400 (0.6745)	Acc@1 87.891 (86.711)	Acc@5 99.219 (99.454)
Max memory in training epoch: 62.4716288
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.179 (0.179)	Data 0.287 (0.287)	Loss 0.6123 (0.6123)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.7413 (0.6658)	Acc@1 80.859 (87.085)	Acc@5 99.219 (99.417)
Epoch: [70][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.7630 (0.6773)	Acc@1 82.812 (86.685)	Acc@5 99.609 (99.379)
Epoch: [70][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.5983 (0.6786)	Acc@1 87.500 (86.599)	Acc@5 100.000 (99.411)
Max memory in training epoch: 62.4716288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 373366 ; 375390 ; 0.9946082740616425
[INFO] Storing checkpoint...
  78.72
Max memory: 96.1847808
 25.433s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3052
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1573376
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.195 (0.195)	Data 0.283 (0.283)	Loss 0.6316 (0.6316)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.7489 (0.6442)	Acc@1 83.984 (87.566)	Acc@5 99.219 (99.543)
Epoch: [71][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7431 (0.6586)	Acc@1 84.766 (87.176)	Acc@5 99.609 (99.519)
Epoch: [71][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.6438 (0.6662)	Acc@1 88.281 (86.836)	Acc@5 99.219 (99.514)
Max memory in training epoch: 62.059264
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.185 (0.185)	Data 0.263 (0.263)	Loss 0.6257 (0.6257)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [72][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.7263 (0.6683)	Acc@1 85.547 (86.755)	Acc@5 98.828 (99.501)
Epoch: [72][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.6282 (0.6657)	Acc@1 89.062 (86.734)	Acc@5 100.000 (99.494)
Epoch: [72][192/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.7381 (0.6716)	Acc@1 82.812 (86.545)	Acc@5 99.219 (99.464)
Max memory in training epoch: 62.1799936
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.144 (0.144)	Data 0.304 (0.304)	Loss 0.6455 (0.6455)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.6531 (0.6715)	Acc@1 87.109 (86.490)	Acc@5 99.219 (99.537)
Epoch: [73][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.6535 (0.6756)	Acc@1 89.453 (86.361)	Acc@5 100.000 (99.452)
Epoch: [73][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6153 (0.6745)	Acc@1 88.672 (86.401)	Acc@5 99.609 (99.472)
Max memory in training epoch: 62.1799936
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.165 (0.165)	Data 0.275 (0.275)	Loss 0.7522 (0.7522)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [74][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.8015 (0.6836)	Acc@1 83.203 (86.490)	Acc@5 99.219 (99.441)
Epoch: [74][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6610 (0.6752)	Acc@1 85.938 (86.661)	Acc@5 98.828 (99.440)
Epoch: [74][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6814 (0.6748)	Acc@1 85.938 (86.581)	Acc@5 99.609 (99.439)
Max memory in training epoch: 62.1799936
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.174 (0.174)	Data 0.283 (0.283)	Loss 0.6393 (0.6393)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.6248 (0.6969)	Acc@1 86.719 (85.505)	Acc@5 100.000 (99.471)
Epoch: [75][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.6425 (0.6761)	Acc@1 87.109 (86.477)	Acc@5 99.609 (99.516)
Epoch: [75][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6198 (0.6740)	Acc@1 89.062 (86.634)	Acc@5 99.219 (99.502)
Max memory in training epoch: 62.1799936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 367156 ; 373366 ; 0.9833675267699791
[INFO] Storing checkpoint...
  82.54
Max memory: 96.1298944
 25.185s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5056
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1550336
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.219 (0.219)	Data 0.288 (0.288)	Loss 0.6604 (0.6604)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.6486 (0.6311)	Acc@1 86.719 (88.185)	Acc@5 100.000 (99.573)
Epoch: [76][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7624 (0.6510)	Acc@1 83.594 (87.315)	Acc@5 98.828 (99.540)
Epoch: [76][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.6147 (0.6595)	Acc@1 89.062 (87.012)	Acc@5 99.219 (99.514)
Max memory in training epoch: 61.3581312
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.186 (0.186)	Data 0.268 (0.268)	Loss 0.6509 (0.6509)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.6294 (0.6559)	Acc@1 87.891 (87.470)	Acc@5 100.000 (99.573)
Epoch: [77][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6331 (0.6622)	Acc@1 87.891 (87.103)	Acc@5 99.609 (99.528)
Epoch: [77][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.5906 (0.6668)	Acc@1 88.672 (86.830)	Acc@5 100.000 (99.512)
Max memory in training epoch: 62.0855808
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.184 (0.184)	Data 0.315 (0.315)	Loss 0.6532 (0.6532)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.6153 (0.6676)	Acc@1 91.016 (86.761)	Acc@5 99.219 (99.369)
Epoch: [78][128/196]	Time 0.125 (0.127)	Data 0.000 (0.003)	Loss 0.6666 (0.6692)	Acc@1 86.719 (86.728)	Acc@5 99.219 (99.413)
Epoch: [78][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6684 (0.6778)	Acc@1 87.109 (86.391)	Acc@5 99.609 (99.405)
Max memory in training epoch: 62.0855808
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.183 (0.183)	Data 0.300 (0.300)	Loss 0.6798 (0.6798)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [79][64/196]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 0.7260 (0.6520)	Acc@1 83.594 (87.145)	Acc@5 98.828 (99.567)
Epoch: [79][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6727 (0.6638)	Acc@1 85.938 (86.934)	Acc@5 99.219 (99.458)
Epoch: [79][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6507 (0.6690)	Acc@1 85.938 (86.713)	Acc@5 100.000 (99.437)
Max memory in training epoch: 62.0855808
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.180 (0.180)	Data 0.316 (0.316)	Loss 0.6403 (0.6403)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.130 (0.128)	Data 0.000 (0.005)	Loss 0.6410 (0.6481)	Acc@1 87.109 (87.464)	Acc@5 99.609 (99.567)
Epoch: [80][128/196]	Time 0.129 (0.128)	Data 0.000 (0.003)	Loss 0.6297 (0.6608)	Acc@1 86.719 (87.118)	Acc@5 99.609 (99.491)
Epoch: [80][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.8046 (0.6639)	Acc@1 83.984 (87.010)	Acc@5 98.438 (99.478)
Max memory in training epoch: 62.0855808
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 364266 ; 367156 ; 0.9921286864439094
[INFO] Storing checkpoint...
  81.63
Max memory: 95.3029632
 25.417s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4338
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1537536
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.203 (0.203)	Data 0.297 (0.297)	Loss 0.7287 (0.7287)	Acc@1 85.547 (85.547)	Acc@5 98.438 (98.438)
Epoch: [81][64/196]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.6129 (0.6258)	Acc@1 88.281 (88.329)	Acc@5 99.219 (99.549)
Epoch: [81][128/196]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.6481 (0.6474)	Acc@1 88.672 (87.506)	Acc@5 98.828 (99.416)
Epoch: [81][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.6376 (0.6560)	Acc@1 86.719 (87.196)	Acc@5 99.219 (99.437)
Max memory in training epoch: 60.9729024
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.180 (0.180)	Data 0.302 (0.302)	Loss 0.6280 (0.6280)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.6369 (0.6639)	Acc@1 88.672 (86.725)	Acc@5 99.219 (99.459)
Epoch: [82][128/196]	Time 0.128 (0.132)	Data 0.000 (0.003)	Loss 0.6624 (0.6596)	Acc@1 86.719 (86.961)	Acc@5 99.609 (99.482)
Epoch: [82][192/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.6682 (0.6658)	Acc@1 85.938 (86.784)	Acc@5 99.609 (99.433)
Max memory in training epoch: 61.2612608
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.187 (0.187)	Data 0.266 (0.266)	Loss 0.6231 (0.6231)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.6772 (0.6637)	Acc@1 86.719 (86.761)	Acc@5 99.609 (99.321)
Epoch: [83][128/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.5452 (0.6602)	Acc@1 91.016 (86.873)	Acc@5 99.609 (99.422)
Epoch: [83][192/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.6324 (0.6667)	Acc@1 87.109 (86.650)	Acc@5 99.609 (99.425)
Max memory in training epoch: 61.2547072
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.157 (0.157)	Data 0.305 (0.305)	Loss 0.7108 (0.7108)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [84][64/196]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.6524 (0.6613)	Acc@1 86.719 (86.947)	Acc@5 99.219 (99.489)
Epoch: [84][128/196]	Time 0.137 (0.127)	Data 0.000 (0.003)	Loss 0.6958 (0.6587)	Acc@1 88.281 (86.864)	Acc@5 100.000 (99.485)
Epoch: [84][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7271 (0.6624)	Acc@1 87.891 (86.840)	Acc@5 97.656 (99.454)
Max memory in training epoch: 61.2612608
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.171 (0.171)	Data 0.300 (0.300)	Loss 0.7008 (0.7008)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.5826 (0.6438)	Acc@1 89.453 (87.530)	Acc@5 99.609 (99.513)
Epoch: [85][128/196]	Time 0.175 (0.129)	Data 0.000 (0.002)	Loss 0.7387 (0.6545)	Acc@1 85.156 (87.197)	Acc@5 98.828 (99.485)
Epoch: [85][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6686 (0.6608)	Acc@1 87.891 (86.947)	Acc@5 99.609 (99.452)
Max memory in training epoch: 61.2612608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 360154 ; 364266 ; 0.9887115459581735
[INFO] Storing checkpoint...
  79.76
Max memory: 94.5126912
 25.557s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8582
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1516032
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.212 (0.212)	Data 0.275 (0.275)	Loss 0.6939 (0.6939)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [86][64/196]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.6289 (0.6397)	Acc@1 88.281 (87.518)	Acc@5 100.000 (99.561)
Epoch: [86][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.7239 (0.6544)	Acc@1 86.719 (87.091)	Acc@5 99.609 (99.467)
Epoch: [86][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.5817 (0.6562)	Acc@1 89.844 (87.097)	Acc@5 100.000 (99.456)
Max memory in training epoch: 58.5010688
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.174 (0.174)	Data 0.323 (0.323)	Loss 0.6830 (0.6830)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.137 (0.123)	Data 0.000 (0.005)	Loss 0.7266 (0.6774)	Acc@1 83.984 (86.220)	Acc@5 99.609 (99.399)
Epoch: [87][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.6207 (0.6688)	Acc@1 87.109 (86.492)	Acc@5 99.219 (99.485)
Epoch: [87][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6573 (0.6702)	Acc@1 85.938 (86.437)	Acc@5 100.000 (99.478)
Max memory in training epoch: 58.8025344
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.147 (0.147)	Data 0.273 (0.273)	Loss 0.6248 (0.6248)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.6794 (0.6563)	Acc@1 84.375 (86.839)	Acc@5 98.828 (99.471)
Epoch: [88][128/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.7357 (0.6566)	Acc@1 83.203 (86.979)	Acc@5 99.609 (99.467)
Epoch: [88][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6559 (0.6629)	Acc@1 87.500 (86.854)	Acc@5 99.609 (99.458)
Max memory in training epoch: 58.907392
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.171 (0.171)	Data 0.296 (0.296)	Loss 0.7725 (0.7725)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [89][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.6024 (0.6758)	Acc@1 89.062 (86.322)	Acc@5 98.828 (99.447)
Epoch: [89][128/196]	Time 0.128 (0.120)	Data 0.000 (0.002)	Loss 0.6889 (0.6703)	Acc@1 84.375 (86.595)	Acc@5 99.609 (99.479)
Epoch: [89][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6279 (0.6720)	Acc@1 87.500 (86.545)	Acc@5 99.609 (99.490)
Max memory in training epoch: 58.907392
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.171 (0.171)	Data 0.265 (0.265)	Loss 0.6431 (0.6431)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.7157 (0.6461)	Acc@1 84.766 (87.254)	Acc@5 99.609 (99.609)
Epoch: [90][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7656 (0.6531)	Acc@1 84.375 (87.197)	Acc@5 99.609 (99.561)
Epoch: [90][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.5849 (0.6586)	Acc@1 89.062 (86.974)	Acc@5 99.609 (99.484)
Max memory in training epoch: 58.907392
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 358420 ; 360154 ; 0.9951853929152529
[INFO] Storing checkpoint...
  75.07
Max memory: 90.7483648
 24.038s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5192
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1508864
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.188 (0.188)	Data 0.269 (0.269)	Loss 0.5969 (0.5969)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.6766 (0.6346)	Acc@1 86.719 (87.885)	Acc@5 99.609 (99.603)
Epoch: [91][128/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.7127 (0.6438)	Acc@1 86.719 (87.548)	Acc@5 98.438 (99.546)
Epoch: [91][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6626 (0.6513)	Acc@1 85.547 (87.269)	Acc@5 99.609 (99.464)
Max memory in training epoch: 58.4719872
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.151 (0.151)	Data 0.293 (0.293)	Loss 0.6048 (0.6048)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.126 (0.123)	Data 0.000 (0.005)	Loss 0.7084 (0.6676)	Acc@1 85.547 (86.635)	Acc@5 99.219 (99.531)
Epoch: [92][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.7871 (0.6651)	Acc@1 82.031 (86.695)	Acc@5 99.219 (99.516)
Epoch: [92][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.7808 (0.6640)	Acc@1 82.812 (86.721)	Acc@5 99.219 (99.514)
Max memory in training epoch: 58.5506304
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.142 (0.142)	Data 0.308 (0.308)	Loss 0.5571 (0.5571)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.4650 (0.5581)	Acc@1 93.750 (90.577)	Acc@5 100.000 (99.742)
Epoch: [93][128/196]	Time 0.122 (0.122)	Data 0.000 (0.003)	Loss 0.4526 (0.5335)	Acc@1 94.141 (91.364)	Acc@5 100.000 (99.788)
Epoch: [93][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.5131 (0.5234)	Acc@1 91.016 (91.720)	Acc@5 100.000 (99.775)
Max memory in training epoch: 58.5506304
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.164 (0.164)	Data 0.306 (0.306)	Loss 0.4805 (0.4805)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.4804 (0.4847)	Acc@1 91.797 (92.927)	Acc@5 100.000 (99.814)
Epoch: [94][128/196]	Time 0.119 (0.125)	Data 0.000 (0.003)	Loss 0.4933 (0.4754)	Acc@1 92.188 (93.278)	Acc@5 99.609 (99.827)
Epoch: [94][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.4513 (0.4735)	Acc@1 93.750 (93.236)	Acc@5 100.000 (99.840)
Max memory in training epoch: 58.5506304
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.144 (0.144)	Data 0.319 (0.319)	Loss 0.4195 (0.4195)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.5091 (0.4562)	Acc@1 92.578 (93.798)	Acc@5 99.609 (99.850)
Epoch: [95][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.4592 (0.4531)	Acc@1 93.359 (93.808)	Acc@5 100.000 (99.861)
Epoch: [95][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.4935 (0.4516)	Acc@1 91.797 (93.766)	Acc@5 99.609 (99.864)
Max memory in training epoch: 58.5506304
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356974 ; 358420 ; 0.9959656269181407
[INFO] Storing checkpoint...
  90.79
Max memory: 90.8166656
 24.369s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2769
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.204 (0.204)	Data 0.313 (0.313)	Loss 0.4112 (0.4112)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.3996 (0.4322)	Acc@1 94.922 (94.237)	Acc@5 100.000 (99.904)
Epoch: [96][128/196]	Time 0.126 (0.121)	Data 0.000 (0.003)	Loss 0.4302 (0.4366)	Acc@1 94.531 (94.083)	Acc@5 100.000 (99.876)
Epoch: [96][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3665 (0.4346)	Acc@1 97.266 (94.131)	Acc@5 100.000 (99.887)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.174 (0.174)	Data 0.266 (0.266)	Loss 0.3989 (0.3989)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.4013 (0.4189)	Acc@1 96.484 (94.633)	Acc@5 100.000 (99.880)
Epoch: [97][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.4605 (0.4210)	Acc@1 93.359 (94.410)	Acc@5 99.609 (99.885)
Epoch: [97][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.4048 (0.4198)	Acc@1 94.922 (94.438)	Acc@5 100.000 (99.889)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.180 (0.180)	Data 0.270 (0.270)	Loss 0.4320 (0.4320)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.4124 (0.4025)	Acc@1 94.531 (94.916)	Acc@5 100.000 (99.892)
Epoch: [98][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3773 (0.4039)	Acc@1 96.094 (94.858)	Acc@5 100.000 (99.897)
Epoch: [98][192/196]	Time 0.127 (0.120)	Data 0.000 (0.002)	Loss 0.4581 (0.4045)	Acc@1 92.969 (94.782)	Acc@5 100.000 (99.901)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.145 (0.145)	Data 0.317 (0.317)	Loss 0.4054 (0.4054)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.3897 (0.4010)	Acc@1 94.922 (94.748)	Acc@5 100.000 (99.922)
Epoch: [99][128/196]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.4282 (0.3983)	Acc@1 94.922 (94.873)	Acc@5 99.609 (99.915)
Epoch: [99][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3896 (0.3981)	Acc@1 94.922 (94.875)	Acc@5 100.000 (99.923)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.147 (0.147)	Data 0.320 (0.320)	Loss 0.3630 (0.3630)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.3102 (0.3851)	Acc@1 96.875 (95.150)	Acc@5 100.000 (99.916)
Epoch: [100][128/196]	Time 0.117 (0.123)	Data 0.000 (0.003)	Loss 0.3851 (0.3861)	Acc@1 94.531 (95.067)	Acc@5 100.000 (99.927)
Epoch: [100][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3841 (0.3872)	Acc@1 95.703 (95.015)	Acc@5 100.000 (99.915)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.42
Max memory: 90.4444416
 24.284s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5255
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.196 (0.196)	Data 0.331 (0.331)	Loss 0.3982 (0.3982)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.4172 (0.3732)	Acc@1 93.359 (95.637)	Acc@5 99.609 (99.952)
Epoch: [101][128/196]	Time 0.129 (0.120)	Data 0.000 (0.003)	Loss 0.3381 (0.3734)	Acc@1 96.484 (95.518)	Acc@5 100.000 (99.936)
Epoch: [101][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3528 (0.3725)	Acc@1 94.922 (95.485)	Acc@5 100.000 (99.941)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.161 (0.161)	Data 0.298 (0.298)	Loss 0.3268 (0.3268)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.3853 (0.3646)	Acc@1 93.750 (95.607)	Acc@5 100.000 (99.928)
Epoch: [102][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3759 (0.3672)	Acc@1 94.531 (95.506)	Acc@5 100.000 (99.945)
Epoch: [102][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3566 (0.3675)	Acc@1 95.703 (95.458)	Acc@5 100.000 (99.941)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.161 (0.161)	Data 0.274 (0.274)	Loss 0.3968 (0.3968)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [103][64/196]	Time 0.138 (0.121)	Data 0.000 (0.004)	Loss 0.3432 (0.3592)	Acc@1 95.703 (95.673)	Acc@5 100.000 (99.928)
Epoch: [103][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3773 (0.3615)	Acc@1 94.922 (95.591)	Acc@5 100.000 (99.921)
Epoch: [103][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3439 (0.3619)	Acc@1 96.094 (95.578)	Acc@5 100.000 (99.919)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.148 (0.148)	Data 0.290 (0.290)	Loss 0.3151 (0.3151)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.116 (0.121)	Data 0.000 (0.005)	Loss 0.3493 (0.3459)	Acc@1 94.922 (96.160)	Acc@5 99.609 (99.916)
Epoch: [104][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3163 (0.3515)	Acc@1 97.266 (95.836)	Acc@5 99.609 (99.918)
Epoch: [104][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3086 (0.3505)	Acc@1 97.656 (95.823)	Acc@5 100.000 (99.925)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.149 (0.149)	Data 0.265 (0.265)	Loss 0.3468 (0.3468)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [105][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.3080 (0.3427)	Acc@1 97.656 (95.986)	Acc@5 100.000 (99.958)
Epoch: [105][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3232 (0.3432)	Acc@1 97.266 (95.951)	Acc@5 100.000 (99.952)
Epoch: [105][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3725 (0.3442)	Acc@1 95.703 (95.918)	Acc@5 100.000 (99.949)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.45
Max memory: 90.4444416
 24.057s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9117
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.175 (0.175)	Data 0.279 (0.279)	Loss 0.3485 (0.3485)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.3528 (0.3270)	Acc@1 96.094 (96.460)	Acc@5 100.000 (99.946)
Epoch: [106][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.3196 (0.3304)	Acc@1 97.266 (96.254)	Acc@5 100.000 (99.955)
Epoch: [106][192/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.3430 (0.3348)	Acc@1 95.703 (96.055)	Acc@5 100.000 (99.947)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.140 (0.140)	Data 0.291 (0.291)	Loss 0.3003 (0.3003)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.3141 (0.3287)	Acc@1 96.484 (96.238)	Acc@5 100.000 (99.958)
Epoch: [107][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3314 (0.3306)	Acc@1 96.875 (96.121)	Acc@5 100.000 (99.964)
Epoch: [107][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3834 (0.3309)	Acc@1 94.922 (96.061)	Acc@5 99.609 (99.953)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.177 (0.177)	Data 0.256 (0.256)	Loss 0.3696 (0.3696)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.3179 (0.3270)	Acc@1 95.703 (95.980)	Acc@5 100.000 (99.934)
Epoch: [108][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3094 (0.3268)	Acc@1 97.266 (95.988)	Acc@5 100.000 (99.952)
Epoch: [108][192/196]	Time 0.118 (0.121)	Data 0.000 (0.001)	Loss 0.2952 (0.3280)	Acc@1 96.484 (95.958)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.159 (0.159)	Data 0.285 (0.285)	Loss 0.3365 (0.3365)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.3431 (0.3148)	Acc@1 94.922 (96.364)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3145 (0.3198)	Acc@1 97.266 (96.203)	Acc@5 100.000 (99.967)
Epoch: [109][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2971 (0.3244)	Acc@1 97.656 (96.039)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.151 (0.151)	Data 0.322 (0.322)	Loss 0.3705 (0.3705)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.3534 (0.3192)	Acc@1 94.922 (96.412)	Acc@5 100.000 (99.940)
Epoch: [110][128/196]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.2979 (0.3193)	Acc@1 97.266 (96.191)	Acc@5 100.000 (99.942)
Epoch: [110][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3215 (0.3196)	Acc@1 95.312 (96.124)	Acc@5 100.000 (99.945)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.46
Max memory: 90.4444416
 24.304s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 685
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.181 (0.181)	Data 0.274 (0.274)	Loss 0.3449 (0.3449)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.3244 (0.3044)	Acc@1 94.922 (96.490)	Acc@5 100.000 (99.952)
Epoch: [111][128/196]	Time 0.118 (0.126)	Data 0.000 (0.002)	Loss 0.3075 (0.3100)	Acc@1 96.875 (96.303)	Acc@5 100.000 (99.945)
Epoch: [111][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.3091 (0.3112)	Acc@1 96.484 (96.304)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.182 (0.182)	Data 0.266 (0.266)	Loss 0.3113 (0.3113)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.3296 (0.3074)	Acc@1 95.312 (96.346)	Acc@5 99.609 (99.964)
Epoch: [112][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3108 (0.3093)	Acc@1 96.875 (96.288)	Acc@5 100.000 (99.973)
Epoch: [112][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2774 (0.3118)	Acc@1 96.875 (96.156)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.188 (0.188)	Data 0.289 (0.289)	Loss 0.3199 (0.3199)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.2897 (0.3054)	Acc@1 96.875 (96.484)	Acc@5 100.000 (99.958)
Epoch: [113][128/196]	Time 0.131 (0.123)	Data 0.000 (0.002)	Loss 0.3073 (0.3100)	Acc@1 96.484 (96.257)	Acc@5 100.000 (99.955)
Epoch: [113][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3230 (0.3106)	Acc@1 95.312 (96.104)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.176 (0.176)	Data 0.266 (0.266)	Loss 0.2842 (0.2842)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2915 (0.3084)	Acc@1 96.875 (96.190)	Acc@5 100.000 (99.958)
Epoch: [114][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.3542 (0.3059)	Acc@1 94.922 (96.200)	Acc@5 100.000 (99.964)
Epoch: [114][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.3252 (0.3086)	Acc@1 96.094 (96.039)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.161 (0.161)	Data 0.298 (0.298)	Loss 0.3016 (0.3016)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2744 (0.3026)	Acc@1 96.875 (96.352)	Acc@5 100.000 (99.946)
Epoch: [115][128/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.2759 (0.3056)	Acc@1 97.656 (96.148)	Acc@5 100.000 (99.955)
Epoch: [115][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3351 (0.3056)	Acc@1 96.484 (96.159)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.21
Max memory: 90.4444416
 24.170s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6628
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.195 (0.195)	Data 0.262 (0.262)	Loss 0.2805 (0.2805)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.2989 (0.2926)	Acc@1 96.094 (96.436)	Acc@5 100.000 (99.988)
Epoch: [116][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3034 (0.2996)	Acc@1 96.094 (96.200)	Acc@5 100.000 (99.970)
Epoch: [116][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3121 (0.3013)	Acc@1 97.266 (96.159)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.145 (0.145)	Data 0.289 (0.289)	Loss 0.3313 (0.3313)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.3198 (0.2946)	Acc@1 94.922 (96.394)	Acc@5 100.000 (99.952)
Epoch: [117][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.3265 (0.2963)	Acc@1 93.359 (96.360)	Acc@5 100.000 (99.958)
Epoch: [117][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.3100 (0.3002)	Acc@1 95.703 (96.209)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.147 (0.147)	Data 0.304 (0.304)	Loss 0.3067 (0.3067)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.3058 (0.2943)	Acc@1 96.484 (96.430)	Acc@5 100.000 (99.952)
Epoch: [118][128/196]	Time 0.124 (0.123)	Data 0.000 (0.003)	Loss 0.2843 (0.2957)	Acc@1 96.094 (96.330)	Acc@5 100.000 (99.964)
Epoch: [118][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3302 (0.2991)	Acc@1 95.703 (96.250)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.158 (0.158)	Data 0.297 (0.297)	Loss 0.3134 (0.3134)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [119][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.3240 (0.2898)	Acc@1 96.484 (96.550)	Acc@5 100.000 (99.982)
Epoch: [119][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3293 (0.2937)	Acc@1 95.312 (96.397)	Acc@5 99.609 (99.979)
Epoch: [119][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.3292 (0.2943)	Acc@1 95.703 (96.343)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.150 (0.150)	Data 0.294 (0.294)	Loss 0.2400 (0.2400)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.3152 (0.2958)	Acc@1 95.312 (96.250)	Acc@5 100.000 (99.970)
Epoch: [120][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.2950 (0.2986)	Acc@1 96.094 (96.070)	Acc@5 100.000 (99.982)
Epoch: [120][192/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.2454 (0.3010)	Acc@1 98.047 (95.952)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.52
Max memory: 90.4444416
 24.455s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6273
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.198 (0.198)	Data 0.260 (0.260)	Loss 0.3121 (0.3121)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.2403 (0.2845)	Acc@1 98.438 (96.617)	Acc@5 100.000 (99.958)
Epoch: [121][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2891 (0.2859)	Acc@1 96.875 (96.578)	Acc@5 100.000 (99.967)
Epoch: [121][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2779 (0.2882)	Acc@1 96.875 (96.464)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.171 (0.171)	Data 0.266 (0.266)	Loss 0.2958 (0.2958)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.3142 (0.2906)	Acc@1 95.703 (96.274)	Acc@5 100.000 (99.958)
Epoch: [122][128/196]	Time 0.126 (0.121)	Data 0.000 (0.002)	Loss 0.2753 (0.2929)	Acc@1 98.047 (96.212)	Acc@5 100.000 (99.967)
Epoch: [122][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2854 (0.2964)	Acc@1 96.484 (96.037)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.176 (0.176)	Data 0.280 (0.280)	Loss 0.2652 (0.2652)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.2659 (0.2924)	Acc@1 98.438 (96.238)	Acc@5 99.609 (99.964)
Epoch: [123][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2702 (0.2926)	Acc@1 96.875 (96.236)	Acc@5 100.000 (99.967)
Epoch: [123][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2728 (0.2944)	Acc@1 98.047 (96.195)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.173 (0.173)	Data 0.277 (0.277)	Loss 0.2792 (0.2792)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.3098 (0.2862)	Acc@1 95.312 (96.448)	Acc@5 100.000 (99.958)
Epoch: [124][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2762 (0.2912)	Acc@1 97.266 (96.200)	Acc@5 100.000 (99.952)
Epoch: [124][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3207 (0.2975)	Acc@1 96.484 (95.972)	Acc@5 100.000 (99.949)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.151 (0.151)	Data 0.295 (0.295)	Loss 0.3384 (0.3384)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 0.3126 (0.2963)	Acc@1 96.484 (95.877)	Acc@5 99.609 (99.964)
Epoch: [125][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2553 (0.2969)	Acc@1 97.656 (95.885)	Acc@5 100.000 (99.961)
Epoch: [125][192/196]	Time 0.136 (0.120)	Data 0.000 (0.002)	Loss 0.3162 (0.2964)	Acc@1 96.094 (95.940)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.68
Max memory: 90.4444416
 23.963s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5241
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1503744
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.181 (0.181)	Data 0.285 (0.285)	Loss 0.2534 (0.2534)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.3039 (0.2735)	Acc@1 95.703 (96.719)	Acc@5 100.000 (99.982)
Epoch: [126][128/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.3161 (0.2819)	Acc@1 94.141 (96.421)	Acc@5 100.000 (99.979)
Epoch: [126][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2749 (0.2873)	Acc@1 95.703 (96.183)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.3388672
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.169 (0.169)	Data 0.295 (0.295)	Loss 0.2513 (0.2513)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.3053 (0.2823)	Acc@1 95.312 (96.526)	Acc@5 100.000 (99.964)
Epoch: [127][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3050 (0.2881)	Acc@1 95.703 (96.236)	Acc@5 100.000 (99.979)
Epoch: [127][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3156 (0.2927)	Acc@1 94.922 (96.047)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.175 (0.175)	Data 0.290 (0.290)	Loss 0.2628 (0.2628)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.116 (0.124)	Data 0.000 (0.005)	Loss 0.2263 (0.2837)	Acc@1 98.438 (96.232)	Acc@5 100.000 (99.970)
Epoch: [128][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.3141 (0.2861)	Acc@1 96.094 (96.197)	Acc@5 100.000 (99.964)
Epoch: [128][192/196]	Time 0.129 (0.123)	Data 0.000 (0.002)	Loss 0.3718 (0.2919)	Acc@1 91.797 (95.991)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.168 (0.168)	Data 0.288 (0.288)	Loss 0.2691 (0.2691)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.2787 (0.2876)	Acc@1 96.484 (96.118)	Acc@5 100.000 (99.988)
Epoch: [129][128/196]	Time 0.149 (0.122)	Data 0.000 (0.002)	Loss 0.3398 (0.2902)	Acc@1 94.531 (96.033)	Acc@5 100.000 (99.982)
Epoch: [129][192/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.3555 (0.2953)	Acc@1 92.969 (95.841)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.3323136
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.178 (0.178)	Data 0.280 (0.280)	Loss 0.2644 (0.2644)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.117 (0.125)	Data 0.000 (0.004)	Loss 0.3271 (0.2904)	Acc@1 95.312 (95.956)	Acc@5 100.000 (99.976)
Epoch: [130][128/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.2921 (0.2905)	Acc@1 95.703 (95.979)	Acc@5 100.000 (99.973)
Epoch: [130][192/196]	Time 0.135 (0.123)	Data 0.000 (0.002)	Loss 0.3172 (0.2938)	Acc@1 95.703 (95.867)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.3323136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356396 ; 356974 ; 0.998380834458532
[INFO] Storing checkpoint...
  89.27
Max memory: 90.4444416
 24.477s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4056
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1501696
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.196 (0.196)	Data 0.265 (0.265)	Loss 0.2783 (0.2783)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2950 (0.2769)	Acc@1 95.703 (96.556)	Acc@5 100.000 (99.982)
Epoch: [131][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2350 (0.2825)	Acc@1 98.047 (96.309)	Acc@5 100.000 (99.973)
Epoch: [131][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2807 (0.2872)	Acc@1 95.703 (96.076)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.338048
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.150 (0.150)	Data 0.259 (0.259)	Loss 0.2806 (0.2806)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.3017 (0.2884)	Acc@1 95.312 (96.190)	Acc@5 100.000 (99.952)
Epoch: [132][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2963 (0.2891)	Acc@1 94.922 (96.133)	Acc@5 100.000 (99.958)
Epoch: [132][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2503 (0.2934)	Acc@1 98.438 (95.926)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.140 (0.140)	Data 0.292 (0.292)	Loss 0.2548 (0.2548)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.126 (0.120)	Data 0.000 (0.005)	Loss 0.3184 (0.2872)	Acc@1 94.141 (95.974)	Acc@5 100.000 (99.940)
Epoch: [133][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2869 (0.2874)	Acc@1 96.484 (95.991)	Acc@5 100.000 (99.958)
Epoch: [133][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2778 (0.2926)	Acc@1 96.094 (95.873)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.141 (0.141)	Data 0.281 (0.281)	Loss 0.2681 (0.2681)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.125 (0.122)	Data 0.000 (0.005)	Loss 0.2882 (0.2868)	Acc@1 95.703 (96.118)	Acc@5 100.000 (99.976)
Epoch: [134][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2964 (0.2886)	Acc@1 95.703 (96.082)	Acc@5 100.000 (99.976)
Epoch: [134][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2295 (0.2914)	Acc@1 97.656 (95.952)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.155 (0.155)	Data 0.269 (0.269)	Loss 0.2507 (0.2507)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.138 (0.122)	Data 0.000 (0.004)	Loss 0.2573 (0.2845)	Acc@1 96.484 (96.100)	Acc@5 100.000 (99.970)
Epoch: [135][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2657 (0.2906)	Acc@1 97.266 (95.933)	Acc@5 100.000 (99.964)
Epoch: [135][192/196]	Time 0.142 (0.122)	Data 0.000 (0.002)	Loss 0.2981 (0.2941)	Acc@1 94.922 (95.802)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.09
Max memory: 90.4438272
 24.163s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5597
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1501696
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.194 (0.194)	Data 0.258 (0.258)	Loss 0.2627 (0.2627)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.132 (0.121)	Data 0.000 (0.004)	Loss 0.2884 (0.2706)	Acc@1 96.094 (96.689)	Acc@5 100.000 (99.976)
Epoch: [136][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2518 (0.2786)	Acc@1 97.266 (96.394)	Acc@5 100.000 (99.979)
Epoch: [136][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3067 (0.2843)	Acc@1 95.703 (96.169)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.338048
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.180 (0.180)	Data 0.264 (0.264)	Loss 0.2297 (0.2297)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.3157 (0.2805)	Acc@1 96.094 (96.352)	Acc@5 99.609 (99.982)
Epoch: [137][128/196]	Time 0.110 (0.121)	Data 0.000 (0.002)	Loss 0.3264 (0.2863)	Acc@1 93.359 (96.021)	Acc@5 100.000 (99.979)
Epoch: [137][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3074 (0.2919)	Acc@1 95.312 (95.814)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.159 (0.159)	Data 0.266 (0.266)	Loss 0.2948 (0.2948)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.2991 (0.2940)	Acc@1 96.875 (95.757)	Acc@5 99.609 (99.964)
Epoch: [138][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3287 (0.2905)	Acc@1 95.312 (95.894)	Acc@5 99.609 (99.952)
Epoch: [138][192/196]	Time 0.128 (0.120)	Data 0.000 (0.002)	Loss 0.2876 (0.2944)	Acc@1 96.484 (95.748)	Acc@5 100.000 (99.949)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.156 (0.156)	Data 0.269 (0.269)	Loss 0.2528 (0.2528)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.3060 (0.2885)	Acc@1 95.703 (96.076)	Acc@5 100.000 (99.988)
Epoch: [139][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.3012 (0.2907)	Acc@1 94.922 (95.897)	Acc@5 100.000 (99.961)
Epoch: [139][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.3286 (0.2929)	Acc@1 95.312 (95.831)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.154 (0.154)	Data 0.294 (0.294)	Loss 0.2731 (0.2731)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2931 (0.2816)	Acc@1 94.922 (96.154)	Acc@5 100.000 (99.988)
Epoch: [140][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2787 (0.2836)	Acc@1 96.484 (96.151)	Acc@5 100.000 (99.976)
Epoch: [140][192/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.2986 (0.2879)	Acc@1 95.312 (95.968)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.58
Max memory: 90.4438272
 24.087s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8626
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1501696
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.182 (0.182)	Data 0.291 (0.291)	Loss 0.2305 (0.2305)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.2665 (0.2624)	Acc@1 96.094 (97.001)	Acc@5 100.000 (99.976)
Epoch: [141][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3348 (0.2774)	Acc@1 94.531 (96.378)	Acc@5 100.000 (99.982)
Epoch: [141][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2478 (0.2840)	Acc@1 97.656 (96.078)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.338048
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.162 (0.162)	Data 0.270 (0.270)	Loss 0.2846 (0.2846)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.3274 (0.2976)	Acc@1 94.922 (95.577)	Acc@5 100.000 (99.958)
Epoch: [142][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3190 (0.2987)	Acc@1 94.141 (95.473)	Acc@5 100.000 (99.952)
Epoch: [142][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.3149 (0.3007)	Acc@1 95.312 (95.422)	Acc@5 100.000 (99.951)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.147 (0.147)	Data 0.307 (0.307)	Loss 0.2860 (0.2860)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.2570 (0.2903)	Acc@1 96.875 (95.865)	Acc@5 100.000 (99.982)
Epoch: [143][128/196]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.2568 (0.2880)	Acc@1 98.047 (96.003)	Acc@5 100.000 (99.973)
Epoch: [143][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3476 (0.2907)	Acc@1 94.141 (95.877)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.167 (0.167)	Data 0.267 (0.267)	Loss 0.2511 (0.2511)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.2825 (0.2862)	Acc@1 96.875 (96.142)	Acc@5 100.000 (99.976)
Epoch: [144][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.2807 (0.2918)	Acc@1 96.875 (95.933)	Acc@5 100.000 (99.973)
Epoch: [144][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3152 (0.2939)	Acc@1 95.312 (95.831)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.143 (0.143)	Data 0.271 (0.271)	Loss 0.3169 (0.3169)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.131 (0.123)	Data 0.000 (0.004)	Loss 0.2383 (0.2892)	Acc@1 97.656 (95.925)	Acc@5 100.000 (99.976)
Epoch: [145][128/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.2929 (0.2872)	Acc@1 94.922 (96.048)	Acc@5 100.000 (99.976)
Epoch: [145][192/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.2443 (0.2888)	Acc@1 97.656 (95.974)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.82
Max memory: 90.4438272
 24.243s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5299
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1501696
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.180 (0.180)	Data 0.279 (0.279)	Loss 0.2930 (0.2930)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.133 (0.122)	Data 0.000 (0.004)	Loss 0.2777 (0.2774)	Acc@1 97.656 (96.340)	Acc@5 100.000 (99.970)
Epoch: [146][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2757 (0.2823)	Acc@1 96.094 (96.218)	Acc@5 100.000 (99.970)
Epoch: [146][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.2950 (0.2845)	Acc@1 96.484 (96.096)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.338048
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.173 (0.173)	Data 0.301 (0.301)	Loss 0.2530 (0.2530)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.2923 (0.2862)	Acc@1 96.484 (95.901)	Acc@5 100.000 (99.952)
Epoch: [147][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3140 (0.2867)	Acc@1 95.703 (95.915)	Acc@5 100.000 (99.961)
Epoch: [147][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3904 (0.2903)	Acc@1 93.359 (95.804)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.173 (0.173)	Data 0.267 (0.267)	Loss 0.2865 (0.2865)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.2733 (0.2850)	Acc@1 94.531 (96.040)	Acc@5 100.000 (99.982)
Epoch: [148][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2625 (0.2908)	Acc@1 96.875 (95.809)	Acc@5 100.000 (99.964)
Epoch: [148][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2625 (0.2912)	Acc@1 97.266 (95.778)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.167 (0.167)	Data 0.274 (0.274)	Loss 0.2877 (0.2877)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3206 (0.2844)	Acc@1 94.531 (95.974)	Acc@5 100.000 (99.958)
Epoch: [149][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2628 (0.2867)	Acc@1 94.922 (95.867)	Acc@5 100.000 (99.955)
Epoch: [149][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3493 (0.2931)	Acc@1 93.359 (95.675)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.2790656
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.155 (0.155)	Data 0.284 (0.284)	Loss 0.2401 (0.2401)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2199 (0.2608)	Acc@1 98.438 (96.983)	Acc@5 100.000 (99.994)
Epoch: [150][128/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.3296 (0.2548)	Acc@1 93.750 (97.196)	Acc@5 100.000 (99.985)
Epoch: [150][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.2421 (0.2477)	Acc@1 96.875 (97.504)	Acc@5 100.000 (99.986)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.51
Max memory: 90.4438272
 24.384s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2827
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1501696
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.191 (0.191)	Data 0.274 (0.274)	Loss 0.2517 (0.2517)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.2526 (0.2315)	Acc@1 97.656 (98.137)	Acc@5 100.000 (99.994)
Epoch: [151][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2313 (0.2283)	Acc@1 98.438 (98.229)	Acc@5 100.000 (99.994)
Epoch: [151][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2281 (0.2274)	Acc@1 97.656 (98.263)	Acc@5 100.000 (99.992)
Max memory in training epoch: 58.338048
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.167 (0.167)	Data 0.253 (0.253)	Loss 0.2196 (0.2196)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.2179 (0.2233)	Acc@1 98.438 (98.395)	Acc@5 100.000 (100.000)
Epoch: [152][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2119 (0.2223)	Acc@1 99.219 (98.465)	Acc@5 100.000 (99.997)
Epoch: [152][192/196]	Time 0.121 (0.119)	Data 0.000 (0.001)	Loss 0.2248 (0.2212)	Acc@1 97.656 (98.478)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.161 (0.161)	Data 0.294 (0.294)	Loss 0.2142 (0.2142)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 0.2304 (0.2178)	Acc@1 97.656 (98.588)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2303 (0.2180)	Acc@1 97.656 (98.540)	Acc@5 100.000 (99.997)
Epoch: [153][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2234 (0.2170)	Acc@1 97.656 (98.585)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.170 (0.170)	Data 0.263 (0.263)	Loss 0.2403 (0.2403)	Acc@1 98.438 (98.438)	Acc@5 99.609 (99.609)
Epoch: [154][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.1999 (0.2117)	Acc@1 99.609 (98.828)	Acc@5 100.000 (99.988)
Epoch: [154][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2036 (0.2111)	Acc@1 99.219 (98.849)	Acc@5 100.000 (99.991)
Epoch: [154][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2157 (0.2113)	Acc@1 98.438 (98.812)	Acc@5 100.000 (99.992)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.174 (0.174)	Data 0.297 (0.297)	Loss 0.2173 (0.2173)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.1926 (0.2107)	Acc@1 99.219 (98.798)	Acc@5 100.000 (99.994)
Epoch: [155][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.1859 (0.2095)	Acc@1 99.609 (98.877)	Acc@5 100.000 (99.997)
Epoch: [155][192/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.1926 (0.2088)	Acc@1 99.609 (98.893)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.74
Max memory: 90.4438272
 23.949s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3006
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1501696
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.170 (0.170)	Data 0.304 (0.304)	Loss 0.2207 (0.2207)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.2009 (0.2062)	Acc@1 99.609 (99.014)	Acc@5 100.000 (99.988)
Epoch: [156][128/196]	Time 0.115 (0.122)	Data 0.000 (0.003)	Loss 0.2003 (0.2071)	Acc@1 98.828 (98.967)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1980 (0.2067)	Acc@1 98.828 (98.948)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.338048
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.172 (0.172)	Data 0.277 (0.277)	Loss 0.1949 (0.1949)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.1826 (0.2049)	Acc@1 100.000 (98.900)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2063 (0.2047)	Acc@1 98.828 (98.958)	Acc@5 100.000 (99.997)
Epoch: [157][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2005 (0.2045)	Acc@1 99.219 (98.964)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.168 (0.168)	Data 0.286 (0.286)	Loss 0.1990 (0.1990)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.1962 (0.2035)	Acc@1 99.609 (99.020)	Acc@5 100.000 (99.988)
Epoch: [158][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1819 (0.2030)	Acc@1 100.000 (99.082)	Acc@5 100.000 (99.991)
Epoch: [158][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1871 (0.2028)	Acc@1 100.000 (99.059)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.137 (0.137)	Data 0.291 (0.291)	Loss 0.2442 (0.2442)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2083 (0.2013)	Acc@1 98.828 (99.038)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1921 (0.2008)	Acc@1 100.000 (99.067)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1946 (0.2005)	Acc@1 99.219 (99.045)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.173 (0.173)	Data 0.273 (0.273)	Loss 0.1924 (0.1924)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.1936 (0.1993)	Acc@1 99.219 (99.111)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.2068 (0.1984)	Acc@1 98.047 (99.146)	Acc@5 100.000 (99.997)
Epoch: [160][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2023 (0.1988)	Acc@1 98.828 (99.138)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.85
Max memory: 90.4438272
 24.260s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4342
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1501696
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.182 (0.182)	Data 0.284 (0.284)	Loss 0.1874 (0.1874)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.124 (0.125)	Data 0.000 (0.005)	Loss 0.2054 (0.1952)	Acc@1 98.828 (99.297)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.1988 (0.1959)	Acc@1 99.219 (99.243)	Acc@5 100.000 (99.997)
Epoch: [161][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.1860 (0.1959)	Acc@1 99.609 (99.241)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.338048
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.173 (0.173)	Data 0.281 (0.281)	Loss 0.2028 (0.2028)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.2170 (0.1968)	Acc@1 97.266 (99.201)	Acc@5 100.000 (99.982)
Epoch: [162][128/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.2208 (0.1954)	Acc@1 98.047 (99.270)	Acc@5 100.000 (99.985)
Epoch: [162][192/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.1992 (0.1958)	Acc@1 99.219 (99.225)	Acc@5 100.000 (99.990)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.171 (0.171)	Data 0.294 (0.294)	Loss 0.1949 (0.1949)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.1979 (0.1953)	Acc@1 99.219 (99.213)	Acc@5 100.000 (99.994)
Epoch: [163][128/196]	Time 0.115 (0.124)	Data 0.000 (0.002)	Loss 0.1969 (0.1944)	Acc@1 99.609 (99.219)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1886 (0.1942)	Acc@1 99.219 (99.237)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.174 (0.174)	Data 0.290 (0.290)	Loss 0.1953 (0.1953)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.1988 (0.1936)	Acc@1 98.438 (99.303)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.1828 (0.1928)	Acc@1 100.000 (99.343)	Acc@5 100.000 (99.997)
Epoch: [164][192/196]	Time 0.128 (0.123)	Data 0.000 (0.002)	Loss 0.2184 (0.1930)	Acc@1 97.656 (99.322)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.152 (0.152)	Data 0.299 (0.299)	Loss 0.1896 (0.1896)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.1807 (0.1920)	Acc@1 100.000 (99.321)	Acc@5 100.000 (99.994)
Epoch: [165][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1786 (0.1918)	Acc@1 100.000 (99.310)	Acc@5 100.000 (99.994)
Epoch: [165][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.1943 (0.1917)	Acc@1 99.609 (99.324)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.76
Max memory: 90.4438272
 24.538s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1747
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1501696
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.173 (0.173)	Data 0.290 (0.290)	Loss 0.1965 (0.1965)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.113 (0.121)	Data 0.000 (0.005)	Loss 0.1928 (0.1902)	Acc@1 99.609 (99.291)	Acc@5 100.000 (99.994)
Epoch: [166][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2141 (0.1903)	Acc@1 98.047 (99.325)	Acc@5 100.000 (99.997)
Epoch: [166][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1894 (0.1913)	Acc@1 99.219 (99.281)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.338048
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.162 (0.162)	Data 0.304 (0.304)	Loss 0.1961 (0.1961)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.1809 (0.1898)	Acc@1 100.000 (99.357)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.125 (0.123)	Data 0.000 (0.003)	Loss 0.1920 (0.1913)	Acc@1 99.219 (99.310)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1879 (0.1907)	Acc@1 98.828 (99.342)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.169 (0.169)	Data 0.268 (0.268)	Loss 0.1715 (0.1715)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.1889 (0.1880)	Acc@1 99.219 (99.351)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1886 (0.1890)	Acc@1 99.609 (99.304)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1818 (0.1888)	Acc@1 100.000 (99.324)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.163 (0.163)	Data 0.262 (0.262)	Loss 0.2145 (0.2145)	Acc@1 98.438 (98.438)	Acc@5 99.609 (99.609)
Epoch: [169][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.1734 (0.1866)	Acc@1 100.000 (99.501)	Acc@5 100.000 (99.988)
Epoch: [169][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1872 (0.1874)	Acc@1 99.609 (99.458)	Acc@5 100.000 (99.994)
Epoch: [169][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.1807 (0.1876)	Acc@1 100.000 (99.439)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.169 (0.169)	Data 0.308 (0.308)	Loss 0.1887 (0.1887)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.1828 (0.1860)	Acc@1 99.219 (99.417)	Acc@5 100.000 (99.994)
Epoch: [170][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.1908 (0.1868)	Acc@1 98.828 (99.397)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2013 (0.1866)	Acc@1 98.438 (99.405)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.84
Max memory: 90.4438272
 24.021s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9339
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1501696
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.187 (0.187)	Data 0.291 (0.291)	Loss 0.1707 (0.1707)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.1797 (0.1842)	Acc@1 100.000 (99.519)	Acc@5 100.000 (99.994)
Epoch: [171][128/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.1831 (0.1841)	Acc@1 99.609 (99.516)	Acc@5 100.000 (99.997)
Epoch: [171][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1815 (0.1846)	Acc@1 98.828 (99.480)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.338048
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.151 (0.151)	Data 0.270 (0.270)	Loss 0.1770 (0.1770)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.1949 (0.1839)	Acc@1 99.219 (99.465)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.129 (0.124)	Data 0.000 (0.002)	Loss 0.1938 (0.1844)	Acc@1 98.828 (99.458)	Acc@5 100.000 (99.997)
Epoch: [172][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.1834 (0.1844)	Acc@1 99.219 (99.431)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.170 (0.170)	Data 0.340 (0.340)	Loss 0.1686 (0.1686)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.1876 (0.1817)	Acc@1 99.219 (99.537)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.115 (0.123)	Data 0.000 (0.003)	Loss 0.1758 (0.1816)	Acc@1 99.609 (99.558)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.1739 (0.1814)	Acc@1 99.609 (99.565)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.173 (0.173)	Data 0.278 (0.278)	Loss 0.1862 (0.1862)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.127 (0.124)	Data 0.000 (0.004)	Loss 0.2160 (0.1843)	Acc@1 97.656 (99.435)	Acc@5 99.609 (99.994)
Epoch: [174][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.1798 (0.1835)	Acc@1 99.609 (99.461)	Acc@5 100.000 (99.994)
Epoch: [174][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1949 (0.1835)	Acc@1 98.828 (99.447)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.164 (0.164)	Data 0.284 (0.284)	Loss 0.1902 (0.1902)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.1926 (0.1816)	Acc@1 98.438 (99.483)	Acc@5 100.000 (99.994)
Epoch: [175][128/196]	Time 0.131 (0.122)	Data 0.000 (0.002)	Loss 0.1743 (0.1814)	Acc@1 100.000 (99.509)	Acc@5 100.000 (99.997)
Epoch: [175][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1699 (0.1815)	Acc@1 100.000 (99.494)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.2790656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.7
Max memory: 90.4438272
 24.221s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 457
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1501696
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.195 (0.195)	Data 0.294 (0.294)	Loss 0.1813 (0.1813)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.1761 (0.1795)	Acc@1 99.609 (99.561)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2038 (0.1797)	Acc@1 98.828 (99.555)	Acc@5 100.000 (99.997)
Epoch: [176][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1862 (0.1806)	Acc@1 99.609 (99.528)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.338048
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.159 (0.159)	Data 0.295 (0.295)	Loss 0.1880 (0.1880)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.1710 (0.1802)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.1771 (0.1795)	Acc@1 99.609 (99.573)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1699 (0.1791)	Acc@1 100.000 (99.585)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.171 (0.171)	Data 0.320 (0.320)	Loss 0.1787 (0.1787)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.1829 (0.1780)	Acc@1 99.219 (99.633)	Acc@5 100.000 (99.994)
Epoch: [178][128/196]	Time 0.120 (0.126)	Data 0.000 (0.003)	Loss 0.1724 (0.1785)	Acc@1 100.000 (99.561)	Acc@5 100.000 (99.994)
Epoch: [178][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.1830 (0.1780)	Acc@1 99.609 (99.577)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.164 (0.164)	Data 0.298 (0.298)	Loss 0.2026 (0.2026)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.1941 (0.1797)	Acc@1 98.438 (99.447)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.1670 (0.1793)	Acc@1 100.000 (99.464)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1649 (0.1783)	Acc@1 100.000 (99.534)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.2790656
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.171 (0.171)	Data 0.289 (0.289)	Loss 0.1814 (0.1814)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.1763 (0.1752)	Acc@1 99.609 (99.645)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.1749 (0.1764)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1777 (0.1766)	Acc@1 99.609 (99.597)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.2790656
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 25, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(25, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(18, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(13, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.77
Max memory: 90.4438272
 24.086s  Thres 0.001 2
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9003
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.209 (0.209)	Data 0.292 (0.292)	Loss 3.1343 (3.1343)	Acc@1 11.328 (11.328)	Acc@5 46.484 (46.484)
Epoch: [1][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 2.4761 (2.5802)	Acc@1 28.516 (26.232)	Acc@5 85.938 (79.681)
Epoch: [1][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 2.2602 (2.4122)	Acc@1 35.938 (31.968)	Acc@5 86.719 (84.526)
Epoch: [1][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 1.8693 (2.2850)	Acc@1 54.688 (36.800)	Acc@5 94.531 (87.176)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.152 (0.152)	Data 0.270 (0.270)	Loss 1.9343 (1.9343)	Acc@1 48.438 (48.438)	Acc@5 93.750 (93.750)
Epoch: [2][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 1.6988 (1.8087)	Acc@1 56.641 (54.573)	Acc@5 96.094 (94.531)
Epoch: [2][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.6011 (1.7401)	Acc@1 58.594 (56.601)	Acc@5 97.266 (95.067)
Epoch: [2][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 1.4324 (1.6723)	Acc@1 64.844 (58.744)	Acc@5 96.484 (95.630)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.157 (0.157)	Data 0.275 (0.275)	Loss 1.6648 (1.6648)	Acc@1 61.328 (61.328)	Acc@5 95.703 (95.703)
Epoch: [3][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 1.3162 (1.4565)	Acc@1 69.531 (65.349)	Acc@5 98.047 (97.007)
Epoch: [3][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 1.3428 (1.4089)	Acc@1 63.672 (67.054)	Acc@5 98.438 (97.296)
Epoch: [3][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 1.3121 (1.3798)	Acc@1 68.750 (67.859)	Acc@5 98.047 (97.513)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.178 (0.178)	Data 0.267 (0.267)	Loss 1.2357 (1.2357)	Acc@1 73.438 (73.438)	Acc@5 99.219 (99.219)
Epoch: [4][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 1.2387 (1.2260)	Acc@1 75.391 (72.638)	Acc@5 98.438 (98.077)
Epoch: [4][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 1.3017 (1.2072)	Acc@1 66.797 (73.032)	Acc@5 99.219 (98.201)
Epoch: [4][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 1.0894 (1.1914)	Acc@1 76.172 (73.332)	Acc@5 97.656 (98.221)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.164 (0.164)	Data 0.295 (0.295)	Loss 1.1640 (1.1640)	Acc@1 74.219 (74.219)	Acc@5 96.094 (96.094)
Epoch: [5][64/196]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 1.0945 (1.0993)	Acc@1 77.734 (75.877)	Acc@5 98.438 (98.576)
Epoch: [5][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.1470 (1.0895)	Acc@1 73.828 (75.960)	Acc@5 96.875 (98.489)
Epoch: [5][192/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.9763 (1.0806)	Acc@1 80.859 (76.150)	Acc@5 98.438 (98.433)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  66.49
Max memory: 103.3835008
 25.697s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9367
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.180 (0.180)	Data 0.285 (0.285)	Loss 1.0563 (1.0563)	Acc@1 75.781 (75.781)	Acc@5 99.219 (99.219)
Epoch: [6][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 1.0286 (0.9855)	Acc@1 73.828 (78.474)	Acc@5 98.438 (98.750)
Epoch: [6][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.9555 (0.9963)	Acc@1 79.688 (78.098)	Acc@5 98.047 (98.734)
Epoch: [6][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 1.0446 (0.9902)	Acc@1 74.609 (78.236)	Acc@5 97.656 (98.731)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.202 (0.202)	Data 0.260 (0.260)	Loss 1.1114 (1.1114)	Acc@1 74.609 (74.609)	Acc@5 98.438 (98.438)
Epoch: [7][64/196]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 0.9447 (0.9660)	Acc@1 79.297 (78.191)	Acc@5 98.438 (98.810)
Epoch: [7][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.9525 (0.9456)	Acc@1 77.734 (78.855)	Acc@5 98.047 (98.861)
Epoch: [7][192/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.8905 (0.9375)	Acc@1 80.469 (79.127)	Acc@5 99.219 (98.909)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.176 (0.176)	Data 0.305 (0.305)	Loss 0.9651 (0.9651)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.140 (0.134)	Data 0.000 (0.005)	Loss 0.8981 (0.9090)	Acc@1 80.078 (79.886)	Acc@5 99.219 (98.912)
Epoch: [8][128/196]	Time 0.137 (0.134)	Data 0.000 (0.003)	Loss 0.9284 (0.8979)	Acc@1 80.859 (80.187)	Acc@5 98.047 (98.955)
Epoch: [8][192/196]	Time 0.153 (0.134)	Data 0.000 (0.002)	Loss 0.9616 (0.8910)	Acc@1 80.078 (80.309)	Acc@5 98.438 (98.976)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.176 (0.176)	Data 0.299 (0.299)	Loss 0.8201 (0.8201)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.9837 (0.8627)	Acc@1 76.953 (81.238)	Acc@5 98.828 (98.948)
Epoch: [9][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.9117 (0.8551)	Acc@1 79.688 (81.320)	Acc@5 97.656 (99.031)
Epoch: [9][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.9647 (0.8575)	Acc@1 74.219 (81.147)	Acc@5 99.609 (98.978)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.152 (0.152)	Data 0.292 (0.292)	Loss 0.8753 (0.8753)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [10][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.8557 (0.8282)	Acc@1 80.078 (81.815)	Acc@5 98.438 (99.147)
Epoch: [10][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.8000 (0.8316)	Acc@1 82.422 (81.480)	Acc@5 99.609 (99.125)
Epoch: [10][192/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.7499 (0.8312)	Acc@1 85.938 (81.473)	Acc@5 100.000 (99.126)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  70.91
Max memory: 103.3833984
 25.917s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9208
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.198 (0.198)	Data 0.280 (0.280)	Loss 0.8651 (0.8651)	Acc@1 79.688 (79.688)	Acc@5 99.609 (99.609)
Epoch: [11][64/196]	Time 0.152 (0.132)	Data 0.000 (0.004)	Loss 0.7748 (0.7794)	Acc@1 83.594 (83.371)	Acc@5 98.828 (99.249)
Epoch: [11][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7919 (0.7992)	Acc@1 82.812 (82.495)	Acc@5 99.219 (99.155)
Epoch: [11][192/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.7822 (0.8022)	Acc@1 82.422 (82.436)	Acc@5 99.219 (99.120)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.163 (0.163)	Data 0.296 (0.296)	Loss 0.7867 (0.7867)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7408 (0.7824)	Acc@1 83.984 (82.981)	Acc@5 99.219 (99.177)
Epoch: [12][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.8002 (0.7867)	Acc@1 80.859 (82.691)	Acc@5 99.219 (99.207)
Epoch: [12][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7759 (0.7918)	Acc@1 83.594 (82.432)	Acc@5 99.219 (99.188)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.174 (0.174)	Data 0.298 (0.298)	Loss 0.7587 (0.7587)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [13][64/196]	Time 0.137 (0.132)	Data 0.000 (0.005)	Loss 0.7257 (0.7815)	Acc@1 84.375 (82.909)	Acc@5 98.828 (99.183)
Epoch: [13][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7744 (0.7898)	Acc@1 81.250 (82.628)	Acc@5 99.219 (99.173)
Epoch: [13][192/196]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.7793 (0.7912)	Acc@1 84.375 (82.479)	Acc@5 98.828 (99.168)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.179 (0.179)	Data 0.284 (0.284)	Loss 0.7495 (0.7495)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [14][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.7075 (0.7724)	Acc@1 87.891 (83.233)	Acc@5 99.609 (99.219)
Epoch: [14][128/196]	Time 0.136 (0.132)	Data 0.000 (0.002)	Loss 0.6849 (0.7788)	Acc@1 87.500 (82.922)	Acc@5 99.219 (99.170)
Epoch: [14][192/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.8034 (0.7770)	Acc@1 82.812 (83.013)	Acc@5 99.609 (99.166)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.197 (0.197)	Data 0.292 (0.292)	Loss 0.8686 (0.8686)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 0.7349 (0.7695)	Acc@1 85.547 (83.281)	Acc@5 98.438 (99.225)
Epoch: [15][128/196]	Time 0.124 (0.132)	Data 0.000 (0.002)	Loss 0.7318 (0.7610)	Acc@1 82.812 (83.391)	Acc@5 99.219 (99.240)
Epoch: [15][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7810 (0.7630)	Acc@1 82.422 (83.385)	Acc@5 99.609 (99.257)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.9
Max memory: 103.3833984
 26.182s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6718
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.221 (0.221)	Data 0.264 (0.264)	Loss 0.7270 (0.7270)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [16][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.7201 (0.7446)	Acc@1 85.156 (84.093)	Acc@5 98.828 (99.213)
Epoch: [16][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6313 (0.7524)	Acc@1 88.672 (83.881)	Acc@5 99.609 (99.264)
Epoch: [16][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6908 (0.7585)	Acc@1 84.766 (83.644)	Acc@5 98.828 (99.241)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.165 (0.165)	Data 0.300 (0.300)	Loss 0.8631 (0.8631)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.120 (0.130)	Data 0.000 (0.005)	Loss 0.7654 (0.7542)	Acc@1 84.375 (83.630)	Acc@5 99.219 (99.213)
Epoch: [17][128/196]	Time 0.147 (0.131)	Data 0.000 (0.003)	Loss 0.7495 (0.7584)	Acc@1 86.719 (83.736)	Acc@5 99.609 (99.161)
Epoch: [17][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7086 (0.7604)	Acc@1 83.984 (83.650)	Acc@5 99.219 (99.201)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.167 (0.167)	Data 0.283 (0.283)	Loss 0.7698 (0.7698)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.7273 (0.7522)	Acc@1 86.719 (83.588)	Acc@5 99.609 (99.375)
Epoch: [18][128/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.8278 (0.7561)	Acc@1 80.859 (83.412)	Acc@5 98.828 (99.270)
Epoch: [18][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.8925 (0.7579)	Acc@1 77.734 (83.468)	Acc@5 99.609 (99.233)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.189 (0.189)	Data 0.310 (0.310)	Loss 0.7234 (0.7234)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [19][64/196]	Time 0.136 (0.136)	Data 0.000 (0.005)	Loss 0.7734 (0.7336)	Acc@1 84.766 (84.141)	Acc@5 100.000 (99.351)
Epoch: [19][128/196]	Time 0.132 (0.134)	Data 0.000 (0.003)	Loss 0.6807 (0.7441)	Acc@1 85.938 (83.921)	Acc@5 99.219 (99.304)
Epoch: [19][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.8059 (0.7459)	Acc@1 82.422 (83.924)	Acc@5 98.047 (99.269)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.167 (0.167)	Data 0.269 (0.269)	Loss 0.6200 (0.6200)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.126 (0.133)	Data 0.000 (0.004)	Loss 0.7032 (0.7350)	Acc@1 86.328 (84.135)	Acc@5 100.000 (99.381)
Epoch: [20][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.7676 (0.7439)	Acc@1 83.984 (83.978)	Acc@5 98.438 (99.249)
Epoch: [20][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.6562 (0.7458)	Acc@1 89.062 (83.865)	Acc@5 99.609 (99.302)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 481616 ; 487386 ; 0.988161334137624
[INFO] Storing checkpoint...
  75.15
Max memory: 103.3833984
 26.314s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 646
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2002432
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.193 (0.193)	Data 0.293 (0.293)	Loss 0.7120 (0.7120)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.124 (0.132)	Data 0.000 (0.005)	Loss 0.7277 (0.7218)	Acc@1 84.375 (84.778)	Acc@5 99.219 (99.423)
Epoch: [21][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7528 (0.7229)	Acc@1 85.938 (84.850)	Acc@5 98.828 (99.364)
Epoch: [21][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6766 (0.7320)	Acc@1 85.938 (84.604)	Acc@5 100.000 (99.320)
Max memory in training epoch: 66.6376704
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.152 (0.152)	Data 0.312 (0.312)	Loss 0.6985 (0.6985)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.8218 (0.7269)	Acc@1 82.812 (84.603)	Acc@5 98.438 (99.315)
Epoch: [22][128/196]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.7148 (0.7325)	Acc@1 87.891 (84.511)	Acc@5 98.828 (99.334)
Epoch: [22][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7673 (0.7364)	Acc@1 83.594 (84.391)	Acc@5 99.609 (99.300)
Max memory in training epoch: 66.5197056
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.168 (0.168)	Data 0.295 (0.295)	Loss 0.8127 (0.8127)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.7056 (0.7388)	Acc@1 85.156 (84.375)	Acc@5 99.219 (99.279)
Epoch: [23][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6383 (0.7290)	Acc@1 89.062 (84.675)	Acc@5 99.219 (99.364)
Epoch: [23][192/196]	Time 0.144 (0.131)	Data 0.000 (0.002)	Loss 0.7201 (0.7270)	Acc@1 83.594 (84.618)	Acc@5 99.219 (99.340)
Max memory in training epoch: 66.5197056
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.190 (0.190)	Data 0.288 (0.288)	Loss 0.7540 (0.7540)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.5997 (0.7175)	Acc@1 91.016 (84.712)	Acc@5 99.219 (99.393)
Epoch: [24][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7163 (0.7204)	Acc@1 80.859 (84.793)	Acc@5 99.219 (99.406)
Epoch: [24][192/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.6933 (0.7234)	Acc@1 84.766 (84.703)	Acc@5 99.219 (99.371)
Max memory in training epoch: 66.5197056
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.177 (0.177)	Data 0.306 (0.306)	Loss 0.7134 (0.7134)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [25][64/196]	Time 0.139 (0.133)	Data 0.000 (0.005)	Loss 0.7911 (0.7180)	Acc@1 83.203 (84.826)	Acc@5 99.219 (99.411)
Epoch: [25][128/196]	Time 0.128 (0.132)	Data 0.000 (0.003)	Loss 0.7399 (0.7210)	Acc@1 83.594 (84.569)	Acc@5 98.438 (99.358)
Epoch: [25][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6626 (0.7220)	Acc@1 85.938 (84.594)	Acc@5 98.828 (99.354)
Max memory in training epoch: 66.5197056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 460266 ; 481616 ; 0.9556700774060662
[INFO] Storing checkpoint...
  76.33
Max memory: 103.37664
 26.087s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1937
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.191744
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.218 (0.218)	Data 0.261 (0.261)	Loss 0.6827 (0.6827)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.141 (0.135)	Data 0.000 (0.004)	Loss 0.7477 (0.6924)	Acc@1 83.594 (85.841)	Acc@5 98.828 (99.399)
Epoch: [26][128/196]	Time 0.128 (0.134)	Data 0.000 (0.002)	Loss 0.6172 (0.7016)	Acc@1 89.453 (85.486)	Acc@5 99.609 (99.382)
Epoch: [26][192/196]	Time 0.128 (0.134)	Data 0.000 (0.002)	Loss 0.7019 (0.7099)	Acc@1 88.281 (85.223)	Acc@5 99.219 (99.358)
Max memory in training epoch: 66.4529408
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.176 (0.176)	Data 0.309 (0.309)	Loss 0.7503 (0.7503)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [27][64/196]	Time 0.131 (0.133)	Data 0.000 (0.005)	Loss 0.7608 (0.7126)	Acc@1 83.984 (84.874)	Acc@5 99.609 (99.417)
Epoch: [27][128/196]	Time 0.125 (0.132)	Data 0.000 (0.003)	Loss 0.7863 (0.7167)	Acc@1 82.812 (84.775)	Acc@5 98.828 (99.325)
Epoch: [27][192/196]	Time 0.138 (0.132)	Data 0.000 (0.002)	Loss 0.6498 (0.7183)	Acc@1 85.156 (84.810)	Acc@5 100.000 (99.344)
Max memory in training epoch: 66.1449216
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.175 (0.175)	Data 0.292 (0.292)	Loss 0.6393 (0.6393)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [28][64/196]	Time 0.131 (0.135)	Data 0.000 (0.005)	Loss 0.7349 (0.6868)	Acc@1 83.984 (85.787)	Acc@5 99.219 (99.525)
Epoch: [28][128/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7504 (0.7068)	Acc@1 83.594 (85.081)	Acc@5 99.219 (99.431)
Epoch: [28][192/196]	Time 0.135 (0.133)	Data 0.000 (0.002)	Loss 0.8436 (0.7120)	Acc@1 82.422 (84.972)	Acc@5 99.219 (99.381)
Max memory in training epoch: 66.1449216
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.162 (0.162)	Data 0.307 (0.307)	Loss 0.6961 (0.6961)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [29][64/196]	Time 0.134 (0.135)	Data 0.000 (0.005)	Loss 0.6158 (0.7086)	Acc@1 88.281 (84.856)	Acc@5 99.609 (99.369)
Epoch: [29][128/196]	Time 0.134 (0.135)	Data 0.000 (0.003)	Loss 0.7094 (0.7112)	Acc@1 83.203 (84.941)	Acc@5 99.609 (99.361)
Epoch: [29][192/196]	Time 0.139 (0.135)	Data 0.000 (0.002)	Loss 0.7283 (0.7096)	Acc@1 85.938 (84.940)	Acc@5 98.438 (99.354)
Max memory in training epoch: 66.1449216
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.183 (0.183)	Data 0.265 (0.265)	Loss 0.6160 (0.6160)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 0.125 (0.133)	Data 0.000 (0.004)	Loss 0.7005 (0.7100)	Acc@1 84.766 (85.138)	Acc@5 99.219 (99.447)
Epoch: [30][128/196]	Time 0.137 (0.134)	Data 0.000 (0.002)	Loss 0.6844 (0.7133)	Acc@1 86.719 (85.180)	Acc@5 99.219 (99.373)
Epoch: [30][192/196]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.8069 (0.7084)	Acc@1 81.641 (85.239)	Acc@5 98.828 (99.395)
Max memory in training epoch: 66.1449216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423044 ; 460266 ; 0.919129373014735
[INFO] Storing checkpoint...
  79.91
Max memory: 102.9771776
 26.614s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 40
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1769984
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.192 (0.192)	Data 0.267 (0.267)	Loss 0.7177 (0.7177)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6897 (0.6729)	Acc@1 85.547 (86.220)	Acc@5 100.000 (99.435)
Epoch: [31][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7145 (0.6894)	Acc@1 83.984 (85.568)	Acc@5 99.609 (99.397)
Epoch: [31][192/196]	Time 0.145 (0.128)	Data 0.000 (0.002)	Loss 0.6533 (0.6943)	Acc@1 87.109 (85.403)	Acc@5 99.219 (99.383)
Max memory in training epoch: 65.8369024
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.176 (0.176)	Data 0.270 (0.270)	Loss 0.6991 (0.6991)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.121 (0.129)	Data 0.000 (0.004)	Loss 0.6294 (0.7038)	Acc@1 88.672 (85.138)	Acc@5 99.609 (99.429)
Epoch: [32][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6784 (0.7004)	Acc@1 86.328 (85.244)	Acc@5 100.000 (99.461)
Epoch: [32][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7546 (0.7077)	Acc@1 82.812 (85.061)	Acc@5 98.438 (99.417)
Max memory in training epoch: 65.7713664
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.186 (0.186)	Data 0.273 (0.273)	Loss 0.6922 (0.6922)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.6562 (0.7066)	Acc@1 85.547 (85.000)	Acc@5 99.219 (99.261)
Epoch: [33][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6391 (0.6995)	Acc@1 86.719 (85.256)	Acc@5 99.219 (99.352)
Epoch: [33][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8050 (0.6979)	Acc@1 79.688 (85.290)	Acc@5 98.828 (99.373)
Max memory in training epoch: 65.7713664
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 0.6862 (0.6862)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.127 (0.132)	Data 0.000 (0.004)	Loss 0.6215 (0.6719)	Acc@1 86.719 (86.118)	Acc@5 99.609 (99.477)
Epoch: [34][128/196]	Time 0.137 (0.131)	Data 0.000 (0.002)	Loss 0.8428 (0.6849)	Acc@1 80.469 (85.750)	Acc@5 99.609 (99.470)
Epoch: [34][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6813 (0.6909)	Acc@1 85.547 (85.470)	Acc@5 99.609 (99.452)
Max memory in training epoch: 65.7713664
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.145 (0.145)	Data 0.336 (0.336)	Loss 0.7013 (0.7013)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8643 (0.6823)	Acc@1 81.250 (85.974)	Acc@5 98.828 (99.423)
Epoch: [35][128/196]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.7420 (0.6926)	Acc@1 82.812 (85.653)	Acc@5 99.219 (99.446)
Epoch: [35][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7259 (0.6882)	Acc@1 83.203 (85.723)	Acc@5 98.828 (99.423)
Max memory in training epoch: 65.7713664
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 395344 ; 423044 ; 0.9345221773621656
[INFO] Storing checkpoint...
  79.41
Max memory: 101.4374912
 25.974s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3155
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1658368
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.210 (0.210)	Data 0.295 (0.295)	Loss 0.6545 (0.6545)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.7374 (0.6509)	Acc@1 84.766 (86.743)	Acc@5 97.656 (99.459)
Epoch: [36][128/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.6997 (0.6759)	Acc@1 85.156 (85.871)	Acc@5 99.219 (99.455)
Epoch: [36][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6929 (0.6810)	Acc@1 86.328 (85.790)	Acc@5 99.219 (99.460)
Max memory in training epoch: 65.3203968
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.187 (0.187)	Data 0.298 (0.298)	Loss 0.7254 (0.7254)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [37][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.6271 (0.6749)	Acc@1 88.281 (86.022)	Acc@5 100.000 (99.513)
Epoch: [37][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7579 (0.6808)	Acc@1 83.203 (85.883)	Acc@5 99.609 (99.482)
Epoch: [37][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6098 (0.6826)	Acc@1 87.109 (85.846)	Acc@5 100.000 (99.474)
Max memory in training epoch: 65.3466112
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.190 (0.190)	Data 0.270 (0.270)	Loss 0.6862 (0.6862)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6370 (0.6734)	Acc@1 88.281 (85.974)	Acc@5 99.219 (99.579)
Epoch: [38][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7002 (0.6803)	Acc@1 86.719 (85.898)	Acc@5 100.000 (99.522)
Epoch: [38][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6994 (0.6840)	Acc@1 86.719 (85.855)	Acc@5 100.000 (99.464)
Max memory in training epoch: 65.3466112
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.150 (0.150)	Data 0.312 (0.312)	Loss 0.6557 (0.6557)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [39][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.5882 (0.6765)	Acc@1 89.062 (86.034)	Acc@5 100.000 (99.465)
Epoch: [39][128/196]	Time 0.123 (0.130)	Data 0.000 (0.003)	Loss 0.6648 (0.6817)	Acc@1 85.938 (85.977)	Acc@5 100.000 (99.470)
Epoch: [39][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6181 (0.6793)	Acc@1 88.281 (86.031)	Acc@5 99.609 (99.437)
Max memory in training epoch: 65.3466112
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.161 (0.161)	Data 0.328 (0.328)	Loss 0.7386 (0.7386)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.138 (0.133)	Data 0.000 (0.005)	Loss 0.7613 (0.6857)	Acc@1 82.812 (85.829)	Acc@5 99.219 (99.423)
Epoch: [40][128/196]	Time 0.138 (0.131)	Data 0.000 (0.003)	Loss 0.5738 (0.6812)	Acc@1 89.844 (85.907)	Acc@5 99.609 (99.406)
Epoch: [40][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6779 (0.6860)	Acc@1 87.500 (85.689)	Acc@5 99.219 (99.397)
Max memory in training epoch: 65.3466112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 367640 ; 395344 ; 0.9299243190740216
[INFO] Storing checkpoint...
  75.73
Max memory: 100.8272896
 26.113s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1744
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1547776
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.216 (0.216)	Data 0.260 (0.260)	Loss 0.6483 (0.6483)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.146 (0.131)	Data 0.000 (0.004)	Loss 0.7025 (0.6526)	Acc@1 83.984 (86.767)	Acc@5 98.828 (99.495)
Epoch: [41][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6090 (0.6613)	Acc@1 89.844 (86.358)	Acc@5 99.609 (99.437)
Epoch: [41][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7235 (0.6681)	Acc@1 83.984 (86.112)	Acc@5 99.609 (99.449)
Max memory in training epoch: 64.5159424
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.166 (0.166)	Data 0.296 (0.296)	Loss 0.5919 (0.5919)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [42][64/196]	Time 0.121 (0.130)	Data 0.000 (0.005)	Loss 0.7095 (0.6772)	Acc@1 83.984 (85.907)	Acc@5 99.219 (99.405)
Epoch: [42][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.5627 (0.6824)	Acc@1 89.453 (85.701)	Acc@5 100.000 (99.479)
Epoch: [42][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6572 (0.6857)	Acc@1 85.156 (85.575)	Acc@5 99.609 (99.476)
Max memory in training epoch: 64.4635136
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.182 (0.182)	Data 0.294 (0.294)	Loss 0.6865 (0.6865)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6009 (0.6624)	Acc@1 89.844 (86.713)	Acc@5 100.000 (99.441)
Epoch: [43][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6370 (0.6735)	Acc@1 89.062 (86.098)	Acc@5 100.000 (99.388)
Epoch: [43][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7301 (0.6755)	Acc@1 82.422 (86.063)	Acc@5 98.438 (99.417)
Max memory in training epoch: 64.4635136
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.154 (0.154)	Data 0.289 (0.289)	Loss 0.6156 (0.6156)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.6524 (0.6730)	Acc@1 87.891 (86.244)	Acc@5 99.609 (99.531)
Epoch: [44][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7005 (0.6791)	Acc@1 85.156 (85.977)	Acc@5 99.609 (99.455)
Epoch: [44][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6742 (0.6835)	Acc@1 88.281 (85.770)	Acc@5 99.609 (99.445)
Max memory in training epoch: 64.4635136
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.193 (0.193)	Data 0.265 (0.265)	Loss 0.6068 (0.6068)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [45][64/196]	Time 0.134 (0.131)	Data 0.000 (0.004)	Loss 0.6535 (0.6544)	Acc@1 88.281 (86.707)	Acc@5 100.000 (99.471)
Epoch: [45][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.5728 (0.6604)	Acc@1 91.797 (86.513)	Acc@5 98.828 (99.473)
Epoch: [45][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7572 (0.6628)	Acc@1 83.984 (86.387)	Acc@5 98.828 (99.460)
Max memory in training epoch: 64.4635136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356234 ; 367640 ; 0.9689750843216189
[INFO] Storing checkpoint...
  69.7
Max memory: 99.4473472
 25.877s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 721
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1504256
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.189 (0.189)	Data 0.262 (0.262)	Loss 0.6900 (0.6900)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.5931 (0.6308)	Acc@1 88.672 (87.230)	Acc@5 99.609 (99.609)
Epoch: [46][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6538 (0.6515)	Acc@1 86.328 (86.752)	Acc@5 98.828 (99.522)
Epoch: [46][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6743 (0.6650)	Acc@1 85.938 (86.231)	Acc@5 99.609 (99.462)
Max memory in training epoch: 63.2140288
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.169 (0.169)	Data 0.262 (0.262)	Loss 0.6776 (0.6776)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [47][64/196]	Time 0.128 (0.128)	Data 0.000 (0.004)	Loss 0.6779 (0.6702)	Acc@1 86.719 (86.004)	Acc@5 99.609 (99.489)
Epoch: [47][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.7426 (0.6773)	Acc@1 82.422 (85.835)	Acc@5 99.219 (99.470)
Epoch: [47][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7095 (0.6781)	Acc@1 84.766 (85.826)	Acc@5 99.219 (99.454)
Max memory in training epoch: 63.3844224
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.177 (0.177)	Data 0.267 (0.267)	Loss 0.5936 (0.5936)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [48][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.7256 (0.6553)	Acc@1 84.766 (86.731)	Acc@5 98.828 (99.411)
Epoch: [48][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6255 (0.6604)	Acc@1 88.672 (86.473)	Acc@5 99.609 (99.464)
Epoch: [48][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6422 (0.6657)	Acc@1 86.328 (86.296)	Acc@5 100.000 (99.456)
Max memory in training epoch: 63.3844224
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.183 (0.183)	Data 0.319 (0.319)	Loss 0.5999 (0.5999)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [49][64/196]	Time 0.134 (0.128)	Data 0.000 (0.005)	Loss 0.7120 (0.6734)	Acc@1 84.375 (86.118)	Acc@5 99.219 (99.471)
Epoch: [49][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.7192 (0.6671)	Acc@1 85.156 (86.292)	Acc@5 99.609 (99.464)
Epoch: [49][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6739 (0.6693)	Acc@1 84.766 (86.182)	Acc@5 99.609 (99.468)
Max memory in training epoch: 63.3844224
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.179 (0.179)	Data 0.262 (0.262)	Loss 0.5773 (0.5773)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.133 (0.130)	Data 0.000 (0.004)	Loss 0.6453 (0.6653)	Acc@1 87.109 (86.370)	Acc@5 98.828 (99.405)
Epoch: [50][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.6070 (0.6579)	Acc@1 88.281 (86.519)	Acc@5 100.000 (99.452)
Epoch: [50][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6934 (0.6617)	Acc@1 86.328 (86.371)	Acc@5 98.828 (99.435)
Max memory in training epoch: 63.3844224
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 344684 ; 356234 ; 0.9675774911996048
[INFO] Storing checkpoint...
  78.78
Max memory: 97.737728
 25.559s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5253
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1458176
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.182 (0.182)	Data 0.269 (0.269)	Loss 0.6152 (0.6152)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [51][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7149 (0.6329)	Acc@1 82.812 (87.115)	Acc@5 99.609 (99.501)
Epoch: [51][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6171 (0.6441)	Acc@1 88.281 (86.849)	Acc@5 100.000 (99.473)
Epoch: [51][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7563 (0.6523)	Acc@1 81.250 (86.682)	Acc@5 99.219 (99.462)
Max memory in training epoch: 62.5015296
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.182 (0.182)	Data 0.270 (0.270)	Loss 0.5825 (0.5825)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [52][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.6842 (0.6684)	Acc@1 85.156 (86.148)	Acc@5 99.219 (99.405)
Epoch: [52][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.5052 (0.6664)	Acc@1 92.188 (86.107)	Acc@5 99.609 (99.413)
Epoch: [52][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6692 (0.6642)	Acc@1 87.109 (86.284)	Acc@5 99.219 (99.429)
Max memory in training epoch: 62.5140224
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.184 (0.184)	Data 0.263 (0.263)	Loss 0.6575 (0.6575)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.5453 (0.6630)	Acc@1 91.406 (86.340)	Acc@5 99.609 (99.471)
Epoch: [53][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.5718 (0.6572)	Acc@1 87.500 (86.595)	Acc@5 100.000 (99.485)
Epoch: [53][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6877 (0.6588)	Acc@1 85.547 (86.563)	Acc@5 100.000 (99.468)
Max memory in training epoch: 62.5140224
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.149 (0.149)	Data 0.271 (0.271)	Loss 0.6100 (0.6100)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.6834 (0.6574)	Acc@1 85.156 (86.593)	Acc@5 100.000 (99.369)
Epoch: [54][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6166 (0.6588)	Acc@1 89.062 (86.564)	Acc@5 99.609 (99.419)
Epoch: [54][192/196]	Time 0.120 (0.129)	Data 0.000 (0.002)	Loss 0.6364 (0.6637)	Acc@1 88.672 (86.371)	Acc@5 99.219 (99.411)
Max memory in training epoch: 62.5140224
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.167 (0.167)	Data 0.297 (0.297)	Loss 0.5666 (0.5666)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [55][64/196]	Time 0.132 (0.128)	Data 0.000 (0.005)	Loss 0.6054 (0.6558)	Acc@1 86.328 (86.659)	Acc@5 99.609 (99.585)
Epoch: [55][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6449 (0.6545)	Acc@1 87.500 (86.631)	Acc@5 99.609 (99.540)
Epoch: [55][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.5792 (0.6577)	Acc@1 89.062 (86.579)	Acc@5 100.000 (99.545)
Max memory in training epoch: 62.5140224
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 338332 ; 344684 ; 0.9815715263835861
[INFO] Storing checkpoint...
  81.78
Max memory: 96.7048192
 25.463s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5537
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1432576
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.193 (0.193)	Data 0.281 (0.281)	Loss 0.7189 (0.7189)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.6660 (0.6329)	Acc@1 85.547 (87.386)	Acc@5 99.219 (99.543)
Epoch: [56][128/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.6310 (0.6353)	Acc@1 86.719 (87.203)	Acc@5 100.000 (99.555)
Epoch: [56][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.7201 (0.6450)	Acc@1 83.203 (86.873)	Acc@5 99.609 (99.504)
Max memory in training epoch: 62.09664
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.175 (0.175)	Data 0.297 (0.297)	Loss 0.5828 (0.5828)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.6191 (0.6596)	Acc@1 86.719 (86.190)	Acc@5 99.219 (99.429)
Epoch: [57][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7354 (0.6580)	Acc@1 83.594 (86.361)	Acc@5 100.000 (99.385)
Epoch: [57][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.7041 (0.6596)	Acc@1 83.594 (86.259)	Acc@5 99.609 (99.423)
Max memory in training epoch: 62.1892096
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.162 (0.162)	Data 0.297 (0.297)	Loss 0.6657 (0.6657)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.6730 (0.6587)	Acc@1 87.109 (86.743)	Acc@5 99.609 (99.465)
Epoch: [58][128/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.6908 (0.6577)	Acc@1 84.766 (86.455)	Acc@5 99.609 (99.449)
Epoch: [58][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6526 (0.6605)	Acc@1 84.375 (86.314)	Acc@5 100.000 (99.447)
Max memory in training epoch: 62.1892096
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.186 (0.186)	Data 0.269 (0.269)	Loss 0.6331 (0.6331)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7787 (0.6497)	Acc@1 82.812 (86.226)	Acc@5 99.219 (99.525)
Epoch: [59][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.6784 (0.6560)	Acc@1 85.156 (86.207)	Acc@5 98.828 (99.464)
Epoch: [59][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.5614 (0.6554)	Acc@1 90.625 (86.312)	Acc@5 99.219 (99.464)
Max memory in training epoch: 62.1892096
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.166 (0.166)	Data 0.301 (0.301)	Loss 0.5659 (0.5659)	Acc@1 91.016 (91.016)	Acc@5 99.219 (99.219)
Epoch: [60][64/196]	Time 0.132 (0.127)	Data 0.000 (0.005)	Loss 0.6578 (0.6536)	Acc@1 86.328 (86.629)	Acc@5 99.609 (99.573)
Epoch: [60][128/196]	Time 0.127 (0.126)	Data 0.000 (0.003)	Loss 0.6461 (0.6527)	Acc@1 84.375 (86.652)	Acc@5 100.000 (99.576)
Epoch: [60][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6297 (0.6517)	Acc@1 87.891 (86.636)	Acc@5 98.828 (99.543)
Max memory in training epoch: 62.1892096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 331106 ; 338332 ; 0.9786422803636664
[INFO] Storing checkpoint...
  79.75
Max memory: 96.3538944
 25.086s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 710
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1405952
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.177 (0.177)	Data 0.260 (0.260)	Loss 0.5684 (0.5684)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.7566 (0.6401)	Acc@1 82.031 (86.857)	Acc@5 98.828 (99.537)
Epoch: [61][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6544 (0.6416)	Acc@1 86.719 (86.695)	Acc@5 99.219 (99.549)
Epoch: [61][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.6243 (0.6476)	Acc@1 85.938 (86.520)	Acc@5 99.609 (99.524)
Max memory in training epoch: 60.7760896
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.180 (0.180)	Data 0.309 (0.309)	Loss 0.6341 (0.6341)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.6412 (0.6552)	Acc@1 87.891 (86.190)	Acc@5 99.609 (99.537)
Epoch: [62][128/196]	Time 0.124 (0.126)	Data 0.000 (0.003)	Loss 0.5523 (0.6502)	Acc@1 89.453 (86.480)	Acc@5 99.609 (99.506)
Epoch: [62][192/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.6514 (0.6539)	Acc@1 85.156 (86.423)	Acc@5 99.609 (99.488)
Max memory in training epoch: 60.671232
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.156 (0.156)	Data 0.287 (0.287)	Loss 0.6573 (0.6573)	Acc@1 87.109 (87.109)	Acc@5 98.047 (98.047)
Epoch: [63][64/196]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.6544 (0.6551)	Acc@1 84.766 (86.418)	Acc@5 99.219 (99.459)
Epoch: [63][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6536 (0.6558)	Acc@1 86.719 (86.349)	Acc@5 99.219 (99.506)
Epoch: [63][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6477 (0.6543)	Acc@1 87.891 (86.431)	Acc@5 99.219 (99.488)
Max memory in training epoch: 60.671232
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.164 (0.164)	Data 0.266 (0.266)	Loss 0.6293 (0.6293)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [64][64/196]	Time 0.124 (0.126)	Data 0.000 (0.004)	Loss 0.6217 (0.6544)	Acc@1 88.672 (86.514)	Acc@5 99.219 (99.459)
Epoch: [64][128/196]	Time 0.134 (0.126)	Data 0.000 (0.002)	Loss 0.6181 (0.6522)	Acc@1 89.844 (86.534)	Acc@5 98.828 (99.488)
Epoch: [64][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.6951 (0.6492)	Acc@1 86.719 (86.638)	Acc@5 99.219 (99.486)
Max memory in training epoch: 60.671232
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.157 (0.157)	Data 0.316 (0.316)	Loss 0.6134 (0.6134)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.6105 (0.6425)	Acc@1 88.281 (86.851)	Acc@5 99.609 (99.495)
Epoch: [65][128/196]	Time 0.132 (0.127)	Data 0.000 (0.003)	Loss 0.7339 (0.6459)	Acc@1 83.984 (86.740)	Acc@5 99.609 (99.473)
Epoch: [65][192/196]	Time 0.133 (0.127)	Data 0.000 (0.002)	Loss 0.6925 (0.6504)	Acc@1 87.109 (86.593)	Acc@5 98.828 (99.494)
Max memory in training epoch: 60.671232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 329374 ; 331106 ; 0.9947690467705206
[INFO] Storing checkpoint...
  80.74
Max memory: 94.2528512
 25.260s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9101
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1398784
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.185 (0.185)	Data 0.291 (0.291)	Loss 0.5988 (0.5988)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [66][64/196]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.6538 (0.6099)	Acc@1 87.109 (88.185)	Acc@5 99.219 (99.549)
Epoch: [66][128/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.7515 (0.6300)	Acc@1 82.812 (87.306)	Acc@5 98.438 (99.522)
Epoch: [66][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.6742 (0.6389)	Acc@1 86.719 (86.978)	Acc@5 99.609 (99.528)
Max memory in training epoch: 60.7076864
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.191 (0.191)	Data 0.296 (0.296)	Loss 0.5631 (0.5631)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.6677 (0.6458)	Acc@1 89.062 (86.635)	Acc@5 99.609 (99.495)
Epoch: [67][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.6636 (0.6485)	Acc@1 85.547 (86.598)	Acc@5 99.609 (99.512)
Epoch: [67][192/196]	Time 0.117 (0.126)	Data 0.000 (0.002)	Loss 0.5575 (0.6493)	Acc@1 90.625 (86.634)	Acc@5 100.000 (99.494)
Max memory in training epoch: 60.6028288
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.188 (0.188)	Data 0.261 (0.261)	Loss 0.6084 (0.6084)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.7406 (0.6488)	Acc@1 85.547 (86.707)	Acc@5 99.609 (99.447)
Epoch: [68][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6178 (0.6458)	Acc@1 87.500 (86.746)	Acc@5 99.219 (99.440)
Epoch: [68][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.6840 (0.6509)	Acc@1 87.109 (86.585)	Acc@5 98.828 (99.445)
Max memory in training epoch: 60.6028288
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.171 (0.171)	Data 0.268 (0.268)	Loss 0.6500 (0.6500)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.124 (0.125)	Data 0.000 (0.004)	Loss 0.6870 (0.6495)	Acc@1 83.984 (86.562)	Acc@5 98.828 (99.441)
Epoch: [69][128/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.7881 (0.6478)	Acc@1 83.594 (86.713)	Acc@5 99.219 (99.479)
Epoch: [69][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.6384 (0.6507)	Acc@1 86.328 (86.638)	Acc@5 100.000 (99.474)
Max memory in training epoch: 60.6028288
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.179 (0.179)	Data 0.282 (0.282)	Loss 0.7213 (0.7213)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.121 (0.128)	Data 0.000 (0.005)	Loss 0.6744 (0.6511)	Acc@1 85.938 (86.418)	Acc@5 100.000 (99.489)
Epoch: [70][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6470 (0.6466)	Acc@1 86.328 (86.691)	Acc@5 100.000 (99.467)
Epoch: [70][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.5962 (0.6457)	Acc@1 88.281 (86.690)	Acc@5 99.219 (99.464)
Max memory in training epoch: 60.6028288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 327060 ; 329374 ; 0.9929745517253943
[INFO] Storing checkpoint...
  78.37
Max memory: 93.9631616
 25.395s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7767
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1389568
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.202 (0.202)	Data 0.284 (0.284)	Loss 0.6988 (0.6988)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.6202 (0.6137)	Acc@1 87.891 (87.921)	Acc@5 99.609 (99.573)
Epoch: [71][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5744 (0.6218)	Acc@1 87.891 (87.618)	Acc@5 99.609 (99.567)
Epoch: [71][192/196]	Time 0.134 (0.126)	Data 0.000 (0.002)	Loss 0.7010 (0.6311)	Acc@1 84.766 (87.281)	Acc@5 98.438 (99.541)
Max memory in training epoch: 60.5991424
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.170 (0.170)	Data 0.291 (0.291)	Loss 0.6401 (0.6401)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.129 (0.126)	Data 0.000 (0.005)	Loss 0.6575 (0.6412)	Acc@1 85.547 (86.839)	Acc@5 99.609 (99.591)
Epoch: [72][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7071 (0.6521)	Acc@1 83.203 (86.525)	Acc@5 99.219 (99.516)
Epoch: [72][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.5652 (0.6462)	Acc@1 89.453 (86.680)	Acc@5 99.219 (99.510)
Max memory in training epoch: 60.5204992
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.156 (0.156)	Data 0.305 (0.305)	Loss 0.6564 (0.6564)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.6490 (0.6412)	Acc@1 87.109 (86.743)	Acc@5 99.609 (99.507)
Epoch: [73][128/196]	Time 0.123 (0.127)	Data 0.000 (0.003)	Loss 0.6822 (0.6460)	Acc@1 85.156 (86.619)	Acc@5 99.219 (99.473)
Epoch: [73][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6466 (0.6471)	Acc@1 86.719 (86.636)	Acc@5 100.000 (99.482)
Max memory in training epoch: 60.5204992
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.234 (0.234)	Data 0.266 (0.266)	Loss 0.6085 (0.6085)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.5839 (0.6282)	Acc@1 89.062 (87.404)	Acc@5 99.609 (99.585)
Epoch: [74][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6708 (0.6408)	Acc@1 87.109 (86.943)	Acc@5 99.219 (99.509)
Epoch: [74][192/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.6870 (0.6477)	Acc@1 84.375 (86.632)	Acc@5 99.609 (99.498)
Max memory in training epoch: 60.5204992
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.154 (0.154)	Data 0.281 (0.281)	Loss 0.6309 (0.6309)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.7754 (0.6477)	Acc@1 80.859 (86.406)	Acc@5 99.219 (99.543)
Epoch: [75][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.5328 (0.6419)	Acc@1 91.797 (86.785)	Acc@5 99.219 (99.561)
Epoch: [75][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6542 (0.6403)	Acc@1 88.672 (86.858)	Acc@5 98.438 (99.541)
Max memory in training epoch: 60.5204992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 325326 ; 327060 ; 0.9946982205099981
[INFO] Storing checkpoint...
  77.99
Max memory: 93.4189056
 25.441s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7575
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.13824
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.183 (0.183)	Data 0.319 (0.319)	Loss 0.7005 (0.7005)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.5704 (0.6166)	Acc@1 90.234 (87.320)	Acc@5 100.000 (99.543)
Epoch: [76][128/196]	Time 0.127 (0.127)	Data 0.000 (0.003)	Loss 0.5550 (0.6327)	Acc@1 89.453 (86.900)	Acc@5 100.000 (99.534)
Epoch: [76][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.5705 (0.6350)	Acc@1 91.406 (86.945)	Acc@5 100.000 (99.502)
Max memory in training epoch: 60.4652032
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.160 (0.160)	Data 0.293 (0.293)	Loss 0.6643 (0.6643)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.5921 (0.6413)	Acc@1 89.062 (86.827)	Acc@5 100.000 (99.555)
Epoch: [77][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.6023 (0.6390)	Acc@1 88.672 (86.831)	Acc@5 99.219 (99.552)
Epoch: [77][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.7106 (0.6432)	Acc@1 83.984 (86.747)	Acc@5 99.219 (99.498)
Max memory in training epoch: 60.0719872
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.181 (0.181)	Data 0.270 (0.270)	Loss 0.6499 (0.6499)	Acc@1 86.719 (86.719)	Acc@5 98.828 (98.828)
Epoch: [78][64/196]	Time 0.121 (0.130)	Data 0.000 (0.004)	Loss 0.5515 (0.6295)	Acc@1 90.625 (87.332)	Acc@5 98.828 (99.453)
Epoch: [78][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.5796 (0.6336)	Acc@1 89.062 (87.000)	Acc@5 100.000 (99.497)
Epoch: [78][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.5918 (0.6450)	Acc@1 90.234 (86.581)	Acc@5 99.609 (99.472)
Max memory in training epoch: 60.0719872
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.169 (0.169)	Data 0.295 (0.295)	Loss 0.7159 (0.7159)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [79][64/196]	Time 0.131 (0.129)	Data 0.000 (0.005)	Loss 0.5531 (0.6502)	Acc@1 89.453 (86.448)	Acc@5 99.219 (99.513)
Epoch: [79][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6650 (0.6467)	Acc@1 87.109 (86.452)	Acc@5 99.609 (99.576)
Epoch: [79][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6430 (0.6476)	Acc@1 84.766 (86.419)	Acc@5 100.000 (99.549)
Max memory in training epoch: 60.0719872
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.152 (0.152)	Data 0.272 (0.272)	Loss 0.6008 (0.6008)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [80][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.6467 (0.6558)	Acc@1 86.328 (86.358)	Acc@5 99.609 (99.489)
Epoch: [80][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.6853 (0.6502)	Acc@1 84.766 (86.619)	Acc@5 99.609 (99.494)
Epoch: [80][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.6336 (0.6476)	Acc@1 88.672 (86.745)	Acc@5 100.000 (99.486)
Max memory in training epoch: 60.0719872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 320702 ; 325326 ; 0.9857865648610932
[INFO] Storing checkpoint...
  80.02
Max memory: 93.4913024
 25.512s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7465
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1363968
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.202 (0.202)	Data 0.279 (0.279)	Loss 0.5842 (0.5842)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [81][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6008 (0.6066)	Acc@1 88.281 (87.939)	Acc@5 99.609 (99.543)
Epoch: [81][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.5728 (0.6161)	Acc@1 90.234 (87.718)	Acc@5 100.000 (99.482)
Epoch: [81][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7014 (0.6291)	Acc@1 85.547 (87.209)	Acc@5 98.438 (99.480)
Max memory in training epoch: 59.1077888
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.171 (0.171)	Data 0.312 (0.312)	Loss 0.5590 (0.5590)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [82][64/196]	Time 0.120 (0.128)	Data 0.000 (0.005)	Loss 0.6241 (0.6287)	Acc@1 87.109 (87.013)	Acc@5 100.000 (99.519)
Epoch: [82][128/196]	Time 0.124 (0.127)	Data 0.000 (0.003)	Loss 0.5937 (0.6398)	Acc@1 89.453 (86.801)	Acc@5 99.609 (99.491)
Epoch: [82][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.7500 (0.6459)	Acc@1 83.594 (86.654)	Acc@5 99.609 (99.454)
Max memory in training epoch: 59.3699328
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.161 (0.161)	Data 0.280 (0.280)	Loss 0.6115 (0.6115)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 0.6793 (0.6174)	Acc@1 88.281 (87.638)	Acc@5 99.219 (99.513)
Epoch: [83][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.6990 (0.6309)	Acc@1 86.719 (87.276)	Acc@5 99.219 (99.506)
Epoch: [83][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7104 (0.6368)	Acc@1 84.375 (86.990)	Acc@5 99.609 (99.498)
Max memory in training epoch: 59.3699328
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.171 (0.171)	Data 0.276 (0.276)	Loss 0.6117 (0.6117)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.5582 (0.6507)	Acc@1 89.844 (86.142)	Acc@5 99.609 (99.483)
Epoch: [84][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6640 (0.6439)	Acc@1 84.766 (86.480)	Acc@5 99.609 (99.525)
Epoch: [84][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.6158 (0.6457)	Acc@1 85.547 (86.443)	Acc@5 100.000 (99.526)
Max memory in training epoch: 59.3699328
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.184 (0.184)	Data 0.300 (0.300)	Loss 0.6108 (0.6108)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [85][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.6768 (0.6379)	Acc@1 84.766 (87.085)	Acc@5 100.000 (99.495)
Epoch: [85][128/196]	Time 0.126 (0.129)	Data 0.000 (0.003)	Loss 0.6354 (0.6402)	Acc@1 85.938 (86.882)	Acc@5 100.000 (99.497)
Epoch: [85][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6310 (0.6394)	Acc@1 86.328 (86.893)	Acc@5 99.609 (99.518)
Max memory in training epoch: 59.3699328
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 317380 ; 320702 ; 0.9896414740163766
[INFO] Storing checkpoint...
  82.66
Max memory: 92.1029632
 25.549s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5291
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1351168
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.192 (0.192)	Data 0.299 (0.299)	Loss 0.5549 (0.5549)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.6423 (0.6079)	Acc@1 86.328 (87.782)	Acc@5 99.609 (99.561)
Epoch: [86][128/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.6787 (0.6241)	Acc@1 85.156 (87.197)	Acc@5 98.828 (99.528)
Epoch: [86][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.5419 (0.6253)	Acc@1 90.625 (87.172)	Acc@5 100.000 (99.545)
Max memory in training epoch: 58.9584896
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.151 (0.151)	Data 0.301 (0.301)	Loss 0.6506 (0.6506)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.5792 (0.6256)	Acc@1 88.281 (87.290)	Acc@5 99.609 (99.525)
Epoch: [87][128/196]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.6215 (0.6366)	Acc@1 87.891 (86.864)	Acc@5 99.219 (99.537)
Epoch: [87][192/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.6706 (0.6348)	Acc@1 84.766 (86.873)	Acc@5 98.438 (99.518)
Max memory in training epoch: 58.7749888
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.172 (0.172)	Data 0.279 (0.279)	Loss 0.5872 (0.5872)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [88][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.6189 (0.6300)	Acc@1 88.281 (87.224)	Acc@5 99.609 (99.513)
Epoch: [88][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6028 (0.6376)	Acc@1 85.938 (86.964)	Acc@5 99.609 (99.537)
Epoch: [88][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.6359 (0.6370)	Acc@1 86.328 (87.016)	Acc@5 99.219 (99.506)
Max memory in training epoch: 58.7749888
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.157 (0.157)	Data 0.277 (0.277)	Loss 0.6000 (0.6000)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.124 (0.126)	Data 0.000 (0.004)	Loss 0.6709 (0.6281)	Acc@1 85.156 (87.109)	Acc@5 100.000 (99.531)
Epoch: [89][128/196]	Time 0.118 (0.127)	Data 0.000 (0.002)	Loss 0.6422 (0.6368)	Acc@1 87.500 (86.991)	Acc@5 98.828 (99.525)
Epoch: [89][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.5953 (0.6332)	Acc@1 90.234 (87.071)	Acc@5 99.219 (99.555)
Max memory in training epoch: 58.7749888
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.154 (0.154)	Data 0.268 (0.268)	Loss 0.6623 (0.6623)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [90][64/196]	Time 0.127 (0.126)	Data 0.000 (0.004)	Loss 0.6028 (0.6286)	Acc@1 87.500 (87.175)	Acc@5 99.609 (99.477)
Epoch: [90][128/196]	Time 0.132 (0.127)	Data 0.000 (0.002)	Loss 0.6344 (0.6306)	Acc@1 87.500 (87.158)	Acc@5 99.609 (99.540)
Epoch: [90][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6410 (0.6397)	Acc@1 85.938 (86.739)	Acc@5 100.000 (99.541)
Max memory in training epoch: 58.7749888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 314778 ; 317380 ; 0.9918016258113302
[INFO] Storing checkpoint...
  81.0
Max memory: 91.574016
 25.368s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6478
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1341952
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.184 (0.184)	Data 0.292 (0.292)	Loss 0.6146 (0.6146)	Acc@1 87.891 (87.891)	Acc@5 98.438 (98.438)
Epoch: [91][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.6219 (0.5973)	Acc@1 89.453 (88.071)	Acc@5 98.828 (99.519)
Epoch: [91][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.6858 (0.6142)	Acc@1 83.594 (87.555)	Acc@5 99.609 (99.509)
Epoch: [91][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.6493 (0.6256)	Acc@1 85.938 (87.172)	Acc@5 99.219 (99.490)
Max memory in training epoch: 58.5615872
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.158 (0.158)	Data 0.269 (0.269)	Loss 0.5932 (0.5932)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.120 (0.126)	Data 0.000 (0.004)	Loss 0.6287 (0.6262)	Acc@1 85.938 (87.103)	Acc@5 100.000 (99.555)
Epoch: [92][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.6790 (0.6382)	Acc@1 83.594 (86.579)	Acc@5 98.828 (99.534)
Epoch: [92][192/196]	Time 0.117 (0.125)	Data 0.000 (0.002)	Loss 0.6051 (0.6421)	Acc@1 87.500 (86.508)	Acc@5 100.000 (99.522)
Max memory in training epoch: 58.351872
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.160 (0.160)	Data 0.294 (0.294)	Loss 0.7286 (0.7286)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [93][64/196]	Time 0.140 (0.127)	Data 0.000 (0.005)	Loss 0.5832 (0.5489)	Acc@1 88.672 (90.132)	Acc@5 98.828 (99.736)
Epoch: [93][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.4631 (0.5204)	Acc@1 92.578 (91.137)	Acc@5 100.000 (99.758)
Epoch: [93][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.5365 (0.5058)	Acc@1 89.844 (91.576)	Acc@5 100.000 (99.802)
Max memory in training epoch: 58.351872
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.152 (0.152)	Data 0.295 (0.295)	Loss 0.5073 (0.5073)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.3968 (0.4602)	Acc@1 94.141 (92.849)	Acc@5 100.000 (99.862)
Epoch: [94][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.4795 (0.4567)	Acc@1 90.234 (92.993)	Acc@5 100.000 (99.861)
Epoch: [94][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.5195 (0.4537)	Acc@1 90.625 (93.110)	Acc@5 99.609 (99.858)
Max memory in training epoch: 58.351872
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.182 (0.182)	Data 0.276 (0.276)	Loss 0.4679 (0.4679)	Acc@1 92.578 (92.578)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.5116 (0.4247)	Acc@1 91.016 (94.002)	Acc@5 99.609 (99.922)
Epoch: [95][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.4348 (0.4269)	Acc@1 93.750 (93.962)	Acc@5 100.000 (99.891)
Epoch: [95][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.4730 (0.4264)	Acc@1 91.406 (93.890)	Acc@5 99.609 (99.903)
Max memory in training epoch: 58.351872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 314200 ; 314778 ; 0.9981637852708893
[INFO] Storing checkpoint...
  91.28
Max memory: 90.8847616
 25.206s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1215
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.133888
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.196 (0.196)	Data 0.262 (0.262)	Loss 0.3937 (0.3937)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [96][64/196]	Time 0.127 (0.126)	Data 0.000 (0.004)	Loss 0.4056 (0.4101)	Acc@1 95.312 (94.195)	Acc@5 100.000 (99.886)
Epoch: [96][128/196]	Time 0.144 (0.126)	Data 0.000 (0.002)	Loss 0.3675 (0.4126)	Acc@1 97.266 (94.135)	Acc@5 99.609 (99.900)
Epoch: [96][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.4118 (0.4138)	Acc@1 94.141 (94.066)	Acc@5 100.000 (99.901)
Max memory in training epoch: 58.5603584
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.173 (0.173)	Data 0.261 (0.261)	Loss 0.4586 (0.4586)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.123 (0.126)	Data 0.000 (0.004)	Loss 0.3818 (0.4036)	Acc@1 94.922 (94.363)	Acc@5 100.000 (99.940)
Epoch: [97][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.4333 (0.3974)	Acc@1 93.359 (94.552)	Acc@5 99.609 (99.930)
Epoch: [97][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3852 (0.3966)	Acc@1 94.922 (94.541)	Acc@5 100.000 (99.925)
Max memory in training epoch: 58.2982144
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.177 (0.177)	Data 0.265 (0.265)	Loss 0.3434 (0.3434)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.3900 (0.3880)	Acc@1 94.531 (94.874)	Acc@5 100.000 (99.934)
Epoch: [98][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.4579 (0.3881)	Acc@1 90.234 (94.689)	Acc@5 100.000 (99.918)
Epoch: [98][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.3872 (0.3870)	Acc@1 96.094 (94.724)	Acc@5 99.609 (99.915)
Max memory in training epoch: 58.2982144
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.182 (0.182)	Data 0.274 (0.274)	Loss 0.3623 (0.3623)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.3504 (0.3745)	Acc@1 96.484 (94.976)	Acc@5 100.000 (99.892)
Epoch: [99][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.3886 (0.3754)	Acc@1 93.750 (95.079)	Acc@5 100.000 (99.900)
Epoch: [99][192/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.4259 (0.3769)	Acc@1 93.359 (95.011)	Acc@5 100.000 (99.891)
Max memory in training epoch: 58.2982144
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.168 (0.168)	Data 0.293 (0.293)	Loss 0.3481 (0.3481)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.3406 (0.3627)	Acc@1 96.094 (95.312)	Acc@5 100.000 (99.916)
Epoch: [100][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.3990 (0.3674)	Acc@1 92.969 (95.161)	Acc@5 100.000 (99.924)
Epoch: [100][192/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.3526 (0.3681)	Acc@1 95.312 (95.140)	Acc@5 100.000 (99.923)
Max memory in training epoch: 58.2982144
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 313622 ; 314200 ; 0.9981604073838319
[INFO] Storing checkpoint...
  91.54
Max memory: 90.88384
 25.093s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1371
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1336832
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.187 (0.187)	Data 0.281 (0.281)	Loss 0.3470 (0.3470)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.3234 (0.3512)	Acc@1 96.094 (95.589)	Acc@5 100.000 (99.940)
Epoch: [101][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.4574 (0.3551)	Acc@1 92.188 (95.443)	Acc@5 99.609 (99.912)
Epoch: [101][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.3518 (0.3591)	Acc@1 96.094 (95.272)	Acc@5 100.000 (99.909)
Max memory in training epoch: 58.5595392
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.188 (0.188)	Data 0.251 (0.251)	Loss 0.3000 (0.3000)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.127 (0.127)	Data 0.000 (0.004)	Loss 0.3744 (0.3450)	Acc@1 94.922 (95.853)	Acc@5 99.609 (99.934)
Epoch: [102][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.3516 (0.3480)	Acc@1 95.703 (95.609)	Acc@5 100.000 (99.939)
Epoch: [102][192/196]	Time 0.142 (0.128)	Data 0.000 (0.001)	Loss 0.3153 (0.3479)	Acc@1 96.484 (95.553)	Acc@5 100.000 (99.941)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.158 (0.158)	Data 0.309 (0.309)	Loss 0.3176 (0.3176)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.3923 (0.3396)	Acc@1 91.797 (95.751)	Acc@5 100.000 (99.934)
Epoch: [103][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.3471 (0.3430)	Acc@1 95.312 (95.621)	Acc@5 100.000 (99.939)
Epoch: [103][192/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.3681 (0.3423)	Acc@1 94.141 (95.551)	Acc@5 100.000 (99.929)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.173 (0.173)	Data 0.261 (0.261)	Loss 0.3535 (0.3535)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.3919 (0.3356)	Acc@1 94.922 (95.895)	Acc@5 100.000 (99.964)
Epoch: [104][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.3302 (0.3351)	Acc@1 94.141 (95.752)	Acc@5 100.000 (99.961)
Epoch: [104][192/196]	Time 0.118 (0.128)	Data 0.000 (0.002)	Loss 0.3710 (0.3351)	Acc@1 93.359 (95.733)	Acc@5 100.000 (99.951)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.160 (0.160)	Data 0.257 (0.257)	Loss 0.3112 (0.3112)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.3009 (0.3209)	Acc@1 98.047 (96.292)	Acc@5 100.000 (99.988)
Epoch: [105][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.3101 (0.3246)	Acc@1 96.094 (96.106)	Acc@5 100.000 (99.958)
Epoch: [105][192/196]	Time 0.132 (0.127)	Data 0.000 (0.001)	Loss 0.4201 (0.3277)	Acc@1 92.969 (95.891)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.2449664
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.81
Max memory: 90.6890752
 25.222s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4426
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1336832
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.217 (0.217)	Data 0.256 (0.256)	Loss 0.3444 (0.3444)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.3444 (0.3146)	Acc@1 94.922 (96.256)	Acc@5 100.000 (99.958)
Epoch: [106][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.2962 (0.3185)	Acc@1 97.266 (96.142)	Acc@5 100.000 (99.942)
Epoch: [106][192/196]	Time 0.144 (0.126)	Data 0.000 (0.002)	Loss 0.3114 (0.3212)	Acc@1 95.703 (95.986)	Acc@5 100.000 (99.939)
Max memory in training epoch: 58.5595392
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.177 (0.177)	Data 0.294 (0.294)	Loss 0.3263 (0.3263)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.3331 (0.3204)	Acc@1 95.312 (95.847)	Acc@5 100.000 (99.964)
Epoch: [107][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.2973 (0.3194)	Acc@1 96.094 (95.967)	Acc@5 100.000 (99.955)
Epoch: [107][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.3603 (0.3198)	Acc@1 93.750 (95.968)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.187 (0.187)	Data 0.261 (0.261)	Loss 0.3202 (0.3202)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.3319 (0.3090)	Acc@1 94.922 (96.394)	Acc@5 100.000 (99.946)
Epoch: [108][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.3457 (0.3113)	Acc@1 94.531 (96.157)	Acc@5 100.000 (99.933)
Epoch: [108][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.2803 (0.3110)	Acc@1 96.875 (96.112)	Acc@5 100.000 (99.951)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.183 (0.183)	Data 0.277 (0.277)	Loss 0.3208 (0.3208)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.128 (0.127)	Data 0.000 (0.004)	Loss 0.3056 (0.3079)	Acc@1 95.312 (96.052)	Acc@5 100.000 (99.958)
Epoch: [109][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.3357 (0.3115)	Acc@1 95.703 (95.903)	Acc@5 99.609 (99.958)
Epoch: [109][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.2738 (0.3115)	Acc@1 97.656 (95.922)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.156 (0.156)	Data 0.289 (0.289)	Loss 0.2927 (0.2927)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.3067 (0.3030)	Acc@1 97.266 (96.328)	Acc@5 99.219 (99.934)
Epoch: [110][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3015 (0.3050)	Acc@1 96.484 (96.133)	Acc@5 100.000 (99.961)
Epoch: [110][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.2831 (0.3045)	Acc@1 97.266 (96.148)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.2449664
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.52
Max memory: 90.6890752
 25.133s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5768
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1336832
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.200 (0.200)	Data 0.272 (0.272)	Loss 0.2948 (0.2948)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.122 (0.128)	Data 0.000 (0.004)	Loss 0.2892 (0.2932)	Acc@1 98.047 (96.502)	Acc@5 100.000 (99.970)
Epoch: [111][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.3387 (0.2996)	Acc@1 95.312 (96.215)	Acc@5 100.000 (99.973)
Epoch: [111][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.3026 (0.3006)	Acc@1 96.094 (96.169)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.5595392
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.174 (0.174)	Data 0.292 (0.292)	Loss 0.2724 (0.2724)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.2978 (0.2937)	Acc@1 97.266 (96.352)	Acc@5 100.000 (99.958)
Epoch: [112][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3774 (0.2967)	Acc@1 92.188 (96.185)	Acc@5 100.000 (99.964)
Epoch: [112][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.3064 (0.3006)	Acc@1 94.531 (96.023)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.158 (0.158)	Data 0.291 (0.291)	Loss 0.2779 (0.2779)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.124 (0.126)	Data 0.000 (0.005)	Loss 0.2747 (0.2903)	Acc@1 97.266 (96.280)	Acc@5 100.000 (99.952)
Epoch: [113][128/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.3021 (0.2917)	Acc@1 95.312 (96.236)	Acc@5 99.609 (99.945)
Epoch: [113][192/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.3146 (0.2947)	Acc@1 94.922 (96.140)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.173 (0.173)	Data 0.272 (0.272)	Loss 0.3005 (0.3005)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.120 (0.127)	Data 0.000 (0.004)	Loss 0.2485 (0.2908)	Acc@1 98.438 (96.340)	Acc@5 100.000 (99.964)
Epoch: [114][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.2998 (0.2922)	Acc@1 97.266 (96.230)	Acc@5 99.609 (99.970)
Epoch: [114][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.3758 (0.2940)	Acc@1 92.969 (96.183)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.186 (0.186)	Data 0.265 (0.265)	Loss 0.2930 (0.2930)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.128 (0.126)	Data 0.000 (0.004)	Loss 0.3532 (0.2822)	Acc@1 94.531 (96.490)	Acc@5 100.000 (99.994)
Epoch: [115][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.2421 (0.2882)	Acc@1 98.438 (96.318)	Acc@5 100.000 (99.976)
Epoch: [115][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.2676 (0.2886)	Acc@1 96.484 (96.256)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.2449664
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.68
Max memory: 90.6890752
 24.857s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8677
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1336832
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.200 (0.200)	Data 0.284 (0.284)	Loss 0.3151 (0.3151)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.2988 (0.2840)	Acc@1 95.703 (96.364)	Acc@5 100.000 (99.982)
Epoch: [116][128/196]	Time 0.119 (0.128)	Data 0.000 (0.002)	Loss 0.2664 (0.2850)	Acc@1 97.266 (96.369)	Acc@5 100.000 (99.970)
Epoch: [116][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.2858 (0.2873)	Acc@1 96.484 (96.258)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.5595392
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.161 (0.161)	Data 0.310 (0.310)	Loss 0.3152 (0.3152)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.3126 (0.2898)	Acc@1 95.312 (96.208)	Acc@5 100.000 (99.958)
Epoch: [117][128/196]	Time 0.127 (0.127)	Data 0.000 (0.003)	Loss 0.2570 (0.2848)	Acc@1 96.875 (96.351)	Acc@5 100.000 (99.970)
Epoch: [117][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.2487 (0.2860)	Acc@1 97.656 (96.264)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.176 (0.176)	Data 0.297 (0.297)	Loss 0.2966 (0.2966)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.154 (0.130)	Data 0.000 (0.005)	Loss 0.3113 (0.2834)	Acc@1 93.750 (96.256)	Acc@5 100.000 (99.964)
Epoch: [118][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.2772 (0.2860)	Acc@1 97.266 (96.127)	Acc@5 99.609 (99.964)
Epoch: [118][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.2640 (0.2868)	Acc@1 96.094 (96.059)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.176 (0.176)	Data 0.301 (0.301)	Loss 0.2703 (0.2703)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.3005 (0.2794)	Acc@1 94.922 (96.412)	Acc@5 100.000 (99.964)
Epoch: [119][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.2945 (0.2823)	Acc@1 95.312 (96.154)	Acc@5 100.000 (99.967)
Epoch: [119][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3154 (0.2859)	Acc@1 94.922 (96.033)	Acc@5 100.000 (99.947)
Max memory in training epoch: 58.2449664
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.167 (0.167)	Data 0.262 (0.262)	Loss 0.2760 (0.2760)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.121 (0.127)	Data 0.000 (0.004)	Loss 0.2219 (0.2731)	Acc@1 98.828 (96.599)	Acc@5 100.000 (99.946)
Epoch: [120][128/196]	Time 0.133 (0.127)	Data 0.000 (0.002)	Loss 0.3074 (0.2771)	Acc@1 94.922 (96.418)	Acc@5 100.000 (99.955)
Epoch: [120][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.2655 (0.2803)	Acc@1 96.875 (96.262)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.2449664
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 312980 ; 313622 ; 0.9979529497292919
[INFO] Storing checkpoint...
  89.98
Max memory: 90.6890752
 25.115s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 712
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.132864
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.176 (0.176)	Data 0.286 (0.286)	Loss 0.2738 (0.2738)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.2656 (0.2671)	Acc@1 96.875 (96.683)	Acc@5 99.609 (99.964)
Epoch: [121][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.3086 (0.2739)	Acc@1 95.312 (96.409)	Acc@5 100.000 (99.964)
Epoch: [121][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2928 (0.2799)	Acc@1 96.484 (96.146)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.8270336
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.172 (0.172)	Data 0.270 (0.270)	Loss 0.2536 (0.2536)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.2348 (0.2803)	Acc@1 97.656 (96.250)	Acc@5 100.000 (99.970)
Epoch: [122][128/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.2908 (0.2850)	Acc@1 95.703 (96.079)	Acc@5 100.000 (99.964)
Epoch: [122][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3066 (0.2868)	Acc@1 94.531 (95.944)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.165 (0.165)	Data 0.270 (0.270)	Loss 0.2636 (0.2636)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.136 (0.124)	Data 0.000 (0.004)	Loss 0.2866 (0.2766)	Acc@1 95.703 (96.190)	Acc@5 100.000 (99.976)
Epoch: [123][128/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.2553 (0.2792)	Acc@1 96.875 (96.148)	Acc@5 100.000 (99.970)
Epoch: [123][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.2701 (0.2831)	Acc@1 96.875 (95.954)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.150 (0.150)	Data 0.295 (0.295)	Loss 0.2603 (0.2603)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.126 (0.122)	Data 0.000 (0.005)	Loss 0.2838 (0.2779)	Acc@1 96.094 (96.202)	Acc@5 100.000 (99.946)
Epoch: [124][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2918 (0.2773)	Acc@1 96.484 (96.248)	Acc@5 100.000 (99.949)
Epoch: [124][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2837 (0.2795)	Acc@1 96.484 (96.169)	Acc@5 100.000 (99.947)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.150 (0.150)	Data 0.277 (0.277)	Loss 0.2359 (0.2359)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.116 (0.124)	Data 0.000 (0.004)	Loss 0.2543 (0.2723)	Acc@1 96.484 (96.358)	Acc@5 100.000 (99.958)
Epoch: [125][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2469 (0.2781)	Acc@1 97.266 (96.091)	Acc@5 100.000 (99.964)
Epoch: [125][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.2773 (0.2809)	Acc@1 95.703 (95.999)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.13
Max memory: 88.18048
 24.552s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3048
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.132864
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.183 (0.183)	Data 0.296 (0.296)	Loss 0.2839 (0.2839)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [126][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2810 (0.2668)	Acc@1 94.531 (96.526)	Acc@5 100.000 (99.964)
Epoch: [126][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2322 (0.2691)	Acc@1 97.266 (96.436)	Acc@5 100.000 (99.976)
Epoch: [126][192/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.2677 (0.2731)	Acc@1 96.094 (96.316)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.8270336
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.177 (0.177)	Data 0.260 (0.260)	Loss 0.2950 (0.2950)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.3477 (0.2902)	Acc@1 94.141 (95.349)	Acc@5 100.000 (99.964)
Epoch: [127][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.2485 (0.2863)	Acc@1 97.266 (95.621)	Acc@5 99.609 (99.970)
Epoch: [127][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2306 (0.2853)	Acc@1 98.828 (95.667)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.186 (0.186)	Data 0.264 (0.264)	Loss 0.2730 (0.2730)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2984 (0.2814)	Acc@1 96.094 (95.745)	Acc@5 100.000 (99.946)
Epoch: [128][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2689 (0.2826)	Acc@1 97.656 (95.906)	Acc@5 100.000 (99.958)
Epoch: [128][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2730 (0.2839)	Acc@1 96.484 (95.855)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.174 (0.174)	Data 0.269 (0.269)	Loss 0.2827 (0.2827)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.3409 (0.2737)	Acc@1 92.578 (96.346)	Acc@5 100.000 (99.982)
Epoch: [129][128/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.2980 (0.2780)	Acc@1 94.531 (96.057)	Acc@5 100.000 (99.976)
Epoch: [129][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.3016 (0.2816)	Acc@1 94.141 (95.873)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.157 (0.157)	Data 0.295 (0.295)	Loss 0.2531 (0.2531)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.3036 (0.2756)	Acc@1 94.922 (96.202)	Acc@5 100.000 (99.970)
Epoch: [130][128/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.2486 (0.2805)	Acc@1 96.484 (95.888)	Acc@5 100.000 (99.973)
Epoch: [130][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3307 (0.2821)	Acc@1 93.750 (95.772)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.97
Max memory: 88.18048
 24.425s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7249
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.132864
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.179 (0.179)	Data 0.293 (0.293)	Loss 0.2810 (0.2810)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2863 (0.2586)	Acc@1 95.312 (96.671)	Acc@5 100.000 (99.982)
Epoch: [131][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2691 (0.2670)	Acc@1 96.094 (96.397)	Acc@5 100.000 (99.979)
Epoch: [131][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3056 (0.2753)	Acc@1 94.141 (96.108)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.8270336
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.175 (0.175)	Data 0.309 (0.309)	Loss 0.2496 (0.2496)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.2970 (0.2840)	Acc@1 93.750 (95.715)	Acc@5 100.000 (99.964)
Epoch: [132][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.2857 (0.2786)	Acc@1 96.484 (95.855)	Acc@5 100.000 (99.964)
Epoch: [132][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2953 (0.2828)	Acc@1 94.531 (95.766)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.155 (0.155)	Data 0.298 (0.298)	Loss 0.2563 (0.2563)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [133][64/196]	Time 0.125 (0.122)	Data 0.000 (0.005)	Loss 0.2604 (0.2861)	Acc@1 96.484 (95.787)	Acc@5 100.000 (99.970)
Epoch: [133][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3268 (0.2791)	Acc@1 94.141 (95.988)	Acc@5 100.000 (99.976)
Epoch: [133][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3701 (0.2809)	Acc@1 91.797 (95.885)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.157 (0.157)	Data 0.304 (0.304)	Loss 0.3002 (0.3002)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.112 (0.121)	Data 0.000 (0.005)	Loss 0.4114 (0.2742)	Acc@1 93.750 (96.160)	Acc@5 100.000 (99.988)
Epoch: [134][128/196]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.3226 (0.2726)	Acc@1 94.531 (96.154)	Acc@5 100.000 (99.979)
Epoch: [134][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2816 (0.2771)	Acc@1 94.922 (95.968)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.168 (0.168)	Data 0.289 (0.289)	Loss 0.2407 (0.2407)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2859 (0.2771)	Acc@1 94.531 (95.889)	Acc@5 100.000 (99.976)
Epoch: [135][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2765 (0.2760)	Acc@1 96.094 (95.903)	Acc@5 100.000 (99.979)
Epoch: [135][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2620 (0.2766)	Acc@1 96.875 (95.912)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.23
Max memory: 88.18048
 23.885s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3501
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.132864
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.199 (0.199)	Data 0.270 (0.270)	Loss 0.2786 (0.2786)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.122 (0.122)	Data 0.000 (0.004)	Loss 0.2480 (0.2607)	Acc@1 96.094 (96.653)	Acc@5 100.000 (99.970)
Epoch: [136][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2999 (0.2671)	Acc@1 95.312 (96.375)	Acc@5 100.000 (99.964)
Epoch: [136][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2656 (0.2706)	Acc@1 97.656 (96.209)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.8270336
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.169 (0.169)	Data 0.303 (0.303)	Loss 0.2851 (0.2851)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2997 (0.2777)	Acc@1 94.531 (95.775)	Acc@5 100.000 (99.964)
Epoch: [137][128/196]	Time 0.126 (0.121)	Data 0.000 (0.003)	Loss 0.3293 (0.2792)	Acc@1 93.750 (95.730)	Acc@5 100.000 (99.967)
Epoch: [137][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2754 (0.2808)	Acc@1 95.312 (95.659)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.142 (0.142)	Data 0.332 (0.332)	Loss 0.2735 (0.2735)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.2446 (0.2615)	Acc@1 96.875 (96.448)	Acc@5 100.000 (99.970)
Epoch: [138][128/196]	Time 0.118 (0.119)	Data 0.000 (0.003)	Loss 0.2672 (0.2670)	Acc@1 96.094 (96.206)	Acc@5 100.000 (99.976)
Epoch: [138][192/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.3056 (0.2737)	Acc@1 94.141 (95.956)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.161 (0.161)	Data 0.300 (0.300)	Loss 0.2800 (0.2800)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.2867 (0.2760)	Acc@1 96.094 (95.907)	Acc@5 100.000 (99.982)
Epoch: [139][128/196]	Time 0.123 (0.122)	Data 0.000 (0.003)	Loss 0.2537 (0.2807)	Acc@1 96.875 (95.633)	Acc@5 100.000 (99.973)
Epoch: [139][192/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.3456 (0.2829)	Acc@1 95.703 (95.616)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.152 (0.152)	Data 0.267 (0.267)	Loss 0.2510 (0.2510)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.2717 (0.2700)	Acc@1 95.703 (95.962)	Acc@5 100.000 (99.970)
Epoch: [140][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2363 (0.2716)	Acc@1 98.047 (95.976)	Acc@5 100.000 (99.973)
Epoch: [140][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.2977 (0.2736)	Acc@1 95.312 (95.924)	Acc@5 99.609 (99.972)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.63
Max memory: 88.18048
 23.949s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1187
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.132864
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.184 (0.184)	Data 0.304 (0.304)	Loss 0.2806 (0.2806)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.114 (0.121)	Data 0.000 (0.005)	Loss 0.2955 (0.2610)	Acc@1 94.141 (96.388)	Acc@5 100.000 (99.988)
Epoch: [141][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.3362 (0.2650)	Acc@1 94.141 (96.257)	Acc@5 99.609 (99.979)
Epoch: [141][192/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.2806 (0.2709)	Acc@1 95.703 (96.047)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.8270336
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.172 (0.172)	Data 0.263 (0.263)	Loss 0.3113 (0.3113)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.2904 (0.2770)	Acc@1 94.531 (95.992)	Acc@5 100.000 (99.982)
Epoch: [142][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3341 (0.2795)	Acc@1 92.578 (95.736)	Acc@5 100.000 (99.973)
Epoch: [142][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3219 (0.2836)	Acc@1 93.359 (95.568)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.169 (0.169)	Data 0.268 (0.268)	Loss 0.2689 (0.2689)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.118 (0.123)	Data 0.000 (0.004)	Loss 0.2382 (0.2814)	Acc@1 96.875 (95.643)	Acc@5 100.000 (99.934)
Epoch: [143][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2468 (0.2813)	Acc@1 96.094 (95.664)	Acc@5 100.000 (99.945)
Epoch: [143][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2308 (0.2828)	Acc@1 97.266 (95.570)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.167 (0.167)	Data 0.282 (0.282)	Loss 0.2783 (0.2783)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2925 (0.2754)	Acc@1 94.531 (95.799)	Acc@5 100.000 (99.976)
Epoch: [144][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2414 (0.2716)	Acc@1 97.656 (96.024)	Acc@5 100.000 (99.979)
Epoch: [144][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2828 (0.2747)	Acc@1 96.484 (95.863)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.167 (0.167)	Data 0.285 (0.285)	Loss 0.3087 (0.3087)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.3088 (0.2755)	Acc@1 92.578 (96.082)	Acc@5 100.000 (99.988)
Epoch: [145][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3054 (0.2764)	Acc@1 95.703 (96.015)	Acc@5 100.000 (99.979)
Epoch: [145][192/196]	Time 0.130 (0.122)	Data 0.000 (0.002)	Loss 0.2594 (0.2782)	Acc@1 96.875 (95.954)	Acc@5 100.000 (99.986)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.37
Max memory: 88.18048
 24.243s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1459
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.132864
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.194 (0.194)	Data 0.265 (0.265)	Loss 0.2930 (0.2930)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.115 (0.119)	Data 0.000 (0.004)	Loss 0.2599 (0.2586)	Acc@1 96.875 (96.460)	Acc@5 100.000 (99.988)
Epoch: [146][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2984 (0.2691)	Acc@1 94.531 (96.082)	Acc@5 100.000 (99.979)
Epoch: [146][192/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3044 (0.2735)	Acc@1 94.531 (95.995)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.8270336
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.170 (0.170)	Data 0.294 (0.294)	Loss 0.3152 (0.3152)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [147][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2696 (0.2788)	Acc@1 95.703 (95.859)	Acc@5 100.000 (99.970)
Epoch: [147][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2671 (0.2795)	Acc@1 97.656 (95.779)	Acc@5 100.000 (99.979)
Epoch: [147][192/196]	Time 0.110 (0.118)	Data 0.000 (0.002)	Loss 0.2423 (0.2823)	Acc@1 96.875 (95.659)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.179 (0.179)	Data 0.324 (0.324)	Loss 0.2425 (0.2425)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.113 (0.119)	Data 0.000 (0.005)	Loss 0.2542 (0.2698)	Acc@1 95.703 (96.202)	Acc@5 100.000 (99.982)
Epoch: [148][128/196]	Time 0.120 (0.119)	Data 0.000 (0.003)	Loss 0.2873 (0.2735)	Acc@1 95.703 (96.003)	Acc@5 99.609 (99.976)
Epoch: [148][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2581 (0.2750)	Acc@1 97.266 (95.920)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.174 (0.174)	Data 0.286 (0.286)	Loss 0.2760 (0.2760)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.122 (0.118)	Data 0.000 (0.005)	Loss 0.3211 (0.2819)	Acc@1 94.531 (95.547)	Acc@5 100.000 (99.982)
Epoch: [149][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.2700 (0.2797)	Acc@1 95.312 (95.712)	Acc@5 100.000 (99.979)
Epoch: [149][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2539 (0.2799)	Acc@1 97.656 (95.733)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.5124608
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.174 (0.174)	Data 0.286 (0.286)	Loss 0.2304 (0.2304)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.2394 (0.2504)	Acc@1 96.484 (96.725)	Acc@5 100.000 (99.976)
Epoch: [150][128/196]	Time 0.158 (0.121)	Data 0.000 (0.002)	Loss 0.2168 (0.2415)	Acc@1 98.438 (97.151)	Acc@5 100.000 (99.979)
Epoch: [150][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2214 (0.2354)	Acc@1 98.438 (97.397)	Acc@5 100.000 (99.986)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.07
Max memory: 88.18048
 23.995s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3874
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.132864
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.178 (0.178)	Data 0.265 (0.265)	Loss 0.1905 (0.1905)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.134 (0.122)	Data 0.000 (0.004)	Loss 0.2023 (0.2181)	Acc@1 99.219 (98.059)	Acc@5 100.000 (99.994)
Epoch: [151][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2156 (0.2166)	Acc@1 98.438 (98.156)	Acc@5 100.000 (99.997)
Epoch: [151][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2339 (0.2163)	Acc@1 97.656 (98.162)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8270336
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.163 (0.163)	Data 0.318 (0.318)	Loss 0.1816 (0.1816)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.135 (0.122)	Data 0.000 (0.005)	Loss 0.2069 (0.2091)	Acc@1 98.438 (98.341)	Acc@5 100.000 (99.994)
Epoch: [152][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.2271 (0.2084)	Acc@1 97.656 (98.444)	Acc@5 100.000 (99.994)
Epoch: [152][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2181 (0.2087)	Acc@1 99.219 (98.440)	Acc@5 100.000 (99.992)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.159 (0.159)	Data 0.284 (0.284)	Loss 0.2074 (0.2074)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.2076 (0.2031)	Acc@1 98.047 (98.594)	Acc@5 100.000 (100.000)
Epoch: [153][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1982 (0.2044)	Acc@1 99.219 (98.547)	Acc@5 100.000 (100.000)
Epoch: [153][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1834 (0.2038)	Acc@1 99.219 (98.581)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.154 (0.154)	Data 0.263 (0.263)	Loss 0.2002 (0.2002)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.1993 (0.2030)	Acc@1 98.828 (98.588)	Acc@5 100.000 (99.988)
Epoch: [154][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2093 (0.2015)	Acc@1 96.875 (98.671)	Acc@5 100.000 (99.994)
Epoch: [154][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1979 (0.2008)	Acc@1 98.047 (98.672)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.176 (0.176)	Data 0.303 (0.303)	Loss 0.1799 (0.1799)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2023 (0.2009)	Acc@1 98.438 (98.624)	Acc@5 100.000 (99.994)
Epoch: [155][128/196]	Time 0.113 (0.119)	Data 0.000 (0.003)	Loss 0.2020 (0.1984)	Acc@1 98.438 (98.762)	Acc@5 100.000 (99.997)
Epoch: [155][192/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.2191 (0.1977)	Acc@1 97.656 (98.792)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.66
Max memory: 88.18048
 23.757s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8537
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.132864
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.174 (0.174)	Data 0.298 (0.298)	Loss 0.1748 (0.1748)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.1967 (0.1948)	Acc@1 98.828 (98.948)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1771 (0.1944)	Acc@1 100.000 (98.949)	Acc@5 100.000 (99.997)
Epoch: [156][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.2102 (0.1944)	Acc@1 97.656 (98.948)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8270336
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.147 (0.147)	Data 0.298 (0.298)	Loss 0.1866 (0.1866)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.1966 (0.1931)	Acc@1 98.828 (98.984)	Acc@5 100.000 (99.988)
Epoch: [157][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2152 (0.1942)	Acc@1 98.438 (98.922)	Acc@5 100.000 (99.994)
Epoch: [157][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2019 (0.1938)	Acc@1 98.828 (98.917)	Acc@5 100.000 (99.994)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.169 (0.169)	Data 0.270 (0.270)	Loss 0.1890 (0.1890)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.129 (0.121)	Data 0.000 (0.004)	Loss 0.1937 (0.1911)	Acc@1 98.828 (99.032)	Acc@5 100.000 (99.994)
Epoch: [158][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1832 (0.1904)	Acc@1 99.609 (99.040)	Acc@5 100.000 (99.994)
Epoch: [158][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.1762 (0.1909)	Acc@1 99.609 (99.039)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.150 (0.150)	Data 0.284 (0.284)	Loss 0.1838 (0.1838)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.132 (0.124)	Data 0.000 (0.005)	Loss 0.1935 (0.1867)	Acc@1 98.828 (99.165)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1764 (0.1874)	Acc@1 99.219 (99.101)	Acc@5 100.000 (100.000)
Epoch: [159][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2211 (0.1885)	Acc@1 98.438 (99.053)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.151 (0.151)	Data 0.294 (0.294)	Loss 0.1869 (0.1869)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.1884 (0.1879)	Acc@1 99.219 (99.153)	Acc@5 100.000 (99.994)
Epoch: [160][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2111 (0.1879)	Acc@1 98.047 (99.101)	Acc@5 100.000 (99.994)
Epoch: [160][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.1839 (0.1878)	Acc@1 99.219 (99.105)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.9
Max memory: 88.18048
 24.204s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3285
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.132864
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.204 (0.204)	Data 0.273 (0.273)	Loss 0.1889 (0.1889)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.114 (0.123)	Data 0.000 (0.004)	Loss 0.1731 (0.1857)	Acc@1 99.609 (99.159)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1740 (0.1861)	Acc@1 99.219 (99.092)	Acc@5 100.000 (99.997)
Epoch: [161][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1827 (0.1859)	Acc@1 99.219 (99.116)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8270336
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.159 (0.159)	Data 0.280 (0.280)	Loss 0.1835 (0.1835)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.131 (0.122)	Data 0.000 (0.005)	Loss 0.1904 (0.1834)	Acc@1 98.438 (99.219)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1799 (0.1853)	Acc@1 98.438 (99.134)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1660 (0.1849)	Acc@1 100.000 (99.172)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.167 (0.167)	Data 0.274 (0.274)	Loss 0.1704 (0.1704)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.1731 (0.1851)	Acc@1 99.609 (99.207)	Acc@5 100.000 (99.994)
Epoch: [163][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1824 (0.1837)	Acc@1 99.219 (99.231)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.1782 (0.1838)	Acc@1 99.609 (99.221)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.186 (0.186)	Data 0.261 (0.261)	Loss 0.1774 (0.1774)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.1742 (0.1818)	Acc@1 99.609 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2015 (0.1818)	Acc@1 98.828 (99.261)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1883 (0.1831)	Acc@1 98.828 (99.221)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.172 (0.172)	Data 0.257 (0.257)	Loss 0.1833 (0.1833)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.1944 (0.1823)	Acc@1 98.828 (99.165)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1744 (0.1823)	Acc@1 99.609 (99.213)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.116 (0.121)	Data 0.000 (0.001)	Loss 0.1911 (0.1827)	Acc@1 99.609 (99.182)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.74
Max memory: 88.18048
 24.127s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3845
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.132864
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.186 (0.186)	Data 0.290 (0.290)	Loss 0.1874 (0.1874)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2054 (0.1815)	Acc@1 98.438 (99.183)	Acc@5 100.000 (99.994)
Epoch: [166][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1747 (0.1813)	Acc@1 99.609 (99.213)	Acc@5 100.000 (99.997)
Epoch: [166][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1881 (0.1812)	Acc@1 99.609 (99.225)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8270336
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.167 (0.167)	Data 0.267 (0.267)	Loss 0.1918 (0.1918)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.1793 (0.1799)	Acc@1 98.828 (99.249)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.1823 (0.1802)	Acc@1 98.828 (99.228)	Acc@5 100.000 (99.997)
Epoch: [167][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1827 (0.1797)	Acc@1 98.828 (99.229)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.185 (0.185)	Data 0.278 (0.278)	Loss 0.1833 (0.1833)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.123 (0.123)	Data 0.000 (0.004)	Loss 0.1714 (0.1786)	Acc@1 99.609 (99.273)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1722 (0.1785)	Acc@1 99.609 (99.297)	Acc@5 100.000 (100.000)
Epoch: [168][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1626 (0.1781)	Acc@1 100.000 (99.308)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.168 (0.168)	Data 0.273 (0.273)	Loss 0.1776 (0.1776)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.1827 (0.1757)	Acc@1 99.219 (99.405)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.1627 (0.1756)	Acc@1 100.000 (99.388)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.1938 (0.1763)	Acc@1 98.438 (99.364)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.171 (0.171)	Data 0.267 (0.267)	Loss 0.1793 (0.1793)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.118 (0.124)	Data 0.000 (0.004)	Loss 0.1876 (0.1777)	Acc@1 98.438 (99.243)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.1772 (0.1769)	Acc@1 99.609 (99.304)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1693 (0.1771)	Acc@1 99.609 (99.279)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.73
Max memory: 88.18048
 24.263s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6807
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.132864
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.177 (0.177)	Data 0.293 (0.293)	Loss 0.1705 (0.1705)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.1720 (0.1760)	Acc@1 99.609 (99.327)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1603 (0.1749)	Acc@1 100.000 (99.391)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1842 (0.1746)	Acc@1 99.219 (99.381)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.8270336
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.177 (0.177)	Data 0.256 (0.256)	Loss 0.1674 (0.1674)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.126 (0.122)	Data 0.000 (0.004)	Loss 0.1742 (0.1741)	Acc@1 99.609 (99.339)	Acc@5 100.000 (99.994)
Epoch: [172][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1622 (0.1741)	Acc@1 100.000 (99.400)	Acc@5 100.000 (99.997)
Epoch: [172][192/196]	Time 0.119 (0.122)	Data 0.000 (0.001)	Loss 0.1667 (0.1734)	Acc@1 100.000 (99.423)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.183 (0.183)	Data 0.262 (0.262)	Loss 0.1753 (0.1753)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.1818 (0.1740)	Acc@1 98.828 (99.351)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.1635 (0.1734)	Acc@1 99.609 (99.376)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.1674 (0.1740)	Acc@1 99.609 (99.354)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.166 (0.166)	Data 0.310 (0.310)	Loss 0.1903 (0.1903)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.1638 (0.1733)	Acc@1 100.000 (99.363)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.123 (0.122)	Data 0.000 (0.003)	Loss 0.1831 (0.1734)	Acc@1 99.219 (99.400)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1747 (0.1727)	Acc@1 99.609 (99.427)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.153 (0.153)	Data 0.262 (0.262)	Loss 0.1656 (0.1656)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.1630 (0.1712)	Acc@1 100.000 (99.441)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.1805 (0.1715)	Acc@1 99.219 (99.400)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.1798 (0.1727)	Acc@1 99.219 (99.366)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.7
Max memory: 88.18048
 24.466s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1451
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.132864
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.180 (0.180)	Data 0.278 (0.278)	Loss 0.1599 (0.1599)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.1811 (0.1702)	Acc@1 99.219 (99.429)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.1737 (0.1712)	Acc@1 99.609 (99.416)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1733 (0.1715)	Acc@1 98.828 (99.407)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.8270336
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.166 (0.166)	Data 0.307 (0.307)	Loss 0.1639 (0.1639)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.113 (0.122)	Data 0.000 (0.005)	Loss 0.1585 (0.1691)	Acc@1 100.000 (99.495)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.1769 (0.1690)	Acc@1 98.828 (99.476)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.1630 (0.1696)	Acc@1 99.609 (99.458)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.172 (0.172)	Data 0.287 (0.287)	Loss 0.1633 (0.1633)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.1586 (0.1697)	Acc@1 100.000 (99.459)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.1665 (0.1698)	Acc@1 99.609 (99.449)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.1839 (0.1702)	Acc@1 98.828 (99.427)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.140 (0.140)	Data 0.288 (0.288)	Loss 0.1608 (0.1608)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.1736 (0.1695)	Acc@1 98.828 (99.489)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.1828 (0.1695)	Acc@1 99.219 (99.488)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.1623 (0.1696)	Acc@1 100.000 (99.441)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.153 (0.153)	Data 0.306 (0.306)	Loss 0.1750 (0.1750)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.127 (0.122)	Data 0.000 (0.005)	Loss 0.1718 (0.1672)	Acc@1 98.828 (99.513)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.1866 (0.1679)	Acc@1 99.609 (99.506)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.1590 (0.1683)	Acc@1 100.000 (99.480)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.5124608
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 30, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(23, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(15, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(11, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.71
Max memory: 88.1239552
 24.129s  Thres 0.001 3
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6248
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.185 (0.185)	Data 0.281 (0.281)	Loss 3.2877 (3.2877)	Acc@1 8.203 (8.203)	Acc@5 50.000 (50.000)
Epoch: [1][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 2.3311 (2.6568)	Acc@1 35.938 (24.808)	Acc@5 89.453 (78.690)
Epoch: [1][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 2.0899 (2.4687)	Acc@1 47.266 (31.286)	Acc@5 90.234 (83.763)
Epoch: [1][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 1.9784 (2.3426)	Acc@1 47.656 (35.616)	Acc@5 92.578 (86.346)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.157 (0.157)	Data 0.296 (0.296)	Loss 1.9274 (1.9274)	Acc@1 51.172 (51.172)	Acc@5 95.312 (95.312)
Epoch: [2][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 1.8427 (1.9115)	Acc@1 54.297 (51.364)	Acc@5 93.750 (93.498)
Epoch: [2][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 1.5609 (1.8358)	Acc@1 63.281 (53.828)	Acc@5 97.266 (94.286)
Epoch: [2][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 1.5787 (1.7576)	Acc@1 59.766 (56.471)	Acc@5 94.922 (94.938)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.178 (0.178)	Data 0.266 (0.266)	Loss 1.5217 (1.5217)	Acc@1 64.453 (64.453)	Acc@5 96.875 (96.875)
Epoch: [3][64/196]	Time 0.125 (0.131)	Data 0.000 (0.004)	Loss 1.4041 (1.5157)	Acc@1 66.406 (63.828)	Acc@5 98.438 (96.767)
Epoch: [3][128/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 1.4461 (1.4684)	Acc@1 69.141 (65.443)	Acc@5 96.484 (96.993)
Epoch: [3][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.3470 (1.4249)	Acc@1 73.438 (66.937)	Acc@5 96.875 (97.211)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.171 (0.171)	Data 0.301 (0.301)	Loss 1.3275 (1.3275)	Acc@1 66.797 (66.797)	Acc@5 98.828 (98.828)
Epoch: [4][64/196]	Time 0.157 (0.132)	Data 0.000 (0.005)	Loss 1.3158 (1.2804)	Acc@1 74.219 (71.538)	Acc@5 96.875 (97.837)
Epoch: [4][128/196]	Time 0.132 (0.131)	Data 0.000 (0.003)	Loss 1.2907 (1.2518)	Acc@1 72.266 (72.190)	Acc@5 96.875 (97.986)
Epoch: [4][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 1.1102 (1.2248)	Acc@1 75.391 (72.751)	Acc@5 97.266 (98.095)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.177 (0.177)	Data 0.270 (0.270)	Loss 1.1124 (1.1124)	Acc@1 76.172 (76.172)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.125 (0.133)	Data 0.000 (0.004)	Loss 1.1541 (1.1286)	Acc@1 73.828 (75.282)	Acc@5 98.438 (98.431)
Epoch: [5][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 1.0136 (1.1143)	Acc@1 81.641 (75.509)	Acc@5 98.438 (98.441)
Epoch: [5][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.9480 (1.0961)	Acc@1 81.641 (75.931)	Acc@5 99.219 (98.435)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  61.04
Max memory: 103.3835008
 26.003s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1979
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.208 (0.208)	Data 0.287 (0.287)	Loss 1.0076 (1.0076)	Acc@1 80.859 (80.859)	Acc@5 98.438 (98.438)
Epoch: [6][64/196]	Time 0.125 (0.132)	Data 0.000 (0.005)	Loss 1.1226 (1.0173)	Acc@1 75.000 (77.981)	Acc@5 98.438 (98.708)
Epoch: [6][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 1.0529 (1.0173)	Acc@1 77.734 (77.819)	Acc@5 98.047 (98.774)
Epoch: [6][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.9813 (1.0076)	Acc@1 78.906 (78.000)	Acc@5 98.828 (98.769)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.171 (0.171)	Data 0.322 (0.322)	Loss 0.9671 (0.9671)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [7][64/196]	Time 0.140 (0.131)	Data 0.000 (0.005)	Loss 0.9370 (0.9634)	Acc@1 78.125 (79.014)	Acc@5 98.438 (98.888)
Epoch: [7][128/196]	Time 0.126 (0.130)	Data 0.000 (0.003)	Loss 0.9678 (0.9609)	Acc@1 77.734 (78.949)	Acc@5 98.828 (98.886)
Epoch: [7][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.0356 (0.9557)	Acc@1 75.781 (79.076)	Acc@5 97.656 (98.858)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.194 (0.194)	Data 0.271 (0.271)	Loss 0.9162 (0.9162)	Acc@1 80.078 (80.078)	Acc@5 98.047 (98.047)
Epoch: [8][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.9566 (0.9108)	Acc@1 75.781 (79.928)	Acc@5 99.609 (98.966)
Epoch: [8][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.9106 (0.9113)	Acc@1 80.078 (79.978)	Acc@5 98.828 (98.864)
Epoch: [8][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.9392 (0.9020)	Acc@1 79.688 (80.183)	Acc@5 98.438 (98.923)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.163 (0.163)	Data 0.304 (0.304)	Loss 0.7923 (0.7923)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.148 (0.132)	Data 0.000 (0.005)	Loss 0.8209 (0.8714)	Acc@1 84.766 (80.986)	Acc@5 98.828 (99.044)
Epoch: [9][128/196]	Time 0.144 (0.131)	Data 0.000 (0.003)	Loss 0.8557 (0.8684)	Acc@1 80.469 (81.053)	Acc@5 100.000 (99.043)
Epoch: [9][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.8500 (0.8674)	Acc@1 78.906 (81.013)	Acc@5 98.828 (99.033)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.177 (0.177)	Data 0.308 (0.308)	Loss 0.8417 (0.8417)	Acc@1 80.469 (80.469)	Acc@5 98.828 (98.828)
Epoch: [10][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.8051 (0.8459)	Acc@1 80.469 (81.538)	Acc@5 99.219 (98.996)
Epoch: [10][128/196]	Time 0.131 (0.134)	Data 0.000 (0.003)	Loss 0.8490 (0.8492)	Acc@1 82.422 (81.183)	Acc@5 98.828 (99.031)
Epoch: [10][192/196]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 0.7706 (0.8419)	Acc@1 82.422 (81.456)	Acc@5 99.609 (99.065)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  69.82
Max memory: 103.3833984
 26.595s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2093
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.194 (0.194)	Data 0.288 (0.288)	Loss 0.7896 (0.7896)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [11][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.8064 (0.8007)	Acc@1 82.422 (82.704)	Acc@5 99.219 (99.099)
Epoch: [11][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8276 (0.8127)	Acc@1 82.031 (82.240)	Acc@5 98.828 (99.110)
Epoch: [11][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7608 (0.8166)	Acc@1 83.984 (82.183)	Acc@5 100.000 (99.075)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.170 (0.170)	Data 0.294 (0.294)	Loss 0.7655 (0.7655)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.134 (0.129)	Data 0.000 (0.005)	Loss 0.8291 (0.8062)	Acc@1 80.859 (82.518)	Acc@5 99.219 (99.165)
Epoch: [12][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.8328 (0.8091)	Acc@1 80.469 (82.410)	Acc@5 99.609 (99.170)
Epoch: [12][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7812 (0.8101)	Acc@1 82.812 (82.355)	Acc@5 98.828 (99.158)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.176 (0.176)	Data 0.286 (0.286)	Loss 0.8060 (0.8060)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.140 (0.132)	Data 0.000 (0.005)	Loss 0.8239 (0.8008)	Acc@1 81.641 (82.662)	Acc@5 100.000 (99.117)
Epoch: [13][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7930 (0.7997)	Acc@1 83.203 (82.746)	Acc@5 99.219 (99.170)
Epoch: [13][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.9043 (0.8041)	Acc@1 80.078 (82.657)	Acc@5 99.609 (99.150)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.168 (0.168)	Data 0.293 (0.293)	Loss 0.7963 (0.7963)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.7438 (0.7933)	Acc@1 84.375 (82.873)	Acc@5 99.609 (99.189)
Epoch: [14][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.9142 (0.7928)	Acc@1 81.250 (82.952)	Acc@5 97.656 (99.179)
Epoch: [14][192/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.7800 (0.7986)	Acc@1 82.812 (82.758)	Acc@5 99.609 (99.156)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.185 (0.185)	Data 0.291 (0.291)	Loss 0.7290 (0.7290)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [15][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.6972 (0.7775)	Acc@1 88.672 (83.227)	Acc@5 98.828 (99.249)
Epoch: [15][128/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.8411 (0.7897)	Acc@1 80.859 (83.040)	Acc@5 98.828 (99.179)
Epoch: [15][192/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7069 (0.7880)	Acc@1 86.328 (83.100)	Acc@5 100.000 (99.203)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  65.63
Max memory: 103.3833984
 26.119s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 788
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.216 (0.216)	Data 0.264 (0.264)	Loss 0.7362 (0.7362)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.121 (0.131)	Data 0.000 (0.004)	Loss 0.8158 (0.7721)	Acc@1 82.422 (83.750)	Acc@5 99.219 (99.165)
Epoch: [16][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7566 (0.7724)	Acc@1 82.812 (83.639)	Acc@5 100.000 (99.182)
Epoch: [16][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8285 (0.7812)	Acc@1 81.250 (83.258)	Acc@5 99.609 (99.144)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.164 (0.164)	Data 0.273 (0.273)	Loss 0.8028 (0.8028)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [17][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.7667 (0.7748)	Acc@1 86.328 (83.732)	Acc@5 99.219 (99.231)
Epoch: [17][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.8163 (0.7684)	Acc@1 83.594 (84.000)	Acc@5 98.438 (99.267)
Epoch: [17][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7655 (0.7748)	Acc@1 83.984 (83.731)	Acc@5 99.609 (99.196)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.187 (0.187)	Data 0.275 (0.275)	Loss 0.7378 (0.7378)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [18][64/196]	Time 0.124 (0.133)	Data 0.000 (0.004)	Loss 0.8073 (0.7804)	Acc@1 83.594 (83.804)	Acc@5 98.828 (99.123)
Epoch: [18][128/196]	Time 0.144 (0.132)	Data 0.000 (0.002)	Loss 0.7586 (0.7645)	Acc@1 83.203 (84.154)	Acc@5 99.609 (99.255)
Epoch: [18][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7460 (0.7699)	Acc@1 83.203 (83.758)	Acc@5 99.219 (99.265)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.186 (0.186)	Data 0.271 (0.271)	Loss 0.6318 (0.6318)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.8098 (0.7543)	Acc@1 81.250 (84.261)	Acc@5 99.219 (99.237)
Epoch: [19][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7966 (0.7650)	Acc@1 80.859 (83.778)	Acc@5 99.219 (99.191)
Epoch: [19][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7538 (0.7649)	Acc@1 81.641 (83.885)	Acc@5 100.000 (99.219)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.171 (0.171)	Data 0.305 (0.305)	Loss 0.7084 (0.7084)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.138 (0.131)	Data 0.000 (0.005)	Loss 0.8296 (0.7496)	Acc@1 81.641 (84.609)	Acc@5 99.219 (99.381)
Epoch: [20][128/196]	Time 0.139 (0.131)	Data 0.000 (0.003)	Loss 0.7374 (0.7540)	Acc@1 85.938 (84.369)	Acc@5 98.438 (99.294)
Epoch: [20][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7475 (0.7571)	Acc@1 82.812 (84.211)	Acc@5 100.000 (99.290)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 481616 ; 487386 ; 0.988161334137624
[INFO] Storing checkpoint...
  66.96
Max memory: 103.3833984
 25.903s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8878
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2002432
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.203 (0.203)	Data 0.263 (0.263)	Loss 0.7001 (0.7001)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.7519 (0.7201)	Acc@1 85.938 (85.409)	Acc@5 98.438 (99.405)
Epoch: [21][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7460 (0.7309)	Acc@1 82.812 (85.105)	Acc@5 98.828 (99.352)
Epoch: [21][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7053 (0.7458)	Acc@1 84.375 (84.539)	Acc@5 100.000 (99.340)
Max memory in training epoch: 66.6376704
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.192 (0.192)	Data 0.265 (0.265)	Loss 0.8816 (0.8816)	Acc@1 80.469 (80.469)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.144 (0.131)	Data 0.000 (0.004)	Loss 0.7967 (0.7507)	Acc@1 82.422 (84.369)	Acc@5 100.000 (99.303)
Epoch: [22][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.6982 (0.7494)	Acc@1 84.375 (84.423)	Acc@5 100.000 (99.291)
Epoch: [22][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7779 (0.7515)	Acc@1 81.641 (84.294)	Acc@5 98.828 (99.279)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.186 (0.186)	Data 0.289 (0.289)	Loss 0.7352 (0.7352)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7236 (0.7536)	Acc@1 86.719 (84.237)	Acc@5 99.609 (99.327)
Epoch: [23][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7486 (0.7435)	Acc@1 83.984 (84.475)	Acc@5 99.219 (99.337)
Epoch: [23][192/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.7513 (0.7445)	Acc@1 85.938 (84.505)	Acc@5 100.000 (99.302)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.182 (0.182)	Data 0.299 (0.299)	Loss 0.7385 (0.7385)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7874 (0.7208)	Acc@1 83.984 (85.697)	Acc@5 99.609 (99.489)
Epoch: [24][128/196]	Time 0.126 (0.132)	Data 0.000 (0.003)	Loss 0.6971 (0.7419)	Acc@1 86.719 (84.799)	Acc@5 99.609 (99.397)
Epoch: [24][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6869 (0.7409)	Acc@1 85.938 (84.711)	Acc@5 99.609 (99.407)
Max memory in training epoch: 66.5328128
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.158 (0.158)	Data 0.264 (0.264)	Loss 0.7353 (0.7353)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.134 (0.134)	Data 0.000 (0.004)	Loss 0.8187 (0.7416)	Acc@1 82.422 (84.501)	Acc@5 99.219 (99.411)
Epoch: [25][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7249 (0.7476)	Acc@1 84.375 (84.542)	Acc@5 99.609 (99.379)
Epoch: [25][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.7874 (0.7439)	Acc@1 80.469 (84.638)	Acc@5 98.438 (99.387)
Max memory in training epoch: 66.5328128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 470074 ; 481616 ; 0.9760348493405535
[INFO] Storing checkpoint...
  75.98
Max memory: 103.37664
 26.146s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8290
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1956352
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.184 (0.184)	Data 0.258 (0.258)	Loss 0.7067 (0.7067)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.8056 (0.7049)	Acc@1 83.594 (85.950)	Acc@5 98.828 (99.453)
Epoch: [26][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.6497 (0.7227)	Acc@1 87.891 (85.277)	Acc@5 99.219 (99.364)
Epoch: [26][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8698 (0.7234)	Acc@1 79.688 (85.294)	Acc@5 98.047 (99.377)
Max memory in training epoch: 66.6192384
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.191 (0.191)	Data 0.264 (0.264)	Loss 0.7484 (0.7484)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.138 (0.133)	Data 0.000 (0.004)	Loss 0.7163 (0.7238)	Acc@1 84.766 (85.397)	Acc@5 100.000 (99.369)
Epoch: [27][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6877 (0.7284)	Acc@1 87.500 (85.081)	Acc@5 99.609 (99.343)
Epoch: [27][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6731 (0.7270)	Acc@1 84.766 (85.124)	Acc@5 99.609 (99.358)
Max memory in training epoch: 66.2784512
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.150 (0.150)	Data 0.292 (0.292)	Loss 0.6941 (0.6941)	Acc@1 86.719 (86.719)	Acc@5 98.828 (98.828)
Epoch: [28][64/196]	Time 0.130 (0.133)	Data 0.000 (0.005)	Loss 0.7196 (0.7269)	Acc@1 85.156 (84.880)	Acc@5 100.000 (99.405)
Epoch: [28][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7068 (0.7246)	Acc@1 85.938 (85.168)	Acc@5 99.219 (99.355)
Epoch: [28][192/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.6832 (0.7329)	Acc@1 85.938 (84.865)	Acc@5 99.609 (99.320)
Max memory in training epoch: 66.2784512
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.182 (0.182)	Data 0.308 (0.308)	Loss 0.8347 (0.8347)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [29][64/196]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 0.7738 (0.7285)	Acc@1 84.375 (85.000)	Acc@5 100.000 (99.435)
Epoch: [29][128/196]	Time 0.132 (0.132)	Data 0.000 (0.003)	Loss 0.7408 (0.7243)	Acc@1 83.984 (85.232)	Acc@5 99.609 (99.419)
Epoch: [29][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7860 (0.7276)	Acc@1 82.031 (85.085)	Acc@5 99.219 (99.405)
Max memory in training epoch: 66.2784512
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.172 (0.172)	Data 0.329 (0.329)	Loss 0.7211 (0.7211)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.6569 (0.7116)	Acc@1 88.281 (85.817)	Acc@5 99.609 (99.363)
Epoch: [30][128/196]	Time 0.123 (0.131)	Data 0.000 (0.003)	Loss 0.7316 (0.7182)	Acc@1 85.547 (85.598)	Acc@5 100.000 (99.352)
Epoch: [30][192/196]	Time 0.149 (0.132)	Data 0.000 (0.002)	Loss 0.6954 (0.7242)	Acc@1 85.938 (85.264)	Acc@5 99.609 (99.352)
Max memory in training epoch: 66.2784512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 443524 ; 470074 ; 0.9435195309674647
[INFO] Storing checkpoint...
  81.92
Max memory: 103.0998528
 26.266s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1254
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1851904
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.192 (0.192)	Data 0.309 (0.309)	Loss 0.6387 (0.6387)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.146 (0.130)	Data 0.000 (0.005)	Loss 0.6446 (0.6801)	Acc@1 87.891 (86.713)	Acc@5 99.219 (99.501)
Epoch: [31][128/196]	Time 0.124 (0.130)	Data 0.000 (0.003)	Loss 0.7165 (0.7002)	Acc@1 87.109 (86.053)	Acc@5 99.219 (99.488)
Epoch: [31][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7968 (0.7103)	Acc@1 83.984 (85.717)	Acc@5 98.828 (99.458)
Max memory in training epoch: 65.7910272
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.191 (0.191)	Data 0.261 (0.261)	Loss 0.6445 (0.6445)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7719 (0.7212)	Acc@1 82.031 (85.240)	Acc@5 99.219 (99.351)
Epoch: [32][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7446 (0.7125)	Acc@1 84.766 (85.647)	Acc@5 98.828 (99.410)
Epoch: [32][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6972 (0.7148)	Acc@1 85.156 (85.630)	Acc@5 99.609 (99.389)
Max memory in training epoch: 65.77792
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.153 (0.153)	Data 0.296 (0.296)	Loss 0.7863 (0.7863)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.6188 (0.7147)	Acc@1 90.625 (85.517)	Acc@5 99.219 (99.411)
Epoch: [33][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6921 (0.7135)	Acc@1 85.547 (85.638)	Acc@5 98.438 (99.385)
Epoch: [33][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6767 (0.7138)	Acc@1 86.719 (85.602)	Acc@5 99.609 (99.393)
Max memory in training epoch: 65.77792
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.153 (0.153)	Data 0.262 (0.262)	Loss 0.7014 (0.7014)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.6084 (0.7099)	Acc@1 89.453 (85.829)	Acc@5 99.609 (99.417)
Epoch: [34][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7671 (0.7178)	Acc@1 84.375 (85.541)	Acc@5 99.609 (99.370)
Epoch: [34][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7548 (0.7174)	Acc@1 83.594 (85.525)	Acc@5 99.609 (99.387)
Max memory in training epoch: 65.77792
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.175 (0.175)	Data 0.300 (0.300)	Loss 0.6720 (0.6720)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [35][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.6960 (0.7233)	Acc@1 86.328 (85.373)	Acc@5 98.828 (99.411)
Epoch: [35][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6634 (0.7143)	Acc@1 87.500 (85.598)	Acc@5 98.828 (99.400)
Epoch: [35][192/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.7682 (0.7158)	Acc@1 83.984 (85.567)	Acc@5 98.438 (99.411)
Max memory in training epoch: 65.77792
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 424188 ; 443524 ; 0.9564037120877337
[INFO] Storing checkpoint...
  77.29
Max memory: 101.718272
 26.031s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3636
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1775104
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.190 (0.190)	Data 0.283 (0.283)	Loss 0.6341 (0.6341)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7488 (0.6774)	Acc@1 84.375 (86.983)	Acc@5 99.609 (99.453)
Epoch: [36][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7158 (0.6919)	Acc@1 86.719 (86.431)	Acc@5 99.219 (99.413)
Epoch: [36][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7179 (0.7007)	Acc@1 86.328 (86.103)	Acc@5 100.000 (99.399)
Max memory in training epoch: 65.0197504
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.188 (0.188)	Data 0.265 (0.265)	Loss 0.7120 (0.7120)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6193 (0.7049)	Acc@1 89.453 (86.124)	Acc@5 99.609 (99.465)
Epoch: [37][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.6666 (0.7142)	Acc@1 85.547 (85.771)	Acc@5 100.000 (99.446)
Epoch: [37][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6169 (0.7110)	Acc@1 89.062 (85.830)	Acc@5 99.609 (99.441)
Max memory in training epoch: 65.2425728
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.182 (0.182)	Data 0.273 (0.273)	Loss 0.6150 (0.6150)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [38][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6708 (0.6981)	Acc@1 85.156 (86.142)	Acc@5 99.609 (99.447)
Epoch: [38][128/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.7213 (0.7041)	Acc@1 85.156 (85.901)	Acc@5 99.609 (99.440)
Epoch: [38][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6812 (0.7067)	Acc@1 87.109 (85.850)	Acc@5 99.609 (99.439)
Max memory in training epoch: 65.2425728
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.184 (0.184)	Data 0.268 (0.268)	Loss 0.6906 (0.6906)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [39][64/196]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 0.6669 (0.6893)	Acc@1 86.328 (86.514)	Acc@5 100.000 (99.435)
Epoch: [39][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6592 (0.7033)	Acc@1 87.109 (85.977)	Acc@5 99.219 (99.428)
Epoch: [39][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6908 (0.7053)	Acc@1 86.719 (85.958)	Acc@5 98.438 (99.425)
Max memory in training epoch: 65.2425728
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.174 (0.174)	Data 0.300 (0.300)	Loss 0.6573 (0.6573)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [40][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.6500 (0.7008)	Acc@1 88.672 (85.889)	Acc@5 99.219 (99.465)
Epoch: [40][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.5869 (0.7014)	Acc@1 90.625 (85.995)	Acc@5 99.609 (99.425)
Epoch: [40][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7376 (0.7023)	Acc@1 84.375 (85.970)	Acc@5 99.609 (99.443)
Max memory in training epoch: 65.2425728
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 409316 ; 424188 ; 0.9649400737408885
[INFO] Storing checkpoint...
  79.08
Max memory: 100.889344
 25.655s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8693
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1716224
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.205 (0.205)	Data 0.261 (0.261)	Loss 0.7676 (0.7676)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [41][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7540 (0.6561)	Acc@1 83.203 (87.398)	Acc@5 99.609 (99.423)
Epoch: [41][128/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.7350 (0.6856)	Acc@1 84.375 (86.404)	Acc@5 100.000 (99.352)
Epoch: [41][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7173 (0.6902)	Acc@1 85.156 (86.225)	Acc@5 99.609 (99.342)
Max memory in training epoch: 64.085248
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.149 (0.149)	Data 0.258 (0.258)	Loss 0.6790 (0.6790)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [42][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.6053 (0.6961)	Acc@1 89.062 (85.986)	Acc@5 99.609 (99.387)
Epoch: [42][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6478 (0.6912)	Acc@1 87.891 (86.231)	Acc@5 99.609 (99.434)
Epoch: [42][192/196]	Time 0.130 (0.129)	Data 0.000 (0.001)	Loss 0.7857 (0.6958)	Acc@1 83.203 (86.160)	Acc@5 98.438 (99.417)
Max memory in training epoch: 63.8493184
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.173 (0.173)	Data 0.265 (0.265)	Loss 0.6061 (0.6061)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.7548 (0.6753)	Acc@1 85.938 (86.731)	Acc@5 99.609 (99.489)
Epoch: [43][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6040 (0.6898)	Acc@1 89.453 (86.156)	Acc@5 100.000 (99.512)
Epoch: [43][192/196]	Time 0.120 (0.129)	Data 0.000 (0.002)	Loss 0.7644 (0.6928)	Acc@1 85.547 (86.130)	Acc@5 98.438 (99.484)
Max memory in training epoch: 63.8493184
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.167 (0.167)	Data 0.302 (0.302)	Loss 0.7792 (0.7792)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [44][64/196]	Time 0.132 (0.129)	Data 0.000 (0.005)	Loss 0.7156 (0.7076)	Acc@1 84.375 (85.745)	Acc@5 99.609 (99.345)
Epoch: [44][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7233 (0.7046)	Acc@1 86.328 (85.947)	Acc@5 100.000 (99.376)
Epoch: [44][192/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.7434 (0.7056)	Acc@1 85.156 (85.877)	Acc@5 98.828 (99.391)
Max memory in training epoch: 63.8493184
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.150 (0.150)	Data 0.288 (0.288)	Loss 0.6864 (0.6864)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6430 (0.6776)	Acc@1 87.109 (86.743)	Acc@5 99.609 (99.447)
Epoch: [45][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6466 (0.6948)	Acc@1 87.500 (86.192)	Acc@5 99.219 (99.428)
Epoch: [45][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.6478 (0.6950)	Acc@1 85.938 (86.150)	Acc@5 100.000 (99.441)
Max memory in training epoch: 63.8493184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 402672 ; 409316 ; 0.9837680422949506
[INFO] Storing checkpoint...
  76.04
Max memory: 99.0301184
 25.641s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9177
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.16896
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.182 (0.182)	Data 0.282 (0.282)	Loss 0.6943 (0.6943)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6693 (0.6519)	Acc@1 87.891 (87.554)	Acc@5 100.000 (99.645)
Epoch: [46][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7362 (0.6720)	Acc@1 83.984 (86.825)	Acc@5 99.609 (99.546)
Epoch: [46][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.6735 (0.6827)	Acc@1 87.500 (86.512)	Acc@5 98.828 (99.478)
Max memory in training epoch: 63.4978816
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.185 (0.185)	Data 0.276 (0.276)	Loss 0.6523 (0.6523)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [47][64/196]	Time 0.124 (0.128)	Data 0.000 (0.004)	Loss 0.7527 (0.6976)	Acc@1 84.375 (85.962)	Acc@5 100.000 (99.507)
Epoch: [47][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7214 (0.6928)	Acc@1 85.156 (86.204)	Acc@5 99.609 (99.485)
Epoch: [47][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6299 (0.6921)	Acc@1 89.062 (86.233)	Acc@5 99.609 (99.464)
Max memory in training epoch: 63.3668096
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.192 (0.192)	Data 0.287 (0.287)	Loss 0.6134 (0.6134)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.6690 (0.6920)	Acc@1 87.500 (86.262)	Acc@5 99.609 (99.429)
Epoch: [48][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6792 (0.6919)	Acc@1 88.672 (86.156)	Acc@5 98.438 (99.434)
Epoch: [48][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6366 (0.6866)	Acc@1 87.109 (86.296)	Acc@5 99.219 (99.433)
Max memory in training epoch: 63.45856
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.181 (0.181)	Data 0.267 (0.267)	Loss 0.6560 (0.6560)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.6651 (0.6880)	Acc@1 85.547 (85.944)	Acc@5 99.609 (99.465)
Epoch: [49][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6759 (0.7020)	Acc@1 85.938 (85.680)	Acc@5 99.609 (99.425)
Epoch: [49][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6050 (0.6970)	Acc@1 89.844 (85.923)	Acc@5 99.609 (99.445)
Max memory in training epoch: 63.45856
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.179 (0.179)	Data 0.271 (0.271)	Loss 0.6476 (0.6476)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6589 (0.6976)	Acc@1 87.109 (85.883)	Acc@5 99.219 (99.387)
Epoch: [50][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.5994 (0.6971)	Acc@1 90.234 (86.056)	Acc@5 99.219 (99.391)
Epoch: [50][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6861 (0.6891)	Acc@1 87.891 (86.383)	Acc@5 99.219 (99.427)
Max memory in training epoch: 63.45856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 395162 ; 402672 ; 0.9813495847737116
[INFO] Storing checkpoint...
  82.73
Max memory: 98.0837376
 25.686s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1077
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1659904
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.192 (0.192)	Data 0.294 (0.294)	Loss 0.6925 (0.6925)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.6414 (0.6516)	Acc@1 87.500 (87.458)	Acc@5 100.000 (99.585)
Epoch: [51][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6260 (0.6544)	Acc@1 87.500 (87.400)	Acc@5 100.000 (99.549)
Epoch: [51][192/196]	Time 0.139 (0.127)	Data 0.000 (0.002)	Loss 0.7354 (0.6725)	Acc@1 84.375 (86.701)	Acc@5 98.828 (99.500)
Max memory in training epoch: 62.6733568
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.181 (0.181)	Data 0.262 (0.262)	Loss 0.5763 (0.5763)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.6744 (0.6671)	Acc@1 83.984 (87.037)	Acc@5 100.000 (99.525)
Epoch: [52][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6642 (0.6794)	Acc@1 86.328 (86.498)	Acc@5 99.609 (99.491)
Epoch: [52][192/196]	Time 0.140 (0.126)	Data 0.000 (0.002)	Loss 0.6793 (0.6816)	Acc@1 89.453 (86.417)	Acc@5 99.609 (99.462)
Max memory in training epoch: 62.5816064
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.157 (0.157)	Data 0.291 (0.291)	Loss 0.6259 (0.6259)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.6684 (0.6831)	Acc@1 86.719 (86.581)	Acc@5 99.609 (99.531)
Epoch: [53][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.7666 (0.6882)	Acc@1 82.812 (86.243)	Acc@5 98.438 (99.516)
Epoch: [53][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.5988 (0.6867)	Acc@1 90.625 (86.213)	Acc@5 100.000 (99.549)
Max memory in training epoch: 62.5816064
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.154 (0.154)	Data 0.300 (0.300)	Loss 0.6189 (0.6189)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.127 (0.126)	Data 0.000 (0.005)	Loss 0.6996 (0.6781)	Acc@1 85.156 (86.442)	Acc@5 98.828 (99.441)
Epoch: [54][128/196]	Time 0.132 (0.127)	Data 0.000 (0.002)	Loss 0.6555 (0.6896)	Acc@1 87.109 (86.231)	Acc@5 99.609 (99.376)
Epoch: [54][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7228 (0.6856)	Acc@1 86.328 (86.387)	Acc@5 100.000 (99.423)
Max memory in training epoch: 62.5816064
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.156 (0.156)	Data 0.277 (0.277)	Loss 0.7706 (0.7706)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7911 (0.6715)	Acc@1 80.859 (86.617)	Acc@5 98.828 (99.537)
Epoch: [55][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.6122 (0.6763)	Acc@1 89.062 (86.607)	Acc@5 99.219 (99.506)
Epoch: [55][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6982 (0.6796)	Acc@1 85.156 (86.504)	Acc@5 99.609 (99.496)
Max memory in training epoch: 62.5816064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 387224 ; 395162 ; 0.9799120360763434
[INFO] Storing checkpoint...
  80.42
Max memory: 96.9005056
 25.555s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8460
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1628672
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.201 (0.201)	Data 0.263 (0.263)	Loss 0.7480 (0.7480)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.7457 (0.6559)	Acc@1 83.984 (87.338)	Acc@5 99.219 (99.531)
Epoch: [56][128/196]	Time 0.121 (0.132)	Data 0.000 (0.002)	Loss 0.6848 (0.6680)	Acc@1 86.719 (86.837)	Acc@5 99.609 (99.491)
Epoch: [56][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6824 (0.6727)	Acc@1 84.766 (86.788)	Acc@5 99.609 (99.454)
Max memory in training epoch: 62.4904704
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.182 (0.182)	Data 0.296 (0.296)	Loss 0.6684 (0.6684)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [57][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.6487 (0.6792)	Acc@1 87.891 (86.508)	Acc@5 99.609 (99.459)
Epoch: [57][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.6255 (0.6751)	Acc@1 88.281 (86.704)	Acc@5 100.000 (99.494)
Epoch: [57][192/196]	Time 0.121 (0.131)	Data 0.000 (0.002)	Loss 0.6981 (0.6836)	Acc@1 85.938 (86.358)	Acc@5 99.609 (99.490)
Max memory in training epoch: 62.3528448
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.190 (0.190)	Data 0.272 (0.272)	Loss 0.6629 (0.6629)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.6857 (0.6857)	Acc@1 87.891 (86.316)	Acc@5 100.000 (99.543)
Epoch: [58][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6895 (0.6846)	Acc@1 85.156 (86.180)	Acc@5 98.828 (99.479)
Epoch: [58][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7540 (0.6835)	Acc@1 85.156 (86.253)	Acc@5 99.219 (99.472)
Max memory in training epoch: 62.3200768
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.150 (0.150)	Data 0.292 (0.292)	Loss 0.6720 (0.6720)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6313 (0.6761)	Acc@1 87.500 (86.671)	Acc@5 100.000 (99.555)
Epoch: [59][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6672 (0.6781)	Acc@1 86.328 (86.688)	Acc@5 99.609 (99.473)
Epoch: [59][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.5500 (0.6782)	Acc@1 92.188 (86.688)	Acc@5 100.000 (99.454)
Max memory in training epoch: 62.3200768
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.179 (0.179)	Data 0.321 (0.321)	Loss 0.6079 (0.6079)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.6379 (0.6659)	Acc@1 88.281 (86.995)	Acc@5 99.609 (99.465)
Epoch: [60][128/196]	Time 0.133 (0.131)	Data 0.000 (0.003)	Loss 0.6212 (0.6656)	Acc@1 91.016 (87.070)	Acc@5 99.219 (99.470)
Epoch: [60][192/196]	Time 0.176 (0.131)	Data 0.000 (0.002)	Loss 0.6871 (0.6733)	Acc@1 86.719 (86.883)	Acc@5 99.609 (99.480)
Max memory in training epoch: 62.3200768
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 382602 ; 387224 ; 0.9880637563787369
[INFO] Storing checkpoint...
  76.66
Max memory: 96.665856
 26.091s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2306
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1609216
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.168 (0.168)	Data 0.295 (0.295)	Loss 0.6675 (0.6675)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.130 (0.129)	Data 0.000 (0.005)	Loss 0.7577 (0.6586)	Acc@1 82.422 (87.194)	Acc@5 98.438 (99.411)
Epoch: [61][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6874 (0.6665)	Acc@1 84.766 (86.861)	Acc@5 99.609 (99.464)
Epoch: [61][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6456 (0.6682)	Acc@1 87.109 (86.745)	Acc@5 100.000 (99.484)
Max memory in training epoch: 61.8011136
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.150 (0.150)	Data 0.302 (0.302)	Loss 0.6506 (0.6506)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.137 (0.129)	Data 0.000 (0.005)	Loss 0.6856 (0.6916)	Acc@1 85.938 (86.226)	Acc@5 99.219 (99.441)
Epoch: [62][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.6913 (0.6800)	Acc@1 85.938 (86.549)	Acc@5 99.219 (99.494)
Epoch: [62][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6690 (0.6813)	Acc@1 85.547 (86.484)	Acc@5 99.609 (99.492)
Max memory in training epoch: 61.8011136
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.157 (0.157)	Data 0.267 (0.267)	Loss 0.6576 (0.6576)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.132 (0.128)	Data 0.000 (0.004)	Loss 0.5739 (0.6842)	Acc@1 92.188 (86.466)	Acc@5 99.219 (99.471)
Epoch: [63][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.6057 (0.6708)	Acc@1 87.500 (86.894)	Acc@5 100.000 (99.470)
Epoch: [63][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7337 (0.6761)	Acc@1 85.547 (86.589)	Acc@5 98.828 (99.452)
Max memory in training epoch: 61.8011136
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.176 (0.176)	Data 0.269 (0.269)	Loss 0.8080 (0.8080)	Acc@1 81.250 (81.250)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 0.7253 (0.6679)	Acc@1 85.156 (86.821)	Acc@5 99.219 (99.483)
Epoch: [64][128/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.7732 (0.6684)	Acc@1 83.984 (86.801)	Acc@5 100.000 (99.509)
Epoch: [64][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7612 (0.6737)	Acc@1 83.203 (86.636)	Acc@5 99.609 (99.508)
Max memory in training epoch: 61.8011136
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.155 (0.155)	Data 0.290 (0.290)	Loss 0.6174 (0.6174)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [65][64/196]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 0.6380 (0.6651)	Acc@1 88.281 (86.821)	Acc@5 99.609 (99.393)
Epoch: [65][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6770 (0.6722)	Acc@1 88.281 (86.779)	Acc@5 99.219 (99.410)
Epoch: [65][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7765 (0.6806)	Acc@1 84.375 (86.478)	Acc@5 98.047 (99.441)
Max memory in training epoch: 61.8011136
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 377406 ; 382602 ; 0.9864193077924318
[INFO] Storing checkpoint...
  76.42
Max memory: 95.7113856
 25.633s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4701
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.158976
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.200 (0.200)	Data 0.299 (0.299)	Loss 0.6166 (0.6166)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.6782 (0.6376)	Acc@1 85.938 (87.782)	Acc@5 99.609 (99.573)
Epoch: [66][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6729 (0.6518)	Acc@1 85.547 (87.215)	Acc@5 98.828 (99.567)
Epoch: [66][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7157 (0.6677)	Acc@1 85.156 (86.749)	Acc@5 99.219 (99.549)
Max memory in training epoch: 61.7217536
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.167 (0.167)	Data 0.302 (0.302)	Loss 0.6392 (0.6392)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.6231 (0.6630)	Acc@1 88.672 (87.151)	Acc@5 99.219 (99.501)
Epoch: [67][128/196]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.7477 (0.6742)	Acc@1 85.547 (86.837)	Acc@5 98.828 (99.497)
Epoch: [67][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.6043 (0.6722)	Acc@1 88.672 (86.838)	Acc@5 100.000 (99.472)
Max memory in training epoch: 61.714688
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.151 (0.151)	Data 0.292 (0.292)	Loss 0.6000 (0.6000)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6662 (0.6618)	Acc@1 86.328 (86.893)	Acc@5 98.438 (99.537)
Epoch: [68][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6067 (0.6691)	Acc@1 89.062 (86.749)	Acc@5 99.609 (99.509)
Epoch: [68][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6710 (0.6720)	Acc@1 87.109 (86.636)	Acc@5 98.828 (99.508)
Max memory in training epoch: 61.6688128
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.157 (0.157)	Data 0.300 (0.300)	Loss 0.6347 (0.6347)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [69][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.6397 (0.6624)	Acc@1 87.109 (87.404)	Acc@5 100.000 (99.495)
Epoch: [69][128/196]	Time 0.136 (0.130)	Data 0.000 (0.002)	Loss 0.7829 (0.6690)	Acc@1 82.812 (87.073)	Acc@5 99.609 (99.482)
Epoch: [69][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6698 (0.6715)	Acc@1 87.891 (86.885)	Acc@5 99.609 (99.445)
Max memory in training epoch: 61.6688128
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.193 (0.193)	Data 0.260 (0.260)	Loss 0.6361 (0.6361)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6819 (0.6649)	Acc@1 86.328 (86.701)	Acc@5 100.000 (99.501)
Epoch: [70][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7051 (0.6718)	Acc@1 87.109 (86.525)	Acc@5 99.609 (99.512)
Epoch: [70][192/196]	Time 0.137 (0.130)	Data 0.000 (0.002)	Loss 0.6470 (0.6702)	Acc@1 86.328 (86.715)	Acc@5 99.219 (99.496)
Max memory in training epoch: 61.6688128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 374370 ; 377406 ; 0.99195561278835
[INFO] Storing checkpoint...
  78.49
Max memory: 95.4632704
 25.818s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6099
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1579008
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.193 (0.193)	Data 0.293 (0.293)	Loss 0.6471 (0.6471)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.6856 (0.6336)	Acc@1 85.547 (88.023)	Acc@5 100.000 (99.531)
Epoch: [71][128/196]	Time 0.144 (0.128)	Data 0.000 (0.002)	Loss 0.7141 (0.6543)	Acc@1 85.547 (87.261)	Acc@5 99.609 (99.458)
Epoch: [71][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6758 (0.6649)	Acc@1 86.328 (86.893)	Acc@5 99.609 (99.431)
Max memory in training epoch: 61.0380288
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.190 (0.190)	Data 0.278 (0.278)	Loss 0.6685 (0.6685)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [72][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7463 (0.6617)	Acc@1 84.375 (87.091)	Acc@5 99.219 (99.573)
Epoch: [72][128/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.6081 (0.6681)	Acc@1 88.281 (86.649)	Acc@5 100.000 (99.516)
Epoch: [72][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6491 (0.6683)	Acc@1 90.234 (86.709)	Acc@5 98.828 (99.500)
Max memory in training epoch: 61.4744576
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.183 (0.183)	Data 0.312 (0.312)	Loss 0.6874 (0.6874)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.7077 (0.6618)	Acc@1 84.766 (87.007)	Acc@5 99.219 (99.429)
Epoch: [73][128/196]	Time 0.126 (0.131)	Data 0.000 (0.003)	Loss 0.5645 (0.6696)	Acc@1 90.625 (86.734)	Acc@5 99.609 (99.461)
Epoch: [73][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.5960 (0.6768)	Acc@1 89.453 (86.535)	Acc@5 99.219 (99.452)
Max memory in training epoch: 61.4744576
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.167 (0.167)	Data 0.291 (0.291)	Loss 0.6597 (0.6597)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.6460 (0.6684)	Acc@1 88.281 (86.605)	Acc@5 99.609 (99.537)
Epoch: [74][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7057 (0.6646)	Acc@1 84.766 (86.810)	Acc@5 99.609 (99.522)
Epoch: [74][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7039 (0.6701)	Acc@1 86.328 (86.696)	Acc@5 99.219 (99.498)
Max memory in training epoch: 61.4744576
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.180 (0.180)	Data 0.278 (0.278)	Loss 0.6272 (0.6272)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.5983 (0.6686)	Acc@1 90.234 (86.611)	Acc@5 99.219 (99.405)
Epoch: [75][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7090 (0.6668)	Acc@1 85.938 (86.819)	Acc@5 100.000 (99.458)
Epoch: [75][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7071 (0.6676)	Acc@1 85.156 (86.893)	Acc@5 98.438 (99.437)
Max memory in training epoch: 61.4744576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 367872 ; 374370 ; 0.9826428399711515
[INFO] Storing checkpoint...
  75.98
Max memory: 95.1510016
 25.483s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 434
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1553408
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.212 (0.212)	Data 0.256 (0.256)	Loss 0.6435 (0.6435)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [76][64/196]	Time 0.144 (0.130)	Data 0.000 (0.004)	Loss 0.6401 (0.6450)	Acc@1 84.766 (87.386)	Acc@5 100.000 (99.567)
Epoch: [76][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6867 (0.6525)	Acc@1 85.547 (87.261)	Acc@5 99.609 (99.534)
Epoch: [76][192/196]	Time 0.128 (0.129)	Data 0.000 (0.001)	Loss 0.5664 (0.6565)	Acc@1 90.234 (87.061)	Acc@5 99.609 (99.510)
Max memory in training epoch: 60.5610496
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.181 (0.181)	Data 0.269 (0.269)	Loss 0.6383 (0.6383)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.6242 (0.6723)	Acc@1 87.891 (86.821)	Acc@5 100.000 (99.465)
Epoch: [77][128/196]	Time 0.138 (0.129)	Data 0.000 (0.002)	Loss 0.6478 (0.6661)	Acc@1 88.672 (86.961)	Acc@5 100.000 (99.482)
Epoch: [77][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6006 (0.6699)	Acc@1 90.625 (86.836)	Acc@5 100.000 (99.482)
Max memory in training epoch: 60.7433216
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.164 (0.164)	Data 0.298 (0.298)	Loss 0.6284 (0.6284)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [78][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.6682 (0.6436)	Acc@1 87.500 (87.506)	Acc@5 99.609 (99.543)
Epoch: [78][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7100 (0.6466)	Acc@1 84.375 (87.406)	Acc@5 99.219 (99.482)
Epoch: [78][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6675 (0.6539)	Acc@1 86.719 (87.229)	Acc@5 98.828 (99.494)
Max memory in training epoch: 60.7433216
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.165 (0.165)	Data 0.307 (0.307)	Loss 0.5491 (0.5491)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.6439 (0.6612)	Acc@1 87.500 (87.133)	Acc@5 100.000 (99.555)
Epoch: [79][128/196]	Time 0.136 (0.131)	Data 0.000 (0.003)	Loss 0.6613 (0.6635)	Acc@1 86.719 (87.079)	Acc@5 99.609 (99.531)
Epoch: [79][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.6139 (0.6654)	Acc@1 89.062 (86.927)	Acc@5 100.000 (99.518)
Max memory in training epoch: 60.7433216
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.157 (0.157)	Data 0.301 (0.301)	Loss 0.5648 (0.5648)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.6532 (0.6621)	Acc@1 84.766 (86.719)	Acc@5 99.609 (99.507)
Epoch: [80][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.7105 (0.6637)	Acc@1 85.547 (86.670)	Acc@5 99.219 (99.482)
Epoch: [80][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6713 (0.6649)	Acc@1 89.062 (86.709)	Acc@5 98.828 (99.502)
Max memory in training epoch: 60.7433216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 365784 ; 367872 ; 0.9943241127348643
[INFO] Storing checkpoint...
  80.95
Max memory: 94.5616896
 25.589s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7299
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1540096
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.6352 (0.6352)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.6413 (0.6331)	Acc@1 87.109 (87.945)	Acc@5 99.609 (99.609)
Epoch: [81][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6292 (0.6511)	Acc@1 88.672 (87.246)	Acc@5 99.219 (99.516)
Epoch: [81][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6791 (0.6567)	Acc@1 86.328 (87.041)	Acc@5 99.609 (99.516)
Max memory in training epoch: 58.6417664
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.171 (0.171)	Data 0.268 (0.268)	Loss 0.5958 (0.5958)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.138 (0.122)	Data 0.000 (0.004)	Loss 0.7096 (0.6723)	Acc@1 83.594 (86.472)	Acc@5 99.219 (99.483)
Epoch: [82][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6291 (0.6614)	Acc@1 88.281 (86.955)	Acc@5 98.828 (99.519)
Epoch: [82][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.6437 (0.6654)	Acc@1 86.719 (86.871)	Acc@5 99.609 (99.474)
Max memory in training epoch: 58.7007488
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.165 (0.165)	Data 0.274 (0.274)	Loss 0.6522 (0.6522)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.5276 (0.6477)	Acc@1 91.797 (87.242)	Acc@5 99.609 (99.561)
Epoch: [83][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6750 (0.6542)	Acc@1 85.938 (87.112)	Acc@5 99.609 (99.482)
Epoch: [83][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6738 (0.6595)	Acc@1 85.938 (87.067)	Acc@5 98.828 (99.468)
Max memory in training epoch: 58.7597312
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.157 (0.157)	Data 0.292 (0.292)	Loss 0.5398 (0.5398)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.6195 (0.6602)	Acc@1 88.281 (86.923)	Acc@5 100.000 (99.519)
Epoch: [84][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.6605 (0.6616)	Acc@1 89.844 (86.937)	Acc@5 98.828 (99.512)
Epoch: [84][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6596 (0.6577)	Acc@1 86.328 (87.067)	Acc@5 99.219 (99.512)
Max memory in training epoch: 58.7597312
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.169 (0.169)	Data 0.285 (0.285)	Loss 0.6478 (0.6478)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [85][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.7331 (0.6652)	Acc@1 84.766 (87.133)	Acc@5 99.609 (99.423)
Epoch: [85][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.6957 (0.6654)	Acc@1 84.766 (87.003)	Acc@5 100.000 (99.431)
Epoch: [85][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.7880 (0.6685)	Acc@1 81.641 (86.794)	Acc@5 100.000 (99.413)
Max memory in training epoch: 58.7597312
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 365206 ; 365784 ; 0.9984198324694356
[INFO] Storing checkpoint...
  82.26
Max memory: 91.1881216
 24.534s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1015
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1538048
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.189 (0.189)	Data 0.299 (0.299)	Loss 0.7374 (0.7374)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6189 (0.6273)	Acc@1 86.719 (88.005)	Acc@5 99.609 (99.627)
Epoch: [86][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.5909 (0.6403)	Acc@1 88.672 (87.527)	Acc@5 100.000 (99.549)
Epoch: [86][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6976 (0.6497)	Acc@1 85.938 (87.241)	Acc@5 99.609 (99.541)
Max memory in training epoch: 58.5098752
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.158 (0.158)	Data 0.304 (0.304)	Loss 0.7378 (0.7378)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.114 (0.121)	Data 0.000 (0.005)	Loss 0.7349 (0.6449)	Acc@1 85.156 (87.326)	Acc@5 99.219 (99.633)
Epoch: [87][128/196]	Time 0.127 (0.121)	Data 0.000 (0.003)	Loss 0.6419 (0.6572)	Acc@1 87.109 (87.067)	Acc@5 100.000 (99.564)
Epoch: [87][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.6798 (0.6658)	Acc@1 87.109 (86.775)	Acc@5 100.000 (99.563)
Max memory in training epoch: 58.7458048
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.174 (0.174)	Data 0.261 (0.261)	Loss 0.6152 (0.6152)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [88][64/196]	Time 0.125 (0.124)	Data 0.000 (0.004)	Loss 0.6849 (0.6517)	Acc@1 85.938 (87.175)	Acc@5 100.000 (99.567)
Epoch: [88][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6542 (0.6601)	Acc@1 88.281 (86.922)	Acc@5 100.000 (99.512)
Epoch: [88][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.6617 (0.6625)	Acc@1 87.500 (86.877)	Acc@5 99.219 (99.510)
Max memory in training epoch: 58.8047872
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.179 (0.179)	Data 0.297 (0.297)	Loss 0.6950 (0.6950)	Acc@1 86.328 (86.328)	Acc@5 98.438 (98.438)
Epoch: [89][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.6618 (0.6613)	Acc@1 87.500 (86.773)	Acc@5 99.609 (99.543)
Epoch: [89][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6835 (0.6613)	Acc@1 87.500 (86.867)	Acc@5 98.438 (99.546)
Epoch: [89][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.6532 (0.6644)	Acc@1 86.328 (86.840)	Acc@5 98.438 (99.520)
Max memory in training epoch: 58.8047872
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.152 (0.152)	Data 0.299 (0.299)	Loss 0.7058 (0.7058)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [90][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.7933 (0.6697)	Acc@1 83.984 (86.424)	Acc@5 99.609 (99.519)
Epoch: [90][128/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.6059 (0.6636)	Acc@1 87.109 (86.849)	Acc@5 100.000 (99.497)
Epoch: [90][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.5733 (0.6600)	Acc@1 89.453 (86.954)	Acc@5 99.609 (99.484)
Max memory in training epoch: 58.8047872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 363758 ; 365206 ; 0.9960351144285691
[INFO] Storing checkpoint...
  78.39
Max memory: 90.99008
 24.411s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5145
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1531904
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.174 (0.174)	Data 0.267 (0.267)	Loss 0.6432 (0.6432)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.6717 (0.6366)	Acc@1 85.547 (87.506)	Acc@5 100.000 (99.597)
Epoch: [91][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.6812 (0.6462)	Acc@1 86.719 (87.306)	Acc@5 99.609 (99.506)
Epoch: [91][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6550 (0.6538)	Acc@1 87.109 (87.043)	Acc@5 99.609 (99.512)
Max memory in training epoch: 57.517824
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.139 (0.139)	Data 0.294 (0.294)	Loss 0.6379 (0.6379)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.5711 (0.6498)	Acc@1 88.672 (87.194)	Acc@5 99.219 (99.555)
Epoch: [92][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.7334 (0.6529)	Acc@1 86.328 (87.161)	Acc@5 98.438 (99.509)
Epoch: [92][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.7081 (0.6572)	Acc@1 85.156 (87.022)	Acc@5 99.609 (99.488)
Max memory in training epoch: 57.7996288
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.141 (0.141)	Data 0.274 (0.274)	Loss 0.6139 (0.6139)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [93][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.5820 (0.5650)	Acc@1 90.625 (90.379)	Acc@5 99.219 (99.675)
Epoch: [93][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.4865 (0.5379)	Acc@1 92.188 (91.128)	Acc@5 100.000 (99.743)
Epoch: [93][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.5038 (0.5244)	Acc@1 92.969 (91.639)	Acc@5 99.219 (99.773)
Max memory in training epoch: 57.7996288
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.165 (0.165)	Data 0.266 (0.266)	Loss 0.4452 (0.4452)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.129 (0.122)	Data 0.000 (0.004)	Loss 0.4697 (0.4705)	Acc@1 94.531 (93.462)	Acc@5 100.000 (99.886)
Epoch: [94][128/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.4834 (0.4721)	Acc@1 93.359 (93.323)	Acc@5 99.609 (99.870)
Epoch: [94][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.4485 (0.4700)	Acc@1 92.969 (93.303)	Acc@5 100.000 (99.850)
Max memory in training epoch: 57.7996288
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.163 (0.163)	Data 0.289 (0.289)	Loss 0.3960 (0.3960)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.4084 (0.4421)	Acc@1 95.312 (94.075)	Acc@5 100.000 (99.910)
Epoch: [95][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.4185 (0.4445)	Acc@1 94.531 (94.001)	Acc@5 100.000 (99.891)
Epoch: [95][192/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.4895 (0.4444)	Acc@1 92.969 (93.999)	Acc@5 100.000 (99.887)
Max memory in training epoch: 57.7996288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 361158 ; 363758 ; 0.9928523908752522
[INFO] Storing checkpoint...
  91.19
Max memory: 90.0617216
 24.160s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 901
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.161 (0.161)	Data 0.291 (0.291)	Loss 0.4281 (0.4281)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.124 (0.121)	Data 0.000 (0.005)	Loss 0.4217 (0.4250)	Acc@1 94.531 (94.423)	Acc@5 100.000 (99.904)
Epoch: [96][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.4437 (0.4280)	Acc@1 92.969 (94.368)	Acc@5 100.000 (99.909)
Epoch: [96][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3830 (0.4260)	Acc@1 95.703 (94.402)	Acc@5 100.000 (99.905)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.146 (0.146)	Data 0.266 (0.266)	Loss 0.3838 (0.3838)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.126 (0.122)	Data 0.000 (0.004)	Loss 0.4433 (0.4147)	Acc@1 91.797 (94.651)	Acc@5 100.000 (99.892)
Epoch: [97][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.4709 (0.4141)	Acc@1 94.141 (94.655)	Acc@5 99.219 (99.897)
Epoch: [97][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3711 (0.4150)	Acc@1 96.484 (94.604)	Acc@5 100.000 (99.911)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.172 (0.172)	Data 0.290 (0.290)	Loss 0.3842 (0.3842)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.3529 (0.3951)	Acc@1 97.266 (95.252)	Acc@5 100.000 (99.946)
Epoch: [98][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.4791 (0.3991)	Acc@1 92.969 (95.013)	Acc@5 100.000 (99.912)
Epoch: [98][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3577 (0.4015)	Acc@1 96.484 (94.944)	Acc@5 100.000 (99.901)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.167 (0.167)	Data 0.260 (0.260)	Loss 0.3986 (0.3986)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.116 (0.121)	Data 0.000 (0.004)	Loss 0.4676 (0.3915)	Acc@1 91.797 (95.126)	Acc@5 99.609 (99.940)
Epoch: [99][128/196]	Time 0.131 (0.121)	Data 0.000 (0.002)	Loss 0.4105 (0.3915)	Acc@1 94.922 (95.091)	Acc@5 100.000 (99.915)
Epoch: [99][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.3523 (0.3919)	Acc@1 95.312 (95.057)	Acc@5 100.000 (99.905)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.193 (0.193)	Data 0.302 (0.302)	Loss 0.4266 (0.4266)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [100][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.3617 (0.3811)	Acc@1 94.922 (95.349)	Acc@5 100.000 (99.892)
Epoch: [100][128/196]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.3746 (0.3775)	Acc@1 95.703 (95.518)	Acc@5 100.000 (99.903)
Epoch: [100][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3790 (0.3798)	Acc@1 95.703 (95.345)	Acc@5 99.609 (99.905)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.34
Max memory: 89.6520192
 24.140s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3842
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.192 (0.192)	Data 0.283 (0.283)	Loss 0.3840 (0.3840)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.3441 (0.3591)	Acc@1 96.875 (95.992)	Acc@5 100.000 (99.916)
Epoch: [101][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3862 (0.3685)	Acc@1 93.359 (95.579)	Acc@5 100.000 (99.936)
Epoch: [101][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3237 (0.3695)	Acc@1 96.484 (95.531)	Acc@5 100.000 (99.921)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.151 (0.151)	Data 0.259 (0.259)	Loss 0.3563 (0.3563)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.3685 (0.3631)	Acc@1 94.922 (95.571)	Acc@5 100.000 (99.916)
Epoch: [102][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3724 (0.3591)	Acc@1 95.312 (95.755)	Acc@5 100.000 (99.936)
Epoch: [102][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3267 (0.3621)	Acc@1 97.266 (95.602)	Acc@5 100.000 (99.933)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.168 (0.168)	Data 0.298 (0.298)	Loss 0.3346 (0.3346)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.3636 (0.3547)	Acc@1 96.484 (95.871)	Acc@5 100.000 (99.928)
Epoch: [103][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3406 (0.3488)	Acc@1 95.703 (96.054)	Acc@5 100.000 (99.942)
Epoch: [103][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.3935 (0.3496)	Acc@1 96.094 (95.980)	Acc@5 100.000 (99.937)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.172 (0.172)	Data 0.273 (0.273)	Loss 0.3268 (0.3268)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.126 (0.121)	Data 0.000 (0.004)	Loss 0.3041 (0.3432)	Acc@1 97.266 (96.160)	Acc@5 100.000 (99.970)
Epoch: [104][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3102 (0.3428)	Acc@1 96.875 (96.166)	Acc@5 100.000 (99.955)
Epoch: [104][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3455 (0.3439)	Acc@1 96.094 (96.051)	Acc@5 100.000 (99.960)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.173 (0.173)	Data 0.263 (0.263)	Loss 0.3252 (0.3252)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3317 (0.3348)	Acc@1 95.703 (96.244)	Acc@5 100.000 (99.970)
Epoch: [105][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3193 (0.3337)	Acc@1 96.484 (96.242)	Acc@5 100.000 (99.964)
Epoch: [105][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.4124 (0.3354)	Acc@1 94.922 (96.136)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.28
Max memory: 89.6520192
 23.860s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9128
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.198 (0.198)	Data 0.287 (0.287)	Loss 0.3373 (0.3373)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.3298 (0.3273)	Acc@1 96.875 (96.502)	Acc@5 99.609 (99.946)
Epoch: [106][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3082 (0.3303)	Acc@1 96.484 (96.294)	Acc@5 100.000 (99.936)
Epoch: [106][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3560 (0.3323)	Acc@1 94.141 (96.161)	Acc@5 100.000 (99.951)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.165 (0.165)	Data 0.301 (0.301)	Loss 0.3351 (0.3351)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [107][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.3032 (0.3253)	Acc@1 97.266 (96.364)	Acc@5 100.000 (99.958)
Epoch: [107][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.3272 (0.3304)	Acc@1 96.484 (96.136)	Acc@5 100.000 (99.961)
Epoch: [107][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3148 (0.3306)	Acc@1 96.094 (96.063)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.171 (0.171)	Data 0.266 (0.266)	Loss 0.3010 (0.3010)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.129 (0.123)	Data 0.000 (0.004)	Loss 0.3258 (0.3256)	Acc@1 94.922 (96.178)	Acc@5 100.000 (99.940)
Epoch: [108][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.3420 (0.3254)	Acc@1 94.531 (96.221)	Acc@5 100.000 (99.958)
Epoch: [108][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3029 (0.3263)	Acc@1 97.656 (96.169)	Acc@5 100.000 (99.957)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.159 (0.159)	Data 0.297 (0.297)	Loss 0.3176 (0.3176)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.3160 (0.3178)	Acc@1 96.484 (96.406)	Acc@5 100.000 (99.952)
Epoch: [109][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3201 (0.3190)	Acc@1 96.094 (96.342)	Acc@5 100.000 (99.952)
Epoch: [109][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3355 (0.3215)	Acc@1 95.312 (96.235)	Acc@5 100.000 (99.947)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.173 (0.173)	Data 0.298 (0.298)	Loss 0.2937 (0.2937)	Acc@1 97.656 (97.656)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.3069 (0.3142)	Acc@1 96.484 (96.376)	Acc@5 100.000 (99.970)
Epoch: [110][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3092 (0.3148)	Acc@1 96.094 (96.442)	Acc@5 100.000 (99.967)
Epoch: [110][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3189 (0.3154)	Acc@1 95.703 (96.349)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.66
Max memory: 89.6520192
 24.144s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 126
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.159 (0.159)	Data 0.301 (0.301)	Loss 0.3245 (0.3245)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.138 (0.122)	Data 0.000 (0.005)	Loss 0.2686 (0.2934)	Acc@1 98.828 (97.175)	Acc@5 100.000 (99.982)
Epoch: [111][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3314 (0.3018)	Acc@1 96.484 (96.784)	Acc@5 100.000 (99.979)
Epoch: [111][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3187 (0.3094)	Acc@1 94.922 (96.428)	Acc@5 100.000 (99.980)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.144 (0.144)	Data 0.271 (0.271)	Loss 0.3282 (0.3282)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.2940 (0.3114)	Acc@1 97.656 (96.262)	Acc@5 100.000 (99.964)
Epoch: [112][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3327 (0.3126)	Acc@1 96.094 (96.197)	Acc@5 100.000 (99.973)
Epoch: [112][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3617 (0.3117)	Acc@1 94.141 (96.213)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.153 (0.153)	Data 0.264 (0.264)	Loss 0.3403 (0.3403)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [113][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.2806 (0.3099)	Acc@1 96.875 (96.280)	Acc@5 99.609 (99.952)
Epoch: [113][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3021 (0.3067)	Acc@1 96.094 (96.424)	Acc@5 100.000 (99.961)
Epoch: [113][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.3135 (0.3083)	Acc@1 95.312 (96.314)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.179 (0.179)	Data 0.263 (0.263)	Loss 0.3321 (0.3321)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.2736 (0.2955)	Acc@1 98.828 (96.731)	Acc@5 100.000 (99.970)
Epoch: [114][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2807 (0.2999)	Acc@1 97.266 (96.512)	Acc@5 100.000 (99.964)
Epoch: [114][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3361 (0.3027)	Acc@1 94.531 (96.339)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.167 (0.167)	Data 0.289 (0.289)	Loss 0.2922 (0.2922)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.2748 (0.2968)	Acc@1 96.484 (96.538)	Acc@5 100.000 (99.976)
Epoch: [115][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3285 (0.2983)	Acc@1 95.703 (96.512)	Acc@5 100.000 (99.976)
Epoch: [115][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2806 (0.3024)	Acc@1 96.875 (96.339)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.45
Max memory: 89.6520192
 24.248s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6988
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.181 (0.181)	Data 0.286 (0.286)	Loss 0.2797 (0.2797)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.2967 (0.2869)	Acc@1 96.094 (96.863)	Acc@5 100.000 (99.988)
Epoch: [116][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3082 (0.2907)	Acc@1 96.484 (96.699)	Acc@5 100.000 (99.985)
Epoch: [116][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2901 (0.2970)	Acc@1 95.703 (96.412)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.147 (0.147)	Data 0.268 (0.268)	Loss 0.2620 (0.2620)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.126 (0.121)	Data 0.000 (0.004)	Loss 0.2804 (0.2931)	Acc@1 97.656 (96.508)	Acc@5 100.000 (99.982)
Epoch: [117][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2950 (0.2941)	Acc@1 95.703 (96.478)	Acc@5 100.000 (99.982)
Epoch: [117][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3294 (0.3008)	Acc@1 94.531 (96.215)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.146 (0.146)	Data 0.296 (0.296)	Loss 0.2840 (0.2840)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.2924 (0.2955)	Acc@1 96.094 (96.364)	Acc@5 100.000 (99.970)
Epoch: [118][128/196]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.4091 (0.2965)	Acc@1 91.016 (96.257)	Acc@5 100.000 (99.967)
Epoch: [118][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.3154 (0.2986)	Acc@1 95.312 (96.175)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.176 (0.176)	Data 0.291 (0.291)	Loss 0.2865 (0.2865)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.2492 (0.2909)	Acc@1 97.266 (96.532)	Acc@5 100.000 (99.958)
Epoch: [119][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3114 (0.2932)	Acc@1 95.312 (96.384)	Acc@5 100.000 (99.970)
Epoch: [119][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2427 (0.2966)	Acc@1 98.828 (96.248)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.167 (0.167)	Data 0.301 (0.301)	Loss 0.3199 (0.3199)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2833 (0.2886)	Acc@1 97.266 (96.496)	Acc@5 100.000 (99.982)
Epoch: [120][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.2944 (0.2942)	Acc@1 96.484 (96.236)	Acc@5 100.000 (99.979)
Epoch: [120][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2550 (0.2973)	Acc@1 97.656 (96.163)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.59
Max memory: 89.6520192
 24.029s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3238
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.185 (0.185)	Data 0.289 (0.289)	Loss 0.2696 (0.2696)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.2887 (0.2808)	Acc@1 95.703 (96.809)	Acc@5 100.000 (99.976)
Epoch: [121][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2964 (0.2890)	Acc@1 96.094 (96.475)	Acc@5 100.000 (99.976)
Epoch: [121][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2907 (0.2912)	Acc@1 96.094 (96.365)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.168 (0.168)	Data 0.296 (0.296)	Loss 0.2716 (0.2716)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.2492 (0.2976)	Acc@1 98.828 (96.106)	Acc@5 100.000 (99.958)
Epoch: [122][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.3030 (0.2938)	Acc@1 95.703 (96.278)	Acc@5 100.000 (99.964)
Epoch: [122][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.2868 (0.2962)	Acc@1 95.703 (96.124)	Acc@5 100.000 (99.957)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.162 (0.162)	Data 0.329 (0.329)	Loss 0.2699 (0.2699)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.2861 (0.2816)	Acc@1 96.875 (96.671)	Acc@5 100.000 (99.964)
Epoch: [123][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.2818 (0.2869)	Acc@1 96.484 (96.439)	Acc@5 100.000 (99.964)
Epoch: [123][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2748 (0.2918)	Acc@1 96.875 (96.233)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.179 (0.179)	Data 0.298 (0.298)	Loss 0.2805 (0.2805)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.2843 (0.2831)	Acc@1 96.484 (96.466)	Acc@5 100.000 (99.982)
Epoch: [124][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3081 (0.2860)	Acc@1 94.922 (96.375)	Acc@5 100.000 (99.964)
Epoch: [124][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2420 (0.2876)	Acc@1 97.656 (96.290)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.170 (0.170)	Data 0.269 (0.269)	Loss 0.2914 (0.2914)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [125][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.2902 (0.2896)	Acc@1 96.094 (96.166)	Acc@5 100.000 (99.970)
Epoch: [125][128/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.2687 (0.2924)	Acc@1 96.484 (96.100)	Acc@5 99.609 (99.964)
Epoch: [125][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.3192 (0.2953)	Acc@1 95.312 (95.966)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.71
Max memory: 89.6520192
 24.198s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9644
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.186 (0.186)	Data 0.297 (0.297)	Loss 0.2603 (0.2603)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2830 (0.2758)	Acc@1 96.875 (96.827)	Acc@5 100.000 (99.952)
Epoch: [126][128/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.2711 (0.2842)	Acc@1 96.875 (96.484)	Acc@5 100.000 (99.961)
Epoch: [126][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.3269 (0.2896)	Acc@1 95.312 (96.254)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.162 (0.162)	Data 0.301 (0.301)	Loss 0.2821 (0.2821)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.2691 (0.2841)	Acc@1 97.266 (96.400)	Acc@5 100.000 (99.970)
Epoch: [127][128/196]	Time 0.131 (0.122)	Data 0.000 (0.003)	Loss 0.3597 (0.2896)	Acc@1 93.359 (96.169)	Acc@5 100.000 (99.964)
Epoch: [127][192/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.3060 (0.2936)	Acc@1 94.141 (95.964)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.145 (0.145)	Data 0.317 (0.317)	Loss 0.3080 (0.3080)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.3306 (0.2922)	Acc@1 94.141 (96.004)	Acc@5 99.609 (99.982)
Epoch: [128][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.3130 (0.2924)	Acc@1 95.312 (96.073)	Acc@5 100.000 (99.982)
Epoch: [128][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2980 (0.2934)	Acc@1 94.922 (96.013)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.182 (0.182)	Data 0.270 (0.270)	Loss 0.2634 (0.2634)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.2844 (0.2864)	Acc@1 96.484 (96.238)	Acc@5 99.609 (99.964)
Epoch: [129][128/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.3044 (0.2885)	Acc@1 95.312 (96.176)	Acc@5 100.000 (99.973)
Epoch: [129][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.3665 (0.2920)	Acc@1 94.141 (96.045)	Acc@5 99.609 (99.968)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.179 (0.179)	Data 0.271 (0.271)	Loss 0.2536 (0.2536)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.2806 (0.2845)	Acc@1 97.656 (96.364)	Acc@5 100.000 (99.988)
Epoch: [130][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2832 (0.2882)	Acc@1 96.484 (96.221)	Acc@5 100.000 (99.988)
Epoch: [130][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.3063 (0.2891)	Acc@1 94.922 (96.138)	Acc@5 99.609 (99.976)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.01
Max memory: 89.6520192
 24.244s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1212
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.152064
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.205 (0.205)	Data 0.256 (0.256)	Loss 0.2925 (0.2925)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3011 (0.2716)	Acc@1 95.312 (96.496)	Acc@5 100.000 (99.982)
Epoch: [131][128/196]	Time 0.126 (0.121)	Data 0.000 (0.002)	Loss 0.2728 (0.2813)	Acc@1 96.484 (96.239)	Acc@5 100.000 (99.970)
Epoch: [131][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3116 (0.2890)	Acc@1 95.312 (96.069)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.323264
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.163 (0.163)	Data 0.299 (0.299)	Loss 0.2552 (0.2552)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.2855 (0.2832)	Acc@1 96.484 (96.202)	Acc@5 100.000 (99.970)
Epoch: [132][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2493 (0.2843)	Acc@1 98.047 (96.227)	Acc@5 100.000 (99.961)
Epoch: [132][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3220 (0.2900)	Acc@1 95.312 (96.031)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.167 (0.167)	Data 0.266 (0.266)	Loss 0.2526 (0.2526)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.2757 (0.2929)	Acc@1 97.266 (95.919)	Acc@5 100.000 (99.976)
Epoch: [133][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3316 (0.2925)	Acc@1 94.141 (95.942)	Acc@5 100.000 (99.982)
Epoch: [133][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3365 (0.2943)	Acc@1 94.141 (95.881)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.160 (0.160)	Data 0.303 (0.303)	Loss 0.2674 (0.2674)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.3016 (0.2869)	Acc@1 96.094 (96.130)	Acc@5 100.000 (99.976)
Epoch: [134][128/196]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.2936 (0.2883)	Acc@1 97.266 (96.145)	Acc@5 100.000 (99.976)
Epoch: [134][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2795 (0.2906)	Acc@1 96.484 (96.029)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7361408
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.172 (0.172)	Data 0.304 (0.304)	Loss 0.3971 (0.3971)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.127 (0.123)	Data 0.000 (0.005)	Loss 0.3248 (0.2913)	Acc@1 95.703 (95.944)	Acc@5 100.000 (99.946)
Epoch: [135][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.3018 (0.2894)	Acc@1 96.484 (95.945)	Acc@5 100.000 (99.955)
Epoch: [135][192/196]	Time 0.128 (0.121)	Data 0.000 (0.002)	Loss 0.2785 (0.2910)	Acc@1 96.875 (95.942)	Acc@5 100.000 (99.949)
Max memory in training epoch: 57.7361408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 360868 ; 361158 ; 0.9991970273398346
[INFO] Storing checkpoint...
  89.34
Max memory: 89.6520192
 24.106s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8528
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1518592
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.160 (0.160)	Data 0.294 (0.294)	Loss 0.2595 (0.2595)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.114 (0.120)	Data 0.000 (0.005)	Loss 0.2978 (0.2758)	Acc@1 96.094 (96.418)	Acc@5 100.000 (99.976)
Epoch: [136][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.3140 (0.2842)	Acc@1 95.312 (96.112)	Acc@5 100.000 (99.979)
Epoch: [136][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2719 (0.2900)	Acc@1 97.266 (95.936)	Acc@5 100.000 (99.978)
Max memory in training epoch: 57.3224448
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.168 (0.168)	Data 0.330 (0.330)	Loss 0.2543 (0.2543)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.3164 (0.2900)	Acc@1 94.141 (95.998)	Acc@5 100.000 (100.000)
Epoch: [137][128/196]	Time 0.122 (0.120)	Data 0.000 (0.003)	Loss 0.2622 (0.2922)	Acc@1 97.266 (95.900)	Acc@5 100.000 (99.988)
Epoch: [137][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2520 (0.2952)	Acc@1 97.656 (95.833)	Acc@5 100.000 (99.984)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.180 (0.180)	Data 0.267 (0.267)	Loss 0.2870 (0.2870)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.116 (0.121)	Data 0.000 (0.004)	Loss 0.2722 (0.2862)	Acc@1 97.266 (96.142)	Acc@5 100.000 (99.964)
Epoch: [138][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3178 (0.2878)	Acc@1 94.531 (96.091)	Acc@5 100.000 (99.961)
Epoch: [138][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3118 (0.2885)	Acc@1 93.750 (96.007)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.148 (0.148)	Data 0.275 (0.275)	Loss 0.2635 (0.2635)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.125 (0.120)	Data 0.000 (0.004)	Loss 0.3105 (0.2874)	Acc@1 95.703 (95.962)	Acc@5 100.000 (99.976)
Epoch: [139][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2693 (0.2884)	Acc@1 97.266 (95.994)	Acc@5 100.000 (99.970)
Epoch: [139][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2720 (0.2890)	Acc@1 97.266 (96.019)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.157 (0.157)	Data 0.305 (0.305)	Loss 0.2697 (0.2697)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.112 (0.120)	Data 0.000 (0.005)	Loss 0.2958 (0.2805)	Acc@1 96.484 (96.346)	Acc@5 100.000 (99.994)
Epoch: [140][128/196]	Time 0.116 (0.120)	Data 0.000 (0.003)	Loss 0.2921 (0.2870)	Acc@1 95.312 (96.079)	Acc@5 100.000 (99.976)
Epoch: [140][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3482 (0.2907)	Acc@1 92.969 (95.968)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.64
Max memory: 89.2934144
 23.806s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4333
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1518592
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.193 (0.193)	Data 0.269 (0.269)	Loss 0.2638 (0.2638)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.125 (0.125)	Data 0.000 (0.004)	Loss 0.2676 (0.2712)	Acc@1 96.094 (96.611)	Acc@5 100.000 (99.970)
Epoch: [141][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2958 (0.2778)	Acc@1 94.922 (96.387)	Acc@5 100.000 (99.976)
Epoch: [141][192/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.2954 (0.2830)	Acc@1 94.531 (96.165)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.3224448
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.171 (0.171)	Data 0.274 (0.274)	Loss 0.2731 (0.2731)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.124 (0.122)	Data 0.000 (0.004)	Loss 0.3185 (0.2975)	Acc@1 94.922 (95.805)	Acc@5 100.000 (99.994)
Epoch: [142][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2526 (0.2945)	Acc@1 97.656 (95.855)	Acc@5 100.000 (99.976)
Epoch: [142][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2961 (0.2952)	Acc@1 96.484 (95.835)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.151 (0.151)	Data 0.290 (0.290)	Loss 0.3199 (0.3199)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.2432 (0.2805)	Acc@1 98.438 (96.298)	Acc@5 100.000 (99.988)
Epoch: [143][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2799 (0.2827)	Acc@1 96.875 (96.206)	Acc@5 100.000 (99.985)
Epoch: [143][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.2972 (0.2880)	Acc@1 96.484 (95.993)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.171 (0.171)	Data 0.295 (0.295)	Loss 0.2843 (0.2843)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.127 (0.122)	Data 0.000 (0.005)	Loss 0.2847 (0.2991)	Acc@1 95.703 (95.637)	Acc@5 100.000 (99.958)
Epoch: [144][128/196]	Time 0.130 (0.122)	Data 0.000 (0.002)	Loss 0.3093 (0.2956)	Acc@1 96.094 (95.764)	Acc@5 100.000 (99.955)
Epoch: [144][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3222 (0.2964)	Acc@1 94.531 (95.707)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.162 (0.162)	Data 0.282 (0.282)	Loss 0.2897 (0.2897)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.141 (0.124)	Data 0.000 (0.005)	Loss 0.2748 (0.2871)	Acc@1 95.703 (96.016)	Acc@5 100.000 (99.982)
Epoch: [145][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.3477 (0.2886)	Acc@1 93.750 (96.018)	Acc@5 100.000 (99.973)
Epoch: [145][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2855 (0.2910)	Acc@1 95.703 (95.954)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.14
Max memory: 89.2934144
 24.243s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 369
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1518592
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.202 (0.202)	Data 0.260 (0.260)	Loss 0.2703 (0.2703)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.2820 (0.2685)	Acc@1 97.656 (96.749)	Acc@5 100.000 (99.994)
Epoch: [146][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.2689 (0.2735)	Acc@1 96.484 (96.506)	Acc@5 100.000 (99.994)
Epoch: [146][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3219 (0.2827)	Acc@1 95.703 (96.179)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.3224448
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.160 (0.160)	Data 0.268 (0.268)	Loss 0.3038 (0.3038)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.2654 (0.2882)	Acc@1 97.266 (96.064)	Acc@5 100.000 (99.982)
Epoch: [147][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3026 (0.2880)	Acc@1 94.922 (95.942)	Acc@5 100.000 (99.976)
Epoch: [147][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2647 (0.2903)	Acc@1 95.703 (95.802)	Acc@5 100.000 (99.980)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.153 (0.153)	Data 0.291 (0.291)	Loss 0.2668 (0.2668)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.3060 (0.2899)	Acc@1 95.703 (95.823)	Acc@5 100.000 (99.988)
Epoch: [148][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2936 (0.2871)	Acc@1 96.094 (95.933)	Acc@5 100.000 (99.976)
Epoch: [148][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3222 (0.2905)	Acc@1 94.141 (95.833)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.143 (0.143)	Data 0.283 (0.283)	Loss 0.2578 (0.2578)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.2363 (0.2726)	Acc@1 97.266 (96.460)	Acc@5 100.000 (99.988)
Epoch: [149][128/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.2734 (0.2821)	Acc@1 96.875 (96.206)	Acc@5 100.000 (99.985)
Epoch: [149][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3125 (0.2856)	Acc@1 95.312 (96.116)	Acc@5 100.000 (99.986)
Max memory in training epoch: 57.7549824
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.163 (0.163)	Data 0.270 (0.270)	Loss 0.3052 (0.3052)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.2399 (0.2599)	Acc@1 97.656 (97.055)	Acc@5 100.000 (99.988)
Epoch: [150][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2111 (0.2486)	Acc@1 98.828 (97.453)	Acc@5 100.000 (99.991)
Epoch: [150][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2178 (0.2441)	Acc@1 98.828 (97.640)	Acc@5 100.000 (99.988)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.31
Max memory: 89.2934144
 24.020s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4984
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1518592
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.189 (0.189)	Data 0.273 (0.273)	Loss 0.2151 (0.2151)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2149 (0.2279)	Acc@1 98.828 (98.311)	Acc@5 100.000 (99.994)
Epoch: [151][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2063 (0.2251)	Acc@1 99.609 (98.377)	Acc@5 100.000 (99.994)
Epoch: [151][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2113 (0.2234)	Acc@1 98.438 (98.460)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.3224448
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.163 (0.163)	Data 0.281 (0.281)	Loss 0.2225 (0.2225)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.2446 (0.2176)	Acc@1 98.047 (98.798)	Acc@5 100.000 (100.000)
Epoch: [152][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2167 (0.2193)	Acc@1 98.438 (98.634)	Acc@5 99.609 (99.997)
Epoch: [152][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2053 (0.2194)	Acc@1 99.219 (98.555)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.147 (0.147)	Data 0.270 (0.270)	Loss 0.2157 (0.2157)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.2262 (0.2176)	Acc@1 98.438 (98.600)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2290 (0.2145)	Acc@1 97.656 (98.725)	Acc@5 100.000 (99.991)
Epoch: [153][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2191 (0.2138)	Acc@1 97.656 (98.765)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.172 (0.172)	Data 0.267 (0.267)	Loss 0.1862 (0.1862)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.1962 (0.2108)	Acc@1 99.609 (98.924)	Acc@5 100.000 (99.988)
Epoch: [154][128/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.1937 (0.2106)	Acc@1 99.219 (98.901)	Acc@5 100.000 (99.994)
Epoch: [154][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1980 (0.2099)	Acc@1 99.219 (98.915)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.161 (0.161)	Data 0.285 (0.285)	Loss 0.2357 (0.2357)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.1974 (0.2065)	Acc@1 99.609 (99.044)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1996 (0.2066)	Acc@1 98.828 (99.019)	Acc@5 100.000 (100.000)
Epoch: [155][192/196]	Time 0.137 (0.121)	Data 0.000 (0.002)	Loss 0.1923 (0.2062)	Acc@1 99.609 (99.033)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.44
Max memory: 89.2934144
 24.167s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7214
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1518592
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.186 (0.186)	Data 0.261 (0.261)	Loss 0.2414 (0.2414)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.1924 (0.2048)	Acc@1 100.000 (98.990)	Acc@5 100.000 (99.994)
Epoch: [156][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2361 (0.2033)	Acc@1 96.875 (99.073)	Acc@5 100.000 (99.997)
Epoch: [156][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.2094 (0.2038)	Acc@1 98.828 (99.067)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.3224448
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.169 (0.169)	Data 0.272 (0.272)	Loss 0.2332 (0.2332)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.2235 (0.2039)	Acc@1 97.656 (99.050)	Acc@5 100.000 (99.994)
Epoch: [157][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2223 (0.2042)	Acc@1 99.219 (99.013)	Acc@5 100.000 (99.997)
Epoch: [157][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.1921 (0.2026)	Acc@1 99.609 (99.087)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.151 (0.151)	Data 0.296 (0.296)	Loss 0.1998 (0.1998)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.114 (0.121)	Data 0.000 (0.005)	Loss 0.2050 (0.1990)	Acc@1 98.828 (99.207)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1888 (0.1994)	Acc@1 99.609 (99.185)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2148 (0.2006)	Acc@1 98.438 (99.152)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.172 (0.172)	Data 0.292 (0.292)	Loss 0.1908 (0.1908)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2130 (0.1965)	Acc@1 98.828 (99.279)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.2241 (0.1975)	Acc@1 97.656 (99.255)	Acc@5 100.000 (99.994)
Epoch: [159][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.1840 (0.1976)	Acc@1 100.000 (99.221)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.149 (0.149)	Data 0.299 (0.299)	Loss 0.2043 (0.2043)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.1969 (0.1976)	Acc@1 99.219 (99.207)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.1852 (0.1993)	Acc@1 99.609 (99.146)	Acc@5 100.000 (99.997)
Epoch: [160][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1895 (0.1989)	Acc@1 99.609 (99.166)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.54
Max memory: 89.2934144
 24.222s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 320
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1518592
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.190 (0.190)	Data 0.283 (0.283)	Loss 0.2051 (0.2051)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.2081 (0.1940)	Acc@1 98.438 (99.315)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1926 (0.1944)	Acc@1 99.609 (99.358)	Acc@5 100.000 (100.000)
Epoch: [161][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1944 (0.1951)	Acc@1 99.219 (99.302)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.3224448
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.161 (0.161)	Data 0.260 (0.260)	Loss 0.1831 (0.1831)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.111 (0.122)	Data 0.000 (0.004)	Loss 0.1857 (0.1974)	Acc@1 99.609 (99.207)	Acc@5 100.000 (99.994)
Epoch: [162][128/196]	Time 0.132 (0.122)	Data 0.000 (0.002)	Loss 0.1969 (0.1967)	Acc@1 98.828 (99.240)	Acc@5 100.000 (99.997)
Epoch: [162][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1881 (0.1951)	Acc@1 99.219 (99.296)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.168 (0.168)	Data 0.303 (0.303)	Loss 0.2054 (0.2054)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.1910 (0.1946)	Acc@1 99.219 (99.297)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.120 (0.121)	Data 0.000 (0.003)	Loss 0.1978 (0.1931)	Acc@1 99.219 (99.337)	Acc@5 100.000 (100.000)
Epoch: [163][192/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.1867 (0.1929)	Acc@1 99.609 (99.358)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.172 (0.172)	Data 0.277 (0.277)	Loss 0.1866 (0.1866)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.2124 (0.1910)	Acc@1 99.219 (99.423)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1815 (0.1919)	Acc@1 100.000 (99.382)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1853 (0.1920)	Acc@1 100.000 (99.381)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.174 (0.174)	Data 0.259 (0.259)	Loss 0.1929 (0.1929)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.115 (0.122)	Data 0.000 (0.004)	Loss 0.1852 (0.1924)	Acc@1 100.000 (99.333)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2119 (0.1919)	Acc@1 98.047 (99.337)	Acc@5 99.609 (99.997)
Epoch: [165][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.1870 (0.1914)	Acc@1 99.219 (99.326)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.38
Max memory: 89.2934144
 24.199s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4270
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1518592
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.196 (0.196)	Data 0.265 (0.265)	Loss 0.1924 (0.1924)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.1910 (0.1895)	Acc@1 99.609 (99.363)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1892 (0.1897)	Acc@1 99.219 (99.397)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.1871 (0.1889)	Acc@1 99.609 (99.427)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.3224448
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.151 (0.151)	Data 0.278 (0.278)	Loss 0.1916 (0.1916)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.134 (0.121)	Data 0.000 (0.004)	Loss 0.1813 (0.1893)	Acc@1 99.219 (99.363)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1886 (0.1884)	Acc@1 99.609 (99.437)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1779 (0.1882)	Acc@1 100.000 (99.425)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.175 (0.175)	Data 0.267 (0.267)	Loss 0.1834 (0.1834)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.1891 (0.1867)	Acc@1 99.609 (99.519)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.1859 (0.1871)	Acc@1 99.609 (99.452)	Acc@5 100.000 (100.000)
Epoch: [168][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.1859 (0.1879)	Acc@1 99.219 (99.419)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.178 (0.178)	Data 0.262 (0.262)	Loss 0.1819 (0.1819)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.122 (0.120)	Data 0.000 (0.004)	Loss 0.1784 (0.1864)	Acc@1 99.609 (99.495)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1775 (0.1865)	Acc@1 100.000 (99.461)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1860 (0.1869)	Acc@1 99.609 (99.454)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.182 (0.182)	Data 0.266 (0.266)	Loss 0.1794 (0.1794)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.139 (0.121)	Data 0.000 (0.004)	Loss 0.1912 (0.1864)	Acc@1 99.609 (99.459)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.131 (0.120)	Data 0.000 (0.002)	Loss 0.1887 (0.1856)	Acc@1 99.609 (99.500)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1819 (0.1860)	Acc@1 100.000 (99.476)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.44
Max memory: 89.2934144
 23.975s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3579
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1518592
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.159 (0.159)	Data 0.296 (0.296)	Loss 0.1780 (0.1780)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.123 (0.120)	Data 0.000 (0.005)	Loss 0.1827 (0.1838)	Acc@1 99.609 (99.513)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1734 (0.1840)	Acc@1 100.000 (99.570)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1741 (0.1841)	Acc@1 100.000 (99.539)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.3224448
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.173 (0.173)	Data 0.270 (0.270)	Loss 0.1997 (0.1997)	Acc@1 98.828 (98.828)	Acc@5 99.609 (99.609)
Epoch: [172][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.1793 (0.1818)	Acc@1 99.609 (99.609)	Acc@5 100.000 (99.988)
Epoch: [172][128/196]	Time 0.110 (0.121)	Data 0.000 (0.002)	Loss 0.1855 (0.1834)	Acc@1 98.828 (99.531)	Acc@5 100.000 (99.994)
Epoch: [172][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1838 (0.1837)	Acc@1 99.219 (99.516)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.148 (0.148)	Data 0.265 (0.265)	Loss 0.1892 (0.1892)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.119 (0.119)	Data 0.000 (0.004)	Loss 0.1738 (0.1823)	Acc@1 100.000 (99.585)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1859 (0.1833)	Acc@1 99.219 (99.531)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.134 (0.120)	Data 0.000 (0.002)	Loss 0.1774 (0.1828)	Acc@1 99.609 (99.561)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.151 (0.151)	Data 0.265 (0.265)	Loss 0.1754 (0.1754)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.1757 (0.1816)	Acc@1 100.000 (99.579)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1704 (0.1813)	Acc@1 100.000 (99.591)	Acc@5 100.000 (100.000)
Epoch: [174][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1888 (0.1825)	Acc@1 98.828 (99.502)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.161 (0.161)	Data 0.298 (0.298)	Loss 0.1759 (0.1759)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.1890 (0.1825)	Acc@1 99.609 (99.471)	Acc@5 100.000 (99.994)
Epoch: [175][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.1760 (0.1823)	Acc@1 100.000 (99.503)	Acc@5 100.000 (99.997)
Epoch: [175][192/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.1776 (0.1821)	Acc@1 99.609 (99.502)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.65
Max memory: 89.2934144
 24.091s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 896
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1518592
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.182 (0.182)	Data 0.256 (0.256)	Loss 0.2034 (0.2034)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.2013 (0.1804)	Acc@1 98.828 (99.645)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1894 (0.1804)	Acc@1 99.219 (99.625)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.115 (0.120)	Data 0.000 (0.001)	Loss 0.1776 (0.1802)	Acc@1 99.609 (99.615)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.3224448
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.172 (0.172)	Data 0.285 (0.285)	Loss 0.1725 (0.1725)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.1832 (0.1781)	Acc@1 99.609 (99.621)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.1787 (0.1792)	Acc@1 99.609 (99.612)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.1875 (0.1792)	Acc@1 99.219 (99.603)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.154 (0.154)	Data 0.300 (0.300)	Loss 0.1770 (0.1770)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.1733 (0.1791)	Acc@1 100.000 (99.633)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.115 (0.121)	Data 0.000 (0.003)	Loss 0.1784 (0.1795)	Acc@1 100.000 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.1820 (0.1800)	Acc@1 99.219 (99.565)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.164 (0.164)	Data 0.258 (0.258)	Loss 0.1811 (0.1811)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.115 (0.120)	Data 0.000 (0.004)	Loss 0.1687 (0.1763)	Acc@1 100.000 (99.712)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.126 (0.120)	Data 0.000 (0.002)	Loss 0.1967 (0.1765)	Acc@1 98.438 (99.676)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1855 (0.1770)	Acc@1 98.828 (99.654)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.7549824
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.190 (0.190)	Data 0.266 (0.266)	Loss 0.1707 (0.1707)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.1739 (0.1777)	Acc@1 99.609 (99.579)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.1814 (0.1776)	Acc@1 99.219 (99.561)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1710 (0.1781)	Acc@1 100.000 (99.555)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.7549824
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 28, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(21, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(54, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(55, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(55, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.6
Max memory: 89.2934144
 24.034s  Thres 0.001 4
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 861
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.219 (0.219)	Data 0.255 (0.255)	Loss 3.3652 (3.3652)	Acc@1 11.328 (11.328)	Acc@5 50.391 (50.391)
Epoch: [1][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 2.4459 (2.6517)	Acc@1 33.594 (26.569)	Acc@5 85.547 (78.912)
Epoch: [1][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 2.1235 (2.4686)	Acc@1 43.750 (32.122)	Acc@5 91.797 (83.996)
Epoch: [1][192/196]	Time 0.127 (0.131)	Data 0.000 (0.001)	Loss 1.9746 (2.3336)	Acc@1 48.828 (36.895)	Acc@5 93.359 (86.848)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.176 (0.176)	Data 0.257 (0.257)	Loss 2.0846 (2.0846)	Acc@1 46.484 (46.484)	Acc@5 92.969 (92.969)
Epoch: [2][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 1.8540 (1.8853)	Acc@1 48.047 (52.909)	Acc@5 94.531 (94.153)
Epoch: [2][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.6885 (1.8163)	Acc@1 55.469 (54.948)	Acc@5 96.875 (94.755)
Epoch: [2][192/196]	Time 0.140 (0.130)	Data 0.000 (0.002)	Loss 1.5538 (1.7438)	Acc@1 61.328 (57.238)	Acc@5 97.266 (95.341)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.166 (0.166)	Data 0.285 (0.285)	Loss 1.4948 (1.4948)	Acc@1 61.328 (61.328)	Acc@5 98.438 (98.438)
Epoch: [3][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 1.4919 (1.5109)	Acc@1 65.234 (64.681)	Acc@5 97.266 (96.959)
Epoch: [3][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 1.4826 (1.4768)	Acc@1 65.234 (65.782)	Acc@5 96.875 (97.151)
Epoch: [3][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.4539 (1.4373)	Acc@1 66.016 (66.866)	Acc@5 98.047 (97.296)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.166 (0.166)	Data 0.258 (0.258)	Loss 1.3618 (1.3618)	Acc@1 67.188 (67.188)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 1.2863 (1.2926)	Acc@1 72.266 (71.382)	Acc@5 97.656 (97.843)
Epoch: [4][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 1.2228 (1.2729)	Acc@1 75.781 (71.799)	Acc@5 98.047 (97.944)
Epoch: [4][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.1796 (1.2514)	Acc@1 70.703 (72.164)	Acc@5 99.219 (98.025)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.165 (0.165)	Data 0.289 (0.289)	Loss 1.2010 (1.2010)	Acc@1 75.000 (75.000)	Acc@5 98.047 (98.047)
Epoch: [5][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 1.1677 (1.1532)	Acc@1 75.391 (74.808)	Acc@5 98.828 (98.245)
Epoch: [5][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.0318 (1.1306)	Acc@1 77.344 (75.315)	Acc@5 99.609 (98.416)
Epoch: [5][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 1.0115 (1.1098)	Acc@1 76.172 (75.810)	Acc@5 99.219 (98.525)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  55.44
Max memory: 103.3835008
 26.175s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2776
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.219 (0.219)	Data 0.269 (0.269)	Loss 1.0258 (1.0258)	Acc@1 76.953 (76.953)	Acc@5 99.609 (99.609)
Epoch: [6][64/196]	Time 0.133 (0.130)	Data 0.000 (0.004)	Loss 1.0361 (1.0214)	Acc@1 77.734 (77.692)	Acc@5 98.828 (98.768)
Epoch: [6][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.9496 (1.0241)	Acc@1 80.859 (77.547)	Acc@5 99.609 (98.731)
Epoch: [6][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 1.0356 (1.0149)	Acc@1 78.516 (77.842)	Acc@5 98.438 (98.749)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.179 (0.179)	Data 0.302 (0.302)	Loss 0.8782 (0.8782)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.9819 (0.9726)	Acc@1 77.734 (78.978)	Acc@5 99.609 (98.810)
Epoch: [7][128/196]	Time 0.127 (0.131)	Data 0.000 (0.003)	Loss 0.8994 (0.9631)	Acc@1 78.906 (79.046)	Acc@5 100.000 (98.804)
Epoch: [7][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.8169 (0.9553)	Acc@1 83.203 (79.198)	Acc@5 98.828 (98.850)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.157 (0.157)	Data 0.263 (0.263)	Loss 0.9715 (0.9715)	Acc@1 77.734 (77.734)	Acc@5 98.828 (98.828)
Epoch: [8][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.9153 (0.9209)	Acc@1 80.469 (80.036)	Acc@5 98.438 (98.840)
Epoch: [8][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.9339 (0.9092)	Acc@1 80.078 (80.323)	Acc@5 99.219 (98.886)
Epoch: [8][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8908 (0.8997)	Acc@1 79.688 (80.453)	Acc@5 98.828 (98.937)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.177 (0.177)	Data 0.296 (0.296)	Loss 0.8789 (0.8789)	Acc@1 80.859 (80.859)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8347 (0.8756)	Acc@1 82.422 (81.352)	Acc@5 99.609 (98.990)
Epoch: [9][128/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.8053 (0.8742)	Acc@1 84.766 (81.032)	Acc@5 98.438 (98.977)
Epoch: [9][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.8548 (0.8706)	Acc@1 80.078 (81.096)	Acc@5 99.609 (98.978)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.184 (0.184)	Data 0.287 (0.287)	Loss 0.8383 (0.8383)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [10][64/196]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.8482 (0.8569)	Acc@1 82.422 (81.172)	Acc@5 98.828 (99.087)
Epoch: [10][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8601 (0.8520)	Acc@1 80.469 (81.229)	Acc@5 98.438 (99.019)
Epoch: [10][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.9056 (0.8491)	Acc@1 80.078 (81.373)	Acc@5 98.438 (98.960)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  72.31
Max memory: 103.3833984
 25.945s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6869
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.177 (0.177)	Data 0.274 (0.274)	Loss 0.8403 (0.8403)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.8691 (0.8087)	Acc@1 81.250 (82.428)	Acc@5 99.219 (99.165)
Epoch: [11][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7532 (0.8160)	Acc@1 84.375 (82.228)	Acc@5 99.219 (99.170)
Epoch: [11][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.8168 (0.8221)	Acc@1 83.203 (82.064)	Acc@5 99.219 (99.144)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.187 (0.187)	Data 0.260 (0.260)	Loss 0.8294 (0.8294)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.7733 (0.8216)	Acc@1 85.547 (82.266)	Acc@5 99.609 (99.105)
Epoch: [12][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.8173 (0.8165)	Acc@1 82.422 (82.219)	Acc@5 99.219 (99.079)
Epoch: [12][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7085 (0.8116)	Acc@1 84.375 (82.385)	Acc@5 100.000 (99.116)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.162 (0.162)	Data 0.319 (0.319)	Loss 0.7880 (0.7880)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [13][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.8948 (0.7837)	Acc@1 79.297 (83.269)	Acc@5 97.656 (99.219)
Epoch: [13][128/196]	Time 0.131 (0.130)	Data 0.000 (0.003)	Loss 0.7723 (0.7952)	Acc@1 86.328 (82.879)	Acc@5 99.219 (99.170)
Epoch: [13][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.8873 (0.7941)	Acc@1 80.859 (82.987)	Acc@5 99.609 (99.180)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.151 (0.151)	Data 0.296 (0.296)	Loss 0.8291 (0.8291)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.7472 (0.7920)	Acc@1 82.812 (83.095)	Acc@5 99.219 (99.267)
Epoch: [14][128/196]	Time 0.144 (0.130)	Data 0.000 (0.002)	Loss 0.7533 (0.7938)	Acc@1 84.766 (82.946)	Acc@5 98.828 (99.304)
Epoch: [14][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8075 (0.7934)	Acc@1 82.031 (82.936)	Acc@5 98.828 (99.251)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.188 (0.188)	Data 0.257 (0.257)	Loss 0.7687 (0.7687)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [15][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.7974 (0.7755)	Acc@1 82.422 (83.594)	Acc@5 100.000 (99.297)
Epoch: [15][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8493 (0.7782)	Acc@1 79.297 (83.345)	Acc@5 98.047 (99.237)
Epoch: [15][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8177 (0.7798)	Acc@1 82.812 (83.333)	Acc@5 99.219 (99.255)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  76.38
Max memory: 103.3833984
 26.047s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5900
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.193 (0.193)	Data 0.297 (0.297)	Loss 0.8091 (0.8091)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [16][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.6278 (0.7426)	Acc@1 87.500 (84.675)	Acc@5 99.609 (99.291)
Epoch: [16][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8547 (0.7725)	Acc@1 80.078 (83.600)	Acc@5 98.828 (99.231)
Epoch: [16][192/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.7654 (0.7771)	Acc@1 85.156 (83.523)	Acc@5 99.219 (99.199)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.175 (0.175)	Data 0.268 (0.268)	Loss 0.7420 (0.7420)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [17][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.7762 (0.7880)	Acc@1 81.250 (83.431)	Acc@5 99.219 (99.123)
Epoch: [17][128/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7666 (0.7823)	Acc@1 83.594 (83.430)	Acc@5 99.609 (99.198)
Epoch: [17][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.8072 (0.7805)	Acc@1 80.469 (83.537)	Acc@5 100.000 (99.160)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.152 (0.152)	Data 0.273 (0.273)	Loss 0.7038 (0.7038)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.8109 (0.7700)	Acc@1 83.594 (83.822)	Acc@5 99.609 (99.315)
Epoch: [18][128/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7591 (0.7731)	Acc@1 83.984 (83.669)	Acc@5 98.828 (99.276)
Epoch: [18][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7890 (0.7748)	Acc@1 81.641 (83.507)	Acc@5 100.000 (99.302)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.184 (0.184)	Data 0.276 (0.276)	Loss 0.5966 (0.5966)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.7123 (0.7595)	Acc@1 86.328 (84.441)	Acc@5 100.000 (99.183)
Epoch: [19][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7533 (0.7597)	Acc@1 81.641 (84.257)	Acc@5 98.438 (99.252)
Epoch: [19][192/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.8756 (0.7642)	Acc@1 83.203 (84.039)	Acc@5 98.828 (99.249)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.154 (0.154)	Data 0.259 (0.259)	Loss 0.7733 (0.7733)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.7231 (0.7438)	Acc@1 83.984 (84.645)	Acc@5 98.828 (99.387)
Epoch: [20][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8520 (0.7505)	Acc@1 79.297 (84.442)	Acc@5 99.219 (99.358)
Epoch: [20][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6688 (0.7583)	Acc@1 87.500 (84.256)	Acc@5 99.219 (99.298)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  76.51
Max memory: 103.3833984
 25.847s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2939
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2020864
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.203 (0.203)	Data 0.268 (0.268)	Loss 0.8425 (0.8425)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6937 (0.7323)	Acc@1 87.891 (85.246)	Acc@5 100.000 (99.387)
Epoch: [21][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7308 (0.7477)	Acc@1 84.375 (84.584)	Acc@5 99.609 (99.325)
Epoch: [21][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7343 (0.7518)	Acc@1 88.281 (84.456)	Acc@5 99.609 (99.326)
Max memory in training epoch: 66.6450432
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.185 (0.185)	Data 0.261 (0.261)	Loss 0.6684 (0.6684)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [22][64/196]	Time 0.150 (0.130)	Data 0.000 (0.004)	Loss 0.8832 (0.7409)	Acc@1 79.688 (84.663)	Acc@5 98.828 (99.279)
Epoch: [22][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8539 (0.7534)	Acc@1 79.688 (84.257)	Acc@5 98.438 (99.285)
Epoch: [22][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.8967 (0.7585)	Acc@1 78.906 (84.181)	Acc@5 100.000 (99.300)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.179 (0.179)	Data 0.260 (0.260)	Loss 0.7142 (0.7142)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.133 (0.131)	Data 0.000 (0.004)	Loss 0.7900 (0.7393)	Acc@1 82.812 (84.874)	Acc@5 98.438 (99.387)
Epoch: [23][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.6864 (0.7462)	Acc@1 88.281 (84.611)	Acc@5 99.219 (99.379)
Epoch: [23][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7830 (0.7525)	Acc@1 82.031 (84.438)	Acc@5 99.609 (99.330)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.169 (0.169)	Data 0.259 (0.259)	Loss 0.7273 (0.7273)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [24][64/196]	Time 0.125 (0.131)	Data 0.000 (0.004)	Loss 0.7156 (0.7449)	Acc@1 86.328 (84.429)	Acc@5 100.000 (99.351)
Epoch: [24][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.6318 (0.7388)	Acc@1 89.062 (84.866)	Acc@5 100.000 (99.337)
Epoch: [24][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7005 (0.7402)	Acc@1 85.547 (84.756)	Acc@5 99.609 (99.326)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.167 (0.167)	Data 0.305 (0.305)	Loss 0.7282 (0.7282)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.7037 (0.7364)	Acc@1 87.891 (85.012)	Acc@5 99.609 (99.315)
Epoch: [25][128/196]	Time 0.126 (0.131)	Data 0.000 (0.003)	Loss 0.7857 (0.7496)	Acc@1 82.812 (84.439)	Acc@5 98.828 (99.331)
Epoch: [25][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.8596 (0.7518)	Acc@1 80.859 (84.415)	Acc@5 99.219 (99.350)
Max memory in training epoch: 66.5401856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 477576 ; 486232 ; 0.9821977985817469
[INFO] Storing checkpoint...
  76.52
Max memory: 103.3821696
 26.138s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2618
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1987072
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.208 (0.208)	Data 0.261 (0.261)	Loss 0.7054 (0.7054)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.7928 (0.7261)	Acc@1 81.641 (85.391)	Acc@5 98.828 (99.459)
Epoch: [26][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7090 (0.7291)	Acc@1 86.719 (85.202)	Acc@5 99.219 (99.370)
Epoch: [26][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6869 (0.7331)	Acc@1 86.328 (85.102)	Acc@5 99.609 (99.332)
Max memory in training epoch: 66.6315264
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.183 (0.183)	Data 0.279 (0.279)	Loss 0.7420 (0.7420)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.8162 (0.7478)	Acc@1 82.422 (84.255)	Acc@5 99.609 (99.381)
Epoch: [27][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7169 (0.7414)	Acc@1 83.984 (84.623)	Acc@5 99.609 (99.376)
Epoch: [27][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7626 (0.7406)	Acc@1 83.984 (84.695)	Acc@5 98.828 (99.385)
Max memory in training epoch: 66.4349184
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.188 (0.188)	Data 0.267 (0.267)	Loss 0.6154 (0.6154)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [28][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.7339 (0.7044)	Acc@1 84.375 (85.962)	Acc@5 100.000 (99.525)
Epoch: [28][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7483 (0.7282)	Acc@1 83.203 (85.120)	Acc@5 99.609 (99.410)
Epoch: [28][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7002 (0.7363)	Acc@1 88.281 (85.021)	Acc@5 98.438 (99.375)
Max memory in training epoch: 66.4349184
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.170 (0.170)	Data 0.262 (0.262)	Loss 0.8322 (0.8322)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [29][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.7113 (0.7103)	Acc@1 85.938 (85.769)	Acc@5 100.000 (99.501)
Epoch: [29][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7424 (0.7150)	Acc@1 84.375 (85.653)	Acc@5 100.000 (99.440)
Epoch: [29][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.8042 (0.7227)	Acc@1 82.031 (85.409)	Acc@5 98.828 (99.407)
Max memory in training epoch: 66.4349184
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.167 (0.167)	Data 0.288 (0.288)	Loss 0.7199 (0.7199)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.7398 (0.7265)	Acc@1 86.719 (85.427)	Acc@5 100.000 (99.435)
Epoch: [30][128/196]	Time 0.142 (0.131)	Data 0.000 (0.002)	Loss 0.6762 (0.7272)	Acc@1 87.500 (85.229)	Acc@5 100.000 (99.391)
Epoch: [30][192/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.8017 (0.7302)	Acc@1 83.594 (85.051)	Acc@5 99.609 (99.377)
Max memory in training epoch: 66.4349184
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 457228 ; 477576 ; 0.9573931688359549
[INFO] Storing checkpoint...
  81.74
Max memory: 103.372032
 26.137s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7990
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1905664
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.218 (0.218)	Data 0.257 (0.257)	Loss 0.7382 (0.7382)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [31][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.6941 (0.6995)	Acc@1 87.109 (85.956)	Acc@5 98.438 (99.411)
Epoch: [31][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.7537 (0.7112)	Acc@1 85.547 (85.644)	Acc@5 98.438 (99.419)
Epoch: [31][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7932 (0.7209)	Acc@1 82.422 (85.409)	Acc@5 99.219 (99.383)
Max memory in training epoch: 66.0091392
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.185 (0.185)	Data 0.259 (0.259)	Loss 0.8143 (0.8143)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.140 (0.129)	Data 0.000 (0.004)	Loss 0.7707 (0.7105)	Acc@1 83.594 (86.016)	Acc@5 99.609 (99.495)
Epoch: [32][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6897 (0.7316)	Acc@1 86.719 (85.150)	Acc@5 98.828 (99.431)
Epoch: [32][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6864 (0.7272)	Acc@1 87.109 (85.241)	Acc@5 99.609 (99.427)
Max memory in training epoch: 65.86496
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.174 (0.174)	Data 0.284 (0.284)	Loss 0.6274 (0.6274)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [33][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.7234 (0.7128)	Acc@1 83.594 (85.745)	Acc@5 100.000 (99.333)
Epoch: [33][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8189 (0.7172)	Acc@1 82.812 (85.589)	Acc@5 98.047 (99.343)
Epoch: [33][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6871 (0.7188)	Acc@1 87.500 (85.512)	Acc@5 100.000 (99.342)
Max memory in training epoch: 65.86496
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.160 (0.160)	Data 0.256 (0.256)	Loss 0.6675 (0.6675)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.6584 (0.7109)	Acc@1 87.891 (85.974)	Acc@5 100.000 (99.375)
Epoch: [34][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.7535 (0.7124)	Acc@1 85.547 (85.792)	Acc@5 99.219 (99.406)
Epoch: [34][192/196]	Time 0.127 (0.129)	Data 0.000 (0.001)	Loss 0.6764 (0.7130)	Acc@1 87.500 (85.753)	Acc@5 99.219 (99.397)
Max memory in training epoch: 65.86496
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.180 (0.180)	Data 0.293 (0.293)	Loss 0.7790 (0.7790)	Acc@1 81.641 (81.641)	Acc@5 98.438 (98.438)
Epoch: [35][64/196]	Time 0.137 (0.129)	Data 0.000 (0.005)	Loss 0.7499 (0.7195)	Acc@1 85.547 (85.499)	Acc@5 100.000 (99.405)
Epoch: [35][128/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.7646 (0.7174)	Acc@1 81.641 (85.477)	Acc@5 99.219 (99.355)
Epoch: [35][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6998 (0.7192)	Acc@1 85.547 (85.444)	Acc@5 100.000 (99.336)
Max memory in training epoch: 65.86496
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423308 ; 457228 ; 0.9258138171765509
[INFO] Storing checkpoint...
  78.87
Max memory: 102.5759232
 25.547s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7841
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1771008
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.177 (0.177)	Data 0.276 (0.276)	Loss 0.6792 (0.6792)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6895 (0.6923)	Acc@1 85.938 (86.394)	Acc@5 100.000 (99.531)
Epoch: [36][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7434 (0.7083)	Acc@1 82.812 (85.726)	Acc@5 100.000 (99.449)
Epoch: [36][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7764 (0.7055)	Acc@1 82.422 (85.857)	Acc@5 98.828 (99.427)
Max memory in training epoch: 64.526592
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.178 (0.178)	Data 0.290 (0.290)	Loss 0.6819 (0.6819)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.8301 (0.7120)	Acc@1 82.812 (85.415)	Acc@5 99.609 (99.339)
Epoch: [37][128/196]	Time 0.120 (0.131)	Data 0.000 (0.002)	Loss 0.6974 (0.7126)	Acc@1 87.500 (85.544)	Acc@5 99.219 (99.397)
Epoch: [37][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.5921 (0.7151)	Acc@1 89.062 (85.521)	Acc@5 100.000 (99.381)
Max memory in training epoch: 64.1464832
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.189 (0.189)	Data 0.261 (0.261)	Loss 0.6453 (0.6453)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.6895 (0.7020)	Acc@1 84.766 (85.625)	Acc@5 99.609 (99.405)
Epoch: [38][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8209 (0.7058)	Acc@1 83.203 (85.647)	Acc@5 99.609 (99.397)
Epoch: [38][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6836 (0.7080)	Acc@1 85.547 (85.727)	Acc@5 98.047 (99.369)
Max memory in training epoch: 64.1464832
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.192 (0.192)	Data 0.258 (0.258)	Loss 0.5771 (0.5771)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7495 (0.7255)	Acc@1 86.328 (85.150)	Acc@5 99.219 (99.363)
Epoch: [39][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7511 (0.7167)	Acc@1 83.594 (85.538)	Acc@5 99.609 (99.319)
Epoch: [39][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6983 (0.7152)	Acc@1 83.984 (85.565)	Acc@5 99.219 (99.360)
Max memory in training epoch: 64.1464832
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.183 (0.183)	Data 0.290 (0.290)	Loss 0.6608 (0.6608)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [40][64/196]	Time 0.131 (0.129)	Data 0.000 (0.005)	Loss 0.6153 (0.6929)	Acc@1 87.500 (86.226)	Acc@5 100.000 (99.411)
Epoch: [40][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6793 (0.6998)	Acc@1 86.719 (86.068)	Acc@5 100.000 (99.422)
Epoch: [40][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.7198 (0.7041)	Acc@1 85.938 (85.881)	Acc@5 99.219 (99.401)
Max memory in training epoch: 64.1464832
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 405698 ; 423308 ; 0.9583990852995927
[INFO] Storing checkpoint...
  79.78
Max memory: 100.1340416
 25.528s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5175
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1701376
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.186 (0.186)	Data 0.271 (0.271)	Loss 0.6665 (0.6665)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.7606 (0.6655)	Acc@1 83.594 (87.338)	Acc@5 99.219 (99.411)
Epoch: [41][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.8422 (0.6877)	Acc@1 81.641 (86.443)	Acc@5 98.438 (99.379)
Epoch: [41][192/196]	Time 0.132 (0.128)	Data 0.000 (0.002)	Loss 0.7501 (0.6895)	Acc@1 84.375 (86.419)	Acc@5 100.000 (99.397)
Max memory in training epoch: 63.240448
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.149 (0.149)	Data 0.285 (0.285)	Loss 0.7680 (0.7680)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.121 (0.127)	Data 0.000 (0.005)	Loss 0.6644 (0.7030)	Acc@1 85.547 (85.751)	Acc@5 99.609 (99.423)
Epoch: [42][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.7611 (0.7057)	Acc@1 85.938 (85.795)	Acc@5 98.828 (99.367)
Epoch: [42][192/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.7681 (0.7050)	Acc@1 81.641 (85.713)	Acc@5 98.828 (99.389)
Max memory in training epoch: 63.1355904
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.179 (0.179)	Data 0.260 (0.260)	Loss 0.7165 (0.7165)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [43][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.7949 (0.7007)	Acc@1 84.375 (85.697)	Acc@5 99.609 (99.417)
Epoch: [43][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6595 (0.6998)	Acc@1 87.891 (85.850)	Acc@5 99.219 (99.437)
Epoch: [43][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.7749 (0.7041)	Acc@1 80.469 (85.743)	Acc@5 100.000 (99.439)
Max memory in training epoch: 63.1355904
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.179 (0.179)	Data 0.280 (0.280)	Loss 0.6180 (0.6180)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [44][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.7222 (0.6930)	Acc@1 83.984 (86.358)	Acc@5 98.828 (99.435)
Epoch: [44][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6842 (0.6945)	Acc@1 87.500 (86.280)	Acc@5 98.828 (99.482)
Epoch: [44][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.8031 (0.6978)	Acc@1 83.984 (86.162)	Acc@5 99.219 (99.447)
Max memory in training epoch: 63.1355904
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.171 (0.171)	Data 0.288 (0.288)	Loss 0.6307 (0.6307)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.8755 (0.7082)	Acc@1 80.078 (85.517)	Acc@5 99.219 (99.411)
Epoch: [45][128/196]	Time 0.137 (0.128)	Data 0.000 (0.002)	Loss 0.7069 (0.7028)	Acc@1 84.375 (85.744)	Acc@5 98.828 (99.479)
Epoch: [45][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7067 (0.7038)	Acc@1 85.938 (85.780)	Acc@5 99.609 (99.447)
Max memory in training epoch: 63.1355904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 387514 ; 405698 ; 0.9551784825165517
[INFO] Storing checkpoint...
  72.18
Max memory: 98.5595392
 25.584s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7367
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1628672
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.182 (0.182)	Data 0.258 (0.258)	Loss 0.6544 (0.6544)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.6241 (0.6591)	Acc@1 88.672 (87.206)	Acc@5 99.219 (99.555)
Epoch: [46][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6534 (0.6808)	Acc@1 86.328 (86.525)	Acc@5 100.000 (99.473)
Epoch: [46][192/196]	Time 0.135 (0.130)	Data 0.000 (0.001)	Loss 0.6894 (0.6862)	Acc@1 85.547 (86.338)	Acc@5 100.000 (99.464)
Max memory in training epoch: 62.7132928
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.185 (0.185)	Data 0.290 (0.290)	Loss 0.7199 (0.7199)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7763 (0.6966)	Acc@1 83.984 (86.076)	Acc@5 100.000 (99.423)
Epoch: [47][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.7479 (0.7016)	Acc@1 84.375 (85.780)	Acc@5 98.828 (99.452)
Epoch: [47][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6687 (0.7011)	Acc@1 86.328 (85.747)	Acc@5 99.609 (99.462)
Max memory in training epoch: 62.5560064
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.172 (0.172)	Data 0.334 (0.334)	Loss 0.6517 (0.6517)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.7040 (0.6862)	Acc@1 85.547 (86.340)	Acc@5 99.219 (99.423)
Epoch: [48][128/196]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.6531 (0.6873)	Acc@1 87.500 (86.255)	Acc@5 98.828 (99.449)
Epoch: [48][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7407 (0.6955)	Acc@1 83.594 (85.942)	Acc@5 98.828 (99.389)
Max memory in training epoch: 62.5560064
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.176 (0.176)	Data 0.260 (0.260)	Loss 0.6680 (0.6680)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6436 (0.6844)	Acc@1 87.109 (86.298)	Acc@5 99.219 (99.507)
Epoch: [49][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7096 (0.6844)	Acc@1 85.156 (86.440)	Acc@5 98.828 (99.419)
Epoch: [49][192/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.6668 (0.6881)	Acc@1 86.719 (86.320)	Acc@5 99.609 (99.431)
Max memory in training epoch: 62.5560064
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.188 (0.188)	Data 0.271 (0.271)	Loss 0.5761 (0.5761)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [50][64/196]	Time 0.139 (0.132)	Data 0.000 (0.004)	Loss 0.6753 (0.6893)	Acc@1 87.109 (86.370)	Acc@5 99.609 (99.411)
Epoch: [50][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.5501 (0.6878)	Acc@1 91.406 (86.258)	Acc@5 99.609 (99.446)
Epoch: [50][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6942 (0.6925)	Acc@1 87.891 (86.164)	Acc@5 100.000 (99.411)
Max memory in training epoch: 62.5560064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 369042 ; 387514 ; 0.952332044777737
[INFO] Storing checkpoint...
  78.34
Max memory: 97.4285312
 26.228s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2487
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1555968
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.203 (0.203)	Data 0.298 (0.298)	Loss 0.6993 (0.6993)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [51][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.7126 (0.6583)	Acc@1 84.766 (87.115)	Acc@5 99.219 (99.591)
Epoch: [51][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7904 (0.6739)	Acc@1 80.859 (86.555)	Acc@5 99.609 (99.497)
Epoch: [51][192/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.6989 (0.6811)	Acc@1 85.547 (86.395)	Acc@5 99.219 (99.458)
Max memory in training epoch: 61.7404928
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.164 (0.164)	Data 0.296 (0.296)	Loss 0.7491 (0.7491)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [52][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.7627 (0.6880)	Acc@1 83.984 (86.514)	Acc@5 98.438 (99.567)
Epoch: [52][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7140 (0.6869)	Acc@1 84.766 (86.480)	Acc@5 99.219 (99.491)
Epoch: [52][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6694 (0.6914)	Acc@1 85.938 (86.269)	Acc@5 100.000 (99.449)
Max memory in training epoch: 61.7536
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.188 (0.188)	Data 0.272 (0.272)	Loss 0.6560 (0.6560)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [53][64/196]	Time 0.134 (0.129)	Data 0.000 (0.004)	Loss 0.7989 (0.6821)	Acc@1 84.766 (86.358)	Acc@5 99.219 (99.507)
Epoch: [53][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6441 (0.6801)	Acc@1 88.281 (86.449)	Acc@5 100.000 (99.491)
Epoch: [53][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7182 (0.6876)	Acc@1 86.328 (86.193)	Acc@5 99.219 (99.445)
Max memory in training epoch: 61.7536
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.172 (0.172)	Data 0.269 (0.269)	Loss 0.6937 (0.6937)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.8238 (0.6758)	Acc@1 82.031 (86.232)	Acc@5 99.609 (99.561)
Epoch: [54][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6616 (0.6865)	Acc@1 86.719 (86.171)	Acc@5 99.219 (99.522)
Epoch: [54][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7365 (0.6869)	Acc@1 84.766 (86.170)	Acc@5 99.219 (99.478)
Max memory in training epoch: 61.7536
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.155 (0.155)	Data 0.262 (0.262)	Loss 0.6647 (0.6647)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.5704 (0.6819)	Acc@1 91.406 (86.659)	Acc@5 100.000 (99.519)
Epoch: [55][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6905 (0.6825)	Acc@1 86.719 (86.449)	Acc@5 98.438 (99.464)
Epoch: [55][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6965 (0.6906)	Acc@1 85.547 (86.103)	Acc@5 100.000 (99.435)
Max memory in training epoch: 61.7536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 357436 ; 369042 ; 0.9685510050346573
[INFO] Storing checkpoint...
  77.59
Max memory: 95.8846464
 25.465s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9134
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1504768
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 0.6749 (0.6749)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [56][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.6130 (0.6379)	Acc@1 90.234 (87.897)	Acc@5 99.219 (99.573)
Epoch: [56][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.6883 (0.6660)	Acc@1 85.938 (86.785)	Acc@5 98.828 (99.482)
Epoch: [56][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6768 (0.6719)	Acc@1 87.500 (86.701)	Acc@5 99.609 (99.476)
Max memory in training epoch: 59.7155328
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.148 (0.148)	Data 0.257 (0.257)	Loss 0.6714 (0.6714)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [57][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.6078 (0.6875)	Acc@1 89.453 (86.556)	Acc@5 99.609 (99.363)
Epoch: [57][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.7750 (0.6863)	Acc@1 82.422 (86.410)	Acc@5 99.609 (99.410)
Epoch: [57][192/196]	Time 0.124 (0.121)	Data 0.000 (0.001)	Loss 0.6544 (0.6894)	Acc@1 86.328 (86.213)	Acc@5 100.000 (99.397)
Max memory in training epoch: 59.7417472
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.166 (0.166)	Data 0.282 (0.282)	Loss 0.6143 (0.6143)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.111 (0.121)	Data 0.000 (0.005)	Loss 0.6715 (0.6599)	Acc@1 85.938 (87.133)	Acc@5 99.609 (99.459)
Epoch: [58][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6603 (0.6713)	Acc@1 85.156 (86.640)	Acc@5 99.219 (99.458)
Epoch: [58][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.6290 (0.6780)	Acc@1 89.062 (86.409)	Acc@5 99.219 (99.443)
Max memory in training epoch: 59.7417472
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.162 (0.162)	Data 0.287 (0.287)	Loss 0.6663 (0.6663)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [59][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.6744 (0.6953)	Acc@1 88.281 (85.499)	Acc@5 98.828 (99.507)
Epoch: [59][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6397 (0.6860)	Acc@1 87.891 (85.962)	Acc@5 99.609 (99.540)
Epoch: [59][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.8249 (0.6823)	Acc@1 82.031 (86.067)	Acc@5 99.219 (99.530)
Max memory in training epoch: 59.7417472
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.173 (0.173)	Data 0.259 (0.259)	Loss 0.5952 (0.5952)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.124 (0.122)	Data 0.000 (0.004)	Loss 0.6443 (0.6725)	Acc@1 88.281 (86.587)	Acc@5 99.219 (99.597)
Epoch: [60][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6350 (0.6759)	Acc@1 87.891 (86.519)	Acc@5 99.609 (99.512)
Epoch: [60][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6568 (0.6792)	Acc@1 85.938 (86.409)	Acc@5 99.609 (99.490)
Max memory in training epoch: 59.7417472
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 349354 ; 357436 ; 0.9773889591423359
[INFO] Storing checkpoint...
  79.49
Max memory: 92.8667136
 24.241s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5072
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1472
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.198 (0.198)	Data 0.255 (0.255)	Loss 0.6313 (0.6313)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.117 (0.125)	Data 0.000 (0.004)	Loss 0.7071 (0.6427)	Acc@1 85.938 (87.434)	Acc@5 99.219 (99.549)
Epoch: [61][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6523 (0.6672)	Acc@1 88.672 (86.613)	Acc@5 99.609 (99.525)
Epoch: [61][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.7730 (0.6712)	Acc@1 82.812 (86.494)	Acc@5 97.656 (99.494)
Max memory in training epoch: 59.204352
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.174 (0.174)	Data 0.258 (0.258)	Loss 0.5929 (0.5929)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.6315 (0.6841)	Acc@1 91.406 (86.052)	Acc@5 100.000 (99.441)
Epoch: [62][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6114 (0.6865)	Acc@1 88.672 (86.001)	Acc@5 100.000 (99.446)
Epoch: [62][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.6658 (0.6854)	Acc@1 85.547 (86.085)	Acc@5 99.219 (99.449)
Max memory in training epoch: 59.1519232
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.187 (0.187)	Data 0.285 (0.285)	Loss 0.6663 (0.6663)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.6697 (0.6780)	Acc@1 85.938 (86.400)	Acc@5 99.219 (99.519)
Epoch: [63][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6634 (0.6685)	Acc@1 87.891 (86.773)	Acc@5 99.219 (99.540)
Epoch: [63][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.6440 (0.6752)	Acc@1 87.891 (86.476)	Acc@5 99.609 (99.510)
Max memory in training epoch: 59.1519232
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.170 (0.170)	Data 0.257 (0.257)	Loss 0.6244 (0.6244)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [64][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.6830 (0.6737)	Acc@1 85.938 (86.689)	Acc@5 99.609 (99.453)
Epoch: [64][128/196]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.6752 (0.6795)	Acc@1 85.547 (86.422)	Acc@5 99.219 (99.452)
Epoch: [64][192/196]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.6721 (0.6797)	Acc@1 87.500 (86.346)	Acc@5 99.609 (99.472)
Max memory in training epoch: 59.1519232
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.163 (0.163)	Data 0.304 (0.304)	Loss 0.6199 (0.6199)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [65][64/196]	Time 0.138 (0.131)	Data 0.000 (0.005)	Loss 0.6150 (0.6859)	Acc@1 91.016 (85.956)	Acc@5 99.219 (99.435)
Epoch: [65][128/196]	Time 0.120 (0.130)	Data 0.000 (0.003)	Loss 0.6490 (0.6755)	Acc@1 88.672 (86.419)	Acc@5 99.219 (99.473)
Epoch: [65][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7854 (0.6757)	Acc@1 81.641 (86.429)	Acc@5 99.219 (99.484)
Max memory in training epoch: 59.1519232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 341994 ; 349354 ; 0.9789325440670494
[INFO] Storing checkpoint...
  78.02
Max memory: 91.7988864
 25.884s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7341
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1442816
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.197 (0.197)	Data 0.295 (0.295)	Loss 0.6599 (0.6599)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.116 (0.126)	Data 0.000 (0.005)	Loss 0.7150 (0.6525)	Acc@1 85.938 (87.362)	Acc@5 100.000 (99.519)
Epoch: [66][128/196]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.6437 (0.6670)	Acc@1 86.719 (86.816)	Acc@5 99.219 (99.494)
Epoch: [66][192/196]	Time 0.134 (0.128)	Data 0.000 (0.002)	Loss 0.7692 (0.6753)	Acc@1 84.375 (86.484)	Acc@5 100.000 (99.466)
Max memory in training epoch: 59.1140352
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.194 (0.194)	Data 0.382 (0.382)	Loss 0.7312 (0.7312)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [67][64/196]	Time 0.139 (0.130)	Data 0.000 (0.006)	Loss 0.7909 (0.6836)	Acc@1 83.594 (86.208)	Acc@5 99.219 (99.381)
Epoch: [67][128/196]	Time 0.148 (0.129)	Data 0.000 (0.003)	Loss 0.7072 (0.6831)	Acc@1 82.422 (86.258)	Acc@5 99.609 (99.376)
Epoch: [67][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6157 (0.6860)	Acc@1 85.938 (86.154)	Acc@5 99.609 (99.383)
Max memory in training epoch: 59.035392
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.170 (0.170)	Data 0.352 (0.352)	Loss 0.7185 (0.7185)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.125 (0.127)	Data 0.000 (0.006)	Loss 0.7151 (0.6757)	Acc@1 84.375 (86.358)	Acc@5 99.219 (99.501)
Epoch: [68][128/196]	Time 0.115 (0.127)	Data 0.000 (0.003)	Loss 0.6226 (0.6698)	Acc@1 85.938 (86.452)	Acc@5 99.609 (99.512)
Epoch: [68][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.7149 (0.6795)	Acc@1 84.766 (86.205)	Acc@5 98.438 (99.458)
Max memory in training epoch: 59.035392
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.167 (0.167)	Data 0.293 (0.293)	Loss 0.6057 (0.6057)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.123 (0.127)	Data 0.000 (0.005)	Loss 0.6820 (0.6652)	Acc@1 84.766 (86.803)	Acc@5 100.000 (99.555)
Epoch: [69][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.7210 (0.6727)	Acc@1 86.328 (86.543)	Acc@5 98.828 (99.470)
Epoch: [69][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.6322 (0.6739)	Acc@1 87.500 (86.597)	Acc@5 100.000 (99.460)
Max memory in training epoch: 59.035392
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.6796 (0.6796)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.6602 (0.6633)	Acc@1 87.500 (86.785)	Acc@5 99.609 (99.471)
Epoch: [70][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.5669 (0.6682)	Acc@1 89.062 (86.610)	Acc@5 100.000 (99.470)
Epoch: [70][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6308 (0.6722)	Acc@1 87.500 (86.474)	Acc@5 99.609 (99.411)
Max memory in training epoch: 59.035392
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 339826 ; 341994 ; 0.9936607074977923
[INFO] Storing checkpoint...
  83.59
Max memory: 91.598848
 24.519s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9672
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1434624
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.178 (0.178)	Data 0.262 (0.262)	Loss 0.6953 (0.6953)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [71][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.5616 (0.6579)	Acc@1 89.453 (86.653)	Acc@5 99.609 (99.513)
Epoch: [71][128/196]	Time 0.128 (0.120)	Data 0.000 (0.002)	Loss 0.7546 (0.6675)	Acc@1 82.812 (86.467)	Acc@5 99.219 (99.500)
Epoch: [71][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.7197 (0.6748)	Acc@1 85.156 (86.265)	Acc@5 99.219 (99.466)
Max memory in training epoch: 59.0059008
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.153 (0.153)	Data 0.264 (0.264)	Loss 0.6324 (0.6324)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [72][64/196]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.5779 (0.6631)	Acc@1 88.281 (86.623)	Acc@5 99.609 (99.507)
Epoch: [72][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.6893 (0.6763)	Acc@1 86.328 (86.304)	Acc@5 100.000 (99.479)
Epoch: [72][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.6462 (0.6737)	Acc@1 88.281 (86.474)	Acc@5 99.609 (99.488)
Max memory in training epoch: 58.8748288
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.144 (0.144)	Data 0.264 (0.264)	Loss 0.6608 (0.6608)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.7286 (0.6764)	Acc@1 82.422 (86.322)	Acc@5 99.609 (99.501)
Epoch: [73][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6669 (0.6746)	Acc@1 85.938 (86.489)	Acc@5 99.609 (99.540)
Epoch: [73][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6158 (0.6755)	Acc@1 89.453 (86.423)	Acc@5 98.438 (99.484)
Max memory in training epoch: 58.8748288
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.168 (0.168)	Data 0.265 (0.265)	Loss 0.6903 (0.6903)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.6624 (0.6525)	Acc@1 89.062 (87.350)	Acc@5 99.609 (99.459)
Epoch: [74][128/196]	Time 0.131 (0.121)	Data 0.000 (0.002)	Loss 0.7314 (0.6703)	Acc@1 82.422 (86.558)	Acc@5 99.609 (99.494)
Epoch: [74][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.6730 (0.6764)	Acc@1 85.156 (86.330)	Acc@5 99.609 (99.476)
Max memory in training epoch: 58.8748288
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.147 (0.147)	Data 0.276 (0.276)	Loss 0.6488 (0.6488)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.5704 (0.6796)	Acc@1 90.234 (86.340)	Acc@5 99.609 (99.501)
Epoch: [75][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7296 (0.6813)	Acc@1 83.984 (86.192)	Acc@5 100.000 (99.503)
Epoch: [75][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6288 (0.6725)	Acc@1 90.234 (86.559)	Acc@5 99.609 (99.496)
Max memory in training epoch: 58.8748288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 338668 ; 339826 ; 0.9965923737442103
[INFO] Storing checkpoint...
  82.39
Max memory: 91.5472384
 23.959s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7325
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1430528
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.195 (0.195)	Data 0.293 (0.293)	Loss 0.5934 (0.5934)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [76][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.6451 (0.6298)	Acc@1 87.500 (88.113)	Acc@5 100.000 (99.561)
Epoch: [76][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6718 (0.6569)	Acc@1 86.328 (87.040)	Acc@5 100.000 (99.522)
Epoch: [76][192/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.6975 (0.6577)	Acc@1 85.938 (87.032)	Acc@5 99.609 (99.541)
Max memory in training epoch: 58.5061888
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.166 (0.166)	Data 0.260 (0.260)	Loss 0.7129 (0.7129)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [77][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.7341 (0.6695)	Acc@1 84.375 (86.352)	Acc@5 99.219 (99.417)
Epoch: [77][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.6877 (0.6717)	Acc@1 84.766 (86.262)	Acc@5 99.609 (99.455)
Epoch: [77][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6772 (0.6778)	Acc@1 87.109 (86.243)	Acc@5 100.000 (99.456)
Max memory in training epoch: 58.45376
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.171 (0.171)	Data 0.271 (0.271)	Loss 0.6202 (0.6202)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.6378 (0.6729)	Acc@1 88.672 (86.562)	Acc@5 99.609 (99.483)
Epoch: [78][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.7232 (0.6771)	Acc@1 85.547 (86.389)	Acc@5 99.609 (99.470)
Epoch: [78][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.6474 (0.6741)	Acc@1 87.500 (86.437)	Acc@5 100.000 (99.472)
Max memory in training epoch: 58.45376
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.180 (0.180)	Data 0.292 (0.292)	Loss 0.6190 (0.6190)	Acc@1 91.016 (91.016)	Acc@5 99.219 (99.219)
Epoch: [79][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.6975 (0.6600)	Acc@1 84.766 (87.025)	Acc@5 99.219 (99.525)
Epoch: [79][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.6724 (0.6713)	Acc@1 85.547 (86.540)	Acc@5 99.609 (99.512)
Epoch: [79][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6680 (0.6710)	Acc@1 85.156 (86.535)	Acc@5 100.000 (99.514)
Max memory in training epoch: 58.45376
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.171 (0.171)	Data 0.274 (0.274)	Loss 0.6639 (0.6639)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [80][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.7508 (0.6705)	Acc@1 81.250 (86.767)	Acc@5 99.609 (99.369)
Epoch: [80][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.5929 (0.6679)	Acc@1 87.891 (86.716)	Acc@5 99.609 (99.422)
Epoch: [80][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6462 (0.6706)	Acc@1 87.109 (86.640)	Acc@5 99.609 (99.421)
Max memory in training epoch: 58.45376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 334916 ; 338668 ; 0.9889213034594352
[INFO] Storing checkpoint...
  81.01
Max memory: 90.7218944
 24.327s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5964
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1416192
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.185 (0.185)	Data 0.281 (0.281)	Loss 0.6436 (0.6436)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.6800 (0.6387)	Acc@1 87.109 (87.638)	Acc@5 99.609 (99.585)
Epoch: [81][128/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.6916 (0.6505)	Acc@1 86.328 (87.188)	Acc@5 100.000 (99.512)
Epoch: [81][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.7543 (0.6570)	Acc@1 82.812 (86.970)	Acc@5 98.828 (99.510)
Max memory in training epoch: 58.5004544
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.158 (0.158)	Data 0.277 (0.277)	Loss 0.6490 (0.6490)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.133 (0.123)	Data 0.000 (0.004)	Loss 0.6450 (0.6742)	Acc@1 85.938 (86.382)	Acc@5 99.609 (99.459)
Epoch: [82][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6590 (0.6617)	Acc@1 83.203 (86.740)	Acc@5 99.609 (99.482)
Epoch: [82][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.7268 (0.6690)	Acc@1 86.328 (86.490)	Acc@5 98.828 (99.470)
Max memory in training epoch: 58.4480256
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.142 (0.142)	Data 0.270 (0.270)	Loss 0.5940 (0.5940)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.6750 (0.6690)	Acc@1 87.500 (86.725)	Acc@5 98.828 (99.495)
Epoch: [83][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6421 (0.6719)	Acc@1 85.547 (86.676)	Acc@5 99.609 (99.455)
Epoch: [83][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.6048 (0.6703)	Acc@1 89.844 (86.638)	Acc@5 100.000 (99.470)
Max memory in training epoch: 58.4480256
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.165 (0.165)	Data 0.316 (0.316)	Loss 0.7416 (0.7416)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.125 (0.122)	Data 0.000 (0.005)	Loss 0.6323 (0.6663)	Acc@1 89.062 (86.593)	Acc@5 98.047 (99.453)
Epoch: [84][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.6782 (0.6666)	Acc@1 85.938 (86.743)	Acc@5 100.000 (99.488)
Epoch: [84][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.6334 (0.6668)	Acc@1 87.891 (86.761)	Acc@5 100.000 (99.508)
Max memory in training epoch: 58.4480256
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.168 (0.168)	Data 0.286 (0.286)	Loss 0.6337 (0.6337)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [85][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.6383 (0.6554)	Acc@1 89.062 (87.019)	Acc@5 99.609 (99.591)
Epoch: [85][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.7325 (0.6700)	Acc@1 86.719 (86.531)	Acc@5 98.828 (99.519)
Epoch: [85][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7224 (0.6679)	Acc@1 85.938 (86.719)	Acc@5 98.047 (99.500)
Max memory in training epoch: 58.4480256
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 334048 ; 334916 ; 0.9974083053661217
[INFO] Storing checkpoint...
  81.16
Max memory: 90.4128512
 24.263s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5336
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1412096
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.180 (0.180)	Data 0.270 (0.270)	Loss 0.5776 (0.5776)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.7056 (0.6315)	Acc@1 85.547 (87.662)	Acc@5 99.609 (99.639)
Epoch: [86][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6675 (0.6582)	Acc@1 88.672 (86.701)	Acc@5 98.828 (99.576)
Epoch: [86][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6703 (0.6691)	Acc@1 87.500 (86.377)	Acc@5 100.000 (99.543)
Max memory in training epoch: 58.236672
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.178 (0.178)	Data 0.281 (0.281)	Loss 0.7789 (0.7789)	Acc@1 83.203 (83.203)	Acc@5 98.828 (98.828)
Epoch: [87][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.6855 (0.6514)	Acc@1 86.328 (87.308)	Acc@5 99.219 (99.519)
Epoch: [87][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6313 (0.6555)	Acc@1 87.109 (86.949)	Acc@5 99.609 (99.540)
Epoch: [87][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7430 (0.6591)	Acc@1 83.594 (86.794)	Acc@5 99.609 (99.522)
Max memory in training epoch: 58.3415296
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.146 (0.146)	Data 0.296 (0.296)	Loss 0.6675 (0.6675)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.6652 (0.6791)	Acc@1 89.062 (86.190)	Acc@5 100.000 (99.453)
Epoch: [88][128/196]	Time 0.153 (0.121)	Data 0.000 (0.002)	Loss 0.6247 (0.6766)	Acc@1 85.547 (86.328)	Acc@5 100.000 (99.446)
Epoch: [88][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7192 (0.6737)	Acc@1 86.328 (86.476)	Acc@5 100.000 (99.415)
Max memory in training epoch: 58.3415296
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.169 (0.169)	Data 0.302 (0.302)	Loss 0.5912 (0.5912)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [89][64/196]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.5565 (0.6628)	Acc@1 91.016 (86.911)	Acc@5 99.609 (99.447)
Epoch: [89][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.6433 (0.6680)	Acc@1 87.891 (86.713)	Acc@5 99.219 (99.476)
Epoch: [89][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.5922 (0.6691)	Acc@1 87.500 (86.664)	Acc@5 100.000 (99.498)
Max memory in training epoch: 58.3415296
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.157 (0.157)	Data 0.271 (0.271)	Loss 0.6942 (0.6942)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [90][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.5765 (0.6515)	Acc@1 88.672 (87.314)	Acc@5 99.219 (99.555)
Epoch: [90][128/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.7027 (0.6608)	Acc@1 85.547 (86.928)	Acc@5 99.609 (99.506)
Epoch: [90][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6188 (0.6621)	Acc@1 88.281 (86.931)	Acc@5 98.828 (99.516)
Max memory in training epoch: 58.3415296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 330006 ; 334048 ; 0.9878999425232302
[INFO] Storing checkpoint...
  78.42
Max memory: 90.3788544
 24.068s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6983
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1396736
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.169 (0.169)	Data 0.271 (0.271)	Loss 0.6893 (0.6893)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.5968 (0.6307)	Acc@1 89.844 (87.656)	Acc@5 100.000 (99.561)
Epoch: [91][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6851 (0.6520)	Acc@1 87.891 (87.009)	Acc@5 99.219 (99.491)
Epoch: [91][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6816 (0.6622)	Acc@1 87.500 (86.705)	Acc@5 99.609 (99.476)
Max memory in training epoch: 58.230528
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.184 (0.184)	Data 0.264 (0.264)	Loss 0.6112 (0.6112)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.7074 (0.6448)	Acc@1 87.109 (87.266)	Acc@5 99.609 (99.471)
Epoch: [92][128/196]	Time 0.137 (0.123)	Data 0.000 (0.002)	Loss 0.8432 (0.6546)	Acc@1 81.250 (87.103)	Acc@5 99.219 (99.464)
Epoch: [92][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6109 (0.6631)	Acc@1 89.453 (86.840)	Acc@5 99.609 (99.464)
Max memory in training epoch: 57.9159552
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.155 (0.155)	Data 0.294 (0.294)	Loss 0.6202 (0.6202)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [93][64/196]	Time 0.136 (0.123)	Data 0.000 (0.005)	Loss 0.4891 (0.5597)	Acc@1 92.188 (90.361)	Acc@5 100.000 (99.694)
Epoch: [93][128/196]	Time 0.132 (0.122)	Data 0.000 (0.002)	Loss 0.5969 (0.5434)	Acc@1 89.453 (90.901)	Acc@5 99.609 (99.743)
Epoch: [93][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.4380 (0.5259)	Acc@1 93.750 (91.469)	Acc@5 100.000 (99.783)
Max memory in training epoch: 57.9159552
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.159 (0.159)	Data 0.298 (0.298)	Loss 0.4685 (0.4685)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.4108 (0.4762)	Acc@1 95.312 (93.287)	Acc@5 100.000 (99.850)
Epoch: [94][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.4474 (0.4733)	Acc@1 94.141 (93.217)	Acc@5 99.609 (99.843)
Epoch: [94][192/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.4569 (0.4720)	Acc@1 92.188 (93.163)	Acc@5 100.000 (99.842)
Max memory in training epoch: 57.9159552
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.157 (0.157)	Data 0.300 (0.300)	Loss 0.4341 (0.4341)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.4341 (0.4453)	Acc@1 94.141 (93.936)	Acc@5 99.609 (99.856)
Epoch: [95][128/196]	Time 0.126 (0.123)	Data 0.000 (0.003)	Loss 0.4820 (0.4536)	Acc@1 92.578 (93.602)	Acc@5 100.000 (99.849)
Epoch: [95][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.4274 (0.4500)	Acc@1 94.531 (93.655)	Acc@5 100.000 (99.860)
Max memory in training epoch: 57.9159552
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 328852 ; 330006 ; 0.9965030938831415
[INFO] Storing checkpoint...
  90.97
Max memory: 89.9269632
 24.519s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6325
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1391616
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.176 (0.176)	Data 0.289 (0.289)	Loss 0.4014 (0.4014)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.3787 (0.4334)	Acc@1 95.703 (94.291)	Acc@5 100.000 (99.874)
Epoch: [96][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.4787 (0.4328)	Acc@1 92.578 (94.241)	Acc@5 100.000 (99.867)
Epoch: [96][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.4053 (0.4334)	Acc@1 95.312 (94.169)	Acc@5 100.000 (99.875)
Max memory in training epoch: 58.22848
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.165 (0.165)	Data 0.306 (0.306)	Loss 0.4710 (0.4710)	Acc@1 94.141 (94.141)	Acc@5 98.828 (98.828)
Epoch: [97][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.4257 (0.4187)	Acc@1 93.359 (94.513)	Acc@5 99.609 (99.826)
Epoch: [97][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.4467 (0.4179)	Acc@1 91.406 (94.459)	Acc@5 100.000 (99.858)
Epoch: [97][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.4089 (0.4176)	Acc@1 94.141 (94.513)	Acc@5 100.000 (99.875)
Max memory in training epoch: 57.9139072
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.175 (0.175)	Data 0.273 (0.273)	Loss 0.3970 (0.3970)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3583 (0.4077)	Acc@1 97.656 (94.796)	Acc@5 100.000 (99.928)
Epoch: [98][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.4252 (0.4044)	Acc@1 94.141 (94.801)	Acc@5 100.000 (99.912)
Epoch: [98][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3599 (0.4065)	Acc@1 96.875 (94.683)	Acc@5 100.000 (99.907)
Max memory in training epoch: 57.9139072
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.174 (0.174)	Data 0.267 (0.267)	Loss 0.3606 (0.3606)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.136 (0.123)	Data 0.000 (0.004)	Loss 0.4184 (0.4000)	Acc@1 93.750 (94.904)	Acc@5 99.609 (99.916)
Epoch: [99][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.3974 (0.3967)	Acc@1 96.094 (95.019)	Acc@5 99.609 (99.906)
Epoch: [99][192/196]	Time 0.132 (0.121)	Data 0.000 (0.002)	Loss 0.4486 (0.3970)	Acc@1 94.922 (94.912)	Acc@5 100.000 (99.909)
Max memory in training epoch: 57.9139072
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.163 (0.163)	Data 0.340 (0.340)	Loss 0.3762 (0.3762)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.3887 (0.3879)	Acc@1 96.094 (95.138)	Acc@5 100.000 (99.916)
Epoch: [100][128/196]	Time 0.119 (0.122)	Data 0.000 (0.003)	Loss 0.4421 (0.3861)	Acc@1 92.969 (95.237)	Acc@5 99.609 (99.949)
Epoch: [100][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.4110 (0.3870)	Acc@1 94.141 (95.142)	Acc@5 100.000 (99.925)
Max memory in training epoch: 57.9139072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv28.weight

 RM:  module.conv29.weight
numoFStages: 3
Count: 327280 ; 328852 ; 0.9952197341053118
[INFO] Storing checkpoint...
  91.19
Max memory: 89.8418688
 24.261s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7112
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1380352
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.170 (0.170)	Data 0.288 (0.288)	Loss 0.3826 (0.3826)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.121 (0.117)	Data 0.000 (0.005)	Loss 0.4262 (0.3703)	Acc@1 94.141 (95.781)	Acc@5 99.609 (99.928)
Epoch: [101][128/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.4432 (0.3720)	Acc@1 92.188 (95.621)	Acc@5 99.609 (99.927)
Epoch: [101][192/196]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.4278 (0.3750)	Acc@1 94.141 (95.398)	Acc@5 100.000 (99.917)
Max memory in training epoch: 57.1632128
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.154 (0.154)	Data 0.297 (0.297)	Loss 0.3129 (0.3129)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.114 (0.116)	Data 0.000 (0.005)	Loss 0.3428 (0.3682)	Acc@1 96.484 (95.493)	Acc@5 99.609 (99.910)
Epoch: [102][128/196]	Time 0.115 (0.115)	Data 0.000 (0.002)	Loss 0.3266 (0.3660)	Acc@1 97.266 (95.549)	Acc@5 100.000 (99.927)
Epoch: [102][192/196]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.3753 (0.3679)	Acc@1 94.531 (95.511)	Acc@5 100.000 (99.925)
Max memory in training epoch: 56.84864
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.162 (0.162)	Data 0.294 (0.294)	Loss 0.3318 (0.3318)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.115 (0.116)	Data 0.000 (0.005)	Loss 0.3269 (0.3608)	Acc@1 97.656 (95.721)	Acc@5 100.000 (99.928)
Epoch: [103][128/196]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3767 (0.3589)	Acc@1 94.922 (95.709)	Acc@5 99.609 (99.924)
Epoch: [103][192/196]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3541 (0.3585)	Acc@1 96.875 (95.719)	Acc@5 100.000 (99.929)
Max memory in training epoch: 56.84864
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.146 (0.146)	Data 0.271 (0.271)	Loss 0.3523 (0.3523)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.112 (0.116)	Data 0.000 (0.004)	Loss 0.3521 (0.3467)	Acc@1 96.094 (95.889)	Acc@5 100.000 (99.952)
Epoch: [104][128/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.3463 (0.3497)	Acc@1 95.703 (95.797)	Acc@5 100.000 (99.927)
Epoch: [104][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.3213 (0.3532)	Acc@1 95.312 (95.659)	Acc@5 100.000 (99.931)
Max memory in training epoch: 56.84864
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.162 (0.162)	Data 0.269 (0.269)	Loss 0.4018 (0.4018)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [105][64/196]	Time 0.119 (0.117)	Data 0.000 (0.004)	Loss 0.2874 (0.3537)	Acc@1 98.828 (95.649)	Acc@5 100.000 (99.952)
Epoch: [105][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3227 (0.3506)	Acc@1 95.703 (95.721)	Acc@5 100.000 (99.958)
Epoch: [105][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.3244 (0.3497)	Acc@1 96.875 (95.697)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.84864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 326702 ; 327280 ; 0.9982339281349303
[INFO] Storing checkpoint...
  91.14
Max memory: 88.131072
 23.222s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2809
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1378304
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.181 (0.181)	Data 0.285 (0.285)	Loss 0.3796 (0.3796)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [106][64/196]	Time 0.118 (0.118)	Data 0.000 (0.005)	Loss 0.3605 (0.3350)	Acc@1 94.531 (96.172)	Acc@5 99.609 (99.916)
Epoch: [106][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.3264 (0.3382)	Acc@1 95.312 (95.957)	Acc@5 100.000 (99.942)
Epoch: [106][192/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.3387 (0.3398)	Acc@1 96.094 (95.908)	Acc@5 100.000 (99.927)
Max memory in training epoch: 56.9002496
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.159 (0.159)	Data 0.269 (0.269)	Loss 0.2965 (0.2965)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.113 (0.116)	Data 0.000 (0.004)	Loss 0.3046 (0.3285)	Acc@1 98.047 (96.118)	Acc@5 100.000 (99.940)
Epoch: [107][128/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3566 (0.3290)	Acc@1 94.531 (96.130)	Acc@5 100.000 (99.949)
Epoch: [107][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3448 (0.3346)	Acc@1 94.922 (95.885)	Acc@5 100.000 (99.951)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.155 (0.155)	Data 0.303 (0.303)	Loss 0.3398 (0.3398)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.113 (0.116)	Data 0.000 (0.005)	Loss 0.2780 (0.3238)	Acc@1 98.047 (96.142)	Acc@5 100.000 (99.940)
Epoch: [108][128/196]	Time 0.119 (0.117)	Data 0.000 (0.003)	Loss 0.2957 (0.3272)	Acc@1 98.047 (96.073)	Acc@5 100.000 (99.933)
Epoch: [108][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3192 (0.3287)	Acc@1 96.094 (96.017)	Acc@5 100.000 (99.939)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.165 (0.165)	Data 0.294 (0.294)	Loss 0.3021 (0.3021)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.111 (0.118)	Data 0.000 (0.005)	Loss 0.3006 (0.3241)	Acc@1 97.266 (96.052)	Acc@5 100.000 (99.940)
Epoch: [109][128/196]	Time 0.117 (0.117)	Data 0.000 (0.002)	Loss 0.3008 (0.3217)	Acc@1 97.656 (96.103)	Acc@5 100.000 (99.945)
Epoch: [109][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.3240 (0.3236)	Acc@1 96.484 (96.025)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.151 (0.151)	Data 0.299 (0.299)	Loss 0.3607 (0.3607)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.118 (0.119)	Data 0.000 (0.005)	Loss 0.3349 (0.3234)	Acc@1 95.312 (95.956)	Acc@5 100.000 (99.946)
Epoch: [110][128/196]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.3258 (0.3215)	Acc@1 95.312 (96.021)	Acc@5 99.609 (99.955)
Epoch: [110][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3872 (0.3218)	Acc@1 94.141 (96.001)	Acc@5 100.000 (99.951)
Max memory in training epoch: 56.8478208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.62
Max memory: 88.2516992
 23.504s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3070
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1378304
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.180 (0.180)	Data 0.265 (0.265)	Loss 0.2903 (0.2903)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.115 (0.118)	Data 0.000 (0.004)	Loss 0.3267 (0.3061)	Acc@1 94.531 (96.496)	Acc@5 100.000 (99.976)
Epoch: [111][128/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.3548 (0.3123)	Acc@1 94.922 (96.309)	Acc@5 100.000 (99.961)
Epoch: [111][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.3104 (0.3164)	Acc@1 96.875 (96.122)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.9002496
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.139 (0.139)	Data 0.288 (0.288)	Loss 0.3211 (0.3211)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.111 (0.116)	Data 0.000 (0.005)	Loss 0.3478 (0.3142)	Acc@1 94.531 (96.094)	Acc@5 100.000 (99.982)
Epoch: [112][128/196]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.3301 (0.3134)	Acc@1 94.531 (96.197)	Acc@5 100.000 (99.964)
Epoch: [112][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.3186 (0.3160)	Acc@1 96.484 (96.063)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.166 (0.166)	Data 0.282 (0.282)	Loss 0.2902 (0.2902)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.117 (0.118)	Data 0.000 (0.005)	Loss 0.2722 (0.3047)	Acc@1 98.047 (96.442)	Acc@5 100.000 (99.976)
Epoch: [113][128/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2682 (0.3100)	Acc@1 98.828 (96.197)	Acc@5 100.000 (99.961)
Epoch: [113][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3099 (0.3143)	Acc@1 96.875 (96.007)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.166 (0.166)	Data 0.306 (0.306)	Loss 0.3533 (0.3533)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.119 (0.117)	Data 0.000 (0.005)	Loss 0.3405 (0.3045)	Acc@1 94.922 (96.298)	Acc@5 100.000 (99.958)
Epoch: [114][128/196]	Time 0.114 (0.117)	Data 0.000 (0.003)	Loss 0.2967 (0.3071)	Acc@1 96.094 (96.185)	Acc@5 100.000 (99.955)
Epoch: [114][192/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.3593 (0.3093)	Acc@1 94.141 (96.071)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.162 (0.162)	Data 0.280 (0.280)	Loss 0.2640 (0.2640)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.114 (0.118)	Data 0.000 (0.005)	Loss 0.3299 (0.3036)	Acc@1 94.531 (96.160)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2791 (0.3044)	Acc@1 96.094 (96.166)	Acc@5 100.000 (99.961)
Epoch: [115][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3676 (0.3065)	Acc@1 94.531 (96.156)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.8478208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.74
Max memory: 88.2516992
 23.448s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3465
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1378304
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.184 (0.184)	Data 0.291 (0.291)	Loss 0.3000 (0.3000)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.114 (0.118)	Data 0.000 (0.005)	Loss 0.2950 (0.2932)	Acc@1 96.484 (96.635)	Acc@5 100.000 (99.976)
Epoch: [116][128/196]	Time 0.122 (0.117)	Data 0.000 (0.002)	Loss 0.2673 (0.3016)	Acc@1 98.047 (96.275)	Acc@5 100.000 (99.964)
Epoch: [116][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.3325 (0.3062)	Acc@1 94.141 (96.037)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.9002496
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.141 (0.141)	Data 0.263 (0.263)	Loss 0.3019 (0.3019)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.114 (0.116)	Data 0.000 (0.004)	Loss 0.2899 (0.2954)	Acc@1 96.484 (96.454)	Acc@5 100.000 (99.970)
Epoch: [117][128/196]	Time 0.125 (0.116)	Data 0.000 (0.002)	Loss 0.3348 (0.2996)	Acc@1 95.312 (96.278)	Acc@5 100.000 (99.979)
Epoch: [117][192/196]	Time 0.118 (0.116)	Data 0.000 (0.002)	Loss 0.3315 (0.3013)	Acc@1 94.531 (96.209)	Acc@5 100.000 (99.982)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.169 (0.169)	Data 0.264 (0.264)	Loss 0.2786 (0.2786)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.119 (0.116)	Data 0.000 (0.004)	Loss 0.2586 (0.2993)	Acc@1 97.656 (96.232)	Acc@5 100.000 (99.982)
Epoch: [118][128/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.2971 (0.3035)	Acc@1 96.094 (96.009)	Acc@5 100.000 (99.970)
Epoch: [118][192/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3183 (0.3045)	Acc@1 94.531 (96.023)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.154 (0.154)	Data 0.301 (0.301)	Loss 0.3037 (0.3037)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.119 (0.117)	Data 0.000 (0.005)	Loss 0.2837 (0.3010)	Acc@1 96.484 (96.010)	Acc@5 100.000 (99.958)
Epoch: [119][128/196]	Time 0.120 (0.117)	Data 0.000 (0.003)	Loss 0.3277 (0.3016)	Acc@1 95.312 (96.003)	Acc@5 100.000 (99.955)
Epoch: [119][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3265 (0.3045)	Acc@1 95.312 (95.910)	Acc@5 99.609 (99.964)
Max memory in training epoch: 56.8478208
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.161 (0.161)	Data 0.278 (0.278)	Loss 0.2537 (0.2537)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.111 (0.119)	Data 0.000 (0.004)	Loss 0.3351 (0.2995)	Acc@1 94.922 (96.130)	Acc@5 99.609 (99.970)
Epoch: [120][128/196]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.2826 (0.3028)	Acc@1 98.047 (95.988)	Acc@5 99.609 (99.964)
Epoch: [120][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3094 (0.3058)	Acc@1 96.484 (95.810)	Acc@5 99.609 (99.964)
Max memory in training epoch: 56.8478208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 326124 ; 326702 ; 0.9982308036069568
[INFO] Storing checkpoint...
  90.09
Max memory: 88.2516992
 23.246s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2938
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1375232
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.189 (0.189)	Data 0.268 (0.268)	Loss 0.2781 (0.2781)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.115 (0.116)	Data 0.000 (0.004)	Loss 0.2630 (0.2855)	Acc@1 97.266 (96.749)	Acc@5 100.000 (99.982)
Epoch: [121][128/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.3640 (0.2939)	Acc@1 93.750 (96.281)	Acc@5 100.000 (99.976)
Epoch: [121][192/196]	Time 0.131 (0.116)	Data 0.000 (0.002)	Loss 0.2949 (0.2976)	Acc@1 95.312 (96.057)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.6368768
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.160 (0.160)	Data 0.264 (0.264)	Loss 0.2886 (0.2886)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.115 (0.116)	Data 0.000 (0.004)	Loss 0.3176 (0.2893)	Acc@1 95.703 (96.334)	Acc@5 100.000 (99.988)
Epoch: [122][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.2499 (0.2982)	Acc@1 97.266 (95.967)	Acc@5 100.000 (99.979)
Epoch: [122][192/196]	Time 0.112 (0.115)	Data 0.000 (0.002)	Loss 0.2669 (0.3005)	Acc@1 97.266 (95.922)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.139 (0.139)	Data 0.289 (0.289)	Loss 0.2783 (0.2783)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.124 (0.117)	Data 0.000 (0.005)	Loss 0.2932 (0.3034)	Acc@1 96.484 (95.889)	Acc@5 100.000 (99.964)
Epoch: [123][128/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3492 (0.3007)	Acc@1 95.703 (95.957)	Acc@5 99.219 (99.952)
Epoch: [123][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2934 (0.3018)	Acc@1 94.922 (95.916)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.166 (0.166)	Data 0.285 (0.285)	Loss 0.3182 (0.3182)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.117 (0.116)	Data 0.000 (0.005)	Loss 0.3229 (0.2924)	Acc@1 94.922 (96.406)	Acc@5 99.609 (99.958)
Epoch: [124][128/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.3198 (0.2927)	Acc@1 94.922 (96.227)	Acc@5 100.000 (99.970)
Epoch: [124][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3003 (0.2977)	Acc@1 95.703 (95.989)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.165 (0.165)	Data 0.277 (0.277)	Loss 0.3224 (0.3224)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.128 (0.118)	Data 0.000 (0.004)	Loss 0.2997 (0.3025)	Acc@1 95.312 (95.913)	Acc@5 100.000 (99.976)
Epoch: [125][128/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.2542 (0.3014)	Acc@1 97.266 (95.870)	Acc@5 100.000 (99.973)
Epoch: [125][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3182 (0.3031)	Acc@1 94.922 (95.768)	Acc@5 99.609 (99.966)
Max memory in training epoch: 56.846592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.22
Max memory: 88.0582656
 23.423s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5825
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1375232
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.203 (0.203)	Data 0.262 (0.262)	Loss 0.2857 (0.2857)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.112 (0.118)	Data 0.000 (0.004)	Loss 0.2908 (0.2836)	Acc@1 96.484 (96.364)	Acc@5 100.000 (99.970)
Epoch: [126][128/196]	Time 0.122 (0.117)	Data 0.000 (0.002)	Loss 0.3320 (0.2902)	Acc@1 93.359 (96.166)	Acc@5 99.609 (99.964)
Epoch: [126][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2984 (0.2942)	Acc@1 94.531 (95.944)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.6368768
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.160 (0.160)	Data 0.264 (0.264)	Loss 0.3290 (0.3290)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [127][64/196]	Time 0.112 (0.116)	Data 0.000 (0.004)	Loss 0.3442 (0.2901)	Acc@1 93.750 (96.040)	Acc@5 100.000 (99.982)
Epoch: [127][128/196]	Time 0.161 (0.117)	Data 0.000 (0.002)	Loss 0.2719 (0.2934)	Acc@1 96.484 (95.945)	Acc@5 100.000 (99.976)
Epoch: [127][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3009 (0.2979)	Acc@1 96.094 (95.776)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.157 (0.157)	Data 0.261 (0.261)	Loss 0.3175 (0.3175)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.110 (0.116)	Data 0.000 (0.004)	Loss 0.2964 (0.3068)	Acc@1 96.484 (95.613)	Acc@5 100.000 (99.970)
Epoch: [128][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2944 (0.2999)	Acc@1 95.703 (95.724)	Acc@5 100.000 (99.964)
Epoch: [128][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.2724 (0.3062)	Acc@1 96.875 (95.446)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.133 (0.133)	Data 0.334 (0.334)	Loss 0.2953 (0.2953)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.123 (0.117)	Data 0.000 (0.005)	Loss 0.3474 (0.2933)	Acc@1 93.750 (96.058)	Acc@5 100.000 (99.976)
Epoch: [129][128/196]	Time 0.117 (0.116)	Data 0.000 (0.003)	Loss 0.3110 (0.2942)	Acc@1 96.094 (96.027)	Acc@5 100.000 (99.970)
Epoch: [129][192/196]	Time 0.120 (0.116)	Data 0.000 (0.002)	Loss 0.3197 (0.2997)	Acc@1 94.141 (95.754)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.142 (0.142)	Data 0.289 (0.289)	Loss 0.2974 (0.2974)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.114 (0.117)	Data 0.000 (0.005)	Loss 0.3222 (0.2926)	Acc@1 96.875 (96.058)	Acc@5 99.609 (99.946)
Epoch: [130][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.3045 (0.2955)	Acc@1 95.703 (95.897)	Acc@5 100.000 (99.952)
Epoch: [130][192/196]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.2587 (0.2974)	Acc@1 96.875 (95.865)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.846592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.98
Max memory: 88.0582656
 23.173s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1881
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1375232
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.183 (0.183)	Data 0.264 (0.264)	Loss 0.2798 (0.2798)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.113 (0.118)	Data 0.000 (0.004)	Loss 0.3516 (0.2805)	Acc@1 93.750 (96.418)	Acc@5 100.000 (99.976)
Epoch: [131][128/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3392 (0.2903)	Acc@1 94.531 (96.042)	Acc@5 100.000 (99.958)
Epoch: [131][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3085 (0.2945)	Acc@1 94.922 (95.891)	Acc@5 99.609 (99.955)
Max memory in training epoch: 56.6368768
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.160 (0.160)	Data 0.288 (0.288)	Loss 0.3198 (0.3198)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.114 (0.115)	Data 0.000 (0.005)	Loss 0.3243 (0.3001)	Acc@1 94.922 (95.703)	Acc@5 100.000 (99.976)
Epoch: [132][128/196]	Time 0.120 (0.115)	Data 0.000 (0.002)	Loss 0.2905 (0.2987)	Acc@1 95.703 (95.700)	Acc@5 100.000 (99.970)
Epoch: [132][192/196]	Time 0.124 (0.115)	Data 0.000 (0.002)	Loss 0.2822 (0.2999)	Acc@1 97.266 (95.721)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.142 (0.142)	Data 0.286 (0.286)	Loss 0.2551 (0.2551)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.109 (0.117)	Data 0.000 (0.005)	Loss 0.2987 (0.2903)	Acc@1 97.656 (96.226)	Acc@5 100.000 (99.970)
Epoch: [133][128/196]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.3826 (0.2924)	Acc@1 93.359 (95.970)	Acc@5 100.000 (99.955)
Epoch: [133][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3063 (0.2962)	Acc@1 95.312 (95.812)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.156 (0.156)	Data 0.287 (0.287)	Loss 0.2576 (0.2576)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.108 (0.116)	Data 0.000 (0.005)	Loss 0.2863 (0.2922)	Acc@1 95.312 (96.082)	Acc@5 100.000 (99.964)
Epoch: [134][128/196]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.2957 (0.2959)	Acc@1 94.922 (95.779)	Acc@5 100.000 (99.964)
Epoch: [134][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.3689 (0.2992)	Acc@1 94.531 (95.612)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.161 (0.161)	Data 0.256 (0.256)	Loss 0.3108 (0.3108)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.117 (0.117)	Data 0.000 (0.004)	Loss 0.3061 (0.2907)	Acc@1 95.312 (95.823)	Acc@5 100.000 (99.970)
Epoch: [135][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.3263 (0.2976)	Acc@1 94.531 (95.531)	Acc@5 99.609 (99.955)
Epoch: [135][192/196]	Time 0.116 (0.117)	Data 0.000 (0.001)	Loss 0.3397 (0.3019)	Acc@1 93.359 (95.462)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.846592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.65
Max memory: 88.0582656
 23.211s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3334
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1375232
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.199 (0.199)	Data 0.254 (0.254)	Loss 0.2802 (0.2802)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.113 (0.115)	Data 0.000 (0.004)	Loss 0.2706 (0.2869)	Acc@1 96.875 (96.070)	Acc@5 100.000 (99.964)
Epoch: [136][128/196]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.3079 (0.2898)	Acc@1 96.094 (95.976)	Acc@5 100.000 (99.970)
Epoch: [136][192/196]	Time 0.111 (0.116)	Data 0.000 (0.001)	Loss 0.3867 (0.2906)	Acc@1 92.578 (95.950)	Acc@5 99.609 (99.964)
Max memory in training epoch: 56.6368768
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.156 (0.156)	Data 0.301 (0.301)	Loss 0.3735 (0.3735)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.113 (0.116)	Data 0.000 (0.005)	Loss 0.2708 (0.3072)	Acc@1 96.484 (95.355)	Acc@5 100.000 (99.964)
Epoch: [137][128/196]	Time 0.119 (0.116)	Data 0.000 (0.003)	Loss 0.2851 (0.3062)	Acc@1 95.703 (95.485)	Acc@5 100.000 (99.952)
Epoch: [137][192/196]	Time 0.112 (0.116)	Data 0.000 (0.002)	Loss 0.2990 (0.3025)	Acc@1 95.703 (95.576)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.156 (0.156)	Data 0.313 (0.313)	Loss 0.2831 (0.2831)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.119 (0.117)	Data 0.000 (0.005)	Loss 0.3380 (0.2828)	Acc@1 94.141 (96.244)	Acc@5 100.000 (99.964)
Epoch: [138][128/196]	Time 0.113 (0.116)	Data 0.000 (0.003)	Loss 0.3478 (0.2903)	Acc@1 93.750 (96.006)	Acc@5 100.000 (99.970)
Epoch: [138][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.3673 (0.2962)	Acc@1 93.750 (95.764)	Acc@5 99.609 (99.966)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.168 (0.168)	Data 0.274 (0.274)	Loss 0.2609 (0.2609)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.295 (0.156)	Data 0.000 (0.004)	Loss 0.3297 (0.2873)	Acc@1 94.141 (96.082)	Acc@5 100.000 (99.940)
Epoch: [139][128/196]	Time 0.142 (0.163)	Data 0.000 (0.002)	Loss 0.3026 (0.2894)	Acc@1 95.312 (96.018)	Acc@5 100.000 (99.955)
Epoch: [139][192/196]	Time 0.134 (0.157)	Data 0.000 (0.002)	Loss 0.2765 (0.2917)	Acc@1 97.266 (95.912)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.846592
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.277 (0.277)	Data 0.435 (0.435)	Loss 0.2967 (0.2967)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.150 (0.150)	Data 0.000 (0.007)	Loss 0.3169 (0.2876)	Acc@1 94.141 (96.004)	Acc@5 100.000 (99.982)
Epoch: [140][128/196]	Time 0.134 (0.146)	Data 0.000 (0.004)	Loss 0.3088 (0.2955)	Acc@1 95.312 (95.676)	Acc@5 100.000 (99.967)
Epoch: [140][192/196]	Time 0.140 (0.145)	Data 0.000 (0.002)	Loss 0.3463 (0.2969)	Acc@1 94.531 (95.653)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.846592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 325690 ; 326124 ; 0.9986692178435197
[INFO] Storing checkpoint...
  89.14
Max memory: 88.0582656
 28.871s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4727
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1373696
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.262 (0.262)	Data 0.448 (0.448)	Loss 0.2650 (0.2650)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.137 (0.147)	Data 0.000 (0.007)	Loss 0.2926 (0.2808)	Acc@1 94.922 (96.154)	Acc@5 100.000 (99.976)
Epoch: [141][128/196]	Time 0.145 (0.145)	Data 0.000 (0.004)	Loss 0.3106 (0.2900)	Acc@1 95.703 (95.852)	Acc@5 100.000 (99.973)
Epoch: [141][192/196]	Time 0.151 (0.144)	Data 0.000 (0.003)	Loss 0.3218 (0.2938)	Acc@1 95.312 (95.778)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.6362624
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.182 (0.182)	Data 0.457 (0.457)	Loss 0.2726 (0.2726)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.138 (0.139)	Data 0.000 (0.007)	Loss 0.3772 (0.2900)	Acc@1 92.188 (95.907)	Acc@5 100.000 (99.934)
Epoch: [142][128/196]	Time 0.146 (0.141)	Data 0.000 (0.004)	Loss 0.3559 (0.2967)	Acc@1 92.969 (95.576)	Acc@5 100.000 (99.942)
Epoch: [142][192/196]	Time 0.135 (0.141)	Data 0.000 (0.003)	Loss 0.3490 (0.2989)	Acc@1 94.531 (95.480)	Acc@5 100.000 (99.951)
Max memory in training epoch: 56.8459776
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.202 (0.202)	Data 0.462 (0.462)	Loss 0.2740 (0.2740)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.139 (0.143)	Data 0.000 (0.007)	Loss 0.2983 (0.2830)	Acc@1 95.312 (96.148)	Acc@5 100.000 (99.958)
Epoch: [143][128/196]	Time 0.138 (0.144)	Data 0.000 (0.004)	Loss 0.2670 (0.2964)	Acc@1 95.703 (95.688)	Acc@5 100.000 (99.958)
Epoch: [143][192/196]	Time 0.135 (0.142)	Data 0.000 (0.003)	Loss 0.2994 (0.2970)	Acc@1 94.531 (95.630)	Acc@5 99.609 (99.964)
Max memory in training epoch: 56.8459776
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.225 (0.225)	Data 0.435 (0.435)	Loss 0.2477 (0.2477)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.146 (0.135)	Data 0.000 (0.007)	Loss 0.3004 (0.2824)	Acc@1 94.922 (96.070)	Acc@5 100.000 (99.970)
Epoch: [144][128/196]	Time 0.139 (0.140)	Data 0.000 (0.004)	Loss 0.3456 (0.2911)	Acc@1 95.312 (95.773)	Acc@5 100.000 (99.970)
Epoch: [144][192/196]	Time 0.138 (0.141)	Data 0.000 (0.002)	Loss 0.3092 (0.2989)	Acc@1 94.531 (95.543)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.8459776
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.193 (0.193)	Data 0.508 (0.508)	Loss 0.3346 (0.3346)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.149 (0.158)	Data 0.000 (0.008)	Loss 0.3416 (0.3090)	Acc@1 93.750 (95.192)	Acc@5 100.000 (99.958)
Epoch: [145][128/196]	Time 0.143 (0.151)	Data 0.000 (0.004)	Loss 0.3067 (0.3063)	Acc@1 95.703 (95.346)	Acc@5 100.000 (99.958)
Epoch: [145][192/196]	Time 0.147 (0.152)	Data 0.000 (0.003)	Loss 0.2637 (0.3039)	Acc@1 97.266 (95.393)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.51
Max memory: 88.2314752
 30.424s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4474
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1373696
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.222 (0.222)	Data 0.469 (0.469)	Loss 0.2775 (0.2775)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.167 (0.155)	Data 0.000 (0.007)	Loss 0.2870 (0.2820)	Acc@1 96.484 (96.196)	Acc@5 100.000 (99.952)
Epoch: [146][128/196]	Time 0.140 (0.150)	Data 0.000 (0.004)	Loss 0.3020 (0.2879)	Acc@1 94.922 (95.933)	Acc@5 100.000 (99.961)
Epoch: [146][192/196]	Time 0.132 (0.147)	Data 0.000 (0.003)	Loss 0.2672 (0.2933)	Acc@1 96.484 (95.760)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.6362624
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.166 (0.166)	Data 0.338 (0.338)	Loss 0.2893 (0.2893)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.151 (0.141)	Data 0.000 (0.005)	Loss 0.3168 (0.2947)	Acc@1 94.922 (95.745)	Acc@5 100.000 (99.958)
Epoch: [147][128/196]	Time 0.148 (0.143)	Data 0.000 (0.003)	Loss 0.3022 (0.2963)	Acc@1 96.484 (95.652)	Acc@5 99.609 (99.961)
Epoch: [147][192/196]	Time 0.136 (0.142)	Data 0.000 (0.002)	Loss 0.3483 (0.2978)	Acc@1 94.531 (95.653)	Acc@5 99.219 (99.964)
Max memory in training epoch: 56.8459776
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.185 (0.185)	Data 0.402 (0.402)	Loss 0.2713 (0.2713)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.137 (0.146)	Data 0.000 (0.006)	Loss 0.3370 (0.2946)	Acc@1 94.141 (95.673)	Acc@5 100.000 (100.000)
Epoch: [148][128/196]	Time 0.122 (0.144)	Data 0.000 (0.003)	Loss 0.3483 (0.2928)	Acc@1 93.750 (95.785)	Acc@5 100.000 (99.979)
Epoch: [148][192/196]	Time 0.131 (0.143)	Data 0.000 (0.002)	Loss 0.3441 (0.2953)	Acc@1 95.703 (95.679)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.8459776
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.230 (0.230)	Data 0.474 (0.474)	Loss 0.3489 (0.3489)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.156 (0.145)	Data 0.000 (0.008)	Loss 0.3023 (0.2895)	Acc@1 94.922 (95.907)	Acc@5 100.000 (99.964)
Epoch: [149][128/196]	Time 0.137 (0.145)	Data 0.000 (0.004)	Loss 0.2432 (0.2982)	Acc@1 98.828 (95.546)	Acc@5 100.000 (99.961)
Epoch: [149][192/196]	Time 0.134 (0.144)	Data 0.000 (0.003)	Loss 0.3049 (0.2999)	Acc@1 95.312 (95.452)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.8459776
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.235 (0.235)	Data 0.437 (0.437)	Loss 0.3059 (0.3059)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.140 (0.144)	Data 0.000 (0.007)	Loss 0.2727 (0.2660)	Acc@1 96.094 (96.815)	Acc@5 99.609 (99.994)
Epoch: [150][128/196]	Time 0.150 (0.145)	Data 0.000 (0.004)	Loss 0.2587 (0.2587)	Acc@1 96.484 (97.102)	Acc@5 100.000 (99.988)
Epoch: [150][192/196]	Time 0.138 (0.143)	Data 0.000 (0.002)	Loss 0.2631 (0.2543)	Acc@1 96.094 (97.235)	Acc@5 100.000 (99.986)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.29
Max memory: 88.2314752
 28.654s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1480
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1373696
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.205 (0.205)	Data 0.507 (0.507)	Loss 0.2190 (0.2190)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.152 (0.145)	Data 0.000 (0.008)	Loss 0.2161 (0.2347)	Acc@1 98.828 (98.041)	Acc@5 100.000 (100.000)
Epoch: [151][128/196]	Time 0.146 (0.145)	Data 0.000 (0.004)	Loss 0.2382 (0.2336)	Acc@1 98.828 (98.147)	Acc@5 100.000 (99.991)
Epoch: [151][192/196]	Time 0.129 (0.145)	Data 0.000 (0.003)	Loss 0.2185 (0.2333)	Acc@1 98.828 (98.102)	Acc@5 100.000 (99.990)
Max memory in training epoch: 56.6362624
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.164 (0.164)	Data 0.341 (0.341)	Loss 0.2333 (0.2333)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.135 (0.141)	Data 0.000 (0.005)	Loss 0.2167 (0.2255)	Acc@1 98.438 (98.365)	Acc@5 100.000 (99.988)
Epoch: [152][128/196]	Time 0.130 (0.144)	Data 0.000 (0.003)	Loss 0.2020 (0.2267)	Acc@1 99.609 (98.304)	Acc@5 100.000 (99.991)
Epoch: [152][192/196]	Time 0.152 (0.145)	Data 0.000 (0.002)	Loss 0.2129 (0.2263)	Acc@1 98.047 (98.340)	Acc@5 100.000 (99.986)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.245 (0.245)	Data 0.602 (0.602)	Loss 0.2078 (0.2078)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.145 (0.146)	Data 0.000 (0.009)	Loss 0.2297 (0.2220)	Acc@1 97.656 (98.347)	Acc@5 100.000 (100.000)
Epoch: [153][128/196]	Time 0.145 (0.146)	Data 0.000 (0.005)	Loss 0.2484 (0.2210)	Acc@1 97.266 (98.413)	Acc@5 100.000 (99.997)
Epoch: [153][192/196]	Time 0.137 (0.148)	Data 0.000 (0.003)	Loss 0.1929 (0.2203)	Acc@1 99.609 (98.440)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.225 (0.225)	Data 0.442 (0.442)	Loss 0.2090 (0.2090)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.130 (0.147)	Data 0.000 (0.007)	Loss 0.2060 (0.2159)	Acc@1 99.219 (98.750)	Acc@5 100.000 (99.994)
Epoch: [154][128/196]	Time 0.153 (0.151)	Data 0.000 (0.004)	Loss 0.2106 (0.2147)	Acc@1 98.438 (98.725)	Acc@5 100.000 (99.997)
Epoch: [154][192/196]	Time 0.125 (0.149)	Data 0.000 (0.002)	Loss 0.2130 (0.2144)	Acc@1 98.828 (98.743)	Acc@5 100.000 (99.994)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.236 (0.236)	Data 0.502 (0.502)	Loss 0.2066 (0.2066)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.137 (0.144)	Data 0.000 (0.008)	Loss 0.2080 (0.2131)	Acc@1 99.219 (98.762)	Acc@5 100.000 (99.982)
Epoch: [155][128/196]	Time 0.153 (0.144)	Data 0.000 (0.004)	Loss 0.1967 (0.2135)	Acc@1 99.219 (98.731)	Acc@5 100.000 (99.991)
Epoch: [155][192/196]	Time 0.158 (0.144)	Data 0.000 (0.003)	Loss 0.2137 (0.2132)	Acc@1 98.438 (98.755)	Acc@5 100.000 (99.992)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.52
Max memory: 88.2314752
 28.946s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7730
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1373696
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.231 (0.231)	Data 0.528 (0.528)	Loss 0.2083 (0.2083)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.142 (0.148)	Data 0.000 (0.008)	Loss 0.2240 (0.2105)	Acc@1 98.438 (98.744)	Acc@5 100.000 (99.994)
Epoch: [156][128/196]	Time 0.157 (0.148)	Data 0.000 (0.004)	Loss 0.2012 (0.2109)	Acc@1 98.828 (98.728)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.161 (0.148)	Data 0.000 (0.003)	Loss 0.2239 (0.2105)	Acc@1 98.047 (98.786)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.6362624
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.193 (0.193)	Data 0.478 (0.478)	Loss 0.1964 (0.1964)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.161 (0.150)	Data 0.000 (0.008)	Loss 0.2254 (0.2110)	Acc@1 99.219 (98.798)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.133 (0.148)	Data 0.000 (0.004)	Loss 0.2167 (0.2098)	Acc@1 98.047 (98.822)	Acc@5 100.000 (100.000)
Epoch: [157][192/196]	Time 0.143 (0.146)	Data 0.000 (0.003)	Loss 0.1953 (0.2091)	Acc@1 99.609 (98.873)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.181 (0.181)	Data 0.529 (0.529)	Loss 0.1982 (0.1982)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.148 (0.149)	Data 0.000 (0.008)	Loss 0.2003 (0.2049)	Acc@1 99.219 (99.075)	Acc@5 100.000 (99.994)
Epoch: [158][128/196]	Time 0.144 (0.147)	Data 0.000 (0.004)	Loss 0.2076 (0.2061)	Acc@1 98.828 (98.955)	Acc@5 100.000 (99.997)
Epoch: [158][192/196]	Time 0.146 (0.147)	Data 0.000 (0.003)	Loss 0.2167 (0.2061)	Acc@1 98.438 (98.915)	Acc@5 100.000 (99.994)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.187 (0.187)	Data 0.471 (0.471)	Loss 0.2246 (0.2246)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.136 (0.148)	Data 0.000 (0.007)	Loss 0.2047 (0.2045)	Acc@1 99.219 (99.050)	Acc@5 100.000 (99.988)
Epoch: [159][128/196]	Time 0.149 (0.146)	Data 0.000 (0.004)	Loss 0.1943 (0.2046)	Acc@1 99.219 (99.004)	Acc@5 100.000 (99.994)
Epoch: [159][192/196]	Time 0.134 (0.146)	Data 0.000 (0.003)	Loss 0.2060 (0.2043)	Acc@1 98.828 (98.998)	Acc@5 100.000 (99.992)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.209 (0.209)	Data 0.457 (0.457)	Loss 0.2166 (0.2166)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.140 (0.136)	Data 0.000 (0.007)	Loss 0.1891 (0.2015)	Acc@1 99.609 (99.069)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.140 (0.142)	Data 0.000 (0.004)	Loss 0.2184 (0.2034)	Acc@1 97.266 (98.973)	Acc@5 100.000 (99.997)
Epoch: [160][192/196]	Time 0.140 (0.144)	Data 0.000 (0.003)	Loss 0.2184 (0.2033)	Acc@1 97.656 (98.966)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.57
Max memory: 88.2314752
 28.807s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2669
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1373696
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.260 (0.260)	Data 0.470 (0.470)	Loss 0.2342 (0.2342)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.134 (0.145)	Data 0.000 (0.007)	Loss 0.2126 (0.2013)	Acc@1 99.219 (99.044)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.151 (0.151)	Data 0.000 (0.004)	Loss 0.1958 (0.2012)	Acc@1 99.219 (99.013)	Acc@5 100.000 (100.000)
Epoch: [161][192/196]	Time 0.149 (0.149)	Data 0.000 (0.003)	Loss 0.1865 (0.2004)	Acc@1 99.609 (99.065)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.6362624
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.220 (0.220)	Data 0.418 (0.418)	Loss 0.2048 (0.2048)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.163 (0.156)	Data 0.000 (0.007)	Loss 0.1821 (0.2007)	Acc@1 100.000 (99.038)	Acc@5 100.000 (99.994)
Epoch: [162][128/196]	Time 0.139 (0.150)	Data 0.000 (0.004)	Loss 0.2208 (0.1991)	Acc@1 98.047 (99.064)	Acc@5 100.000 (99.994)
Epoch: [162][192/196]	Time 0.125 (0.147)	Data 0.000 (0.002)	Loss 0.2051 (0.1996)	Acc@1 98.828 (99.059)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.158 (0.158)	Data 0.334 (0.334)	Loss 0.1827 (0.1827)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.145 (0.140)	Data 0.000 (0.005)	Loss 0.1817 (0.1962)	Acc@1 100.000 (99.225)	Acc@5 100.000 (99.994)
Epoch: [163][128/196]	Time 0.142 (0.142)	Data 0.000 (0.003)	Loss 0.2078 (0.1966)	Acc@1 98.828 (99.210)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.137 (0.143)	Data 0.000 (0.002)	Loss 0.2151 (0.1971)	Acc@1 98.438 (99.174)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.199 (0.199)	Data 0.460 (0.460)	Loss 0.1950 (0.1950)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.145 (0.144)	Data 0.000 (0.007)	Loss 0.2443 (0.1972)	Acc@1 97.656 (99.201)	Acc@5 99.609 (99.988)
Epoch: [164][128/196]	Time 0.128 (0.144)	Data 0.000 (0.004)	Loss 0.1847 (0.1963)	Acc@1 99.609 (99.201)	Acc@5 100.000 (99.994)
Epoch: [164][192/196]	Time 0.148 (0.144)	Data 0.000 (0.003)	Loss 0.2006 (0.1962)	Acc@1 99.219 (99.190)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.233 (0.233)	Data 0.485 (0.485)	Loss 0.1853 (0.1853)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.147 (0.143)	Data 0.000 (0.008)	Loss 0.1974 (0.1941)	Acc@1 99.219 (99.267)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.134 (0.144)	Data 0.000 (0.004)	Loss 0.1909 (0.1947)	Acc@1 99.219 (99.231)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.130 (0.144)	Data 0.000 (0.003)	Loss 0.2012 (0.1954)	Acc@1 98.828 (99.209)	Acc@5 100.000 (99.994)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.74
Max memory: 88.2314752
 28.825s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 600
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1373696
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.241 (0.241)	Data 0.471 (0.471)	Loss 0.1999 (0.1999)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.156 (0.151)	Data 0.000 (0.007)	Loss 0.1820 (0.1923)	Acc@1 100.000 (99.297)	Acc@5 100.000 (99.994)
Epoch: [166][128/196]	Time 0.130 (0.147)	Data 0.000 (0.004)	Loss 0.1832 (0.1933)	Acc@1 99.609 (99.237)	Acc@5 100.000 (99.994)
Epoch: [166][192/196]	Time 0.132 (0.146)	Data 0.000 (0.003)	Loss 0.1982 (0.1936)	Acc@1 99.219 (99.235)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.6362624
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.194 (0.194)	Data 0.446 (0.446)	Loss 0.1860 (0.1860)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.137 (0.145)	Data 0.000 (0.007)	Loss 0.1819 (0.1947)	Acc@1 99.609 (99.165)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.148 (0.144)	Data 0.000 (0.004)	Loss 0.1985 (0.1938)	Acc@1 99.609 (99.182)	Acc@5 100.000 (99.997)
Epoch: [167][192/196]	Time 0.116 (0.142)	Data 0.000 (0.003)	Loss 0.1870 (0.1938)	Acc@1 99.219 (99.211)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.173 (0.173)	Data 0.310 (0.310)	Loss 0.1925 (0.1925)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.145 (0.147)	Data 0.000 (0.005)	Loss 0.1839 (0.1916)	Acc@1 99.609 (99.291)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.137 (0.146)	Data 0.000 (0.003)	Loss 0.1934 (0.1924)	Acc@1 99.219 (99.240)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.146 (0.146)	Data 0.000 (0.002)	Loss 0.2040 (0.1922)	Acc@1 98.828 (99.247)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.227 (0.227)	Data 0.647 (0.647)	Loss 0.2111 (0.2111)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.141 (0.145)	Data 0.000 (0.010)	Loss 0.1939 (0.1920)	Acc@1 98.828 (99.189)	Acc@5 100.000 (99.994)
Epoch: [169][128/196]	Time 0.148 (0.145)	Data 0.000 (0.005)	Loss 0.1766 (0.1916)	Acc@1 100.000 (99.228)	Acc@5 100.000 (99.997)
Epoch: [169][192/196]	Time 0.142 (0.149)	Data 0.000 (0.004)	Loss 0.1882 (0.1915)	Acc@1 99.609 (99.225)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.188 (0.188)	Data 0.462 (0.462)	Loss 0.1885 (0.1885)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.144 (0.148)	Data 0.000 (0.007)	Loss 0.1838 (0.1881)	Acc@1 100.000 (99.381)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.149 (0.153)	Data 0.000 (0.004)	Loss 0.1864 (0.1891)	Acc@1 99.609 (99.334)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.143 (0.149)	Data 0.000 (0.003)	Loss 0.1753 (0.1891)	Acc@1 99.609 (99.312)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.62
Max memory: 88.2314752
 29.835s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7610
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1373696
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.218 (0.218)	Data 0.517 (0.517)	Loss 0.1928 (0.1928)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.143 (0.147)	Data 0.000 (0.008)	Loss 0.1890 (0.1880)	Acc@1 99.219 (99.405)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.149 (0.146)	Data 0.000 (0.004)	Loss 0.1832 (0.1879)	Acc@1 100.000 (99.400)	Acc@5 100.000 (99.997)
Epoch: [171][192/196]	Time 0.138 (0.146)	Data 0.000 (0.003)	Loss 0.2073 (0.1878)	Acc@1 98.047 (99.377)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.6362624
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.227 (0.227)	Data 0.423 (0.423)	Loss 0.1837 (0.1837)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.143 (0.141)	Data 0.000 (0.007)	Loss 0.1895 (0.1869)	Acc@1 99.219 (99.363)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.137 (0.141)	Data 0.000 (0.003)	Loss 0.1761 (0.1875)	Acc@1 100.000 (99.352)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.135 (0.141)	Data 0.000 (0.002)	Loss 0.1833 (0.1878)	Acc@1 99.219 (99.292)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.242 (0.242)	Data 0.462 (0.462)	Loss 0.1929 (0.1929)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.141 (0.143)	Data 0.000 (0.007)	Loss 0.1797 (0.1864)	Acc@1 99.609 (99.267)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.130 (0.142)	Data 0.000 (0.004)	Loss 0.1837 (0.1866)	Acc@1 99.609 (99.291)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.137 (0.141)	Data 0.000 (0.003)	Loss 0.1783 (0.1861)	Acc@1 99.609 (99.340)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.192 (0.192)	Data 0.560 (0.560)	Loss 0.1761 (0.1761)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.136 (0.144)	Data 0.000 (0.009)	Loss 0.1850 (0.1858)	Acc@1 99.219 (99.405)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.157 (0.143)	Data 0.000 (0.005)	Loss 0.1819 (0.1856)	Acc@1 99.219 (99.413)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.123 (0.143)	Data 0.000 (0.003)	Loss 0.1922 (0.1854)	Acc@1 98.438 (99.409)	Acc@5 100.000 (99.994)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.209 (0.209)	Data 0.483 (0.483)	Loss 0.1898 (0.1898)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.152 (0.147)	Data 0.000 (0.008)	Loss 0.1837 (0.1833)	Acc@1 100.000 (99.441)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.143 (0.146)	Data 0.000 (0.004)	Loss 0.1778 (0.1836)	Acc@1 99.609 (99.419)	Acc@5 100.000 (99.997)
Epoch: [175][192/196]	Time 0.124 (0.145)	Data 0.000 (0.003)	Loss 0.1735 (0.1839)	Acc@1 100.000 (99.423)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.55
Max memory: 88.2314752
 28.884s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5104
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1373696
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.243 (0.243)	Data 0.435 (0.435)	Loss 0.1786 (0.1786)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.146 (0.144)	Data 0.000 (0.007)	Loss 0.1813 (0.1824)	Acc@1 99.609 (99.471)	Acc@5 100.000 (99.994)
Epoch: [176][128/196]	Time 0.148 (0.143)	Data 0.000 (0.004)	Loss 0.1759 (0.1819)	Acc@1 100.000 (99.482)	Acc@5 100.000 (99.997)
Epoch: [176][192/196]	Time 0.152 (0.148)	Data 0.000 (0.002)	Loss 0.1814 (0.1821)	Acc@1 99.219 (99.470)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.6362624
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.178 (0.178)	Data 0.550 (0.550)	Loss 0.1974 (0.1974)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.146 (0.146)	Data 0.000 (0.009)	Loss 0.1965 (0.1830)	Acc@1 98.828 (99.435)	Acc@5 100.000 (99.994)
Epoch: [177][128/196]	Time 0.199 (0.149)	Data 0.000 (0.004)	Loss 0.1746 (0.1831)	Acc@1 99.609 (99.443)	Acc@5 100.000 (99.988)
Epoch: [177][192/196]	Time 0.140 (0.150)	Data 0.000 (0.003)	Loss 0.1905 (0.1829)	Acc@1 98.828 (99.431)	Acc@5 100.000 (99.992)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.220 (0.220)	Data 0.452 (0.452)	Loss 0.1794 (0.1794)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.147 (0.144)	Data 0.003 (0.007)	Loss 0.1844 (0.1816)	Acc@1 99.219 (99.453)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.166 (0.149)	Data 0.000 (0.004)	Loss 0.2012 (0.1820)	Acc@1 98.828 (99.455)	Acc@5 99.609 (99.997)
Epoch: [178][192/196]	Time 0.138 (0.148)	Data 0.000 (0.003)	Loss 0.1726 (0.1818)	Acc@1 99.609 (99.476)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.182 (0.182)	Data 0.508 (0.508)	Loss 0.1743 (0.1743)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.136 (0.136)	Data 0.000 (0.008)	Loss 0.1652 (0.1794)	Acc@1 100.000 (99.489)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.145 (0.140)	Data 0.000 (0.004)	Loss 0.1750 (0.1796)	Acc@1 99.609 (99.485)	Acc@5 100.000 (99.997)
Epoch: [179][192/196]	Time 0.140 (0.142)	Data 0.000 (0.003)	Loss 0.1808 (0.1801)	Acc@1 99.219 (99.476)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.8459776
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.228 (0.228)	Data 0.493 (0.493)	Loss 0.1714 (0.1714)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.128 (0.145)	Data 0.000 (0.008)	Loss 0.1691 (0.1781)	Acc@1 100.000 (99.603)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.137 (0.143)	Data 0.000 (0.004)	Loss 0.1738 (0.1778)	Acc@1 100.000 (99.597)	Acc@5 100.000 (99.997)
Epoch: [180][192/196]	Time 0.137 (0.143)	Data 0.000 (0.003)	Loss 0.1730 (0.1795)	Acc@1 99.609 (99.543)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.8459776
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(9, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 27, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(27, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(17, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.49
Max memory: 88.2314752
 28.577s  Thres 0.001 5
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6657
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.245 (0.245)	Data 0.520 (0.520)	Loss 3.1340 (3.1340)	Acc@1 12.500 (12.500)	Acc@5 49.219 (49.219)
Epoch: [1][64/196]	Time 0.157 (0.163)	Data 0.000 (0.008)	Loss 2.5457 (2.5960)	Acc@1 23.438 (25.751)	Acc@5 81.641 (79.850)
Epoch: [1][128/196]	Time 0.172 (0.163)	Data 0.000 (0.004)	Loss 2.1098 (2.4298)	Acc@1 43.750 (31.674)	Acc@5 91.016 (84.102)
Epoch: [1][192/196]	Time 0.156 (0.162)	Data 0.000 (0.003)	Loss 1.8865 (2.3155)	Acc@1 49.219 (35.695)	Acc@5 94.922 (86.476)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.274 (0.274)	Data 0.461 (0.461)	Loss 2.0671 (2.0671)	Acc@1 46.484 (46.484)	Acc@5 92.578 (92.578)
Epoch: [2][64/196]	Time 0.156 (0.165)	Data 0.000 (0.007)	Loss 1.8468 (1.9038)	Acc@1 53.906 (50.385)	Acc@5 92.969 (93.510)
Epoch: [2][128/196]	Time 0.154 (0.164)	Data 0.000 (0.004)	Loss 1.5955 (1.8298)	Acc@1 58.203 (52.986)	Acc@5 98.047 (94.262)
Epoch: [2][192/196]	Time 0.170 (0.162)	Data 0.000 (0.003)	Loss 1.5700 (1.7609)	Acc@1 60.156 (55.236)	Acc@5 95.703 (94.835)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.200 (0.200)	Data 0.498 (0.498)	Loss 1.5676 (1.5676)	Acc@1 60.938 (60.938)	Acc@5 98.047 (98.047)
Epoch: [3][64/196]	Time 0.131 (0.162)	Data 0.000 (0.008)	Loss 1.4415 (1.4936)	Acc@1 64.453 (64.489)	Acc@5 95.703 (96.779)
Epoch: [3][128/196]	Time 0.147 (0.161)	Data 0.000 (0.004)	Loss 1.4372 (1.4443)	Acc@1 68.359 (66.170)	Acc@5 95.703 (97.048)
Epoch: [3][192/196]	Time 0.151 (0.160)	Data 0.000 (0.003)	Loss 1.3437 (1.4020)	Acc@1 66.406 (67.400)	Acc@5 97.656 (97.316)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.221 (0.221)	Data 0.429 (0.429)	Loss 1.2882 (1.2882)	Acc@1 71.094 (71.094)	Acc@5 96.875 (96.875)
Epoch: [4][64/196]	Time 0.170 (0.178)	Data 0.001 (0.007)	Loss 1.0890 (1.2419)	Acc@1 79.688 (72.308)	Acc@5 98.828 (98.125)
Epoch: [4][128/196]	Time 0.171 (0.173)	Data 0.000 (0.004)	Loss 1.1871 (1.2185)	Acc@1 72.266 (72.811)	Acc@5 98.438 (98.129)
Epoch: [4][192/196]	Time 0.184 (0.172)	Data 0.000 (0.002)	Loss 1.1541 (1.1957)	Acc@1 74.219 (73.332)	Acc@5 98.438 (98.140)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.222 (0.222)	Data 0.489 (0.489)	Loss 1.0799 (1.0799)	Acc@1 74.609 (74.609)	Acc@5 98.438 (98.438)
Epoch: [5][64/196]	Time 0.160 (0.165)	Data 0.000 (0.008)	Loss 1.0091 (1.1080)	Acc@1 76.953 (75.084)	Acc@5 99.219 (98.407)
Epoch: [5][128/196]	Time 0.173 (0.170)	Data 0.000 (0.004)	Loss 1.0862 (1.0887)	Acc@1 76.172 (75.766)	Acc@5 98.828 (98.559)
Epoch: [5][192/196]	Time 0.160 (0.169)	Data 0.000 (0.003)	Loss 1.0902 (1.0753)	Acc@1 75.000 (76.139)	Acc@5 99.219 (98.563)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  68.59
Max memory: 103.3835008
 33.678s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8449
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.224 (0.224)	Data 0.465 (0.465)	Loss 0.9883 (0.9883)	Acc@1 79.688 (79.688)	Acc@5 98.828 (98.828)
Epoch: [6][64/196]	Time 0.170 (0.161)	Data 0.000 (0.007)	Loss 0.8731 (0.9921)	Acc@1 84.766 (78.492)	Acc@5 98.828 (98.822)
Epoch: [6][128/196]	Time 0.160 (0.162)	Data 0.000 (0.004)	Loss 0.9230 (0.9882)	Acc@1 79.688 (78.497)	Acc@5 99.609 (98.852)
Epoch: [6][192/196]	Time 0.169 (0.162)	Data 0.000 (0.003)	Loss 1.0033 (0.9868)	Acc@1 75.391 (78.350)	Acc@5 99.609 (98.806)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.192 (0.192)	Data 0.540 (0.540)	Loss 0.9720 (0.9720)	Acc@1 77.344 (77.344)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.171 (0.161)	Data 0.000 (0.009)	Loss 0.9013 (0.9501)	Acc@1 83.203 (79.099)	Acc@5 96.094 (98.786)
Epoch: [7][128/196]	Time 0.152 (0.164)	Data 0.000 (0.004)	Loss 0.8726 (0.9455)	Acc@1 80.469 (79.194)	Acc@5 99.219 (98.789)
Epoch: [7][192/196]	Time 0.174 (0.164)	Data 0.000 (0.003)	Loss 0.9112 (0.9326)	Acc@1 81.641 (79.530)	Acc@5 98.438 (98.822)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.225 (0.225)	Data 0.445 (0.445)	Loss 0.7744 (0.7744)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [8][64/196]	Time 0.161 (0.168)	Data 0.000 (0.007)	Loss 0.9624 (0.8778)	Acc@1 79.688 (80.715)	Acc@5 99.609 (99.044)
Epoch: [8][128/196]	Time 0.156 (0.165)	Data 0.000 (0.004)	Loss 0.8282 (0.8809)	Acc@1 82.031 (80.811)	Acc@5 98.438 (99.034)
Epoch: [8][192/196]	Time 0.169 (0.164)	Data 0.000 (0.003)	Loss 0.9322 (0.8812)	Acc@1 78.125 (80.657)	Acc@5 99.219 (98.992)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.217 (0.217)	Data 0.476 (0.476)	Loss 0.8045 (0.8045)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [9][64/196]	Time 0.164 (0.164)	Data 0.000 (0.008)	Loss 0.8909 (0.8449)	Acc@1 80.469 (81.538)	Acc@5 98.828 (99.273)
Epoch: [9][128/196]	Time 0.173 (0.165)	Data 0.000 (0.004)	Loss 0.8417 (0.8487)	Acc@1 82.031 (81.326)	Acc@5 99.609 (99.143)
Epoch: [9][192/196]	Time 0.152 (0.164)	Data 0.000 (0.003)	Loss 0.9777 (0.8547)	Acc@1 75.781 (81.159)	Acc@5 98.438 (99.016)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.202 (0.202)	Data 0.470 (0.470)	Loss 0.7253 (0.7253)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.142 (0.165)	Data 0.000 (0.007)	Loss 0.8216 (0.8302)	Acc@1 81.641 (81.556)	Acc@5 98.828 (99.044)
Epoch: [10][128/196]	Time 0.148 (0.162)	Data 0.000 (0.004)	Loss 0.7892 (0.8295)	Acc@1 82.422 (81.753)	Acc@5 99.609 (99.037)
Epoch: [10][192/196]	Time 0.168 (0.160)	Data 0.000 (0.003)	Loss 0.7465 (0.8339)	Acc@1 85.938 (81.574)	Acc@5 98.828 (99.024)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.97
Max memory: 103.3833984
 32.048s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8623
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.312 (0.312)	Data 0.530 (0.530)	Loss 0.7811 (0.7811)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.183 (0.172)	Data 0.000 (0.008)	Loss 0.8071 (0.7919)	Acc@1 83.984 (82.921)	Acc@5 100.000 (99.099)
Epoch: [11][128/196]	Time 0.155 (0.168)	Data 0.000 (0.004)	Loss 0.7538 (0.8007)	Acc@1 84.766 (82.588)	Acc@5 98.828 (99.098)
Epoch: [11][192/196]	Time 0.161 (0.171)	Data 0.000 (0.003)	Loss 0.7124 (0.8073)	Acc@1 85.938 (82.211)	Acc@5 99.609 (99.091)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.246 (0.246)	Data 0.490 (0.490)	Loss 0.7721 (0.7721)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.170 (0.168)	Data 0.000 (0.008)	Loss 0.7762 (0.7931)	Acc@1 85.156 (82.957)	Acc@5 97.656 (99.183)
Epoch: [12][128/196]	Time 0.159 (0.173)	Data 0.000 (0.004)	Loss 0.7882 (0.7974)	Acc@1 81.250 (82.564)	Acc@5 99.609 (99.158)
Epoch: [12][192/196]	Time 0.142 (0.171)	Data 0.000 (0.003)	Loss 0.7869 (0.7991)	Acc@1 82.812 (82.525)	Acc@5 99.219 (99.148)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.217 (0.217)	Data 0.443 (0.443)	Loss 0.8666 (0.8666)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [13][64/196]	Time 0.147 (0.155)	Data 0.000 (0.007)	Loss 0.8486 (0.7956)	Acc@1 80.469 (82.704)	Acc@5 99.219 (99.159)
Epoch: [13][128/196]	Time 0.156 (0.161)	Data 0.000 (0.004)	Loss 0.8489 (0.7963)	Acc@1 79.688 (82.658)	Acc@5 98.438 (99.158)
Epoch: [13][192/196]	Time 0.166 (0.162)	Data 0.000 (0.003)	Loss 0.7452 (0.7924)	Acc@1 84.375 (82.835)	Acc@5 98.828 (99.114)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.221 (0.221)	Data 0.492 (0.492)	Loss 0.7374 (0.7374)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [14][64/196]	Time 0.165 (0.168)	Data 0.000 (0.008)	Loss 0.8216 (0.7936)	Acc@1 82.812 (82.710)	Acc@5 99.609 (99.093)
Epoch: [14][128/196]	Time 0.162 (0.169)	Data 0.000 (0.004)	Loss 0.9731 (0.7917)	Acc@1 80.469 (82.976)	Acc@5 99.609 (99.140)
Epoch: [14][192/196]	Time 0.165 (0.168)	Data 0.000 (0.003)	Loss 0.7621 (0.7830)	Acc@1 82.031 (83.314)	Acc@5 99.609 (99.154)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.265 (0.265)	Data 0.465 (0.465)	Loss 0.6359 (0.6359)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [15][64/196]	Time 0.164 (0.173)	Data 0.000 (0.007)	Loss 0.8013 (0.7662)	Acc@1 83.203 (83.419)	Acc@5 98.828 (99.333)
Epoch: [15][128/196]	Time 0.169 (0.170)	Data 0.000 (0.004)	Loss 0.7375 (0.7822)	Acc@1 85.156 (82.931)	Acc@5 99.219 (99.201)
Epoch: [15][192/196]	Time 0.170 (0.167)	Data 0.000 (0.003)	Loss 0.8560 (0.7787)	Acc@1 83.984 (83.092)	Acc@5 99.219 (99.221)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  71.57
Max memory: 103.3833984
 33.414s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3854
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.220 (0.220)	Data 0.536 (0.536)	Loss 0.7163 (0.7163)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [16][64/196]	Time 0.154 (0.165)	Data 0.000 (0.008)	Loss 0.7833 (0.7563)	Acc@1 81.641 (84.171)	Acc@5 98.828 (99.171)
Epoch: [16][128/196]	Time 0.160 (0.165)	Data 0.000 (0.004)	Loss 0.7774 (0.7631)	Acc@1 82.812 (83.881)	Acc@5 100.000 (99.152)
Epoch: [16][192/196]	Time 0.148 (0.163)	Data 0.000 (0.003)	Loss 0.8996 (0.7653)	Acc@1 78.516 (83.683)	Acc@5 99.219 (99.182)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.251 (0.251)	Data 0.441 (0.441)	Loss 0.8647 (0.8647)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [17][64/196]	Time 0.131 (0.160)	Data 0.000 (0.007)	Loss 0.8576 (0.7578)	Acc@1 80.469 (84.087)	Acc@5 98.438 (99.231)
Epoch: [17][128/196]	Time 0.146 (0.159)	Data 0.000 (0.004)	Loss 0.7103 (0.7553)	Acc@1 86.719 (84.072)	Acc@5 100.000 (99.279)
Epoch: [17][192/196]	Time 0.157 (0.161)	Data 0.000 (0.002)	Loss 0.7168 (0.7586)	Acc@1 85.938 (84.019)	Acc@5 99.609 (99.237)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.228 (0.228)	Data 0.434 (0.434)	Loss 0.6707 (0.6707)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 0.165 (0.178)	Data 0.000 (0.007)	Loss 0.6888 (0.7488)	Acc@1 87.500 (84.309)	Acc@5 99.219 (99.255)
Epoch: [18][128/196]	Time 0.162 (0.171)	Data 0.000 (0.004)	Loss 0.7522 (0.7510)	Acc@1 85.156 (84.357)	Acc@5 98.828 (99.258)
Epoch: [18][192/196]	Time 0.174 (0.170)	Data 0.000 (0.002)	Loss 0.7948 (0.7486)	Acc@1 82.422 (84.383)	Acc@5 100.000 (99.271)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.235 (0.235)	Data 0.465 (0.465)	Loss 0.8756 (0.8756)	Acc@1 80.859 (80.859)	Acc@5 98.047 (98.047)
Epoch: [19][64/196]	Time 0.146 (0.165)	Data 0.000 (0.007)	Loss 0.7716 (0.7476)	Acc@1 83.594 (84.363)	Acc@5 99.219 (99.183)
Epoch: [19][128/196]	Time 0.190 (0.170)	Data 0.000 (0.004)	Loss 0.7347 (0.7471)	Acc@1 85.156 (84.384)	Acc@5 100.000 (99.198)
Epoch: [19][192/196]	Time 0.163 (0.169)	Data 0.000 (0.003)	Loss 0.8757 (0.7500)	Acc@1 80.469 (84.203)	Acc@5 98.828 (99.217)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.209 (0.209)	Data 0.481 (0.481)	Loss 0.6878 (0.6878)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [20][64/196]	Time 0.143 (0.160)	Data 0.000 (0.008)	Loss 0.7606 (0.7469)	Acc@1 83.594 (84.171)	Acc@5 98.047 (99.201)
Epoch: [20][128/196]	Time 0.155 (0.162)	Data 0.000 (0.004)	Loss 0.8533 (0.7548)	Acc@1 82.422 (84.033)	Acc@5 98.438 (99.246)
Epoch: [20][192/196]	Time 0.159 (0.162)	Data 0.000 (0.003)	Loss 0.7189 (0.7522)	Acc@1 83.594 (84.084)	Acc@5 99.609 (99.255)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.05
Max memory: 103.3833984
 32.433s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5321
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.202496
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.250 (0.250)	Data 0.473 (0.473)	Loss 0.6934 (0.6934)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 0.162 (0.161)	Data 0.001 (0.007)	Loss 0.6950 (0.7288)	Acc@1 84.766 (84.988)	Acc@5 99.609 (99.315)
Epoch: [21][128/196]	Time 0.177 (0.165)	Data 0.000 (0.004)	Loss 0.6559 (0.7326)	Acc@1 87.109 (84.890)	Acc@5 99.609 (99.285)
Epoch: [21][192/196]	Time 0.148 (0.164)	Data 0.000 (0.003)	Loss 0.8141 (0.7368)	Acc@1 82.422 (84.849)	Acc@5 98.438 (99.249)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.216 (0.216)	Data 0.481 (0.481)	Loss 0.7038 (0.7038)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 0.160 (0.164)	Data 0.000 (0.008)	Loss 0.7681 (0.7317)	Acc@1 82.031 (84.832)	Acc@5 98.438 (99.387)
Epoch: [22][128/196]	Time 0.166 (0.165)	Data 0.000 (0.004)	Loss 0.7106 (0.7307)	Acc@1 85.156 (84.793)	Acc@5 98.828 (99.343)
Epoch: [22][192/196]	Time 0.139 (0.165)	Data 0.000 (0.003)	Loss 0.7332 (0.7328)	Acc@1 85.156 (84.697)	Acc@5 99.219 (99.334)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.267 (0.267)	Data 0.439 (0.439)	Loss 0.7734 (0.7734)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.159 (0.164)	Data 0.000 (0.007)	Loss 0.6536 (0.7385)	Acc@1 86.328 (84.766)	Acc@5 100.000 (99.267)
Epoch: [23][128/196]	Time 0.173 (0.165)	Data 0.000 (0.004)	Loss 0.7164 (0.7336)	Acc@1 85.938 (84.962)	Acc@5 98.828 (99.282)
Epoch: [23][192/196]	Time 0.157 (0.163)	Data 0.000 (0.002)	Loss 0.6717 (0.7351)	Acc@1 85.938 (84.915)	Acc@5 100.000 (99.275)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.202 (0.202)	Data 0.513 (0.513)	Loss 0.6727 (0.6727)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.155 (0.161)	Data 0.000 (0.008)	Loss 0.6736 (0.7605)	Acc@1 85.547 (83.768)	Acc@5 99.219 (99.291)
Epoch: [24][128/196]	Time 0.140 (0.160)	Data 0.000 (0.004)	Loss 0.8612 (0.7443)	Acc@1 80.859 (84.417)	Acc@5 100.000 (99.346)
Epoch: [24][192/196]	Time 0.158 (0.159)	Data 0.000 (0.003)	Loss 0.7115 (0.7408)	Acc@1 83.594 (84.557)	Acc@5 99.219 (99.316)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.220 (0.220)	Data 0.492 (0.492)	Loss 0.7392 (0.7392)	Acc@1 81.250 (81.250)	Acc@5 100.000 (100.000)
Epoch: [25][64/196]	Time 0.162 (0.163)	Data 0.000 (0.008)	Loss 0.8308 (0.7244)	Acc@1 80.469 (84.964)	Acc@5 98.828 (99.477)
Epoch: [25][128/196]	Time 0.156 (0.172)	Data 0.001 (0.004)	Loss 0.7314 (0.7334)	Acc@1 85.547 (84.757)	Acc@5 99.609 (99.397)
Epoch: [25][192/196]	Time 0.148 (0.170)	Data 0.000 (0.003)	Loss 0.7342 (0.7320)	Acc@1 85.938 (84.859)	Acc@5 99.609 (99.358)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 483922 ; 487386 ; 0.9928926969588786
[INFO] Storing checkpoint...
  74.41
Max memory: 103.3833984
 33.950s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6530
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.2011648
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.236 (0.236)	Data 0.534 (0.534)	Loss 0.5695 (0.5695)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 0.165 (0.168)	Data 0.000 (0.008)	Loss 0.7380 (0.7027)	Acc@1 83.984 (85.835)	Acc@5 99.609 (99.297)
Epoch: [26][128/196]	Time 0.167 (0.173)	Data 0.000 (0.004)	Loss 0.7517 (0.7074)	Acc@1 83.594 (85.677)	Acc@5 99.219 (99.319)
Epoch: [26][192/196]	Time 0.165 (0.171)	Data 0.000 (0.003)	Loss 0.6775 (0.7177)	Acc@1 88.672 (85.288)	Acc@5 99.219 (99.316)
Max memory in training epoch: 66.6413568
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.230 (0.230)	Data 0.448 (0.448)	Loss 0.8632 (0.8632)	Acc@1 81.250 (81.250)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.180 (0.153)	Data 0.000 (0.007)	Loss 0.7416 (0.7128)	Acc@1 84.766 (85.529)	Acc@5 99.609 (99.375)
Epoch: [27][128/196]	Time 0.163 (0.161)	Data 0.000 (0.004)	Loss 0.7684 (0.7199)	Acc@1 83.594 (85.323)	Acc@5 99.219 (99.367)
Epoch: [27][192/196]	Time 0.157 (0.163)	Data 0.000 (0.003)	Loss 0.7160 (0.7265)	Acc@1 85.547 (85.051)	Acc@5 99.609 (99.346)
Max memory in training epoch: 66.457856
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.245 (0.245)	Data 0.440 (0.440)	Loss 0.6529 (0.6529)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.182 (0.173)	Data 0.000 (0.007)	Loss 0.7376 (0.7314)	Acc@1 84.766 (84.736)	Acc@5 99.609 (99.321)
Epoch: [28][128/196]	Time 0.156 (0.171)	Data 0.002 (0.004)	Loss 0.6815 (0.7243)	Acc@1 84.766 (84.993)	Acc@5 99.609 (99.346)
Epoch: [28][192/196]	Time 0.169 (0.170)	Data 0.000 (0.002)	Loss 0.6654 (0.7217)	Acc@1 87.500 (85.124)	Acc@5 100.000 (99.358)
Max memory in training epoch: 66.457856
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.281 (0.281)	Data 0.457 (0.457)	Loss 0.6306 (0.6306)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.198 (0.172)	Data 0.000 (0.007)	Loss 0.6584 (0.7131)	Acc@1 87.109 (85.505)	Acc@5 99.609 (99.345)
Epoch: [29][128/196]	Time 0.173 (0.167)	Data 0.000 (0.004)	Loss 0.6362 (0.7163)	Acc@1 87.891 (85.441)	Acc@5 99.219 (99.328)
Epoch: [29][192/196]	Time 0.170 (0.167)	Data 0.000 (0.003)	Loss 0.7989 (0.7157)	Acc@1 82.422 (85.531)	Acc@5 99.609 (99.364)
Max memory in training epoch: 66.457856
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.244 (0.244)	Data 0.467 (0.467)	Loss 0.6103 (0.6103)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [30][64/196]	Time 0.180 (0.171)	Data 0.000 (0.007)	Loss 0.7617 (0.7212)	Acc@1 83.203 (85.150)	Acc@5 98.828 (99.321)
Epoch: [30][128/196]	Time 0.165 (0.170)	Data 0.000 (0.004)	Loss 0.6592 (0.7259)	Acc@1 89.062 (85.138)	Acc@5 99.609 (99.376)
Epoch: [30][192/196]	Time 0.158 (0.169)	Data 0.000 (0.003)	Loss 0.7291 (0.7200)	Acc@1 85.547 (85.320)	Acc@5 98.828 (99.379)
Max memory in training epoch: 66.457856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 464876 ; 483922 ; 0.9606424175796926
[INFO] Storing checkpoint...
  79.8
Max memory: 103.3384448
 33.770s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3375
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1936896
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.235 (0.235)	Data 0.388 (0.388)	Loss 0.6932 (0.6932)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [31][64/196]	Time 0.135 (0.154)	Data 0.000 (0.006)	Loss 0.6843 (0.6776)	Acc@1 87.500 (86.875)	Acc@5 99.609 (99.513)
Epoch: [31][128/196]	Time 0.142 (0.155)	Data 0.000 (0.003)	Loss 0.7200 (0.7061)	Acc@1 83.594 (85.856)	Acc@5 98.438 (99.385)
Epoch: [31][192/196]	Time 0.167 (0.158)	Data 0.000 (0.002)	Loss 0.7297 (0.7106)	Acc@1 84.375 (85.729)	Acc@5 98.438 (99.373)
Max memory in training epoch: 66.349312
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.225 (0.225)	Data 0.545 (0.545)	Loss 0.7338 (0.7338)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.164 (0.183)	Data 0.000 (0.009)	Loss 0.6588 (0.6975)	Acc@1 88.672 (85.703)	Acc@5 99.219 (99.441)
Epoch: [32][128/196]	Time 0.168 (0.172)	Data 0.000 (0.004)	Loss 0.6774 (0.7003)	Acc@1 86.328 (85.868)	Acc@5 98.828 (99.376)
Epoch: [32][192/196]	Time 0.167 (0.173)	Data 0.000 (0.003)	Loss 0.7071 (0.7097)	Acc@1 84.766 (85.565)	Acc@5 98.828 (99.350)
Max memory in training epoch: 66.0478464
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.213 (0.213)	Data 0.488 (0.488)	Loss 0.6752 (0.6752)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [33][64/196]	Time 0.161 (0.167)	Data 0.000 (0.008)	Loss 0.7489 (0.6982)	Acc@1 82.812 (85.787)	Acc@5 98.438 (99.471)
Epoch: [33][128/196]	Time 0.185 (0.173)	Data 0.000 (0.004)	Loss 0.6657 (0.7068)	Acc@1 88.672 (85.668)	Acc@5 99.609 (99.446)
Epoch: [33][192/196]	Time 0.158 (0.169)	Data 0.000 (0.003)	Loss 0.6830 (0.7065)	Acc@1 84.766 (85.685)	Acc@5 99.609 (99.419)
Max memory in training epoch: 66.0478464
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.233 (0.233)	Data 0.488 (0.488)	Loss 0.6645 (0.6645)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.128 (0.152)	Data 0.000 (0.008)	Loss 0.6505 (0.7035)	Acc@1 87.500 (85.775)	Acc@5 100.000 (99.459)
Epoch: [34][128/196]	Time 0.127 (0.140)	Data 0.000 (0.004)	Loss 0.6125 (0.7050)	Acc@1 87.891 (85.695)	Acc@5 99.609 (99.434)
Epoch: [34][192/196]	Time 0.128 (0.136)	Data 0.000 (0.003)	Loss 0.8122 (0.7043)	Acc@1 83.984 (85.729)	Acc@5 98.438 (99.443)
Max memory in training epoch: 66.0478464
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.187 (0.187)	Data 0.282 (0.282)	Loss 0.7088 (0.7088)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.6539 (0.7093)	Acc@1 87.891 (85.715)	Acc@5 99.609 (99.417)
Epoch: [35][128/196]	Time 0.136 (0.129)	Data 0.000 (0.002)	Loss 0.6785 (0.7059)	Acc@1 87.891 (85.847)	Acc@5 99.609 (99.428)
Epoch: [35][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.7919 (0.7010)	Acc@1 82.422 (85.954)	Acc@5 99.219 (99.452)
Max memory in training epoch: 66.0478464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 449576 ; 464876 ; 0.967087997659591
[INFO] Storing checkpoint...
  82.99
Max memory: 102.701824
 25.455s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3809
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1875456
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.179 (0.179)	Data 0.290 (0.290)	Loss 0.7139 (0.7139)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.7186 (0.6749)	Acc@1 82.422 (86.418)	Acc@5 99.609 (99.501)
Epoch: [36][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.7181 (0.6913)	Acc@1 87.891 (86.116)	Acc@5 99.609 (99.461)
Epoch: [36][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7032 (0.6889)	Acc@1 85.156 (86.146)	Acc@5 100.000 (99.474)
Max memory in training epoch: 65.5907328
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.163 (0.163)	Data 0.303 (0.303)	Loss 0.6693 (0.6693)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.7346 (0.6911)	Acc@1 84.766 (85.992)	Acc@5 99.219 (99.453)
Epoch: [37][128/196]	Time 0.125 (0.129)	Data 0.000 (0.003)	Loss 0.6243 (0.6984)	Acc@1 89.844 (85.674)	Acc@5 100.000 (99.434)
Epoch: [37][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.5800 (0.7002)	Acc@1 88.672 (85.618)	Acc@5 99.609 (99.419)
Max memory in training epoch: 65.6955904
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.191 (0.191)	Data 0.263 (0.263)	Loss 0.6921 (0.6921)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [38][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.8078 (0.7068)	Acc@1 82.031 (86.058)	Acc@5 99.219 (99.429)
Epoch: [38][128/196]	Time 0.137 (0.129)	Data 0.000 (0.002)	Loss 0.6530 (0.6949)	Acc@1 86.328 (86.065)	Acc@5 99.609 (99.464)
Epoch: [38][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7233 (0.6963)	Acc@1 85.938 (85.974)	Acc@5 99.219 (99.472)
Max memory in training epoch: 65.6955904
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.181 (0.181)	Data 0.289 (0.289)	Loss 0.7045 (0.7045)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [39][64/196]	Time 0.121 (0.131)	Data 0.000 (0.005)	Loss 0.6144 (0.6961)	Acc@1 88.281 (86.070)	Acc@5 100.000 (99.471)
Epoch: [39][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6884 (0.6998)	Acc@1 88.281 (85.907)	Acc@5 98.828 (99.431)
Epoch: [39][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7383 (0.6971)	Acc@1 84.766 (85.948)	Acc@5 99.219 (99.427)
Max memory in training epoch: 65.6955904
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.175 (0.175)	Data 0.286 (0.286)	Loss 0.6347 (0.6347)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6939 (0.6919)	Acc@1 85.156 (86.040)	Acc@5 98.828 (99.393)
Epoch: [40][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7154 (0.6906)	Acc@1 87.109 (86.116)	Acc@5 99.219 (99.461)
Epoch: [40][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7014 (0.6953)	Acc@1 85.156 (85.899)	Acc@5 98.828 (99.423)
Max memory in training epoch: 65.6955904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 433696 ; 449576 ; 0.9646778297773902
[INFO] Storing checkpoint...
  79.96
Max memory: 101.6796672
 25.725s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6263
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1811968
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.203 (0.203)	Data 0.264 (0.264)	Loss 0.7354 (0.7354)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [41][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6946 (0.6604)	Acc@1 83.984 (86.911)	Acc@5 99.609 (99.609)
Epoch: [41][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6727 (0.6753)	Acc@1 87.109 (86.685)	Acc@5 100.000 (99.519)
Epoch: [41][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6842 (0.6821)	Acc@1 87.109 (86.342)	Acc@5 99.609 (99.486)
Max memory in training epoch: 65.3031936
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.177 (0.177)	Data 0.273 (0.273)	Loss 0.5869 (0.5869)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [42][64/196]	Time 0.148 (0.130)	Data 0.000 (0.004)	Loss 0.7376 (0.6853)	Acc@1 85.156 (86.328)	Acc@5 98.828 (99.429)
Epoch: [42][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6042 (0.6886)	Acc@1 90.625 (86.140)	Acc@5 100.000 (99.440)
Epoch: [42][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.7353 (0.6913)	Acc@1 84.766 (86.089)	Acc@5 99.219 (99.401)
Max memory in training epoch: 64.9886208
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.166 (0.166)	Data 0.282 (0.282)	Loss 0.6312 (0.6312)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [43][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.7016 (0.6907)	Acc@1 86.719 (86.208)	Acc@5 99.609 (99.561)
Epoch: [43][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6544 (0.6853)	Acc@1 85.938 (86.419)	Acc@5 99.609 (99.494)
Epoch: [43][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7470 (0.6868)	Acc@1 84.766 (86.342)	Acc@5 100.000 (99.476)
Max memory in training epoch: 64.9886208
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.166 (0.166)	Data 0.300 (0.300)	Loss 0.5355 (0.5355)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [44][64/196]	Time 0.116 (0.128)	Data 0.000 (0.005)	Loss 0.6036 (0.6859)	Acc@1 89.844 (86.376)	Acc@5 100.000 (99.411)
Epoch: [44][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.6552 (0.6882)	Acc@1 87.109 (86.210)	Acc@5 100.000 (99.494)
Epoch: [44][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.5931 (0.6882)	Acc@1 89.062 (86.195)	Acc@5 99.219 (99.464)
Max memory in training epoch: 64.9886208
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.154 (0.154)	Data 0.294 (0.294)	Loss 0.6724 (0.6724)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.135 (0.129)	Data 0.000 (0.005)	Loss 0.7197 (0.6805)	Acc@1 85.156 (86.352)	Acc@5 99.219 (99.459)
Epoch: [45][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7704 (0.6874)	Acc@1 85.547 (86.286)	Acc@5 98.828 (99.440)
Epoch: [45][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7650 (0.6851)	Acc@1 83.984 (86.324)	Acc@5 99.219 (99.464)
Max memory in training epoch: 64.9886208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423012 ; 433696 ; 0.9753652327897883
[INFO] Storing checkpoint...
  80.64
Max memory: 100.5768192
 25.687s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8470
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1771008
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.193 (0.193)	Data 0.284 (0.284)	Loss 0.6260 (0.6260)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.6981 (0.6409)	Acc@1 85.938 (87.710)	Acc@5 99.609 (99.531)
Epoch: [46][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6868 (0.6628)	Acc@1 84.766 (86.922)	Acc@5 99.219 (99.506)
Epoch: [46][192/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.6861 (0.6769)	Acc@1 85.938 (86.379)	Acc@5 99.609 (99.466)
Max memory in training epoch: 63.9236608
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.180 (0.180)	Data 0.299 (0.299)	Loss 0.6633 (0.6633)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [47][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.6862 (0.6620)	Acc@1 85.547 (87.230)	Acc@5 99.219 (99.531)
Epoch: [47][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7551 (0.6781)	Acc@1 85.156 (86.513)	Acc@5 99.609 (99.497)
Epoch: [47][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6894 (0.6838)	Acc@1 86.719 (86.288)	Acc@5 99.609 (99.500)
Max memory in training epoch: 64.0154112
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.181 (0.181)	Data 0.299 (0.299)	Loss 0.5890 (0.5890)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [48][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.7045 (0.6704)	Acc@1 85.547 (86.815)	Acc@5 98.438 (99.495)
Epoch: [48][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.6355 (0.6707)	Acc@1 86.328 (86.746)	Acc@5 99.609 (99.503)
Epoch: [48][192/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.5664 (0.6751)	Acc@1 89.062 (86.441)	Acc@5 99.609 (99.522)
Max memory in training epoch: 64.0154112
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.157 (0.157)	Data 0.300 (0.300)	Loss 0.7419 (0.7419)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.7304 (0.6597)	Acc@1 84.766 (86.941)	Acc@5 99.609 (99.525)
Epoch: [49][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6692 (0.6722)	Acc@1 85.938 (86.634)	Acc@5 99.219 (99.485)
Epoch: [49][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6536 (0.6747)	Acc@1 87.109 (86.583)	Acc@5 99.609 (99.466)
Max memory in training epoch: 64.0154112
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.168 (0.168)	Data 0.320 (0.320)	Loss 0.6412 (0.6412)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.6286 (0.6635)	Acc@1 87.891 (86.935)	Acc@5 100.000 (99.477)
Epoch: [50][128/196]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.7602 (0.6721)	Acc@1 84.375 (86.592)	Acc@5 99.219 (99.488)
Epoch: [50][192/196]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.7168 (0.6761)	Acc@1 87.109 (86.498)	Acc@5 98.828 (99.498)
Max memory in training epoch: 64.0154112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 414058 ; 423012 ; 0.9788327517895473
[INFO] Storing checkpoint...
  81.12
Max memory: 99.2527872
 26.022s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8567
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1736192
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.184 (0.184)	Data 0.296 (0.296)	Loss 0.7158 (0.7158)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [51][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.5749 (0.6400)	Acc@1 91.016 (87.452)	Acc@5 100.000 (99.543)
Epoch: [51][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7026 (0.6562)	Acc@1 85.156 (86.770)	Acc@5 99.609 (99.473)
Epoch: [51][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7750 (0.6663)	Acc@1 82.422 (86.571)	Acc@5 99.219 (99.460)
Max memory in training epoch: 63.3854464
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.171 (0.171)	Data 0.293 (0.293)	Loss 0.6419 (0.6419)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.137 (0.130)	Data 0.000 (0.005)	Loss 0.6063 (0.6629)	Acc@1 87.891 (86.767)	Acc@5 99.609 (99.513)
Epoch: [52][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.5956 (0.6707)	Acc@1 88.672 (86.682)	Acc@5 100.000 (99.491)
Epoch: [52][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6500 (0.6796)	Acc@1 88.672 (86.290)	Acc@5 98.828 (99.435)
Max memory in training epoch: 63.523072
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.187 (0.187)	Data 0.257 (0.257)	Loss 0.6766 (0.6766)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.6988 (0.6612)	Acc@1 83.984 (86.611)	Acc@5 99.219 (99.459)
Epoch: [53][128/196]	Time 0.139 (0.130)	Data 0.000 (0.002)	Loss 0.6568 (0.6745)	Acc@1 87.500 (86.283)	Acc@5 100.000 (99.497)
Epoch: [53][192/196]	Time 0.122 (0.129)	Data 0.000 (0.001)	Loss 0.6478 (0.6756)	Acc@1 89.453 (86.334)	Acc@5 100.000 (99.472)
Max memory in training epoch: 63.523072
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.168 (0.168)	Data 0.304 (0.304)	Loss 0.5607 (0.5607)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.140 (0.130)	Data 0.000 (0.005)	Loss 0.6714 (0.6645)	Acc@1 86.328 (86.677)	Acc@5 99.219 (99.465)
Epoch: [54][128/196]	Time 0.130 (0.130)	Data 0.000 (0.003)	Loss 0.7093 (0.6632)	Acc@1 85.547 (86.849)	Acc@5 99.219 (99.470)
Epoch: [54][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7421 (0.6689)	Acc@1 84.375 (86.642)	Acc@5 98.828 (99.449)
Max memory in training epoch: 63.523072
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.149 (0.149)	Data 0.302 (0.302)	Loss 0.6457 (0.6457)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.7291 (0.6648)	Acc@1 83.594 (86.587)	Acc@5 98.828 (99.507)
Epoch: [55][128/196]	Time 0.129 (0.130)	Data 0.000 (0.003)	Loss 0.5670 (0.6726)	Acc@1 89.844 (86.301)	Acc@5 100.000 (99.543)
Epoch: [55][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7211 (0.6745)	Acc@1 85.156 (86.342)	Acc@5 99.609 (99.510)
Max memory in training epoch: 63.523072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 406262 ; 414058 ; 0.9811717199039748
[INFO] Storing checkpoint...
  79.75
Max memory: 98.1054976
 25.823s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3352
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1703424
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.182 (0.182)	Data 0.262 (0.262)	Loss 0.6370 (0.6370)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.134 (0.130)	Data 0.000 (0.004)	Loss 0.6424 (0.6261)	Acc@1 87.109 (87.752)	Acc@5 100.000 (99.651)
Epoch: [56][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.7072 (0.6554)	Acc@1 86.328 (86.979)	Acc@5 99.609 (99.561)
Epoch: [56][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6719 (0.6613)	Acc@1 85.938 (86.852)	Acc@5 100.000 (99.537)
Max memory in training epoch: 62.7956224
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.194 (0.194)	Data 0.261 (0.261)	Loss 0.6244 (0.6244)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.132 (0.128)	Data 0.000 (0.004)	Loss 0.6489 (0.6829)	Acc@1 87.891 (86.250)	Acc@5 100.000 (99.483)
Epoch: [57][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.5896 (0.6760)	Acc@1 90.234 (86.513)	Acc@5 99.609 (99.422)
Epoch: [57][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6713 (0.6749)	Acc@1 87.500 (86.526)	Acc@5 99.219 (99.443)
Max memory in training epoch: 62.7431936
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.177 (0.177)	Data 0.288 (0.288)	Loss 0.5699 (0.5699)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.6761 (0.6499)	Acc@1 86.328 (87.109)	Acc@5 99.609 (99.615)
Epoch: [58][128/196]	Time 0.136 (0.127)	Data 0.000 (0.002)	Loss 0.7319 (0.6643)	Acc@1 83.203 (86.658)	Acc@5 100.000 (99.540)
Epoch: [58][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.5302 (0.6651)	Acc@1 92.578 (86.678)	Acc@5 100.000 (99.510)
Max memory in training epoch: 62.7431936
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.168 (0.168)	Data 0.311 (0.311)	Loss 0.6550 (0.6550)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [59][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.7705 (0.6699)	Acc@1 81.641 (86.611)	Acc@5 98.438 (99.489)
Epoch: [59][128/196]	Time 0.121 (0.128)	Data 0.000 (0.003)	Loss 0.6804 (0.6682)	Acc@1 85.938 (86.631)	Acc@5 100.000 (99.512)
Epoch: [59][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6166 (0.6692)	Acc@1 88.281 (86.591)	Acc@5 99.219 (99.502)
Max memory in training epoch: 62.7431936
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.178 (0.178)	Data 0.291 (0.291)	Loss 0.6248 (0.6248)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.6909 (0.6618)	Acc@1 85.156 (86.953)	Acc@5 98.828 (99.423)
Epoch: [60][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.6389 (0.6687)	Acc@1 89.453 (86.825)	Acc@5 99.609 (99.434)
Epoch: [60][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.5999 (0.6735)	Acc@1 89.453 (86.611)	Acc@5 100.000 (99.441)
Max memory in training epoch: 62.7431936
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 401578 ; 406262 ; 0.9884704944100112
[INFO] Storing checkpoint...
  78.84
Max memory: 97.1912704
 25.522s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2813
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1679872
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.189 (0.189)	Data 0.261 (0.261)	Loss 0.5626 (0.5626)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.126 (0.122)	Data 0.000 (0.004)	Loss 0.5900 (0.6234)	Acc@1 88.672 (87.927)	Acc@5 100.000 (99.537)
Epoch: [61][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7257 (0.6400)	Acc@1 82.812 (87.382)	Acc@5 99.609 (99.549)
Epoch: [61][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6934 (0.6566)	Acc@1 85.938 (86.962)	Acc@5 99.609 (99.524)
Max memory in training epoch: 60.9259008
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.149 (0.149)	Data 0.286 (0.286)	Loss 0.6596 (0.6596)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.125 (0.122)	Data 0.000 (0.005)	Loss 0.5925 (0.6546)	Acc@1 88.281 (87.037)	Acc@5 100.000 (99.519)
Epoch: [62][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.7162 (0.6645)	Acc@1 84.375 (86.722)	Acc@5 99.609 (99.494)
Epoch: [62][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.6651 (0.6601)	Acc@1 85.938 (86.808)	Acc@5 100.000 (99.492)
Max memory in training epoch: 60.7948288
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.167 (0.167)	Data 0.263 (0.263)	Loss 0.8103 (0.8103)	Acc@1 82.031 (82.031)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.6220 (0.6568)	Acc@1 88.281 (86.905)	Acc@5 100.000 (99.537)
Epoch: [63][128/196]	Time 0.117 (0.124)	Data 0.000 (0.002)	Loss 0.7228 (0.6603)	Acc@1 84.766 (86.685)	Acc@5 98.438 (99.534)
Epoch: [63][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6327 (0.6643)	Acc@1 86.328 (86.549)	Acc@5 100.000 (99.520)
Max memory in training epoch: 60.7948288
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.164 (0.164)	Data 0.294 (0.294)	Loss 0.6569 (0.6569)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.6658 (0.6427)	Acc@1 88.281 (87.374)	Acc@5 99.219 (99.519)
Epoch: [64][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6170 (0.6563)	Acc@1 89.062 (86.997)	Acc@5 99.219 (99.470)
Epoch: [64][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.7206 (0.6657)	Acc@1 86.719 (86.719)	Acc@5 98.828 (99.447)
Max memory in training epoch: 60.7948288
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.175 (0.175)	Data 0.262 (0.262)	Loss 0.6795 (0.6795)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [65][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.5434 (0.6489)	Acc@1 92.578 (87.404)	Acc@5 99.609 (99.549)
Epoch: [65][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.5972 (0.6539)	Acc@1 87.109 (87.097)	Acc@5 100.000 (99.537)
Epoch: [65][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.6386 (0.6565)	Acc@1 86.719 (87.037)	Acc@5 99.609 (99.520)
Max memory in training epoch: 60.7948288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 394646 ; 401578 ; 0.9827380982025907
[INFO] Storing checkpoint...
  80.93
Max memory: 93.9424256
 24.371s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3975
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.16512
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.173 (0.173)	Data 0.270 (0.270)	Loss 0.6820 (0.6820)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [66][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.7084 (0.6331)	Acc@1 85.156 (87.536)	Acc@5 99.219 (99.525)
Epoch: [66][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.5837 (0.6457)	Acc@1 88.281 (87.249)	Acc@5 100.000 (99.497)
Epoch: [66][192/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.6518 (0.6518)	Acc@1 88.672 (87.085)	Acc@5 99.609 (99.496)
Max memory in training epoch: 60.6260736
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.156 (0.156)	Data 0.296 (0.296)	Loss 0.6581 (0.6581)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.128 (0.122)	Data 0.000 (0.005)	Loss 0.5892 (0.6600)	Acc@1 91.406 (86.713)	Acc@5 100.000 (99.591)
Epoch: [67][128/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.7900 (0.6658)	Acc@1 81.250 (86.619)	Acc@5 98.438 (99.479)
Epoch: [67][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6661 (0.6676)	Acc@1 87.891 (86.567)	Acc@5 99.609 (99.502)
Max memory in training epoch: 60.5736448
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.146 (0.146)	Data 0.293 (0.293)	Loss 0.6038 (0.6038)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.126 (0.122)	Data 0.000 (0.005)	Loss 0.6786 (0.6565)	Acc@1 87.500 (86.989)	Acc@5 99.609 (99.627)
Epoch: [68][128/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.5986 (0.6547)	Acc@1 89.844 (87.052)	Acc@5 99.219 (99.570)
Epoch: [68][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.6864 (0.6566)	Acc@1 86.719 (87.091)	Acc@5 98.438 (99.506)
Max memory in training epoch: 60.5736448
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.177 (0.177)	Data 0.263 (0.263)	Loss 0.5703 (0.5703)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [69][64/196]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.6285 (0.6352)	Acc@1 89.062 (87.722)	Acc@5 99.609 (99.567)
Epoch: [69][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.6373 (0.6505)	Acc@1 88.672 (87.167)	Acc@5 100.000 (99.543)
Epoch: [69][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.8556 (0.6619)	Acc@1 77.344 (86.828)	Acc@5 99.609 (99.484)
Max memory in training epoch: 60.5736448
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.190 (0.190)	Data 0.269 (0.269)	Loss 0.6376 (0.6376)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [70][64/196]	Time 0.118 (0.124)	Data 0.000 (0.004)	Loss 0.6946 (0.6598)	Acc@1 86.719 (86.725)	Acc@5 100.000 (99.525)
Epoch: [70][128/196]	Time 0.140 (0.124)	Data 0.000 (0.002)	Loss 0.6291 (0.6528)	Acc@1 87.891 (87.088)	Acc@5 99.609 (99.540)
Epoch: [70][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.6167 (0.6582)	Acc@1 87.500 (86.903)	Acc@5 100.000 (99.524)
Max memory in training epoch: 60.5736448
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 389448 ; 394646 ; 0.9868287021786614
[INFO] Storing checkpoint...
  83.1
Max memory: 93.2563456
 24.602s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3089
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1631744
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.177 (0.177)	Data 0.292 (0.292)	Loss 0.6283 (0.6283)	Acc@1 89.844 (89.844)	Acc@5 98.438 (98.438)
Epoch: [71][64/196]	Time 0.128 (0.123)	Data 0.000 (0.005)	Loss 0.6502 (0.6284)	Acc@1 86.328 (88.071)	Acc@5 99.609 (99.543)
Epoch: [71][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.5887 (0.6435)	Acc@1 89.062 (87.430)	Acc@5 100.000 (99.522)
Epoch: [71][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.7260 (0.6505)	Acc@1 84.375 (87.176)	Acc@5 99.219 (99.522)
Max memory in training epoch: 59.884288
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.191 (0.191)	Data 0.272 (0.272)	Loss 0.6500 (0.6500)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [72][64/196]	Time 0.126 (0.123)	Data 0.000 (0.004)	Loss 0.7704 (0.6684)	Acc@1 84.375 (86.454)	Acc@5 99.609 (99.471)
Epoch: [72][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.6584 (0.6624)	Acc@1 86.328 (86.634)	Acc@5 100.000 (99.509)
Epoch: [72][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6105 (0.6607)	Acc@1 86.719 (86.642)	Acc@5 100.000 (99.512)
Max memory in training epoch: 60.01536
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.177 (0.177)	Data 0.267 (0.267)	Loss 0.7196 (0.7196)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.117 (0.122)	Data 0.000 (0.004)	Loss 0.5971 (0.6535)	Acc@1 88.672 (87.302)	Acc@5 98.828 (99.495)
Epoch: [73][128/196]	Time 0.116 (0.123)	Data 0.000 (0.002)	Loss 0.6744 (0.6572)	Acc@1 86.328 (87.028)	Acc@5 100.000 (99.509)
Epoch: [73][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.6440 (0.6614)	Acc@1 89.062 (86.834)	Acc@5 100.000 (99.496)
Max memory in training epoch: 60.01536
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.174 (0.174)	Data 0.282 (0.282)	Loss 0.5541 (0.5541)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.6292 (0.6435)	Acc@1 86.719 (87.374)	Acc@5 99.609 (99.525)
Epoch: [74][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.6300 (0.6477)	Acc@1 86.328 (87.161)	Acc@5 99.609 (99.497)
Epoch: [74][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6509 (0.6512)	Acc@1 86.328 (87.051)	Acc@5 100.000 (99.504)
Max memory in training epoch: 60.01536
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.182 (0.182)	Data 0.269 (0.269)	Loss 0.5939 (0.5939)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.7434 (0.6470)	Acc@1 83.594 (87.278)	Acc@5 99.609 (99.567)
Epoch: [75][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6513 (0.6501)	Acc@1 88.672 (87.173)	Acc@5 100.000 (99.525)
Epoch: [75][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.5370 (0.6590)	Acc@1 93.750 (86.893)	Acc@5 99.219 (99.466)
Max memory in training epoch: 60.01536
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 387136 ; 389448 ; 0.9940633922885725
[INFO] Storing checkpoint...
  81.4
Max memory: 92.347136
 24.264s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 356
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1623552
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.184 (0.184)	Data 0.297 (0.297)	Loss 0.6561 (0.6561)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.5391 (0.6158)	Acc@1 91.406 (88.083)	Acc@5 99.609 (99.645)
Epoch: [76][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6471 (0.6365)	Acc@1 85.547 (87.512)	Acc@5 99.609 (99.591)
Epoch: [76][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.6382 (0.6464)	Acc@1 87.109 (87.174)	Acc@5 100.000 (99.543)
Max memory in training epoch: 59.3567232
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.161 (0.161)	Data 0.299 (0.299)	Loss 0.5247 (0.5247)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.128 (0.124)	Data 0.000 (0.005)	Loss 0.6464 (0.6353)	Acc@1 85.547 (87.392)	Acc@5 100.000 (99.591)
Epoch: [77][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.6611 (0.6434)	Acc@1 86.328 (87.300)	Acc@5 100.000 (99.573)
Epoch: [77][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.7374 (0.6526)	Acc@1 83.594 (87.101)	Acc@5 99.609 (99.520)
Max memory in training epoch: 59.5926528
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.179 (0.179)	Data 0.289 (0.289)	Loss 0.6429 (0.6429)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [78][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.5598 (0.6626)	Acc@1 89.844 (86.599)	Acc@5 100.000 (99.507)
Epoch: [78][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.7170 (0.6621)	Acc@1 83.984 (86.737)	Acc@5 99.609 (99.503)
Epoch: [78][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6476 (0.6573)	Acc@1 89.062 (86.921)	Acc@5 99.609 (99.506)
Max memory in training epoch: 59.5467776
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.177 (0.177)	Data 0.304 (0.304)	Loss 0.6386 (0.6386)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.6685 (0.6517)	Acc@1 85.156 (86.935)	Acc@5 98.828 (99.597)
Epoch: [79][128/196]	Time 0.121 (0.123)	Data 0.000 (0.003)	Loss 0.5906 (0.6500)	Acc@1 89.062 (86.937)	Acc@5 99.609 (99.567)
Epoch: [79][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.7088 (0.6526)	Acc@1 87.109 (86.947)	Acc@5 99.219 (99.530)
Max memory in training epoch: 59.5467776
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.178 (0.178)	Data 0.308 (0.308)	Loss 0.6929 (0.6929)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.6050 (0.6499)	Acc@1 89.062 (87.206)	Acc@5 99.609 (99.543)
Epoch: [80][128/196]	Time 0.119 (0.123)	Data 0.000 (0.003)	Loss 0.6005 (0.6529)	Acc@1 88.672 (86.976)	Acc@5 99.219 (99.543)
Epoch: [80][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.8082 (0.6583)	Acc@1 80.859 (86.737)	Acc@5 99.609 (99.539)
Max memory in training epoch: 59.5467776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 381216 ; 387136 ; 0.9847082162340883
[INFO] Storing checkpoint...
  76.71
Max memory: 91.8447616
 24.304s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9811
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1599488
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.201 (0.201)	Data 0.320 (0.320)	Loss 0.5742 (0.5742)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.117 (0.123)	Data 0.000 (0.005)	Loss 0.7412 (0.6228)	Acc@1 84.375 (88.029)	Acc@5 99.609 (99.579)
Epoch: [81][128/196]	Time 0.122 (0.122)	Data 0.000 (0.003)	Loss 0.6837 (0.6378)	Acc@1 84.375 (87.367)	Acc@5 99.609 (99.591)
Epoch: [81][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6021 (0.6411)	Acc@1 88.672 (87.292)	Acc@5 99.609 (99.597)
Max memory in training epoch: 59.0370304
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.156 (0.156)	Data 0.272 (0.272)	Loss 0.6542 (0.6542)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.119 (0.124)	Data 0.000 (0.004)	Loss 0.8033 (0.6634)	Acc@1 81.641 (86.544)	Acc@5 99.219 (99.405)
Epoch: [82][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6424 (0.6569)	Acc@1 88.672 (86.716)	Acc@5 99.219 (99.494)
Epoch: [82][192/196]	Time 0.135 (0.124)	Data 0.000 (0.002)	Loss 0.6785 (0.6574)	Acc@1 84.766 (86.753)	Acc@5 99.609 (99.520)
Max memory in training epoch: 59.0718464
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.186 (0.186)	Data 0.299 (0.299)	Loss 0.5909 (0.5909)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.5698 (0.6606)	Acc@1 86.719 (86.851)	Acc@5 100.000 (99.573)
Epoch: [83][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6644 (0.6591)	Acc@1 85.938 (86.967)	Acc@5 99.609 (99.549)
Epoch: [83][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.6765 (0.6545)	Acc@1 86.719 (87.119)	Acc@5 100.000 (99.555)
Max memory in training epoch: 59.0718464
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.174 (0.174)	Data 0.265 (0.265)	Loss 0.6440 (0.6440)	Acc@1 87.500 (87.500)	Acc@5 98.828 (98.828)
Epoch: [84][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.6526 (0.6321)	Acc@1 88.281 (87.374)	Acc@5 99.219 (99.549)
Epoch: [84][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6090 (0.6429)	Acc@1 85.938 (87.106)	Acc@5 100.000 (99.537)
Epoch: [84][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.6937 (0.6426)	Acc@1 85.938 (87.251)	Acc@5 99.609 (99.545)
Max memory in training epoch: 59.0718464
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.178 (0.178)	Data 0.276 (0.276)	Loss 0.6120 (0.6120)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [85][64/196]	Time 0.126 (0.125)	Data 0.000 (0.004)	Loss 0.6137 (0.6362)	Acc@1 89.844 (87.434)	Acc@5 99.219 (99.543)
Epoch: [85][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6296 (0.6485)	Acc@1 87.891 (87.082)	Acc@5 99.609 (99.519)
Epoch: [85][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.5478 (0.6494)	Acc@1 91.797 (87.134)	Acc@5 100.000 (99.506)
Max memory in training epoch: 59.0718464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 377752 ; 381216 ; 0.9909132880047008
[INFO] Storing checkpoint...
  84.26
Max memory: 91.0117888
 24.500s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9412
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1585152
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.180 (0.180)	Data 0.286 (0.286)	Loss 0.5500 (0.5500)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [86][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.6039 (0.6225)	Acc@1 88.672 (87.831)	Acc@5 99.609 (99.597)
Epoch: [86][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.7061 (0.6333)	Acc@1 83.594 (87.515)	Acc@5 100.000 (99.564)
Epoch: [86][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.6513 (0.6416)	Acc@1 89.062 (87.209)	Acc@5 99.219 (99.534)
Max memory in training epoch: 58.738432
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.143 (0.143)	Data 0.301 (0.301)	Loss 0.6805 (0.6805)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [87][64/196]	Time 0.126 (0.121)	Data 0.000 (0.005)	Loss 0.6835 (0.6410)	Acc@1 87.109 (87.079)	Acc@5 100.000 (99.567)
Epoch: [87][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.7726 (0.6509)	Acc@1 84.766 (86.970)	Acc@5 98.828 (99.525)
Epoch: [87][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6457 (0.6544)	Acc@1 86.719 (86.822)	Acc@5 99.609 (99.498)
Max memory in training epoch: 58.9874688
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.170 (0.170)	Data 0.286 (0.286)	Loss 0.5740 (0.5740)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [88][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.6096 (0.6430)	Acc@1 89.453 (87.266)	Acc@5 100.000 (99.513)
Epoch: [88][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6414 (0.6426)	Acc@1 87.891 (87.297)	Acc@5 99.609 (99.540)
Epoch: [88][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.6344 (0.6497)	Acc@1 88.281 (87.063)	Acc@5 98.828 (99.502)
Max memory in training epoch: 58.9874688
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.175 (0.175)	Data 0.259 (0.259)	Loss 0.6277 (0.6277)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [89][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.5853 (0.6403)	Acc@1 89.453 (87.578)	Acc@5 99.609 (99.585)
Epoch: [89][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.6889 (0.6416)	Acc@1 87.109 (87.455)	Acc@5 100.000 (99.573)
Epoch: [89][192/196]	Time 0.129 (0.122)	Data 0.000 (0.002)	Loss 0.6301 (0.6464)	Acc@1 87.891 (87.235)	Acc@5 100.000 (99.504)
Max memory in training epoch: 58.9874688
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.172 (0.172)	Data 0.263 (0.263)	Loss 0.6537 (0.6537)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.6008 (0.6478)	Acc@1 89.062 (87.109)	Acc@5 99.219 (99.579)
Epoch: [90][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.6958 (0.6489)	Acc@1 85.938 (87.067)	Acc@5 98.438 (99.512)
Epoch: [90][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.6058 (0.6521)	Acc@1 89.453 (86.893)	Acc@5 99.219 (99.543)
Max memory in training epoch: 58.9874688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 374288 ; 377752 ; 0.9908299625150893
[INFO] Storing checkpoint...
  78.8
Max memory: 91.011584
 24.312s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2521
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.157184
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.204 (0.204)	Data 0.288 (0.288)	Loss 0.5797 (0.5797)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [91][64/196]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.5913 (0.6183)	Acc@1 89.844 (88.305)	Acc@5 100.000 (99.591)
Epoch: [91][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6062 (0.6389)	Acc@1 89.844 (87.630)	Acc@5 99.609 (99.549)
Epoch: [91][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6633 (0.6411)	Acc@1 84.766 (87.385)	Acc@5 99.609 (99.528)
Max memory in training epoch: 58.6806784
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.150 (0.150)	Data 0.257 (0.257)	Loss 0.5305 (0.5305)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.6284 (0.6463)	Acc@1 88.281 (87.157)	Acc@5 99.219 (99.519)
Epoch: [92][128/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.5922 (0.6492)	Acc@1 87.500 (87.055)	Acc@5 99.609 (99.534)
Epoch: [92][192/196]	Time 0.116 (0.123)	Data 0.000 (0.001)	Loss 0.7197 (0.6510)	Acc@1 82.031 (86.996)	Acc@5 99.219 (99.522)
Max memory in training epoch: 58.7593216
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.168 (0.168)	Data 0.293 (0.293)	Loss 0.6646 (0.6646)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [93][64/196]	Time 0.125 (0.125)	Data 0.000 (0.005)	Loss 0.4885 (0.5581)	Acc@1 93.359 (90.234)	Acc@5 100.000 (99.718)
Epoch: [93][128/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.5658 (0.5285)	Acc@1 91.016 (91.303)	Acc@5 99.609 (99.764)
Epoch: [93][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.4947 (0.5132)	Acc@1 92.188 (91.769)	Acc@5 100.000 (99.787)
Max memory in training epoch: 58.7593216
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.174 (0.174)	Data 0.289 (0.289)	Loss 0.5229 (0.5229)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.4489 (0.4652)	Acc@1 94.141 (93.365)	Acc@5 100.000 (99.838)
Epoch: [94][128/196]	Time 0.130 (0.125)	Data 0.000 (0.002)	Loss 0.4745 (0.4605)	Acc@1 91.797 (93.465)	Acc@5 100.000 (99.858)
Epoch: [94][192/196]	Time 0.130 (0.124)	Data 0.000 (0.002)	Loss 0.5122 (0.4588)	Acc@1 92.969 (93.537)	Acc@5 99.219 (99.860)
Max memory in training epoch: 58.7593216
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.142 (0.142)	Data 0.300 (0.300)	Loss 0.4883 (0.4883)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.126 (0.125)	Data 0.000 (0.005)	Loss 0.4297 (0.4351)	Acc@1 94.922 (93.894)	Acc@5 100.000 (99.892)
Epoch: [95][128/196]	Time 0.133 (0.124)	Data 0.000 (0.002)	Loss 0.3838 (0.4385)	Acc@1 96.094 (93.838)	Acc@5 100.000 (99.906)
Epoch: [95][192/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.4053 (0.4349)	Acc@1 94.531 (93.997)	Acc@5 100.000 (99.909)
Max memory in training epoch: 58.7593216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 373854 ; 374288 ; 0.9988404650963963
[INFO] Storing checkpoint...
  91.78
Max memory: 90.5807872
 24.790s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2470
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1570304
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.203 (0.203)	Data 0.286 (0.286)	Loss 0.4138 (0.4138)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.112 (0.123)	Data 0.000 (0.005)	Loss 0.3742 (0.4193)	Acc@1 96.875 (94.519)	Acc@5 100.000 (99.874)
Epoch: [96][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.4237 (0.4198)	Acc@1 93.750 (94.449)	Acc@5 99.609 (99.894)
Epoch: [96][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.4080 (0.4203)	Acc@1 95.703 (94.375)	Acc@5 100.000 (99.895)
Max memory in training epoch: 58.5752064
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.182 (0.182)	Data 0.281 (0.281)	Loss 0.3802 (0.3802)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.3886 (0.4055)	Acc@1 95.703 (94.688)	Acc@5 100.000 (99.934)
Epoch: [97][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.4085 (0.4060)	Acc@1 94.922 (94.737)	Acc@5 100.000 (99.906)
Epoch: [97][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.4801 (0.4050)	Acc@1 91.797 (94.750)	Acc@5 99.609 (99.903)
Max memory in training epoch: 58.7062784
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.169 (0.169)	Data 0.285 (0.285)	Loss 0.4143 (0.4143)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.3804 (0.3974)	Acc@1 95.312 (95.072)	Acc@5 100.000 (99.910)
Epoch: [98][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.4348 (0.3957)	Acc@1 92.578 (95.028)	Acc@5 100.000 (99.912)
Epoch: [98][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3640 (0.3944)	Acc@1 95.703 (94.962)	Acc@5 100.000 (99.923)
Max memory in training epoch: 58.7062784
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.170 (0.170)	Data 0.302 (0.302)	Loss 0.3765 (0.3765)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.124 (0.121)	Data 0.000 (0.005)	Loss 0.3498 (0.3795)	Acc@1 97.266 (95.415)	Acc@5 100.000 (99.910)
Epoch: [99][128/196]	Time 0.113 (0.121)	Data 0.000 (0.003)	Loss 0.4177 (0.3822)	Acc@1 94.922 (95.261)	Acc@5 100.000 (99.921)
Epoch: [99][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.4206 (0.3815)	Acc@1 93.359 (95.272)	Acc@5 100.000 (99.919)
Max memory in training epoch: 58.7062784
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.141 (0.141)	Data 0.269 (0.269)	Loss 0.4035 (0.4035)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [100][64/196]	Time 0.122 (0.122)	Data 0.000 (0.004)	Loss 0.3420 (0.3735)	Acc@1 96.094 (95.463)	Acc@5 100.000 (99.916)
Epoch: [100][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.3897 (0.3729)	Acc@1 96.094 (95.376)	Acc@5 100.000 (99.939)
Epoch: [100][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3480 (0.3740)	Acc@1 96.484 (95.347)	Acc@5 100.000 (99.939)
Max memory in training epoch: 58.7062784
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 373564 ; 373854 ; 0.9992242961155959
[INFO] Storing checkpoint...
  91.48
Max memory: 90.5655808
 24.120s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1813
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.156928
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.164 (0.164)	Data 0.280 (0.280)	Loss 0.3657 (0.3657)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.115 (0.122)	Data 0.000 (0.004)	Loss 0.3373 (0.3542)	Acc@1 95.312 (95.962)	Acc@5 100.000 (99.976)
Epoch: [101][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3388 (0.3576)	Acc@1 96.484 (95.848)	Acc@5 100.000 (99.958)
Epoch: [101][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.4026 (0.3584)	Acc@1 95.312 (95.758)	Acc@5 99.609 (99.951)
Max memory in training epoch: 58.391296
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.170 (0.170)	Data 0.256 (0.256)	Loss 0.3365 (0.3365)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.3653 (0.3606)	Acc@1 94.922 (95.511)	Acc@5 100.000 (99.952)
Epoch: [102][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3540 (0.3555)	Acc@1 95.703 (95.727)	Acc@5 99.609 (99.945)
Epoch: [102][192/196]	Time 0.119 (0.120)	Data 0.000 (0.001)	Loss 0.3515 (0.3561)	Acc@1 94.531 (95.671)	Acc@5 100.000 (99.945)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.163 (0.163)	Data 0.294 (0.294)	Loss 0.3769 (0.3769)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [103][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.3273 (0.3511)	Acc@1 96.875 (95.919)	Acc@5 100.000 (99.916)
Epoch: [103][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.3346 (0.3480)	Acc@1 95.703 (95.924)	Acc@5 100.000 (99.933)
Epoch: [103][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3897 (0.3481)	Acc@1 94.922 (95.861)	Acc@5 100.000 (99.943)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.158 (0.158)	Data 0.312 (0.312)	Loss 0.3281 (0.3281)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.3516 (0.3337)	Acc@1 95.703 (96.292)	Acc@5 100.000 (99.976)
Epoch: [104][128/196]	Time 0.120 (0.120)	Data 0.000 (0.003)	Loss 0.3464 (0.3338)	Acc@1 94.922 (96.291)	Acc@5 100.000 (99.961)
Epoch: [104][192/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3496 (0.3371)	Acc@1 95.703 (96.138)	Acc@5 99.609 (99.955)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.178 (0.178)	Data 0.265 (0.265)	Loss 0.2943 (0.2943)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.3370 (0.3333)	Acc@1 95.703 (96.280)	Acc@5 100.000 (99.964)
Epoch: [105][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3434 (0.3355)	Acc@1 96.094 (96.073)	Acc@5 100.000 (99.958)
Epoch: [105][192/196]	Time 0.111 (0.121)	Data 0.000 (0.002)	Loss 0.3475 (0.3333)	Acc@1 96.094 (96.106)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.4044032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.75
Max memory: 90.1114368
 24.055s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7810
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.156928
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.198 (0.198)	Data 0.290 (0.290)	Loss 0.2965 (0.2965)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.2982 (0.3237)	Acc@1 98.047 (96.166)	Acc@5 100.000 (99.964)
Epoch: [106][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3285 (0.3218)	Acc@1 96.875 (96.372)	Acc@5 100.000 (99.961)
Epoch: [106][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3183 (0.3242)	Acc@1 96.484 (96.217)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.391296
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.160 (0.160)	Data 0.311 (0.311)	Loss 0.2951 (0.2951)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.3175 (0.3219)	Acc@1 96.875 (96.400)	Acc@5 100.000 (99.958)
Epoch: [107][128/196]	Time 0.114 (0.120)	Data 0.000 (0.003)	Loss 0.3434 (0.3194)	Acc@1 95.312 (96.442)	Acc@5 100.000 (99.958)
Epoch: [107][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3299 (0.3224)	Acc@1 95.312 (96.191)	Acc@5 100.000 (99.957)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.176 (0.176)	Data 0.297 (0.297)	Loss 0.2817 (0.2817)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.3623 (0.3160)	Acc@1 95.703 (96.466)	Acc@5 100.000 (99.970)
Epoch: [108][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3044 (0.3158)	Acc@1 96.094 (96.375)	Acc@5 100.000 (99.976)
Epoch: [108][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2885 (0.3149)	Acc@1 96.875 (96.399)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.174 (0.174)	Data 0.292 (0.292)	Loss 0.3096 (0.3096)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.2747 (0.3122)	Acc@1 98.438 (96.292)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.3101 (0.3097)	Acc@1 96.875 (96.421)	Acc@5 100.000 (99.976)
Epoch: [109][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3279 (0.3098)	Acc@1 95.312 (96.409)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.167 (0.167)	Data 0.292 (0.292)	Loss 0.2662 (0.2662)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.3228 (0.3074)	Acc@1 95.703 (96.424)	Acc@5 100.000 (99.958)
Epoch: [110][128/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.2705 (0.3077)	Acc@1 97.656 (96.366)	Acc@5 100.000 (99.967)
Epoch: [110][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2912 (0.3088)	Acc@1 96.875 (96.304)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.4044032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.06
Max memory: 90.1114368
 24.139s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 734
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.156928
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.170 (0.170)	Data 0.285 (0.285)	Loss 0.2875 (0.2875)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.3150 (0.2939)	Acc@1 96.484 (96.869)	Acc@5 100.000 (99.952)
Epoch: [111][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3536 (0.2957)	Acc@1 94.922 (96.799)	Acc@5 100.000 (99.964)
Epoch: [111][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3100 (0.3008)	Acc@1 95.703 (96.596)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.391296
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.171 (0.171)	Data 0.266 (0.266)	Loss 0.2761 (0.2761)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.3053 (0.2900)	Acc@1 96.094 (96.959)	Acc@5 100.000 (99.970)
Epoch: [112][128/196]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.2797 (0.2973)	Acc@1 97.266 (96.648)	Acc@5 100.000 (99.979)
Epoch: [112][192/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.2638 (0.3006)	Acc@1 97.656 (96.486)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.165 (0.165)	Data 0.276 (0.276)	Loss 0.3149 (0.3149)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.124 (0.123)	Data 0.000 (0.004)	Loss 0.2689 (0.2889)	Acc@1 98.047 (96.839)	Acc@5 100.000 (99.952)
Epoch: [113][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2579 (0.2900)	Acc@1 98.047 (96.790)	Acc@5 100.000 (99.967)
Epoch: [113][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.3049 (0.2945)	Acc@1 95.703 (96.571)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.139 (0.139)	Data 0.284 (0.284)	Loss 0.3163 (0.3163)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.3261 (0.2972)	Acc@1 94.922 (96.472)	Acc@5 100.000 (99.970)
Epoch: [114][128/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.2853 (0.2952)	Acc@1 96.484 (96.539)	Acc@5 100.000 (99.970)
Epoch: [114][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.2911 (0.2965)	Acc@1 96.484 (96.444)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.4044032
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.153 (0.153)	Data 0.274 (0.274)	Loss 0.2973 (0.2973)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.125 (0.125)	Data 0.000 (0.004)	Loss 0.3046 (0.2921)	Acc@1 96.484 (96.587)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.127 (0.124)	Data 0.000 (0.002)	Loss 0.2923 (0.2933)	Acc@1 94.141 (96.490)	Acc@5 100.000 (99.970)
Epoch: [115][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.2644 (0.2966)	Acc@1 98.047 (96.383)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.4044032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 372408 ; 373564 ; 0.9969054833977579
[INFO] Storing checkpoint...
  90.38
Max memory: 90.1114368
 24.657s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3876
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1565184
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.196 (0.196)	Data 0.258 (0.258)	Loss 0.2719 (0.2719)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.2851 (0.2810)	Acc@1 95.703 (96.959)	Acc@5 99.609 (99.952)
Epoch: [116][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3629 (0.2830)	Acc@1 93.750 (96.808)	Acc@5 100.000 (99.967)
Epoch: [116][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2820 (0.2883)	Acc@1 97.656 (96.638)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.2323712
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.169 (0.169)	Data 0.273 (0.273)	Loss 0.2815 (0.2815)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [117][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.3283 (0.2786)	Acc@1 95.703 (96.863)	Acc@5 100.000 (99.982)
Epoch: [117][128/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.2864 (0.2831)	Acc@1 96.484 (96.751)	Acc@5 100.000 (99.979)
Epoch: [117][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2760 (0.2852)	Acc@1 97.656 (96.632)	Acc@5 100.000 (99.980)
Max memory in training epoch: 58.4027648
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.184 (0.184)	Data 0.261 (0.261)	Loss 0.2705 (0.2705)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.2553 (0.2786)	Acc@1 98.047 (96.869)	Acc@5 100.000 (99.970)
Epoch: [118][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3423 (0.2830)	Acc@1 94.141 (96.687)	Acc@5 100.000 (99.979)
Epoch: [118][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2958 (0.2862)	Acc@1 96.094 (96.545)	Acc@5 100.000 (99.982)
Max memory in training epoch: 58.4027648
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.171 (0.171)	Data 0.270 (0.270)	Loss 0.2765 (0.2765)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.116 (0.120)	Data 0.000 (0.004)	Loss 0.2419 (0.2815)	Acc@1 98.438 (96.562)	Acc@5 100.000 (99.964)
Epoch: [119][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2920 (0.2868)	Acc@1 96.094 (96.445)	Acc@5 100.000 (99.967)
Epoch: [119][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2886 (0.2895)	Acc@1 96.094 (96.306)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.4027648
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.166 (0.166)	Data 0.319 (0.319)	Loss 0.2366 (0.2366)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.3031 (0.2828)	Acc@1 96.484 (96.605)	Acc@5 100.000 (99.988)
Epoch: [120][128/196]	Time 0.120 (0.122)	Data 0.000 (0.003)	Loss 0.3177 (0.2854)	Acc@1 94.922 (96.442)	Acc@5 100.000 (99.988)
Epoch: [120][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3194 (0.2883)	Acc@1 94.531 (96.353)	Acc@5 100.000 (99.984)
Max memory in training epoch: 58.4027648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.99
Max memory: 89.7694208
 24.217s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3404
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1565184
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.162 (0.162)	Data 0.255 (0.255)	Loss 0.2750 (0.2750)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.2914 (0.2701)	Acc@1 98.047 (96.977)	Acc@5 100.000 (99.970)
Epoch: [121][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3105 (0.2777)	Acc@1 95.312 (96.724)	Acc@5 100.000 (99.973)
Epoch: [121][192/196]	Time 0.121 (0.121)	Data 0.000 (0.001)	Loss 0.2571 (0.2815)	Acc@1 98.438 (96.537)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.2323712
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.181 (0.181)	Data 0.269 (0.269)	Loss 0.2673 (0.2673)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.2899 (0.2792)	Acc@1 95.703 (96.550)	Acc@5 100.000 (99.982)
Epoch: [122][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3377 (0.2818)	Acc@1 94.141 (96.463)	Acc@5 100.000 (99.982)
Epoch: [122][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3027 (0.2839)	Acc@1 94.922 (96.436)	Acc@5 100.000 (99.986)
Max memory in training epoch: 58.4027648
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.152 (0.152)	Data 0.292 (0.292)	Loss 0.2544 (0.2544)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.2365 (0.2745)	Acc@1 98.438 (96.761)	Acc@5 100.000 (100.000)
Epoch: [123][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3132 (0.2784)	Acc@1 94.922 (96.575)	Acc@5 99.609 (99.988)
Epoch: [123][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2703 (0.2838)	Acc@1 97.266 (96.375)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.4027648
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.166 (0.166)	Data 0.270 (0.270)	Loss 0.2534 (0.2534)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.2864 (0.2779)	Acc@1 95.703 (96.436)	Acc@5 99.609 (99.964)
Epoch: [124][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3038 (0.2846)	Acc@1 95.312 (96.230)	Acc@5 99.609 (99.973)
Epoch: [124][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2890 (0.2885)	Acc@1 96.094 (96.096)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.4027648
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.171 (0.171)	Data 0.276 (0.276)	Loss 0.2640 (0.2640)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2903 (0.2899)	Acc@1 95.703 (96.160)	Acc@5 100.000 (99.964)
Epoch: [125][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2663 (0.2858)	Acc@1 97.266 (96.269)	Acc@5 100.000 (99.967)
Epoch: [125][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2837 (0.2851)	Acc@1 96.094 (96.280)	Acc@5 100.000 (99.962)
Max memory in training epoch: 58.4027648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 372118 ; 372408 ; 0.9992212841829391
[INFO] Storing checkpoint...
  90.31
Max memory: 89.7694208
 24.163s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2736
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.156416
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.188 (0.188)	Data 0.303 (0.303)	Loss 0.2546 (0.2546)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.3350 (0.2665)	Acc@1 95.312 (96.989)	Acc@5 100.000 (99.994)
Epoch: [126][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.2434 (0.2721)	Acc@1 98.047 (96.760)	Acc@5 100.000 (99.976)
Epoch: [126][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2968 (0.2796)	Acc@1 96.094 (96.450)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.8125312
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.159 (0.159)	Data 0.320 (0.320)	Loss 0.2539 (0.2539)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.2563 (0.2748)	Acc@1 97.266 (96.562)	Acc@5 100.000 (99.982)
Epoch: [127][128/196]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.2718 (0.2808)	Acc@1 96.875 (96.357)	Acc@5 100.000 (99.979)
Epoch: [127][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.2774 (0.2851)	Acc@1 96.484 (96.177)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.9829248
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.169 (0.169)	Data 0.292 (0.292)	Loss 0.2622 (0.2622)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.3103 (0.2784)	Acc@1 95.312 (96.623)	Acc@5 100.000 (99.982)
Epoch: [128][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2515 (0.2814)	Acc@1 97.656 (96.339)	Acc@5 100.000 (99.979)
Epoch: [128][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2832 (0.2854)	Acc@1 96.875 (96.167)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.166 (0.166)	Data 0.277 (0.277)	Loss 0.2698 (0.2698)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2460 (0.2787)	Acc@1 98.047 (96.514)	Acc@5 100.000 (99.982)
Epoch: [129][128/196]	Time 0.112 (0.121)	Data 0.000 (0.002)	Loss 0.3098 (0.2765)	Acc@1 94.922 (96.448)	Acc@5 99.609 (99.982)
Epoch: [129][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2806 (0.2824)	Acc@1 96.484 (96.179)	Acc@5 100.000 (99.980)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.151 (0.151)	Data 0.312 (0.312)	Loss 0.2515 (0.2515)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.134 (0.123)	Data 0.000 (0.005)	Loss 0.2736 (0.2800)	Acc@1 96.484 (96.448)	Acc@5 100.000 (99.952)
Epoch: [130][128/196]	Time 0.118 (0.123)	Data 0.000 (0.003)	Loss 0.2899 (0.2863)	Acc@1 94.531 (96.103)	Acc@5 100.000 (99.967)
Epoch: [130][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.2732 (0.2851)	Acc@1 95.703 (96.126)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.08
Max memory: 89.4856704
 24.281s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4803
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.156416
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.198 (0.198)	Data 0.256 (0.256)	Loss 0.2858 (0.2858)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2425 (0.2616)	Acc@1 97.656 (96.851)	Acc@5 100.000 (99.994)
Epoch: [131][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2818 (0.2706)	Acc@1 95.703 (96.524)	Acc@5 100.000 (99.979)
Epoch: [131][192/196]	Time 0.118 (0.122)	Data 0.000 (0.001)	Loss 0.2779 (0.2784)	Acc@1 96.875 (96.308)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.8125312
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.182 (0.182)	Data 0.264 (0.264)	Loss 0.2874 (0.2874)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.2747 (0.2770)	Acc@1 96.094 (96.358)	Acc@5 100.000 (99.982)
Epoch: [132][128/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.2717 (0.2768)	Acc@1 97.656 (96.378)	Acc@5 100.000 (99.985)
Epoch: [132][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2880 (0.2798)	Acc@1 95.703 (96.258)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9829248
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.164 (0.164)	Data 0.291 (0.291)	Loss 0.2297 (0.2297)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.4009 (0.2796)	Acc@1 92.188 (96.220)	Acc@5 100.000 (99.994)
Epoch: [133][128/196]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.3116 (0.2803)	Acc@1 94.531 (96.109)	Acc@5 100.000 (99.979)
Epoch: [133][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3092 (0.2811)	Acc@1 94.922 (96.076)	Acc@5 100.000 (99.984)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.168 (0.168)	Data 0.257 (0.257)	Loss 0.2323 (0.2323)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.118 (0.123)	Data 0.000 (0.004)	Loss 0.3480 (0.2848)	Acc@1 92.188 (95.974)	Acc@5 100.000 (99.976)
Epoch: [134][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.3354 (0.2804)	Acc@1 94.531 (96.266)	Acc@5 100.000 (99.970)
Epoch: [134][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3030 (0.2818)	Acc@1 95.703 (96.215)	Acc@5 100.000 (99.968)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.158 (0.158)	Data 0.305 (0.305)	Loss 0.2855 (0.2855)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.2709 (0.2779)	Acc@1 96.094 (96.250)	Acc@5 100.000 (99.952)
Epoch: [135][128/196]	Time 0.124 (0.123)	Data 0.000 (0.003)	Loss 0.2998 (0.2779)	Acc@1 95.703 (96.221)	Acc@5 100.000 (99.970)
Epoch: [135][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.3109 (0.2794)	Acc@1 94.531 (96.191)	Acc@5 99.609 (99.970)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.27
Max memory: 89.4856704
 24.438s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8589
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.156416
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.184 (0.184)	Data 0.292 (0.292)	Loss 0.2304 (0.2304)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.3053 (0.2688)	Acc@1 95.703 (96.677)	Acc@5 100.000 (99.994)
Epoch: [136][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2652 (0.2725)	Acc@1 96.875 (96.536)	Acc@5 100.000 (99.991)
Epoch: [136][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.2871 (0.2778)	Acc@1 96.484 (96.345)	Acc@5 100.000 (99.984)
Max memory in training epoch: 57.8125312
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.157 (0.157)	Data 0.292 (0.292)	Loss 0.2549 (0.2549)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.2705 (0.2774)	Acc@1 97.266 (96.394)	Acc@5 100.000 (99.970)
Epoch: [137][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.2957 (0.2803)	Acc@1 94.922 (96.263)	Acc@5 100.000 (99.976)
Epoch: [137][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.2516 (0.2826)	Acc@1 96.484 (96.122)	Acc@5 100.000 (99.978)
Max memory in training epoch: 57.9829248
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.176 (0.176)	Data 0.271 (0.271)	Loss 0.2671 (0.2671)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3123 (0.2817)	Acc@1 95.703 (96.052)	Acc@5 100.000 (99.940)
Epoch: [138][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2934 (0.2845)	Acc@1 95.703 (95.936)	Acc@5 100.000 (99.942)
Epoch: [138][192/196]	Time 0.129 (0.121)	Data 0.000 (0.002)	Loss 0.2804 (0.2844)	Acc@1 97.266 (95.936)	Acc@5 100.000 (99.945)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.163 (0.163)	Data 0.257 (0.257)	Loss 0.2609 (0.2609)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.2859 (0.2785)	Acc@1 94.922 (96.238)	Acc@5 100.000 (99.964)
Epoch: [139][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.2737 (0.2805)	Acc@1 96.094 (96.215)	Acc@5 100.000 (99.970)
Epoch: [139][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2346 (0.2828)	Acc@1 98.047 (96.104)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.178 (0.178)	Data 0.266 (0.266)	Loss 0.2850 (0.2850)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.2815 (0.2835)	Acc@1 95.703 (96.040)	Acc@5 100.000 (99.982)
Epoch: [140][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2798 (0.2866)	Acc@1 96.094 (95.897)	Acc@5 100.000 (99.973)
Epoch: [140][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3175 (0.2865)	Acc@1 93.359 (95.879)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.98
Max memory: 89.4856704
 23.975s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1428
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.156416
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.206 (0.206)	Data 0.251 (0.251)	Loss 0.2674 (0.2674)	Acc@1 97.656 (97.656)	Acc@5 99.609 (99.609)
Epoch: [141][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.2661 (0.2637)	Acc@1 97.266 (96.695)	Acc@5 100.000 (99.994)
Epoch: [141][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.3287 (0.2710)	Acc@1 94.141 (96.421)	Acc@5 100.000 (99.976)
Epoch: [141][192/196]	Time 0.119 (0.123)	Data 0.000 (0.001)	Loss 0.2558 (0.2762)	Acc@1 96.875 (96.213)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.8125312
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.173 (0.173)	Data 0.267 (0.267)	Loss 0.2484 (0.2484)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.3013 (0.2745)	Acc@1 95.312 (96.238)	Acc@5 100.000 (99.970)
Epoch: [142][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3421 (0.2810)	Acc@1 94.531 (96.042)	Acc@5 99.609 (99.967)
Epoch: [142][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3441 (0.2823)	Acc@1 94.531 (96.029)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.9829248
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.164 (0.164)	Data 0.282 (0.282)	Loss 0.2739 (0.2739)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.2928 (0.2783)	Acc@1 96.484 (96.178)	Acc@5 100.000 (99.964)
Epoch: [143][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2983 (0.2816)	Acc@1 96.875 (96.036)	Acc@5 99.219 (99.970)
Epoch: [143][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3086 (0.2832)	Acc@1 95.703 (96.031)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.174 (0.174)	Data 0.286 (0.286)	Loss 0.2439 (0.2439)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.115 (0.123)	Data 0.000 (0.005)	Loss 0.2433 (0.2773)	Acc@1 97.656 (96.190)	Acc@5 100.000 (99.988)
Epoch: [144][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2897 (0.2787)	Acc@1 94.922 (96.200)	Acc@5 100.000 (99.982)
Epoch: [144][192/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.2820 (0.2805)	Acc@1 95.703 (96.165)	Acc@5 100.000 (99.982)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.171 (0.171)	Data 0.254 (0.254)	Loss 0.2854 (0.2854)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.2835 (0.2756)	Acc@1 96.875 (96.358)	Acc@5 100.000 (99.988)
Epoch: [145][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2804 (0.2805)	Acc@1 96.875 (96.130)	Acc@5 100.000 (99.982)
Epoch: [145][192/196]	Time 0.119 (0.121)	Data 0.000 (0.001)	Loss 0.2954 (0.2835)	Acc@1 95.703 (96.001)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.16
Max memory: 89.4856704
 23.955s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 463
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.156416
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.194 (0.194)	Data 0.262 (0.262)	Loss 0.3201 (0.3201)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.116 (0.125)	Data 0.000 (0.004)	Loss 0.2920 (0.2707)	Acc@1 95.312 (96.526)	Acc@5 100.000 (99.976)
Epoch: [146][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2598 (0.2728)	Acc@1 96.094 (96.375)	Acc@5 100.000 (99.967)
Epoch: [146][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3246 (0.2749)	Acc@1 94.141 (96.264)	Acc@5 100.000 (99.964)
Max memory in training epoch: 57.8125312
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.170 (0.170)	Data 0.283 (0.283)	Loss 0.2851 (0.2851)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.2727 (0.2826)	Acc@1 94.922 (96.010)	Acc@5 100.000 (99.982)
Epoch: [147][128/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.3288 (0.2817)	Acc@1 94.531 (96.091)	Acc@5 100.000 (99.985)
Epoch: [147][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3130 (0.2847)	Acc@1 94.922 (95.972)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.9829248
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.145 (0.145)	Data 0.316 (0.316)	Loss 0.2935 (0.2935)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.137 (0.124)	Data 0.000 (0.005)	Loss 0.2555 (0.2774)	Acc@1 97.266 (96.172)	Acc@5 100.000 (99.982)
Epoch: [148][128/196]	Time 0.123 (0.123)	Data 0.000 (0.003)	Loss 0.2752 (0.2806)	Acc@1 96.875 (96.103)	Acc@5 100.000 (99.982)
Epoch: [148][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.2501 (0.2829)	Acc@1 96.875 (96.011)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.166 (0.166)	Data 0.269 (0.269)	Loss 0.3022 (0.3022)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.123 (0.125)	Data 0.000 (0.004)	Loss 0.2545 (0.2805)	Acc@1 98.047 (96.172)	Acc@5 100.000 (99.988)
Epoch: [149][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.3383 (0.2810)	Acc@1 96.094 (96.194)	Acc@5 99.609 (99.973)
Epoch: [149][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.2982 (0.2826)	Acc@1 96.875 (96.146)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.9436032
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.177 (0.177)	Data 0.262 (0.262)	Loss 0.2718 (0.2718)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.125 (0.124)	Data 0.000 (0.004)	Loss 0.2225 (0.2499)	Acc@1 98.828 (97.386)	Acc@5 100.000 (99.988)
Epoch: [150][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.2243 (0.2433)	Acc@1 98.438 (97.562)	Acc@5 100.000 (99.994)
Epoch: [150][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.2178 (0.2388)	Acc@1 99.219 (97.719)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.96
Max memory: 89.4856704
 24.647s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3922
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.156416
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.180 (0.180)	Data 0.271 (0.271)	Loss 0.2062 (0.2062)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.2270 (0.2218)	Acc@1 97.656 (98.413)	Acc@5 100.000 (99.988)
Epoch: [151][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2239 (0.2218)	Acc@1 98.438 (98.398)	Acc@5 100.000 (99.988)
Epoch: [151][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2277 (0.2209)	Acc@1 97.656 (98.403)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.8125312
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.172 (0.172)	Data 0.303 (0.303)	Loss 0.1992 (0.1992)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.2105 (0.2146)	Acc@1 98.047 (98.624)	Acc@5 100.000 (100.000)
Epoch: [152][128/196]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.1983 (0.2139)	Acc@1 99.219 (98.631)	Acc@5 100.000 (99.991)
Epoch: [152][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.2328 (0.2131)	Acc@1 97.656 (98.654)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.9829248
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.160 (0.160)	Data 0.308 (0.308)	Loss 0.2067 (0.2067)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.2373 (0.2068)	Acc@1 98.828 (98.912)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.114 (0.121)	Data 0.000 (0.003)	Loss 0.2167 (0.2084)	Acc@1 98.438 (98.883)	Acc@5 100.000 (99.997)
Epoch: [153][192/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.2210 (0.2089)	Acc@1 98.047 (98.812)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.169 (0.169)	Data 0.263 (0.263)	Loss 0.2214 (0.2214)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.115 (0.122)	Data 0.000 (0.004)	Loss 0.1967 (0.2060)	Acc@1 99.609 (98.852)	Acc@5 100.000 (99.988)
Epoch: [154][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2013 (0.2058)	Acc@1 98.828 (98.874)	Acc@5 100.000 (99.991)
Epoch: [154][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1946 (0.2051)	Acc@1 99.219 (98.899)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.162 (0.162)	Data 0.258 (0.258)	Loss 0.1990 (0.1990)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.126 (0.123)	Data 0.000 (0.004)	Loss 0.2116 (0.1993)	Acc@1 98.828 (99.183)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2484 (0.2005)	Acc@1 97.656 (99.101)	Acc@5 100.000 (99.997)
Epoch: [155][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1900 (0.2009)	Acc@1 99.609 (99.077)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.3
Max memory: 89.4856704
 24.255s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8497
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.156416
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.181 (0.181)	Data 0.284 (0.284)	Loss 0.2049 (0.2049)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.1888 (0.1986)	Acc@1 99.609 (99.141)	Acc@5 100.000 (99.994)
Epoch: [156][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.2062 (0.1984)	Acc@1 98.047 (99.152)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1866 (0.1995)	Acc@1 99.609 (99.120)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.8125312
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.172 (0.172)	Data 0.266 (0.266)	Loss 0.1914 (0.1914)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.1922 (0.1967)	Acc@1 99.609 (99.177)	Acc@5 100.000 (99.994)
Epoch: [157][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1954 (0.1971)	Acc@1 99.609 (99.152)	Acc@5 100.000 (99.994)
Epoch: [157][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.1983 (0.1976)	Acc@1 98.828 (99.130)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9829248
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.147 (0.147)	Data 0.287 (0.287)	Loss 0.1878 (0.1878)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.1969 (0.1953)	Acc@1 98.828 (99.183)	Acc@5 100.000 (99.988)
Epoch: [158][128/196]	Time 0.114 (0.123)	Data 0.000 (0.002)	Loss 0.1934 (0.1958)	Acc@1 98.438 (99.204)	Acc@5 100.000 (99.988)
Epoch: [158][192/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.1960 (0.1959)	Acc@1 99.219 (99.192)	Acc@5 100.000 (99.992)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.153 (0.153)	Data 0.300 (0.300)	Loss 0.1984 (0.1984)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.1939 (0.1933)	Acc@1 99.219 (99.273)	Acc@5 100.000 (99.988)
Epoch: [159][128/196]	Time 0.122 (0.123)	Data 0.000 (0.003)	Loss 0.2035 (0.1930)	Acc@1 98.828 (99.288)	Acc@5 100.000 (99.994)
Epoch: [159][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2037 (0.1935)	Acc@1 99.219 (99.292)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.173 (0.173)	Data 0.286 (0.286)	Loss 0.1911 (0.1911)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.114 (0.124)	Data 0.000 (0.005)	Loss 0.1808 (0.1918)	Acc@1 100.000 (99.339)	Acc@5 100.000 (99.994)
Epoch: [160][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1743 (0.1924)	Acc@1 100.000 (99.307)	Acc@5 100.000 (99.997)
Epoch: [160][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1784 (0.1926)	Acc@1 100.000 (99.281)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.49
Max memory: 89.4856704
 24.419s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8591
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.156416
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.188 (0.188)	Data 0.286 (0.286)	Loss 0.1880 (0.1880)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.112 (0.121)	Data 0.000 (0.005)	Loss 0.1843 (0.1908)	Acc@1 98.828 (99.321)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.147 (0.120)	Data 0.000 (0.002)	Loss 0.1848 (0.1918)	Acc@1 99.609 (99.285)	Acc@5 100.000 (100.000)
Epoch: [161][192/196]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.2009 (0.1918)	Acc@1 99.219 (99.312)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.8125312
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.173 (0.173)	Data 0.267 (0.267)	Loss 0.1955 (0.1955)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.1965 (0.1898)	Acc@1 99.219 (99.375)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2107 (0.1899)	Acc@1 98.828 (99.334)	Acc@5 100.000 (99.997)
Epoch: [162][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1852 (0.1903)	Acc@1 99.609 (99.300)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9829248
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.139 (0.139)	Data 0.302 (0.302)	Loss 0.2138 (0.2138)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.2178 (0.1898)	Acc@1 96.875 (99.351)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.123 (0.120)	Data 0.000 (0.003)	Loss 0.1827 (0.1887)	Acc@1 99.609 (99.373)	Acc@5 100.000 (100.000)
Epoch: [163][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1836 (0.1882)	Acc@1 99.609 (99.371)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.155 (0.155)	Data 0.324 (0.324)	Loss 0.1937 (0.1937)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.1917 (0.1875)	Acc@1 99.219 (99.417)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.117 (0.121)	Data 0.000 (0.003)	Loss 0.2018 (0.1880)	Acc@1 98.438 (99.373)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1815 (0.1876)	Acc@1 99.219 (99.391)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.183 (0.183)	Data 0.302 (0.302)	Loss 0.1805 (0.1805)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 0.1810 (0.1873)	Acc@1 99.219 (99.345)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.1750 (0.1866)	Acc@1 100.000 (99.394)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1857 (0.1865)	Acc@1 99.219 (99.391)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.58
Max memory: 89.4856704
 24.188s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1285
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.156416
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.193 (0.193)	Data 0.290 (0.290)	Loss 0.1887 (0.1887)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.1890 (0.1844)	Acc@1 99.219 (99.459)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1831 (0.1844)	Acc@1 99.609 (99.479)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1986 (0.1846)	Acc@1 99.219 (99.468)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.8125312
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.181 (0.181)	Data 0.256 (0.256)	Loss 0.1843 (0.1843)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.1868 (0.1846)	Acc@1 98.438 (99.447)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.1852 (0.1837)	Acc@1 99.219 (99.482)	Acc@5 100.000 (99.997)
Epoch: [167][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.1915 (0.1839)	Acc@1 99.219 (99.474)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9829248
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.143 (0.143)	Data 0.277 (0.277)	Loss 0.1767 (0.1767)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.1704 (0.1822)	Acc@1 100.000 (99.537)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1800 (0.1825)	Acc@1 99.219 (99.512)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1953 (0.1823)	Acc@1 98.828 (99.514)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.160 (0.160)	Data 0.262 (0.262)	Loss 0.1723 (0.1723)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.1883 (0.1807)	Acc@1 99.609 (99.549)	Acc@5 100.000 (99.994)
Epoch: [169][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.1889 (0.1817)	Acc@1 99.219 (99.509)	Acc@5 100.000 (99.997)
Epoch: [169][192/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.1802 (0.1821)	Acc@1 99.609 (99.468)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.187 (0.187)	Data 0.260 (0.260)	Loss 0.1846 (0.1846)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.1818 (0.1805)	Acc@1 99.609 (99.507)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.1877 (0.1814)	Acc@1 100.000 (99.491)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1827 (0.1816)	Acc@1 99.609 (99.476)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.85
Max memory: 89.4856704
 24.183s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9701
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.156416
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.196 (0.196)	Data 0.284 (0.284)	Loss 0.1753 (0.1753)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.114 (0.123)	Data 0.000 (0.005)	Loss 0.1884 (0.1799)	Acc@1 98.438 (99.561)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.129 (0.123)	Data 0.000 (0.002)	Loss 0.1708 (0.1796)	Acc@1 100.000 (99.540)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.1746 (0.1798)	Acc@1 100.000 (99.530)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.8125312
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.174 (0.174)	Data 0.265 (0.265)	Loss 0.1731 (0.1731)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.1733 (0.1789)	Acc@1 100.000 (99.543)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.1850 (0.1790)	Acc@1 98.828 (99.522)	Acc@5 100.000 (99.997)
Epoch: [172][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1841 (0.1789)	Acc@1 98.828 (99.539)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.9829248
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.176 (0.176)	Data 0.289 (0.289)	Loss 0.1721 (0.1721)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.1972 (0.1794)	Acc@1 99.219 (99.543)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.1834 (0.1785)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.1724 (0.1788)	Acc@1 99.609 (99.557)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.170 (0.170)	Data 0.268 (0.268)	Loss 0.1772 (0.1772)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.117 (0.122)	Data 0.000 (0.004)	Loss 0.1733 (0.1779)	Acc@1 99.609 (99.567)	Acc@5 100.000 (99.994)
Epoch: [174][128/196]	Time 0.140 (0.122)	Data 0.000 (0.002)	Loss 0.1664 (0.1780)	Acc@1 100.000 (99.555)	Acc@5 100.000 (99.994)
Epoch: [174][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1919 (0.1782)	Acc@1 99.219 (99.567)	Acc@5 100.000 (99.994)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.161 (0.161)	Data 0.284 (0.284)	Loss 0.1995 (0.1995)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.1672 (0.1800)	Acc@1 100.000 (99.441)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1814 (0.1779)	Acc@1 98.828 (99.537)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.1779 (0.1771)	Acc@1 99.609 (99.573)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.9436032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.64
Max memory: 89.4856704
 24.455s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3391
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.156416
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.194 (0.194)	Data 0.265 (0.265)	Loss 0.1719 (0.1719)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.1755 (0.1770)	Acc@1 99.219 (99.585)	Acc@5 100.000 (99.994)
Epoch: [176][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.1679 (0.1766)	Acc@1 100.000 (99.576)	Acc@5 100.000 (99.994)
Epoch: [176][192/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.1758 (0.1763)	Acc@1 99.609 (99.573)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.8125312
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.145 (0.145)	Data 0.290 (0.290)	Loss 0.1894 (0.1894)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.1963 (0.1747)	Acc@1 98.828 (99.621)	Acc@5 99.609 (99.994)
Epoch: [177][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1697 (0.1746)	Acc@1 99.609 (99.612)	Acc@5 100.000 (99.997)
Epoch: [177][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1871 (0.1755)	Acc@1 99.219 (99.587)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9829248
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.176 (0.176)	Data 0.265 (0.265)	Loss 0.1841 (0.1841)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.1739 (0.1742)	Acc@1 99.609 (99.645)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1683 (0.1746)	Acc@1 100.000 (99.606)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1775 (0.1747)	Acc@1 99.219 (99.613)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.163 (0.163)	Data 0.287 (0.287)	Loss 0.1932 (0.1932)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.1746 (0.1738)	Acc@1 100.000 (99.657)	Acc@5 100.000 (99.994)
Epoch: [179][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.1720 (0.1740)	Acc@1 99.609 (99.649)	Acc@5 100.000 (99.997)
Epoch: [179][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.1721 (0.1737)	Acc@1 99.609 (99.652)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.9436032
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.158 (0.158)	Data 0.291 (0.291)	Loss 0.1786 (0.1786)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.1870 (0.1748)	Acc@1 98.828 (99.525)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1801 (0.1739)	Acc@1 99.609 (99.564)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.142 (0.120)	Data 0.000 (0.002)	Loss 0.1738 (0.1735)	Acc@1 99.219 (99.593)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.9436032
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 30, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(22, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(58, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.73
Max memory: 89.4856704
 23.875s  Thres 0.0001 1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6117
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.190 (0.190)	Data 0.290 (0.290)	Loss 3.1094 (3.1094)	Acc@1 14.062 (14.062)	Acc@5 52.344 (52.344)
Epoch: [1][64/196]	Time 0.151 (0.130)	Data 0.000 (0.005)	Loss 2.3778 (2.6016)	Acc@1 37.891 (25.829)	Acc@5 85.938 (78.540)
Epoch: [1][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 2.0897 (2.4331)	Acc@1 41.406 (31.744)	Acc@5 92.578 (83.548)
Epoch: [1][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.9999 (2.2936)	Acc@1 52.344 (36.788)	Acc@5 91.797 (86.565)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.180 (0.180)	Data 0.260 (0.260)	Loss 1.9981 (1.9981)	Acc@1 46.875 (46.875)	Acc@5 93.750 (93.750)
Epoch: [2][64/196]	Time 0.151 (0.131)	Data 0.000 (0.004)	Loss 1.8273 (1.8443)	Acc@1 53.906 (52.915)	Acc@5 95.703 (93.996)
Epoch: [2][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.5842 (1.7767)	Acc@1 61.719 (54.842)	Acc@5 94.922 (94.764)
Epoch: [2][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 1.5544 (1.7175)	Acc@1 61.719 (56.568)	Acc@5 96.484 (95.240)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.176 (0.176)	Data 0.269 (0.269)	Loss 1.4626 (1.4626)	Acc@1 67.188 (67.188)	Acc@5 96.875 (96.875)
Epoch: [3][64/196]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 1.3737 (1.4733)	Acc@1 68.750 (64.892)	Acc@5 98.047 (96.941)
Epoch: [3][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.4005 (1.4389)	Acc@1 66.797 (65.728)	Acc@5 96.484 (97.120)
Epoch: [3][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.4419 (1.4006)	Acc@1 62.109 (67.009)	Acc@5 94.922 (97.231)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.170 (0.170)	Data 0.267 (0.267)	Loss 1.2731 (1.2731)	Acc@1 69.922 (69.922)	Acc@5 98.047 (98.047)
Epoch: [4][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 1.2434 (1.2445)	Acc@1 71.094 (71.707)	Acc@5 98.828 (97.915)
Epoch: [4][128/196]	Time 0.140 (0.131)	Data 0.000 (0.002)	Loss 1.2047 (1.2187)	Acc@1 73.828 (72.511)	Acc@5 98.438 (98.029)
Epoch: [4][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 1.0883 (1.2004)	Acc@1 76.562 (72.986)	Acc@5 99.219 (98.027)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.175 (0.175)	Data 0.292 (0.292)	Loss 1.2047 (1.2047)	Acc@1 71.094 (71.094)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.123 (0.132)	Data 0.000 (0.005)	Loss 1.0398 (1.1037)	Acc@1 77.344 (75.553)	Acc@5 98.828 (98.498)
Epoch: [5][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 1.0742 (1.0942)	Acc@1 76.953 (75.675)	Acc@5 98.828 (98.495)
Epoch: [5][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 1.0447 (1.0794)	Acc@1 76.562 (75.854)	Acc@5 97.656 (98.539)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  64.39
Max memory: 103.3835008
 26.072s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5263
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.219 (0.219)	Data 0.258 (0.258)	Loss 0.9862 (0.9862)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [6][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.9608 (0.9846)	Acc@1 78.125 (78.978)	Acc@5 99.219 (98.822)
Epoch: [6][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.9198 (0.9917)	Acc@1 80.859 (78.500)	Acc@5 99.219 (98.752)
Epoch: [6][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.9578 (0.9930)	Acc@1 80.469 (78.319)	Acc@5 99.219 (98.695)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.176 (0.176)	Data 0.281 (0.281)	Loss 0.8968 (0.8968)	Acc@1 82.422 (82.422)	Acc@5 98.047 (98.047)
Epoch: [7][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.8814 (0.9358)	Acc@1 82.422 (79.964)	Acc@5 98.828 (98.852)
Epoch: [7][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 1.0101 (0.9417)	Acc@1 75.391 (79.485)	Acc@5 98.438 (98.792)
Epoch: [7][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.9594 (0.9359)	Acc@1 75.781 (79.611)	Acc@5 98.047 (98.820)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.176 (0.176)	Data 0.265 (0.265)	Loss 0.8833 (0.8833)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [8][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.8620 (0.8977)	Acc@1 79.688 (80.228)	Acc@5 99.219 (98.924)
Epoch: [8][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8696 (0.8890)	Acc@1 80.469 (80.496)	Acc@5 99.219 (99.019)
Epoch: [8][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.8361 (0.8900)	Acc@1 82.422 (80.416)	Acc@5 99.609 (99.016)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.182 (0.182)	Data 0.304 (0.304)	Loss 0.8234 (0.8234)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 0.9308 (0.8508)	Acc@1 80.469 (81.388)	Acc@5 98.438 (99.044)
Epoch: [9][128/196]	Time 0.132 (0.129)	Data 0.000 (0.003)	Loss 0.8772 (0.8615)	Acc@1 80.859 (80.971)	Acc@5 98.047 (99.013)
Epoch: [9][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8164 (0.8566)	Acc@1 80.859 (81.100)	Acc@5 99.609 (99.028)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.158 (0.158)	Data 0.295 (0.295)	Loss 0.7958 (0.7958)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [10][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.7204 (0.8321)	Acc@1 85.547 (81.701)	Acc@5 99.609 (99.183)
Epoch: [10][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8100 (0.8312)	Acc@1 80.859 (81.756)	Acc@5 99.219 (99.064)
Epoch: [10][192/196]	Time 0.137 (0.130)	Data 0.000 (0.002)	Loss 0.8212 (0.8271)	Acc@1 83.203 (81.944)	Acc@5 98.828 (99.085)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.46
Max memory: 103.3833984
 25.809s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6510
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.191 (0.191)	Data 0.261 (0.261)	Loss 0.8379 (0.8379)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.127 (0.131)	Data 0.000 (0.004)	Loss 0.8410 (0.8102)	Acc@1 78.516 (82.121)	Acc@5 98.828 (99.111)
Epoch: [11][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8658 (0.8204)	Acc@1 82.422 (82.062)	Acc@5 98.438 (99.137)
Epoch: [11][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7104 (0.8214)	Acc@1 86.719 (81.991)	Acc@5 99.609 (99.134)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.188 (0.188)	Data 0.293 (0.293)	Loss 0.7648 (0.7648)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [12][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.7911 (0.7803)	Acc@1 80.078 (83.281)	Acc@5 99.219 (99.165)
Epoch: [12][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.8129 (0.7973)	Acc@1 80.469 (82.725)	Acc@5 100.000 (99.146)
Epoch: [12][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8582 (0.8003)	Acc@1 80.078 (82.634)	Acc@5 99.609 (99.120)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.152 (0.152)	Data 0.287 (0.287)	Loss 0.7888 (0.7888)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [13][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.8483 (0.7832)	Acc@1 80.469 (83.011)	Acc@5 99.219 (99.177)
Epoch: [13][128/196]	Time 0.143 (0.130)	Data 0.000 (0.002)	Loss 0.8944 (0.7905)	Acc@1 80.469 (82.840)	Acc@5 97.266 (99.122)
Epoch: [13][192/196]	Time 0.144 (0.131)	Data 0.000 (0.002)	Loss 0.7051 (0.7911)	Acc@1 86.328 (82.707)	Acc@5 99.609 (99.148)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.176 (0.176)	Data 0.294 (0.294)	Loss 0.7092 (0.7092)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [14][64/196]	Time 0.122 (0.129)	Data 0.000 (0.005)	Loss 0.7807 (0.7925)	Acc@1 83.594 (82.716)	Acc@5 98.828 (99.105)
Epoch: [14][128/196]	Time 0.136 (0.129)	Data 0.000 (0.002)	Loss 0.7972 (0.7940)	Acc@1 82.422 (82.555)	Acc@5 99.219 (99.143)
Epoch: [14][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7095 (0.7906)	Acc@1 86.328 (82.711)	Acc@5 99.219 (99.138)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.162 (0.162)	Data 0.263 (0.263)	Loss 0.7772 (0.7772)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.131 (0.132)	Data 0.000 (0.004)	Loss 0.8838 (0.7756)	Acc@1 78.906 (83.215)	Acc@5 99.219 (99.141)
Epoch: [15][128/196]	Time 0.121 (0.131)	Data 0.000 (0.002)	Loss 0.9255 (0.7798)	Acc@1 78.125 (83.037)	Acc@5 99.609 (99.216)
Epoch: [15][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7230 (0.7773)	Acc@1 84.375 (83.191)	Acc@5 98.828 (99.221)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  79.18
Max memory: 103.3833984
 26.083s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8491
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.185 (0.185)	Data 0.283 (0.283)	Loss 0.6393 (0.6393)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [16][64/196]	Time 0.135 (0.132)	Data 0.000 (0.005)	Loss 0.7708 (0.7539)	Acc@1 84.766 (83.978)	Acc@5 99.609 (99.417)
Epoch: [16][128/196]	Time 0.136 (0.131)	Data 0.000 (0.002)	Loss 0.9030 (0.7638)	Acc@1 82.031 (83.730)	Acc@5 98.438 (99.304)
Epoch: [16][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.9260 (0.7637)	Acc@1 80.078 (83.693)	Acc@5 99.219 (99.294)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.194 (0.194)	Data 0.319 (0.319)	Loss 0.6782 (0.6782)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.8498 (0.7650)	Acc@1 81.641 (83.570)	Acc@5 98.828 (99.345)
Epoch: [17][128/196]	Time 0.133 (0.132)	Data 0.000 (0.003)	Loss 0.7307 (0.7608)	Acc@1 84.766 (83.706)	Acc@5 98.828 (99.316)
Epoch: [17][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7366 (0.7666)	Acc@1 83.594 (83.576)	Acc@5 100.000 (99.275)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.188 (0.188)	Data 0.289 (0.289)	Loss 0.7368 (0.7368)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [18][64/196]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.7839 (0.7569)	Acc@1 81.641 (83.900)	Acc@5 99.609 (99.285)
Epoch: [18][128/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.7712 (0.7633)	Acc@1 82.031 (83.815)	Acc@5 99.609 (99.249)
Epoch: [18][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.7103 (0.7587)	Acc@1 85.547 (83.990)	Acc@5 98.828 (99.263)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.186 (0.186)	Data 0.261 (0.261)	Loss 0.7608 (0.7608)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.131 (0.133)	Data 0.000 (0.004)	Loss 0.6859 (0.7422)	Acc@1 84.375 (84.345)	Acc@5 99.609 (99.351)
Epoch: [19][128/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.7628 (0.7462)	Acc@1 81.250 (84.248)	Acc@5 100.000 (99.307)
Epoch: [19][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.7693 (0.7507)	Acc@1 82.812 (84.152)	Acc@5 98.828 (99.273)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.155 (0.155)	Data 0.293 (0.293)	Loss 0.7172 (0.7172)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [20][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.8271 (0.7529)	Acc@1 81.641 (84.231)	Acc@5 99.609 (99.279)
Epoch: [20][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.8311 (0.7511)	Acc@1 81.641 (84.360)	Acc@5 99.219 (99.216)
Epoch: [20][192/196]	Time 0.149 (0.132)	Data 0.000 (0.002)	Loss 0.7493 (0.7524)	Acc@1 83.594 (84.276)	Acc@5 99.219 (99.249)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  80.56
Max memory: 103.3833984
 26.315s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6540
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.202496
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.224 (0.224)	Data 0.258 (0.258)	Loss 0.7347 (0.7347)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.127 (0.132)	Data 0.000 (0.004)	Loss 0.7506 (0.7067)	Acc@1 84.375 (85.751)	Acc@5 100.000 (99.351)
Epoch: [21][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.7996 (0.7395)	Acc@1 83.203 (84.702)	Acc@5 99.219 (99.276)
Epoch: [21][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8622 (0.7384)	Acc@1 79.688 (84.836)	Acc@5 99.609 (99.255)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.188 (0.188)	Data 0.267 (0.267)	Loss 0.7256 (0.7256)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.138 (0.132)	Data 0.000 (0.004)	Loss 0.7274 (0.7431)	Acc@1 85.547 (84.471)	Acc@5 98.828 (99.255)
Epoch: [22][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8054 (0.7440)	Acc@1 82.422 (84.454)	Acc@5 99.609 (99.288)
Epoch: [22][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.8611 (0.7441)	Acc@1 82.422 (84.468)	Acc@5 99.609 (99.296)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.185 (0.185)	Data 0.286 (0.286)	Loss 0.6913 (0.6913)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.7191 (0.7405)	Acc@1 82.422 (84.814)	Acc@5 98.828 (99.381)
Epoch: [23][128/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.7368 (0.7360)	Acc@1 84.375 (84.893)	Acc@5 99.219 (99.349)
Epoch: [23][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7202 (0.7371)	Acc@1 86.719 (84.857)	Acc@5 99.219 (99.324)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.186 (0.186)	Data 0.271 (0.271)	Loss 0.7296 (0.7296)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.8036 (0.7182)	Acc@1 84.766 (85.367)	Acc@5 99.219 (99.399)
Epoch: [24][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6956 (0.7258)	Acc@1 87.891 (85.141)	Acc@5 98.438 (99.385)
Epoch: [24][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8056 (0.7285)	Acc@1 82.422 (84.996)	Acc@5 99.609 (99.381)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.157 (0.157)	Data 0.290 (0.290)	Loss 0.7271 (0.7271)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.7303 (0.7218)	Acc@1 85.938 (85.463)	Acc@5 99.219 (99.255)
Epoch: [25][128/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7644 (0.7317)	Acc@1 82.812 (84.738)	Acc@5 100.000 (99.310)
Epoch: [25][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7613 (0.7311)	Acc@1 83.594 (84.838)	Acc@5 99.219 (99.320)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 485078 ; 487386 ; 0.9952645336550496
[INFO] Storing checkpoint...
  81.21
Max memory: 103.3833984
 26.129s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3529
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.2015744
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.187 (0.187)	Data 0.284 (0.284)	Loss 0.7673 (0.7673)	Acc@1 83.203 (83.203)	Acc@5 98.828 (98.828)
Epoch: [26][64/196]	Time 0.129 (0.133)	Data 0.000 (0.005)	Loss 0.6475 (0.7019)	Acc@1 89.062 (85.931)	Acc@5 99.219 (99.369)
Epoch: [26][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.6816 (0.7163)	Acc@1 85.547 (85.338)	Acc@5 100.000 (99.385)
Epoch: [26][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.6927 (0.7216)	Acc@1 86.328 (85.130)	Acc@5 99.219 (99.336)
Max memory in training epoch: 66.6429952
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.162 (0.162)	Data 0.294 (0.294)	Loss 0.6512 (0.6512)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.7767 (0.7137)	Acc@1 83.203 (85.373)	Acc@5 99.219 (99.387)
Epoch: [27][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7800 (0.7181)	Acc@1 82.422 (85.347)	Acc@5 99.219 (99.361)
Epoch: [27][192/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7071 (0.7276)	Acc@1 83.594 (85.031)	Acc@5 99.609 (99.320)
Max memory in training epoch: 66.5381376
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.192 (0.192)	Data 0.261 (0.261)	Loss 0.7476 (0.7476)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.6659 (0.7070)	Acc@1 87.500 (85.871)	Acc@5 99.219 (99.417)
Epoch: [28][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.6730 (0.7117)	Acc@1 83.203 (85.480)	Acc@5 99.219 (99.382)
Epoch: [28][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7558 (0.7161)	Acc@1 85.156 (85.367)	Acc@5 99.609 (99.377)
Max memory in training epoch: 66.5381376
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.193 (0.193)	Data 0.293 (0.293)	Loss 0.7035 (0.7035)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.7981 (0.7268)	Acc@1 82.031 (84.946)	Acc@5 99.609 (99.429)
Epoch: [29][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7501 (0.7211)	Acc@1 83.203 (85.199)	Acc@5 100.000 (99.400)
Epoch: [29][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.7216 (0.7213)	Acc@1 83.594 (85.304)	Acc@5 99.219 (99.344)
Max memory in training epoch: 66.5381376
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.169 (0.169)	Data 0.265 (0.265)	Loss 0.7167 (0.7167)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [30][64/196]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.7210 (0.7201)	Acc@1 86.328 (85.306)	Acc@5 98.828 (99.417)
Epoch: [30][128/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.6416 (0.7135)	Acc@1 87.891 (85.535)	Acc@5 100.000 (99.422)
Epoch: [30][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7056 (0.7181)	Acc@1 83.594 (85.357)	Acc@5 100.000 (99.401)
Max memory in training epoch: 66.5381376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 467188 ; 485078 ; 0.9631193333855587
[INFO] Storing checkpoint...
  68.5
Max memory: 103.3806336
 26.281s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5425
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1945088
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.192 (0.192)	Data 0.271 (0.271)	Loss 0.8459 (0.8459)	Acc@1 78.125 (78.125)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.134 (0.131)	Data 0.000 (0.004)	Loss 0.7621 (0.6865)	Acc@1 82.812 (86.154)	Acc@5 98.438 (99.507)
Epoch: [31][128/196]	Time 0.121 (0.131)	Data 0.000 (0.002)	Loss 0.7302 (0.7044)	Acc@1 85.547 (85.617)	Acc@5 99.609 (99.397)
Epoch: [31][192/196]	Time 0.136 (0.130)	Data 0.000 (0.002)	Loss 0.7042 (0.7163)	Acc@1 85.156 (85.257)	Acc@5 99.219 (99.360)
Max memory in training epoch: 66.6147328
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.154 (0.154)	Data 0.268 (0.268)	Loss 0.6675 (0.6675)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [32][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6972 (0.7084)	Acc@1 87.891 (85.523)	Acc@5 99.609 (99.465)
Epoch: [32][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7038 (0.7138)	Acc@1 84.375 (85.598)	Acc@5 98.828 (99.461)
Epoch: [32][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7753 (0.7151)	Acc@1 83.203 (85.563)	Acc@5 99.219 (99.411)
Max memory in training epoch: 66.1953024
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.182 (0.182)	Data 0.256 (0.256)	Loss 0.5916 (0.5916)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.7587 (0.6972)	Acc@1 83.984 (86.052)	Acc@5 100.000 (99.429)
Epoch: [33][128/196]	Time 0.138 (0.132)	Data 0.000 (0.002)	Loss 0.8431 (0.6987)	Acc@1 82.812 (86.143)	Acc@5 99.219 (99.437)
Epoch: [33][192/196]	Time 0.128 (0.131)	Data 0.000 (0.001)	Loss 0.6471 (0.7023)	Acc@1 88.672 (86.047)	Acc@5 99.219 (99.439)
Max memory in training epoch: 66.1953024
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.170 (0.170)	Data 0.299 (0.299)	Loss 0.6866 (0.6866)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [34][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.7110 (0.6993)	Acc@1 87.500 (85.944)	Acc@5 98.828 (99.471)
Epoch: [34][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6307 (0.7050)	Acc@1 89.844 (85.747)	Acc@5 100.000 (99.449)
Epoch: [34][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.5999 (0.7056)	Acc@1 90.234 (85.703)	Acc@5 100.000 (99.429)
Max memory in training epoch: 66.1953024
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.157 (0.157)	Data 0.306 (0.306)	Loss 0.8365 (0.8365)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.7452 (0.7089)	Acc@1 86.328 (85.577)	Acc@5 99.219 (99.339)
Epoch: [35][128/196]	Time 0.123 (0.130)	Data 0.000 (0.003)	Loss 0.6601 (0.7111)	Acc@1 87.500 (85.574)	Acc@5 99.219 (99.343)
Epoch: [35][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7292 (0.7095)	Acc@1 84.375 (85.701)	Acc@5 98.828 (99.360)
Max memory in training epoch: 66.1953024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 458818 ; 467188 ; 0.982084300110448
[INFO] Storing checkpoint...
  80.73
Max memory: 103.0350336
 25.755s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2324
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.191232
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.203 (0.203)	Data 0.257 (0.257)	Loss 0.8077 (0.8077)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.126 (0.133)	Data 0.000 (0.004)	Loss 0.6467 (0.6791)	Acc@1 89.062 (86.490)	Acc@5 99.609 (99.495)
Epoch: [36][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6671 (0.6873)	Acc@1 86.328 (86.289)	Acc@5 100.000 (99.470)
Epoch: [36][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7525 (0.6951)	Acc@1 83.594 (86.071)	Acc@5 99.609 (99.415)
Max memory in training epoch: 66.3132672
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.180 (0.180)	Data 0.267 (0.267)	Loss 0.6179 (0.6179)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.7209 (0.6952)	Acc@1 88.672 (86.508)	Acc@5 97.656 (99.465)
Epoch: [37][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7104 (0.6947)	Acc@1 85.547 (86.313)	Acc@5 99.609 (99.428)
Epoch: [37][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7154 (0.7032)	Acc@1 86.719 (85.954)	Acc@5 99.219 (99.391)
Max memory in training epoch: 66.2084096
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.167 (0.167)	Data 0.292 (0.292)	Loss 0.6286 (0.6286)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [38][64/196]	Time 0.123 (0.132)	Data 0.000 (0.005)	Loss 0.7032 (0.6863)	Acc@1 87.109 (86.520)	Acc@5 99.219 (99.477)
Epoch: [38][128/196]	Time 0.138 (0.132)	Data 0.000 (0.002)	Loss 0.7494 (0.6899)	Acc@1 82.422 (86.249)	Acc@5 99.219 (99.434)
Epoch: [38][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7524 (0.6929)	Acc@1 85.938 (86.186)	Acc@5 99.219 (99.395)
Max memory in training epoch: 66.2084096
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.172 (0.172)	Data 0.268 (0.268)	Loss 0.6030 (0.6030)	Acc@1 90.234 (90.234)	Acc@5 99.219 (99.219)
Epoch: [39][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.6359 (0.7046)	Acc@1 89.062 (85.787)	Acc@5 99.609 (99.393)
Epoch: [39][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7205 (0.6982)	Acc@1 85.547 (86.104)	Acc@5 99.219 (99.440)
Epoch: [39][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6511 (0.6983)	Acc@1 88.281 (86.081)	Acc@5 99.219 (99.421)
Max memory in training epoch: 66.2084096
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.166 (0.166)	Data 0.300 (0.300)	Loss 0.6783 (0.6783)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.142 (0.130)	Data 0.000 (0.005)	Loss 0.6570 (0.6758)	Acc@1 85.547 (86.665)	Acc@5 98.438 (99.477)
Epoch: [40][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.7485 (0.6889)	Acc@1 83.984 (86.271)	Acc@5 100.000 (99.406)
Epoch: [40][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7733 (0.6916)	Acc@1 84.375 (86.110)	Acc@5 99.219 (99.405)
Max memory in training epoch: 66.2084096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 440060 ; 458818 ; 0.9591166867908408
[INFO] Storing checkpoint...
  63.11
Max memory: 102.6274816
 25.938s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1222
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1838592
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.207 (0.207)	Data 0.312 (0.312)	Loss 0.6545 (0.6545)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [41][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6825 (0.6655)	Acc@1 87.109 (87.013)	Acc@5 100.000 (99.387)
Epoch: [41][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.7259 (0.6767)	Acc@1 84.766 (86.555)	Acc@5 99.609 (99.479)
Epoch: [41][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6515 (0.6831)	Acc@1 87.109 (86.381)	Acc@5 98.828 (99.443)
Max memory in training epoch: 65.8381312
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.179 (0.179)	Data 0.281 (0.281)	Loss 0.6330 (0.6330)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [42][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.7507 (0.6903)	Acc@1 84.766 (86.076)	Acc@5 99.219 (99.531)
Epoch: [42][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7119 (0.6863)	Acc@1 85.938 (86.277)	Acc@5 98.438 (99.528)
Epoch: [42][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6473 (0.6893)	Acc@1 86.328 (86.265)	Acc@5 98.828 (99.502)
Max memory in training epoch: 65.6742912
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.153 (0.153)	Data 0.325 (0.325)	Loss 0.6497 (0.6497)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [43][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.8297 (0.6969)	Acc@1 81.641 (85.889)	Acc@5 99.219 (99.507)
Epoch: [43][128/196]	Time 0.131 (0.130)	Data 0.000 (0.003)	Loss 0.6834 (0.6963)	Acc@1 88.281 (85.938)	Acc@5 98.828 (99.464)
Epoch: [43][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8568 (0.6999)	Acc@1 79.297 (85.887)	Acc@5 99.609 (99.435)
Max memory in training epoch: 65.6742912
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.185 (0.185)	Data 0.261 (0.261)	Loss 0.7378 (0.7378)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.6109 (0.6857)	Acc@1 91.406 (86.310)	Acc@5 100.000 (99.465)
Epoch: [44][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6876 (0.6921)	Acc@1 84.766 (86.174)	Acc@5 99.609 (99.449)
Epoch: [44][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6859 (0.6925)	Acc@1 87.500 (86.180)	Acc@5 100.000 (99.449)
Max memory in training epoch: 65.6742912
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.184 (0.184)	Data 0.271 (0.271)	Loss 0.5933 (0.5933)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.6657 (0.6853)	Acc@1 87.500 (86.550)	Acc@5 99.219 (99.459)
Epoch: [45][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6753 (0.6782)	Acc@1 87.500 (86.673)	Acc@5 99.609 (99.503)
Epoch: [45][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6703 (0.6808)	Acc@1 85.938 (86.500)	Acc@5 99.609 (99.492)
Max memory in training epoch: 65.6742912
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 429088 ; 440060 ; 0.97506703631323
[INFO] Storing checkpoint...
  78.23
Max memory: 101.5973376
 25.799s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6319
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.179456
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.188 (0.188)	Data 0.297 (0.297)	Loss 0.7387 (0.7387)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.6893 (0.6637)	Acc@1 86.719 (86.863)	Acc@5 99.609 (99.549)
Epoch: [46][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7669 (0.6683)	Acc@1 82.422 (86.861)	Acc@5 99.609 (99.491)
Epoch: [46][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6597 (0.6799)	Acc@1 85.156 (86.561)	Acc@5 100.000 (99.445)
Max memory in training epoch: 64.9816576
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.151 (0.151)	Data 0.296 (0.296)	Loss 0.6028 (0.6028)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.133 (0.128)	Data 0.000 (0.005)	Loss 0.8159 (0.6968)	Acc@1 83.203 (85.992)	Acc@5 98.828 (99.441)
Epoch: [47][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7927 (0.6884)	Acc@1 83.984 (86.207)	Acc@5 98.828 (99.455)
Epoch: [47][192/196]	Time 0.135 (0.129)	Data 0.000 (0.002)	Loss 0.6400 (0.6842)	Acc@1 87.500 (86.425)	Acc@5 99.609 (99.452)
Max memory in training epoch: 65.0275328
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.156 (0.156)	Data 0.268 (0.268)	Loss 0.6429 (0.6429)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [48][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.6829 (0.6877)	Acc@1 86.328 (86.100)	Acc@5 98.828 (99.471)
Epoch: [48][128/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6233 (0.6826)	Acc@1 89.062 (86.395)	Acc@5 99.609 (99.482)
Epoch: [48][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6700 (0.6840)	Acc@1 86.719 (86.367)	Acc@5 99.219 (99.482)
Max memory in training epoch: 65.0275328
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.179 (0.179)	Data 0.300 (0.300)	Loss 0.6322 (0.6322)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [49][64/196]	Time 0.129 (0.130)	Data 0.000 (0.005)	Loss 0.7448 (0.6778)	Acc@1 84.375 (86.701)	Acc@5 98.828 (99.501)
Epoch: [49][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7178 (0.6836)	Acc@1 85.547 (86.501)	Acc@5 99.219 (99.482)
Epoch: [49][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6731 (0.6875)	Acc@1 86.719 (86.243)	Acc@5 99.219 (99.462)
Max memory in training epoch: 65.0275328
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.171 (0.171)	Data 0.260 (0.260)	Loss 0.6057 (0.6057)	Acc@1 91.016 (91.016)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.6617 (0.6817)	Acc@1 87.109 (86.538)	Acc@5 100.000 (99.417)
Epoch: [50][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.5747 (0.6796)	Acc@1 89.844 (86.558)	Acc@5 100.000 (99.419)
Epoch: [50][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.7212 (0.6818)	Acc@1 87.109 (86.500)	Acc@5 99.609 (99.417)
Max memory in training epoch: 65.0275328
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423600 ; 429088 ; 0.9872100827802223
[INFO] Storing checkpoint...
  81.82
Max memory: 100.40448
 25.671s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4938
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1773056
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.193 (0.193)	Data 0.281 (0.281)	Loss 0.6901 (0.6901)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.142 (0.130)	Data 0.000 (0.005)	Loss 0.6838 (0.6542)	Acc@1 87.891 (87.518)	Acc@5 100.000 (99.507)
Epoch: [51][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 0.6608 (0.6593)	Acc@1 85.938 (87.237)	Acc@5 99.609 (99.488)
Epoch: [51][192/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.6312 (0.6662)	Acc@1 87.109 (86.949)	Acc@5 100.000 (99.494)
Max memory in training epoch: 64.4191744
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.162 (0.162)	Data 0.292 (0.292)	Loss 0.6240 (0.6240)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [52][64/196]	Time 0.132 (0.129)	Data 0.000 (0.005)	Loss 0.6254 (0.6716)	Acc@1 89.062 (86.599)	Acc@5 99.609 (99.519)
Epoch: [52][128/196]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.6342 (0.6824)	Acc@1 87.891 (86.249)	Acc@5 100.000 (99.485)
Epoch: [52][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7466 (0.6778)	Acc@1 83.203 (86.425)	Acc@5 100.000 (99.470)
Max memory in training epoch: 64.7567872
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.174 (0.174)	Data 0.299 (0.299)	Loss 0.5775 (0.5775)	Acc@1 90.625 (90.625)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6876 (0.6751)	Acc@1 83.984 (86.605)	Acc@5 98.828 (99.459)
Epoch: [53][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7026 (0.6708)	Acc@1 85.547 (86.852)	Acc@5 99.609 (99.437)
Epoch: [53][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6812 (0.6765)	Acc@1 87.500 (86.567)	Acc@5 98.828 (99.423)
Max memory in training epoch: 64.7567872
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.162 (0.162)	Data 0.257 (0.257)	Loss 0.7591 (0.7591)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.6149 (0.6925)	Acc@1 88.281 (86.118)	Acc@5 99.609 (99.363)
Epoch: [54][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7732 (0.6785)	Acc@1 82.422 (86.507)	Acc@5 99.609 (99.434)
Epoch: [54][192/196]	Time 0.129 (0.130)	Data 0.000 (0.001)	Loss 0.6688 (0.6794)	Acc@1 87.500 (86.583)	Acc@5 99.219 (99.433)
Max memory in training epoch: 64.7567872
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.176 (0.176)	Data 0.293 (0.293)	Loss 0.6735 (0.6735)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.6163 (0.6689)	Acc@1 88.672 (86.953)	Acc@5 100.000 (99.489)
Epoch: [55][128/196]	Time 0.119 (0.130)	Data 0.000 (0.002)	Loss 0.7420 (0.6682)	Acc@1 83.594 (86.819)	Acc@5 98.828 (99.488)
Epoch: [55][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.7556 (0.6722)	Acc@1 85.938 (86.690)	Acc@5 98.047 (99.478)
Max memory in training epoch: 64.7567872
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 416958 ; 423600 ; 0.9843201133144476
[INFO] Storing checkpoint...
  77.28
Max memory: 99.3248768
 25.814s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8161
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1747456
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.185 (0.185)	Data 0.286 (0.286)	Loss 0.5816 (0.5816)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.123 (0.129)	Data 0.000 (0.005)	Loss 0.6820 (0.6376)	Acc@1 86.719 (88.077)	Acc@5 100.000 (99.507)
Epoch: [56][128/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.6498 (0.6601)	Acc@1 90.234 (87.312)	Acc@5 99.609 (99.449)
Epoch: [56][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6746 (0.6744)	Acc@1 86.719 (86.836)	Acc@5 100.000 (99.443)
Max memory in training epoch: 64.0715264
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.171 (0.171)	Data 0.297 (0.297)	Loss 0.5875 (0.5875)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [57][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7104 (0.6720)	Acc@1 84.375 (86.851)	Acc@5 99.609 (99.477)
Epoch: [57][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6899 (0.6781)	Acc@1 85.938 (86.710)	Acc@5 99.219 (99.476)
Epoch: [57][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.6294 (0.6808)	Acc@1 89.453 (86.624)	Acc@5 99.609 (99.468)
Max memory in training epoch: 64.2222592
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.165 (0.165)	Data 0.281 (0.281)	Loss 0.7278 (0.7278)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [58][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.7851 (0.6656)	Acc@1 83.594 (86.983)	Acc@5 98.047 (99.525)
Epoch: [58][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.7615 (0.6717)	Acc@1 85.938 (86.595)	Acc@5 99.219 (99.506)
Epoch: [58][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6531 (0.6726)	Acc@1 87.891 (86.656)	Acc@5 98.828 (99.470)
Max memory in training epoch: 64.2288128
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.184 (0.184)	Data 0.280 (0.280)	Loss 0.5911 (0.5911)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.5906 (0.6608)	Acc@1 89.453 (86.923)	Acc@5 100.000 (99.555)
Epoch: [59][128/196]	Time 0.147 (0.130)	Data 0.000 (0.002)	Loss 0.6764 (0.6581)	Acc@1 87.500 (86.964)	Acc@5 100.000 (99.519)
Epoch: [59][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6766 (0.6677)	Acc@1 88.281 (86.753)	Acc@5 100.000 (99.480)
Max memory in training epoch: 64.2288128
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.172 (0.172)	Data 0.272 (0.272)	Loss 0.6153 (0.6153)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [60][64/196]	Time 0.136 (0.131)	Data 0.000 (0.004)	Loss 0.6398 (0.6648)	Acc@1 87.891 (86.827)	Acc@5 99.609 (99.423)
Epoch: [60][128/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.6112 (0.6703)	Acc@1 89.062 (86.652)	Acc@5 100.000 (99.413)
Epoch: [60][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7220 (0.6709)	Acc@1 84.375 (86.498)	Acc@5 100.000 (99.470)
Max memory in training epoch: 64.2288128
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 413636 ; 416958 ; 0.9920327706867358
[INFO] Storing checkpoint...
  76.24
Max memory: 98.6905088
 25.647s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2525
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1733632
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.202 (0.202)	Data 0.256 (0.256)	Loss 0.7076 (0.7076)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.5712 (0.6502)	Acc@1 91.797 (87.776)	Acc@5 100.000 (99.567)
Epoch: [61][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6948 (0.6544)	Acc@1 87.109 (87.391)	Acc@5 99.219 (99.552)
Epoch: [61][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.6022 (0.6602)	Acc@1 90.625 (87.016)	Acc@5 99.219 (99.518)
Max memory in training epoch: 63.5154944
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.170 (0.170)	Data 0.313 (0.313)	Loss 0.7318 (0.7318)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.134 (0.129)	Data 0.000 (0.005)	Loss 0.7673 (0.6741)	Acc@1 83.203 (86.442)	Acc@5 99.219 (99.555)
Epoch: [62][128/196]	Time 0.122 (0.129)	Data 0.000 (0.003)	Loss 0.6910 (0.6691)	Acc@1 87.109 (86.537)	Acc@5 99.219 (99.506)
Epoch: [62][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6758 (0.6667)	Acc@1 85.156 (86.644)	Acc@5 99.609 (99.506)
Max memory in training epoch: 63.5613696
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.154 (0.154)	Data 0.304 (0.304)	Loss 0.6687 (0.6687)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.123 (0.129)	Data 0.000 (0.005)	Loss 0.6858 (0.6588)	Acc@1 88.672 (87.374)	Acc@5 99.609 (99.363)
Epoch: [63][128/196]	Time 0.132 (0.129)	Data 0.000 (0.003)	Loss 0.7288 (0.6676)	Acc@1 83.203 (86.952)	Acc@5 98.828 (99.479)
Epoch: [63][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6550 (0.6696)	Acc@1 86.328 (86.808)	Acc@5 99.609 (99.478)
Max memory in training epoch: 63.5679232
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.174 (0.174)	Data 0.297 (0.297)	Loss 0.6535 (0.6535)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [64][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.5751 (0.6614)	Acc@1 89.844 (86.815)	Acc@5 100.000 (99.429)
Epoch: [64][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7616 (0.6619)	Acc@1 84.375 (86.776)	Acc@5 98.828 (99.467)
Epoch: [64][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7176 (0.6628)	Acc@1 85.938 (86.842)	Acc@5 98.438 (99.470)
Max memory in training epoch: 63.5679232
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.158 (0.158)	Data 0.289 (0.289)	Loss 0.5899 (0.5899)	Acc@1 90.234 (90.234)	Acc@5 99.219 (99.219)
Epoch: [65][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.5918 (0.6610)	Acc@1 89.062 (86.935)	Acc@5 99.219 (99.525)
Epoch: [65][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.6416 (0.6630)	Acc@1 88.672 (86.910)	Acc@5 100.000 (99.494)
Epoch: [65][192/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.6751 (0.6648)	Acc@1 84.766 (86.806)	Acc@5 99.609 (99.496)
Max memory in training epoch: 63.5679232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 403816 ; 413636 ; 0.976259319788413
[INFO] Storing checkpoint...
  78.92
Max memory: 98.6560512
 25.501s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5732
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1695744
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.193 (0.193)	Data 0.287 (0.287)	Loss 0.7359 (0.7359)	Acc@1 85.547 (85.547)	Acc@5 98.438 (98.438)
Epoch: [66][64/196]	Time 0.133 (0.127)	Data 0.000 (0.005)	Loss 0.7198 (0.6324)	Acc@1 84.766 (87.825)	Acc@5 99.609 (99.537)
Epoch: [66][128/196]	Time 0.117 (0.127)	Data 0.000 (0.002)	Loss 0.6635 (0.6525)	Acc@1 86.328 (87.097)	Acc@5 100.000 (99.543)
Epoch: [66][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6596 (0.6587)	Acc@1 85.938 (86.988)	Acc@5 99.609 (99.551)
Max memory in training epoch: 62.438656
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.175 (0.175)	Data 0.298 (0.298)	Loss 0.5791 (0.5791)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.130 (0.127)	Data 0.000 (0.005)	Loss 0.5771 (0.6485)	Acc@1 90.234 (87.506)	Acc@5 99.609 (99.501)
Epoch: [67][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.5716 (0.6510)	Acc@1 89.062 (87.340)	Acc@5 99.609 (99.519)
Epoch: [67][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6512 (0.6575)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.502)
Max memory in training epoch: 62.4124416
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.168 (0.168)	Data 0.294 (0.294)	Loss 0.5825 (0.5825)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.145 (0.129)	Data 0.000 (0.005)	Loss 0.5962 (0.6651)	Acc@1 90.625 (86.905)	Acc@5 100.000 (99.603)
Epoch: [68][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.6549 (0.6581)	Acc@1 88.281 (87.152)	Acc@5 99.219 (99.552)
Epoch: [68][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6558 (0.6655)	Acc@1 86.719 (86.810)	Acc@5 99.609 (99.545)
Max memory in training epoch: 62.4124416
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.188 (0.188)	Data 0.260 (0.260)	Loss 0.6497 (0.6497)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.138 (0.129)	Data 0.000 (0.004)	Loss 0.7061 (0.6498)	Acc@1 85.938 (87.380)	Acc@5 99.219 (99.459)
Epoch: [69][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6305 (0.6577)	Acc@1 88.672 (87.052)	Acc@5 99.219 (99.443)
Epoch: [69][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.7288 (0.6660)	Acc@1 83.203 (86.822)	Acc@5 99.609 (99.462)
Max memory in training epoch: 62.4124416
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.164 (0.164)	Data 0.266 (0.266)	Loss 0.7393 (0.7393)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [70][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.6695 (0.6617)	Acc@1 84.766 (86.707)	Acc@5 99.609 (99.537)
Epoch: [70][128/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.7384 (0.6538)	Acc@1 82.422 (87.094)	Acc@5 99.609 (99.552)
Epoch: [70][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.5685 (0.6631)	Acc@1 87.891 (86.781)	Acc@5 100.000 (99.508)
Max memory in training epoch: 62.4124416
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 398034 ; 403816 ; 0.9856815975592844
[INFO] Storing checkpoint...
  68.12
Max memory: 96.621056
 25.338s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7467
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1672704
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.211 (0.211)	Data 0.258 (0.258)	Loss 0.7401 (0.7401)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [71][64/196]	Time 0.123 (0.126)	Data 0.000 (0.004)	Loss 0.6295 (0.6418)	Acc@1 87.109 (87.746)	Acc@5 100.000 (99.501)
Epoch: [71][128/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.6454 (0.6447)	Acc@1 88.281 (87.609)	Acc@5 99.609 (99.503)
Epoch: [71][192/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.7082 (0.6532)	Acc@1 85.156 (87.239)	Acc@5 99.219 (99.496)
Max memory in training epoch: 60.8172544
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.181 (0.181)	Data 0.287 (0.287)	Loss 0.6197 (0.6197)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.7539 (0.6495)	Acc@1 82.812 (87.121)	Acc@5 99.609 (99.537)
Epoch: [72][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.7396 (0.6536)	Acc@1 84.766 (87.064)	Acc@5 100.000 (99.528)
Epoch: [72][192/196]	Time 0.132 (0.126)	Data 0.000 (0.002)	Loss 0.6148 (0.6597)	Acc@1 87.109 (86.814)	Acc@5 99.609 (99.532)
Max memory in training epoch: 61.0269696
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.153 (0.153)	Data 0.297 (0.297)	Loss 0.6351 (0.6351)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.118 (0.126)	Data 0.000 (0.005)	Loss 0.6217 (0.6646)	Acc@1 88.281 (86.803)	Acc@5 100.000 (99.453)
Epoch: [73][128/196]	Time 0.132 (0.126)	Data 0.000 (0.002)	Loss 0.7627 (0.6661)	Acc@1 84.375 (86.643)	Acc@5 98.438 (99.485)
Epoch: [73][192/196]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.6793 (0.6685)	Acc@1 85.938 (86.650)	Acc@5 99.609 (99.510)
Max memory in training epoch: 60.9745408
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.166 (0.166)	Data 0.307 (0.307)	Loss 0.5241 (0.5241)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.8002 (0.6418)	Acc@1 80.078 (87.608)	Acc@5 99.609 (99.579)
Epoch: [74][128/196]	Time 0.125 (0.125)	Data 0.000 (0.003)	Loss 0.5642 (0.6507)	Acc@1 90.625 (87.358)	Acc@5 100.000 (99.531)
Epoch: [74][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.6696 (0.6517)	Acc@1 87.109 (87.257)	Acc@5 99.219 (99.532)
Max memory in training epoch: 60.9745408
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.178 (0.178)	Data 0.270 (0.270)	Loss 0.6863 (0.6863)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.123 (0.126)	Data 0.000 (0.004)	Loss 0.6670 (0.6605)	Acc@1 83.984 (86.971)	Acc@5 99.219 (99.567)
Epoch: [75][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.6461 (0.6550)	Acc@1 88.281 (87.025)	Acc@5 99.609 (99.552)
Epoch: [75][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.6217 (0.6536)	Acc@1 89.062 (87.117)	Acc@5 99.609 (99.565)
Max memory in training epoch: 60.9745408
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 395864 ; 398034 ; 0.9945482044247477
[INFO] Storing checkpoint...
  79.24
Max memory: 95.0953472
 25.108s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8387
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1664
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.189 (0.189)	Data 0.270 (0.270)	Loss 0.6679 (0.6679)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.120 (0.127)	Data 0.000 (0.004)	Loss 0.6503 (0.6271)	Acc@1 88.672 (88.035)	Acc@5 100.000 (99.615)
Epoch: [76][128/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.6547 (0.6444)	Acc@1 88.281 (87.379)	Acc@5 99.219 (99.588)
Epoch: [76][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.5844 (0.6467)	Acc@1 88.672 (87.362)	Acc@5 99.609 (99.555)
Max memory in training epoch: 60.4467712
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.162 (0.162)	Data 0.256 (0.256)	Loss 0.6714 (0.6714)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.130 (0.127)	Data 0.000 (0.004)	Loss 0.6862 (0.6583)	Acc@1 87.109 (86.809)	Acc@5 99.219 (99.459)
Epoch: [77][128/196]	Time 0.132 (0.127)	Data 0.000 (0.002)	Loss 0.6161 (0.6610)	Acc@1 89.453 (86.719)	Acc@5 99.219 (99.494)
Epoch: [77][192/196]	Time 0.126 (0.127)	Data 0.000 (0.001)	Loss 0.7490 (0.6612)	Acc@1 84.766 (86.757)	Acc@5 98.828 (99.492)
Max memory in training epoch: 60.4467712
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.184 (0.184)	Data 0.289 (0.289)	Loss 0.5426 (0.5426)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.6856 (0.6480)	Acc@1 86.328 (87.248)	Acc@5 99.219 (99.489)
Epoch: [78][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.7360 (0.6544)	Acc@1 86.328 (87.022)	Acc@5 99.219 (99.494)
Epoch: [78][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6053 (0.6544)	Acc@1 90.234 (87.069)	Acc@5 99.609 (99.502)
Max memory in training epoch: 60.4467712
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.165 (0.165)	Data 0.298 (0.298)	Loss 0.6486 (0.6486)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [79][64/196]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 0.7116 (0.6406)	Acc@1 84.766 (87.416)	Acc@5 99.219 (99.561)
Epoch: [79][128/196]	Time 0.134 (0.128)	Data 0.000 (0.002)	Loss 0.6380 (0.6532)	Acc@1 86.719 (87.006)	Acc@5 99.219 (99.543)
Epoch: [79][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6254 (0.6542)	Acc@1 89.453 (86.960)	Acc@5 99.609 (99.522)
Max memory in training epoch: 60.4467712
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.180 (0.180)	Data 0.262 (0.262)	Loss 0.6336 (0.6336)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.122 (0.129)	Data 0.000 (0.004)	Loss 0.6346 (0.6497)	Acc@1 88.281 (87.019)	Acc@5 100.000 (99.471)
Epoch: [80][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.6021 (0.6500)	Acc@1 87.109 (87.079)	Acc@5 100.000 (99.473)
Epoch: [80][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6355 (0.6555)	Acc@1 87.500 (87.022)	Acc@5 99.219 (99.508)
Max memory in training epoch: 60.4467712
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 392972 ; 395864 ; 0.992694460723885
[INFO] Storing checkpoint...
  77.34
Max memory: 93.9116544
 25.555s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4293
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1652736
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.180 (0.180)	Data 0.283 (0.283)	Loss 0.5747 (0.5747)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.7030 (0.6205)	Acc@1 82.812 (88.377)	Acc@5 99.609 (99.627)
Epoch: [81][128/196]	Time 0.121 (0.125)	Data 0.000 (0.002)	Loss 0.7374 (0.6369)	Acc@1 84.766 (87.588)	Acc@5 98.828 (99.570)
Epoch: [81][192/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.6591 (0.6483)	Acc@1 86.719 (87.196)	Acc@5 98.828 (99.526)
Max memory in training epoch: 60.1014784
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.149 (0.149)	Data 0.294 (0.294)	Loss 0.7509 (0.7509)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [82][64/196]	Time 0.122 (0.126)	Data 0.000 (0.005)	Loss 0.7238 (0.6493)	Acc@1 81.250 (86.977)	Acc@5 100.000 (99.519)
Epoch: [82][128/196]	Time 0.130 (0.125)	Data 0.000 (0.002)	Loss 0.6889 (0.6516)	Acc@1 87.500 (87.188)	Acc@5 98.047 (99.458)
Epoch: [82][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.6518 (0.6563)	Acc@1 85.938 (86.994)	Acc@5 99.219 (99.466)
Max memory in training epoch: 60.0228352
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.171 (0.171)	Data 0.300 (0.300)	Loss 0.6029 (0.6029)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [83][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.6201 (0.6514)	Acc@1 86.719 (87.127)	Acc@5 99.609 (99.591)
Epoch: [83][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7035 (0.6548)	Acc@1 86.328 (87.100)	Acc@5 98.438 (99.525)
Epoch: [83][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.7291 (0.6589)	Acc@1 84.766 (86.941)	Acc@5 99.609 (99.504)
Max memory in training epoch: 60.0228352
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.166 (0.166)	Data 0.306 (0.306)	Loss 0.5878 (0.5878)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [84][64/196]	Time 0.123 (0.125)	Data 0.000 (0.005)	Loss 0.6527 (0.6312)	Acc@1 89.844 (87.951)	Acc@5 98.438 (99.519)
Epoch: [84][128/196]	Time 0.121 (0.125)	Data 0.000 (0.003)	Loss 0.6855 (0.6365)	Acc@1 87.891 (87.703)	Acc@5 99.219 (99.531)
Epoch: [84][192/196]	Time 0.131 (0.126)	Data 0.000 (0.002)	Loss 0.6649 (0.6464)	Acc@1 85.547 (87.356)	Acc@5 98.828 (99.510)
Max memory in training epoch: 60.0228352
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.169 (0.169)	Data 0.320 (0.320)	Loss 0.7824 (0.7824)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [85][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.6473 (0.6376)	Acc@1 88.281 (87.314)	Acc@5 100.000 (99.615)
Epoch: [85][128/196]	Time 0.125 (0.127)	Data 0.000 (0.003)	Loss 0.6532 (0.6397)	Acc@1 85.156 (87.206)	Acc@5 99.609 (99.531)
Epoch: [85][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.6280 (0.6470)	Acc@1 88.672 (87.051)	Acc@5 100.000 (99.532)
Max memory in training epoch: 60.0228352
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 390948 ; 392972 ; 0.9948495058172083
[INFO] Storing checkpoint...
  73.38
Max memory: 93.0767872
 25.313s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3122
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1644544
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.201 (0.201)	Data 0.271 (0.271)	Loss 0.6519 (0.6519)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.5622 (0.6243)	Acc@1 91.016 (88.323)	Acc@5 100.000 (99.543)
Epoch: [86][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7133 (0.6367)	Acc@1 85.938 (87.660)	Acc@5 98.828 (99.528)
Epoch: [86][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6765 (0.6453)	Acc@1 85.938 (87.451)	Acc@5 99.609 (99.524)
Max memory in training epoch: 59.7049856
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.183 (0.183)	Data 0.257 (0.257)	Loss 0.5651 (0.5651)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.134 (0.129)	Data 0.000 (0.004)	Loss 0.6909 (0.6448)	Acc@1 85.156 (87.338)	Acc@5 99.609 (99.561)
Epoch: [87][128/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.5626 (0.6499)	Acc@1 90.625 (87.188)	Acc@5 100.000 (99.528)
Epoch: [87][192/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6877 (0.6490)	Acc@1 84.766 (87.227)	Acc@5 99.219 (99.537)
Max memory in training epoch: 59.8884864
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.176 (0.176)	Data 0.273 (0.273)	Loss 0.6357 (0.6357)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [88][64/196]	Time 0.129 (0.128)	Data 0.000 (0.004)	Loss 0.7632 (0.6470)	Acc@1 83.203 (87.230)	Acc@5 100.000 (99.483)
Epoch: [88][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.6371 (0.6478)	Acc@1 86.328 (87.237)	Acc@5 98.828 (99.506)
Epoch: [88][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.6892 (0.6532)	Acc@1 85.938 (87.081)	Acc@5 99.219 (99.488)
Max memory in training epoch: 59.8884864
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.187 (0.187)	Data 0.269 (0.269)	Loss 0.5601 (0.5601)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.121 (0.129)	Data 0.000 (0.004)	Loss 0.7082 (0.6576)	Acc@1 83.984 (87.073)	Acc@5 100.000 (99.549)
Epoch: [89][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6121 (0.6508)	Acc@1 89.844 (87.146)	Acc@5 100.000 (99.528)
Epoch: [89][192/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.7180 (0.6528)	Acc@1 84.766 (87.117)	Acc@5 100.000 (99.528)
Max memory in training epoch: 59.8884864
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.191 (0.191)	Data 0.263 (0.263)	Loss 0.6130 (0.6130)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.133 (0.128)	Data 0.000 (0.004)	Loss 0.7166 (0.6281)	Acc@1 84.766 (87.770)	Acc@5 99.609 (99.645)
Epoch: [90][128/196]	Time 0.130 (0.127)	Data 0.000 (0.002)	Loss 0.6984 (0.6399)	Acc@1 84.766 (87.494)	Acc@5 99.219 (99.552)
Epoch: [90][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.7396 (0.6487)	Acc@1 84.766 (87.200)	Acc@5 99.219 (99.508)
Max memory in training epoch: 59.8884864
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 387190 ; 390948 ; 0.990387468410121
[INFO] Storing checkpoint...
  74.89
Max memory: 92.752384
 25.260s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8535
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1629184
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.192 (0.192)	Data 0.286 (0.286)	Loss 0.7039 (0.7039)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [91][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.6117 (0.6131)	Acc@1 89.062 (88.504)	Acc@5 99.219 (99.561)
Epoch: [91][128/196]	Time 0.139 (0.127)	Data 0.000 (0.002)	Loss 0.6377 (0.6320)	Acc@1 87.109 (87.718)	Acc@5 99.219 (99.567)
Epoch: [91][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.6289 (0.6420)	Acc@1 89.062 (87.411)	Acc@5 100.000 (99.559)
Max memory in training epoch: 59.4891264
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.159 (0.159)	Data 0.271 (0.271)	Loss 0.5847 (0.5847)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.7123 (0.6304)	Acc@1 84.375 (87.716)	Acc@5 99.609 (99.525)
Epoch: [92][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.5968 (0.6426)	Acc@1 89.453 (87.415)	Acc@5 100.000 (99.506)
Epoch: [92][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.7563 (0.6452)	Acc@1 85.156 (87.346)	Acc@5 100.000 (99.547)
Max memory in training epoch: 59.4366976
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.179 (0.179)	Data 0.300 (0.300)	Loss 0.6277 (0.6277)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [93][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.5678 (0.5604)	Acc@1 90.234 (90.162)	Acc@5 100.000 (99.736)
Epoch: [93][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.5030 (0.5335)	Acc@1 92.969 (91.179)	Acc@5 99.609 (99.758)
Epoch: [93][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.4170 (0.5165)	Acc@1 95.312 (91.769)	Acc@5 100.000 (99.783)
Max memory in training epoch: 59.4366976
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.181 (0.181)	Data 0.269 (0.269)	Loss 0.4309 (0.4309)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.4664 (0.4636)	Acc@1 92.578 (93.672)	Acc@5 100.000 (99.862)
Epoch: [94][128/196]	Time 0.119 (0.126)	Data 0.000 (0.002)	Loss 0.4557 (0.4636)	Acc@1 92.578 (93.517)	Acc@5 99.609 (99.852)
Epoch: [94][192/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.3874 (0.4593)	Acc@1 95.703 (93.525)	Acc@5 100.000 (99.844)
Max memory in training epoch: 59.4366976
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.202 (0.202)	Data 0.301 (0.301)	Loss 0.4404 (0.4404)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.4866 (0.4350)	Acc@1 94.531 (94.327)	Acc@5 99.219 (99.904)
Epoch: [95][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.3817 (0.4364)	Acc@1 96.484 (94.125)	Acc@5 100.000 (99.924)
Epoch: [95][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.4274 (0.4369)	Acc@1 94.141 (94.048)	Acc@5 100.000 (99.897)
Max memory in training epoch: 59.4366976
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 386756 ; 387190 ; 0.9988791032826261
[INFO] Storing checkpoint...
  91.36
Max memory: 91.9252992
 25.287s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1797
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.196 (0.196)	Data 0.282 (0.282)	Loss 0.4467 (0.4467)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [96][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.3968 (0.4264)	Acc@1 94.922 (94.171)	Acc@5 100.000 (99.898)
Epoch: [96][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.4397 (0.4221)	Acc@1 94.141 (94.419)	Acc@5 100.000 (99.912)
Epoch: [96][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.4098 (0.4197)	Acc@1 95.312 (94.521)	Acc@5 99.219 (99.907)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.172 (0.172)	Data 0.288 (0.288)	Loss 0.3495 (0.3495)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.135 (0.128)	Data 0.000 (0.005)	Loss 0.4084 (0.4053)	Acc@1 94.141 (95.030)	Acc@5 100.000 (99.880)
Epoch: [97][128/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.3650 (0.4056)	Acc@1 96.484 (94.892)	Acc@5 100.000 (99.888)
Epoch: [97][192/196]	Time 0.117 (0.127)	Data 0.000 (0.002)	Loss 0.3768 (0.4059)	Acc@1 95.703 (94.853)	Acc@5 100.000 (99.895)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.175 (0.175)	Data 0.270 (0.270)	Loss 0.3776 (0.3776)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.4130 (0.3915)	Acc@1 94.531 (95.210)	Acc@5 100.000 (99.910)
Epoch: [98][128/196]	Time 0.120 (0.127)	Data 0.000 (0.002)	Loss 0.3711 (0.3933)	Acc@1 96.875 (95.113)	Acc@5 100.000 (99.918)
Epoch: [98][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.3850 (0.3920)	Acc@1 96.094 (95.118)	Acc@5 100.000 (99.919)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.172 (0.172)	Data 0.263 (0.263)	Loss 0.4151 (0.4151)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [99][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.3603 (0.3762)	Acc@1 96.094 (95.733)	Acc@5 100.000 (99.934)
Epoch: [99][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.4278 (0.3823)	Acc@1 92.969 (95.367)	Acc@5 100.000 (99.927)
Epoch: [99][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.4088 (0.3824)	Acc@1 93.359 (95.321)	Acc@5 100.000 (99.917)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.173 (0.173)	Data 0.298 (0.298)	Loss 0.4291 (0.4291)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.3387 (0.3753)	Acc@1 97.656 (95.427)	Acc@5 100.000 (99.952)
Epoch: [100][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.3558 (0.3740)	Acc@1 97.656 (95.473)	Acc@5 99.609 (99.945)
Epoch: [100][192/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.3428 (0.3719)	Acc@1 96.094 (95.559)	Acc@5 100.000 (99.943)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.37
Max memory: 91.898624
 25.222s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2109
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.210 (0.210)	Data 0.264 (0.264)	Loss 0.3553 (0.3553)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.131 (0.128)	Data 0.000 (0.004)	Loss 0.3306 (0.3518)	Acc@1 97.266 (96.220)	Acc@5 100.000 (99.922)
Epoch: [101][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3721 (0.3574)	Acc@1 96.094 (95.939)	Acc@5 100.000 (99.930)
Epoch: [101][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.4173 (0.3600)	Acc@1 94.141 (95.806)	Acc@5 100.000 (99.935)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.174 (0.174)	Data 0.297 (0.297)	Loss 0.3656 (0.3656)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.127 (0.127)	Data 0.000 (0.005)	Loss 0.3163 (0.3493)	Acc@1 97.656 (96.052)	Acc@5 100.000 (99.958)
Epoch: [102][128/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.3611 (0.3536)	Acc@1 93.750 (95.773)	Acc@5 100.000 (99.942)
Epoch: [102][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.3355 (0.3524)	Acc@1 96.094 (95.821)	Acc@5 100.000 (99.953)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.185 (0.185)	Data 0.261 (0.261)	Loss 0.3909 (0.3909)	Acc@1 94.922 (94.922)	Acc@5 99.219 (99.219)
Epoch: [103][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.3702 (0.3505)	Acc@1 94.922 (95.763)	Acc@5 100.000 (99.958)
Epoch: [103][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.3506 (0.3449)	Acc@1 96.094 (95.945)	Acc@5 100.000 (99.967)
Epoch: [103][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.3458 (0.3424)	Acc@1 95.312 (95.986)	Acc@5 100.000 (99.972)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.155 (0.155)	Data 0.260 (0.260)	Loss 0.3442 (0.3442)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.132 (0.127)	Data 0.000 (0.004)	Loss 0.2844 (0.3323)	Acc@1 98.828 (96.472)	Acc@5 100.000 (99.952)
Epoch: [104][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.2959 (0.3358)	Acc@1 98.047 (96.342)	Acc@5 100.000 (99.961)
Epoch: [104][192/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.3320 (0.3360)	Acc@1 96.875 (96.292)	Acc@5 100.000 (99.960)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.161 (0.161)	Data 0.286 (0.286)	Loss 0.3272 (0.3272)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.130 (0.128)	Data 0.000 (0.005)	Loss 0.3421 (0.3235)	Acc@1 95.312 (96.659)	Acc@5 100.000 (99.958)
Epoch: [105][128/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.3564 (0.3255)	Acc@1 94.922 (96.412)	Acc@5 100.000 (99.961)
Epoch: [105][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 0.3159 (0.3308)	Acc@1 96.875 (96.256)	Acc@5 100.000 (99.955)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.65
Max memory: 91.898624
 25.346s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1973
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.177 (0.177)	Data 0.287 (0.287)	Loss 0.2937 (0.2937)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.3396 (0.3166)	Acc@1 95.703 (96.749)	Acc@5 100.000 (99.946)
Epoch: [106][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.3041 (0.3209)	Acc@1 97.656 (96.557)	Acc@5 100.000 (99.958)
Epoch: [106][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3060 (0.3224)	Acc@1 96.484 (96.470)	Acc@5 100.000 (99.960)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.178 (0.178)	Data 0.296 (0.296)	Loss 0.2792 (0.2792)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.131 (0.127)	Data 0.000 (0.005)	Loss 0.3138 (0.3170)	Acc@1 96.875 (96.550)	Acc@5 99.609 (99.970)
Epoch: [107][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.3046 (0.3181)	Acc@1 97.266 (96.509)	Acc@5 100.000 (99.964)
Epoch: [107][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.3371 (0.3198)	Acc@1 96.094 (96.399)	Acc@5 99.609 (99.964)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.164 (0.164)	Data 0.262 (0.262)	Loss 0.2996 (0.2996)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.3177 (0.3163)	Acc@1 97.266 (96.460)	Acc@5 100.000 (99.964)
Epoch: [108][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.3209 (0.3166)	Acc@1 95.703 (96.324)	Acc@5 100.000 (99.967)
Epoch: [108][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.3428 (0.3167)	Acc@1 93.359 (96.327)	Acc@5 100.000 (99.962)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.180 (0.180)	Data 0.263 (0.263)	Loss 0.3367 (0.3367)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.2850 (0.3085)	Acc@1 96.484 (96.514)	Acc@5 100.000 (99.958)
Epoch: [109][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.2943 (0.3102)	Acc@1 96.875 (96.406)	Acc@5 100.000 (99.955)
Epoch: [109][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3117 (0.3100)	Acc@1 96.875 (96.468)	Acc@5 100.000 (99.957)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.152 (0.152)	Data 0.271 (0.271)	Loss 0.3214 (0.3214)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.3345 (0.3024)	Acc@1 97.266 (96.929)	Acc@5 100.000 (99.988)
Epoch: [110][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.3043 (0.3058)	Acc@1 96.484 (96.605)	Acc@5 100.000 (99.979)
Epoch: [110][192/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.3060 (0.3076)	Acc@1 96.875 (96.474)	Acc@5 100.000 (99.968)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.01
Max memory: 91.898624
 25.402s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5775
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.212 (0.212)	Data 0.278 (0.278)	Loss 0.3621 (0.3621)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.129 (0.128)	Data 0.000 (0.004)	Loss 0.2788 (0.2942)	Acc@1 97.656 (96.851)	Acc@5 100.000 (99.982)
Epoch: [111][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.3300 (0.2998)	Acc@1 95.703 (96.621)	Acc@5 100.000 (99.979)
Epoch: [111][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.2906 (0.3026)	Acc@1 96.875 (96.531)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.187 (0.187)	Data 0.273 (0.273)	Loss 0.2992 (0.2992)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.121 (0.127)	Data 0.000 (0.004)	Loss 0.2735 (0.2972)	Acc@1 97.656 (96.659)	Acc@5 100.000 (99.964)
Epoch: [112][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.3025 (0.2953)	Acc@1 97.266 (96.751)	Acc@5 100.000 (99.976)
Epoch: [112][192/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.3519 (0.2999)	Acc@1 94.922 (96.561)	Acc@5 100.000 (99.972)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.182 (0.182)	Data 0.285 (0.285)	Loss 0.3542 (0.3542)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.122 (0.127)	Data 0.000 (0.005)	Loss 0.3033 (0.3058)	Acc@1 96.484 (96.232)	Acc@5 100.000 (99.940)
Epoch: [113][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.2987 (0.3011)	Acc@1 96.875 (96.406)	Acc@5 100.000 (99.961)
Epoch: [113][192/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.3352 (0.3015)	Acc@1 94.922 (96.389)	Acc@5 100.000 (99.964)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.171 (0.171)	Data 0.290 (0.290)	Loss 0.2640 (0.2640)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.2590 (0.2828)	Acc@1 97.656 (97.055)	Acc@5 100.000 (99.988)
Epoch: [114][128/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.3146 (0.2909)	Acc@1 96.875 (96.730)	Acc@5 99.609 (99.979)
Epoch: [114][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.2898 (0.2933)	Acc@1 96.484 (96.600)	Acc@5 100.000 (99.978)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.154 (0.154)	Data 0.278 (0.278)	Loss 0.2966 (0.2966)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.126 (0.127)	Data 0.000 (0.004)	Loss 0.2958 (0.2853)	Acc@1 94.531 (96.857)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.3208 (0.2872)	Acc@1 94.922 (96.733)	Acc@5 100.000 (99.967)
Epoch: [115][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.3341 (0.2918)	Acc@1 94.922 (96.573)	Acc@5 100.000 (99.972)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.46
Max memory: 91.898624
 25.044s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4813
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.184 (0.184)	Data 0.266 (0.266)	Loss 0.3213 (0.3213)	Acc@1 96.094 (96.094)	Acc@5 99.219 (99.219)
Epoch: [116][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.3168 (0.2798)	Acc@1 96.484 (96.989)	Acc@5 100.000 (99.964)
Epoch: [116][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.2839 (0.2841)	Acc@1 96.875 (96.790)	Acc@5 100.000 (99.964)
Epoch: [116][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.2923 (0.2885)	Acc@1 96.484 (96.608)	Acc@5 100.000 (99.968)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.152 (0.152)	Data 0.269 (0.269)	Loss 0.2438 (0.2438)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.2804 (0.2806)	Acc@1 96.484 (96.827)	Acc@5 100.000 (99.958)
Epoch: [117][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.3336 (0.2842)	Acc@1 95.703 (96.657)	Acc@5 100.000 (99.970)
Epoch: [117][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.3018 (0.2850)	Acc@1 97.266 (96.650)	Acc@5 100.000 (99.976)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.164 (0.164)	Data 0.266 (0.266)	Loss 0.2847 (0.2847)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.3188 (0.2820)	Acc@1 95.703 (96.731)	Acc@5 100.000 (99.988)
Epoch: [118][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.3407 (0.2838)	Acc@1 93.359 (96.657)	Acc@5 100.000 (99.991)
Epoch: [118][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.2904 (0.2860)	Acc@1 96.094 (96.545)	Acc@5 100.000 (99.982)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.157 (0.157)	Data 0.291 (0.291)	Loss 0.2576 (0.2576)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.3392 (0.2881)	Acc@1 94.922 (96.484)	Acc@5 100.000 (99.976)
Epoch: [119][128/196]	Time 0.140 (0.127)	Data 0.000 (0.002)	Loss 0.2605 (0.2881)	Acc@1 97.656 (96.412)	Acc@5 100.000 (99.982)
Epoch: [119][192/196]	Time 0.129 (0.127)	Data 0.000 (0.002)	Loss 0.3116 (0.2875)	Acc@1 94.531 (96.430)	Acc@5 100.000 (99.980)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.181 (0.181)	Data 0.286 (0.286)	Loss 0.2822 (0.2822)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.120 (0.129)	Data 0.000 (0.005)	Loss 0.2644 (0.2754)	Acc@1 97.656 (96.851)	Acc@5 100.000 (99.982)
Epoch: [120][128/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.2773 (0.2775)	Acc@1 96.875 (96.727)	Acc@5 100.000 (99.976)
Epoch: [120][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.2896 (0.2844)	Acc@1 95.703 (96.484)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.74
Max memory: 91.898624
 25.322s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9049
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.200 (0.200)	Data 0.276 (0.276)	Loss 0.3486 (0.3486)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.143 (0.127)	Data 0.000 (0.004)	Loss 0.3086 (0.2750)	Acc@1 96.875 (96.725)	Acc@5 100.000 (99.982)
Epoch: [121][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.2756 (0.2786)	Acc@1 96.875 (96.569)	Acc@5 100.000 (99.985)
Epoch: [121][192/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.3337 (0.2821)	Acc@1 93.359 (96.484)	Acc@5 100.000 (99.982)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.181 (0.181)	Data 0.290 (0.290)	Loss 0.2615 (0.2615)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.2560 (0.2803)	Acc@1 97.266 (96.599)	Acc@5 100.000 (99.970)
Epoch: [122][128/196]	Time 0.124 (0.126)	Data 0.000 (0.002)	Loss 0.2551 (0.2805)	Acc@1 98.047 (96.557)	Acc@5 99.609 (99.976)
Epoch: [122][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.3335 (0.2818)	Acc@1 94.922 (96.499)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.161 (0.161)	Data 0.284 (0.284)	Loss 0.2646 (0.2646)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.122 (0.128)	Data 0.000 (0.005)	Loss 0.2242 (0.2681)	Acc@1 99.219 (97.061)	Acc@5 100.000 (99.988)
Epoch: [123][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.3502 (0.2758)	Acc@1 94.141 (96.772)	Acc@5 100.000 (99.979)
Epoch: [123][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.3265 (0.2818)	Acc@1 94.531 (96.515)	Acc@5 100.000 (99.972)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.148 (0.148)	Data 0.268 (0.268)	Loss 0.2546 (0.2546)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.2935 (0.2731)	Acc@1 95.312 (96.791)	Acc@5 100.000 (100.000)
Epoch: [124][128/196]	Time 0.131 (0.127)	Data 0.000 (0.002)	Loss 0.2874 (0.2783)	Acc@1 96.875 (96.578)	Acc@5 100.000 (99.994)
Epoch: [124][192/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.3269 (0.2807)	Acc@1 93.359 (96.474)	Acc@5 100.000 (99.990)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.169 (0.169)	Data 0.287 (0.287)	Loss 0.2784 (0.2784)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.129 (0.127)	Data 0.000 (0.005)	Loss 0.2514 (0.2818)	Acc@1 98.047 (96.400)	Acc@5 100.000 (99.994)
Epoch: [125][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.2706 (0.2796)	Acc@1 97.266 (96.466)	Acc@5 100.000 (99.982)
Epoch: [125][192/196]	Time 0.135 (0.126)	Data 0.000 (0.002)	Loss 0.2849 (0.2800)	Acc@1 96.484 (96.472)	Acc@5 100.000 (99.980)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.91
Max memory: 91.898624
 25.067s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4197
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.210 (0.210)	Data 0.260 (0.260)	Loss 0.2713 (0.2713)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.2388 (0.2649)	Acc@1 97.656 (96.929)	Acc@5 100.000 (99.988)
Epoch: [126][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.2783 (0.2710)	Acc@1 96.875 (96.751)	Acc@5 100.000 (99.979)
Epoch: [126][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.3148 (0.2772)	Acc@1 96.094 (96.525)	Acc@5 100.000 (99.972)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.184 (0.184)	Data 0.264 (0.264)	Loss 0.2401 (0.2401)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.2598 (0.2759)	Acc@1 96.875 (96.599)	Acc@5 100.000 (99.976)
Epoch: [127][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.2685 (0.2774)	Acc@1 96.875 (96.521)	Acc@5 100.000 (99.979)
Epoch: [127][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.2668 (0.2857)	Acc@1 96.875 (96.159)	Acc@5 100.000 (99.978)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.156 (0.156)	Data 0.287 (0.287)	Loss 0.2710 (0.2710)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.3001 (0.2842)	Acc@1 94.922 (96.376)	Acc@5 100.000 (99.976)
Epoch: [128][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.2541 (0.2814)	Acc@1 96.875 (96.357)	Acc@5 100.000 (99.982)
Epoch: [128][192/196]	Time 0.142 (0.129)	Data 0.000 (0.002)	Loss 0.2755 (0.2829)	Acc@1 96.094 (96.272)	Acc@5 99.609 (99.968)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.165 (0.165)	Data 0.261 (0.261)	Loss 0.2608 (0.2608)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.125 (0.130)	Data 0.000 (0.004)	Loss 0.2908 (0.2815)	Acc@1 95.703 (96.376)	Acc@5 100.000 (99.982)
Epoch: [129][128/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.2531 (0.2815)	Acc@1 98.047 (96.339)	Acc@5 100.000 (99.982)
Epoch: [129][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.2945 (0.2837)	Acc@1 96.094 (96.250)	Acc@5 100.000 (99.982)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.170 (0.170)	Data 0.309 (0.309)	Loss 0.2966 (0.2966)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.125 (0.130)	Data 0.000 (0.005)	Loss 0.2747 (0.2780)	Acc@1 96.875 (96.484)	Acc@5 100.000 (99.970)
Epoch: [130][128/196]	Time 0.123 (0.130)	Data 0.000 (0.003)	Loss 0.2739 (0.2745)	Acc@1 96.484 (96.572)	Acc@5 100.000 (99.979)
Epoch: [130][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.3043 (0.2778)	Acc@1 94.141 (96.355)	Acc@5 100.000 (99.982)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.51
Max memory: 91.898624
 25.844s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8764
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1627648
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.179 (0.179)	Data 0.282 (0.282)	Loss 0.2450 (0.2450)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.2828 (0.2647)	Acc@1 96.484 (96.941)	Acc@5 100.000 (99.994)
Epoch: [131][128/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.2454 (0.2709)	Acc@1 97.656 (96.612)	Acc@5 100.000 (99.988)
Epoch: [131][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.2442 (0.2751)	Acc@1 98.438 (96.478)	Acc@5 100.000 (99.982)
Max memory in training epoch: 59.488512
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.179 (0.179)	Data 0.298 (0.298)	Loss 0.2710 (0.2710)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.2987 (0.2743)	Acc@1 96.094 (96.418)	Acc@5 100.000 (99.994)
Epoch: [132][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.2942 (0.2755)	Acc@1 96.094 (96.433)	Acc@5 100.000 (99.982)
Epoch: [132][192/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.3085 (0.2790)	Acc@1 94.531 (96.250)	Acc@5 100.000 (99.980)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.177 (0.177)	Data 0.283 (0.283)	Loss 0.2781 (0.2781)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.2724 (0.2722)	Acc@1 95.703 (96.641)	Acc@5 100.000 (99.982)
Epoch: [133][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.2413 (0.2766)	Acc@1 97.656 (96.412)	Acc@5 100.000 (99.982)
Epoch: [133][192/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.2984 (0.2808)	Acc@1 95.312 (96.254)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.193 (0.193)	Data 0.266 (0.266)	Loss 0.2458 (0.2458)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.3124 (0.2719)	Acc@1 94.922 (96.406)	Acc@5 100.000 (99.964)
Epoch: [134][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.2608 (0.2789)	Acc@1 98.047 (96.179)	Acc@5 100.000 (99.970)
Epoch: [134][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.2746 (0.2808)	Acc@1 95.703 (96.122)	Acc@5 100.000 (99.968)
Max memory in training epoch: 59.4098688
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.181 (0.181)	Data 0.283 (0.283)	Loss 0.2658 (0.2658)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.2819 (0.2787)	Acc@1 95.703 (96.322)	Acc@5 100.000 (99.970)
Epoch: [135][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.3324 (0.2789)	Acc@1 94.922 (96.306)	Acc@5 100.000 (99.979)
Epoch: [135][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.3039 (0.2798)	Acc@1 94.922 (96.241)	Acc@5 100.000 (99.976)
Max memory in training epoch: 59.4098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 386178 ; 386756 ; 0.9985055176907404
[INFO] Storing checkpoint...
  89.73
Max memory: 91.898624
 25.642s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4239
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.16256
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.197 (0.197)	Data 0.260 (0.260)	Loss 0.2463 (0.2463)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.2962 (0.2696)	Acc@1 97.266 (96.659)	Acc@5 100.000 (99.976)
Epoch: [136][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.2772 (0.2761)	Acc@1 96.094 (96.351)	Acc@5 100.000 (99.979)
Epoch: [136][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.3063 (0.2789)	Acc@1 94.922 (96.260)	Acc@5 100.000 (99.976)
Max memory in training epoch: 59.435264
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.184 (0.184)	Data 0.303 (0.303)	Loss 0.2504 (0.2504)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.2723 (0.2715)	Acc@1 96.875 (96.430)	Acc@5 100.000 (99.988)
Epoch: [137][128/196]	Time 0.127 (0.128)	Data 0.000 (0.003)	Loss 0.3195 (0.2788)	Acc@1 94.141 (96.203)	Acc@5 100.000 (99.979)
Epoch: [137][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.2610 (0.2813)	Acc@1 96.484 (96.098)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.165 (0.165)	Data 0.297 (0.297)	Loss 0.2804 (0.2804)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.124 (0.128)	Data 0.000 (0.005)	Loss 0.3215 (0.2772)	Acc@1 94.531 (96.334)	Acc@5 100.000 (99.982)
Epoch: [138][128/196]	Time 0.121 (0.127)	Data 0.000 (0.002)	Loss 0.2622 (0.2796)	Acc@1 96.875 (96.257)	Acc@5 100.000 (99.973)
Epoch: [138][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.3448 (0.2821)	Acc@1 94.531 (96.156)	Acc@5 99.609 (99.972)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.186 (0.186)	Data 0.263 (0.263)	Loss 0.3247 (0.3247)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.3290 (0.2777)	Acc@1 94.922 (96.310)	Acc@5 100.000 (99.982)
Epoch: [139][128/196]	Time 0.121 (0.128)	Data 0.000 (0.002)	Loss 0.2977 (0.2812)	Acc@1 93.750 (96.027)	Acc@5 100.000 (99.982)
Epoch: [139][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.2595 (0.2798)	Acc@1 97.266 (96.156)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.181 (0.181)	Data 0.310 (0.310)	Loss 0.2562 (0.2562)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.2899 (0.2825)	Acc@1 97.656 (96.124)	Acc@5 100.000 (99.964)
Epoch: [140][128/196]	Time 0.126 (0.129)	Data 0.000 (0.003)	Loss 0.2950 (0.2823)	Acc@1 95.312 (96.079)	Acc@5 100.000 (99.964)
Epoch: [140][192/196]	Time 0.139 (0.129)	Data 0.000 (0.002)	Loss 0.3048 (0.2839)	Acc@1 95.312 (95.999)	Acc@5 100.000 (99.970)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.76
Max memory: 91.8160896
 25.643s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3882
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.16256
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.199 (0.199)	Data 0.287 (0.287)	Loss 0.2658 (0.2658)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.141 (0.127)	Data 0.000 (0.005)	Loss 0.3226 (0.2621)	Acc@1 92.969 (96.719)	Acc@5 100.000 (99.982)
Epoch: [141][128/196]	Time 0.125 (0.127)	Data 0.000 (0.002)	Loss 0.2591 (0.2667)	Acc@1 96.875 (96.612)	Acc@5 100.000 (99.982)
Epoch: [141][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.3027 (0.2747)	Acc@1 94.922 (96.399)	Acc@5 99.609 (99.980)
Max memory in training epoch: 59.435264
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.174 (0.174)	Data 0.265 (0.265)	Loss 0.2371 (0.2371)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.128 (0.126)	Data 0.000 (0.004)	Loss 0.2985 (0.2808)	Acc@1 96.875 (96.268)	Acc@5 100.000 (99.970)
Epoch: [142][128/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.3237 (0.2831)	Acc@1 94.531 (96.085)	Acc@5 100.000 (99.970)
Epoch: [142][192/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.2646 (0.2843)	Acc@1 96.484 (96.023)	Acc@5 100.000 (99.966)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.187 (0.187)	Data 0.267 (0.267)	Loss 0.2787 (0.2787)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.2801 (0.2755)	Acc@1 96.484 (96.316)	Acc@5 100.000 (99.964)
Epoch: [143][128/196]	Time 0.126 (0.127)	Data 0.000 (0.002)	Loss 0.3092 (0.2751)	Acc@1 95.703 (96.360)	Acc@5 99.609 (99.970)
Epoch: [143][192/196]	Time 0.122 (0.127)	Data 0.000 (0.002)	Loss 0.2443 (0.2759)	Acc@1 96.484 (96.320)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.183 (0.183)	Data 0.275 (0.275)	Loss 0.2791 (0.2791)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.2644 (0.2682)	Acc@1 96.875 (96.749)	Acc@5 100.000 (99.994)
Epoch: [144][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.3102 (0.2717)	Acc@1 94.531 (96.530)	Acc@5 100.000 (99.988)
Epoch: [144][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.2893 (0.2798)	Acc@1 95.312 (96.225)	Acc@5 100.000 (99.980)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.169 (0.169)	Data 0.266 (0.266)	Loss 0.2654 (0.2654)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.130 (0.128)	Data 0.000 (0.004)	Loss 0.2957 (0.2767)	Acc@1 94.922 (96.292)	Acc@5 100.000 (99.964)
Epoch: [145][128/196]	Time 0.127 (0.127)	Data 0.000 (0.002)	Loss 0.2997 (0.2786)	Acc@1 93.750 (96.163)	Acc@5 100.000 (99.970)
Epoch: [145][192/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.3242 (0.2798)	Acc@1 93.359 (96.114)	Acc@5 100.000 (99.962)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.55
Max memory: 91.8160896
 25.138s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7790
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.16256
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.183 (0.183)	Data 0.282 (0.282)	Loss 0.2731 (0.2731)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.124 (0.127)	Data 0.000 (0.005)	Loss 0.2588 (0.2648)	Acc@1 95.703 (96.683)	Acc@5 100.000 (99.982)
Epoch: [146][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.2952 (0.2701)	Acc@1 94.922 (96.496)	Acc@5 100.000 (99.979)
Epoch: [146][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.2965 (0.2715)	Acc@1 96.094 (96.454)	Acc@5 100.000 (99.982)
Max memory in training epoch: 59.435264
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.160 (0.160)	Data 0.255 (0.255)	Loss 0.2617 (0.2617)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.126 (0.126)	Data 0.000 (0.004)	Loss 0.2457 (0.2839)	Acc@1 96.484 (95.950)	Acc@5 100.000 (99.976)
Epoch: [147][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.3033 (0.2843)	Acc@1 94.922 (95.885)	Acc@5 100.000 (99.976)
Epoch: [147][192/196]	Time 0.124 (0.125)	Data 0.000 (0.001)	Loss 0.2826 (0.2853)	Acc@1 95.703 (95.926)	Acc@5 100.000 (99.980)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.156 (0.156)	Data 0.263 (0.263)	Loss 0.2974 (0.2974)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.119 (0.126)	Data 0.000 (0.004)	Loss 0.2812 (0.2750)	Acc@1 94.922 (96.238)	Acc@5 100.000 (99.988)
Epoch: [148][128/196]	Time 0.129 (0.125)	Data 0.000 (0.002)	Loss 0.3558 (0.2750)	Acc@1 93.750 (96.351)	Acc@5 100.000 (99.970)
Epoch: [148][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.2910 (0.2801)	Acc@1 94.531 (96.138)	Acc@5 100.000 (99.974)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.186 (0.186)	Data 0.290 (0.290)	Loss 0.2708 (0.2708)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.2887 (0.2750)	Acc@1 96.094 (96.280)	Acc@5 100.000 (99.982)
Epoch: [149][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.2702 (0.2824)	Acc@1 96.484 (95.994)	Acc@5 100.000 (99.982)
Epoch: [149][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.2558 (0.2841)	Acc@1 98.047 (95.914)	Acc@5 100.000 (99.978)
Max memory in training epoch: 59.3566208
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.161 (0.161)	Data 0.263 (0.263)	Loss 0.2701 (0.2701)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.128 (0.128)	Data 0.000 (0.004)	Loss 0.2537 (0.2576)	Acc@1 98.047 (97.085)	Acc@5 100.000 (99.982)
Epoch: [150][128/196]	Time 0.136 (0.127)	Data 0.000 (0.002)	Loss 0.2292 (0.2452)	Acc@1 97.656 (97.574)	Acc@5 100.000 (99.982)
Epoch: [150][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.1977 (0.2408)	Acc@1 99.609 (97.689)	Acc@5 100.000 (99.986)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.29
Max memory: 91.8160896
 25.091s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1468
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.16256
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.182 (0.182)	Data 0.284 (0.284)	Loss 0.2348 (0.2348)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 0.2341 (0.2231)	Acc@1 98.047 (98.359)	Acc@5 100.000 (99.994)
Epoch: [151][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.2149 (0.2225)	Acc@1 98.047 (98.386)	Acc@5 100.000 (99.994)
Epoch: [151][192/196]	Time 0.122 (0.128)	Data 0.000 (0.002)	Loss 0.2205 (0.2209)	Acc@1 98.828 (98.429)	Acc@5 100.000 (99.994)
Max memory in training epoch: 59.435264
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.187 (0.187)	Data 0.271 (0.271)	Loss 0.2243 (0.2243)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.123 (0.128)	Data 0.000 (0.004)	Loss 0.2184 (0.2126)	Acc@1 98.438 (98.744)	Acc@5 100.000 (99.994)
Epoch: [152][128/196]	Time 0.128 (0.127)	Data 0.000 (0.002)	Loss 0.2237 (0.2121)	Acc@1 98.828 (98.728)	Acc@5 100.000 (99.997)
Epoch: [152][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.2303 (0.2125)	Acc@1 98.047 (98.721)	Acc@5 100.000 (99.994)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.180 (0.180)	Data 0.293 (0.293)	Loss 0.2012 (0.2012)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.1920 (0.2081)	Acc@1 99.609 (98.870)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.2405 (0.2080)	Acc@1 97.266 (98.961)	Acc@5 100.000 (99.997)
Epoch: [153][192/196]	Time 0.131 (0.128)	Data 0.000 (0.002)	Loss 0.2159 (0.2079)	Acc@1 98.438 (98.956)	Acc@5 100.000 (99.996)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.181 (0.181)	Data 0.272 (0.272)	Loss 0.2057 (0.2057)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.131 (0.131)	Data 0.000 (0.004)	Loss 0.1865 (0.2056)	Acc@1 100.000 (98.852)	Acc@5 100.000 (100.000)
Epoch: [154][128/196]	Time 0.120 (0.129)	Data 0.000 (0.002)	Loss 0.2057 (0.2048)	Acc@1 98.438 (98.922)	Acc@5 100.000 (99.997)
Epoch: [154][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.1952 (0.2055)	Acc@1 99.219 (98.901)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.185 (0.185)	Data 0.265 (0.265)	Loss 0.2071 (0.2071)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.2070 (0.2013)	Acc@1 98.828 (99.099)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.1979 (0.2028)	Acc@1 99.219 (99.010)	Acc@5 100.000 (100.000)
Epoch: [155][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.1938 (0.2020)	Acc@1 100.000 (99.047)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.76
Max memory: 91.8160896
 25.401s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2753
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.16256
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.177 (0.177)	Data 0.286 (0.286)	Loss 0.1965 (0.1965)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.126 (0.127)	Data 0.000 (0.005)	Loss 0.1961 (0.1993)	Acc@1 99.219 (99.129)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.126 (0.126)	Data 0.000 (0.002)	Loss 0.1978 (0.2004)	Acc@1 99.219 (99.055)	Acc@5 100.000 (100.000)
Epoch: [156][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.2069 (0.2014)	Acc@1 98.047 (99.026)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.435264
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.153 (0.153)	Data 0.296 (0.296)	Loss 0.1878 (0.1878)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.2011 (0.1981)	Acc@1 99.609 (99.141)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.2128 (0.1976)	Acc@1 97.656 (99.125)	Acc@5 100.000 (100.000)
Epoch: [157][192/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.1921 (0.1972)	Acc@1 100.000 (99.172)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.171 (0.171)	Data 0.264 (0.264)	Loss 0.1885 (0.1885)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.1887 (0.1949)	Acc@1 99.219 (99.267)	Acc@5 100.000 (99.994)
Epoch: [158][128/196]	Time 0.128 (0.125)	Data 0.000 (0.002)	Loss 0.1950 (0.1950)	Acc@1 99.219 (99.237)	Acc@5 100.000 (99.997)
Epoch: [158][192/196]	Time 0.118 (0.125)	Data 0.000 (0.002)	Loss 0.2041 (0.1952)	Acc@1 99.219 (99.235)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.167 (0.167)	Data 0.294 (0.294)	Loss 0.1942 (0.1942)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.132 (0.127)	Data 0.000 (0.005)	Loss 0.1946 (0.1932)	Acc@1 99.219 (99.327)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.1992 (0.1925)	Acc@1 98.828 (99.355)	Acc@5 100.000 (100.000)
Epoch: [159][192/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.1907 (0.1932)	Acc@1 99.609 (99.306)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.176 (0.176)	Data 0.265 (0.265)	Loss 0.1937 (0.1937)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.129 (0.127)	Data 0.000 (0.004)	Loss 0.1819 (0.1919)	Acc@1 99.609 (99.351)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.133 (0.126)	Data 0.000 (0.002)	Loss 0.1974 (0.1916)	Acc@1 99.219 (99.397)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.122 (0.126)	Data 0.000 (0.002)	Loss 0.1830 (0.1924)	Acc@1 99.609 (99.369)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.86
Max memory: 91.8160896
 25.003s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9906
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.16256
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.186 (0.186)	Data 0.298 (0.298)	Loss 0.2049 (0.2049)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.125 (0.128)	Data 0.000 (0.005)	Loss 0.2250 (0.1893)	Acc@1 98.438 (99.447)	Acc@5 100.000 (99.988)
Epoch: [161][128/196]	Time 0.129 (0.126)	Data 0.000 (0.002)	Loss 0.1925 (0.1890)	Acc@1 99.219 (99.413)	Acc@5 100.000 (99.994)
Epoch: [161][192/196]	Time 0.121 (0.126)	Data 0.000 (0.002)	Loss 0.1956 (0.1907)	Acc@1 98.828 (99.342)	Acc@5 100.000 (99.994)
Max memory in training epoch: 59.435264
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.190 (0.190)	Data 0.290 (0.290)	Loss 0.2116 (0.2116)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.125 (0.127)	Data 0.000 (0.005)	Loss 0.1809 (0.1893)	Acc@1 100.000 (99.405)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.125 (0.126)	Data 0.000 (0.002)	Loss 0.1865 (0.1893)	Acc@1 99.219 (99.413)	Acc@5 100.000 (99.997)
Epoch: [162][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.1832 (0.1890)	Acc@1 99.609 (99.385)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.182 (0.182)	Data 0.354 (0.354)	Loss 0.2001 (0.2001)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.126 (0.128)	Data 0.000 (0.006)	Loss 0.1884 (0.1879)	Acc@1 99.219 (99.393)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.123 (0.126)	Data 0.000 (0.003)	Loss 0.2195 (0.1889)	Acc@1 99.219 (99.391)	Acc@5 100.000 (100.000)
Epoch: [163][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.1981 (0.1879)	Acc@1 98.828 (99.427)	Acc@5 99.609 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.182 (0.182)	Data 0.315 (0.315)	Loss 0.1999 (0.1999)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.124 (0.129)	Data 0.000 (0.005)	Loss 0.1867 (0.1875)	Acc@1 98.828 (99.435)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.132 (0.129)	Data 0.000 (0.003)	Loss 0.1906 (0.1877)	Acc@1 99.219 (99.455)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.1948 (0.1876)	Acc@1 98.047 (99.419)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.185 (0.185)	Data 0.282 (0.282)	Loss 0.1913 (0.1913)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.1995 (0.1851)	Acc@1 99.219 (99.561)	Acc@5 100.000 (99.988)
Epoch: [165][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.2036 (0.1854)	Acc@1 98.438 (99.497)	Acc@5 100.000 (99.994)
Epoch: [165][192/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.1844 (0.1851)	Acc@1 99.609 (99.520)	Acc@5 100.000 (99.996)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.93
Max memory: 91.8160896
 25.455s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 952
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.16256
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.207 (0.207)	Data 0.249 (0.249)	Loss 0.1761 (0.1761)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.126 (0.128)	Data 0.000 (0.004)	Loss 0.1849 (0.1856)	Acc@1 99.219 (99.471)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.1751 (0.1861)	Acc@1 99.609 (99.440)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.125 (0.127)	Data 0.000 (0.001)	Loss 0.1806 (0.1859)	Acc@1 100.000 (99.458)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.435264
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.175 (0.175)	Data 0.280 (0.280)	Loss 0.1778 (0.1778)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.129 (0.127)	Data 0.000 (0.004)	Loss 0.1800 (0.1839)	Acc@1 100.000 (99.567)	Acc@5 100.000 (99.994)
Epoch: [167][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.1808 (0.1834)	Acc@1 99.609 (99.531)	Acc@5 100.000 (99.997)
Epoch: [167][192/196]	Time 0.127 (0.125)	Data 0.000 (0.002)	Loss 0.1948 (0.1834)	Acc@1 99.609 (99.524)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.175 (0.175)	Data 0.268 (0.268)	Loss 0.1781 (0.1781)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.123 (0.127)	Data 0.000 (0.004)	Loss 0.1973 (0.1816)	Acc@1 98.828 (99.615)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.1871 (0.1823)	Acc@1 99.219 (99.558)	Acc@5 100.000 (100.000)
Epoch: [168][192/196]	Time 0.127 (0.126)	Data 0.000 (0.002)	Loss 0.1726 (0.1827)	Acc@1 100.000 (99.555)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.164 (0.164)	Data 0.292 (0.292)	Loss 0.1795 (0.1795)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.2032 (0.1817)	Acc@1 99.609 (99.525)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.1791 (0.1810)	Acc@1 99.609 (99.549)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.1881 (0.1812)	Acc@1 99.219 (99.553)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.189 (0.189)	Data 0.284 (0.284)	Loss 0.1790 (0.1790)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.1827 (0.1809)	Acc@1 99.609 (99.579)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.149 (0.128)	Data 0.000 (0.002)	Loss 0.1820 (0.1811)	Acc@1 99.609 (99.558)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.123 (0.127)	Data 0.000 (0.002)	Loss 0.1798 (0.1808)	Acc@1 99.609 (99.547)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.93
Max memory: 91.8160896
 25.338s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4687
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.16256
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.184 (0.184)	Data 0.293 (0.293)	Loss 0.1770 (0.1770)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.1794 (0.1796)	Acc@1 99.609 (99.555)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.1939 (0.1790)	Acc@1 98.828 (99.618)	Acc@5 100.000 (99.997)
Epoch: [171][192/196]	Time 0.120 (0.126)	Data 0.000 (0.002)	Loss 0.1963 (0.1803)	Acc@1 98.828 (99.559)	Acc@5 100.000 (99.992)
Max memory in training epoch: 59.435264
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.181 (0.181)	Data 0.265 (0.265)	Loss 0.1895 (0.1895)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.130 (0.126)	Data 0.000 (0.004)	Loss 0.1800 (0.1808)	Acc@1 99.609 (99.549)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.1799 (0.1805)	Acc@1 99.219 (99.522)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.133 (0.125)	Data 0.000 (0.002)	Loss 0.1835 (0.1798)	Acc@1 99.609 (99.563)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.164 (0.164)	Data 0.292 (0.292)	Loss 0.1719 (0.1719)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.1808 (0.1795)	Acc@1 99.219 (99.585)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.134 (0.126)	Data 0.000 (0.002)	Loss 0.1764 (0.1784)	Acc@1 99.609 (99.600)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.128 (0.126)	Data 0.000 (0.002)	Loss 0.1796 (0.1779)	Acc@1 99.219 (99.615)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.174 (0.174)	Data 0.269 (0.269)	Loss 0.1910 (0.1910)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.122 (0.126)	Data 0.000 (0.004)	Loss 0.1825 (0.1776)	Acc@1 99.609 (99.615)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.150 (0.126)	Data 0.000 (0.002)	Loss 0.1798 (0.1774)	Acc@1 99.609 (99.600)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.139 (0.127)	Data 0.000 (0.002)	Loss 0.1725 (0.1769)	Acc@1 99.609 (99.632)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.167 (0.167)	Data 0.306 (0.306)	Loss 0.1746 (0.1746)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.128 (0.126)	Data 0.000 (0.005)	Loss 0.1838 (0.1772)	Acc@1 98.828 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.127 (0.126)	Data 0.000 (0.003)	Loss 0.1702 (0.1773)	Acc@1 100.000 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.123 (0.126)	Data 0.000 (0.002)	Loss 0.1729 (0.1766)	Acc@1 100.000 (99.626)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  93.09
Max memory: 91.8160896
 25.047s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 713
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.16256
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.191 (0.191)	Data 0.279 (0.279)	Loss 0.1773 (0.1773)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.125 (0.127)	Data 0.000 (0.004)	Loss 0.1674 (0.1764)	Acc@1 100.000 (99.603)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.1689 (0.1759)	Acc@1 100.000 (99.631)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.1774 (0.1759)	Acc@1 99.609 (99.628)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.435264
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.180 (0.180)	Data 0.292 (0.292)	Loss 0.1703 (0.1703)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.123 (0.128)	Data 0.000 (0.005)	Loss 0.1735 (0.1768)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.1775 (0.1754)	Acc@1 99.219 (99.625)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 0.1716 (0.1749)	Acc@1 100.000 (99.644)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.177 (0.177)	Data 0.277 (0.277)	Loss 0.1708 (0.1708)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.1709 (0.1748)	Acc@1 100.000 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.138 (0.128)	Data 0.000 (0.002)	Loss 0.1751 (0.1749)	Acc@1 99.609 (99.631)	Acc@5 100.000 (99.997)
Epoch: [178][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.1705 (0.1745)	Acc@1 99.609 (99.638)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.152 (0.152)	Data 0.290 (0.290)	Loss 0.1744 (0.1744)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.129 (0.128)	Data 0.000 (0.005)	Loss 0.1776 (0.1744)	Acc@1 99.609 (99.645)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.133 (0.128)	Data 0.000 (0.002)	Loss 0.1751 (0.1738)	Acc@1 99.219 (99.655)	Acc@5 100.000 (99.997)
Epoch: [179][192/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.1712 (0.1744)	Acc@1 100.000 (99.638)	Acc@5 100.000 (99.998)
Max memory in training epoch: 59.3566208
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.152 (0.152)	Data 0.290 (0.290)	Loss 0.1762 (0.1762)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.126 (0.128)	Data 0.000 (0.005)	Loss 0.1702 (0.1726)	Acc@1 100.000 (99.700)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.1685 (0.1730)	Acc@1 100.000 (99.700)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.123 (0.128)	Data 0.000 (0.002)	Loss 0.1646 (0.1728)	Acc@1 100.000 (99.688)	Acc@5 100.000 (100.000)
Max memory in training epoch: 59.3566208
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(11, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(21, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(10, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  93.03
Max memory: 91.8160896
 25.498s  Thres 0.0001 2
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8819
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.210 (0.210)	Data 0.287 (0.287)	Loss 3.1075 (3.1075)	Acc@1 8.984 (8.984)	Acc@5 50.391 (50.391)
Epoch: [1][64/196]	Time 0.134 (0.129)	Data 0.000 (0.005)	Loss 2.3959 (2.6076)	Acc@1 32.812 (25.234)	Acc@5 88.281 (79.321)
Epoch: [1][128/196]	Time 0.137 (0.129)	Data 0.000 (0.002)	Loss 2.0649 (2.4413)	Acc@1 42.578 (30.772)	Acc@5 91.406 (84.027)
Epoch: [1][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 1.9298 (2.3118)	Acc@1 44.531 (35.614)	Acc@5 95.703 (86.721)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.178 (0.178)	Data 0.293 (0.293)	Loss 1.9416 (1.9416)	Acc@1 47.656 (47.656)	Acc@5 93.359 (93.359)
Epoch: [2][64/196]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 1.7436 (1.8452)	Acc@1 53.516 (52.620)	Acc@5 94.141 (94.135)
Epoch: [2][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 1.6284 (1.7612)	Acc@1 62.109 (55.320)	Acc@5 95.703 (94.934)
Epoch: [2][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 1.6199 (1.7007)	Acc@1 62.500 (57.367)	Acc@5 95.312 (95.373)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.175 (0.175)	Data 0.264 (0.264)	Loss 1.4974 (1.4974)	Acc@1 66.797 (66.797)	Acc@5 96.094 (96.094)
Epoch: [3][64/196]	Time 0.124 (0.129)	Data 0.000 (0.004)	Loss 1.2742 (1.4602)	Acc@1 70.703 (65.559)	Acc@5 98.828 (96.959)
Epoch: [3][128/196]	Time 0.125 (0.128)	Data 0.000 (0.002)	Loss 1.3528 (1.4122)	Acc@1 70.312 (66.773)	Acc@5 96.484 (97.290)
Epoch: [3][192/196]	Time 0.128 (0.128)	Data 0.000 (0.002)	Loss 1.3055 (1.3719)	Acc@1 70.312 (68.147)	Acc@5 97.266 (97.415)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.178 (0.178)	Data 0.265 (0.265)	Loss 1.2524 (1.2524)	Acc@1 73.828 (73.828)	Acc@5 98.828 (98.828)
Epoch: [4][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 1.1557 (1.2311)	Acc@1 76.562 (72.626)	Acc@5 99.219 (97.957)
Epoch: [4][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 1.2730 (1.2081)	Acc@1 72.656 (72.959)	Acc@5 96.094 (98.186)
Epoch: [4][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 1.1681 (1.1863)	Acc@1 72.266 (73.614)	Acc@5 99.219 (98.201)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.176 (0.176)	Data 0.291 (0.291)	Loss 1.0494 (1.0494)	Acc@1 78.125 (78.125)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 1.0459 (1.0779)	Acc@1 74.219 (76.929)	Acc@5 98.828 (98.540)
Epoch: [5][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 1.0994 (1.0716)	Acc@1 72.656 (76.702)	Acc@5 98.828 (98.525)
Epoch: [5][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.9605 (1.0557)	Acc@1 78.125 (77.022)	Acc@5 99.609 (98.573)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  63.05
Max memory: 103.3835008
 25.822s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2172
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.179 (0.179)	Data 0.258 (0.258)	Loss 1.0782 (1.0782)	Acc@1 76.953 (76.953)	Acc@5 97.266 (97.266)
Epoch: [6][64/196]	Time 0.128 (0.130)	Data 0.000 (0.004)	Loss 0.9554 (0.9787)	Acc@1 78.516 (78.996)	Acc@5 99.219 (98.852)
Epoch: [6][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.0566 (0.9810)	Acc@1 73.438 (78.773)	Acc@5 98.828 (98.804)
Epoch: [6][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.1811 (0.9765)	Acc@1 72.266 (78.795)	Acc@5 98.047 (98.790)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.172 (0.172)	Data 0.299 (0.299)	Loss 0.8642 (0.8642)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.8915 (0.9169)	Acc@1 79.688 (79.850)	Acc@5 99.609 (99.050)
Epoch: [7][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.9909 (0.9175)	Acc@1 75.781 (79.990)	Acc@5 99.609 (98.964)
Epoch: [7][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.9379 (0.9174)	Acc@1 78.906 (79.934)	Acc@5 97.266 (98.915)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.165 (0.165)	Data 0.292 (0.292)	Loss 0.9893 (0.9893)	Acc@1 73.438 (73.438)	Acc@5 99.609 (99.609)
Epoch: [8][64/196]	Time 0.125 (0.132)	Data 0.000 (0.005)	Loss 0.8464 (0.8881)	Acc@1 80.859 (80.451)	Acc@5 99.609 (99.008)
Epoch: [8][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.9929 (0.8768)	Acc@1 76.172 (80.729)	Acc@5 100.000 (99.086)
Epoch: [8][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.8495 (0.8760)	Acc@1 82.031 (80.776)	Acc@5 99.609 (99.053)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.182 (0.182)	Data 0.309 (0.309)	Loss 0.8793 (0.8793)	Acc@1 81.250 (81.250)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.7795 (0.8339)	Acc@1 84.375 (81.929)	Acc@5 100.000 (99.056)
Epoch: [9][128/196]	Time 0.134 (0.134)	Data 0.000 (0.003)	Loss 0.9043 (0.8464)	Acc@1 78.125 (81.350)	Acc@5 99.219 (99.001)
Epoch: [9][192/196]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.8298 (0.8486)	Acc@1 79.688 (81.191)	Acc@5 98.828 (99.037)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.159 (0.159)	Data 0.295 (0.295)	Loss 0.8225 (0.8225)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [10][64/196]	Time 0.134 (0.133)	Data 0.000 (0.005)	Loss 0.8711 (0.8197)	Acc@1 80.078 (82.175)	Acc@5 98.047 (99.075)
Epoch: [10][128/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.8630 (0.8205)	Acc@1 82.812 (82.037)	Acc@5 97.266 (99.095)
Epoch: [10][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.8182 (0.8187)	Acc@1 82.422 (82.001)	Acc@5 99.609 (99.087)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.01
Max memory: 103.3833984
 26.131s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7750
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.199 (0.199)	Data 0.284 (0.284)	Loss 0.9202 (0.9202)	Acc@1 78.906 (78.906)	Acc@5 98.438 (98.438)
Epoch: [11][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7851 (0.7772)	Acc@1 83.203 (83.293)	Acc@5 98.828 (99.303)
Epoch: [11][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7831 (0.7854)	Acc@1 83.594 (82.900)	Acc@5 99.609 (99.249)
Epoch: [11][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.8000 (0.7980)	Acc@1 80.469 (82.462)	Acc@5 99.609 (99.166)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.155 (0.155)	Data 0.260 (0.260)	Loss 0.7436 (0.7436)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.8331 (0.7908)	Acc@1 79.688 (83.107)	Acc@5 99.609 (99.105)
Epoch: [12][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.8474 (0.7922)	Acc@1 80.859 (82.658)	Acc@5 98.828 (99.140)
Epoch: [12][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7695 (0.7896)	Acc@1 83.203 (82.719)	Acc@5 99.609 (99.134)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.173 (0.173)	Data 0.263 (0.263)	Loss 0.8313 (0.8313)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.135 (0.133)	Data 0.000 (0.004)	Loss 0.7270 (0.7656)	Acc@1 81.641 (83.540)	Acc@5 99.609 (99.261)
Epoch: [13][128/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.7464 (0.7744)	Acc@1 84.375 (83.236)	Acc@5 99.219 (99.207)
Epoch: [13][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.8087 (0.7778)	Acc@1 80.859 (83.072)	Acc@5 98.828 (99.217)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.178 (0.178)	Data 0.288 (0.288)	Loss 0.6989 (0.6989)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [14][64/196]	Time 0.132 (0.134)	Data 0.000 (0.005)	Loss 0.8328 (0.7900)	Acc@1 80.078 (82.632)	Acc@5 98.438 (99.237)
Epoch: [14][128/196]	Time 0.142 (0.132)	Data 0.000 (0.002)	Loss 0.7897 (0.7746)	Acc@1 84.375 (83.161)	Acc@5 98.828 (99.258)
Epoch: [14][192/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.8207 (0.7747)	Acc@1 78.125 (83.175)	Acc@5 98.828 (99.251)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.162 (0.162)	Data 0.328 (0.328)	Loss 0.8304 (0.8304)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.128 (0.134)	Data 0.000 (0.005)	Loss 0.7579 (0.7624)	Acc@1 82.812 (83.618)	Acc@5 99.609 (99.129)
Epoch: [15][128/196]	Time 0.127 (0.133)	Data 0.000 (0.003)	Loss 0.8072 (0.7637)	Acc@1 82.812 (83.563)	Acc@5 98.828 (99.258)
Epoch: [15][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.8101 (0.7641)	Acc@1 83.203 (83.582)	Acc@5 98.438 (99.257)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  71.2
Max memory: 103.3833984
 26.317s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 89
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.178 (0.178)	Data 0.271 (0.271)	Loss 0.7129 (0.7129)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.7535 (0.7265)	Acc@1 82.812 (85.210)	Acc@5 99.219 (99.327)
Epoch: [16][128/196]	Time 0.129 (0.128)	Data 0.000 (0.002)	Loss 0.8909 (0.7520)	Acc@1 78.906 (84.093)	Acc@5 98.828 (99.267)
Epoch: [16][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7717 (0.7595)	Acc@1 83.203 (83.812)	Acc@5 99.609 (99.237)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.167 (0.167)	Data 0.264 (0.264)	Loss 0.7504 (0.7504)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [17][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.7051 (0.7572)	Acc@1 86.328 (83.858)	Acc@5 100.000 (99.381)
Epoch: [17][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6937 (0.7666)	Acc@1 85.938 (83.594)	Acc@5 99.609 (99.294)
Epoch: [17][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7966 (0.7630)	Acc@1 83.594 (83.640)	Acc@5 99.219 (99.294)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.158 (0.158)	Data 0.276 (0.276)	Loss 0.6391 (0.6391)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [18][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 0.8095 (0.7597)	Acc@1 82.812 (83.666)	Acc@5 98.047 (99.261)
Epoch: [18][128/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6763 (0.7515)	Acc@1 86.328 (84.105)	Acc@5 100.000 (99.249)
Epoch: [18][192/196]	Time 0.137 (0.130)	Data 0.000 (0.002)	Loss 0.8736 (0.7537)	Acc@1 79.688 (84.047)	Acc@5 97.656 (99.217)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.175 (0.175)	Data 0.301 (0.301)	Loss 0.6860 (0.6860)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.123 (0.130)	Data 0.000 (0.005)	Loss 0.8031 (0.7365)	Acc@1 80.859 (84.603)	Acc@5 99.609 (99.321)
Epoch: [19][128/196]	Time 0.130 (0.131)	Data 0.000 (0.003)	Loss 0.7204 (0.7493)	Acc@1 85.547 (84.224)	Acc@5 100.000 (99.237)
Epoch: [19][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7075 (0.7505)	Acc@1 86.328 (84.250)	Acc@5 99.609 (99.223)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.174 (0.174)	Data 0.316 (0.316)	Loss 0.6835 (0.6835)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.6983 (0.7359)	Acc@1 87.891 (84.585)	Acc@5 99.219 (99.201)
Epoch: [20][128/196]	Time 0.133 (0.131)	Data 0.000 (0.003)	Loss 0.8433 (0.7364)	Acc@1 80.859 (84.699)	Acc@5 97.656 (99.234)
Epoch: [20][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.6989 (0.7428)	Acc@1 87.500 (84.426)	Acc@5 99.609 (99.241)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  75.3
Max memory: 103.3833984
 25.995s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9676
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.202496
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.192 (0.192)	Data 0.266 (0.266)	Loss 0.7159 (0.7159)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.132 (0.134)	Data 0.000 (0.004)	Loss 0.7560 (0.7023)	Acc@1 83.203 (85.817)	Acc@5 99.219 (99.411)
Epoch: [21][128/196]	Time 0.135 (0.134)	Data 0.000 (0.002)	Loss 0.8112 (0.7204)	Acc@1 81.250 (85.308)	Acc@5 99.219 (99.304)
Epoch: [21][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.8085 (0.7286)	Acc@1 82.031 (84.994)	Acc@5 98.828 (99.322)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.177 (0.177)	Data 0.263 (0.263)	Loss 0.7264 (0.7264)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.7418 (0.7350)	Acc@1 86.328 (84.832)	Acc@5 99.219 (99.327)
Epoch: [22][128/196]	Time 0.138 (0.133)	Data 0.000 (0.002)	Loss 0.7083 (0.7274)	Acc@1 86.719 (84.984)	Acc@5 98.438 (99.310)
Epoch: [22][192/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7618 (0.7334)	Acc@1 84.375 (84.715)	Acc@5 98.828 (99.310)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.199 (0.199)	Data 0.263 (0.263)	Loss 0.6607 (0.6607)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.131 (0.134)	Data 0.000 (0.004)	Loss 0.8649 (0.7184)	Acc@1 82.031 (84.904)	Acc@5 98.438 (99.333)
Epoch: [23][128/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7646 (0.7227)	Acc@1 84.766 (84.811)	Acc@5 98.438 (99.285)
Epoch: [23][192/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.7483 (0.7290)	Acc@1 81.641 (84.685)	Acc@5 99.609 (99.304)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.158 (0.158)	Data 0.299 (0.299)	Loss 0.6918 (0.6918)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.126 (0.132)	Data 0.000 (0.005)	Loss 0.6240 (0.7299)	Acc@1 87.500 (84.802)	Acc@5 99.609 (99.387)
Epoch: [24][128/196]	Time 0.128 (0.133)	Data 0.000 (0.002)	Loss 0.7646 (0.7361)	Acc@1 83.203 (84.684)	Acc@5 99.219 (99.304)
Epoch: [24][192/196]	Time 0.136 (0.133)	Data 0.000 (0.002)	Loss 0.6563 (0.7297)	Acc@1 87.500 (84.907)	Acc@5 99.609 (99.334)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.192 (0.192)	Data 0.283 (0.283)	Loss 0.6582 (0.6582)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.134 (0.133)	Data 0.000 (0.005)	Loss 0.7098 (0.7117)	Acc@1 86.719 (85.246)	Acc@5 97.656 (99.441)
Epoch: [25][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7193 (0.7154)	Acc@1 83.203 (85.296)	Acc@5 99.609 (99.382)
Epoch: [25][192/196]	Time 0.145 (0.132)	Data 0.000 (0.002)	Loss 0.8155 (0.7197)	Acc@1 82.031 (85.207)	Acc@5 98.828 (99.348)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 485078 ; 487386 ; 0.9952645336550496
[INFO] Storing checkpoint...
  79.06
Max memory: 103.3833984
 26.290s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6017
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.2015744
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.207 (0.207)	Data 0.253 (0.253)	Loss 0.6196 (0.6196)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 0.125 (0.133)	Data 0.000 (0.004)	Loss 0.7114 (0.7007)	Acc@1 83.984 (85.517)	Acc@5 99.219 (99.447)
Epoch: [26][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7291 (0.7197)	Acc@1 86.328 (85.059)	Acc@5 99.609 (99.385)
Epoch: [26][192/196]	Time 0.132 (0.132)	Data 0.000 (0.001)	Loss 0.7484 (0.7196)	Acc@1 82.422 (85.148)	Acc@5 99.609 (99.342)
Max memory in training epoch: 66.6429952
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.164 (0.164)	Data 0.293 (0.293)	Loss 0.6962 (0.6962)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [27][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 0.6746 (0.7122)	Acc@1 87.500 (85.312)	Acc@5 99.609 (99.447)
Epoch: [27][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7125 (0.7145)	Acc@1 83.984 (85.365)	Acc@5 99.609 (99.376)
Epoch: [27][192/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.6961 (0.7199)	Acc@1 86.719 (85.215)	Acc@5 99.219 (99.332)
Max memory in training epoch: 66.5381376
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.181 (0.181)	Data 0.262 (0.262)	Loss 0.7637 (0.7637)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [28][64/196]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 0.6499 (0.7158)	Acc@1 87.109 (85.463)	Acc@5 100.000 (99.357)
Epoch: [28][128/196]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.7060 (0.7188)	Acc@1 85.547 (85.232)	Acc@5 99.609 (99.319)
Epoch: [28][192/196]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.7298 (0.7190)	Acc@1 85.156 (85.187)	Acc@5 99.609 (99.328)
Max memory in training epoch: 66.5381376
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.176 (0.176)	Data 0.278 (0.278)	Loss 0.5790 (0.5790)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.8417 (0.7188)	Acc@1 80.078 (85.006)	Acc@5 98.438 (99.357)
Epoch: [29][128/196]	Time 0.136 (0.133)	Data 0.000 (0.002)	Loss 0.7520 (0.7229)	Acc@1 82.812 (85.120)	Acc@5 99.609 (99.358)
Epoch: [29][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7374 (0.7193)	Acc@1 85.547 (85.136)	Acc@5 99.219 (99.362)
Max memory in training epoch: 66.5381376
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.188 (0.188)	Data 0.275 (0.275)	Loss 0.6232 (0.6232)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.7806 (0.7060)	Acc@1 85.547 (85.871)	Acc@5 98.828 (99.375)
Epoch: [30][128/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7707 (0.7097)	Acc@1 85.156 (85.656)	Acc@5 99.219 (99.358)
Epoch: [30][192/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7491 (0.7114)	Acc@1 85.156 (85.531)	Acc@5 99.609 (99.401)
Max memory in training epoch: 66.5381376
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 472956 ; 485078 ; 0.9750102045444238
[INFO] Storing checkpoint...
  78.86
Max memory: 103.3806336
 26.496s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2656
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1967616
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.194 (0.194)	Data 0.262 (0.262)	Loss 0.6783 (0.6783)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [31][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.7513 (0.6764)	Acc@1 83.594 (86.617)	Acc@5 99.219 (99.471)
Epoch: [31][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7471 (0.6910)	Acc@1 82.812 (86.195)	Acc@5 99.609 (99.400)
Epoch: [31][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7500 (0.6992)	Acc@1 85.156 (85.905)	Acc@5 98.828 (99.393)
Max memory in training epoch: 66.623744
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.155 (0.155)	Data 0.265 (0.265)	Loss 0.6926 (0.6926)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [32][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.8355 (0.7083)	Acc@1 81.641 (85.457)	Acc@5 98.828 (99.441)
Epoch: [32][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8361 (0.7065)	Acc@1 81.250 (85.562)	Acc@5 99.219 (99.434)
Epoch: [32][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6805 (0.7114)	Acc@1 87.891 (85.395)	Acc@5 100.000 (99.427)
Max memory in training epoch: 66.230528
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.154 (0.154)	Data 0.292 (0.292)	Loss 0.7786 (0.7786)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [33][64/196]	Time 0.130 (0.131)	Data 0.000 (0.005)	Loss 0.6342 (0.6968)	Acc@1 87.500 (86.220)	Acc@5 99.609 (99.273)
Epoch: [33][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.7052 (0.7024)	Acc@1 85.938 (85.998)	Acc@5 98.828 (99.273)
Epoch: [33][192/196]	Time 0.124 (0.132)	Data 0.000 (0.002)	Loss 0.6326 (0.7046)	Acc@1 88.281 (85.877)	Acc@5 99.219 (99.322)
Max memory in training epoch: 66.230528
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.164 (0.164)	Data 0.311 (0.311)	Loss 0.7461 (0.7461)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.123 (0.131)	Data 0.000 (0.005)	Loss 0.8215 (0.7170)	Acc@1 81.641 (85.541)	Acc@5 99.219 (99.213)
Epoch: [34][128/196]	Time 0.126 (0.131)	Data 0.000 (0.003)	Loss 0.7272 (0.7061)	Acc@1 85.156 (85.847)	Acc@5 99.609 (99.285)
Epoch: [34][192/196]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.6574 (0.7078)	Acc@1 87.109 (85.725)	Acc@5 100.000 (99.314)
Max memory in training epoch: 66.230528
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.172 (0.172)	Data 0.289 (0.289)	Loss 0.7112 (0.7112)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.7382 (0.6954)	Acc@1 82.812 (85.835)	Acc@5 99.609 (99.423)
Epoch: [35][128/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7434 (0.6976)	Acc@1 84.375 (85.689)	Acc@5 98.438 (99.431)
Epoch: [35][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6286 (0.6992)	Acc@1 89.062 (85.646)	Acc@5 99.609 (99.425)
Max memory in training epoch: 66.230528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 450734 ; 472956 ; 0.9530146567545396
[INFO] Storing checkpoint...
  78.38
Max memory: 103.1921152
 26.112s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1332
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1879552
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.190 (0.190)	Data 0.262 (0.262)	Loss 0.6688 (0.6688)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [36][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.8021 (0.6544)	Acc@1 82.031 (87.470)	Acc@5 100.000 (99.483)
Epoch: [36][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6803 (0.6845)	Acc@1 87.109 (86.401)	Acc@5 99.609 (99.458)
Epoch: [36][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.5911 (0.6902)	Acc@1 88.672 (86.114)	Acc@5 100.000 (99.449)
Max memory in training epoch: 65.775872
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.186 (0.186)	Data 0.280 (0.280)	Loss 0.6361 (0.6361)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.148 (0.130)	Data 0.000 (0.004)	Loss 0.5999 (0.6878)	Acc@1 86.719 (86.250)	Acc@5 100.000 (99.411)
Epoch: [37][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6859 (0.6941)	Acc@1 85.156 (86.113)	Acc@5 99.609 (99.428)
Epoch: [37][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6104 (0.6938)	Acc@1 89.062 (86.160)	Acc@5 99.609 (99.409)
Max memory in training epoch: 65.7496576
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.159 (0.159)	Data 0.257 (0.257)	Loss 0.7251 (0.7251)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [38][64/196]	Time 0.125 (0.131)	Data 0.000 (0.004)	Loss 0.5938 (0.6952)	Acc@1 90.625 (85.871)	Acc@5 99.609 (99.429)
Epoch: [38][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7219 (0.6922)	Acc@1 85.156 (85.889)	Acc@5 99.609 (99.437)
Epoch: [38][192/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.7660 (0.6949)	Acc@1 84.766 (85.875)	Acc@5 99.219 (99.415)
Max memory in training epoch: 65.7496576
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.155 (0.155)	Data 0.298 (0.298)	Loss 0.6279 (0.6279)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.133 (0.130)	Data 0.000 (0.005)	Loss 0.7286 (0.7014)	Acc@1 86.328 (85.721)	Acc@5 100.000 (99.417)
Epoch: [39][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6205 (0.6917)	Acc@1 89.062 (86.174)	Acc@5 99.219 (99.397)
Epoch: [39][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7105 (0.6922)	Acc@1 85.156 (86.229)	Acc@5 99.609 (99.413)
Max memory in training epoch: 65.7496576
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.177 (0.177)	Data 0.262 (0.262)	Loss 0.8547 (0.8547)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.132 (0.130)	Data 0.000 (0.004)	Loss 0.6219 (0.6808)	Acc@1 88.281 (86.292)	Acc@5 99.219 (99.483)
Epoch: [40][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7229 (0.6877)	Acc@1 84.766 (86.074)	Acc@5 99.609 (99.479)
Epoch: [40][192/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.6611 (0.6886)	Acc@1 87.109 (86.103)	Acc@5 99.609 (99.490)
Max memory in training epoch: 65.7496576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 439760 ; 450734 ; 0.9756530459206538
[INFO] Storing checkpoint...
  79.47
Max memory: 101.8676736
 25.877s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4527
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.183552
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.203 (0.203)	Data 0.282 (0.282)	Loss 0.5790 (0.5790)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.126 (0.131)	Data 0.000 (0.005)	Loss 0.7867 (0.6599)	Acc@1 81.250 (86.809)	Acc@5 99.609 (99.579)
Epoch: [41][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7455 (0.6816)	Acc@1 83.594 (86.056)	Acc@5 99.219 (99.479)
Epoch: [41][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6981 (0.6840)	Acc@1 86.719 (86.029)	Acc@5 98.438 (99.464)
Max memory in training epoch: 65.3388288
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.188 (0.188)	Data 0.278 (0.278)	Loss 0.7856 (0.7856)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [42][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.6024 (0.6752)	Acc@1 87.891 (86.707)	Acc@5 100.000 (99.453)
Epoch: [42][128/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 0.7439 (0.6841)	Acc@1 85.156 (86.519)	Acc@5 98.828 (99.482)
Epoch: [42][192/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 0.6207 (0.6869)	Acc@1 88.281 (86.330)	Acc@5 98.828 (99.468)
Max memory in training epoch: 65.1160064
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.159 (0.159)	Data 0.284 (0.284)	Loss 0.7748 (0.7748)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [43][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.6322 (0.6907)	Acc@1 87.109 (85.895)	Acc@5 99.609 (99.423)
Epoch: [43][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7193 (0.6830)	Acc@1 83.594 (86.268)	Acc@5 99.219 (99.428)
Epoch: [43][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7147 (0.6849)	Acc@1 86.328 (86.188)	Acc@5 99.219 (99.431)
Max memory in training epoch: 65.1160064
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.158 (0.158)	Data 0.279 (0.279)	Loss 0.6433 (0.6433)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.124 (0.131)	Data 0.000 (0.004)	Loss 0.6853 (0.6617)	Acc@1 85.938 (86.995)	Acc@5 100.000 (99.561)
Epoch: [44][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6734 (0.6696)	Acc@1 86.719 (86.634)	Acc@5 98.828 (99.503)
Epoch: [44][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.6144 (0.6754)	Acc@1 89.844 (86.423)	Acc@5 98.828 (99.498)
Max memory in training epoch: 65.1160064
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.186 (0.186)	Data 0.286 (0.286)	Loss 0.5565 (0.5565)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.126 (0.130)	Data 0.000 (0.005)	Loss 0.6560 (0.6749)	Acc@1 87.500 (86.647)	Acc@5 99.609 (99.453)
Epoch: [45][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6849 (0.6766)	Acc@1 88.672 (86.598)	Acc@5 99.219 (99.397)
Epoch: [45][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.6797 (0.6836)	Acc@1 86.719 (86.332)	Acc@5 99.219 (99.371)
Max memory in training epoch: 65.1160064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 431384 ; 439760 ; 0.9809532472257595
[INFO] Storing checkpoint...
  78.18
Max memory: 101.0819584
 25.862s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6025
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1802752
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.205 (0.205)	Data 0.277 (0.277)	Loss 0.7795 (0.7795)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.6604 (0.6587)	Acc@1 84.375 (87.097)	Acc@5 99.219 (99.501)
Epoch: [46][128/196]	Time 0.118 (0.129)	Data 0.000 (0.002)	Loss 0.6222 (0.6715)	Acc@1 87.109 (86.601)	Acc@5 100.000 (99.446)
Epoch: [46][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7304 (0.6767)	Acc@1 83.594 (86.332)	Acc@5 99.219 (99.456)
Max memory in training epoch: 64.8669696
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.170 (0.170)	Data 0.298 (0.298)	Loss 0.6735 (0.6735)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.124 (0.131)	Data 0.000 (0.005)	Loss 0.6102 (0.6701)	Acc@1 88.281 (86.599)	Acc@5 99.219 (99.405)
Epoch: [47][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7202 (0.6765)	Acc@1 83.594 (86.352)	Acc@5 99.609 (99.497)
Epoch: [47][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6446 (0.6765)	Acc@1 87.891 (86.358)	Acc@5 100.000 (99.500)
Max memory in training epoch: 64.6703616
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.187 (0.187)	Data 0.300 (0.300)	Loss 0.7214 (0.7214)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.133 (0.132)	Data 0.000 (0.005)	Loss 0.6334 (0.6639)	Acc@1 86.328 (86.677)	Acc@5 99.219 (99.447)
Epoch: [48][128/196]	Time 0.123 (0.132)	Data 0.000 (0.002)	Loss 0.7326 (0.6777)	Acc@1 83.203 (86.265)	Acc@5 98.828 (99.470)
Epoch: [48][192/196]	Time 0.144 (0.131)	Data 0.000 (0.002)	Loss 0.7231 (0.6797)	Acc@1 84.375 (86.269)	Acc@5 99.609 (99.421)
Max memory in training epoch: 64.6703616
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.159 (0.159)	Data 0.291 (0.291)	Loss 0.6788 (0.6788)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.129 (0.129)	Data 0.000 (0.005)	Loss 0.6805 (0.6645)	Acc@1 85.547 (86.556)	Acc@5 100.000 (99.435)
Epoch: [49][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6801 (0.6644)	Acc@1 85.938 (86.867)	Acc@5 99.609 (99.491)
Epoch: [49][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7014 (0.6719)	Acc@1 86.719 (86.539)	Acc@5 99.609 (99.480)
Max memory in training epoch: 64.6703616
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.179 (0.179)	Data 0.262 (0.262)	Loss 0.6209 (0.6209)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.122 (0.131)	Data 0.000 (0.004)	Loss 0.6469 (0.6721)	Acc@1 87.891 (86.635)	Acc@5 99.219 (99.507)
Epoch: [50][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.6975 (0.6705)	Acc@1 87.109 (86.634)	Acc@5 99.609 (99.525)
Epoch: [50][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.6873 (0.6731)	Acc@1 84.766 (86.557)	Acc@5 99.219 (99.516)
Max memory in training epoch: 64.6703616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 420410 ; 431384 ; 0.9745609480184708
[INFO] Storing checkpoint...
  76.35
Max memory: 100.0301056
 25.743s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1739
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1759744
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.188 (0.188)	Data 0.289 (0.289)	Loss 0.7568 (0.7568)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.6985 (0.6508)	Acc@1 84.766 (87.121)	Acc@5 99.219 (99.507)
Epoch: [51][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 0.5826 (0.6572)	Acc@1 89.453 (86.988)	Acc@5 100.000 (99.512)
Epoch: [51][192/196]	Time 0.120 (0.128)	Data 0.000 (0.002)	Loss 0.6478 (0.6593)	Acc@1 86.328 (86.875)	Acc@5 99.609 (99.512)
Max memory in training epoch: 63.1261696
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.190 (0.190)	Data 0.265 (0.265)	Loss 0.5842 (0.5842)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.6620 (0.6666)	Acc@1 89.453 (86.683)	Acc@5 99.609 (99.483)
Epoch: [52][128/196]	Time 0.126 (0.128)	Data 0.000 (0.002)	Loss 0.6398 (0.6813)	Acc@1 87.891 (86.213)	Acc@5 99.609 (99.455)
Epoch: [52][192/196]	Time 0.119 (0.127)	Data 0.000 (0.002)	Loss 0.7235 (0.6845)	Acc@1 85.156 (86.136)	Acc@5 99.609 (99.409)
Max memory in training epoch: 63.0147584
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.160 (0.160)	Data 0.292 (0.292)	Loss 0.7583 (0.7583)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.6278 (0.6802)	Acc@1 87.109 (86.244)	Acc@5 100.000 (99.339)
Epoch: [53][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.6695 (0.6805)	Acc@1 88.672 (86.419)	Acc@5 99.609 (99.376)
Epoch: [53][192/196]	Time 0.124 (0.130)	Data 0.000 (0.002)	Loss 0.6396 (0.6821)	Acc@1 87.109 (86.261)	Acc@5 99.219 (99.385)
Max memory in training epoch: 63.0147584
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.164 (0.164)	Data 0.265 (0.265)	Loss 0.6228 (0.6228)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.6155 (0.6535)	Acc@1 87.109 (87.194)	Acc@5 99.219 (99.525)
Epoch: [54][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7651 (0.6580)	Acc@1 83.594 (86.958)	Acc@5 99.609 (99.509)
Epoch: [54][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.8162 (0.6685)	Acc@1 82.031 (86.674)	Acc@5 98.438 (99.470)
Max memory in training epoch: 63.0147584
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.159 (0.159)	Data 0.266 (0.266)	Loss 0.6249 (0.6249)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.120 (0.128)	Data 0.000 (0.004)	Loss 0.7226 (0.6834)	Acc@1 85.156 (86.070)	Acc@5 98.828 (99.315)
Epoch: [55][128/196]	Time 0.134 (0.129)	Data 0.000 (0.002)	Loss 0.6013 (0.6826)	Acc@1 88.672 (86.180)	Acc@5 100.000 (99.431)
Epoch: [55][192/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.6894 (0.6770)	Acc@1 86.719 (86.403)	Acc@5 100.000 (99.439)
Max memory in training epoch: 63.0147584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 412906 ; 420410 ; 0.9821507575937775
[INFO] Storing checkpoint...
  74.07
Max memory: 98.0199936
 25.577s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3238
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1731072
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.216 (0.216)	Data 0.272 (0.272)	Loss 0.6055 (0.6055)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.6130 (0.6536)	Acc@1 85.547 (87.073)	Acc@5 100.000 (99.537)
Epoch: [56][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6998 (0.6645)	Acc@1 85.547 (86.788)	Acc@5 99.219 (99.512)
Epoch: [56][192/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.7026 (0.6671)	Acc@1 85.547 (86.727)	Acc@5 99.219 (99.482)
Max memory in training epoch: 62.9377536
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.151 (0.151)	Data 0.295 (0.295)	Loss 0.6795 (0.6795)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.6552 (0.6774)	Acc@1 87.500 (86.629)	Acc@5 100.000 (99.543)
Epoch: [57][128/196]	Time 0.139 (0.128)	Data 0.000 (0.002)	Loss 0.6537 (0.6762)	Acc@1 86.719 (86.531)	Acc@5 99.609 (99.509)
Epoch: [57][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6328 (0.6814)	Acc@1 87.109 (86.292)	Acc@5 99.609 (99.470)
Max memory in training epoch: 62.8591104
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.179 (0.179)	Data 0.307 (0.307)	Loss 0.6667 (0.6667)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [58][64/196]	Time 0.125 (0.129)	Data 0.000 (0.005)	Loss 0.7819 (0.6622)	Acc@1 80.078 (86.641)	Acc@5 99.219 (99.597)
Epoch: [58][128/196]	Time 0.131 (0.128)	Data 0.000 (0.003)	Loss 0.6775 (0.6669)	Acc@1 87.891 (86.622)	Acc@5 99.609 (99.564)
Epoch: [58][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6585 (0.6706)	Acc@1 87.500 (86.433)	Acc@5 100.000 (99.526)
Max memory in training epoch: 62.8591104
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.177 (0.177)	Data 0.289 (0.289)	Loss 0.6549 (0.6549)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.127 (0.128)	Data 0.000 (0.005)	Loss 0.6316 (0.6676)	Acc@1 86.328 (86.316)	Acc@5 99.609 (99.591)
Epoch: [59][128/196]	Time 0.124 (0.127)	Data 0.000 (0.002)	Loss 0.7349 (0.6678)	Acc@1 84.375 (86.383)	Acc@5 98.438 (99.519)
Epoch: [59][192/196]	Time 0.136 (0.128)	Data 0.000 (0.002)	Loss 0.6287 (0.6648)	Acc@1 87.500 (86.579)	Acc@5 99.219 (99.512)
Max memory in training epoch: 62.8591104
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.164 (0.164)	Data 0.295 (0.295)	Loss 0.6397 (0.6397)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [60][64/196]	Time 0.124 (0.130)	Data 0.000 (0.005)	Loss 0.7372 (0.6685)	Acc@1 83.594 (86.743)	Acc@5 100.000 (99.411)
Epoch: [60][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.6603 (0.6693)	Acc@1 85.938 (86.558)	Acc@5 99.609 (99.512)
Epoch: [60][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.8109 (0.6735)	Acc@1 83.594 (86.450)	Acc@5 98.828 (99.466)
Max memory in training epoch: 62.8591104
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 406552 ; 412906 ; 0.9846115096414196
[INFO] Storing checkpoint...
  77.42
Max memory: 97.7066496
 25.606s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1155
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1705472
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.206 (0.206)	Data 0.268 (0.268)	Loss 0.6154 (0.6154)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.136 (0.130)	Data 0.000 (0.004)	Loss 0.7504 (0.6448)	Acc@1 83.203 (87.560)	Acc@5 98.828 (99.561)
Epoch: [61][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6629 (0.6592)	Acc@1 85.156 (87.043)	Acc@5 100.000 (99.540)
Epoch: [61][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.5854 (0.6581)	Acc@1 88.672 (87.083)	Acc@5 100.000 (99.530)
Max memory in training epoch: 62.0493312
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.177 (0.177)	Data 0.261 (0.261)	Loss 0.6736 (0.6736)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.136 (0.129)	Data 0.000 (0.004)	Loss 0.8031 (0.6676)	Acc@1 82.422 (86.550)	Acc@5 99.219 (99.483)
Epoch: [62][128/196]	Time 0.122 (0.129)	Data 0.000 (0.002)	Loss 0.6492 (0.6629)	Acc@1 83.594 (86.676)	Acc@5 99.609 (99.500)
Epoch: [62][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7179 (0.6699)	Acc@1 88.281 (86.508)	Acc@5 99.609 (99.468)
Max memory in training epoch: 62.1410816
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.187 (0.187)	Data 0.266 (0.266)	Loss 0.6012 (0.6012)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.130 (0.131)	Data 0.000 (0.004)	Loss 0.6461 (0.6692)	Acc@1 87.500 (86.749)	Acc@5 99.609 (99.405)
Epoch: [63][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.5978 (0.6672)	Acc@1 87.891 (86.704)	Acc@5 99.609 (99.437)
Epoch: [63][192/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.8532 (0.6665)	Acc@1 83.203 (86.705)	Acc@5 99.219 (99.480)
Max memory in training epoch: 62.1410816
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.182 (0.182)	Data 0.285 (0.285)	Loss 0.7737 (0.7737)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [64][64/196]	Time 0.135 (0.130)	Data 0.000 (0.005)	Loss 0.7099 (0.6745)	Acc@1 85.938 (86.593)	Acc@5 100.000 (99.363)
Epoch: [64][128/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7388 (0.6684)	Acc@1 84.375 (86.758)	Acc@5 99.219 (99.431)
Epoch: [64][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7167 (0.6676)	Acc@1 85.156 (86.765)	Acc@5 99.219 (99.470)
Max memory in training epoch: 62.1410816
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.156 (0.156)	Data 0.255 (0.255)	Loss 0.7043 (0.7043)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [65][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.7104 (0.6612)	Acc@1 85.938 (86.887)	Acc@5 99.609 (99.537)
Epoch: [65][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6694 (0.6560)	Acc@1 86.328 (86.961)	Acc@5 98.828 (99.534)
Epoch: [65][192/196]	Time 0.133 (0.131)	Data 0.000 (0.001)	Loss 0.5802 (0.6580)	Acc@1 89.844 (86.820)	Acc@5 99.609 (99.498)
Max memory in training epoch: 62.1410816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 399840 ; 406552 ; 0.9834904268088707
[INFO] Storing checkpoint...
  84.05
Max memory: 96.4578816
 26.009s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 673
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1672704
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.165 (0.165)	Data 0.297 (0.297)	Loss 0.6547 (0.6547)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.120 (0.124)	Data 0.000 (0.005)	Loss 0.6781 (0.6297)	Acc@1 88.672 (87.825)	Acc@5 99.609 (99.477)
Epoch: [66][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.7009 (0.6490)	Acc@1 85.547 (87.134)	Acc@5 98.828 (99.461)
Epoch: [66][192/196]	Time 0.135 (0.123)	Data 0.000 (0.002)	Loss 0.6441 (0.6545)	Acc@1 88.672 (86.877)	Acc@5 100.000 (99.470)
Max memory in training epoch: 59.0224896
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.182 (0.182)	Data 0.253 (0.253)	Loss 0.6445 (0.6445)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [67][64/196]	Time 0.127 (0.122)	Data 0.000 (0.004)	Loss 0.8113 (0.6594)	Acc@1 83.203 (86.845)	Acc@5 99.609 (99.477)
Epoch: [67][128/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.6619 (0.6547)	Acc@1 83.984 (86.988)	Acc@5 99.609 (99.479)
Epoch: [67][192/196]	Time 0.120 (0.122)	Data 0.000 (0.001)	Loss 0.7342 (0.6605)	Acc@1 86.719 (86.737)	Acc@5 97.656 (99.452)
Max memory in training epoch: 59.3632768
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.168 (0.168)	Data 0.280 (0.280)	Loss 0.6674 (0.6674)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [68][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.6333 (0.6655)	Acc@1 84.766 (86.484)	Acc@5 100.000 (99.453)
Epoch: [68][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.7081 (0.6670)	Acc@1 85.547 (86.467)	Acc@5 99.609 (99.455)
Epoch: [68][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6653 (0.6657)	Acc@1 87.109 (86.585)	Acc@5 99.219 (99.443)
Max memory in training epoch: 59.3632768
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.169 (0.169)	Data 0.279 (0.279)	Loss 0.7037 (0.7037)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [69][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.6773 (0.6685)	Acc@1 86.328 (86.695)	Acc@5 98.828 (99.477)
Epoch: [69][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.7149 (0.6655)	Acc@1 83.984 (86.955)	Acc@5 99.609 (99.500)
Epoch: [69][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6443 (0.6655)	Acc@1 88.281 (86.911)	Acc@5 98.828 (99.478)
Max memory in training epoch: 59.3632768
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.187 (0.187)	Data 0.342 (0.342)	Loss 0.6363 (0.6363)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [70][64/196]	Time 0.123 (0.126)	Data 0.000 (0.005)	Loss 0.7041 (0.6569)	Acc@1 85.156 (87.055)	Acc@5 100.000 (99.513)
Epoch: [70][128/196]	Time 0.118 (0.124)	Data 0.000 (0.003)	Loss 0.7193 (0.6616)	Acc@1 85.938 (86.931)	Acc@5 99.609 (99.479)
Epoch: [70][192/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.7448 (0.6618)	Acc@1 82.422 (86.838)	Acc@5 99.609 (99.452)
Max memory in training epoch: 59.3632768
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 393198 ; 399840 ; 0.9833883553421369
[INFO] Storing checkpoint...
  76.65
Max memory: 91.9102976
 24.560s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9556
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1647104
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.179 (0.179)	Data 0.295 (0.295)	Loss 0.6552 (0.6552)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [71][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.7145 (0.6316)	Acc@1 85.938 (87.752)	Acc@5 99.609 (99.567)
Epoch: [71][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.6163 (0.6446)	Acc@1 86.328 (87.264)	Acc@5 98.828 (99.522)
Epoch: [71][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.7605 (0.6548)	Acc@1 83.203 (86.871)	Acc@5 98.828 (99.492)
Max memory in training epoch: 58.2913536
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.158 (0.158)	Data 0.261 (0.261)	Loss 0.6778 (0.6778)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.5841 (0.6693)	Acc@1 89.844 (86.538)	Acc@5 99.219 (99.417)
Epoch: [72][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6385 (0.6561)	Acc@1 85.938 (86.964)	Acc@5 99.609 (99.455)
Epoch: [72][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6193 (0.6572)	Acc@1 88.672 (86.964)	Acc@5 99.609 (99.468)
Max memory in training epoch: 58.5272832
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.150 (0.150)	Data 0.262 (0.262)	Loss 0.5590 (0.5590)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [73][64/196]	Time 0.121 (0.121)	Data 0.000 (0.004)	Loss 0.6812 (0.6660)	Acc@1 85.938 (86.689)	Acc@5 99.609 (99.429)
Epoch: [73][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.7088 (0.6598)	Acc@1 86.719 (86.828)	Acc@5 98.047 (99.479)
Epoch: [73][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.7056 (0.6658)	Acc@1 83.984 (86.684)	Acc@5 98.828 (99.504)
Max memory in training epoch: 58.5272832
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.173 (0.173)	Data 0.264 (0.264)	Loss 0.6124 (0.6124)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.118 (0.125)	Data 0.000 (0.004)	Loss 0.6312 (0.6467)	Acc@1 85.547 (87.254)	Acc@5 99.609 (99.519)
Epoch: [74][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.7001 (0.6510)	Acc@1 87.500 (87.170)	Acc@5 99.219 (99.488)
Epoch: [74][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.6327 (0.6513)	Acc@1 87.500 (87.170)	Acc@5 99.609 (99.494)
Max memory in training epoch: 58.5272832
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.179 (0.179)	Data 0.259 (0.259)	Loss 0.6292 (0.6292)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.119 (0.124)	Data 0.000 (0.004)	Loss 0.6208 (0.6455)	Acc@1 88.672 (87.308)	Acc@5 98.828 (99.465)
Epoch: [75][128/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.5780 (0.6450)	Acc@1 90.234 (87.318)	Acc@5 100.000 (99.491)
Epoch: [75][192/196]	Time 0.131 (0.122)	Data 0.000 (0.002)	Loss 0.7200 (0.6542)	Acc@1 85.938 (87.067)	Acc@5 98.828 (99.480)
Max memory in training epoch: 58.5272832
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 388432 ; 393198 ; 0.9878788803605308
[INFO] Storing checkpoint...
  80.49
Max memory: 91.1593984
 24.317s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8676
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.162816
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.173 (0.173)	Data 0.263 (0.263)	Loss 0.6871 (0.6871)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [76][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 0.6344 (0.6411)	Acc@1 88.672 (87.332)	Acc@5 99.609 (99.561)
Epoch: [76][128/196]	Time 0.135 (0.124)	Data 0.000 (0.002)	Loss 0.7423 (0.6516)	Acc@1 84.766 (87.112)	Acc@5 99.219 (99.552)
Epoch: [76][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.6982 (0.6537)	Acc@1 87.109 (87.010)	Acc@5 100.000 (99.494)
Max memory in training epoch: 57.89056
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.162 (0.162)	Data 0.297 (0.297)	Loss 0.6008 (0.6008)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.117 (0.125)	Data 0.000 (0.005)	Loss 0.6380 (0.6601)	Acc@1 87.500 (86.911)	Acc@5 99.219 (99.531)
Epoch: [77][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.6449 (0.6528)	Acc@1 84.375 (87.109)	Acc@5 99.609 (99.537)
Epoch: [77][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.5729 (0.6509)	Acc@1 90.234 (87.164)	Acc@5 100.000 (99.516)
Max memory in training epoch: 57.9954176
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.175 (0.175)	Data 0.287 (0.287)	Loss 0.6030 (0.6030)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.6570 (0.6456)	Acc@1 86.719 (87.121)	Acc@5 99.219 (99.453)
Epoch: [78][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.6632 (0.6506)	Acc@1 87.500 (86.946)	Acc@5 100.000 (99.500)
Epoch: [78][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.6890 (0.6545)	Acc@1 85.547 (86.828)	Acc@5 98.828 (99.512)
Max memory in training epoch: 57.9954176
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.170 (0.170)	Data 0.323 (0.323)	Loss 0.6729 (0.6729)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.132 (0.124)	Data 0.000 (0.005)	Loss 0.6902 (0.6600)	Acc@1 85.938 (86.815)	Acc@5 100.000 (99.459)
Epoch: [79][128/196]	Time 0.127 (0.124)	Data 0.000 (0.003)	Loss 0.6705 (0.6560)	Acc@1 87.891 (86.831)	Acc@5 99.609 (99.467)
Epoch: [79][192/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.7091 (0.6589)	Acc@1 86.328 (86.729)	Acc@5 98.828 (99.476)
Max memory in training epoch: 57.9954176
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.151 (0.151)	Data 0.306 (0.306)	Loss 0.5196 (0.5196)	Acc@1 94.531 (94.531)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.7168 (0.6516)	Acc@1 85.547 (87.043)	Acc@5 100.000 (99.495)
Epoch: [80][128/196]	Time 0.125 (0.124)	Data 0.000 (0.003)	Loss 0.6434 (0.6538)	Acc@1 87.891 (87.055)	Acc@5 100.000 (99.519)
Epoch: [80][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.7191 (0.6524)	Acc@1 83.984 (87.115)	Acc@5 98.828 (99.502)
Max memory in training epoch: 57.9954176
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 386408 ; 388432 ; 0.994789306751246
[INFO] Storing checkpoint...
  83.5
Max memory: 90.0135936
 24.646s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5949
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1620992
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.175 (0.175)	Data 0.283 (0.283)	Loss 0.6338 (0.6338)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.5879 (0.6098)	Acc@1 88.672 (88.317)	Acc@5 99.219 (99.579)
Epoch: [81][128/196]	Time 0.114 (0.120)	Data 0.000 (0.002)	Loss 0.5965 (0.6321)	Acc@1 89.844 (87.627)	Acc@5 99.609 (99.512)
Epoch: [81][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.6872 (0.6355)	Acc@1 85.938 (87.601)	Acc@5 98.828 (99.512)
Max memory in training epoch: 57.4158336
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.180 (0.180)	Data 0.301 (0.301)	Loss 0.6138 (0.6138)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.5656 (0.6552)	Acc@1 90.234 (87.103)	Acc@5 99.609 (99.405)
Epoch: [82][128/196]	Time 0.110 (0.120)	Data 0.000 (0.003)	Loss 0.6109 (0.6536)	Acc@1 86.719 (87.000)	Acc@5 100.000 (99.470)
Epoch: [82][192/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.6119 (0.6534)	Acc@1 87.500 (87.028)	Acc@5 100.000 (99.494)
Max memory in training epoch: 57.5469056
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.145 (0.145)	Data 0.265 (0.265)	Loss 0.5694 (0.5694)	Acc@1 91.797 (91.797)	Acc@5 98.438 (98.438)
Epoch: [83][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.6331 (0.6473)	Acc@1 87.500 (87.236)	Acc@5 99.609 (99.393)
Epoch: [83][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6643 (0.6451)	Acc@1 85.938 (87.403)	Acc@5 99.219 (99.394)
Epoch: [83][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.5903 (0.6500)	Acc@1 89.453 (87.188)	Acc@5 99.609 (99.439)
Max memory in training epoch: 57.5469056
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.145 (0.145)	Data 0.273 (0.273)	Loss 0.5265 (0.5265)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.6106 (0.6492)	Acc@1 88.281 (86.929)	Acc@5 100.000 (99.531)
Epoch: [84][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.5757 (0.6487)	Acc@1 91.016 (87.121)	Acc@5 99.219 (99.500)
Epoch: [84][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6833 (0.6537)	Acc@1 86.719 (87.039)	Acc@5 99.219 (99.482)
Max memory in training epoch: 57.5469056
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.148 (0.148)	Data 0.290 (0.290)	Loss 0.6152 (0.6152)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [85][64/196]	Time 0.138 (0.121)	Data 0.000 (0.005)	Loss 0.6350 (0.6342)	Acc@1 87.891 (87.632)	Acc@5 99.219 (99.567)
Epoch: [85][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.7076 (0.6445)	Acc@1 85.938 (87.303)	Acc@5 99.609 (99.558)
Epoch: [85][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.7153 (0.6507)	Acc@1 83.203 (86.970)	Acc@5 99.219 (99.528)
Max memory in training epoch: 57.5469056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 381790 ; 386408 ; 0.9880489016790542
[INFO] Storing checkpoint...
  79.45
Max memory: 89.609216
 23.924s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9767
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.160256
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.202 (0.202)	Data 0.261 (0.261)	Loss 0.6741 (0.6741)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [86][64/196]	Time 0.119 (0.123)	Data 0.000 (0.004)	Loss 0.5408 (0.6274)	Acc@1 91.406 (87.614)	Acc@5 100.000 (99.627)
Epoch: [86][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6649 (0.6458)	Acc@1 87.500 (87.103)	Acc@5 98.047 (99.561)
Epoch: [86][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.6197 (0.6479)	Acc@1 89.062 (87.081)	Acc@5 99.609 (99.530)
Max memory in training epoch: 57.3298176
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.166 (0.166)	Data 0.267 (0.267)	Loss 0.5873 (0.5873)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.7191 (0.6348)	Acc@1 82.422 (87.548)	Acc@5 99.609 (99.579)
Epoch: [87][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.7053 (0.6511)	Acc@1 86.328 (87.115)	Acc@5 100.000 (99.549)
Epoch: [87][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6753 (0.6471)	Acc@1 86.328 (87.205)	Acc@5 100.000 (99.545)
Max memory in training epoch: 57.4019072
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.172 (0.172)	Data 0.288 (0.288)	Loss 0.6342 (0.6342)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [88][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.6360 (0.6590)	Acc@1 88.281 (86.502)	Acc@5 100.000 (99.537)
Epoch: [88][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.5896 (0.6600)	Acc@1 89.844 (86.682)	Acc@5 99.609 (99.494)
Epoch: [88][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.7282 (0.6533)	Acc@1 83.984 (86.919)	Acc@5 98.438 (99.506)
Max memory in training epoch: 57.4019072
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.146 (0.146)	Data 0.290 (0.290)	Loss 0.6408 (0.6408)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [89][64/196]	Time 0.119 (0.125)	Data 0.000 (0.005)	Loss 0.5711 (0.6668)	Acc@1 90.625 (86.617)	Acc@5 99.219 (99.483)
Epoch: [89][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.6169 (0.6542)	Acc@1 90.234 (86.997)	Acc@5 99.219 (99.522)
Epoch: [89][192/196]	Time 0.115 (0.123)	Data 0.000 (0.002)	Loss 0.6281 (0.6508)	Acc@1 87.500 (87.099)	Acc@5 100.000 (99.516)
Max memory in training epoch: 57.4019072
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.143 (0.143)	Data 0.271 (0.271)	Loss 0.6407 (0.6407)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [90][64/196]	Time 0.120 (0.125)	Data 0.000 (0.004)	Loss 0.6066 (0.6493)	Acc@1 85.938 (86.833)	Acc@5 99.219 (99.507)
Epoch: [90][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.6188 (0.6417)	Acc@1 88.672 (87.188)	Acc@5 99.609 (99.537)
Epoch: [90][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.6621 (0.6488)	Acc@1 86.719 (86.952)	Acc@5 99.219 (99.512)
Max memory in training epoch: 57.4019072
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 379768 ; 381790 ; 0.9947038948112837
[INFO] Storing checkpoint...
  77.38
Max memory: 89.3751296
 24.302s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2876
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1594368
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.191 (0.191)	Data 0.256 (0.256)	Loss 0.6466 (0.6466)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.5988 (0.6130)	Acc@1 87.109 (88.209)	Acc@5 99.609 (99.573)
Epoch: [91][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6753 (0.6286)	Acc@1 85.938 (87.760)	Acc@5 99.219 (99.552)
Epoch: [91][192/196]	Time 0.122 (0.120)	Data 0.000 (0.001)	Loss 0.6237 (0.6357)	Acc@1 87.500 (87.453)	Acc@5 98.828 (99.547)
Max memory in training epoch: 57.1168256
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.172 (0.172)	Data 0.294 (0.294)	Loss 0.6663 (0.6663)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [92][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.5707 (0.6504)	Acc@1 90.234 (87.206)	Acc@5 99.609 (99.459)
Epoch: [92][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.7150 (0.6530)	Acc@1 85.547 (87.091)	Acc@5 99.609 (99.506)
Epoch: [92][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6252 (0.6526)	Acc@1 90.234 (87.034)	Acc@5 99.219 (99.488)
Max memory in training epoch: 56.9529856
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.173 (0.173)	Data 0.314 (0.314)	Loss 0.6579 (0.6579)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.5348 (0.5558)	Acc@1 92.578 (90.487)	Acc@5 100.000 (99.712)
Epoch: [93][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.4659 (0.5278)	Acc@1 92.188 (91.403)	Acc@5 100.000 (99.761)
Epoch: [93][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.4833 (0.5143)	Acc@1 92.188 (91.769)	Acc@5 100.000 (99.785)
Max memory in training epoch: 56.9529856
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.168 (0.168)	Data 0.268 (0.268)	Loss 0.4299 (0.4299)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.4309 (0.4698)	Acc@1 94.141 (93.305)	Acc@5 100.000 (99.766)
Epoch: [94][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.4149 (0.4621)	Acc@1 94.141 (93.474)	Acc@5 100.000 (99.812)
Epoch: [94][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.4021 (0.4586)	Acc@1 94.531 (93.521)	Acc@5 100.000 (99.840)
Max memory in training epoch: 56.9529856
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.171 (0.171)	Data 0.306 (0.306)	Loss 0.4017 (0.4017)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.4356 (0.4320)	Acc@1 94.531 (94.219)	Acc@5 100.000 (99.898)
Epoch: [95][128/196]	Time 0.126 (0.122)	Data 0.000 (0.003)	Loss 0.3502 (0.4342)	Acc@1 98.047 (94.210)	Acc@5 100.000 (99.876)
Epoch: [95][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.4354 (0.4341)	Acc@1 92.188 (94.137)	Acc@5 100.000 (99.881)
Max memory in training epoch: 56.9529856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 378614 ; 379768 ; 0.9969613026900634
[INFO] Storing checkpoint...
  91.34
Max memory: 88.676352
 24.182s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7777
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1590272
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.196 (0.196)	Data 0.263 (0.263)	Loss 0.4174 (0.4174)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.123 (0.124)	Data 0.000 (0.004)	Loss 0.3678 (0.4175)	Acc@1 97.266 (94.621)	Acc@5 100.000 (99.928)
Epoch: [96][128/196]	Time 0.131 (0.123)	Data 0.000 (0.002)	Loss 0.4196 (0.4170)	Acc@1 94.141 (94.671)	Acc@5 100.000 (99.921)
Epoch: [96][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.4045 (0.4202)	Acc@1 95.312 (94.505)	Acc@5 99.609 (99.901)
Max memory in training epoch: 57.10208
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.165 (0.165)	Data 0.289 (0.289)	Loss 0.3291 (0.3291)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.3873 (0.3982)	Acc@1 95.703 (95.114)	Acc@5 100.000 (99.898)
Epoch: [97][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.4030 (0.4035)	Acc@1 93.750 (94.883)	Acc@5 100.000 (99.891)
Epoch: [97][192/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.4511 (0.4048)	Acc@1 92.969 (94.796)	Acc@5 99.609 (99.893)
Max memory in training epoch: 56.93824
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.159 (0.159)	Data 0.299 (0.299)	Loss 0.4057 (0.4057)	Acc@1 96.094 (96.094)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.125 (0.122)	Data 0.000 (0.005)	Loss 0.3437 (0.3915)	Acc@1 97.656 (95.216)	Acc@5 100.000 (99.886)
Epoch: [98][128/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.3704 (0.3908)	Acc@1 96.875 (95.155)	Acc@5 100.000 (99.903)
Epoch: [98][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.4234 (0.3932)	Acc@1 92.188 (95.001)	Acc@5 100.000 (99.913)
Max memory in training epoch: 56.93824
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.149 (0.149)	Data 0.263 (0.263)	Loss 0.4541 (0.4541)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.3818 (0.3786)	Acc@1 95.312 (95.571)	Acc@5 100.000 (99.910)
Epoch: [99][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.4157 (0.3811)	Acc@1 93.359 (95.397)	Acc@5 100.000 (99.921)
Epoch: [99][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3881 (0.3819)	Acc@1 95.312 (95.349)	Acc@5 100.000 (99.913)
Max memory in training epoch: 56.93824
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.172 (0.172)	Data 0.284 (0.284)	Loss 0.3751 (0.3751)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.120 (0.123)	Data 0.000 (0.005)	Loss 0.3982 (0.3722)	Acc@1 95.312 (95.505)	Acc@5 100.000 (99.964)
Epoch: [100][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3566 (0.3691)	Acc@1 95.312 (95.561)	Acc@5 100.000 (99.921)
Epoch: [100][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.3212 (0.3691)	Acc@1 97.266 (95.596)	Acc@5 100.000 (99.913)
Max memory in training epoch: 56.93824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 378036 ; 378614 ; 0.9984733792199971
[INFO] Storing checkpoint...
  91.66
Max memory: 88.6546432
 24.351s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3096
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.163 (0.163)	Data 0.274 (0.274)	Loss 0.3601 (0.3601)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.131 (0.120)	Data 0.000 (0.004)	Loss 0.3699 (0.3577)	Acc@1 97.266 (95.968)	Acc@5 100.000 (99.928)
Epoch: [101][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.3325 (0.3598)	Acc@1 96.484 (95.752)	Acc@5 100.000 (99.924)
Epoch: [101][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3701 (0.3625)	Acc@1 95.703 (95.618)	Acc@5 100.000 (99.933)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.146 (0.146)	Data 0.262 (0.262)	Loss 0.3248 (0.3248)	Acc@1 98.047 (98.047)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.3240 (0.3479)	Acc@1 98.047 (96.064)	Acc@5 100.000 (99.952)
Epoch: [102][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3219 (0.3499)	Acc@1 96.875 (96.006)	Acc@5 100.000 (99.921)
Epoch: [102][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3145 (0.3511)	Acc@1 97.656 (95.910)	Acc@5 100.000 (99.927)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.146 (0.146)	Data 0.290 (0.290)	Loss 0.3462 (0.3462)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.3659 (0.3457)	Acc@1 93.359 (95.962)	Acc@5 100.000 (99.952)
Epoch: [103][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3492 (0.3459)	Acc@1 96.094 (95.948)	Acc@5 99.609 (99.961)
Epoch: [103][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3326 (0.3456)	Acc@1 96.484 (95.910)	Acc@5 100.000 (99.951)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.164 (0.164)	Data 0.265 (0.265)	Loss 0.3004 (0.3004)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.3286 (0.3340)	Acc@1 98.047 (96.238)	Acc@5 100.000 (99.964)
Epoch: [104][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3853 (0.3362)	Acc@1 95.312 (96.169)	Acc@5 100.000 (99.964)
Epoch: [104][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3505 (0.3378)	Acc@1 95.312 (96.092)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.169 (0.169)	Data 0.265 (0.265)	Loss 0.3113 (0.3113)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.3571 (0.3272)	Acc@1 95.703 (96.358)	Acc@5 99.609 (99.964)
Epoch: [105][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.3065 (0.3304)	Acc@1 96.484 (96.297)	Acc@5 100.000 (99.949)
Epoch: [105][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3530 (0.3311)	Acc@1 95.312 (96.241)	Acc@5 100.000 (99.945)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.86
Max memory: 88.6810624
 23.867s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3016
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.178 (0.178)	Data 0.287 (0.287)	Loss 0.3487 (0.3487)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.116 (0.121)	Data 0.000 (0.005)	Loss 0.3270 (0.3152)	Acc@1 95.703 (96.635)	Acc@5 100.000 (99.964)
Epoch: [106][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3712 (0.3177)	Acc@1 96.094 (96.572)	Acc@5 99.609 (99.958)
Epoch: [106][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2919 (0.3229)	Acc@1 98.047 (96.300)	Acc@5 99.609 (99.962)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.169 (0.169)	Data 0.274 (0.274)	Loss 0.2999 (0.2999)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.118 (0.121)	Data 0.000 (0.004)	Loss 0.3075 (0.3109)	Acc@1 97.266 (96.743)	Acc@5 100.000 (99.946)
Epoch: [107][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2908 (0.3134)	Acc@1 97.266 (96.681)	Acc@5 100.000 (99.955)
Epoch: [107][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.3228 (0.3183)	Acc@1 96.875 (96.482)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.170 (0.170)	Data 0.301 (0.301)	Loss 0.2965 (0.2965)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.3377 (0.3172)	Acc@1 95.312 (96.400)	Acc@5 99.609 (99.970)
Epoch: [108][128/196]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.3227 (0.3120)	Acc@1 96.094 (96.584)	Acc@5 100.000 (99.961)
Epoch: [108][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3388 (0.3134)	Acc@1 96.094 (96.484)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.141 (0.141)	Data 0.297 (0.297)	Loss 0.3309 (0.3309)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.130 (0.120)	Data 0.000 (0.005)	Loss 0.3374 (0.3085)	Acc@1 95.312 (96.520)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.3553 (0.3061)	Acc@1 94.141 (96.633)	Acc@5 99.609 (99.964)
Epoch: [109][192/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.3360 (0.3081)	Acc@1 94.922 (96.533)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.154 (0.154)	Data 0.292 (0.292)	Loss 0.2819 (0.2819)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.3322 (0.3003)	Acc@1 95.312 (96.725)	Acc@5 100.000 (99.982)
Epoch: [110][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3139 (0.3030)	Acc@1 95.703 (96.627)	Acc@5 100.000 (99.976)
Epoch: [110][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2949 (0.3050)	Acc@1 97.656 (96.519)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.22
Max memory: 88.6810624
 23.857s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6032
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.195 (0.195)	Data 0.287 (0.287)	Loss 0.3070 (0.3070)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [111][64/196]	Time 0.119 (0.123)	Data 0.000 (0.005)	Loss 0.3081 (0.2968)	Acc@1 96.094 (96.767)	Acc@5 100.000 (99.970)
Epoch: [111][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2913 (0.2998)	Acc@1 96.484 (96.609)	Acc@5 100.000 (99.958)
Epoch: [111][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2982 (0.3032)	Acc@1 96.875 (96.486)	Acc@5 100.000 (99.970)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.167 (0.167)	Data 0.291 (0.291)	Loss 0.2825 (0.2825)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.126 (0.121)	Data 0.000 (0.005)	Loss 0.2891 (0.2956)	Acc@1 98.438 (96.791)	Acc@5 100.000 (99.970)
Epoch: [112][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2858 (0.2989)	Acc@1 95.703 (96.596)	Acc@5 100.000 (99.979)
Epoch: [112][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.3254 (0.2999)	Acc@1 96.094 (96.565)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.147 (0.147)	Data 0.304 (0.304)	Loss 0.2934 (0.2934)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.2490 (0.2860)	Acc@1 97.656 (96.905)	Acc@5 100.000 (99.964)
Epoch: [113][128/196]	Time 0.122 (0.123)	Data 0.000 (0.003)	Loss 0.3305 (0.2916)	Acc@1 94.922 (96.754)	Acc@5 100.000 (99.970)
Epoch: [113][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.3592 (0.2970)	Acc@1 94.531 (96.549)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.177 (0.177)	Data 0.303 (0.303)	Loss 0.3299 (0.3299)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.126 (0.124)	Data 0.000 (0.005)	Loss 0.2919 (0.2881)	Acc@1 96.484 (96.791)	Acc@5 100.000 (99.952)
Epoch: [114][128/196]	Time 0.114 (0.123)	Data 0.000 (0.003)	Loss 0.2816 (0.2921)	Acc@1 96.094 (96.657)	Acc@5 100.000 (99.958)
Epoch: [114][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.2982 (0.2923)	Acc@1 95.703 (96.665)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.158 (0.158)	Data 0.280 (0.280)	Loss 0.2885 (0.2885)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.3216 (0.2858)	Acc@1 96.875 (96.893)	Acc@5 99.609 (99.982)
Epoch: [115][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.3475 (0.2884)	Acc@1 93.750 (96.711)	Acc@5 99.609 (99.976)
Epoch: [115][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.2909 (0.2932)	Acc@1 97.266 (96.470)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.51
Max memory: 88.6810624
 24.330s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 660
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.181 (0.181)	Data 0.291 (0.291)	Loss 0.2585 (0.2585)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.2479 (0.2812)	Acc@1 97.656 (97.025)	Acc@5 100.000 (99.958)
Epoch: [116][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2699 (0.2845)	Acc@1 96.875 (96.824)	Acc@5 100.000 (99.964)
Epoch: [116][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2866 (0.2881)	Acc@1 98.828 (96.717)	Acc@5 100.000 (99.962)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.156 (0.156)	Data 0.288 (0.288)	Loss 0.2580 (0.2580)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.3138 (0.2795)	Acc@1 95.312 (96.953)	Acc@5 99.609 (99.952)
Epoch: [117][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3083 (0.2844)	Acc@1 95.703 (96.663)	Acc@5 100.000 (99.961)
Epoch: [117][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3240 (0.2881)	Acc@1 95.312 (96.503)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.140 (0.140)	Data 0.275 (0.275)	Loss 0.2801 (0.2801)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.116 (0.120)	Data 0.000 (0.004)	Loss 0.2958 (0.2800)	Acc@1 95.312 (96.833)	Acc@5 100.000 (99.994)
Epoch: [118][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3171 (0.2857)	Acc@1 94.531 (96.639)	Acc@5 100.000 (99.976)
Epoch: [118][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2781 (0.2864)	Acc@1 97.266 (96.594)	Acc@5 100.000 (99.980)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.161 (0.161)	Data 0.263 (0.263)	Loss 0.2902 (0.2902)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.2654 (0.2863)	Acc@1 96.875 (96.532)	Acc@5 100.000 (99.964)
Epoch: [119][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.2605 (0.2853)	Acc@1 98.047 (96.575)	Acc@5 100.000 (99.967)
Epoch: [119][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2875 (0.2868)	Acc@1 96.484 (96.490)	Acc@5 99.609 (99.966)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.145 (0.145)	Data 0.291 (0.291)	Loss 0.3045 (0.3045)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.2930 (0.2881)	Acc@1 95.703 (96.502)	Acc@5 100.000 (99.982)
Epoch: [120][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.3041 (0.2861)	Acc@1 96.484 (96.515)	Acc@5 100.000 (99.976)
Epoch: [120][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2721 (0.2852)	Acc@1 97.656 (96.490)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.12
Max memory: 88.6810624
 24.088s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1578
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.184 (0.184)	Data 0.272 (0.272)	Loss 0.2590 (0.2590)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2466 (0.2710)	Acc@1 97.656 (96.989)	Acc@5 100.000 (99.946)
Epoch: [121][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2522 (0.2763)	Acc@1 97.266 (96.814)	Acc@5 99.609 (99.964)
Epoch: [121][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3075 (0.2816)	Acc@1 94.922 (96.537)	Acc@5 99.609 (99.968)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.175 (0.175)	Data 0.268 (0.268)	Loss 0.2896 (0.2896)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.117 (0.123)	Data 0.000 (0.004)	Loss 0.2722 (0.2739)	Acc@1 97.266 (96.809)	Acc@5 100.000 (99.976)
Epoch: [122][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.3011 (0.2768)	Acc@1 94.922 (96.690)	Acc@5 100.000 (99.976)
Epoch: [122][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3273 (0.2803)	Acc@1 96.094 (96.527)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.167 (0.167)	Data 0.264 (0.264)	Loss 0.3178 (0.3178)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [123][64/196]	Time 0.114 (0.122)	Data 0.000 (0.004)	Loss 0.2824 (0.2890)	Acc@1 96.094 (96.208)	Acc@5 100.000 (99.988)
Epoch: [123][128/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.2425 (0.2828)	Acc@1 98.828 (96.427)	Acc@5 100.000 (99.970)
Epoch: [123][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2650 (0.2854)	Acc@1 96.484 (96.329)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.143 (0.143)	Data 0.299 (0.299)	Loss 0.2769 (0.2769)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2712 (0.2779)	Acc@1 97.266 (96.550)	Acc@5 99.609 (99.970)
Epoch: [124][128/196]	Time 0.122 (0.121)	Data 0.000 (0.003)	Loss 0.2677 (0.2787)	Acc@1 96.484 (96.518)	Acc@5 100.000 (99.970)
Epoch: [124][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2660 (0.2820)	Acc@1 97.656 (96.409)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.173 (0.173)	Data 0.277 (0.277)	Loss 0.2764 (0.2764)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2453 (0.2740)	Acc@1 97.266 (96.641)	Acc@5 100.000 (99.976)
Epoch: [125][128/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.3033 (0.2765)	Acc@1 96.875 (96.563)	Acc@5 100.000 (99.973)
Epoch: [125][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2875 (0.2826)	Acc@1 94.531 (96.250)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.39
Max memory: 88.6196224
 24.180s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6601
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.189 (0.189)	Data 0.261 (0.261)	Loss 0.3177 (0.3177)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.3648 (0.2723)	Acc@1 92.969 (96.581)	Acc@5 100.000 (99.988)
Epoch: [126][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2562 (0.2787)	Acc@1 98.828 (96.412)	Acc@5 100.000 (99.976)
Epoch: [126][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2693 (0.2801)	Acc@1 97.266 (96.320)	Acc@5 100.000 (99.972)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.149 (0.149)	Data 0.269 (0.269)	Loss 0.2847 (0.2847)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.128 (0.122)	Data 0.000 (0.004)	Loss 0.2518 (0.2652)	Acc@1 98.047 (96.893)	Acc@5 100.000 (99.994)
Epoch: [127][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3074 (0.2729)	Acc@1 95.703 (96.593)	Acc@5 100.000 (99.985)
Epoch: [127][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.3033 (0.2784)	Acc@1 96.484 (96.412)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.177 (0.177)	Data 0.299 (0.299)	Loss 0.2343 (0.2343)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.2709 (0.2730)	Acc@1 96.875 (96.581)	Acc@5 100.000 (99.970)
Epoch: [128][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2875 (0.2768)	Acc@1 95.703 (96.348)	Acc@5 100.000 (99.976)
Epoch: [128][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.2586 (0.2806)	Acc@1 96.875 (96.140)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.160 (0.160)	Data 0.320 (0.320)	Loss 0.2969 (0.2969)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.3022 (0.2705)	Acc@1 94.922 (96.791)	Acc@5 100.000 (99.982)
Epoch: [129][128/196]	Time 0.122 (0.121)	Data 0.000 (0.003)	Loss 0.2865 (0.2752)	Acc@1 94.531 (96.518)	Acc@5 100.000 (99.970)
Epoch: [129][192/196]	Time 0.134 (0.121)	Data 0.000 (0.002)	Loss 0.3266 (0.2792)	Acc@1 96.094 (96.353)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.181 (0.181)	Data 0.273 (0.273)	Loss 0.2831 (0.2831)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.116 (0.123)	Data 0.000 (0.004)	Loss 0.2310 (0.2779)	Acc@1 98.438 (96.382)	Acc@5 100.000 (99.964)
Epoch: [130][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.3398 (0.2856)	Acc@1 94.531 (96.091)	Acc@5 100.000 (99.970)
Epoch: [130][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3243 (0.2892)	Acc@1 94.141 (96.025)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.77
Max memory: 88.7138304
 24.313s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1315
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1588224
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.195 (0.195)	Data 0.288 (0.288)	Loss 0.2503 (0.2503)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.115 (0.125)	Data 0.000 (0.005)	Loss 0.2685 (0.2699)	Acc@1 96.094 (96.653)	Acc@5 100.000 (99.988)
Epoch: [131][128/196]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.2893 (0.2740)	Acc@1 96.875 (96.503)	Acc@5 100.000 (99.958)
Epoch: [131][192/196]	Time 0.129 (0.123)	Data 0.000 (0.002)	Loss 0.2820 (0.2784)	Acc@1 95.312 (96.318)	Acc@5 100.000 (99.966)
Max memory in training epoch: 57.1012608
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.161 (0.161)	Data 0.291 (0.291)	Loss 0.2381 (0.2381)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.2334 (0.2718)	Acc@1 98.438 (96.556)	Acc@5 100.000 (99.994)
Epoch: [132][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.2945 (0.2768)	Acc@1 96.094 (96.397)	Acc@5 100.000 (99.979)
Epoch: [132][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.2545 (0.2794)	Acc@1 98.047 (96.308)	Acc@5 100.000 (99.980)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.180 (0.180)	Data 0.255 (0.255)	Loss 0.2174 (0.2174)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.113 (0.126)	Data 0.000 (0.004)	Loss 0.2271 (0.2765)	Acc@1 98.828 (96.352)	Acc@5 100.000 (99.970)
Epoch: [133][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.2700 (0.2767)	Acc@1 96.875 (96.324)	Acc@5 100.000 (99.961)
Epoch: [133][192/196]	Time 0.122 (0.124)	Data 0.000 (0.001)	Loss 0.3499 (0.2805)	Acc@1 92.969 (96.165)	Acc@5 99.609 (99.970)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.159 (0.159)	Data 0.322 (0.322)	Loss 0.2762 (0.2762)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.129 (0.124)	Data 0.000 (0.005)	Loss 0.2275 (0.2785)	Acc@1 98.438 (96.340)	Acc@5 100.000 (99.964)
Epoch: [134][128/196]	Time 0.121 (0.124)	Data 0.000 (0.003)	Loss 0.2697 (0.2765)	Acc@1 96.875 (96.348)	Acc@5 100.000 (99.973)
Epoch: [134][192/196]	Time 0.128 (0.124)	Data 0.000 (0.002)	Loss 0.2524 (0.2789)	Acc@1 96.484 (96.246)	Acc@5 100.000 (99.978)
Max memory in training epoch: 56.91776
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.173 (0.173)	Data 0.287 (0.287)	Loss 0.2265 (0.2265)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.130 (0.126)	Data 0.000 (0.005)	Loss 0.2784 (0.2758)	Acc@1 97.266 (96.304)	Acc@5 100.000 (99.976)
Epoch: [135][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.3110 (0.2779)	Acc@1 95.312 (96.248)	Acc@5 100.000 (99.982)
Epoch: [135][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.2765 (0.2789)	Acc@1 95.703 (96.197)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.91776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 377458 ; 378036 ; 0.9984710450856532
[INFO] Storing checkpoint...
  90.49
Max memory: 88.6810624
 24.729s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5842
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.1586176
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.168 (0.168)	Data 0.289 (0.289)	Loss 0.2547 (0.2547)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.121 (0.121)	Data 0.000 (0.005)	Loss 0.2425 (0.2560)	Acc@1 98.047 (97.115)	Acc@5 100.000 (99.994)
Epoch: [136][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2811 (0.2683)	Acc@1 96.484 (96.699)	Acc@5 100.000 (99.982)
Epoch: [136][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2767 (0.2717)	Acc@1 96.875 (96.535)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.1004416
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.151 (0.151)	Data 0.287 (0.287)	Loss 0.2564 (0.2564)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.2585 (0.2754)	Acc@1 96.875 (96.328)	Acc@5 100.000 (99.994)
Epoch: [137][128/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.3004 (0.2774)	Acc@1 95.312 (96.257)	Acc@5 100.000 (99.973)
Epoch: [137][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2676 (0.2785)	Acc@1 96.875 (96.201)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.173 (0.173)	Data 0.256 (0.256)	Loss 0.2243 (0.2243)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2779 (0.2731)	Acc@1 95.312 (96.412)	Acc@5 100.000 (99.994)
Epoch: [138][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.2863 (0.2783)	Acc@1 94.922 (96.188)	Acc@5 100.000 (99.985)
Epoch: [138][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2668 (0.2807)	Acc@1 96.094 (96.088)	Acc@5 100.000 (99.984)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.150 (0.150)	Data 0.304 (0.304)	Loss 0.2849 (0.2849)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.131 (0.121)	Data 0.000 (0.005)	Loss 0.2903 (0.2859)	Acc@1 95.703 (95.925)	Acc@5 100.000 (99.970)
Epoch: [139][128/196]	Time 0.126 (0.122)	Data 0.000 (0.003)	Loss 0.2890 (0.2827)	Acc@1 95.703 (96.003)	Acc@5 100.000 (99.967)
Epoch: [139][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3508 (0.2850)	Acc@1 94.141 (95.991)	Acc@5 99.609 (99.972)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.159 (0.159)	Data 0.301 (0.301)	Loss 0.3014 (0.3014)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.2812 (0.2795)	Acc@1 95.312 (96.142)	Acc@5 100.000 (99.976)
Epoch: [140][128/196]	Time 0.124 (0.122)	Data 0.000 (0.003)	Loss 0.2588 (0.2804)	Acc@1 97.266 (96.109)	Acc@5 100.000 (99.976)
Epoch: [140][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3012 (0.2794)	Acc@1 95.703 (96.150)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.64
Max memory: 88.680448
 24.341s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6978
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.1586176
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.188 (0.188)	Data 0.267 (0.267)	Loss 0.2402 (0.2402)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.2787 (0.2510)	Acc@1 96.875 (97.326)	Acc@5 100.000 (99.976)
Epoch: [141][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2757 (0.2637)	Acc@1 95.703 (96.845)	Acc@5 100.000 (99.976)
Epoch: [141][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3022 (0.2691)	Acc@1 94.922 (96.604)	Acc@5 100.000 (99.974)
Max memory in training epoch: 57.1004416
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.173 (0.173)	Data 0.263 (0.263)	Loss 0.2702 (0.2702)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.3166 (0.2695)	Acc@1 95.312 (96.520)	Acc@5 100.000 (99.964)
Epoch: [142][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2800 (0.2757)	Acc@1 96.094 (96.300)	Acc@5 100.000 (99.970)
Epoch: [142][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3153 (0.2781)	Acc@1 94.141 (96.179)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.168 (0.168)	Data 0.278 (0.278)	Loss 0.2705 (0.2705)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.123 (0.121)	Data 0.000 (0.004)	Loss 0.2421 (0.2659)	Acc@1 97.656 (96.653)	Acc@5 100.000 (99.988)
Epoch: [143][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.2831 (0.2705)	Acc@1 95.703 (96.515)	Acc@5 100.000 (99.973)
Epoch: [143][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.2705 (0.2763)	Acc@1 96.484 (96.286)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.144 (0.144)	Data 0.307 (0.307)	Loss 0.3120 (0.3120)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2871 (0.2698)	Acc@1 95.312 (96.322)	Acc@5 100.000 (99.976)
Epoch: [144][128/196]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.2464 (0.2711)	Acc@1 97.266 (96.387)	Acc@5 100.000 (99.976)
Epoch: [144][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2554 (0.2765)	Acc@1 97.266 (96.154)	Acc@5 100.000 (99.978)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.146 (0.146)	Data 0.270 (0.270)	Loss 0.2531 (0.2531)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.3762 (0.2778)	Acc@1 92.188 (96.334)	Acc@5 100.000 (99.976)
Epoch: [145][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2289 (0.2798)	Acc@1 98.438 (96.218)	Acc@5 100.000 (99.976)
Epoch: [145][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3175 (0.2808)	Acc@1 95.312 (96.146)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.22
Max memory: 88.680448
 24.146s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8550
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1586176
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.192 (0.192)	Data 0.263 (0.263)	Loss 0.2914 (0.2914)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.125 (0.123)	Data 0.000 (0.004)	Loss 0.2677 (0.2652)	Acc@1 98.047 (96.611)	Acc@5 100.000 (99.970)
Epoch: [146][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2768 (0.2736)	Acc@1 95.703 (96.348)	Acc@5 100.000 (99.976)
Epoch: [146][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.2351 (0.2767)	Acc@1 98.047 (96.221)	Acc@5 100.000 (99.976)
Max memory in training epoch: 57.1004416
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.150 (0.150)	Data 0.298 (0.298)	Loss 0.3077 (0.3077)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.122 (0.123)	Data 0.000 (0.005)	Loss 0.2472 (0.2704)	Acc@1 96.875 (96.364)	Acc@5 100.000 (99.970)
Epoch: [147][128/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.2991 (0.2703)	Acc@1 96.094 (96.463)	Acc@5 100.000 (99.973)
Epoch: [147][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.3287 (0.2763)	Acc@1 93.359 (96.223)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.149 (0.149)	Data 0.292 (0.292)	Loss 0.2594 (0.2594)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.116 (0.122)	Data 0.000 (0.005)	Loss 0.2956 (0.2781)	Acc@1 93.750 (95.931)	Acc@5 100.000 (99.970)
Epoch: [148][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3239 (0.2734)	Acc@1 94.141 (96.254)	Acc@5 100.000 (99.973)
Epoch: [148][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.3169 (0.2786)	Acc@1 95.312 (96.100)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.2670 (0.2670)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.3139 (0.2804)	Acc@1 94.922 (96.196)	Acc@5 100.000 (99.946)
Epoch: [149][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.2561 (0.2830)	Acc@1 96.094 (96.006)	Acc@5 100.000 (99.961)
Epoch: [149][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.2329 (0.2836)	Acc@1 98.047 (95.972)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.864512
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.176 (0.176)	Data 0.267 (0.267)	Loss 0.2578 (0.2578)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.125 (0.125)	Data 0.000 (0.004)	Loss 0.2161 (0.2487)	Acc@1 98.047 (97.188)	Acc@5 100.000 (99.988)
Epoch: [150][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.2203 (0.2419)	Acc@1 98.438 (97.526)	Acc@5 100.000 (99.988)
Epoch: [150][192/196]	Time 0.124 (0.124)	Data 0.000 (0.002)	Loss 0.2051 (0.2357)	Acc@1 99.219 (97.776)	Acc@5 100.000 (99.988)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.18
Max memory: 88.619008
 24.707s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4663
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1586176
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.180 (0.180)	Data 0.259 (0.259)	Loss 0.2307 (0.2307)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.125 (0.122)	Data 0.000 (0.004)	Loss 0.2133 (0.2217)	Acc@1 98.438 (98.137)	Acc@5 100.000 (99.982)
Epoch: [151][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1950 (0.2187)	Acc@1 99.609 (98.341)	Acc@5 100.000 (99.991)
Epoch: [151][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2100 (0.2189)	Acc@1 98.047 (98.373)	Acc@5 100.000 (99.990)
Max memory in training epoch: 57.1004416
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.167 (0.167)	Data 0.288 (0.288)	Loss 0.2179 (0.2179)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.125 (0.120)	Data 0.000 (0.005)	Loss 0.2124 (0.2126)	Acc@1 98.047 (98.732)	Acc@5 100.000 (99.988)
Epoch: [152][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2148 (0.2115)	Acc@1 98.047 (98.725)	Acc@5 100.000 (99.994)
Epoch: [152][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2433 (0.2117)	Acc@1 97.266 (98.719)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.145 (0.145)	Data 0.306 (0.306)	Loss 0.2333 (0.2333)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.2122 (0.2061)	Acc@1 98.828 (98.948)	Acc@5 100.000 (100.000)
Epoch: [153][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.2071 (0.2059)	Acc@1 99.219 (98.946)	Acc@5 100.000 (100.000)
Epoch: [153][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.2113 (0.2064)	Acc@1 99.609 (98.917)	Acc@5 100.000 (99.994)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.159 (0.159)	Data 0.266 (0.266)	Loss 0.1984 (0.1984)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.1816 (0.2024)	Acc@1 100.000 (98.948)	Acc@5 100.000 (99.994)
Epoch: [154][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2089 (0.2035)	Acc@1 98.438 (98.925)	Acc@5 100.000 (99.994)
Epoch: [154][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2105 (0.2044)	Acc@1 98.438 (98.899)	Acc@5 100.000 (99.992)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.146 (0.146)	Data 0.295 (0.295)	Loss 0.2026 (0.2026)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.2193 (0.2023)	Acc@1 98.047 (99.008)	Acc@5 100.000 (99.994)
Epoch: [155][128/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.1929 (0.2009)	Acc@1 99.609 (99.058)	Acc@5 100.000 (99.997)
Epoch: [155][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1843 (0.2000)	Acc@1 100.000 (99.099)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.46
Max memory: 88.713216
 24.174s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6653
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1586176
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.199 (0.199)	Data 0.281 (0.281)	Loss 0.1954 (0.1954)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.1876 (0.1983)	Acc@1 99.609 (99.141)	Acc@5 100.000 (99.994)
Epoch: [156][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.1987 (0.1975)	Acc@1 98.828 (99.149)	Acc@5 100.000 (99.997)
Epoch: [156][192/196]	Time 0.128 (0.122)	Data 0.000 (0.002)	Loss 0.1871 (0.1974)	Acc@1 99.609 (99.160)	Acc@5 100.000 (99.996)
Max memory in training epoch: 57.1004416
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.167 (0.167)	Data 0.266 (0.266)	Loss 0.1886 (0.1886)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.127 (0.122)	Data 0.000 (0.004)	Loss 0.1938 (0.1988)	Acc@1 99.609 (99.123)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1955 (0.1983)	Acc@1 98.828 (99.098)	Acc@5 100.000 (100.000)
Epoch: [157][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.1911 (0.1973)	Acc@1 99.219 (99.130)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.138 (0.138)	Data 0.297 (0.297)	Loss 0.1933 (0.1933)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.128 (0.122)	Data 0.000 (0.005)	Loss 0.1895 (0.1953)	Acc@1 99.219 (99.165)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.1959 (0.1949)	Acc@1 99.219 (99.170)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.134 (0.121)	Data 0.000 (0.002)	Loss 0.1917 (0.1952)	Acc@1 99.609 (99.162)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.142 (0.142)	Data 0.330 (0.330)	Loss 0.1935 (0.1935)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.115 (0.122)	Data 0.000 (0.005)	Loss 0.1886 (0.1925)	Acc@1 99.609 (99.279)	Acc@5 100.000 (99.994)
Epoch: [159][128/196]	Time 0.118 (0.122)	Data 0.000 (0.003)	Loss 0.1971 (0.1927)	Acc@1 99.219 (99.285)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1873 (0.1933)	Acc@1 99.609 (99.245)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.168 (0.168)	Data 0.296 (0.296)	Loss 0.1821 (0.1821)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.1893 (0.1898)	Acc@1 100.000 (99.345)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1870 (0.1896)	Acc@1 99.219 (99.358)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1947 (0.1903)	Acc@1 98.828 (99.346)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.68
Max memory: 88.680448
 24.323s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1116
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1586176
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.184 (0.184)	Data 0.284 (0.284)	Loss 0.1770 (0.1770)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.1782 (0.1898)	Acc@1 99.609 (99.345)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1974 (0.1899)	Acc@1 99.219 (99.282)	Acc@5 100.000 (100.000)
Epoch: [161][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2184 (0.1895)	Acc@1 98.438 (99.334)	Acc@5 100.000 (99.998)
Max memory in training epoch: 57.1004416
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.161 (0.161)	Data 0.302 (0.302)	Loss 0.1801 (0.1801)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.144 (0.120)	Data 0.000 (0.005)	Loss 0.1847 (0.1887)	Acc@1 99.609 (99.411)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.121 (0.120)	Data 0.000 (0.003)	Loss 0.1866 (0.1885)	Acc@1 99.609 (99.385)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1882 (0.1883)	Acc@1 99.219 (99.381)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.171 (0.171)	Data 0.260 (0.260)	Loss 0.1958 (0.1958)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.1821 (0.1863)	Acc@1 100.000 (99.489)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1803 (0.1868)	Acc@1 100.000 (99.437)	Acc@5 100.000 (100.000)
Epoch: [163][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1854 (0.1867)	Acc@1 99.609 (99.409)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.157 (0.157)	Data 0.301 (0.301)	Loss 0.1735 (0.1735)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.1772 (0.1851)	Acc@1 99.609 (99.465)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.114 (0.119)	Data 0.000 (0.003)	Loss 0.1780 (0.1855)	Acc@1 99.219 (99.464)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.1988 (0.1857)	Acc@1 98.047 (99.429)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.150 (0.150)	Data 0.297 (0.297)	Loss 0.1747 (0.1747)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.1789 (0.1845)	Acc@1 100.000 (99.483)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.1806 (0.1852)	Acc@1 99.609 (99.443)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1864 (0.1850)	Acc@1 98.828 (99.449)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.87
Max memory: 88.680448
 23.929s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 176
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1586176
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.179 (0.179)	Data 0.259 (0.259)	Loss 0.1899 (0.1899)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.118 (0.123)	Data 0.000 (0.004)	Loss 0.1768 (0.1824)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.1847 (0.1831)	Acc@1 98.828 (99.497)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1754 (0.1827)	Acc@1 99.609 (99.512)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.1004416
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.173 (0.173)	Data 0.286 (0.286)	Loss 0.1874 (0.1874)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.1818 (0.1833)	Acc@1 99.219 (99.507)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1880 (0.1820)	Acc@1 99.219 (99.531)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1708 (0.1819)	Acc@1 100.000 (99.539)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.167 (0.167)	Data 0.306 (0.306)	Loss 0.1815 (0.1815)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.1906 (0.1804)	Acc@1 99.609 (99.579)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.119 (0.123)	Data 0.000 (0.003)	Loss 0.1768 (0.1811)	Acc@1 100.000 (99.555)	Acc@5 100.000 (100.000)
Epoch: [168][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1970 (0.1815)	Acc@1 99.219 (99.537)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.139 (0.139)	Data 0.290 (0.290)	Loss 0.1715 (0.1715)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.1671 (0.1803)	Acc@1 100.000 (99.555)	Acc@5 100.000 (99.988)
Epoch: [169][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1796 (0.1799)	Acc@1 99.609 (99.561)	Acc@5 100.000 (99.994)
Epoch: [169][192/196]	Time 0.124 (0.122)	Data 0.000 (0.002)	Loss 0.1723 (0.1797)	Acc@1 100.000 (99.565)	Acc@5 100.000 (99.996)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.169 (0.169)	Data 0.276 (0.276)	Loss 0.1716 (0.1716)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.1704 (0.1805)	Acc@1 100.000 (99.513)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.112 (0.123)	Data 0.000 (0.002)	Loss 0.1896 (0.1812)	Acc@1 98.828 (99.449)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1747 (0.1809)	Acc@1 100.000 (99.464)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.63
Max memory: 88.619008
 24.361s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8972
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1586176
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.177 (0.177)	Data 0.290 (0.290)	Loss 0.1829 (0.1829)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.114 (0.122)	Data 0.000 (0.005)	Loss 0.1871 (0.1786)	Acc@1 99.219 (99.567)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1776 (0.1793)	Acc@1 99.609 (99.516)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1776 (0.1791)	Acc@1 100.000 (99.530)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.1004416
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.155 (0.155)	Data 0.303 (0.303)	Loss 0.1726 (0.1726)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.1669 (0.1790)	Acc@1 100.000 (99.543)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.121 (0.121)	Data 0.000 (0.003)	Loss 0.1706 (0.1783)	Acc@1 99.609 (99.567)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.113 (0.121)	Data 0.000 (0.002)	Loss 0.1707 (0.1781)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.158 (0.158)	Data 0.300 (0.300)	Loss 0.1713 (0.1713)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.1721 (0.1754)	Acc@1 100.000 (99.700)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2078 (0.1762)	Acc@1 98.828 (99.661)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.1748 (0.1771)	Acc@1 99.219 (99.591)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.155 (0.155)	Data 0.304 (0.304)	Loss 0.1681 (0.1681)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.1727 (0.1771)	Acc@1 99.609 (99.567)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.1779 (0.1768)	Acc@1 99.219 (99.576)	Acc@5 100.000 (100.000)
Epoch: [174][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1919 (0.1770)	Acc@1 99.219 (99.563)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.151 (0.151)	Data 0.288 (0.288)	Loss 0.1682 (0.1682)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.1901 (0.1762)	Acc@1 98.438 (99.555)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.1696 (0.1761)	Acc@1 99.609 (99.552)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.1900 (0.1764)	Acc@1 99.219 (99.563)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.88
Max memory: 88.680448
 24.372s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5727
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1586176
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.190 (0.190)	Data 0.283 (0.283)	Loss 0.1701 (0.1701)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.1659 (0.1737)	Acc@1 100.000 (99.669)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.1787 (0.1749)	Acc@1 98.828 (99.625)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1788 (0.1747)	Acc@1 99.219 (99.619)	Acc@5 100.000 (100.000)
Max memory in training epoch: 57.1004416
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.169 (0.169)	Data 0.288 (0.288)	Loss 0.1708 (0.1708)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.114 (0.120)	Data 0.000 (0.005)	Loss 0.1703 (0.1739)	Acc@1 99.609 (99.627)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.141 (0.120)	Data 0.000 (0.002)	Loss 0.1681 (0.1741)	Acc@1 100.000 (99.625)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1815 (0.1740)	Acc@1 99.609 (99.630)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.158 (0.158)	Data 0.314 (0.314)	Loss 0.1788 (0.1788)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.1795 (0.1733)	Acc@1 99.609 (99.633)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.117 (0.120)	Data 0.000 (0.003)	Loss 0.1745 (0.1729)	Acc@1 99.609 (99.658)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1688 (0.1727)	Acc@1 100.000 (99.654)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.155 (0.155)	Data 0.260 (0.260)	Loss 0.1693 (0.1693)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.1653 (0.1723)	Acc@1 100.000 (99.675)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1764 (0.1724)	Acc@1 99.609 (99.658)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1785 (0.1725)	Acc@1 98.828 (99.650)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.864512
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.167 (0.167)	Data 0.280 (0.280)	Loss 0.1607 (0.1607)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.123 (0.121)	Data 0.000 (0.004)	Loss 0.1765 (0.1711)	Acc@1 99.219 (99.645)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.1773 (0.1714)	Acc@1 98.828 (99.658)	Acc@5 100.000 (99.997)
Epoch: [180][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1671 (0.1716)	Acc@1 100.000 (99.652)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.864512
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(25, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(14, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(59, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(11, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.66
Max memory: 88.680448
 23.961s  Thres 0.0001 3
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1563
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.204 (0.204)	Data 0.273 (0.273)	Loss 3.4472 (3.4472)	Acc@1 6.641 (6.641)	Acc@5 44.922 (44.922)
Epoch: [1][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 2.3843 (2.6704)	Acc@1 34.766 (26.520)	Acc@5 88.281 (79.020)
Epoch: [1][128/196]	Time 0.124 (0.128)	Data 0.000 (0.002)	Loss 2.0727 (2.4712)	Acc@1 46.875 (33.236)	Acc@5 94.922 (84.336)
Epoch: [1][192/196]	Time 0.130 (0.128)	Data 0.000 (0.002)	Loss 1.9125 (2.3286)	Acc@1 52.734 (37.913)	Acc@5 95.703 (87.182)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.179 (0.179)	Data 0.283 (0.283)	Loss 1.9104 (1.9104)	Acc@1 52.734 (52.734)	Acc@5 91.797 (91.797)
Epoch: [2][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 1.8655 (1.8777)	Acc@1 50.000 (53.636)	Acc@5 96.875 (94.069)
Epoch: [2][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 1.7048 (1.8138)	Acc@1 59.375 (55.699)	Acc@5 95.703 (94.834)
Epoch: [2][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 1.5646 (1.7553)	Acc@1 62.500 (57.367)	Acc@5 95.703 (95.270)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.182 (0.182)	Data 0.246 (0.246)	Loss 1.5065 (1.5065)	Acc@1 66.406 (66.406)	Acc@5 96.875 (96.875)
Epoch: [3][64/196]	Time 0.130 (0.130)	Data 0.000 (0.004)	Loss 1.4748 (1.5153)	Acc@1 67.969 (65.469)	Acc@5 96.875 (96.821)
Epoch: [3][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 1.4610 (1.4789)	Acc@1 69.531 (66.409)	Acc@5 96.875 (97.069)
Epoch: [3][192/196]	Time 0.127 (0.128)	Data 0.000 (0.001)	Loss 1.2785 (1.4475)	Acc@1 71.875 (67.155)	Acc@5 98.047 (97.227)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.169 (0.169)	Data 0.286 (0.286)	Loss 1.3327 (1.3327)	Acc@1 69.922 (69.922)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.123 (0.129)	Data 0.000 (0.005)	Loss 1.2081 (1.3082)	Acc@1 73.438 (71.514)	Acc@5 98.828 (97.686)
Epoch: [4][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 1.1694 (1.2718)	Acc@1 74.609 (72.211)	Acc@5 98.828 (97.929)
Epoch: [4][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 1.2222 (1.2470)	Acc@1 70.312 (72.729)	Acc@5 98.828 (97.990)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.179 (0.179)	Data 0.246 (0.246)	Loss 1.1732 (1.1732)	Acc@1 75.781 (75.781)	Acc@5 97.656 (97.656)
Epoch: [5][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 1.1191 (1.1469)	Acc@1 75.781 (75.024)	Acc@5 98.828 (98.546)
Epoch: [5][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.0438 (1.1310)	Acc@1 76.953 (75.375)	Acc@5 98.438 (98.495)
Epoch: [5][192/196]	Time 0.132 (0.130)	Data 0.000 (0.001)	Loss 1.1623 (1.1216)	Acc@1 74.219 (75.553)	Acc@5 97.266 (98.494)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  71.2
Max memory: 103.3835008
 25.890s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8385
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.204 (0.204)	Data 0.284 (0.284)	Loss 0.9204 (0.9204)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [6][64/196]	Time 0.128 (0.129)	Data 0.000 (0.005)	Loss 1.0550 (1.0296)	Acc@1 76.562 (78.317)	Acc@5 98.047 (98.612)
Epoch: [6][128/196]	Time 0.132 (0.129)	Data 0.000 (0.002)	Loss 1.0605 (1.0268)	Acc@1 77.344 (78.170)	Acc@5 98.047 (98.628)
Epoch: [6][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 1.1660 (1.0260)	Acc@1 69.922 (77.842)	Acc@5 98.828 (98.703)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.192 (0.192)	Data 0.261 (0.261)	Loss 1.0954 (1.0954)	Acc@1 71.875 (71.875)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.135 (0.129)	Data 0.000 (0.004)	Loss 0.9594 (0.9680)	Acc@1 78.516 (79.261)	Acc@5 98.438 (98.888)
Epoch: [7][128/196]	Time 0.140 (0.129)	Data 0.000 (0.002)	Loss 0.8781 (0.9707)	Acc@1 83.203 (79.073)	Acc@5 99.609 (98.762)
Epoch: [7][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.9374 (0.9678)	Acc@1 79.297 (79.121)	Acc@5 98.047 (98.739)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.182 (0.182)	Data 0.280 (0.280)	Loss 0.8981 (0.8981)	Acc@1 80.469 (80.469)	Acc@5 98.047 (98.047)
Epoch: [8][64/196]	Time 0.134 (0.130)	Data 0.000 (0.005)	Loss 0.8611 (0.9148)	Acc@1 81.641 (80.282)	Acc@5 100.000 (98.888)
Epoch: [8][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.8393 (0.9071)	Acc@1 80.859 (80.402)	Acc@5 99.219 (98.955)
Epoch: [8][192/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.9150 (0.9124)	Acc@1 77.344 (80.196)	Acc@5 99.609 (98.927)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.171 (0.171)	Data 0.287 (0.287)	Loss 0.9098 (0.9098)	Acc@1 81.250 (81.250)	Acc@5 97.266 (97.266)
Epoch: [9][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.8146 (0.8869)	Acc@1 85.156 (80.685)	Acc@5 98.828 (98.984)
Epoch: [9][128/196]	Time 0.135 (0.130)	Data 0.000 (0.002)	Loss 0.8856 (0.8907)	Acc@1 80.078 (80.487)	Acc@5 98.438 (98.916)
Epoch: [9][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8946 (0.8894)	Acc@1 78.516 (80.428)	Acc@5 99.219 (98.941)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.152 (0.152)	Data 0.301 (0.301)	Loss 0.9627 (0.9627)	Acc@1 74.609 (74.609)	Acc@5 98.828 (98.828)
Epoch: [10][64/196]	Time 0.143 (0.132)	Data 0.000 (0.005)	Loss 0.7811 (0.8613)	Acc@1 83.984 (81.184)	Acc@5 99.219 (99.038)
Epoch: [10][128/196]	Time 0.132 (0.132)	Data 0.000 (0.003)	Loss 0.7715 (0.8573)	Acc@1 84.766 (81.317)	Acc@5 98.828 (99.061)
Epoch: [10][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.8587 (0.8590)	Acc@1 82.031 (81.212)	Acc@5 99.219 (99.018)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  54.54
Max memory: 103.3833984
 26.243s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4726
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.212 (0.212)	Data 0.253 (0.253)	Loss 0.8682 (0.8682)	Acc@1 79.688 (79.688)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.135 (0.132)	Data 0.000 (0.004)	Loss 0.8301 (0.8219)	Acc@1 83.594 (82.512)	Acc@5 99.609 (99.050)
Epoch: [11][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.8484 (0.8348)	Acc@1 82.422 (81.962)	Acc@5 97.656 (99.040)
Epoch: [11][192/196]	Time 0.130 (0.131)	Data 0.000 (0.001)	Loss 0.8293 (0.8402)	Acc@1 82.422 (81.653)	Acc@5 99.219 (99.073)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.157 (0.157)	Data 0.255 (0.255)	Loss 0.6966 (0.6966)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [12][64/196]	Time 0.135 (0.132)	Data 0.000 (0.004)	Loss 0.8305 (0.8314)	Acc@1 81.250 (82.206)	Acc@5 99.219 (99.075)
Epoch: [12][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.9013 (0.8319)	Acc@1 80.469 (82.028)	Acc@5 98.438 (99.055)
Epoch: [12][192/196]	Time 0.125 (0.131)	Data 0.000 (0.001)	Loss 0.8286 (0.8304)	Acc@1 82.422 (81.993)	Acc@5 98.438 (99.053)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.170 (0.170)	Data 0.300 (0.300)	Loss 0.8516 (0.8516)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.8940 (0.7974)	Acc@1 78.516 (82.861)	Acc@5 98.828 (99.273)
Epoch: [13][128/196]	Time 0.134 (0.132)	Data 0.000 (0.003)	Loss 0.7480 (0.8068)	Acc@1 85.547 (82.546)	Acc@5 98.828 (99.134)
Epoch: [13][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7820 (0.8169)	Acc@1 83.594 (82.187)	Acc@5 99.219 (99.126)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.191 (0.191)	Data 0.257 (0.257)	Loss 0.7875 (0.7875)	Acc@1 81.641 (81.641)	Acc@5 98.438 (98.438)
Epoch: [14][64/196]	Time 0.133 (0.131)	Data 0.000 (0.004)	Loss 0.7544 (0.7926)	Acc@1 83.203 (83.239)	Acc@5 98.828 (99.249)
Epoch: [14][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8460 (0.8030)	Acc@1 82.812 (82.764)	Acc@5 99.609 (99.225)
Epoch: [14][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.7790 (0.8037)	Acc@1 85.156 (82.770)	Acc@5 99.609 (99.196)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.169 (0.169)	Data 0.261 (0.261)	Loss 0.7410 (0.7410)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.7897 (0.7954)	Acc@1 83.203 (82.584)	Acc@5 98.047 (99.267)
Epoch: [15][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.7985 (0.7981)	Acc@1 82.422 (82.755)	Acc@5 98.438 (99.185)
Epoch: [15][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.9127 (0.8001)	Acc@1 78.516 (82.711)	Acc@5 99.219 (99.144)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.42
Max memory: 103.3833984
 26.163s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6105
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.187 (0.187)	Data 0.269 (0.269)	Loss 0.8120 (0.8120)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 0.8199 (0.7700)	Acc@1 83.203 (83.864)	Acc@5 99.219 (99.327)
Epoch: [16][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.8419 (0.7858)	Acc@1 81.250 (83.300)	Acc@5 98.828 (99.246)
Epoch: [16][192/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 0.7755 (0.7874)	Acc@1 83.594 (83.256)	Acc@5 99.219 (99.249)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.173 (0.173)	Data 0.257 (0.257)	Loss 0.7583 (0.7583)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.131 (0.129)	Data 0.000 (0.004)	Loss 0.8910 (0.7865)	Acc@1 81.250 (83.317)	Acc@5 98.438 (99.267)
Epoch: [17][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7617 (0.7840)	Acc@1 82.812 (83.512)	Acc@5 100.000 (99.216)
Epoch: [17][192/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7679 (0.7902)	Acc@1 85.156 (83.302)	Acc@5 97.656 (99.182)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.173 (0.173)	Data 0.287 (0.287)	Loss 0.7525 (0.7525)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.132 (0.129)	Data 0.000 (0.005)	Loss 0.8308 (0.7742)	Acc@1 80.469 (83.798)	Acc@5 98.047 (99.177)
Epoch: [18][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7912 (0.7715)	Acc@1 81.641 (83.900)	Acc@5 99.219 (99.228)
Epoch: [18][192/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.7419 (0.7777)	Acc@1 84.766 (83.758)	Acc@5 98.828 (99.180)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.181 (0.181)	Data 0.306 (0.306)	Loss 0.6661 (0.6661)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [19][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.7850 (0.7913)	Acc@1 83.594 (83.155)	Acc@5 98.438 (99.261)
Epoch: [19][128/196]	Time 0.133 (0.130)	Data 0.000 (0.003)	Loss 0.6923 (0.7830)	Acc@1 87.109 (83.457)	Acc@5 99.609 (99.322)
Epoch: [19][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7751 (0.7834)	Acc@1 84.375 (83.446)	Acc@5 99.219 (99.296)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.186 (0.186)	Data 0.261 (0.261)	Loss 0.7737 (0.7737)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [20][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.7567 (0.7716)	Acc@1 84.766 (83.768)	Acc@5 99.609 (99.333)
Epoch: [20][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.7701 (0.7742)	Acc@1 84.766 (83.788)	Acc@5 99.219 (99.297)
Epoch: [20][192/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.7233 (0.7724)	Acc@1 84.375 (83.869)	Acc@5 99.219 (99.284)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  78.84
Max memory: 103.3833984
 26.174s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9750
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2020864
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.192 (0.192)	Data 0.279 (0.279)	Loss 0.6969 (0.6969)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [21][64/196]	Time 0.134 (0.132)	Data 0.000 (0.004)	Loss 0.7988 (0.7531)	Acc@1 82.031 (84.237)	Acc@5 98.438 (99.273)
Epoch: [21][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.6948 (0.7614)	Acc@1 85.547 (84.090)	Acc@5 98.438 (99.285)
Epoch: [21][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7637 (0.7682)	Acc@1 83.594 (83.928)	Acc@5 99.219 (99.239)
Max memory in training epoch: 66.6450432
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.162 (0.162)	Data 0.258 (0.258)	Loss 0.6810 (0.6810)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.122 (0.129)	Data 0.000 (0.004)	Loss 0.7365 (0.7489)	Acc@1 83.594 (84.820)	Acc@5 98.828 (99.261)
Epoch: [22][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.8300 (0.7565)	Acc@1 85.156 (84.496)	Acc@5 99.609 (99.279)
Epoch: [22][192/196]	Time 0.135 (0.130)	Data 0.000 (0.001)	Loss 0.7606 (0.7634)	Acc@1 82.422 (84.138)	Acc@5 99.609 (99.233)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.171 (0.171)	Data 0.292 (0.292)	Loss 0.6115 (0.6115)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.146 (0.132)	Data 0.000 (0.005)	Loss 0.7688 (0.7639)	Acc@1 80.469 (84.165)	Acc@5 99.609 (99.309)
Epoch: [23][128/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.7139 (0.7573)	Acc@1 85.938 (84.369)	Acc@5 99.609 (99.319)
Epoch: [23][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.8227 (0.7571)	Acc@1 82.812 (84.312)	Acc@5 99.609 (99.326)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.191 (0.191)	Data 0.256 (0.256)	Loss 0.6899 (0.6899)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [24][64/196]	Time 0.124 (0.132)	Data 0.000 (0.004)	Loss 0.7726 (0.7612)	Acc@1 83.984 (84.171)	Acc@5 98.438 (99.297)
Epoch: [24][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.6489 (0.7612)	Acc@1 90.234 (84.345)	Acc@5 100.000 (99.297)
Epoch: [24][192/196]	Time 0.132 (0.132)	Data 0.000 (0.001)	Loss 0.7641 (0.7585)	Acc@1 85.938 (84.399)	Acc@5 99.219 (99.255)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.188 (0.188)	Data 0.263 (0.263)	Loss 0.7690 (0.7690)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.133 (0.133)	Data 0.000 (0.004)	Loss 0.7676 (0.7411)	Acc@1 84.766 (85.012)	Acc@5 99.219 (99.447)
Epoch: [25][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7566 (0.7514)	Acc@1 85.547 (84.535)	Acc@5 98.438 (99.355)
Epoch: [25][192/196]	Time 0.128 (0.133)	Data 0.000 (0.002)	Loss 0.6757 (0.7518)	Acc@1 85.156 (84.602)	Acc@5 99.609 (99.332)
Max memory in training epoch: 66.5401856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 469494 ; 486232 ; 0.9655761035884105
[INFO] Storing checkpoint...
  77.86
Max memory: 103.3821696
 26.498s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 318
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1954304
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.198 (0.198)	Data 0.286 (0.286)	Loss 0.7367 (0.7367)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.7493 (0.7344)	Acc@1 83.984 (85.108)	Acc@5 99.219 (99.393)
Epoch: [26][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.7244 (0.7439)	Acc@1 82.422 (84.741)	Acc@5 99.609 (99.297)
Epoch: [26][192/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.8375 (0.7422)	Acc@1 81.250 (84.778)	Acc@5 99.609 (99.326)
Max memory in training epoch: 66.3562752
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.163 (0.163)	Data 0.289 (0.289)	Loss 0.6968 (0.6968)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.128 (0.128)	Data 0.000 (0.005)	Loss 0.6991 (0.7443)	Acc@1 86.719 (84.663)	Acc@5 99.219 (99.285)
Epoch: [27][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.6503 (0.7397)	Acc@1 88.281 (84.817)	Acc@5 99.219 (99.346)
Epoch: [27][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.8420 (0.7470)	Acc@1 81.641 (84.583)	Acc@5 98.047 (99.316)
Max memory in training epoch: 66.14656
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.152 (0.152)	Data 0.302 (0.302)	Loss 0.7267 (0.7267)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.7801 (0.7341)	Acc@1 83.203 (85.084)	Acc@5 98.828 (99.351)
Epoch: [28][128/196]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.7106 (0.7485)	Acc@1 85.938 (84.669)	Acc@5 99.219 (99.249)
Epoch: [28][192/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.7550 (0.7470)	Acc@1 83.594 (84.588)	Acc@5 98.438 (99.288)
Max memory in training epoch: 66.14656
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.159 (0.159)	Data 0.293 (0.293)	Loss 0.7146 (0.7146)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [29][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.7140 (0.7392)	Acc@1 86.328 (84.802)	Acc@5 99.219 (99.411)
Epoch: [29][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7307 (0.7340)	Acc@1 86.328 (84.893)	Acc@5 98.438 (99.391)
Epoch: [29][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7425 (0.7374)	Acc@1 84.766 (84.887)	Acc@5 99.609 (99.322)
Max memory in training epoch: 66.14656
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.186 (0.186)	Data 0.255 (0.255)	Loss 0.8771 (0.8771)	Acc@1 78.516 (78.516)	Acc@5 98.828 (98.828)
Epoch: [30][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 0.6999 (0.7402)	Acc@1 88.281 (84.790)	Acc@5 99.609 (99.261)
Epoch: [30][128/196]	Time 0.140 (0.131)	Data 0.000 (0.002)	Loss 0.7601 (0.7401)	Acc@1 82.031 (84.754)	Acc@5 100.000 (99.316)
Epoch: [30][192/196]	Time 0.130 (0.131)	Data 0.000 (0.001)	Loss 0.7432 (0.7384)	Acc@1 84.766 (84.735)	Acc@5 98.438 (99.332)
Max memory in training epoch: 66.14656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 437170 ; 469494 ; 0.9311514098156739
[INFO] Storing checkpoint...
  74.78
Max memory: 103.2854016
 26.052s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6732
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1826304
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.189 (0.189)	Data 0.286 (0.286)	Loss 0.7368 (0.7368)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.127 (0.129)	Data 0.000 (0.005)	Loss 0.7264 (0.6944)	Acc@1 85.938 (86.148)	Acc@5 98.828 (99.549)
Epoch: [31][128/196]	Time 0.127 (0.129)	Data 0.000 (0.002)	Loss 0.7333 (0.7159)	Acc@1 82.812 (85.471)	Acc@5 100.000 (99.446)
Epoch: [31][192/196]	Time 0.130 (0.129)	Data 0.000 (0.002)	Loss 0.7657 (0.7233)	Acc@1 83.203 (85.219)	Acc@5 98.828 (99.411)
Max memory in training epoch: 65.4006784
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.162 (0.162)	Data 0.309 (0.309)	Loss 0.6896 (0.6896)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.131 (0.129)	Data 0.000 (0.005)	Loss 0.8361 (0.7095)	Acc@1 80.469 (85.649)	Acc@5 98.438 (99.441)
Epoch: [32][128/196]	Time 0.128 (0.129)	Data 0.000 (0.003)	Loss 0.6586 (0.7204)	Acc@1 89.062 (85.362)	Acc@5 100.000 (99.413)
Epoch: [32][192/196]	Time 0.140 (0.129)	Data 0.000 (0.002)	Loss 0.6828 (0.7251)	Acc@1 85.156 (85.251)	Acc@5 100.000 (99.383)
Max memory in training epoch: 65.308928
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.170 (0.170)	Data 0.253 (0.253)	Loss 0.8284 (0.8284)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.135 (0.131)	Data 0.000 (0.004)	Loss 0.9132 (0.7251)	Acc@1 77.344 (85.060)	Acc@5 99.609 (99.267)
Epoch: [33][128/196]	Time 0.132 (0.130)	Data 0.000 (0.002)	Loss 0.7390 (0.7263)	Acc@1 82.812 (85.050)	Acc@5 99.609 (99.301)
Epoch: [33][192/196]	Time 0.129 (0.130)	Data 0.000 (0.001)	Loss 0.7267 (0.7294)	Acc@1 87.500 (84.984)	Acc@5 99.219 (99.298)
Max memory in training epoch: 65.308928
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.199 (0.199)	Data 0.261 (0.261)	Loss 0.7315 (0.7315)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [34][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.7517 (0.7020)	Acc@1 83.594 (85.877)	Acc@5 99.609 (99.495)
Epoch: [34][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.7668 (0.7122)	Acc@1 83.594 (85.571)	Acc@5 98.828 (99.413)
Epoch: [34][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7230 (0.7179)	Acc@1 85.547 (85.468)	Acc@5 99.609 (99.399)
Max memory in training epoch: 65.308928
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.184 (0.184)	Data 0.263 (0.263)	Loss 0.6019 (0.6019)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [35][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 0.7186 (0.7133)	Acc@1 84.766 (85.481)	Acc@5 100.000 (99.411)
Epoch: [35][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6041 (0.7125)	Acc@1 92.578 (85.556)	Acc@5 98.828 (99.385)
Epoch: [35][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 0.7109 (0.7175)	Acc@1 85.938 (85.377)	Acc@5 99.219 (99.338)
Max memory in training epoch: 65.308928
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 390414 ; 437170 ; 0.8930484708465815
[INFO] Storing checkpoint...
  78.06
Max memory: 101.801728
 26.061s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3722
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1639936
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.269 (0.269)	Data 0.257 (0.257)	Loss 0.7754 (0.7754)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.134 (0.130)	Data 0.000 (0.004)	Loss 0.7328 (0.6914)	Acc@1 83.203 (86.010)	Acc@5 99.609 (99.465)
Epoch: [36][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7998 (0.7072)	Acc@1 85.547 (85.686)	Acc@5 97.656 (99.400)
Epoch: [36][192/196]	Time 0.127 (0.128)	Data 0.000 (0.002)	Loss 0.6663 (0.7120)	Acc@1 88.672 (85.500)	Acc@5 98.828 (99.356)
Max memory in training epoch: 63.4714624
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.176 (0.176)	Data 0.247 (0.247)	Loss 0.8605 (0.8605)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [37][64/196]	Time 0.125 (0.128)	Data 0.000 (0.004)	Loss 0.7576 (0.7395)	Acc@1 84.375 (84.681)	Acc@5 98.828 (99.315)
Epoch: [37][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.7234 (0.7228)	Acc@1 84.766 (85.314)	Acc@5 100.000 (99.388)
Epoch: [37][192/196]	Time 0.128 (0.129)	Data 0.000 (0.001)	Loss 0.7168 (0.7223)	Acc@1 83.984 (85.397)	Acc@5 100.000 (99.385)
Max memory in training epoch: 63.6287488
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.161 (0.161)	Data 0.252 (0.252)	Loss 0.6390 (0.6390)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.6567 (0.6973)	Acc@1 88.281 (86.244)	Acc@5 99.609 (99.501)
Epoch: [38][128/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.6546 (0.7060)	Acc@1 87.891 (85.723)	Acc@5 98.828 (99.443)
Epoch: [38][192/196]	Time 0.125 (0.129)	Data 0.000 (0.001)	Loss 0.7037 (0.7139)	Acc@1 85.938 (85.432)	Acc@5 99.219 (99.419)
Max memory in training epoch: 63.6287488
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.174 (0.174)	Data 0.232 (0.232)	Loss 0.6886 (0.6886)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [39][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 0.6762 (0.6957)	Acc@1 85.156 (85.775)	Acc@5 99.609 (99.297)
Epoch: [39][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.8073 (0.7070)	Acc@1 80.859 (85.617)	Acc@5 99.609 (99.364)
Epoch: [39][192/196]	Time 0.127 (0.130)	Data 0.000 (0.001)	Loss 0.7533 (0.7116)	Acc@1 84.766 (85.561)	Acc@5 99.219 (99.328)
Max memory in training epoch: 63.6287488
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.186 (0.186)	Data 0.232 (0.232)	Loss 0.6377 (0.6377)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.127 (0.129)	Data 0.000 (0.004)	Loss 0.7460 (0.6974)	Acc@1 84.375 (86.100)	Acc@5 98.438 (99.459)
Epoch: [40][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6254 (0.7015)	Acc@1 88.281 (85.777)	Acc@5 99.609 (99.464)
Epoch: [40][192/196]	Time 0.130 (0.131)	Data 0.000 (0.001)	Loss 0.7218 (0.7081)	Acc@1 85.156 (85.591)	Acc@5 99.609 (99.415)
Max memory in training epoch: 63.6287488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 375402 ; 390414 ; 0.961548510043185
[INFO] Storing checkpoint...
  74.77
Max memory: 98.6787328
 25.913s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3285
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.157952
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.209 (0.209)	Data 0.252 (0.252)	Loss 0.6730 (0.6730)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [41][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.6303 (0.6591)	Acc@1 88.281 (87.314)	Acc@5 99.609 (99.537)
Epoch: [41][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.6747 (0.6769)	Acc@1 85.156 (86.673)	Acc@5 100.000 (99.488)
Epoch: [41][192/196]	Time 0.132 (0.130)	Data 0.000 (0.001)	Loss 0.8816 (0.6879)	Acc@1 76.953 (86.280)	Acc@5 99.219 (99.429)
Max memory in training epoch: 62.5887744
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.188 (0.188)	Data 0.256 (0.256)	Loss 0.6605 (0.6605)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.129 (0.132)	Data 0.000 (0.004)	Loss 0.8829 (0.6962)	Acc@1 79.297 (86.022)	Acc@5 98.828 (99.381)
Epoch: [42][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7045 (0.7014)	Acc@1 85.156 (85.759)	Acc@5 99.609 (99.367)
Epoch: [42][192/196]	Time 0.134 (0.132)	Data 0.000 (0.001)	Loss 0.6416 (0.7045)	Acc@1 86.328 (85.672)	Acc@5 99.609 (99.389)
Max memory in training epoch: 62.5887744
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.185 (0.185)	Data 0.267 (0.267)	Loss 0.6631 (0.6631)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [43][64/196]	Time 0.126 (0.133)	Data 0.000 (0.004)	Loss 0.6443 (0.7067)	Acc@1 87.500 (85.601)	Acc@5 100.000 (99.387)
Epoch: [43][128/196]	Time 0.136 (0.133)	Data 0.000 (0.002)	Loss 0.8267 (0.7112)	Acc@1 80.859 (85.411)	Acc@5 98.438 (99.419)
Epoch: [43][192/196]	Time 0.150 (0.133)	Data 0.000 (0.002)	Loss 0.6412 (0.7084)	Acc@1 89.453 (85.529)	Acc@5 99.609 (99.415)
Max memory in training epoch: 62.5887744
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.199 (0.199)	Data 0.259 (0.259)	Loss 0.6115 (0.6115)	Acc@1 90.234 (90.234)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.136 (0.133)	Data 0.000 (0.004)	Loss 0.7274 (0.7041)	Acc@1 82.812 (85.781)	Acc@5 99.219 (99.345)
Epoch: [44][128/196]	Time 0.165 (0.134)	Data 0.000 (0.002)	Loss 0.7793 (0.7118)	Acc@1 82.422 (85.538)	Acc@5 99.609 (99.367)
Epoch: [44][192/196]	Time 0.134 (0.133)	Data 0.000 (0.001)	Loss 0.6213 (0.7088)	Acc@1 88.281 (85.682)	Acc@5 100.000 (99.389)
Max memory in training epoch: 62.5887744
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.190 (0.190)	Data 0.227 (0.227)	Loss 0.6997 (0.6997)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.6880 (0.6908)	Acc@1 87.500 (86.346)	Acc@5 98.438 (99.405)
Epoch: [45][128/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.6951 (0.6956)	Acc@1 85.156 (85.862)	Acc@5 100.000 (99.397)
Epoch: [45][192/196]	Time 0.132 (0.133)	Data 0.000 (0.001)	Loss 0.7086 (0.6980)	Acc@1 84.766 (85.857)	Acc@5 99.609 (99.409)
Max memory in training epoch: 62.5887744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 362700 ; 375402 ; 0.9661642719005227
[INFO] Storing checkpoint...
  80.25
Max memory: 97.497344
 26.391s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1529344
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.184 (0.184)	Data 0.263 (0.263)	Loss 0.6839 (0.6839)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 0.6872 (0.6622)	Acc@1 85.156 (87.079)	Acc@5 99.609 (99.423)
Epoch: [46][128/196]	Time 0.146 (0.130)	Data 0.000 (0.002)	Loss 0.6710 (0.6753)	Acc@1 88.281 (86.537)	Acc@5 98.828 (99.443)
Epoch: [46][192/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.6230 (0.6844)	Acc@1 88.672 (86.314)	Acc@5 99.609 (99.411)
Max memory in training epoch: 62.3327744
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 0.6528 (0.6528)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.138 (0.131)	Data 0.000 (0.004)	Loss 0.7741 (0.7069)	Acc@1 85.547 (85.895)	Acc@5 99.609 (99.429)
Epoch: [47][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.7499 (0.7039)	Acc@1 85.156 (85.931)	Acc@5 98.828 (99.434)
Epoch: [47][192/196]	Time 0.144 (0.132)	Data 0.000 (0.002)	Loss 0.7204 (0.7033)	Acc@1 83.594 (85.859)	Acc@5 100.000 (99.433)
Max memory in training epoch: 62.3589888
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.165 (0.165)	Data 0.237 (0.237)	Loss 0.6634 (0.6634)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.132 (0.134)	Data 0.000 (0.004)	Loss 0.7281 (0.6955)	Acc@1 82.031 (85.907)	Acc@5 98.828 (99.375)
Epoch: [48][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7943 (0.7049)	Acc@1 83.203 (85.532)	Acc@5 98.828 (99.388)
Epoch: [48][192/196]	Time 0.135 (0.133)	Data 0.000 (0.001)	Loss 0.6908 (0.7036)	Acc@1 85.156 (85.612)	Acc@5 100.000 (99.411)
Max memory in training epoch: 62.3589888
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.179 (0.179)	Data 0.235 (0.235)	Loss 0.6148 (0.6148)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 0.6244 (0.6905)	Acc@1 90.234 (86.232)	Acc@5 99.609 (99.495)
Epoch: [49][128/196]	Time 0.173 (0.133)	Data 0.000 (0.002)	Loss 0.7454 (0.7055)	Acc@1 84.375 (85.723)	Acc@5 99.609 (99.425)
Epoch: [49][192/196]	Time 0.131 (0.133)	Data 0.000 (0.001)	Loss 0.7217 (0.6999)	Acc@1 84.766 (85.893)	Acc@5 99.609 (99.437)
Max memory in training epoch: 62.3589888
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.165 (0.165)	Data 0.233 (0.233)	Loss 0.6823 (0.6823)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.7741 (0.6812)	Acc@1 84.766 (86.508)	Acc@5 99.219 (99.447)
Epoch: [50][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.6377 (0.6898)	Acc@1 86.328 (86.134)	Acc@5 99.609 (99.440)
Epoch: [50][192/196]	Time 0.134 (0.133)	Data 0.000 (0.001)	Loss 0.6379 (0.6927)	Acc@1 89.062 (86.116)	Acc@5 99.609 (99.425)
Max memory in training epoch: 62.3589888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight

 RM:  module.conv30.weight

 RM:  module.conv31.weight
numoFStages: 3
Count: 356010 ; 362700 ; 0.9815550041356493
[INFO] Storing checkpoint...
  79.02
Max memory: 96.1637888
 26.308s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8517
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1494016
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.206 (0.206)	Data 0.235 (0.235)	Loss 0.6853 (0.6853)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [51][64/196]	Time 0.112 (0.117)	Data 0.000 (0.004)	Loss 0.5966 (0.6529)	Acc@1 88.672 (87.422)	Acc@5 99.219 (99.573)
Epoch: [51][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.6058 (0.6761)	Acc@1 90.234 (86.695)	Acc@5 100.000 (99.479)
Epoch: [51][192/196]	Time 0.117 (0.118)	Data 0.000 (0.001)	Loss 0.5920 (0.6828)	Acc@1 89.062 (86.371)	Acc@5 100.000 (99.470)
Max memory in training epoch: 58.8798464
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.155 (0.155)	Data 0.307 (0.307)	Loss 0.6771 (0.6771)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.6483 (0.7011)	Acc@1 88.281 (85.769)	Acc@5 99.219 (99.405)
Epoch: [52][128/196]	Time 0.117 (0.119)	Data 0.000 (0.003)	Loss 0.6544 (0.6902)	Acc@1 87.891 (86.162)	Acc@5 99.609 (99.440)
Epoch: [52][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6231 (0.6922)	Acc@1 89.453 (86.069)	Acc@5 100.000 (99.439)
Max memory in training epoch: 58.8012032
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.169 (0.169)	Data 0.263 (0.263)	Loss 0.7235 (0.7235)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.115 (0.120)	Data 0.000 (0.004)	Loss 0.6329 (0.6949)	Acc@1 87.891 (86.250)	Acc@5 99.609 (99.423)
Epoch: [53][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.6706 (0.6923)	Acc@1 88.672 (86.243)	Acc@5 99.609 (99.419)
Epoch: [53][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.6773 (0.6937)	Acc@1 85.938 (86.136)	Acc@5 99.219 (99.421)
Max memory in training epoch: 58.8012032
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.156 (0.156)	Data 0.239 (0.239)	Loss 0.6110 (0.6110)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.7564 (0.6957)	Acc@1 83.594 (85.907)	Acc@5 98.438 (99.417)
Epoch: [54][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.7273 (0.6934)	Acc@1 85.547 (85.904)	Acc@5 98.828 (99.452)
Epoch: [54][192/196]	Time 0.114 (0.118)	Data 0.000 (0.001)	Loss 0.6551 (0.6942)	Acc@1 88.672 (85.978)	Acc@5 99.219 (99.429)
Max memory in training epoch: 58.8012032
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.149 (0.149)	Data 0.293 (0.293)	Loss 0.6670 (0.6670)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [55][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.6596 (0.6920)	Acc@1 87.109 (86.304)	Acc@5 100.000 (99.423)
Epoch: [55][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.7069 (0.6937)	Acc@1 85.156 (86.010)	Acc@5 100.000 (99.437)
Epoch: [55][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.7098 (0.6968)	Acc@1 85.547 (85.933)	Acc@5 99.609 (99.401)
Max memory in training epoch: 58.8012032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 349078 ; 356010 ; 0.980528636836044
[INFO] Storing checkpoint...
  76.34
Max memory: 91.3098752
 23.606s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1528
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1467392
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.192 (0.192)	Data 0.266 (0.266)	Loss 0.7019 (0.7019)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.113 (0.119)	Data 0.000 (0.004)	Loss 0.6256 (0.6546)	Acc@1 89.453 (87.266)	Acc@5 99.609 (99.483)
Epoch: [56][128/196]	Time 0.109 (0.117)	Data 0.000 (0.002)	Loss 0.7343 (0.6714)	Acc@1 85.156 (86.776)	Acc@5 99.219 (99.503)
Epoch: [56][192/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.7114 (0.6828)	Acc@1 88.281 (86.334)	Acc@5 98.828 (99.484)
Max memory in training epoch: 58.7905536
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.149 (0.149)	Data 0.296 (0.296)	Loss 0.6955 (0.6955)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.7907 (0.6891)	Acc@1 82.812 (86.034)	Acc@5 99.219 (99.525)
Epoch: [57][128/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.6946 (0.6908)	Acc@1 86.328 (86.243)	Acc@5 99.219 (99.482)
Epoch: [57][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.6983 (0.6875)	Acc@1 85.938 (86.247)	Acc@5 100.000 (99.484)
Max memory in training epoch: 58.5021952
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.169 (0.169)	Data 0.276 (0.276)	Loss 0.6850 (0.6850)	Acc@1 87.109 (87.109)	Acc@5 98.828 (98.828)
Epoch: [58][64/196]	Time 0.115 (0.117)	Data 0.000 (0.004)	Loss 0.6660 (0.6694)	Acc@1 86.328 (86.911)	Acc@5 100.000 (99.393)
Epoch: [58][128/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.5666 (0.6768)	Acc@1 91.797 (86.531)	Acc@5 99.609 (99.425)
Epoch: [58][192/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.7629 (0.6823)	Acc@1 83.984 (86.306)	Acc@5 98.828 (99.429)
Max memory in training epoch: 58.5021952
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.171 (0.171)	Data 0.292 (0.292)	Loss 0.7135 (0.7135)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [59][64/196]	Time 0.118 (0.117)	Data 0.000 (0.005)	Loss 0.7315 (0.6782)	Acc@1 86.328 (86.635)	Acc@5 99.609 (99.459)
Epoch: [59][128/196]	Time 0.123 (0.118)	Data 0.000 (0.002)	Loss 0.6993 (0.6806)	Acc@1 85.938 (86.313)	Acc@5 99.609 (99.455)
Epoch: [59][192/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.6347 (0.6888)	Acc@1 87.891 (86.065)	Acc@5 98.828 (99.441)
Max memory in training epoch: 58.5021952
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.155 (0.155)	Data 0.289 (0.289)	Loss 0.6853 (0.6853)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.114 (0.119)	Data 0.000 (0.005)	Loss 0.7251 (0.6621)	Acc@1 85.938 (87.181)	Acc@5 99.609 (99.555)
Epoch: [60][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.7434 (0.6794)	Acc@1 84.375 (86.549)	Acc@5 99.609 (99.461)
Epoch: [60][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.6174 (0.6840)	Acc@1 89.844 (86.300)	Acc@5 99.219 (99.452)
Max memory in training epoch: 58.5021952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 343586 ; 349078 ; 0.9842671265447837
[INFO] Storing checkpoint...
  78.61
Max memory: 90.6586112
 23.391s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7687
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1444864
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.184 (0.184)	Data 0.250 (0.250)	Loss 0.6611 (0.6611)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.110 (0.116)	Data 0.000 (0.004)	Loss 0.6785 (0.6560)	Acc@1 87.109 (87.019)	Acc@5 99.609 (99.567)
Epoch: [61][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.6521 (0.6684)	Acc@1 90.234 (86.661)	Acc@5 100.000 (99.479)
Epoch: [61][192/196]	Time 0.119 (0.116)	Data 0.000 (0.001)	Loss 0.6038 (0.6749)	Acc@1 88.672 (86.439)	Acc@5 99.609 (99.445)
Max memory in training epoch: 57.5494656
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.162 (0.162)	Data 0.277 (0.277)	Loss 0.6577 (0.6577)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.118 (0.117)	Data 0.000 (0.004)	Loss 0.5855 (0.7057)	Acc@1 89.062 (85.276)	Acc@5 99.609 (99.357)
Epoch: [62][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.7261 (0.6999)	Acc@1 81.641 (85.632)	Acc@5 100.000 (99.373)
Epoch: [62][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.7735 (0.6908)	Acc@1 81.250 (85.859)	Acc@5 99.609 (99.403)
Max memory in training epoch: 57.2414464
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.167 (0.167)	Data 0.257 (0.257)	Loss 0.6241 (0.6241)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [63][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.6603 (0.6700)	Acc@1 87.891 (86.737)	Acc@5 99.609 (99.357)
Epoch: [63][128/196]	Time 0.112 (0.118)	Data 0.000 (0.002)	Loss 0.7101 (0.6728)	Acc@1 84.766 (86.731)	Acc@5 99.609 (99.431)
Epoch: [63][192/196]	Time 0.124 (0.118)	Data 0.000 (0.001)	Loss 0.6722 (0.6790)	Acc@1 86.719 (86.407)	Acc@5 99.219 (99.447)
Max memory in training epoch: 57.2414464
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.162 (0.162)	Data 0.296 (0.296)	Loss 0.7572 (0.7572)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [64][64/196]	Time 0.121 (0.119)	Data 0.000 (0.005)	Loss 0.6530 (0.6810)	Acc@1 86.719 (86.226)	Acc@5 99.609 (99.555)
Epoch: [64][128/196]	Time 0.128 (0.119)	Data 0.000 (0.002)	Loss 0.7083 (0.6760)	Acc@1 84.375 (86.495)	Acc@5 100.000 (99.576)
Epoch: [64][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.6839 (0.6785)	Acc@1 84.766 (86.367)	Acc@5 100.000 (99.547)
Max memory in training epoch: 57.2414464
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.150 (0.150)	Data 0.271 (0.271)	Loss 0.7119 (0.7119)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [65][64/196]	Time 0.116 (0.122)	Data 0.000 (0.004)	Loss 0.6416 (0.6706)	Acc@1 88.672 (86.977)	Acc@5 99.219 (99.483)
Epoch: [65][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.7445 (0.6829)	Acc@1 84.766 (86.386)	Acc@5 99.219 (99.452)
Epoch: [65][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.7165 (0.6817)	Acc@1 83.594 (86.425)	Acc@5 99.219 (99.462)
Max memory in training epoch: 57.2414464
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 339538 ; 343586 ; 0.9882183790957723
[INFO] Storing checkpoint...
  76.8
Max memory: 88.8569856
 23.777s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8355
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1429504
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.195 (0.195)	Data 0.276 (0.276)	Loss 0.7001 (0.7001)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.6864 (0.6651)	Acc@1 88.672 (86.917)	Acc@5 99.609 (99.537)
Epoch: [66][128/196]	Time 0.134 (0.120)	Data 0.000 (0.002)	Loss 0.7201 (0.6766)	Acc@1 83.594 (86.495)	Acc@5 99.609 (99.491)
Epoch: [66][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6367 (0.6736)	Acc@1 86.328 (86.567)	Acc@5 100.000 (99.506)
Max memory in training epoch: 56.8551936
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.166 (0.166)	Data 0.248 (0.248)	Loss 0.6547 (0.6547)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.7276 (0.6890)	Acc@1 83.203 (85.859)	Acc@5 99.609 (99.513)
Epoch: [67][128/196]	Time 0.137 (0.121)	Data 0.000 (0.002)	Loss 0.6279 (0.6803)	Acc@1 87.500 (86.277)	Acc@5 99.609 (99.488)
Epoch: [67][192/196]	Time 0.118 (0.121)	Data 0.000 (0.001)	Loss 0.6924 (0.6838)	Acc@1 84.766 (86.269)	Acc@5 99.609 (99.447)
Max memory in training epoch: 56.652032
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.173 (0.173)	Data 0.250 (0.250)	Loss 0.6022 (0.6022)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.6427 (0.6761)	Acc@1 88.281 (86.376)	Acc@5 100.000 (99.531)
Epoch: [68][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6935 (0.6730)	Acc@1 86.328 (86.519)	Acc@5 100.000 (99.512)
Epoch: [68][192/196]	Time 0.119 (0.121)	Data 0.000 (0.001)	Loss 0.6004 (0.6755)	Acc@1 88.672 (86.381)	Acc@5 99.219 (99.482)
Max memory in training epoch: 56.652032
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.154 (0.154)	Data 0.309 (0.309)	Loss 0.6281 (0.6281)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [69][64/196]	Time 0.121 (0.122)	Data 0.000 (0.005)	Loss 0.7098 (0.6785)	Acc@1 85.547 (86.310)	Acc@5 99.609 (99.453)
Epoch: [69][128/196]	Time 0.118 (0.122)	Data 0.000 (0.003)	Loss 0.6527 (0.6816)	Acc@1 89.844 (86.274)	Acc@5 98.828 (99.413)
Epoch: [69][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6994 (0.6776)	Acc@1 87.109 (86.348)	Acc@5 99.609 (99.429)
Max memory in training epoch: 56.652032
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.181 (0.181)	Data 0.253 (0.253)	Loss 0.6379 (0.6379)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.6835 (0.6717)	Acc@1 86.719 (86.484)	Acc@5 99.609 (99.501)
Epoch: [70][128/196]	Time 0.160 (0.123)	Data 0.000 (0.002)	Loss 0.7476 (0.6810)	Acc@1 84.766 (86.165)	Acc@5 99.219 (99.506)
Epoch: [70][192/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.6356 (0.6841)	Acc@1 87.109 (86.118)	Acc@5 99.609 (99.488)
Max memory in training epoch: 56.652032
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 337228 ; 339538 ; 0.9931966377842834
[INFO] Storing checkpoint...
  82.93
Max memory: 88.1032192
 24.175s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9649
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1420288
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.195 (0.195)	Data 0.287 (0.287)	Loss 0.7099 (0.7099)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [71][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.7011 (0.6584)	Acc@1 83.984 (86.965)	Acc@5 99.219 (99.483)
Epoch: [71][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6735 (0.6747)	Acc@1 87.500 (86.573)	Acc@5 99.609 (99.416)
Epoch: [71][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.7213 (0.6768)	Acc@1 85.938 (86.498)	Acc@5 99.219 (99.415)
Max memory in training epoch: 56.6024704
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.156 (0.156)	Data 0.246 (0.246)	Loss 0.6707 (0.6707)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.128 (0.120)	Data 0.000 (0.004)	Loss 0.6158 (0.6681)	Acc@1 86.328 (86.562)	Acc@5 100.000 (99.573)
Epoch: [72][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.7009 (0.6776)	Acc@1 86.328 (86.416)	Acc@5 99.609 (99.476)
Epoch: [72][192/196]	Time 0.119 (0.120)	Data 0.000 (0.001)	Loss 0.7360 (0.6828)	Acc@1 83.594 (86.209)	Acc@5 99.609 (99.445)
Max memory in training epoch: 56.5500416
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.152 (0.152)	Data 0.299 (0.299)	Loss 0.6559 (0.6559)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.6476 (0.6662)	Acc@1 87.891 (86.791)	Acc@5 99.219 (99.525)
Epoch: [73][128/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.6604 (0.6726)	Acc@1 87.500 (86.437)	Acc@5 100.000 (99.503)
Epoch: [73][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.6865 (0.6734)	Acc@1 86.328 (86.385)	Acc@5 100.000 (99.500)
Max memory in training epoch: 56.5500416
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.152 (0.152)	Data 0.288 (0.288)	Loss 0.6645 (0.6645)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.121 (0.119)	Data 0.000 (0.005)	Loss 0.5964 (0.6805)	Acc@1 90.234 (86.406)	Acc@5 99.219 (99.459)
Epoch: [74][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.7281 (0.6817)	Acc@1 84.766 (86.183)	Acc@5 100.000 (99.431)
Epoch: [74][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.7512 (0.6821)	Acc@1 83.984 (86.152)	Acc@5 98.438 (99.454)
Max memory in training epoch: 56.5500416
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.162 (0.162)	Data 0.288 (0.288)	Loss 0.6146 (0.6146)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.115 (0.120)	Data 0.000 (0.005)	Loss 0.6903 (0.6627)	Acc@1 85.547 (86.911)	Acc@5 100.000 (99.561)
Epoch: [75][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.6433 (0.6641)	Acc@1 89.844 (86.828)	Acc@5 100.000 (99.552)
Epoch: [75][192/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.6984 (0.6718)	Acc@1 88.281 (86.640)	Acc@5 100.000 (99.480)
Max memory in training epoch: 56.5500416
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight
numoFStages: 3
Count: 332544 ; 337228 ; 0.9861102874019951
[INFO] Storing checkpoint...
  77.0
Max memory: 87.9988736
 23.712s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3413
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1396736
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.184 (0.184)	Data 0.284 (0.284)	Loss 0.6304 (0.6304)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.127 (0.111)	Data 0.000 (0.005)	Loss 0.7248 (0.6407)	Acc@1 84.375 (87.716)	Acc@5 99.609 (99.549)
Epoch: [76][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.6802 (0.6569)	Acc@1 87.500 (87.037)	Acc@5 100.000 (99.534)
Epoch: [76][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.7062 (0.6613)	Acc@1 84.375 (86.915)	Acc@5 99.609 (99.524)
Max memory in training epoch: 54.745856
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.172 (0.172)	Data 0.244 (0.244)	Loss 0.6721 (0.6721)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.122 (0.111)	Data 0.000 (0.004)	Loss 0.6754 (0.6636)	Acc@1 86.719 (86.713)	Acc@5 98.828 (99.555)
Epoch: [77][128/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.7390 (0.6697)	Acc@1 84.375 (86.716)	Acc@5 99.219 (99.467)
Epoch: [77][192/196]	Time 0.107 (0.111)	Data 0.000 (0.001)	Loss 0.5794 (0.6758)	Acc@1 89.844 (86.482)	Acc@5 100.000 (99.466)
Max memory in training epoch: 54.7065344
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.157 (0.157)	Data 0.287 (0.287)	Loss 0.5968 (0.5968)	Acc@1 89.453 (89.453)	Acc@5 99.219 (99.219)
Epoch: [78][64/196]	Time 0.117 (0.114)	Data 0.000 (0.005)	Loss 0.7351 (0.6568)	Acc@1 85.938 (87.248)	Acc@5 98.828 (99.399)
Epoch: [78][128/196]	Time 0.113 (0.114)	Data 0.000 (0.002)	Loss 0.7181 (0.6572)	Acc@1 85.547 (87.106)	Acc@5 100.000 (99.452)
Epoch: [78][192/196]	Time 0.116 (0.113)	Data 0.000 (0.002)	Loss 0.6537 (0.6703)	Acc@1 85.156 (86.642)	Acc@5 100.000 (99.421)
Max memory in training epoch: 54.7065344
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.125 (0.125)	Data 0.280 (0.280)	Loss 0.6978 (0.6978)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.113 (0.112)	Data 0.000 (0.004)	Loss 0.6056 (0.6661)	Acc@1 89.844 (86.995)	Acc@5 99.219 (99.447)
Epoch: [79][128/196]	Time 0.106 (0.112)	Data 0.000 (0.002)	Loss 0.6539 (0.6668)	Acc@1 87.891 (86.949)	Acc@5 100.000 (99.500)
Epoch: [79][192/196]	Time 0.117 (0.112)	Data 0.000 (0.002)	Loss 0.6117 (0.6734)	Acc@1 88.672 (86.593)	Acc@5 100.000 (99.468)
Max memory in training epoch: 54.7065344
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.147 (0.147)	Data 0.272 (0.272)	Loss 0.7133 (0.7133)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [80][64/196]	Time 0.110 (0.111)	Data 0.000 (0.004)	Loss 0.6408 (0.6625)	Acc@1 83.984 (86.953)	Acc@5 100.000 (99.327)
Epoch: [80][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.6712 (0.6699)	Acc@1 87.891 (86.640)	Acc@5 100.000 (99.416)
Epoch: [80][192/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.6329 (0.6714)	Acc@1 89.453 (86.616)	Acc@5 99.609 (99.435)
Max memory in training epoch: 54.7065344
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 331964 ; 332544 ; 0.998255869899923
[INFO] Storing checkpoint...
  76.96
Max memory: 85.180928
 22.365s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6007
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1394688
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.169 (0.169)	Data 0.288 (0.288)	Loss 0.6723 (0.6723)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.108 (0.111)	Data 0.000 (0.005)	Loss 0.6445 (0.6325)	Acc@1 85.547 (87.831)	Acc@5 99.219 (99.645)
Epoch: [81][128/196]	Time 0.113 (0.112)	Data 0.000 (0.002)	Loss 0.6335 (0.6630)	Acc@1 87.500 (86.849)	Acc@5 100.000 (99.519)
Epoch: [81][192/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.6840 (0.6651)	Acc@1 85.938 (86.850)	Acc@5 99.609 (99.520)
Max memory in training epoch: 54.3256064
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.138 (0.138)	Data 0.283 (0.283)	Loss 0.6639 (0.6639)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [82][64/196]	Time 0.108 (0.114)	Data 0.000 (0.005)	Loss 0.6807 (0.6722)	Acc@1 84.375 (86.412)	Acc@5 99.609 (99.555)
Epoch: [82][128/196]	Time 0.108 (0.113)	Data 0.000 (0.002)	Loss 0.6031 (0.6723)	Acc@1 87.109 (86.477)	Acc@5 99.609 (99.531)
Epoch: [82][192/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.7698 (0.6769)	Acc@1 82.422 (86.300)	Acc@5 99.609 (99.510)
Max memory in training epoch: 54.2862848
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.146 (0.146)	Data 0.280 (0.280)	Loss 0.7187 (0.7187)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [83][64/196]	Time 0.111 (0.112)	Data 0.000 (0.004)	Loss 0.6126 (0.6684)	Acc@1 88.672 (86.761)	Acc@5 100.000 (99.483)
Epoch: [83][128/196]	Time 0.111 (0.113)	Data 0.000 (0.002)	Loss 0.6756 (0.6703)	Acc@1 85.938 (86.695)	Acc@5 99.609 (99.379)
Epoch: [83][192/196]	Time 0.118 (0.113)	Data 0.000 (0.002)	Loss 0.7306 (0.6704)	Acc@1 83.203 (86.571)	Acc@5 99.609 (99.407)
Max memory in training epoch: 54.2862848
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.169 (0.169)	Data 0.251 (0.251)	Loss 0.6676 (0.6676)	Acc@1 86.328 (86.328)	Acc@5 98.438 (98.438)
Epoch: [84][64/196]	Time 0.108 (0.115)	Data 0.000 (0.004)	Loss 0.6509 (0.6745)	Acc@1 85.547 (86.653)	Acc@5 100.000 (99.459)
Epoch: [84][128/196]	Time 0.108 (0.113)	Data 0.000 (0.002)	Loss 0.6021 (0.6697)	Acc@1 90.625 (86.670)	Acc@5 100.000 (99.503)
Epoch: [84][192/196]	Time 0.114 (0.113)	Data 0.000 (0.001)	Loss 0.6190 (0.6671)	Acc@1 89.453 (86.719)	Acc@5 100.000 (99.508)
Max memory in training epoch: 54.2862848
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.148 (0.148)	Data 0.271 (0.271)	Loss 0.6710 (0.6710)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [85][64/196]	Time 0.141 (0.114)	Data 0.000 (0.004)	Loss 0.7061 (0.6756)	Acc@1 87.500 (86.268)	Acc@5 98.047 (99.513)
Epoch: [85][128/196]	Time 0.115 (0.113)	Data 0.000 (0.002)	Loss 0.7469 (0.6703)	Acc@1 83.984 (86.449)	Acc@5 99.609 (99.500)
Epoch: [85][192/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.6479 (0.6702)	Acc@1 87.500 (86.478)	Acc@5 99.609 (99.492)
Max memory in training epoch: 54.2862848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.06
Max memory: 84.6035968
 22.515s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8247
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1394688
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.174 (0.174)	Data 0.279 (0.279)	Loss 0.6611 (0.6611)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [86][64/196]	Time 0.104 (0.112)	Data 0.000 (0.004)	Loss 0.6883 (0.6480)	Acc@1 85.938 (87.416)	Acc@5 100.000 (99.579)
Epoch: [86][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.6673 (0.6628)	Acc@1 87.500 (86.734)	Acc@5 99.219 (99.500)
Epoch: [86][192/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.7070 (0.6684)	Acc@1 86.328 (86.587)	Acc@5 99.609 (99.447)
Max memory in training epoch: 54.3256064
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.129 (0.129)	Data 0.283 (0.283)	Loss 0.6137 (0.6137)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.111 (0.110)	Data 0.000 (0.005)	Loss 0.6941 (0.6608)	Acc@1 86.328 (86.629)	Acc@5 99.219 (99.477)
Epoch: [87][128/196]	Time 0.111 (0.110)	Data 0.000 (0.002)	Loss 0.6530 (0.6584)	Acc@1 85.547 (86.855)	Acc@5 98.438 (99.419)
Epoch: [87][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.6909 (0.6628)	Acc@1 87.500 (86.864)	Acc@5 99.219 (99.449)
Max memory in training epoch: 54.2862848
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.167 (0.167)	Data 0.266 (0.266)	Loss 0.6707 (0.6707)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [88][64/196]	Time 0.107 (0.111)	Data 0.000 (0.004)	Loss 0.6929 (0.6797)	Acc@1 85.547 (86.166)	Acc@5 98.828 (99.423)
Epoch: [88][128/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.7216 (0.6732)	Acc@1 83.984 (86.343)	Acc@5 99.609 (99.494)
Epoch: [88][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.7141 (0.6736)	Acc@1 85.156 (86.314)	Acc@5 99.609 (99.488)
Max memory in training epoch: 54.2862848
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.121 (0.121)	Data 0.299 (0.299)	Loss 0.5895 (0.5895)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [89][64/196]	Time 0.101 (0.112)	Data 0.000 (0.005)	Loss 0.6569 (0.6689)	Acc@1 88.672 (86.556)	Acc@5 100.000 (99.573)
Epoch: [89][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.6353 (0.6745)	Acc@1 87.891 (86.437)	Acc@5 99.609 (99.488)
Epoch: [89][192/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.7135 (0.6734)	Acc@1 86.328 (86.484)	Acc@5 99.609 (99.470)
Max memory in training epoch: 54.2862848
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.141 (0.141)	Data 0.289 (0.289)	Loss 0.6616 (0.6616)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.114 (0.112)	Data 0.000 (0.005)	Loss 0.6594 (0.6781)	Acc@1 87.109 (86.262)	Acc@5 99.219 (99.501)
Epoch: [90][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.6955 (0.6748)	Acc@1 87.891 (86.446)	Acc@5 98.438 (99.485)
Epoch: [90][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.6631 (0.6750)	Acc@1 85.938 (86.524)	Acc@5 100.000 (99.504)
Max memory in training epoch: 54.2862848
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 329798 ; 331964 ; 0.9934751961056019
[INFO] Storing checkpoint...
  77.35
Max memory: 84.6035968
 22.039s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3125
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1385472
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.172 (0.172)	Data 0.292 (0.292)	Loss 0.6406 (0.6406)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.110 (0.110)	Data 0.000 (0.005)	Loss 0.7200 (0.6458)	Acc@1 85.156 (87.440)	Acc@5 99.219 (99.543)
Epoch: [91][128/196]	Time 0.105 (0.109)	Data 0.000 (0.002)	Loss 0.6271 (0.6606)	Acc@1 88.281 (86.940)	Acc@5 99.609 (99.537)
Epoch: [91][192/196]	Time 0.111 (0.109)	Data 0.000 (0.002)	Loss 0.7119 (0.6661)	Acc@1 86.328 (86.822)	Acc@5 99.609 (99.480)
Max memory in training epoch: 54.2039552
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.153 (0.153)	Data 0.282 (0.282)	Loss 0.6790 (0.6790)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.107 (0.109)	Data 0.000 (0.005)	Loss 0.6219 (0.6446)	Acc@1 87.500 (87.218)	Acc@5 99.609 (99.585)
Epoch: [92][128/196]	Time 0.105 (0.109)	Data 0.000 (0.002)	Loss 0.7982 (0.6591)	Acc@1 82.422 (86.852)	Acc@5 99.219 (99.497)
Epoch: [92][192/196]	Time 0.107 (0.109)	Data 0.000 (0.002)	Loss 0.6438 (0.6627)	Acc@1 85.547 (86.662)	Acc@5 99.609 (99.492)
Max memory in training epoch: 54.0335616
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.130 (0.130)	Data 0.275 (0.275)	Loss 0.6494 (0.6494)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [93][64/196]	Time 0.111 (0.110)	Data 0.000 (0.004)	Loss 0.5009 (0.5704)	Acc@1 93.750 (89.994)	Acc@5 100.000 (99.718)
Epoch: [93][128/196]	Time 0.105 (0.109)	Data 0.000 (0.002)	Loss 0.5220 (0.5443)	Acc@1 90.234 (91.016)	Acc@5 100.000 (99.727)
Epoch: [93][192/196]	Time 0.115 (0.109)	Data 0.000 (0.002)	Loss 0.4538 (0.5310)	Acc@1 92.969 (91.437)	Acc@5 99.609 (99.765)
Max memory in training epoch: 54.0335616
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.150 (0.150)	Data 0.294 (0.294)	Loss 0.4919 (0.4919)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.4239 (0.4748)	Acc@1 96.094 (93.239)	Acc@5 99.609 (99.832)
Epoch: [94][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.5109 (0.4745)	Acc@1 92.188 (93.138)	Acc@5 99.219 (99.836)
Epoch: [94][192/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.4688 (0.4741)	Acc@1 92.969 (93.098)	Acc@5 100.000 (99.852)
Max memory in training epoch: 54.0335616
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.127 (0.127)	Data 0.268 (0.268)	Loss 0.4127 (0.4127)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.124 (0.112)	Data 0.000 (0.004)	Loss 0.4396 (0.4555)	Acc@1 92.969 (93.516)	Acc@5 100.000 (99.856)
Epoch: [95][128/196]	Time 0.118 (0.111)	Data 0.000 (0.002)	Loss 0.4288 (0.4571)	Acc@1 94.141 (93.453)	Acc@5 100.000 (99.864)
Epoch: [95][192/196]	Time 0.107 (0.110)	Data 0.000 (0.002)	Loss 0.4442 (0.4527)	Acc@1 93.359 (93.596)	Acc@5 100.000 (99.864)
Max memory in training epoch: 54.0335616
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 328210 ; 329798 ; 0.9951849313822401
[INFO] Storing checkpoint...
  91.3
Max memory: 84.1869312
 21.956s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2167
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.170 (0.170)	Data 0.280 (0.280)	Loss 0.3924 (0.3924)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.112 (0.109)	Data 0.000 (0.004)	Loss 0.4859 (0.4415)	Acc@1 93.359 (93.990)	Acc@5 100.000 (99.868)
Epoch: [96][128/196]	Time 0.101 (0.108)	Data 0.000 (0.002)	Loss 0.4205 (0.4360)	Acc@1 92.578 (94.192)	Acc@5 100.000 (99.873)
Epoch: [96][192/196]	Time 0.103 (0.108)	Data 0.000 (0.002)	Loss 0.4651 (0.4353)	Acc@1 92.188 (94.128)	Acc@5 99.609 (99.858)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.133 (0.133)	Data 0.256 (0.256)	Loss 0.3803 (0.3803)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.108 (0.108)	Data 0.000 (0.004)	Loss 0.4134 (0.4188)	Acc@1 93.750 (94.441)	Acc@5 100.000 (99.904)
Epoch: [97][128/196]	Time 0.128 (0.108)	Data 0.000 (0.002)	Loss 0.4268 (0.4229)	Acc@1 93.359 (94.262)	Acc@5 99.609 (99.933)
Epoch: [97][192/196]	Time 0.106 (0.107)	Data 0.000 (0.001)	Loss 0.4567 (0.4226)	Acc@1 93.750 (94.248)	Acc@5 100.000 (99.921)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.146 (0.146)	Data 0.286 (0.286)	Loss 0.4181 (0.4181)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.108 (0.109)	Data 0.000 (0.005)	Loss 0.3600 (0.4059)	Acc@1 96.484 (94.706)	Acc@5 100.000 (99.910)
Epoch: [98][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.4090 (0.4101)	Acc@1 96.484 (94.562)	Acc@5 99.609 (99.888)
Epoch: [98][192/196]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3636 (0.4098)	Acc@1 96.094 (94.588)	Acc@5 100.000 (99.877)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.129 (0.129)	Data 0.254 (0.254)	Loss 0.3688 (0.3688)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.113 (0.111)	Data 0.000 (0.004)	Loss 0.3966 (0.3925)	Acc@1 94.141 (95.186)	Acc@5 100.000 (99.904)
Epoch: [99][128/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.3605 (0.3958)	Acc@1 96.094 (95.082)	Acc@5 100.000 (99.894)
Epoch: [99][192/196]	Time 0.101 (0.109)	Data 0.000 (0.001)	Loss 0.3891 (0.3966)	Acc@1 95.312 (94.952)	Acc@5 100.000 (99.893)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.146 (0.146)	Data 0.292 (0.292)	Loss 0.4171 (0.4171)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.104 (0.110)	Data 0.000 (0.005)	Loss 0.3761 (0.3829)	Acc@1 95.312 (95.325)	Acc@5 100.000 (99.922)
Epoch: [100][128/196]	Time 0.099 (0.109)	Data 0.000 (0.002)	Loss 0.4184 (0.3856)	Acc@1 93.359 (95.203)	Acc@5 100.000 (99.909)
Epoch: [100][192/196]	Time 0.108 (0.109)	Data 0.000 (0.002)	Loss 0.3776 (0.3854)	Acc@1 94.922 (95.217)	Acc@5 100.000 (99.909)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.73
Max memory: 84.2434048
 21.676s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9948
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.162 (0.162)	Data 0.270 (0.270)	Loss 0.3827 (0.3827)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.109 (0.111)	Data 0.000 (0.004)	Loss 0.3995 (0.3685)	Acc@1 95.312 (95.547)	Acc@5 99.609 (99.946)
Epoch: [101][128/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.4576 (0.3739)	Acc@1 90.625 (95.367)	Acc@5 99.219 (99.930)
Epoch: [101][192/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.3527 (0.3764)	Acc@1 95.703 (95.266)	Acc@5 99.609 (99.921)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.160 (0.160)	Data 0.251 (0.251)	Loss 0.4306 (0.4306)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [102][64/196]	Time 0.111 (0.111)	Data 0.000 (0.004)	Loss 0.3763 (0.3715)	Acc@1 93.359 (95.306)	Acc@5 100.000 (99.928)
Epoch: [102][128/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.3745 (0.3686)	Acc@1 94.531 (95.282)	Acc@5 100.000 (99.942)
Epoch: [102][192/196]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.3102 (0.3703)	Acc@1 98.047 (95.254)	Acc@5 100.000 (99.923)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.152 (0.152)	Data 0.285 (0.285)	Loss 0.3713 (0.3713)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.103 (0.112)	Data 0.000 (0.005)	Loss 0.3391 (0.3673)	Acc@1 95.312 (95.337)	Acc@5 100.000 (99.904)
Epoch: [103][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.3839 (0.3633)	Acc@1 94.922 (95.370)	Acc@5 99.219 (99.930)
Epoch: [103][192/196]	Time 0.107 (0.112)	Data 0.000 (0.002)	Loss 0.4073 (0.3625)	Acc@1 92.969 (95.424)	Acc@5 100.000 (99.917)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.125 (0.125)	Data 0.295 (0.295)	Loss 0.3441 (0.3441)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.113 (0.111)	Data 0.000 (0.005)	Loss 0.3090 (0.3546)	Acc@1 98.047 (95.745)	Acc@5 99.609 (99.898)
Epoch: [104][128/196]	Time 0.130 (0.111)	Data 0.000 (0.002)	Loss 0.3219 (0.3522)	Acc@1 96.484 (95.767)	Acc@5 100.000 (99.930)
Epoch: [104][192/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.3771 (0.3554)	Acc@1 93.359 (95.618)	Acc@5 100.000 (99.933)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.173 (0.173)	Data 0.334 (0.334)	Loss 0.3593 (0.3593)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.111 (0.114)	Data 0.000 (0.005)	Loss 0.3598 (0.3439)	Acc@1 94.531 (95.799)	Acc@5 99.609 (99.946)
Epoch: [105][128/196]	Time 0.109 (0.112)	Data 0.000 (0.003)	Loss 0.3206 (0.3434)	Acc@1 97.266 (95.897)	Acc@5 100.000 (99.939)
Epoch: [105][192/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.3028 (0.3442)	Acc@1 98.047 (95.837)	Acc@5 100.000 (99.935)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.16
Max memory: 84.2434048
 22.277s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 684
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.166 (0.166)	Data 0.281 (0.281)	Loss 0.3151 (0.3151)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.111 (0.110)	Data 0.000 (0.004)	Loss 0.3014 (0.3268)	Acc@1 96.875 (96.538)	Acc@5 100.000 (99.946)
Epoch: [106][128/196]	Time 0.107 (0.110)	Data 0.000 (0.002)	Loss 0.3095 (0.3343)	Acc@1 96.484 (96.203)	Acc@5 100.000 (99.952)
Epoch: [106][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.3373 (0.3394)	Acc@1 95.312 (95.926)	Acc@5 100.000 (99.949)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.157 (0.157)	Data 0.299 (0.299)	Loss 0.3218 (0.3218)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.106 (0.110)	Data 0.000 (0.005)	Loss 0.2908 (0.3270)	Acc@1 97.266 (96.196)	Acc@5 100.000 (99.976)
Epoch: [107][128/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.3618 (0.3309)	Acc@1 94.531 (96.045)	Acc@5 100.000 (99.952)
Epoch: [107][192/196]	Time 0.124 (0.110)	Data 0.000 (0.002)	Loss 0.3631 (0.3327)	Acc@1 94.531 (95.916)	Acc@5 100.000 (99.960)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.152 (0.152)	Data 0.274 (0.274)	Loss 0.3010 (0.3010)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.107 (0.110)	Data 0.000 (0.004)	Loss 0.3014 (0.3249)	Acc@1 96.875 (96.052)	Acc@5 100.000 (99.958)
Epoch: [108][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.3564 (0.3259)	Acc@1 95.312 (96.073)	Acc@5 99.609 (99.933)
Epoch: [108][192/196]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.3257 (0.3294)	Acc@1 96.094 (95.942)	Acc@5 100.000 (99.941)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.143 (0.143)	Data 0.309 (0.309)	Loss 0.3199 (0.3199)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.124 (0.111)	Data 0.000 (0.005)	Loss 0.2896 (0.3291)	Acc@1 97.266 (95.865)	Acc@5 100.000 (99.910)
Epoch: [109][128/196]	Time 0.110 (0.110)	Data 0.000 (0.003)	Loss 0.3988 (0.3320)	Acc@1 92.188 (95.727)	Acc@5 100.000 (99.906)
Epoch: [109][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3902 (0.3310)	Acc@1 96.094 (95.776)	Acc@5 99.609 (99.923)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.147 (0.147)	Data 0.295 (0.295)	Loss 0.2969 (0.2969)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.107 (0.112)	Data 0.000 (0.005)	Loss 0.3470 (0.3200)	Acc@1 96.094 (96.136)	Acc@5 100.000 (99.976)
Epoch: [110][128/196]	Time 0.103 (0.112)	Data 0.000 (0.002)	Loss 0.3604 (0.3219)	Acc@1 94.141 (96.051)	Acc@5 100.000 (99.967)
Epoch: [110][192/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.3262 (0.3242)	Acc@1 95.703 (95.926)	Acc@5 99.609 (99.947)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.14
Max memory: 84.2434048
 22.271s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7600
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.181 (0.181)	Data 0.286 (0.286)	Loss 0.3502 (0.3502)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.107 (0.112)	Data 0.000 (0.005)	Loss 0.3634 (0.3074)	Acc@1 94.531 (96.605)	Acc@5 100.000 (99.958)
Epoch: [111][128/196]	Time 0.117 (0.111)	Data 0.000 (0.002)	Loss 0.3262 (0.3117)	Acc@1 94.922 (96.342)	Acc@5 100.000 (99.945)
Epoch: [111][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3350 (0.3146)	Acc@1 96.484 (96.213)	Acc@5 99.609 (99.947)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.139 (0.139)	Data 0.256 (0.256)	Loss 0.3171 (0.3171)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.114 (0.111)	Data 0.000 (0.004)	Loss 0.3024 (0.3155)	Acc@1 95.703 (96.244)	Acc@5 100.000 (99.970)
Epoch: [112][128/196]	Time 0.115 (0.111)	Data 0.000 (0.002)	Loss 0.3406 (0.3114)	Acc@1 94.141 (96.233)	Acc@5 100.000 (99.958)
Epoch: [112][192/196]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3407 (0.3148)	Acc@1 95.703 (96.110)	Acc@5 99.609 (99.957)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.139 (0.139)	Data 0.305 (0.305)	Loss 0.3123 (0.3123)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.110 (0.114)	Data 0.000 (0.005)	Loss 0.3267 (0.3060)	Acc@1 95.312 (96.328)	Acc@5 100.000 (99.952)
Epoch: [113][128/196]	Time 0.112 (0.114)	Data 0.000 (0.003)	Loss 0.2968 (0.3073)	Acc@1 96.094 (96.248)	Acc@5 100.000 (99.967)
Epoch: [113][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.3362 (0.3108)	Acc@1 94.922 (96.128)	Acc@5 100.000 (99.960)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.149 (0.149)	Data 0.294 (0.294)	Loss 0.2708 (0.2708)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.114 (0.111)	Data 0.000 (0.005)	Loss 0.2945 (0.3063)	Acc@1 96.875 (96.334)	Acc@5 100.000 (99.970)
Epoch: [114][128/196]	Time 0.115 (0.110)	Data 0.000 (0.002)	Loss 0.3284 (0.3080)	Acc@1 94.531 (96.109)	Acc@5 100.000 (99.958)
Epoch: [114][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.3071 (0.3113)	Acc@1 96.484 (95.982)	Acc@5 100.000 (99.951)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.150 (0.150)	Data 0.288 (0.288)	Loss 0.3343 (0.3343)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.2766 (0.3042)	Acc@1 97.266 (96.214)	Acc@5 100.000 (99.970)
Epoch: [115][128/196]	Time 0.104 (0.111)	Data 0.000 (0.002)	Loss 0.3235 (0.3032)	Acc@1 95.312 (96.169)	Acc@5 100.000 (99.955)
Epoch: [115][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3518 (0.3100)	Acc@1 94.141 (95.934)	Acc@5 100.000 (99.937)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.51
Max memory: 84.2434048
 22.099s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3495
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.174 (0.174)	Data 0.284 (0.284)	Loss 0.3015 (0.3015)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.110 (0.112)	Data 0.000 (0.005)	Loss 0.3223 (0.3041)	Acc@1 96.094 (96.322)	Acc@5 99.609 (99.928)
Epoch: [116][128/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.2886 (0.3016)	Acc@1 96.875 (96.342)	Acc@5 100.000 (99.936)
Epoch: [116][192/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.2899 (0.3031)	Acc@1 96.484 (96.203)	Acc@5 100.000 (99.947)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.145 (0.145)	Data 0.260 (0.260)	Loss 0.3203 (0.3203)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.107 (0.110)	Data 0.000 (0.004)	Loss 0.3585 (0.2936)	Acc@1 94.141 (96.562)	Acc@5 100.000 (99.988)
Epoch: [117][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.2952 (0.2991)	Acc@1 96.875 (96.254)	Acc@5 100.000 (99.970)
Epoch: [117][192/196]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.3516 (0.3010)	Acc@1 94.141 (96.209)	Acc@5 100.000 (99.962)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.147 (0.147)	Data 0.290 (0.290)	Loss 0.3166 (0.3166)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [118][64/196]	Time 0.105 (0.110)	Data 0.000 (0.005)	Loss 0.3173 (0.3011)	Acc@1 95.703 (96.034)	Acc@5 100.000 (99.952)
Epoch: [118][128/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.2950 (0.3019)	Acc@1 96.484 (96.073)	Acc@5 100.000 (99.961)
Epoch: [118][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.2952 (0.3062)	Acc@1 95.703 (95.883)	Acc@5 100.000 (99.960)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.141 (0.141)	Data 0.302 (0.302)	Loss 0.2907 (0.2907)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.116 (0.112)	Data 0.000 (0.005)	Loss 0.2716 (0.2957)	Acc@1 96.875 (96.160)	Acc@5 100.000 (99.946)
Epoch: [119][128/196]	Time 0.109 (0.111)	Data 0.000 (0.003)	Loss 0.2872 (0.2983)	Acc@1 96.094 (96.130)	Acc@5 100.000 (99.945)
Epoch: [119][192/196]	Time 0.116 (0.110)	Data 0.000 (0.002)	Loss 0.3129 (0.2998)	Acc@1 95.703 (96.023)	Acc@5 100.000 (99.949)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.145 (0.145)	Data 0.283 (0.283)	Loss 0.2774 (0.2774)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.107 (0.110)	Data 0.000 (0.005)	Loss 0.2939 (0.2978)	Acc@1 95.312 (96.172)	Acc@5 100.000 (99.946)
Epoch: [120][128/196]	Time 0.121 (0.110)	Data 0.000 (0.002)	Loss 0.3078 (0.3018)	Acc@1 96.484 (96.133)	Acc@5 100.000 (99.942)
Epoch: [120][192/196]	Time 0.105 (0.110)	Data 0.000 (0.002)	Loss 0.3262 (0.3018)	Acc@1 94.141 (96.071)	Acc@5 100.000 (99.951)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.16
Max memory: 84.2434048
 21.854s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4873
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.167 (0.167)	Data 0.275 (0.275)	Loss 0.2983 (0.2983)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.112 (0.111)	Data 0.000 (0.004)	Loss 0.2967 (0.2918)	Acc@1 95.312 (96.388)	Acc@5 99.609 (99.940)
Epoch: [121][128/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.3108 (0.2979)	Acc@1 95.312 (96.136)	Acc@5 100.000 (99.955)
Epoch: [121][192/196]	Time 0.111 (0.110)	Data 0.000 (0.002)	Loss 0.2601 (0.2981)	Acc@1 97.266 (96.156)	Acc@5 100.000 (99.941)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.160 (0.160)	Data 0.260 (0.260)	Loss 0.2691 (0.2691)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.101 (0.111)	Data 0.000 (0.004)	Loss 0.2909 (0.2974)	Acc@1 96.484 (96.106)	Acc@5 100.000 (99.958)
Epoch: [122][128/196]	Time 0.101 (0.110)	Data 0.000 (0.002)	Loss 0.2964 (0.3018)	Acc@1 97.656 (95.967)	Acc@5 100.000 (99.958)
Epoch: [122][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.3318 (0.3032)	Acc@1 94.141 (95.883)	Acc@5 100.000 (99.953)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.150 (0.150)	Data 0.286 (0.286)	Loss 0.2682 (0.2682)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.109 (0.111)	Data 0.000 (0.005)	Loss 0.3320 (0.2941)	Acc@1 94.531 (96.130)	Acc@5 100.000 (99.976)
Epoch: [123][128/196]	Time 0.114 (0.111)	Data 0.000 (0.002)	Loss 0.3021 (0.2996)	Acc@1 95.312 (95.921)	Acc@5 100.000 (99.979)
Epoch: [123][192/196]	Time 0.113 (0.111)	Data 0.000 (0.002)	Loss 0.3213 (0.3021)	Acc@1 94.922 (95.835)	Acc@5 100.000 (99.974)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.158 (0.158)	Data 0.259 (0.259)	Loss 0.3036 (0.3036)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [124][64/196]	Time 0.102 (0.111)	Data 0.000 (0.004)	Loss 0.2628 (0.2898)	Acc@1 97.266 (96.166)	Acc@5 100.000 (99.970)
Epoch: [124][128/196]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2654 (0.2926)	Acc@1 97.266 (96.139)	Acc@5 100.000 (99.979)
Epoch: [124][192/196]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.3369 (0.2947)	Acc@1 94.141 (96.011)	Acc@5 100.000 (99.970)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.158 (0.158)	Data 0.277 (0.277)	Loss 0.2797 (0.2797)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.112 (0.113)	Data 0.000 (0.004)	Loss 0.2806 (0.3037)	Acc@1 96.484 (95.643)	Acc@5 100.000 (99.958)
Epoch: [125][128/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.2903 (0.3032)	Acc@1 96.484 (95.694)	Acc@5 100.000 (99.955)
Epoch: [125][192/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.3105 (0.3037)	Acc@1 94.922 (95.707)	Acc@5 100.000 (99.960)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.2
Max memory: 84.2434048
 22.155s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 702
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.216 (0.216)	Data 0.294 (0.294)	Loss 0.2990 (0.2990)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.107 (0.111)	Data 0.000 (0.005)	Loss 0.2422 (0.2806)	Acc@1 97.656 (96.556)	Acc@5 100.000 (99.976)
Epoch: [126][128/196]	Time 0.105 (0.109)	Data 0.000 (0.002)	Loss 0.3105 (0.2915)	Acc@1 96.094 (96.215)	Acc@5 100.000 (99.976)
Epoch: [126][192/196]	Time 0.107 (0.109)	Data 0.000 (0.002)	Loss 0.3247 (0.2990)	Acc@1 94.922 (95.932)	Acc@5 99.609 (99.960)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.118 (0.118)	Data 0.287 (0.287)	Loss 0.3803 (0.3803)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [127][64/196]	Time 0.108 (0.110)	Data 0.000 (0.005)	Loss 0.3053 (0.3032)	Acc@1 95.703 (95.799)	Acc@5 100.000 (99.964)
Epoch: [127][128/196]	Time 0.102 (0.109)	Data 0.000 (0.002)	Loss 0.3000 (0.3002)	Acc@1 96.484 (95.855)	Acc@5 100.000 (99.955)
Epoch: [127][192/196]	Time 0.111 (0.109)	Data 0.000 (0.002)	Loss 0.3123 (0.3002)	Acc@1 95.312 (95.821)	Acc@5 100.000 (99.962)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.131 (0.131)	Data 0.256 (0.256)	Loss 0.3035 (0.3035)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.114 (0.110)	Data 0.000 (0.004)	Loss 0.2965 (0.2898)	Acc@1 96.094 (96.106)	Acc@5 100.000 (99.982)
Epoch: [128][128/196]	Time 0.120 (0.111)	Data 0.000 (0.002)	Loss 0.2842 (0.2926)	Acc@1 95.703 (95.970)	Acc@5 100.000 (99.967)
Epoch: [128][192/196]	Time 0.110 (0.111)	Data 0.000 (0.001)	Loss 0.3069 (0.2978)	Acc@1 94.531 (95.798)	Acc@5 100.000 (99.957)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.157 (0.157)	Data 0.301 (0.301)	Loss 0.2970 (0.2970)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.109 (0.111)	Data 0.000 (0.005)	Loss 0.3235 (0.2996)	Acc@1 94.531 (95.631)	Acc@5 100.000 (99.970)
Epoch: [129][128/196]	Time 0.119 (0.111)	Data 0.000 (0.002)	Loss 0.3445 (0.2991)	Acc@1 94.922 (95.667)	Acc@5 100.000 (99.967)
Epoch: [129][192/196]	Time 0.113 (0.111)	Data 0.000 (0.002)	Loss 0.2883 (0.3000)	Acc@1 94.922 (95.683)	Acc@5 100.000 (99.964)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.127 (0.127)	Data 0.256 (0.256)	Loss 0.2629 (0.2629)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.115 (0.111)	Data 0.000 (0.004)	Loss 0.2487 (0.2961)	Acc@1 97.656 (95.901)	Acc@5 100.000 (99.964)
Epoch: [130][128/196]	Time 0.114 (0.111)	Data 0.000 (0.002)	Loss 0.3583 (0.2981)	Acc@1 93.750 (95.703)	Acc@5 100.000 (99.970)
Epoch: [130][192/196]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2537 (0.2988)	Acc@1 97.656 (95.651)	Acc@5 100.000 (99.964)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.38
Max memory: 84.2434048
 21.952s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 584
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.182 (0.182)	Data 0.265 (0.265)	Loss 0.2368 (0.2368)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.112 (0.111)	Data 0.000 (0.004)	Loss 0.3010 (0.2835)	Acc@1 96.484 (96.418)	Acc@5 100.000 (99.964)
Epoch: [131][128/196]	Time 0.107 (0.110)	Data 0.000 (0.002)	Loss 0.2471 (0.2891)	Acc@1 98.047 (96.127)	Acc@5 100.000 (99.961)
Epoch: [131][192/196]	Time 0.116 (0.110)	Data 0.000 (0.002)	Loss 0.4389 (0.2945)	Acc@1 91.016 (95.962)	Acc@5 100.000 (99.951)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.167 (0.167)	Data 0.324 (0.324)	Loss 0.2592 (0.2592)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.113 (0.111)	Data 0.000 (0.005)	Loss 0.2712 (0.2932)	Acc@1 97.656 (95.980)	Acc@5 100.000 (99.964)
Epoch: [132][128/196]	Time 0.109 (0.111)	Data 0.000 (0.003)	Loss 0.2880 (0.2956)	Acc@1 96.484 (95.897)	Acc@5 100.000 (99.961)
Epoch: [132][192/196]	Time 0.121 (0.111)	Data 0.000 (0.002)	Loss 0.3294 (0.2972)	Acc@1 94.141 (95.814)	Acc@5 100.000 (99.951)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.163 (0.163)	Data 0.293 (0.293)	Loss 0.2913 (0.2913)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.110 (0.115)	Data 0.000 (0.005)	Loss 0.3470 (0.2929)	Acc@1 94.922 (95.962)	Acc@5 99.609 (99.940)
Epoch: [133][128/196]	Time 0.112 (0.113)	Data 0.000 (0.002)	Loss 0.2706 (0.2964)	Acc@1 96.484 (95.694)	Acc@5 100.000 (99.945)
Epoch: [133][192/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.2887 (0.2982)	Acc@1 96.094 (95.638)	Acc@5 100.000 (99.951)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.165 (0.165)	Data 0.250 (0.250)	Loss 0.3192 (0.3192)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.110 (0.111)	Data 0.000 (0.004)	Loss 0.2931 (0.2970)	Acc@1 96.484 (95.913)	Acc@5 100.000 (99.946)
Epoch: [134][128/196]	Time 0.113 (0.111)	Data 0.000 (0.002)	Loss 0.2875 (0.2962)	Acc@1 96.484 (95.900)	Acc@5 100.000 (99.955)
Epoch: [134][192/196]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3324 (0.3009)	Acc@1 93.359 (95.677)	Acc@5 100.000 (99.951)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.152 (0.152)	Data 0.280 (0.280)	Loss 0.3498 (0.3498)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.111 (0.112)	Data 0.000 (0.004)	Loss 0.2597 (0.2859)	Acc@1 97.266 (96.280)	Acc@5 100.000 (99.964)
Epoch: [135][128/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.3086 (0.2915)	Acc@1 95.703 (96.009)	Acc@5 100.000 (99.967)
Epoch: [135][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.3479 (0.2988)	Acc@1 94.922 (95.715)	Acc@5 99.609 (99.960)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.37
Max memory: 84.2434048
 22.195s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7329
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.171 (0.171)	Data 0.292 (0.292)	Loss 0.3392 (0.3392)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [136][64/196]	Time 0.127 (0.113)	Data 0.000 (0.005)	Loss 0.2836 (0.2836)	Acc@1 96.875 (96.160)	Acc@5 100.000 (99.958)
Epoch: [136][128/196]	Time 0.109 (0.112)	Data 0.000 (0.002)	Loss 0.3104 (0.2866)	Acc@1 94.922 (95.991)	Acc@5 100.000 (99.952)
Epoch: [136][192/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.2620 (0.2906)	Acc@1 96.484 (95.897)	Acc@5 100.000 (99.953)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.139 (0.139)	Data 0.284 (0.284)	Loss 0.2824 (0.2824)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.112 (0.112)	Data 0.000 (0.005)	Loss 0.3351 (0.2994)	Acc@1 94.531 (95.499)	Acc@5 100.000 (99.958)
Epoch: [137][128/196]	Time 0.112 (0.111)	Data 0.000 (0.002)	Loss 0.3017 (0.2971)	Acc@1 95.703 (95.618)	Acc@5 99.609 (99.958)
Epoch: [137][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.2855 (0.3023)	Acc@1 96.484 (95.456)	Acc@5 100.000 (99.953)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.190 (0.190)	Data 0.330 (0.330)	Loss 0.2912 (0.2912)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.112 (0.114)	Data 0.000 (0.005)	Loss 0.2991 (0.2941)	Acc@1 95.703 (95.667)	Acc@5 100.000 (99.976)
Epoch: [138][128/196]	Time 0.126 (0.113)	Data 0.000 (0.003)	Loss 0.2979 (0.2918)	Acc@1 95.312 (95.800)	Acc@5 100.000 (99.964)
Epoch: [138][192/196]	Time 0.114 (0.113)	Data 0.000 (0.002)	Loss 0.3416 (0.2952)	Acc@1 95.312 (95.695)	Acc@5 100.000 (99.964)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.148 (0.148)	Data 0.271 (0.271)	Loss 0.2933 (0.2933)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.110 (0.113)	Data 0.000 (0.004)	Loss 0.3125 (0.2999)	Acc@1 95.312 (95.583)	Acc@5 100.000 (99.964)
Epoch: [139][128/196]	Time 0.115 (0.111)	Data 0.000 (0.002)	Loss 0.3312 (0.3035)	Acc@1 94.531 (95.415)	Acc@5 100.000 (99.961)
Epoch: [139][192/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.2604 (0.3016)	Acc@1 97.266 (95.517)	Acc@5 100.000 (99.960)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.142 (0.142)	Data 0.251 (0.251)	Loss 0.2856 (0.2856)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.106 (0.112)	Data 0.000 (0.004)	Loss 0.2640 (0.2974)	Acc@1 95.703 (95.457)	Acc@5 100.000 (99.970)
Epoch: [140][128/196]	Time 0.103 (0.113)	Data 0.000 (0.002)	Loss 0.3435 (0.3000)	Acc@1 95.312 (95.485)	Acc@5 100.000 (99.967)
Epoch: [140][192/196]	Time 0.113 (0.112)	Data 0.000 (0.001)	Loss 0.3047 (0.3010)	Acc@1 95.312 (95.489)	Acc@5 99.219 (99.964)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.03
Max memory: 84.2434048
 22.283s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8875
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.179 (0.179)	Data 0.244 (0.244)	Loss 0.3146 (0.3146)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.111 (0.112)	Data 0.000 (0.004)	Loss 0.2570 (0.2881)	Acc@1 96.484 (95.931)	Acc@5 100.000 (99.958)
Epoch: [141][128/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.3125 (0.2960)	Acc@1 95.703 (95.655)	Acc@5 100.000 (99.967)
Epoch: [141][192/196]	Time 0.109 (0.110)	Data 0.000 (0.001)	Loss 0.2999 (0.2976)	Acc@1 94.922 (95.618)	Acc@5 100.000 (99.966)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.131 (0.131)	Data 0.296 (0.296)	Loss 0.3180 (0.3180)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.107 (0.111)	Data 0.000 (0.005)	Loss 0.2469 (0.2829)	Acc@1 98.438 (96.226)	Acc@5 100.000 (99.982)
Epoch: [142][128/196]	Time 0.113 (0.110)	Data 0.000 (0.002)	Loss 0.2607 (0.2859)	Acc@1 96.875 (96.127)	Acc@5 100.000 (99.964)
Epoch: [142][192/196]	Time 0.114 (0.110)	Data 0.000 (0.002)	Loss 0.2735 (0.2925)	Acc@1 95.703 (95.881)	Acc@5 100.000 (99.962)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.115 (0.115)	Data 0.286 (0.286)	Loss 0.2727 (0.2727)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.114 (0.110)	Data 0.000 (0.005)	Loss 0.3336 (0.3043)	Acc@1 95.312 (95.523)	Acc@5 100.000 (99.952)
Epoch: [143][128/196]	Time 0.121 (0.111)	Data 0.000 (0.002)	Loss 0.3472 (0.3026)	Acc@1 93.359 (95.555)	Acc@5 100.000 (99.958)
Epoch: [143][192/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3105 (0.3021)	Acc@1 95.703 (95.553)	Acc@5 100.000 (99.968)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.180 (0.180)	Data 0.264 (0.264)	Loss 0.2719 (0.2719)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.110 (0.112)	Data 0.000 (0.004)	Loss 0.2934 (0.2932)	Acc@1 96.484 (95.913)	Acc@5 100.000 (99.952)
Epoch: [144][128/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.2586 (0.2945)	Acc@1 98.047 (95.827)	Acc@5 100.000 (99.958)
Epoch: [144][192/196]	Time 0.114 (0.111)	Data 0.000 (0.002)	Loss 0.2716 (0.2969)	Acc@1 96.875 (95.731)	Acc@5 100.000 (99.964)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.151 (0.151)	Data 0.256 (0.256)	Loss 0.2604 (0.2604)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.115 (0.112)	Data 0.000 (0.004)	Loss 0.2632 (0.2889)	Acc@1 96.094 (95.847)	Acc@5 100.000 (99.976)
Epoch: [145][128/196]	Time 0.106 (0.112)	Data 0.000 (0.002)	Loss 0.3687 (0.2913)	Acc@1 93.359 (95.739)	Acc@5 99.609 (99.967)
Epoch: [145][192/196]	Time 0.111 (0.111)	Data 0.000 (0.001)	Loss 0.3434 (0.2929)	Acc@1 92.969 (95.719)	Acc@5 100.000 (99.966)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.96
Max memory: 84.2434048
 22.076s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4121
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.137984
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.178 (0.178)	Data 0.250 (0.250)	Loss 0.2831 (0.2831)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.109 (0.113)	Data 0.000 (0.004)	Loss 0.2900 (0.2789)	Acc@1 96.875 (96.244)	Acc@5 100.000 (99.988)
Epoch: [146][128/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.2598 (0.2873)	Acc@1 96.875 (95.942)	Acc@5 99.609 (99.970)
Epoch: [146][192/196]	Time 0.112 (0.111)	Data 0.000 (0.001)	Loss 0.3302 (0.2939)	Acc@1 94.141 (95.703)	Acc@5 100.000 (99.966)
Max memory in training epoch: 54.0575232
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.157 (0.157)	Data 0.258 (0.258)	Loss 0.2925 (0.2925)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.109 (0.112)	Data 0.000 (0.004)	Loss 0.3071 (0.2844)	Acc@1 95.312 (96.232)	Acc@5 100.000 (99.964)
Epoch: [147][128/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.2526 (0.2905)	Acc@1 97.266 (95.948)	Acc@5 100.000 (99.964)
Epoch: [147][192/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.3343 (0.2936)	Acc@1 93.750 (95.772)	Acc@5 100.000 (99.962)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.151 (0.151)	Data 0.261 (0.261)	Loss 0.2822 (0.2822)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.109 (0.112)	Data 0.000 (0.004)	Loss 0.2757 (0.3072)	Acc@1 97.266 (95.319)	Acc@5 100.000 (99.934)
Epoch: [148][128/196]	Time 0.112 (0.112)	Data 0.000 (0.002)	Loss 0.2403 (0.3014)	Acc@1 98.828 (95.515)	Acc@5 100.000 (99.952)
Epoch: [148][192/196]	Time 0.111 (0.112)	Data 0.000 (0.002)	Loss 0.3702 (0.3006)	Acc@1 91.797 (95.515)	Acc@5 100.000 (99.966)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.166 (0.166)	Data 0.261 (0.261)	Loss 0.2796 (0.2796)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [149][64/196]	Time 0.107 (0.111)	Data 0.000 (0.004)	Loss 0.2764 (0.2958)	Acc@1 97.266 (95.793)	Acc@5 100.000 (99.958)
Epoch: [149][128/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.3124 (0.2954)	Acc@1 95.312 (95.709)	Acc@5 100.000 (99.945)
Epoch: [149][192/196]	Time 0.109 (0.111)	Data 0.000 (0.002)	Loss 0.3006 (0.2988)	Acc@1 95.312 (95.582)	Acc@5 99.609 (99.941)
Max memory in training epoch: 53.9002368
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.143 (0.143)	Data 0.295 (0.295)	Loss 0.2454 (0.2454)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.120 (0.112)	Data 0.000 (0.005)	Loss 0.2452 (0.2605)	Acc@1 98.047 (97.097)	Acc@5 100.000 (99.982)
Epoch: [150][128/196]	Time 0.110 (0.113)	Data 0.000 (0.002)	Loss 0.2233 (0.2526)	Acc@1 98.828 (97.408)	Acc@5 100.000 (99.988)
Epoch: [150][192/196]	Time 0.115 (0.112)	Data 0.000 (0.002)	Loss 0.2202 (0.2495)	Acc@1 97.656 (97.517)	Acc@5 100.000 (99.988)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.17
Max memory: 84.2434048
 22.375s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6878
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.137984
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.191 (0.191)	Data 0.248 (0.248)	Loss 0.1990 (0.1990)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.122 (0.111)	Data 0.000 (0.004)	Loss 0.2458 (0.2354)	Acc@1 98.438 (98.077)	Acc@5 100.000 (99.988)
Epoch: [151][128/196]	Time 0.107 (0.110)	Data 0.000 (0.002)	Loss 0.2305 (0.2345)	Acc@1 98.047 (98.077)	Acc@5 100.000 (99.988)
Epoch: [151][192/196]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2341 (0.2324)	Acc@1 98.047 (98.195)	Acc@5 100.000 (99.992)
Max memory in training epoch: 54.0575232
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.138 (0.138)	Data 0.253 (0.253)	Loss 0.2433 (0.2433)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.104 (0.111)	Data 0.000 (0.004)	Loss 0.2260 (0.2289)	Acc@1 98.047 (98.233)	Acc@5 100.000 (100.000)
Epoch: [152][128/196]	Time 0.110 (0.111)	Data 0.000 (0.002)	Loss 0.2431 (0.2270)	Acc@1 97.656 (98.307)	Acc@5 100.000 (99.997)
Epoch: [152][192/196]	Time 0.105 (0.110)	Data 0.000 (0.001)	Loss 0.2051 (0.2263)	Acc@1 98.828 (98.318)	Acc@5 100.000 (99.996)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.150 (0.150)	Data 0.284 (0.284)	Loss 0.2064 (0.2064)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.110 (0.111)	Data 0.000 (0.005)	Loss 0.2167 (0.2181)	Acc@1 98.828 (98.618)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.124 (0.110)	Data 0.000 (0.002)	Loss 0.2351 (0.2176)	Acc@1 98.047 (98.631)	Acc@5 100.000 (99.991)
Epoch: [153][192/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.2003 (0.2186)	Acc@1 99.609 (98.614)	Acc@5 100.000 (99.992)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.153 (0.153)	Data 0.277 (0.277)	Loss 0.2289 (0.2289)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.105 (0.112)	Data 0.000 (0.004)	Loss 0.2293 (0.2131)	Acc@1 97.656 (98.774)	Acc@5 100.000 (99.994)
Epoch: [154][128/196]	Time 0.106 (0.112)	Data 0.000 (0.002)	Loss 0.1962 (0.2136)	Acc@1 99.609 (98.774)	Acc@5 100.000 (99.997)
Epoch: [154][192/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.2077 (0.2139)	Acc@1 99.219 (98.737)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.151 (0.151)	Data 0.285 (0.285)	Loss 0.2253 (0.2253)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.110 (0.111)	Data 0.000 (0.005)	Loss 0.2101 (0.2132)	Acc@1 98.047 (98.654)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.111 (0.110)	Data 0.000 (0.002)	Loss 0.2039 (0.2124)	Acc@1 99.219 (98.725)	Acc@5 100.000 (100.000)
Epoch: [155][192/196]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.2182 (0.2123)	Acc@1 98.438 (98.739)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.65
Max memory: 84.2434048
 22.006s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3343
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.137984
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.206 (0.206)	Data 0.284 (0.284)	Loss 0.1896 (0.1896)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.114 (0.113)	Data 0.000 (0.005)	Loss 0.2003 (0.2091)	Acc@1 98.828 (98.888)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.2009 (0.2094)	Acc@1 99.219 (98.855)	Acc@5 100.000 (100.000)
Epoch: [156][192/196]	Time 0.107 (0.111)	Data 0.000 (0.002)	Loss 0.2263 (0.2096)	Acc@1 97.266 (98.832)	Acc@5 100.000 (99.998)
Max memory in training epoch: 54.0575232
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.146 (0.146)	Data 0.254 (0.254)	Loss 0.1957 (0.1957)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.103 (0.110)	Data 0.000 (0.004)	Loss 0.2116 (0.2053)	Acc@1 98.828 (99.111)	Acc@5 100.000 (99.994)
Epoch: [157][128/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.2004 (0.2049)	Acc@1 99.219 (99.070)	Acc@5 100.000 (99.994)
Epoch: [157][192/196]	Time 0.108 (0.110)	Data 0.000 (0.001)	Loss 0.2066 (0.2062)	Acc@1 98.828 (98.988)	Acc@5 100.000 (99.996)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.143 (0.143)	Data 0.256 (0.256)	Loss 0.1924 (0.1924)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.107 (0.111)	Data 0.000 (0.004)	Loss 0.1957 (0.2018)	Acc@1 99.219 (99.201)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.111 (0.111)	Data 0.000 (0.002)	Loss 0.2108 (0.2041)	Acc@1 99.219 (99.064)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.2044 (0.2046)	Acc@1 98.828 (99.004)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.163 (0.163)	Data 0.282 (0.282)	Loss 0.2352 (0.2352)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.106 (0.112)	Data 0.000 (0.005)	Loss 0.2216 (0.2045)	Acc@1 98.828 (99.056)	Acc@5 100.000 (99.994)
Epoch: [159][128/196]	Time 0.113 (0.111)	Data 0.000 (0.002)	Loss 0.2047 (0.2036)	Acc@1 98.828 (99.061)	Acc@5 100.000 (99.994)
Epoch: [159][192/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.1975 (0.2037)	Acc@1 99.609 (99.053)	Acc@5 100.000 (99.996)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.152 (0.152)	Data 0.286 (0.286)	Loss 0.2066 (0.2066)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.106 (0.112)	Data 0.000 (0.005)	Loss 0.1979 (0.2021)	Acc@1 99.219 (99.075)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.110 (0.112)	Data 0.000 (0.002)	Loss 0.2285 (0.2012)	Acc@1 98.047 (99.110)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.114 (0.112)	Data 0.000 (0.002)	Loss 0.2212 (0.2012)	Acc@1 98.438 (99.089)	Acc@5 100.000 (99.994)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.88
Max memory: 84.2434048
 22.296s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4756
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.137984
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.186 (0.186)	Data 0.282 (0.282)	Loss 0.2140 (0.2140)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.105 (0.111)	Data 0.000 (0.005)	Loss 0.2003 (0.2000)	Acc@1 99.219 (99.165)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.1873 (0.2000)	Acc@1 99.609 (99.137)	Acc@5 100.000 (99.997)
Epoch: [161][192/196]	Time 0.123 (0.110)	Data 0.000 (0.002)	Loss 0.1814 (0.2001)	Acc@1 100.000 (99.109)	Acc@5 100.000 (99.998)
Max memory in training epoch: 54.0575232
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.162 (0.162)	Data 0.276 (0.276)	Loss 0.1827 (0.1827)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.108 (0.111)	Data 0.000 (0.004)	Loss 0.2168 (0.1971)	Acc@1 98.828 (99.159)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.113 (0.110)	Data 0.000 (0.002)	Loss 0.1919 (0.1977)	Acc@1 99.219 (99.170)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.108 (0.110)	Data 0.000 (0.002)	Loss 0.1992 (0.1973)	Acc@1 98.828 (99.174)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.149 (0.149)	Data 0.268 (0.268)	Loss 0.2013 (0.2013)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.114 (0.110)	Data 0.000 (0.004)	Loss 0.1908 (0.1982)	Acc@1 99.609 (99.171)	Acc@5 100.000 (100.000)
Epoch: [163][128/196]	Time 0.104 (0.110)	Data 0.000 (0.002)	Loss 0.2014 (0.1970)	Acc@1 98.828 (99.198)	Acc@5 100.000 (100.000)
Epoch: [163][192/196]	Time 0.111 (0.110)	Data 0.000 (0.002)	Loss 0.2002 (0.1965)	Acc@1 99.609 (99.223)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.167 (0.167)	Data 0.268 (0.268)	Loss 0.1810 (0.1810)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.109 (0.111)	Data 0.000 (0.004)	Loss 0.1858 (0.1940)	Acc@1 100.000 (99.363)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.2092 (0.1950)	Acc@1 98.828 (99.304)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.124 (0.111)	Data 0.000 (0.002)	Loss 0.1923 (0.1952)	Acc@1 99.219 (99.275)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.151 (0.151)	Data 0.300 (0.300)	Loss 0.1847 (0.1847)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.109 (0.112)	Data 0.000 (0.005)	Loss 0.1907 (0.1936)	Acc@1 98.828 (99.273)	Acc@5 100.000 (99.994)
Epoch: [165][128/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.1962 (0.1946)	Acc@1 99.219 (99.213)	Acc@5 100.000 (99.994)
Epoch: [165][192/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.2233 (0.1948)	Acc@1 97.656 (99.213)	Acc@5 100.000 (99.996)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.58
Max memory: 84.2434048
 21.982s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 567
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.137984
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.163 (0.163)	Data 0.280 (0.280)	Loss 0.2010 (0.2010)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.112 (0.109)	Data 0.000 (0.004)	Loss 0.1856 (0.1948)	Acc@1 99.609 (99.207)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.109 (0.109)	Data 0.000 (0.002)	Loss 0.1753 (0.1940)	Acc@1 100.000 (99.237)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.110 (0.109)	Data 0.000 (0.002)	Loss 0.1923 (0.1932)	Acc@1 99.219 (99.271)	Acc@5 100.000 (99.998)
Max memory in training epoch: 54.0575232
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.150 (0.150)	Data 0.329 (0.329)	Loss 0.1945 (0.1945)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.110 (0.108)	Data 0.000 (0.005)	Loss 0.1889 (0.1899)	Acc@1 99.609 (99.453)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.104 (0.109)	Data 0.000 (0.003)	Loss 0.1831 (0.1912)	Acc@1 100.000 (99.367)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.112 (0.109)	Data 0.000 (0.002)	Loss 0.1916 (0.1912)	Acc@1 99.609 (99.350)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.159 (0.159)	Data 0.286 (0.286)	Loss 0.1769 (0.1769)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.112 (0.110)	Data 0.000 (0.005)	Loss 0.1858 (0.1898)	Acc@1 99.609 (99.357)	Acc@5 100.000 (99.994)
Epoch: [168][128/196]	Time 0.109 (0.110)	Data 0.000 (0.002)	Loss 0.1871 (0.1894)	Acc@1 100.000 (99.364)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.113 (0.110)	Data 0.000 (0.002)	Loss 0.1894 (0.1899)	Acc@1 99.609 (99.340)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.165 (0.165)	Data 0.282 (0.282)	Loss 0.1792 (0.1792)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.103 (0.110)	Data 0.000 (0.004)	Loss 0.1756 (0.1895)	Acc@1 100.000 (99.387)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.110 (0.109)	Data 0.000 (0.002)	Loss 0.1882 (0.1906)	Acc@1 99.609 (99.352)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.1854 (0.1906)	Acc@1 99.219 (99.326)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.124 (0.124)	Data 0.252 (0.252)	Loss 0.1791 (0.1791)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.109 (0.111)	Data 0.000 (0.004)	Loss 0.1817 (0.1893)	Acc@1 99.609 (99.291)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.108 (0.111)	Data 0.000 (0.002)	Loss 0.1828 (0.1885)	Acc@1 98.828 (99.301)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.111 (0.110)	Data 0.000 (0.001)	Loss 0.1919 (0.1889)	Acc@1 98.828 (99.308)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.62
Max memory: 84.2434048
 21.950s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 302
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.137984
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.174 (0.174)	Data 0.272 (0.272)	Loss 0.1834 (0.1834)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.110 (0.110)	Data 0.000 (0.004)	Loss 0.1861 (0.1879)	Acc@1 99.219 (99.333)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.112 (0.109)	Data 0.000 (0.002)	Loss 0.1832 (0.1874)	Acc@1 98.828 (99.370)	Acc@5 100.000 (99.997)
Epoch: [171][192/196]	Time 0.108 (0.109)	Data 0.000 (0.002)	Loss 0.1848 (0.1873)	Acc@1 99.219 (99.401)	Acc@5 100.000 (99.998)
Max memory in training epoch: 54.0575232
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.128 (0.128)	Data 0.299 (0.299)	Loss 0.1747 (0.1747)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.109 (0.109)	Data 0.000 (0.005)	Loss 0.1789 (0.1870)	Acc@1 99.609 (99.369)	Acc@5 100.000 (99.994)
Epoch: [172][128/196]	Time 0.107 (0.108)	Data 0.000 (0.002)	Loss 0.1884 (0.1864)	Acc@1 98.828 (99.422)	Acc@5 100.000 (99.997)
Epoch: [172][192/196]	Time 0.106 (0.108)	Data 0.000 (0.002)	Loss 0.1752 (0.1871)	Acc@1 100.000 (99.383)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.159 (0.159)	Data 0.268 (0.268)	Loss 0.2031 (0.2031)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.114 (0.110)	Data 0.000 (0.004)	Loss 0.1958 (0.1854)	Acc@1 98.438 (99.435)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.110 (0.110)	Data 0.000 (0.002)	Loss 0.1785 (0.1864)	Acc@1 100.000 (99.382)	Acc@5 100.000 (99.997)
Epoch: [173][192/196]	Time 0.106 (0.110)	Data 0.000 (0.002)	Loss 0.1740 (0.1864)	Acc@1 100.000 (99.385)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.144 (0.144)	Data 0.284 (0.284)	Loss 0.1886 (0.1886)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.107 (0.109)	Data 0.000 (0.005)	Loss 0.1824 (0.1845)	Acc@1 99.609 (99.441)	Acc@5 100.000 (99.994)
Epoch: [174][128/196]	Time 0.102 (0.109)	Data 0.000 (0.002)	Loss 0.1750 (0.1846)	Acc@1 99.609 (99.422)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.103 (0.109)	Data 0.000 (0.002)	Loss 0.1790 (0.1847)	Acc@1 100.000 (99.435)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.145 (0.145)	Data 0.256 (0.256)	Loss 0.1782 (0.1782)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.109 (0.111)	Data 0.000 (0.004)	Loss 0.1706 (0.1846)	Acc@1 100.000 (99.435)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.1952 (0.1840)	Acc@1 99.219 (99.452)	Acc@5 100.000 (99.997)
Epoch: [175][192/196]	Time 0.105 (0.110)	Data 0.000 (0.001)	Loss 0.1752 (0.1847)	Acc@1 100.000 (99.427)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.62
Max memory: 84.2434048
 21.941s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8201
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.137984
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.182 (0.182)	Data 0.282 (0.282)	Loss 0.1811 (0.1811)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.111 (0.111)	Data 0.000 (0.005)	Loss 0.1809 (0.1832)	Acc@1 99.219 (99.501)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.146 (0.111)	Data 0.000 (0.002)	Loss 0.1932 (0.1839)	Acc@1 99.219 (99.434)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.106 (0.111)	Data 0.000 (0.002)	Loss 0.1708 (0.1841)	Acc@1 100.000 (99.437)	Acc@5 100.000 (100.000)
Max memory in training epoch: 54.0575232
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.146 (0.146)	Data 0.254 (0.254)	Loss 0.1782 (0.1782)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.108 (0.109)	Data 0.000 (0.004)	Loss 0.1831 (0.1805)	Acc@1 99.609 (99.483)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.118 (0.110)	Data 0.000 (0.002)	Loss 0.1802 (0.1819)	Acc@1 99.609 (99.434)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.110 (0.110)	Data 0.000 (0.001)	Loss 0.1922 (0.1826)	Acc@1 99.219 (99.409)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.142 (0.142)	Data 0.283 (0.283)	Loss 0.1818 (0.1818)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.107 (0.112)	Data 0.000 (0.005)	Loss 0.1801 (0.1818)	Acc@1 99.609 (99.465)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.105 (0.111)	Data 0.000 (0.002)	Loss 0.1809 (0.1822)	Acc@1 99.609 (99.419)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.112 (0.110)	Data 0.000 (0.002)	Loss 0.1732 (0.1819)	Acc@1 100.000 (99.445)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.146 (0.146)	Data 0.283 (0.283)	Loss 0.1778 (0.1778)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.111 (0.115)	Data 0.000 (0.005)	Loss 0.1697 (0.1807)	Acc@1 99.609 (99.459)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.116 (0.114)	Data 0.000 (0.002)	Loss 0.1756 (0.1810)	Acc@1 99.609 (99.452)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.113 (0.113)	Data 0.000 (0.002)	Loss 0.1918 (0.1805)	Acc@1 99.219 (99.490)	Acc@5 100.000 (100.000)
Max memory in training epoch: 53.9002368
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.130 (0.130)	Data 0.275 (0.275)	Loss 0.1687 (0.1687)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.112 (0.112)	Data 0.000 (0.004)	Loss 0.1863 (0.1813)	Acc@1 99.219 (99.441)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.108 (0.112)	Data 0.000 (0.002)	Loss 0.1885 (0.1812)	Acc@1 98.828 (99.406)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.105 (0.112)	Data 0.000 (0.002)	Loss 0.1826 (0.1803)	Acc@1 99.219 (99.474)	Acc@5 100.000 (99.998)
Max memory in training epoch: 53.9002368
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 27, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(27, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 29, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(27, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(33, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): AdaptiveAvgPool2d(output_size=(1, 1))
    (55): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.84
Max memory: 84.2434048
 22.289s  Thres 0.0001 4
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5517
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.207 (0.207)	Data 0.294 (0.294)	Loss 3.3922 (3.3922)	Acc@1 9.375 (9.375)	Acc@5 49.219 (49.219)
Epoch: [1][64/196]	Time 0.131 (0.132)	Data 0.000 (0.005)	Loss 2.4474 (2.6671)	Acc@1 32.422 (25.853)	Acc@5 84.766 (78.546)
Epoch: [1][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 2.3505 (2.5080)	Acc@1 37.500 (30.720)	Acc@5 89.453 (83.282)
Epoch: [1][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 2.0799 (2.3861)	Acc@1 46.484 (34.917)	Acc@5 90.234 (86.020)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.167 (0.167)	Data 0.301 (0.301)	Loss 1.8857 (1.8857)	Acc@1 56.250 (56.250)	Acc@5 96.094 (96.094)
Epoch: [2][64/196]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 1.9101 (1.9857)	Acc@1 48.438 (48.065)	Acc@5 94.531 (92.981)
Epoch: [2][128/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 1.9110 (1.9093)	Acc@1 50.781 (50.984)	Acc@5 92.188 (93.626)
Epoch: [2][192/196]	Time 0.122 (0.131)	Data 0.000 (0.002)	Loss 1.6245 (1.8398)	Acc@1 58.594 (53.459)	Acc@5 96.875 (94.177)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.177 (0.177)	Data 0.277 (0.277)	Loss 1.6248 (1.6248)	Acc@1 59.375 (59.375)	Acc@5 94.922 (94.922)
Epoch: [3][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 1.5429 (1.5864)	Acc@1 63.672 (61.905)	Acc@5 96.484 (96.106)
Epoch: [3][128/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.3980 (1.5295)	Acc@1 64.844 (63.611)	Acc@5 96.094 (96.484)
Epoch: [3][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 1.4000 (1.4871)	Acc@1 70.312 (64.874)	Acc@5 94.922 (96.741)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.177 (0.177)	Data 0.302 (0.302)	Loss 1.3021 (1.3021)	Acc@1 71.094 (71.094)	Acc@5 98.438 (98.438)
Epoch: [4][64/196]	Time 0.125 (0.133)	Data 0.000 (0.005)	Loss 1.2198 (1.3128)	Acc@1 73.438 (70.150)	Acc@5 96.875 (97.674)
Epoch: [4][128/196]	Time 0.137 (0.131)	Data 0.000 (0.003)	Loss 1.2743 (1.2825)	Acc@1 69.922 (70.842)	Acc@5 99.219 (97.908)
Epoch: [4][192/196]	Time 0.127 (0.131)	Data 0.000 (0.002)	Loss 1.0560 (1.2630)	Acc@1 75.391 (71.290)	Acc@5 100.000 (97.915)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.166 (0.166)	Data 0.284 (0.284)	Loss 1.1036 (1.1036)	Acc@1 73.438 (73.438)	Acc@5 98.438 (98.438)
Epoch: [5][64/196]	Time 0.143 (0.133)	Data 0.000 (0.005)	Loss 1.2486 (1.1665)	Acc@1 69.141 (73.930)	Acc@5 99.219 (98.365)
Epoch: [5][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 1.2099 (1.1417)	Acc@1 73.047 (74.697)	Acc@5 97.656 (98.368)
Epoch: [5][192/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.9567 (1.1226)	Acc@1 83.203 (75.221)	Acc@5 99.609 (98.403)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  69.35
Max memory: 103.3835008
 26.060s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3799
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.200 (0.200)	Data 0.284 (0.284)	Loss 1.0854 (1.0854)	Acc@1 72.656 (72.656)	Acc@5 99.219 (99.219)
Epoch: [6][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 1.0370 (1.0500)	Acc@1 79.297 (77.272)	Acc@5 97.266 (98.498)
Epoch: [6][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 0.9675 (1.0316)	Acc@1 80.859 (77.689)	Acc@5 98.047 (98.589)
Epoch: [6][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 1.0003 (1.0180)	Acc@1 76.172 (78.012)	Acc@5 97.656 (98.634)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.168 (0.168)	Data 0.298 (0.298)	Loss 0.9664 (0.9664)	Acc@1 78.125 (78.125)	Acc@5 99.219 (99.219)
Epoch: [7][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.8991 (0.9599)	Acc@1 82.422 (79.044)	Acc@5 98.828 (98.894)
Epoch: [7][128/196]	Time 0.130 (0.130)	Data 0.000 (0.002)	Loss 1.0026 (0.9618)	Acc@1 76.953 (78.873)	Acc@5 99.219 (98.834)
Epoch: [7][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.8962 (0.9567)	Acc@1 80.859 (78.916)	Acc@5 98.828 (98.846)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.187 (0.187)	Data 0.290 (0.290)	Loss 0.9013 (0.9013)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.128 (0.133)	Data 0.000 (0.005)	Loss 0.7517 (0.9186)	Acc@1 83.594 (79.808)	Acc@5 99.609 (98.984)
Epoch: [8][128/196]	Time 0.120 (0.131)	Data 0.000 (0.002)	Loss 0.8146 (0.9101)	Acc@1 82.422 (79.993)	Acc@5 99.219 (98.995)
Epoch: [8][192/196]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.9093 (0.8998)	Acc@1 80.859 (80.242)	Acc@5 99.609 (98.992)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.188 (0.188)	Data 0.274 (0.274)	Loss 0.8624 (0.8624)	Acc@1 80.078 (80.078)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 0.130 (0.135)	Data 0.000 (0.004)	Loss 0.8499 (0.8855)	Acc@1 80.859 (80.210)	Acc@5 98.828 (99.002)
Epoch: [9][128/196]	Time 0.129 (0.133)	Data 0.000 (0.002)	Loss 0.8497 (0.8720)	Acc@1 80.859 (80.732)	Acc@5 99.609 (98.980)
Epoch: [9][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.8484 (0.8745)	Acc@1 80.859 (80.697)	Acc@5 99.219 (98.964)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.184 (0.184)	Data 0.268 (0.268)	Loss 0.7954 (0.7954)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [10][64/196]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.8510 (0.8486)	Acc@1 80.859 (81.364)	Acc@5 98.828 (99.207)
Epoch: [10][128/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.8614 (0.8454)	Acc@1 81.641 (81.653)	Acc@5 99.609 (99.140)
Epoch: [10][192/196]	Time 0.136 (0.132)	Data 0.000 (0.002)	Loss 0.9335 (0.8416)	Acc@1 80.859 (81.754)	Acc@5 98.047 (99.079)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  75.85
Max memory: 103.3833984
 26.241s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5252
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.214 (0.214)	Data 0.284 (0.284)	Loss 0.8449 (0.8449)	Acc@1 80.469 (80.469)	Acc@5 98.828 (98.828)
Epoch: [11][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.8629 (0.8010)	Acc@1 81.250 (82.993)	Acc@5 99.609 (99.195)
Epoch: [11][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7319 (0.8147)	Acc@1 84.766 (82.531)	Acc@5 99.219 (99.149)
Epoch: [11][192/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 0.7927 (0.8214)	Acc@1 82.422 (82.260)	Acc@5 99.219 (99.083)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.166 (0.166)	Data 0.316 (0.316)	Loss 0.8351 (0.8351)	Acc@1 79.297 (79.297)	Acc@5 99.609 (99.609)
Epoch: [12][64/196]	Time 0.150 (0.131)	Data 0.000 (0.005)	Loss 0.7144 (0.8121)	Acc@1 87.500 (82.380)	Acc@5 99.609 (99.087)
Epoch: [12][128/196]	Time 0.128 (0.131)	Data 0.000 (0.003)	Loss 0.7574 (0.8222)	Acc@1 84.766 (82.080)	Acc@5 99.609 (99.004)
Epoch: [12][192/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.8815 (0.8137)	Acc@1 79.688 (82.357)	Acc@5 98.828 (99.091)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.170 (0.170)	Data 0.309 (0.309)	Loss 0.7722 (0.7722)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.8535 (0.7997)	Acc@1 82.812 (82.963)	Acc@5 98.828 (99.195)
Epoch: [13][128/196]	Time 0.131 (0.132)	Data 0.000 (0.003)	Loss 0.7909 (0.8059)	Acc@1 80.859 (82.710)	Acc@5 99.219 (99.164)
Epoch: [13][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.8065 (0.8058)	Acc@1 84.766 (82.717)	Acc@5 99.219 (99.158)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.163 (0.163)	Data 0.309 (0.309)	Loss 0.8169 (0.8169)	Acc@1 82.031 (82.031)	Acc@5 97.656 (97.656)
Epoch: [14][64/196]	Time 0.130 (0.134)	Data 0.000 (0.005)	Loss 0.7348 (0.7895)	Acc@1 83.203 (82.704)	Acc@5 99.219 (99.111)
Epoch: [14][128/196]	Time 0.128 (0.132)	Data 0.000 (0.003)	Loss 0.8272 (0.7947)	Acc@1 82.031 (82.749)	Acc@5 98.438 (99.213)
Epoch: [14][192/196]	Time 0.135 (0.132)	Data 0.000 (0.002)	Loss 0.6910 (0.7909)	Acc@1 87.109 (82.946)	Acc@5 99.609 (99.178)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.173 (0.173)	Data 0.299 (0.299)	Loss 0.8425 (0.8425)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 0.132 (0.133)	Data 0.000 (0.005)	Loss 0.7597 (0.7833)	Acc@1 82.812 (83.095)	Acc@5 98.828 (99.243)
Epoch: [15][128/196]	Time 0.135 (0.132)	Data 0.000 (0.003)	Loss 0.7260 (0.7839)	Acc@1 85.938 (83.103)	Acc@5 99.609 (99.234)
Epoch: [15][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.7411 (0.7843)	Acc@1 85.938 (83.088)	Acc@5 99.219 (99.221)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  73.35
Max memory: 103.3833984
 26.285s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1407
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.207 (0.207)	Data 0.284 (0.284)	Loss 0.9466 (0.9466)	Acc@1 79.688 (79.688)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 0.129 (0.132)	Data 0.000 (0.005)	Loss 0.7933 (0.7616)	Acc@1 85.938 (83.894)	Acc@5 98.828 (99.255)
Epoch: [16][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.7760 (0.7745)	Acc@1 83.984 (83.391)	Acc@5 98.828 (99.207)
Epoch: [16][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.8915 (0.7764)	Acc@1 77.734 (83.347)	Acc@5 99.609 (99.223)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.164 (0.164)	Data 0.273 (0.273)	Loss 0.7818 (0.7818)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [17][64/196]	Time 0.128 (0.132)	Data 0.000 (0.004)	Loss 0.7229 (0.7690)	Acc@1 85.938 (83.510)	Acc@5 100.000 (99.195)
Epoch: [17][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6994 (0.7737)	Acc@1 84.766 (83.394)	Acc@5 99.219 (99.207)
Epoch: [17][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7423 (0.7786)	Acc@1 84.766 (83.244)	Acc@5 100.000 (99.239)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.159 (0.159)	Data 0.265 (0.265)	Loss 0.7816 (0.7816)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [18][64/196]	Time 0.134 (0.133)	Data 0.000 (0.004)	Loss 0.8814 (0.7815)	Acc@1 81.250 (83.594)	Acc@5 98.828 (99.069)
Epoch: [18][128/196]	Time 0.138 (0.133)	Data 0.000 (0.002)	Loss 0.8662 (0.7775)	Acc@1 82.812 (83.757)	Acc@5 98.828 (99.161)
Epoch: [18][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.8076 (0.7781)	Acc@1 83.984 (83.634)	Acc@5 99.219 (99.217)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.184 (0.184)	Data 0.266 (0.266)	Loss 0.7399 (0.7399)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.143 (0.135)	Data 0.000 (0.004)	Loss 0.7574 (0.7756)	Acc@1 82.812 (83.648)	Acc@5 97.656 (99.201)
Epoch: [19][128/196]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.7854 (0.7633)	Acc@1 80.859 (83.957)	Acc@5 100.000 (99.264)
Epoch: [19][192/196]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 0.8063 (0.7642)	Acc@1 80.859 (83.918)	Acc@5 98.438 (99.294)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.185 (0.185)	Data 0.283 (0.283)	Loss 0.7365 (0.7365)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.128 (0.134)	Data 0.000 (0.005)	Loss 0.7549 (0.7752)	Acc@1 83.203 (83.419)	Acc@5 99.609 (99.285)
Epoch: [20][128/196]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.7153 (0.7678)	Acc@1 84.766 (83.766)	Acc@5 99.609 (99.310)
Epoch: [20][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7387 (0.7723)	Acc@1 86.328 (83.652)	Acc@5 99.609 (99.269)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.77
Max memory: 103.3833984
 26.477s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4560
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.202496
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.200 (0.200)	Data 0.267 (0.267)	Loss 0.7222 (0.7222)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 0.7773 (0.7384)	Acc@1 82.031 (84.910)	Acc@5 98.828 (99.315)
Epoch: [21][128/196]	Time 0.132 (0.132)	Data 0.000 (0.002)	Loss 0.8105 (0.7451)	Acc@1 82.422 (84.545)	Acc@5 99.219 (99.349)
Epoch: [21][192/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.7876 (0.7510)	Acc@1 79.688 (84.440)	Acc@5 99.219 (99.292)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.156 (0.156)	Data 0.289 (0.289)	Loss 0.6159 (0.6159)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [22][64/196]	Time 0.132 (0.131)	Data 0.000 (0.005)	Loss 0.7629 (0.7532)	Acc@1 83.594 (84.273)	Acc@5 99.609 (99.273)
Epoch: [22][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.7770 (0.7560)	Acc@1 84.766 (84.157)	Acc@5 98.828 (99.252)
Epoch: [22][192/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.8017 (0.7590)	Acc@1 82.031 (84.077)	Acc@5 100.000 (99.279)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.189 (0.189)	Data 0.281 (0.281)	Loss 0.6297 (0.6297)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 0.131 (0.133)	Data 0.000 (0.005)	Loss 0.6118 (0.7494)	Acc@1 88.672 (84.651)	Acc@5 100.000 (99.297)
Epoch: [23][128/196]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.7946 (0.7528)	Acc@1 83.203 (84.408)	Acc@5 99.219 (99.270)
Epoch: [23][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.7581 (0.7505)	Acc@1 84.766 (84.391)	Acc@5 99.219 (99.286)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.161 (0.161)	Data 0.270 (0.270)	Loss 0.8122 (0.8122)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.132 (0.133)	Data 0.000 (0.004)	Loss 0.8628 (0.7577)	Acc@1 82.812 (84.309)	Acc@5 98.438 (99.249)
Epoch: [24][128/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.8174 (0.7565)	Acc@1 81.641 (84.381)	Acc@5 99.219 (99.282)
Epoch: [24][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.8392 (0.7551)	Acc@1 82.422 (84.341)	Acc@5 99.219 (99.294)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.184 (0.184)	Data 0.299 (0.299)	Loss 0.7681 (0.7681)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.130 (0.135)	Data 0.000 (0.005)	Loss 0.7037 (0.7505)	Acc@1 87.109 (84.255)	Acc@5 99.219 (99.267)
Epoch: [25][128/196]	Time 0.131 (0.134)	Data 0.000 (0.003)	Loss 0.7692 (0.7474)	Acc@1 84.375 (84.475)	Acc@5 100.000 (99.340)
Epoch: [25][192/196]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.7995 (0.7476)	Acc@1 80.859 (84.505)	Acc@5 98.438 (99.336)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 475840 ; 487386 ; 0.9763103577041605
[INFO] Storing checkpoint...
  80.32
Max memory: 103.3833984
 26.500s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5459
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1979904
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.208 (0.208)	Data 0.258 (0.258)	Loss 0.8063 (0.8063)	Acc@1 81.250 (81.250)	Acc@5 98.047 (98.047)
Epoch: [26][64/196]	Time 0.128 (0.131)	Data 0.000 (0.004)	Loss 0.6766 (0.7240)	Acc@1 86.719 (85.114)	Acc@5 99.609 (99.357)
Epoch: [26][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8203 (0.7346)	Acc@1 84.375 (84.996)	Acc@5 98.828 (99.331)
Epoch: [26][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.7558 (0.7407)	Acc@1 85.547 (84.725)	Acc@5 98.828 (99.369)
Max memory in training epoch: 66.1043712
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.166 (0.166)	Data 0.253 (0.253)	Loss 0.6689 (0.6689)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.6636 (0.7392)	Acc@1 87.500 (84.970)	Acc@5 98.828 (99.411)
Epoch: [27][128/196]	Time 0.152 (0.130)	Data 0.000 (0.002)	Loss 0.7156 (0.7322)	Acc@1 88.672 (85.035)	Acc@5 98.438 (99.413)
Epoch: [27][192/196]	Time 0.124 (0.130)	Data 0.000 (0.001)	Loss 0.7713 (0.7354)	Acc@1 80.469 (84.836)	Acc@5 99.219 (99.377)
Max memory in training epoch: 66.1568
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.158 (0.158)	Data 0.282 (0.282)	Loss 0.6901 (0.6901)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.7619 (0.7084)	Acc@1 81.641 (85.625)	Acc@5 100.000 (99.453)
Epoch: [28][128/196]	Time 0.137 (0.131)	Data 0.000 (0.002)	Loss 0.6928 (0.7263)	Acc@1 84.375 (84.893)	Acc@5 100.000 (99.425)
Epoch: [28][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7388 (0.7328)	Acc@1 85.938 (84.800)	Acc@5 99.609 (99.385)
Max memory in training epoch: 66.1568
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.157 (0.157)	Data 0.294 (0.294)	Loss 0.7520 (0.7520)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [29][64/196]	Time 0.129 (0.131)	Data 0.000 (0.005)	Loss 0.7586 (0.7274)	Acc@1 83.984 (85.439)	Acc@5 98.828 (99.489)
Epoch: [29][128/196]	Time 0.135 (0.131)	Data 0.000 (0.002)	Loss 0.6860 (0.7238)	Acc@1 89.062 (85.432)	Acc@5 98.828 (99.440)
Epoch: [29][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.8047 (0.7304)	Acc@1 80.078 (85.176)	Acc@5 99.609 (99.356)
Max memory in training epoch: 66.1568
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.173 (0.173)	Data 0.286 (0.286)	Loss 0.7626 (0.7626)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.7785 (0.7292)	Acc@1 84.766 (84.994)	Acc@5 99.219 (99.303)
Epoch: [30][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6822 (0.7348)	Acc@1 86.328 (84.850)	Acc@5 99.609 (99.297)
Epoch: [30][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7098 (0.7327)	Acc@1 85.938 (84.909)	Acc@5 100.000 (99.308)
Max memory in training epoch: 66.1568
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 443512 ; 475840 ; 0.9320611970410222
[INFO] Storing checkpoint...
  73.49
Max memory: 102.5416704
 25.886s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9232
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1851904
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.210 (0.210)	Data 0.280 (0.280)	Loss 0.6778 (0.6778)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.130 (0.129)	Data 0.000 (0.004)	Loss 0.7256 (0.6904)	Acc@1 82.812 (86.442)	Acc@5 99.609 (99.369)
Epoch: [31][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7883 (0.7117)	Acc@1 82.031 (85.719)	Acc@5 100.000 (99.406)
Epoch: [31][192/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.7381 (0.7209)	Acc@1 84.375 (85.371)	Acc@5 99.219 (99.425)
Max memory in training epoch: 64.9456128
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.155 (0.155)	Data 0.256 (0.256)	Loss 0.6763 (0.6763)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.123 (0.129)	Data 0.000 (0.004)	Loss 0.7575 (0.7195)	Acc@1 84.375 (85.583)	Acc@5 98.828 (99.339)
Epoch: [32][128/196]	Time 0.146 (0.129)	Data 0.000 (0.002)	Loss 0.7641 (0.7202)	Acc@1 82.812 (85.453)	Acc@5 99.219 (99.397)
Epoch: [32][192/196]	Time 0.129 (0.129)	Data 0.000 (0.001)	Loss 0.7224 (0.7189)	Acc@1 85.156 (85.470)	Acc@5 99.219 (99.389)
Max memory in training epoch: 64.925952
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.171 (0.171)	Data 0.290 (0.290)	Loss 0.6035 (0.6035)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.8009 (0.7366)	Acc@1 85.547 (84.627)	Acc@5 99.219 (99.411)
Epoch: [33][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.7168 (0.7310)	Acc@1 86.328 (84.956)	Acc@5 99.609 (99.382)
Epoch: [33][192/196]	Time 0.125 (0.130)	Data 0.000 (0.002)	Loss 0.7655 (0.7313)	Acc@1 83.203 (84.964)	Acc@5 100.000 (99.397)
Max memory in training epoch: 64.925952
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.183 (0.183)	Data 0.257 (0.257)	Loss 0.7807 (0.7807)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.131 (0.130)	Data 0.000 (0.004)	Loss 0.6588 (0.7233)	Acc@1 88.672 (85.403)	Acc@5 98.828 (99.279)
Epoch: [34][128/196]	Time 0.141 (0.130)	Data 0.000 (0.002)	Loss 0.6508 (0.7171)	Acc@1 88.281 (85.583)	Acc@5 100.000 (99.379)
Epoch: [34][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7619 (0.7217)	Acc@1 83.594 (85.338)	Acc@5 98.828 (99.358)
Max memory in training epoch: 64.925952
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.177 (0.177)	Data 0.307 (0.307)	Loss 0.5883 (0.5883)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [35][64/196]	Time 0.130 (0.130)	Data 0.000 (0.005)	Loss 0.7591 (0.7215)	Acc@1 84.375 (85.493)	Acc@5 99.219 (99.411)
Epoch: [35][128/196]	Time 0.128 (0.130)	Data 0.000 (0.003)	Loss 0.7416 (0.7218)	Acc@1 84.375 (85.426)	Acc@5 98.828 (99.361)
Epoch: [35][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7242 (0.7195)	Acc@1 86.719 (85.405)	Acc@5 98.828 (99.383)
Max memory in training epoch: 64.925952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 423880 ; 443512 ; 0.9557351323075813
[INFO] Storing checkpoint...
  74.11
Max memory: 100.9426944
 25.892s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4020
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1775104
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.200 (0.200)	Data 0.249 (0.249)	Loss 0.7026 (0.7026)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [36][64/196]	Time 0.125 (0.129)	Data 0.000 (0.004)	Loss 0.7956 (0.6722)	Acc@1 81.250 (86.995)	Acc@5 99.609 (99.459)
Epoch: [36][128/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 0.7510 (0.6987)	Acc@1 83.984 (86.022)	Acc@5 100.000 (99.416)
Epoch: [36][192/196]	Time 0.128 (0.129)	Data 0.000 (0.001)	Loss 0.7363 (0.7023)	Acc@1 83.203 (85.822)	Acc@5 99.609 (99.395)
Max memory in training epoch: 63.8335488
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.153 (0.153)	Data 0.257 (0.257)	Loss 0.7134 (0.7134)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.127 (0.128)	Data 0.000 (0.004)	Loss 0.6867 (0.7248)	Acc@1 86.719 (85.036)	Acc@5 99.219 (99.363)
Epoch: [37][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.7044 (0.7177)	Acc@1 85.547 (85.402)	Acc@5 99.219 (99.388)
Epoch: [37][192/196]	Time 0.129 (0.129)	Data 0.000 (0.002)	Loss 0.7193 (0.7204)	Acc@1 86.328 (85.259)	Acc@5 99.609 (99.360)
Max memory in training epoch: 63.8859776
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.183 (0.183)	Data 0.257 (0.257)	Loss 0.6356 (0.6356)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [38][64/196]	Time 0.126 (0.129)	Data 0.000 (0.004)	Loss 0.7573 (0.6875)	Acc@1 83.984 (86.232)	Acc@5 98.438 (99.459)
Epoch: [38][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 0.6927 (0.7013)	Acc@1 86.328 (85.810)	Acc@5 99.219 (99.358)
Epoch: [38][192/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.6620 (0.7104)	Acc@1 88.672 (85.521)	Acc@5 100.000 (99.330)
Max memory in training epoch: 63.9252992
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.166 (0.166)	Data 0.268 (0.268)	Loss 0.7724 (0.7724)	Acc@1 84.375 (84.375)	Acc@5 97.656 (97.656)
Epoch: [39][64/196]	Time 0.135 (0.132)	Data 0.000 (0.004)	Loss 0.6400 (0.6990)	Acc@1 87.500 (86.010)	Acc@5 99.609 (99.483)
Epoch: [39][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6433 (0.7082)	Acc@1 88.281 (85.638)	Acc@5 99.609 (99.431)
Epoch: [39][192/196]	Time 0.122 (0.130)	Data 0.000 (0.002)	Loss 0.6820 (0.7076)	Acc@1 88.281 (85.676)	Acc@5 100.000 (99.431)
Max memory in training epoch: 63.9252992
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.197 (0.197)	Data 0.298 (0.298)	Loss 0.7435 (0.7435)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.7550 (0.7039)	Acc@1 84.766 (85.925)	Acc@5 98.828 (99.555)
Epoch: [40][128/196]	Time 0.125 (0.129)	Data 0.000 (0.002)	Loss 0.6785 (0.7143)	Acc@1 84.766 (85.517)	Acc@5 99.609 (99.434)
Epoch: [40][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.6985 (0.7160)	Acc@1 89.062 (85.446)	Acc@5 99.219 (99.411)
Max memory in training epoch: 63.9252992
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 411106 ; 423880 ; 0.9698641124846654
[INFO] Storing checkpoint...
  80.83
Max memory: 98.919168
 25.740s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5787
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1718784
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.185 (0.185)	Data 0.294 (0.294)	Loss 0.6397 (0.6397)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [41][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.6688 (0.6807)	Acc@1 85.156 (86.671)	Acc@5 99.219 (99.489)
Epoch: [41][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6834 (0.6948)	Acc@1 84.766 (86.171)	Acc@5 99.609 (99.449)
Epoch: [41][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6778 (0.7003)	Acc@1 88.281 (85.956)	Acc@5 98.828 (99.445)
Max memory in training epoch: 60.6531072
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.161 (0.161)	Data 0.303 (0.303)	Loss 0.6921 (0.6921)	Acc@1 88.281 (88.281)	Acc@5 98.438 (98.438)
Epoch: [42][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.6966 (0.7105)	Acc@1 84.766 (85.415)	Acc@5 99.219 (99.399)
Epoch: [42][128/196]	Time 0.112 (0.120)	Data 0.000 (0.003)	Loss 0.6675 (0.7128)	Acc@1 87.500 (85.335)	Acc@5 100.000 (99.422)
Epoch: [42][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.6684 (0.7061)	Acc@1 87.891 (85.670)	Acc@5 99.219 (99.419)
Max memory in training epoch: 60.64
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.165 (0.165)	Data 0.318 (0.318)	Loss 0.7620 (0.7620)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [43][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6723 (0.6980)	Acc@1 88.281 (86.046)	Acc@5 98.828 (99.387)
Epoch: [43][128/196]	Time 0.120 (0.121)	Data 0.000 (0.003)	Loss 0.6832 (0.7016)	Acc@1 85.156 (86.053)	Acc@5 99.609 (99.406)
Epoch: [43][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6979 (0.7066)	Acc@1 84.766 (85.804)	Acc@5 99.609 (99.403)
Max memory in training epoch: 60.64
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.172 (0.172)	Data 0.299 (0.299)	Loss 0.7192 (0.7192)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.7157 (0.6724)	Acc@1 84.766 (86.947)	Acc@5 99.609 (99.507)
Epoch: [44][128/196]	Time 0.123 (0.121)	Data 0.000 (0.003)	Loss 0.6675 (0.6879)	Acc@1 88.281 (86.395)	Acc@5 99.609 (99.470)
Epoch: [44][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6979 (0.6963)	Acc@1 85.938 (86.079)	Acc@5 99.609 (99.425)
Max memory in training epoch: 60.64
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.171 (0.171)	Data 0.303 (0.303)	Loss 0.7010 (0.7010)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.123 (0.122)	Data 0.000 (0.005)	Loss 0.5920 (0.6947)	Acc@1 89.453 (85.931)	Acc@5 100.000 (99.531)
Epoch: [45][128/196]	Time 0.117 (0.122)	Data 0.000 (0.003)	Loss 0.6199 (0.6958)	Acc@1 88.672 (85.968)	Acc@5 100.000 (99.467)
Epoch: [45][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6771 (0.6977)	Acc@1 86.719 (86.061)	Acc@5 99.219 (99.419)
Max memory in training epoch: 60.64
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 397826 ; 411106 ; 0.9676968956911356
[INFO] Storing checkpoint...
  79.16
Max memory: 93.7728512
 24.165s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4348
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1665536
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.197 (0.197)	Data 0.258 (0.258)	Loss 0.6585 (0.6585)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [46][64/196]	Time 0.129 (0.127)	Data 0.000 (0.004)	Loss 0.6070 (0.6687)	Acc@1 90.234 (86.977)	Acc@5 99.219 (99.459)
Epoch: [46][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6444 (0.6859)	Acc@1 86.719 (86.452)	Acc@5 99.609 (99.416)
Epoch: [46][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6916 (0.6916)	Acc@1 87.109 (86.271)	Acc@5 99.609 (99.409)
Max memory in training epoch: 59.583232
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.170 (0.170)	Data 0.256 (0.256)	Loss 0.6678 (0.6678)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [47][64/196]	Time 0.121 (0.124)	Data 0.000 (0.004)	Loss 0.7647 (0.6779)	Acc@1 84.766 (86.430)	Acc@5 98.828 (99.447)
Epoch: [47][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.7507 (0.6885)	Acc@1 80.859 (86.146)	Acc@5 98.828 (99.394)
Epoch: [47][192/196]	Time 0.124 (0.123)	Data 0.000 (0.001)	Loss 0.7073 (0.6900)	Acc@1 86.719 (86.112)	Acc@5 98.828 (99.397)
Max memory in training epoch: 59.3604096
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.153 (0.153)	Data 0.290 (0.290)	Loss 0.7294 (0.7294)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.6493 (0.6904)	Acc@1 88.281 (86.148)	Acc@5 99.219 (99.459)
Epoch: [48][128/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.7196 (0.6999)	Acc@1 85.938 (85.956)	Acc@5 100.000 (99.473)
Epoch: [48][192/196]	Time 0.127 (0.123)	Data 0.000 (0.002)	Loss 0.7302 (0.7006)	Acc@1 85.938 (85.919)	Acc@5 99.219 (99.439)
Max memory in training epoch: 59.3604096
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.170 (0.170)	Data 0.262 (0.262)	Loss 0.7040 (0.7040)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.121 (0.124)	Data 0.000 (0.004)	Loss 0.6508 (0.6770)	Acc@1 87.109 (86.575)	Acc@5 99.609 (99.483)
Epoch: [49][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6663 (0.6791)	Acc@1 86.328 (86.449)	Acc@5 99.609 (99.512)
Epoch: [49][192/196]	Time 0.122 (0.123)	Data 0.000 (0.002)	Loss 0.7648 (0.6886)	Acc@1 85.547 (86.176)	Acc@5 100.000 (99.502)
Max memory in training epoch: 59.3604096
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.142 (0.142)	Data 0.291 (0.291)	Loss 0.7425 (0.7425)	Acc@1 83.203 (83.203)	Acc@5 98.828 (98.828)
Epoch: [50][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.6900 (0.7047)	Acc@1 84.766 (85.877)	Acc@5 99.609 (99.417)
Epoch: [50][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.7402 (0.6993)	Acc@1 83.984 (86.037)	Acc@5 100.000 (99.446)
Epoch: [50][192/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6000 (0.6945)	Acc@1 89.062 (86.231)	Acc@5 100.000 (99.417)
Max memory in training epoch: 59.3604096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 384690 ; 397826 ; 0.9669805392307189
[INFO] Storing checkpoint...
  82.4
Max memory: 92.214528
 24.786s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 868
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1613824
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.165 (0.165)	Data 0.282 (0.282)	Loss 0.6924 (0.6924)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [51][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.7091 (0.6659)	Acc@1 85.547 (86.845)	Acc@5 99.609 (99.477)
Epoch: [51][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.7278 (0.6754)	Acc@1 83.203 (86.725)	Acc@5 100.000 (99.473)
Epoch: [51][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7468 (0.6822)	Acc@1 85.547 (86.423)	Acc@5 98.828 (99.456)
Max memory in training epoch: 58.9334016
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.157 (0.157)	Data 0.287 (0.287)	Loss 0.6350 (0.6350)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.6755 (0.6808)	Acc@1 84.375 (86.382)	Acc@5 99.609 (99.513)
Epoch: [52][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.7176 (0.6897)	Acc@1 84.766 (86.107)	Acc@5 99.609 (99.461)
Epoch: [52][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.6768 (0.6928)	Acc@1 85.547 (86.010)	Acc@5 100.000 (99.454)
Max memory in training epoch: 58.697472
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.164 (0.164)	Data 0.291 (0.291)	Loss 0.6077 (0.6077)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.118 (0.121)	Data 0.000 (0.005)	Loss 0.7164 (0.6958)	Acc@1 85.938 (86.088)	Acc@5 99.219 (99.393)
Epoch: [53][128/196]	Time 0.125 (0.121)	Data 0.000 (0.002)	Loss 0.8730 (0.6935)	Acc@1 78.906 (86.092)	Acc@5 98.438 (99.400)
Epoch: [53][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6972 (0.6921)	Acc@1 85.156 (86.178)	Acc@5 98.828 (99.401)
Max memory in training epoch: 58.7564544
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.153 (0.153)	Data 0.271 (0.271)	Loss 0.6590 (0.6590)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.6635 (0.6630)	Acc@1 82.812 (86.911)	Acc@5 100.000 (99.555)
Epoch: [54][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.7245 (0.6778)	Acc@1 85.938 (86.483)	Acc@5 99.219 (99.485)
Epoch: [54][192/196]	Time 0.128 (0.121)	Data 0.000 (0.002)	Loss 0.6281 (0.6829)	Acc@1 86.719 (86.365)	Acc@5 99.609 (99.474)
Max memory in training epoch: 58.7564544
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.144 (0.144)	Data 0.286 (0.286)	Loss 0.6341 (0.6341)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.119 (0.122)	Data 0.000 (0.005)	Loss 0.6079 (0.6718)	Acc@1 87.891 (86.863)	Acc@5 100.000 (99.489)
Epoch: [55][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.6953 (0.6816)	Acc@1 85.156 (86.589)	Acc@5 99.219 (99.449)
Epoch: [55][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.6664 (0.6850)	Acc@1 89.453 (86.492)	Acc@5 99.219 (99.443)
Max memory in training epoch: 58.7564544
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 378914 ; 384690 ; 0.9849853128493072
[INFO] Storing checkpoint...
  78.28
Max memory: 90.983936
 24.315s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9721
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1590272
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.168 (0.168)	Data 0.263 (0.263)	Loss 0.6716 (0.6716)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.6756 (0.6500)	Acc@1 86.328 (87.386)	Acc@5 100.000 (99.495)
Epoch: [56][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6879 (0.6638)	Acc@1 84.766 (86.985)	Acc@5 100.000 (99.485)
Epoch: [56][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.5977 (0.6722)	Acc@1 88.281 (86.715)	Acc@5 99.219 (99.464)
Max memory in training epoch: 58.0720128
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.145 (0.145)	Data 0.253 (0.253)	Loss 0.6710 (0.6710)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [57][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.6965 (0.6886)	Acc@1 86.328 (86.136)	Acc@5 99.609 (99.423)
Epoch: [57][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6901 (0.6846)	Acc@1 86.719 (86.216)	Acc@5 98.828 (99.443)
Epoch: [57][192/196]	Time 0.120 (0.121)	Data 0.000 (0.001)	Loss 0.7500 (0.6862)	Acc@1 85.547 (86.199)	Acc@5 99.609 (99.484)
Max memory in training epoch: 57.8754048
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.139 (0.139)	Data 0.266 (0.266)	Loss 0.6159 (0.6159)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [58][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.6639 (0.6869)	Acc@1 84.766 (86.268)	Acc@5 99.219 (99.453)
Epoch: [58][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.6328 (0.6814)	Acc@1 87.891 (86.401)	Acc@5 99.609 (99.467)
Epoch: [58][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6567 (0.6822)	Acc@1 90.234 (86.363)	Acc@5 99.219 (99.476)
Max memory in training epoch: 57.8754048
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.171 (0.171)	Data 0.267 (0.267)	Loss 0.5943 (0.5943)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.7035 (0.6680)	Acc@1 83.594 (86.989)	Acc@5 100.000 (99.483)
Epoch: [59][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.6136 (0.6759)	Acc@1 89.453 (86.616)	Acc@5 99.609 (99.534)
Epoch: [59][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6471 (0.6797)	Acc@1 85.547 (86.502)	Acc@5 100.000 (99.528)
Max memory in training epoch: 57.8754048
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.173 (0.173)	Data 0.261 (0.261)	Loss 0.6136 (0.6136)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.6397 (0.6531)	Acc@1 88.672 (87.230)	Acc@5 98.438 (99.513)
Epoch: [60][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.6732 (0.6652)	Acc@1 86.719 (86.940)	Acc@5 99.609 (99.512)
Epoch: [60][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6807 (0.6745)	Acc@1 86.328 (86.632)	Acc@5 98.438 (99.486)
Max memory in training epoch: 57.8754048
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 371408 ; 378914 ; 0.9801907556859868
[INFO] Storing checkpoint...
  79.18
Max memory: 90.2709248
 24.004s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 356
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.15616
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.177 (0.177)	Data 0.260 (0.260)	Loss 0.6452 (0.6452)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.122 (0.127)	Data 0.000 (0.004)	Loss 0.6152 (0.6389)	Acc@1 89.453 (87.843)	Acc@5 100.000 (99.525)
Epoch: [61][128/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.6663 (0.6582)	Acc@1 87.500 (87.128)	Acc@5 99.609 (99.503)
Epoch: [61][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.6293 (0.6672)	Acc@1 86.719 (86.749)	Acc@5 99.609 (99.494)
Max memory in training epoch: 57.0840576
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.152 (0.152)	Data 0.268 (0.268)	Loss 0.6121 (0.6121)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.6846 (0.6602)	Acc@1 86.328 (86.953)	Acc@5 99.219 (99.495)
Epoch: [62][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.6432 (0.6687)	Acc@1 88.672 (86.855)	Acc@5 99.609 (99.494)
Epoch: [62][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.6770 (0.6747)	Acc@1 85.938 (86.587)	Acc@5 100.000 (99.468)
Max memory in training epoch: 57.1299328
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.172 (0.172)	Data 0.283 (0.283)	Loss 0.6599 (0.6599)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [63][64/196]	Time 0.121 (0.124)	Data 0.000 (0.005)	Loss 0.6140 (0.6633)	Acc@1 89.844 (86.881)	Acc@5 99.609 (99.513)
Epoch: [63][128/196]	Time 0.121 (0.124)	Data 0.000 (0.002)	Loss 0.6870 (0.6778)	Acc@1 86.328 (86.386)	Acc@5 99.609 (99.479)
Epoch: [63][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.6240 (0.6800)	Acc@1 87.500 (86.361)	Acc@5 100.000 (99.462)
Max memory in training epoch: 57.1299328
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.150 (0.150)	Data 0.290 (0.290)	Loss 0.6537 (0.6537)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.7470 (0.6777)	Acc@1 87.109 (86.683)	Acc@5 98.438 (99.393)
Epoch: [64][128/196]	Time 0.122 (0.125)	Data 0.000 (0.002)	Loss 0.6226 (0.6796)	Acc@1 86.719 (86.473)	Acc@5 99.219 (99.425)
Epoch: [64][192/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.7426 (0.6782)	Acc@1 82.812 (86.458)	Acc@5 100.000 (99.441)
Max memory in training epoch: 57.1299328
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.162 (0.162)	Data 0.260 (0.260)	Loss 0.7100 (0.7100)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [65][64/196]	Time 0.129 (0.126)	Data 0.000 (0.004)	Loss 0.6230 (0.6769)	Acc@1 87.500 (86.767)	Acc@5 99.609 (99.459)
Epoch: [65][128/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.6208 (0.6797)	Acc@1 88.281 (86.334)	Acc@5 99.219 (99.425)
Epoch: [65][192/196]	Time 0.120 (0.124)	Data 0.000 (0.002)	Loss 0.8488 (0.6819)	Acc@1 80.078 (86.385)	Acc@5 98.438 (99.435)
Max memory in training epoch: 57.1299328
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 366214 ; 371408 ; 0.9860153793133158
[INFO] Storing checkpoint...
  77.32
Max memory: 88.8262656
 24.675s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5341
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1539072
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.184 (0.184)	Data 0.259 (0.259)	Loss 0.7179 (0.7179)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.5976 (0.6387)	Acc@1 90.234 (87.650)	Acc@5 99.609 (99.579)
Epoch: [66][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.6764 (0.6564)	Acc@1 86.719 (87.049)	Acc@5 99.609 (99.525)
Epoch: [66][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7248 (0.6702)	Acc@1 84.766 (86.581)	Acc@5 99.609 (99.498)
Max memory in training epoch: 57.0291712
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.167 (0.167)	Data 0.306 (0.306)	Loss 0.6497 (0.6497)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.121 (0.120)	Data 0.000 (0.005)	Loss 0.7320 (0.6646)	Acc@1 83.984 (86.713)	Acc@5 100.000 (99.555)
Epoch: [67][128/196]	Time 0.119 (0.120)	Data 0.000 (0.003)	Loss 0.7013 (0.6721)	Acc@1 83.594 (86.498)	Acc@5 98.828 (99.516)
Epoch: [67][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.6220 (0.6760)	Acc@1 89.844 (86.490)	Acc@5 99.219 (99.494)
Max memory in training epoch: 57.0684928
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.141 (0.141)	Data 0.289 (0.289)	Loss 0.6274 (0.6274)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.126 (0.120)	Data 0.000 (0.005)	Loss 0.6831 (0.6658)	Acc@1 88.281 (86.767)	Acc@5 99.609 (99.591)
Epoch: [68][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.6131 (0.6733)	Acc@1 87.500 (86.698)	Acc@5 99.219 (99.546)
Epoch: [68][192/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.6621 (0.6748)	Acc@1 87.500 (86.654)	Acc@5 99.219 (99.492)
Max memory in training epoch: 57.0684928
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.166 (0.166)	Data 0.287 (0.287)	Loss 0.6958 (0.6958)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.122 (0.122)	Data 0.000 (0.005)	Loss 0.7198 (0.6691)	Acc@1 85.156 (87.163)	Acc@5 99.219 (99.483)
Epoch: [69][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.6771 (0.6737)	Acc@1 87.109 (86.758)	Acc@5 99.609 (99.470)
Epoch: [69][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.7692 (0.6797)	Acc@1 86.719 (86.460)	Acc@5 98.828 (99.435)
Max memory in training epoch: 57.0684928
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.184 (0.184)	Data 0.262 (0.262)	Loss 0.6075 (0.6075)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [70][64/196]	Time 0.115 (0.122)	Data 0.000 (0.004)	Loss 0.7245 (0.6599)	Acc@1 86.328 (86.857)	Acc@5 99.609 (99.471)
Epoch: [70][128/196]	Time 0.126 (0.121)	Data 0.000 (0.002)	Loss 0.6885 (0.6658)	Acc@1 84.766 (86.746)	Acc@5 99.609 (99.476)
Epoch: [70][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.7004 (0.6712)	Acc@1 86.328 (86.682)	Acc@5 98.828 (99.449)
Max memory in training epoch: 57.0684928
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 364768 ; 366214 ; 0.9960514890200811
[INFO] Storing checkpoint...
  71.7
Max memory: 88.6908928
 24.064s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2432
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1533952
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.196 (0.196)	Data 0.251 (0.251)	Loss 0.5813 (0.5813)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.112 (0.122)	Data 0.000 (0.004)	Loss 0.7139 (0.6399)	Acc@1 84.375 (87.494)	Acc@5 98.828 (99.531)
Epoch: [71][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.6764 (0.6568)	Acc@1 87.109 (87.031)	Acc@5 100.000 (99.522)
Epoch: [71][192/196]	Time 0.119 (0.121)	Data 0.000 (0.001)	Loss 0.6559 (0.6650)	Acc@1 86.328 (86.719)	Acc@5 99.609 (99.504)
Max memory in training epoch: 57.0271232
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.161 (0.161)	Data 0.281 (0.281)	Loss 0.6661 (0.6661)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.115 (0.120)	Data 0.000 (0.004)	Loss 0.7235 (0.6757)	Acc@1 85.156 (86.629)	Acc@5 99.609 (99.567)
Epoch: [72][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.6823 (0.6735)	Acc@1 88.281 (86.631)	Acc@5 97.656 (99.512)
Epoch: [72][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.7062 (0.6754)	Acc@1 86.328 (86.555)	Acc@5 99.609 (99.506)
Max memory in training epoch: 57.014016
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.173 (0.173)	Data 0.284 (0.284)	Loss 0.5957 (0.5957)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.124 (0.122)	Data 0.000 (0.005)	Loss 0.6619 (0.6666)	Acc@1 87.500 (86.562)	Acc@5 100.000 (99.549)
Epoch: [73][128/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.6268 (0.6726)	Acc@1 86.719 (86.519)	Acc@5 100.000 (99.482)
Epoch: [73][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6557 (0.6742)	Acc@1 88.672 (86.510)	Acc@5 98.828 (99.498)
Max memory in training epoch: 56.9091584
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.169 (0.169)	Data 0.291 (0.291)	Loss 0.6108 (0.6108)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.6604 (0.6698)	Acc@1 87.500 (86.436)	Acc@5 99.219 (99.495)
Epoch: [74][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.5766 (0.6757)	Acc@1 87.891 (86.298)	Acc@5 100.000 (99.470)
Epoch: [74][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6683 (0.6806)	Acc@1 87.500 (86.261)	Acc@5 99.219 (99.449)
Max memory in training epoch: 56.9091584
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.158 (0.158)	Data 0.286 (0.286)	Loss 0.5673 (0.5673)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.129 (0.121)	Data 0.000 (0.005)	Loss 0.7032 (0.6763)	Acc@1 87.891 (86.532)	Acc@5 99.219 (99.525)
Epoch: [75][128/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6576 (0.6748)	Acc@1 87.500 (86.707)	Acc@5 99.219 (99.500)
Epoch: [75][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.7738 (0.6748)	Acc@1 81.250 (86.642)	Acc@5 100.000 (99.476)
Max memory in training epoch: 56.9091584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 361304 ; 364768 ; 0.9905035529432407
[INFO] Storing checkpoint...
  76.53
Max memory: 88.4124672
 24.042s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8005
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.152064
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.193 (0.193)	Data 0.292 (0.292)	Loss 0.6175 (0.6175)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.6343 (0.6373)	Acc@1 89.062 (87.656)	Acc@5 99.219 (99.483)
Epoch: [76][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.6494 (0.6484)	Acc@1 88.281 (87.370)	Acc@5 100.000 (99.516)
Epoch: [76][192/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.7233 (0.6606)	Acc@1 83.594 (86.929)	Acc@5 99.609 (99.498)
Max memory in training epoch: 57.0086912
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.150 (0.150)	Data 0.261 (0.261)	Loss 0.6489 (0.6489)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [77][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.6619 (0.6656)	Acc@1 87.891 (86.749)	Acc@5 99.219 (99.555)
Epoch: [77][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6686 (0.6693)	Acc@1 87.500 (86.561)	Acc@5 98.828 (99.452)
Epoch: [77][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.6904 (0.6684)	Acc@1 86.719 (86.652)	Acc@5 99.219 (99.431)
Max memory in training epoch: 56.930048
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.171 (0.171)	Data 0.260 (0.260)	Loss 0.6538 (0.6538)	Acc@1 89.844 (89.844)	Acc@5 98.438 (98.438)
Epoch: [78][64/196]	Time 0.139 (0.122)	Data 0.000 (0.004)	Loss 0.6478 (0.6626)	Acc@1 87.891 (86.845)	Acc@5 99.609 (99.555)
Epoch: [78][128/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.6804 (0.6665)	Acc@1 86.719 (86.873)	Acc@5 99.609 (99.488)
Epoch: [78][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.7939 (0.6640)	Acc@1 83.594 (86.911)	Acc@5 99.219 (99.504)
Max memory in training epoch: 56.8251904
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.164 (0.164)	Data 0.295 (0.295)	Loss 0.6755 (0.6755)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [79][64/196]	Time 0.164 (0.122)	Data 0.000 (0.005)	Loss 0.6888 (0.6632)	Acc@1 86.328 (86.911)	Acc@5 99.609 (99.495)
Epoch: [79][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.6495 (0.6584)	Acc@1 86.328 (87.009)	Acc@5 100.000 (99.525)
Epoch: [79][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.5904 (0.6582)	Acc@1 87.891 (87.032)	Acc@5 99.609 (99.559)
Max memory in training epoch: 56.8251904
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.189 (0.189)	Data 0.270 (0.270)	Loss 0.6307 (0.6307)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.7116 (0.6663)	Acc@1 87.109 (86.857)	Acc@5 98.828 (99.513)
Epoch: [80][128/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.7071 (0.6679)	Acc@1 85.547 (86.758)	Acc@5 99.609 (99.540)
Epoch: [80][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.7098 (0.6678)	Acc@1 84.375 (86.767)	Acc@5 100.000 (99.534)
Max memory in training epoch: 56.8251904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 360726 ; 361304 ; 0.9984002391338043
[INFO] Storing checkpoint...
  81.47
Max memory: 88.2593792
 23.874s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 920
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1518592
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.185 (0.185)	Data 0.281 (0.281)	Loss 0.6098 (0.6098)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.129 (0.124)	Data 0.000 (0.005)	Loss 0.5938 (0.6411)	Acc@1 89.453 (87.476)	Acc@5 99.609 (99.633)
Epoch: [81][128/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.7141 (0.6579)	Acc@1 85.938 (86.928)	Acc@5 99.219 (99.552)
Epoch: [81][192/196]	Time 0.112 (0.122)	Data 0.000 (0.002)	Loss 0.7039 (0.6654)	Acc@1 87.109 (86.699)	Acc@5 98.828 (99.502)
Max memory in training epoch: 56.8768
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.173 (0.173)	Data 0.276 (0.276)	Loss 0.7333 (0.7333)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.116 (0.121)	Data 0.000 (0.004)	Loss 0.5559 (0.6580)	Acc@1 89.453 (86.785)	Acc@5 100.000 (99.459)
Epoch: [82][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.7056 (0.6589)	Acc@1 86.328 (86.934)	Acc@5 99.609 (99.449)
Epoch: [82][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.7661 (0.6635)	Acc@1 85.156 (86.806)	Acc@5 98.828 (99.476)
Max memory in training epoch: 56.9292288
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.148 (0.148)	Data 0.295 (0.295)	Loss 0.6509 (0.6509)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.5531 (0.6811)	Acc@1 88.672 (86.022)	Acc@5 100.000 (99.531)
Epoch: [83][128/196]	Time 0.147 (0.123)	Data 0.000 (0.002)	Loss 0.6719 (0.6801)	Acc@1 87.109 (86.056)	Acc@5 99.609 (99.522)
Epoch: [83][192/196]	Time 0.125 (0.122)	Data 0.000 (0.002)	Loss 0.7025 (0.6708)	Acc@1 85.938 (86.452)	Acc@5 99.219 (99.532)
Max memory in training epoch: 56.8243712
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.175 (0.175)	Data 0.261 (0.261)	Loss 0.6639 (0.6639)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.6506 (0.6554)	Acc@1 88.281 (87.206)	Acc@5 98.828 (99.573)
Epoch: [84][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.7369 (0.6664)	Acc@1 85.156 (86.885)	Acc@5 99.609 (99.494)
Epoch: [84][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.6556 (0.6719)	Acc@1 88.281 (86.609)	Acc@5 98.828 (99.490)
Max memory in training epoch: 56.8243712
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.175 (0.175)	Data 0.276 (0.276)	Loss 0.7112 (0.7112)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [85][64/196]	Time 0.113 (0.122)	Data 0.000 (0.004)	Loss 0.6750 (0.6640)	Acc@1 86.328 (86.989)	Acc@5 99.219 (99.483)
Epoch: [85][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.7216 (0.6577)	Acc@1 82.812 (87.209)	Acc@5 100.000 (99.543)
Epoch: [85][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.6931 (0.6627)	Acc@1 85.938 (87.014)	Acc@5 98.828 (99.555)
Max memory in training epoch: 56.8243712
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 359280 ; 360726 ; 0.995991417308428
[INFO] Storing checkpoint...
  65.11
Max memory: 88.2587648
 24.147s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8129
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1512448
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.193 (0.193)	Data 0.258 (0.258)	Loss 0.6411 (0.6411)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [86][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.6420 (0.6420)	Acc@1 86.719 (87.602)	Acc@5 99.609 (99.609)
Epoch: [86][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.6151 (0.6516)	Acc@1 89.062 (87.191)	Acc@5 100.000 (99.534)
Epoch: [86][192/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.6185 (0.6581)	Acc@1 89.062 (86.986)	Acc@5 99.609 (99.567)
Max memory in training epoch: 56.585984
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.176 (0.176)	Data 0.263 (0.263)	Loss 0.5761 (0.5761)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.7004 (0.6404)	Acc@1 86.328 (87.356)	Acc@5 98.828 (99.633)
Epoch: [87][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.7239 (0.6589)	Acc@1 83.594 (86.955)	Acc@5 100.000 (99.540)
Epoch: [87][192/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.6660 (0.6630)	Acc@1 87.500 (86.862)	Acc@5 98.828 (99.518)
Max memory in training epoch: 56.6121984
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.173 (0.173)	Data 0.281 (0.281)	Loss 0.6013 (0.6013)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.113 (0.121)	Data 0.000 (0.005)	Loss 0.6608 (0.6416)	Acc@1 85.547 (87.560)	Acc@5 99.609 (99.459)
Epoch: [88][128/196]	Time 0.129 (0.121)	Data 0.000 (0.002)	Loss 0.6672 (0.6538)	Acc@1 85.156 (87.221)	Acc@5 99.609 (99.485)
Epoch: [88][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.7847 (0.6621)	Acc@1 85.938 (86.824)	Acc@5 99.219 (99.480)
Max memory in training epoch: 56.6121984
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.165 (0.165)	Data 0.271 (0.271)	Loss 0.6417 (0.6417)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [89][64/196]	Time 0.119 (0.121)	Data 0.000 (0.004)	Loss 0.7480 (0.6669)	Acc@1 83.594 (86.827)	Acc@5 100.000 (99.555)
Epoch: [89][128/196]	Time 0.137 (0.120)	Data 0.000 (0.002)	Loss 0.6511 (0.6620)	Acc@1 87.891 (86.891)	Acc@5 99.609 (99.534)
Epoch: [89][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.6256 (0.6641)	Acc@1 89.062 (86.808)	Acc@5 100.000 (99.474)
Max memory in training epoch: 56.6121984
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.166 (0.166)	Data 0.361 (0.361)	Loss 0.6613 (0.6613)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.120 (0.122)	Data 0.000 (0.006)	Loss 0.6797 (0.6645)	Acc@1 85.938 (86.689)	Acc@5 100.000 (99.591)
Epoch: [90][128/196]	Time 0.119 (0.121)	Data 0.000 (0.003)	Loss 0.6525 (0.6575)	Acc@1 87.891 (86.937)	Acc@5 99.219 (99.597)
Epoch: [90][192/196]	Time 0.117 (0.121)	Data 0.000 (0.002)	Loss 0.5517 (0.6583)	Acc@1 91.016 (86.935)	Acc@5 99.609 (99.571)
Max memory in training epoch: 56.6121984
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356394 ; 359280 ; 0.9919672678690715
[INFO] Storing checkpoint...
  77.82
Max memory: 88.0242688
 24.093s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9292
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1501184
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.185 (0.185)	Data 0.272 (0.272)	Loss 0.5789 (0.5789)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.6634 (0.6317)	Acc@1 87.109 (87.716)	Acc@5 99.609 (99.657)
Epoch: [91][128/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.5920 (0.6427)	Acc@1 90.234 (87.388)	Acc@5 99.609 (99.567)
Epoch: [91][192/196]	Time 0.132 (0.120)	Data 0.000 (0.002)	Loss 0.6182 (0.6580)	Acc@1 87.891 (86.897)	Acc@5 100.000 (99.516)
Max memory in training epoch: 56.5618176
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.167 (0.167)	Data 0.261 (0.261)	Loss 0.7093 (0.7093)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.6566 (0.6661)	Acc@1 86.719 (86.749)	Acc@5 100.000 (99.477)
Epoch: [92][128/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.7133 (0.6614)	Acc@1 85.938 (87.070)	Acc@5 98.828 (99.485)
Epoch: [92][192/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.7643 (0.6597)	Acc@1 82.031 (86.968)	Acc@5 98.438 (99.494)
Max memory in training epoch: 56.424192
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.167 (0.167)	Data 0.274 (0.274)	Loss 0.6324 (0.6324)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.5472 (0.5609)	Acc@1 90.625 (90.228)	Acc@5 99.609 (99.766)
Epoch: [93][128/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.4495 (0.5397)	Acc@1 94.141 (90.958)	Acc@5 100.000 (99.779)
Epoch: [93][192/196]	Time 0.131 (0.120)	Data 0.000 (0.002)	Loss 0.5202 (0.5265)	Acc@1 90.234 (91.473)	Acc@5 100.000 (99.787)
Max memory in training epoch: 56.424192
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.169 (0.169)	Data 0.281 (0.281)	Loss 0.4976 (0.4976)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [94][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.5172 (0.4854)	Acc@1 91.797 (92.849)	Acc@5 99.609 (99.826)
Epoch: [94][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.4966 (0.4787)	Acc@1 91.797 (93.044)	Acc@5 99.609 (99.855)
Epoch: [94][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.4845 (0.4752)	Acc@1 92.188 (93.119)	Acc@5 100.000 (99.854)
Max memory in training epoch: 56.424192
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.169 (0.169)	Data 0.284 (0.284)	Loss 0.3785 (0.3785)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.4788 (0.4582)	Acc@1 92.969 (93.654)	Acc@5 100.000 (99.838)
Epoch: [95][128/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.4425 (0.4554)	Acc@1 93.359 (93.665)	Acc@5 100.000 (99.861)
Epoch: [95][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.4249 (0.4513)	Acc@1 95.312 (93.691)	Acc@5 100.000 (99.866)
Max memory in training epoch: 56.424192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353652 ; 356394 ; 0.9923062677822859
[INFO] Storing checkpoint...
  91.01
Max memory: 87.622144
 24.069s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6940
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1490432
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.171 (0.171)	Data 0.284 (0.284)	Loss 0.4133 (0.4133)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.4750 (0.4330)	Acc@1 93.359 (94.243)	Acc@5 99.609 (99.892)
Epoch: [96][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.4996 (0.4333)	Acc@1 93.750 (94.147)	Acc@5 99.219 (99.876)
Epoch: [96][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3831 (0.4306)	Acc@1 96.484 (94.270)	Acc@5 100.000 (99.875)
Max memory in training epoch: 56.5313024
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.148 (0.148)	Data 0.260 (0.260)	Loss 0.4243 (0.4243)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.119 (0.120)	Data 0.000 (0.004)	Loss 0.4148 (0.4213)	Acc@1 93.750 (94.387)	Acc@5 100.000 (99.904)
Epoch: [97][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.4141 (0.4203)	Acc@1 94.141 (94.492)	Acc@5 100.000 (99.897)
Epoch: [97][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3637 (0.4190)	Acc@1 97.266 (94.545)	Acc@5 100.000 (99.901)
Max memory in training epoch: 56.341248
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.186 (0.186)	Data 0.289 (0.289)	Loss 0.4037 (0.4037)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.120 (0.120)	Data 0.000 (0.005)	Loss 0.3744 (0.4089)	Acc@1 96.094 (94.675)	Acc@5 100.000 (99.898)
Epoch: [98][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.3974 (0.4055)	Acc@1 95.312 (94.798)	Acc@5 100.000 (99.906)
Epoch: [98][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.4443 (0.4056)	Acc@1 93.359 (94.764)	Acc@5 99.609 (99.905)
Max memory in training epoch: 56.341248
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.155 (0.155)	Data 0.298 (0.298)	Loss 0.3860 (0.3860)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.127 (0.119)	Data 0.000 (0.005)	Loss 0.3663 (0.3952)	Acc@1 96.094 (95.000)	Acc@5 100.000 (99.958)
Epoch: [99][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.4263 (0.3951)	Acc@1 94.531 (95.022)	Acc@5 100.000 (99.964)
Epoch: [99][192/196]	Time 0.110 (0.119)	Data 0.000 (0.002)	Loss 0.3668 (0.3936)	Acc@1 95.703 (95.055)	Acc@5 100.000 (99.939)
Max memory in training epoch: 56.341248
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.150 (0.150)	Data 0.269 (0.269)	Loss 0.4446 (0.4446)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.114 (0.120)	Data 0.000 (0.004)	Loss 0.3958 (0.3799)	Acc@1 94.922 (95.397)	Acc@5 100.000 (99.940)
Epoch: [100][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.4076 (0.3806)	Acc@1 94.141 (95.370)	Acc@5 99.609 (99.924)
Epoch: [100][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3577 (0.3821)	Acc@1 96.875 (95.252)	Acc@5 100.000 (99.927)
Max memory in training epoch: 56.341248
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.31
Max memory: 87.5388416
 23.871s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5677
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1490432
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.168 (0.168)	Data 0.291 (0.291)	Loss 0.4135 (0.4135)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.3633 (0.3739)	Acc@1 96.094 (95.487)	Acc@5 100.000 (99.940)
Epoch: [101][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.3462 (0.3726)	Acc@1 96.094 (95.479)	Acc@5 100.000 (99.924)
Epoch: [101][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3396 (0.3724)	Acc@1 96.484 (95.472)	Acc@5 100.000 (99.927)
Max memory in training epoch: 56.5313024
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.184 (0.184)	Data 0.269 (0.269)	Loss 0.3689 (0.3689)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 0.3794 (0.3602)	Acc@1 95.703 (96.016)	Acc@5 100.000 (99.970)
Epoch: [102][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.3547 (0.3612)	Acc@1 95.312 (95.773)	Acc@5 100.000 (99.967)
Epoch: [102][192/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.3885 (0.3631)	Acc@1 94.141 (95.697)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.341248
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.140 (0.140)	Data 0.262 (0.262)	Loss 0.3436 (0.3436)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.3485 (0.3550)	Acc@1 95.703 (95.775)	Acc@5 100.000 (99.952)
Epoch: [103][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3583 (0.3552)	Acc@1 94.531 (95.739)	Acc@5 100.000 (99.942)
Epoch: [103][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3986 (0.3561)	Acc@1 94.531 (95.655)	Acc@5 99.609 (99.941)
Max memory in training epoch: 56.341248
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.147 (0.147)	Data 0.280 (0.280)	Loss 0.3148 (0.3148)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.120 (0.122)	Data 0.000 (0.004)	Loss 0.3698 (0.3469)	Acc@1 94.922 (95.913)	Acc@5 99.609 (99.904)
Epoch: [104][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3100 (0.3504)	Acc@1 98.047 (95.830)	Acc@5 100.000 (99.924)
Epoch: [104][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3628 (0.3494)	Acc@1 94.922 (95.806)	Acc@5 100.000 (99.939)
Max memory in training epoch: 56.341248
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.168 (0.168)	Data 0.266 (0.266)	Loss 0.3180 (0.3180)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 0.3506 (0.3375)	Acc@1 95.312 (96.184)	Acc@5 100.000 (99.970)
Epoch: [105][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.3041 (0.3399)	Acc@1 98.047 (96.045)	Acc@5 100.000 (99.961)
Epoch: [105][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.3481 (0.3435)	Acc@1 95.703 (95.914)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.341248
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 353362 ; 353652 ; 0.9991799848438578
[INFO] Storing checkpoint...
  91.01
Max memory: 87.5388416
 24.139s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3505
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1489408
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.185 (0.185)	Data 0.270 (0.270)	Loss 0.2987 (0.2987)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.3385 (0.3338)	Acc@1 96.484 (96.124)	Acc@5 100.000 (99.976)
Epoch: [106][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3543 (0.3344)	Acc@1 94.922 (96.042)	Acc@5 100.000 (99.958)
Epoch: [106][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3194 (0.3358)	Acc@1 97.266 (95.991)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.3211776
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.181 (0.181)	Data 0.314 (0.314)	Loss 0.3226 (0.3226)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.118 (0.122)	Data 0.000 (0.005)	Loss 0.3381 (0.3272)	Acc@1 95.312 (96.280)	Acc@5 100.000 (99.952)
Epoch: [107][128/196]	Time 0.123 (0.120)	Data 0.000 (0.003)	Loss 0.3550 (0.3281)	Acc@1 94.531 (96.154)	Acc@5 99.609 (99.961)
Epoch: [107][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.3397 (0.3320)	Acc@1 94.922 (96.009)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.0131584
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.176 (0.176)	Data 0.296 (0.296)	Loss 0.3145 (0.3145)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.125 (0.123)	Data 0.000 (0.005)	Loss 0.3828 (0.3229)	Acc@1 93.359 (96.256)	Acc@5 100.000 (99.964)
Epoch: [108][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2979 (0.3222)	Acc@1 96.484 (96.318)	Acc@5 100.000 (99.961)
Epoch: [108][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3250 (0.3241)	Acc@1 96.094 (96.183)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.0131584
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.174 (0.174)	Data 0.263 (0.263)	Loss 0.3336 (0.3336)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.2897 (0.3173)	Acc@1 98.047 (96.316)	Acc@5 100.000 (99.952)
Epoch: [109][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3048 (0.3201)	Acc@1 97.266 (96.300)	Acc@5 100.000 (99.949)
Epoch: [109][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3210 (0.3212)	Acc@1 95.703 (96.199)	Acc@5 100.000 (99.951)
Max memory in training epoch: 56.0131584
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.158 (0.158)	Data 0.286 (0.286)	Loss 0.2911 (0.2911)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.120 (0.122)	Data 0.000 (0.005)	Loss 0.3177 (0.3154)	Acc@1 95.312 (96.154)	Acc@5 99.609 (99.970)
Epoch: [110][128/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.3020 (0.3147)	Acc@1 96.094 (96.191)	Acc@5 100.000 (99.958)
Epoch: [110][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.3457 (0.3140)	Acc@1 95.312 (96.254)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.0131584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.23
Max memory: 87.2602112
 24.409s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9674
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1489408
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.177 (0.177)	Data 0.264 (0.264)	Loss 0.3145 (0.3145)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.111 (0.120)	Data 0.000 (0.004)	Loss 0.3025 (0.3026)	Acc@1 96.094 (96.647)	Acc@5 99.609 (99.958)
Epoch: [111][128/196]	Time 0.129 (0.120)	Data 0.000 (0.002)	Loss 0.2839 (0.3071)	Acc@1 98.047 (96.448)	Acc@5 100.000 (99.967)
Epoch: [111][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3093 (0.3115)	Acc@1 94.922 (96.262)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.3211776
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.182 (0.182)	Data 0.261 (0.261)	Loss 0.3368 (0.3368)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.3289 (0.3064)	Acc@1 94.922 (96.508)	Acc@5 100.000 (99.964)
Epoch: [112][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3127 (0.3082)	Acc@1 95.312 (96.375)	Acc@5 100.000 (99.967)
Epoch: [112][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2814 (0.3132)	Acc@1 96.875 (96.154)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.0131584
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.172 (0.172)	Data 0.272 (0.272)	Loss 0.2925 (0.2925)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.121 (0.122)	Data 0.000 (0.004)	Loss 0.2883 (0.3078)	Acc@1 96.094 (96.172)	Acc@5 100.000 (99.934)
Epoch: [113][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3576 (0.3093)	Acc@1 92.578 (96.124)	Acc@5 100.000 (99.952)
Epoch: [113][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 0.2869 (0.3102)	Acc@1 96.875 (96.074)	Acc@5 100.000 (99.947)
Max memory in training epoch: 56.0131584
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.171 (0.171)	Data 0.270 (0.270)	Loss 0.2825 (0.2825)	Acc@1 96.875 (96.875)	Acc@5 99.609 (99.609)
Epoch: [114][64/196]	Time 0.123 (0.121)	Data 0.000 (0.004)	Loss 0.3398 (0.3024)	Acc@1 94.922 (96.310)	Acc@5 100.000 (99.976)
Epoch: [114][128/196]	Time 0.115 (0.121)	Data 0.000 (0.002)	Loss 0.2755 (0.3049)	Acc@1 96.875 (96.200)	Acc@5 100.000 (99.964)
Epoch: [114][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.3332 (0.3064)	Acc@1 92.578 (96.195)	Acc@5 99.609 (99.957)
Max memory in training epoch: 56.0131584
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.150 (0.150)	Data 0.271 (0.271)	Loss 0.3183 (0.3183)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.2900 (0.3032)	Acc@1 98.047 (96.526)	Acc@5 100.000 (99.964)
Epoch: [115][128/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.2984 (0.3034)	Acc@1 97.266 (96.418)	Acc@5 100.000 (99.961)
Epoch: [115][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.2842 (0.3035)	Acc@1 96.875 (96.379)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.0131584
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 352350 ; 353362 ; 0.9971360814122627
[INFO] Storing checkpoint...
  89.4
Max memory: 87.2602112
 23.780s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7894
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1485824
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.177 (0.177)	Data 0.258 (0.258)	Loss 0.3511 (0.3511)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.118 (0.120)	Data 0.000 (0.004)	Loss 0.2984 (0.2964)	Acc@1 96.484 (96.569)	Acc@5 100.000 (99.964)
Epoch: [116][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2641 (0.2974)	Acc@1 98.438 (96.457)	Acc@5 100.000 (99.970)
Epoch: [116][192/196]	Time 0.114 (0.120)	Data 0.000 (0.001)	Loss 0.3288 (0.3020)	Acc@1 93.750 (96.237)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.2083328
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.166 (0.166)	Data 0.280 (0.280)	Loss 0.3215 (0.3215)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.118 (0.119)	Data 0.000 (0.004)	Loss 0.2949 (0.2958)	Acc@1 96.094 (96.394)	Acc@5 100.000 (99.970)
Epoch: [117][128/196]	Time 0.124 (0.119)	Data 0.000 (0.002)	Loss 0.2983 (0.2963)	Acc@1 97.266 (96.369)	Acc@5 100.000 (99.976)
Epoch: [117][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2934 (0.2986)	Acc@1 94.922 (96.262)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.143 (0.143)	Data 0.262 (0.262)	Loss 0.2864 (0.2864)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.3078 (0.2932)	Acc@1 96.875 (96.466)	Acc@5 100.000 (99.958)
Epoch: [118][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.3212 (0.2991)	Acc@1 95.312 (96.248)	Acc@5 100.000 (99.970)
Epoch: [118][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.2552 (0.3023)	Acc@1 98.047 (96.118)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.160 (0.160)	Data 0.259 (0.259)	Loss 0.2581 (0.2581)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.2687 (0.2946)	Acc@1 96.875 (96.334)	Acc@5 100.000 (99.970)
Epoch: [119][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2953 (0.2934)	Acc@1 95.703 (96.357)	Acc@5 100.000 (99.973)
Epoch: [119][192/196]	Time 0.128 (0.119)	Data 0.000 (0.002)	Loss 0.2992 (0.2951)	Acc@1 96.094 (96.250)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.160 (0.160)	Data 0.284 (0.284)	Loss 0.2802 (0.2802)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.119 (0.120)	Data 0.000 (0.005)	Loss 0.3062 (0.2885)	Acc@1 94.531 (96.406)	Acc@5 100.000 (99.976)
Epoch: [120][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.3029 (0.2929)	Acc@1 96.875 (96.288)	Acc@5 100.000 (99.976)
Epoch: [120][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3231 (0.2982)	Acc@1 94.922 (96.076)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.9199744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.05
Max memory: 87.3908224
 23.966s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7103
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1485824
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.199 (0.199)	Data 0.262 (0.262)	Loss 0.2583 (0.2583)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.120 (0.123)	Data 0.000 (0.004)	Loss 0.2765 (0.2805)	Acc@1 96.875 (96.809)	Acc@5 100.000 (99.982)
Epoch: [121][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.2967 (0.2863)	Acc@1 95.703 (96.536)	Acc@5 100.000 (99.976)
Epoch: [121][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3606 (0.2916)	Acc@1 93.359 (96.333)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.2083328
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.168 (0.168)	Data 0.268 (0.268)	Loss 0.3367 (0.3367)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.121 (0.124)	Data 0.000 (0.004)	Loss 0.2772 (0.2958)	Acc@1 97.266 (96.208)	Acc@5 100.000 (99.994)
Epoch: [122][128/196]	Time 0.111 (0.122)	Data 0.000 (0.002)	Loss 0.2724 (0.2953)	Acc@1 97.266 (96.169)	Acc@5 100.000 (99.982)
Epoch: [122][192/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.2794 (0.2984)	Acc@1 95.703 (95.997)	Acc@5 100.000 (99.982)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.144 (0.144)	Data 0.298 (0.298)	Loss 0.2642 (0.2642)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.122 (0.121)	Data 0.000 (0.005)	Loss 0.2635 (0.2905)	Acc@1 98.047 (96.298)	Acc@5 100.000 (99.976)
Epoch: [123][128/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.2943 (0.2907)	Acc@1 94.922 (96.127)	Acc@5 100.000 (99.979)
Epoch: [123][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2842 (0.2956)	Acc@1 96.875 (96.003)	Acc@5 100.000 (99.972)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.166 (0.166)	Data 0.259 (0.259)	Loss 0.2954 (0.2954)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.131 (0.122)	Data 0.000 (0.004)	Loss 0.2717 (0.2931)	Acc@1 96.875 (96.064)	Acc@5 100.000 (99.982)
Epoch: [124][128/196]	Time 0.114 (0.121)	Data 0.000 (0.002)	Loss 0.2797 (0.2945)	Acc@1 96.875 (96.100)	Acc@5 100.000 (99.967)
Epoch: [124][192/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2953 (0.2968)	Acc@1 97.266 (96.035)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.156 (0.156)	Data 0.276 (0.276)	Loss 0.2694 (0.2694)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.137 (0.122)	Data 0.000 (0.004)	Loss 0.2526 (0.2953)	Acc@1 97.266 (95.998)	Acc@5 100.000 (99.958)
Epoch: [125][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.3154 (0.2946)	Acc@1 96.484 (96.048)	Acc@5 99.609 (99.961)
Epoch: [125][192/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.3264 (0.2972)	Acc@1 94.141 (95.952)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9199744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.08
Max memory: 87.3908224
 24.166s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5102
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1485824
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.186 (0.186)	Data 0.264 (0.264)	Loss 0.3159 (0.3159)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.2911 (0.2743)	Acc@1 96.484 (96.851)	Acc@5 100.000 (99.982)
Epoch: [126][128/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3027 (0.2797)	Acc@1 95.312 (96.590)	Acc@5 100.000 (99.982)
Epoch: [126][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2668 (0.2849)	Acc@1 97.656 (96.379)	Acc@5 100.000 (99.980)
Max memory in training epoch: 56.2083328
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.160 (0.160)	Data 0.303 (0.303)	Loss 0.2743 (0.2743)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.136 (0.121)	Data 0.000 (0.005)	Loss 0.2604 (0.2897)	Acc@1 97.656 (96.124)	Acc@5 100.000 (99.994)
Epoch: [127][128/196]	Time 0.118 (0.120)	Data 0.000 (0.003)	Loss 0.3126 (0.2908)	Acc@1 96.094 (96.060)	Acc@5 100.000 (99.979)
Epoch: [127][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3423 (0.2947)	Acc@1 94.141 (95.891)	Acc@5 99.609 (99.964)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.153 (0.153)	Data 0.284 (0.284)	Loss 0.3148 (0.3148)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.3156 (0.2925)	Acc@1 95.703 (96.166)	Acc@5 100.000 (99.976)
Epoch: [128][128/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.3488 (0.2927)	Acc@1 93.750 (96.091)	Acc@5 99.609 (99.970)
Epoch: [128][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.2782 (0.2956)	Acc@1 95.703 (95.952)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.166 (0.166)	Data 0.268 (0.268)	Loss 0.2689 (0.2689)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.2987 (0.2880)	Acc@1 95.703 (96.124)	Acc@5 100.000 (99.952)
Epoch: [129][128/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.2656 (0.2904)	Acc@1 96.484 (96.100)	Acc@5 100.000 (99.958)
Epoch: [129][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2967 (0.2927)	Acc@1 95.703 (96.001)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.9199744
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.181 (0.181)	Data 0.268 (0.268)	Loss 0.2486 (0.2486)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.2710 (0.3037)	Acc@1 97.656 (95.673)	Acc@5 100.000 (99.970)
Epoch: [130][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3468 (0.2985)	Acc@1 93.750 (95.746)	Acc@5 100.000 (99.976)
Epoch: [130][192/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3763 (0.2976)	Acc@1 92.969 (95.740)	Acc@5 100.000 (99.976)
Max memory in training epoch: 55.9199744
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 352060 ; 352350 ; 0.9991769547325103
[INFO] Storing checkpoint...
  89.25
Max memory: 87.3908224
 23.845s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7978
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.14848
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.171 (0.171)	Data 0.260 (0.260)	Loss 0.2777 (0.2777)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.117 (0.119)	Data 0.000 (0.004)	Loss 0.2443 (0.2805)	Acc@1 97.656 (96.472)	Acc@5 100.000 (99.988)
Epoch: [131][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2945 (0.2882)	Acc@1 94.531 (96.106)	Acc@5 100.000 (99.967)
Epoch: [131][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2827 (0.2937)	Acc@1 98.047 (95.901)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.2079232
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.161 (0.161)	Data 0.251 (0.251)	Loss 0.3031 (0.3031)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.121 (0.120)	Data 0.000 (0.004)	Loss 0.2925 (0.2893)	Acc@1 95.703 (96.016)	Acc@5 100.000 (99.976)
Epoch: [132][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.2974 (0.2953)	Acc@1 96.875 (95.882)	Acc@5 100.000 (99.979)
Epoch: [132][192/196]	Time 0.119 (0.120)	Data 0.000 (0.001)	Loss 0.3187 (0.2955)	Acc@1 94.531 (95.849)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.182 (0.182)	Data 0.269 (0.269)	Loss 0.2504 (0.2504)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.124 (0.121)	Data 0.000 (0.004)	Loss 0.3027 (0.2934)	Acc@1 95.312 (95.968)	Acc@5 99.609 (99.976)
Epoch: [133][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.2616 (0.2944)	Acc@1 96.875 (95.891)	Acc@5 100.000 (99.979)
Epoch: [133][192/196]	Time 0.116 (0.120)	Data 0.000 (0.002)	Loss 0.3177 (0.2958)	Acc@1 96.484 (95.853)	Acc@5 99.609 (99.974)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.171 (0.171)	Data 0.290 (0.290)	Loss 0.3011 (0.3011)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.134 (0.120)	Data 0.000 (0.005)	Loss 0.3142 (0.2960)	Acc@1 94.141 (95.907)	Acc@5 100.000 (99.958)
Epoch: [134][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.2774 (0.2942)	Acc@1 95.703 (95.891)	Acc@5 100.000 (99.964)
Epoch: [134][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2724 (0.2962)	Acc@1 96.484 (95.814)	Acc@5 100.000 (99.955)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.175 (0.175)	Data 0.256 (0.256)	Loss 0.2868 (0.2868)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [135][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.3094 (0.2980)	Acc@1 96.094 (95.781)	Acc@5 100.000 (99.928)
Epoch: [135][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.2743 (0.2971)	Acc@1 96.875 (95.806)	Acc@5 100.000 (99.930)
Epoch: [135][192/196]	Time 0.118 (0.120)	Data 0.000 (0.001)	Loss 0.2886 (0.2985)	Acc@1 96.094 (95.695)	Acc@5 99.609 (99.943)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.41
Max memory: 87.3090048
 23.750s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5060
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.14848
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.176 (0.176)	Data 0.294 (0.294)	Loss 0.2827 (0.2827)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.123 (0.123)	Data 0.000 (0.005)	Loss 0.3363 (0.2850)	Acc@1 92.969 (96.028)	Acc@5 100.000 (99.982)
Epoch: [136][128/196]	Time 0.113 (0.122)	Data 0.000 (0.002)	Loss 0.3343 (0.2891)	Acc@1 94.922 (96.003)	Acc@5 100.000 (99.979)
Epoch: [136][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.3216 (0.2928)	Acc@1 94.922 (95.883)	Acc@5 100.000 (99.978)
Max memory in training epoch: 56.2079232
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.141 (0.141)	Data 0.267 (0.267)	Loss 0.2605 (0.2605)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.117 (0.121)	Data 0.000 (0.004)	Loss 0.3215 (0.2880)	Acc@1 94.922 (96.076)	Acc@5 100.000 (99.970)
Epoch: [137][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.3005 (0.2912)	Acc@1 95.703 (95.988)	Acc@5 100.000 (99.976)
Epoch: [137][192/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.3047 (0.2936)	Acc@1 95.312 (95.881)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.164 (0.164)	Data 0.260 (0.260)	Loss 0.3051 (0.3051)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.115 (0.121)	Data 0.000 (0.004)	Loss 0.2432 (0.2916)	Acc@1 96.875 (95.938)	Acc@5 100.000 (99.976)
Epoch: [138][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2752 (0.2926)	Acc@1 97.656 (95.942)	Acc@5 100.000 (99.976)
Epoch: [138][192/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.3100 (0.2920)	Acc@1 93.750 (95.922)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.152 (0.152)	Data 0.290 (0.290)	Loss 0.2554 (0.2554)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2897 (0.2880)	Acc@1 95.312 (96.094)	Acc@5 100.000 (99.976)
Epoch: [139][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.2662 (0.2902)	Acc@1 96.484 (96.012)	Acc@5 100.000 (99.958)
Epoch: [139][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.3229 (0.2962)	Acc@1 95.312 (95.835)	Acc@5 100.000 (99.953)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.160 (0.160)	Data 0.266 (0.266)	Loss 0.2762 (0.2762)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.143 (0.122)	Data 0.000 (0.004)	Loss 0.2836 (0.2945)	Acc@1 96.094 (95.811)	Acc@5 100.000 (99.982)
Epoch: [140][128/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 0.2942 (0.2930)	Acc@1 94.531 (95.827)	Acc@5 100.000 (99.985)
Epoch: [140][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.3262 (0.2938)	Acc@1 93.359 (95.770)	Acc@5 100.000 (99.976)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.84
Max memory: 87.3167872
 24.075s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1844
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.14848
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.164 (0.164)	Data 0.300 (0.300)	Loss 0.2645 (0.2645)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.117 (0.122)	Data 0.000 (0.005)	Loss 0.2616 (0.2692)	Acc@1 95.312 (96.899)	Acc@5 100.000 (99.970)
Epoch: [141][128/196]	Time 0.125 (0.123)	Data 0.000 (0.003)	Loss 0.3030 (0.2763)	Acc@1 96.094 (96.490)	Acc@5 100.000 (99.970)
Epoch: [141][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2930 (0.2829)	Acc@1 95.312 (96.223)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.2079232
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.166 (0.166)	Data 0.268 (0.268)	Loss 0.3022 (0.3022)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [142][64/196]	Time 0.122 (0.122)	Data 0.000 (0.004)	Loss 0.2669 (0.2944)	Acc@1 96.875 (95.655)	Acc@5 100.000 (99.970)
Epoch: [142][128/196]	Time 0.126 (0.122)	Data 0.000 (0.002)	Loss 0.3232 (0.2966)	Acc@1 94.922 (95.670)	Acc@5 99.609 (99.976)
Epoch: [142][192/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.3401 (0.2977)	Acc@1 93.359 (95.612)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.149 (0.149)	Data 0.277 (0.277)	Loss 0.3103 (0.3103)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [143][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.3017 (0.2968)	Acc@1 95.312 (95.673)	Acc@5 100.000 (99.982)
Epoch: [143][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.2681 (0.2907)	Acc@1 96.484 (95.930)	Acc@5 100.000 (99.976)
Epoch: [143][192/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.2697 (0.2925)	Acc@1 96.484 (95.847)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.171 (0.171)	Data 0.277 (0.277)	Loss 0.2537 (0.2537)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.122 (0.123)	Data 0.000 (0.004)	Loss 0.2854 (0.2871)	Acc@1 96.875 (95.925)	Acc@5 100.000 (99.970)
Epoch: [144][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.3246 (0.2855)	Acc@1 94.922 (96.088)	Acc@5 100.000 (99.970)
Epoch: [144][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2578 (0.2886)	Acc@1 98.438 (95.986)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.177 (0.177)	Data 0.264 (0.264)	Loss 0.2916 (0.2916)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.115 (0.123)	Data 0.000 (0.004)	Loss 0.2718 (0.2921)	Acc@1 95.703 (95.805)	Acc@5 100.000 (99.970)
Epoch: [145][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2861 (0.2908)	Acc@1 96.875 (95.858)	Acc@5 100.000 (99.976)
Epoch: [145][192/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.2983 (0.2947)	Acc@1 95.703 (95.748)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.42
Max memory: 87.3090048
 24.440s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7593
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.14848
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.170 (0.170)	Data 0.289 (0.289)	Loss 0.2737 (0.2737)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.2987 (0.2815)	Acc@1 96.484 (96.208)	Acc@5 100.000 (99.988)
Epoch: [146][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.2689 (0.2833)	Acc@1 96.875 (96.188)	Acc@5 99.609 (99.982)
Epoch: [146][192/196]	Time 0.123 (0.120)	Data 0.000 (0.002)	Loss 0.2588 (0.2907)	Acc@1 96.875 (95.952)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.2079232
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.192 (0.192)	Data 0.330 (0.330)	Loss 0.2964 (0.2964)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.119 (0.121)	Data 0.000 (0.005)	Loss 0.2661 (0.2929)	Acc@1 96.875 (95.763)	Acc@5 100.000 (99.982)
Epoch: [147][128/196]	Time 0.119 (0.120)	Data 0.000 (0.003)	Loss 0.3081 (0.2927)	Acc@1 95.703 (95.758)	Acc@5 100.000 (99.973)
Epoch: [147][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.3111 (0.2962)	Acc@1 94.141 (95.646)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.154 (0.154)	Data 0.310 (0.310)	Loss 0.2640 (0.2640)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.116 (0.121)	Data 0.000 (0.005)	Loss 0.3347 (0.2957)	Acc@1 93.359 (95.571)	Acc@5 99.609 (99.952)
Epoch: [148][128/196]	Time 0.115 (0.120)	Data 0.000 (0.003)	Loss 0.3451 (0.2950)	Acc@1 93.750 (95.655)	Acc@5 100.000 (99.970)
Epoch: [148][192/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.3061 (0.2952)	Acc@1 95.703 (95.671)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.178 (0.178)	Data 0.288 (0.288)	Loss 0.2783 (0.2783)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.116 (0.123)	Data 0.000 (0.005)	Loss 0.3002 (0.2773)	Acc@1 94.531 (96.502)	Acc@5 100.000 (99.982)
Epoch: [149][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.2551 (0.2835)	Acc@1 98.047 (96.239)	Acc@5 100.000 (99.973)
Epoch: [149][192/196]	Time 0.120 (0.122)	Data 0.000 (0.002)	Loss 0.2586 (0.2871)	Acc@1 97.266 (96.027)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.9195648
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.165 (0.165)	Data 0.293 (0.293)	Loss 0.2657 (0.2657)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.2366 (0.2614)	Acc@1 97.266 (97.206)	Acc@5 100.000 (99.982)
Epoch: [150][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2177 (0.2520)	Acc@1 99.219 (97.478)	Acc@5 100.000 (99.985)
Epoch: [150][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2436 (0.2473)	Acc@1 98.047 (97.636)	Acc@5 100.000 (99.986)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.81
Max memory: 87.3090048
 24.418s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7375
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.14848
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.195 (0.195)	Data 0.300 (0.300)	Loss 0.2248 (0.2248)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.2108 (0.2299)	Acc@1 98.438 (98.371)	Acc@5 100.000 (99.988)
Epoch: [151][128/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1986 (0.2295)	Acc@1 100.000 (98.359)	Acc@5 100.000 (99.991)
Epoch: [151][192/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.2214 (0.2288)	Acc@1 98.828 (98.342)	Acc@5 100.000 (99.986)
Max memory in training epoch: 56.2079232
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.171 (0.171)	Data 0.283 (0.283)	Loss 0.2036 (0.2036)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.2255 (0.2212)	Acc@1 98.047 (98.588)	Acc@5 100.000 (99.988)
Epoch: [152][128/196]	Time 0.126 (0.123)	Data 0.000 (0.002)	Loss 0.2066 (0.2204)	Acc@1 99.219 (98.583)	Acc@5 100.000 (99.994)
Epoch: [152][192/196]	Time 0.119 (0.123)	Data 0.000 (0.002)	Loss 0.2164 (0.2209)	Acc@1 97.656 (98.535)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.155 (0.155)	Data 0.282 (0.282)	Loss 0.2127 (0.2127)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.1927 (0.2166)	Acc@1 99.609 (98.768)	Acc@5 100.000 (100.000)
Epoch: [153][128/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.2343 (0.2174)	Acc@1 98.047 (98.692)	Acc@5 100.000 (99.997)
Epoch: [153][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 0.2003 (0.2160)	Acc@1 99.609 (98.753)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.150 (0.150)	Data 0.304 (0.304)	Loss 0.2191 (0.2191)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.2144 (0.2149)	Acc@1 98.438 (98.720)	Acc@5 100.000 (100.000)
Epoch: [154][128/196]	Time 0.121 (0.125)	Data 0.000 (0.003)	Loss 0.2222 (0.2132)	Acc@1 98.438 (98.783)	Acc@5 100.000 (99.997)
Epoch: [154][192/196]	Time 0.123 (0.125)	Data 0.000 (0.002)	Loss 0.2026 (0.2118)	Acc@1 99.219 (98.836)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.178 (0.178)	Data 0.273 (0.273)	Loss 0.2065 (0.2065)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.126 (0.125)	Data 0.000 (0.004)	Loss 0.2181 (0.2104)	Acc@1 98.047 (98.894)	Acc@5 100.000 (99.994)
Epoch: [155][128/196]	Time 0.126 (0.125)	Data 0.000 (0.002)	Loss 0.2292 (0.2091)	Acc@1 98.438 (98.910)	Acc@5 100.000 (99.994)
Epoch: [155][192/196]	Time 0.120 (0.125)	Data 0.000 (0.002)	Loss 0.2217 (0.2089)	Acc@1 98.828 (98.927)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.38
Max memory: 87.3167872
 24.814s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6946
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.14848
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.178 (0.178)	Data 0.296 (0.296)	Loss 0.1922 (0.1922)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.115 (0.121)	Data 0.000 (0.005)	Loss 0.2004 (0.2042)	Acc@1 99.219 (99.056)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.157 (0.120)	Data 0.000 (0.002)	Loss 0.1991 (0.2056)	Acc@1 99.609 (99.010)	Acc@5 100.000 (99.997)
Epoch: [156][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.2147 (0.2071)	Acc@1 99.219 (98.941)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.2079232
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.180 (0.180)	Data 0.276 (0.276)	Loss 0.1906 (0.1906)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.118 (0.122)	Data 0.000 (0.004)	Loss 0.2003 (0.2048)	Acc@1 99.219 (99.075)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.123 (0.121)	Data 0.000 (0.002)	Loss 0.1907 (0.2048)	Acc@1 100.000 (99.052)	Acc@5 100.000 (100.000)
Epoch: [157][192/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1930 (0.2053)	Acc@1 99.609 (99.028)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.166 (0.166)	Data 0.279 (0.279)	Loss 0.2028 (0.2028)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.122 (0.121)	Data 0.000 (0.004)	Loss 0.2047 (0.2039)	Acc@1 99.219 (98.984)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.116 (0.122)	Data 0.000 (0.002)	Loss 0.1941 (0.2030)	Acc@1 99.609 (99.016)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.2048 (0.2028)	Acc@1 99.219 (99.039)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.186 (0.186)	Data 0.254 (0.254)	Loss 0.2068 (0.2068)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.119 (0.122)	Data 0.000 (0.004)	Loss 0.2206 (0.2022)	Acc@1 97.656 (99.093)	Acc@5 100.000 (99.994)
Epoch: [159][128/196]	Time 0.120 (0.121)	Data 0.000 (0.002)	Loss 0.2151 (0.2022)	Acc@1 99.219 (99.098)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.120 (0.122)	Data 0.000 (0.001)	Loss 0.1955 (0.2019)	Acc@1 99.609 (99.116)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.165 (0.165)	Data 0.289 (0.289)	Loss 0.2095 (0.2095)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.123 (0.121)	Data 0.000 (0.005)	Loss 0.1907 (0.1999)	Acc@1 100.000 (99.183)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.1906 (0.2002)	Acc@1 99.609 (99.176)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.122 (0.121)	Data 0.000 (0.002)	Loss 0.1864 (0.2005)	Acc@1 100.000 (99.172)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.63
Max memory: 87.3167872
 24.173s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7101
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.14848
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.177 (0.177)	Data 0.295 (0.295)	Loss 0.1918 (0.1918)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.118 (0.120)	Data 0.000 (0.005)	Loss 0.1966 (0.1960)	Acc@1 99.219 (99.333)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.112 (0.120)	Data 0.000 (0.002)	Loss 0.2036 (0.1968)	Acc@1 98.438 (99.261)	Acc@5 100.000 (100.000)
Epoch: [161][192/196]	Time 0.116 (0.121)	Data 0.000 (0.002)	Loss 0.1962 (0.1973)	Acc@1 99.609 (99.247)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.2079232
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.179 (0.179)	Data 0.292 (0.292)	Loss 0.2088 (0.2088)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.1955 (0.1957)	Acc@1 99.219 (99.345)	Acc@5 100.000 (100.000)
Epoch: [162][128/196]	Time 0.121 (0.122)	Data 0.000 (0.002)	Loss 0.1896 (0.1969)	Acc@1 99.609 (99.285)	Acc@5 100.000 (100.000)
Epoch: [162][192/196]	Time 0.118 (0.123)	Data 0.000 (0.002)	Loss 0.1926 (0.1973)	Acc@1 99.219 (99.257)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.157 (0.157)	Data 0.265 (0.265)	Loss 0.2126 (0.2126)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.119 (0.124)	Data 0.000 (0.004)	Loss 0.1889 (0.1943)	Acc@1 99.609 (99.387)	Acc@5 100.000 (99.994)
Epoch: [163][128/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.2092 (0.1943)	Acc@1 99.609 (99.349)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1783 (0.1952)	Acc@1 100.000 (99.288)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.178 (0.178)	Data 0.277 (0.277)	Loss 0.1863 (0.1863)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.122 (0.125)	Data 0.000 (0.004)	Loss 0.2015 (0.1931)	Acc@1 98.828 (99.345)	Acc@5 100.000 (100.000)
Epoch: [164][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 0.1927 (0.1930)	Acc@1 99.219 (99.322)	Acc@5 100.000 (100.000)
Epoch: [164][192/196]	Time 0.135 (0.124)	Data 0.000 (0.002)	Loss 0.1872 (0.1939)	Acc@1 100.000 (99.304)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.141 (0.141)	Data 0.316 (0.316)	Loss 0.1847 (0.1847)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.125 (0.126)	Data 0.000 (0.005)	Loss 0.1855 (0.1919)	Acc@1 100.000 (99.411)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.120 (0.124)	Data 0.000 (0.003)	Loss 0.1886 (0.1916)	Acc@1 99.609 (99.428)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1805 (0.1927)	Acc@1 100.000 (99.350)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.46
Max memory: 87.3167872
 24.576s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5602
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.14848
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.197 (0.197)	Data 0.255 (0.255)	Loss 0.1884 (0.1884)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.121 (0.123)	Data 0.000 (0.004)	Loss 0.1912 (0.1905)	Acc@1 99.609 (99.327)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.117 (0.122)	Data 0.000 (0.002)	Loss 0.1753 (0.1912)	Acc@1 100.000 (99.337)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.115 (0.122)	Data 0.000 (0.002)	Loss 0.1763 (0.1910)	Acc@1 100.000 (99.360)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.2079232
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.170 (0.170)	Data 0.286 (0.286)	Loss 0.1835 (0.1835)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.122 (0.125)	Data 0.000 (0.005)	Loss 0.1908 (0.1892)	Acc@1 99.609 (99.459)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.118 (0.124)	Data 0.000 (0.002)	Loss 0.2025 (0.1897)	Acc@1 98.438 (99.419)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.123 (0.124)	Data 0.000 (0.002)	Loss 0.1864 (0.1900)	Acc@1 99.609 (99.391)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.169 (0.169)	Data 0.302 (0.302)	Loss 0.1866 (0.1866)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.1892 (0.1896)	Acc@1 99.219 (99.381)	Acc@5 100.000 (99.994)
Epoch: [168][128/196]	Time 0.125 (0.126)	Data 0.000 (0.003)	Loss 0.1799 (0.1889)	Acc@1 100.000 (99.440)	Acc@5 100.000 (99.997)
Epoch: [168][192/196]	Time 0.124 (0.125)	Data 0.000 (0.002)	Loss 0.1909 (0.1893)	Acc@1 99.219 (99.411)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.167 (0.167)	Data 0.313 (0.313)	Loss 0.1790 (0.1790)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.119 (0.124)	Data 0.000 (0.005)	Loss 0.1823 (0.1880)	Acc@1 99.609 (99.453)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.122 (0.124)	Data 0.000 (0.003)	Loss 0.1858 (0.1886)	Acc@1 99.219 (99.425)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.123 (0.123)	Data 0.000 (0.002)	Loss 0.1772 (0.1885)	Acc@1 100.000 (99.423)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.177 (0.177)	Data 0.256 (0.256)	Loss 0.1860 (0.1860)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.121 (0.125)	Data 0.000 (0.004)	Loss 0.1826 (0.1874)	Acc@1 99.609 (99.477)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.115 (0.126)	Data 0.000 (0.002)	Loss 0.1867 (0.1876)	Acc@1 99.219 (99.452)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.119 (0.125)	Data 0.000 (0.002)	Loss 0.1824 (0.1873)	Acc@1 99.219 (99.437)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.56
Max memory: 87.3167872
 24.763s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2365
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.14848
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.191 (0.191)	Data 0.288 (0.288)	Loss 0.1913 (0.1913)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.136 (0.123)	Data 0.000 (0.005)	Loss 0.1775 (0.1837)	Acc@1 100.000 (99.609)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.119 (0.122)	Data 0.000 (0.002)	Loss 0.1785 (0.1849)	Acc@1 100.000 (99.534)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.127 (0.122)	Data 0.000 (0.002)	Loss 0.1814 (0.1855)	Acc@1 99.609 (99.518)	Acc@5 100.000 (99.998)
Max memory in training epoch: 56.2079232
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.163 (0.163)	Data 0.287 (0.287)	Loss 0.1923 (0.1923)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.118 (0.123)	Data 0.000 (0.005)	Loss 0.1875 (0.1857)	Acc@1 99.219 (99.501)	Acc@5 100.000 (99.988)
Epoch: [172][128/196]	Time 0.118 (0.122)	Data 0.000 (0.002)	Loss 0.1681 (0.1860)	Acc@1 100.000 (99.485)	Acc@5 100.000 (99.994)
Epoch: [172][192/196]	Time 0.123 (0.122)	Data 0.000 (0.002)	Loss 0.1910 (0.1851)	Acc@1 99.219 (99.506)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.163 (0.163)	Data 0.290 (0.290)	Loss 0.1766 (0.1766)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.127 (0.125)	Data 0.000 (0.005)	Loss 0.1915 (0.1849)	Acc@1 98.828 (99.483)	Acc@5 100.000 (99.994)
Epoch: [173][128/196]	Time 0.129 (0.125)	Data 0.000 (0.002)	Loss 0.1863 (0.1854)	Acc@1 99.219 (99.446)	Acc@5 100.000 (99.994)
Epoch: [173][192/196]	Time 0.125 (0.125)	Data 0.000 (0.002)	Loss 0.1844 (0.1853)	Acc@1 99.609 (99.464)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.167 (0.167)	Data 0.290 (0.290)	Loss 0.2153 (0.2153)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.121 (0.123)	Data 0.000 (0.005)	Loss 0.1807 (0.1840)	Acc@1 100.000 (99.483)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 0.1972 (0.1848)	Acc@1 99.219 (99.479)	Acc@5 100.000 (100.000)
Epoch: [174][192/196]	Time 0.124 (0.123)	Data 0.000 (0.002)	Loss 0.2059 (0.1849)	Acc@1 98.828 (99.464)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.139 (0.139)	Data 0.301 (0.301)	Loss 0.2079 (0.2079)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.123 (0.124)	Data 0.000 (0.005)	Loss 0.1801 (0.1817)	Acc@1 99.609 (99.597)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.120 (0.123)	Data 0.000 (0.003)	Loss 0.1769 (0.1821)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1786 (0.1832)	Acc@1 100.000 (99.510)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.51
Max memory: 87.3167872
 24.553s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8699
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.14848
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.175 (0.175)	Data 0.300 (0.300)	Loss 0.2085 (0.2085)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.133 (0.122)	Data 0.000 (0.005)	Loss 0.1776 (0.1804)	Acc@1 100.000 (99.639)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.121 (0.121)	Data 0.000 (0.002)	Loss 0.1851 (0.1804)	Acc@1 99.219 (99.628)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.119 (0.121)	Data 0.000 (0.002)	Loss 0.1756 (0.1815)	Acc@1 99.609 (99.563)	Acc@5 100.000 (100.000)
Max memory in training epoch: 56.2079232
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.152 (0.152)	Data 0.254 (0.254)	Loss 0.1828 (0.1828)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.123 (0.122)	Data 0.000 (0.004)	Loss 0.1837 (0.1783)	Acc@1 100.000 (99.657)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.134 (0.123)	Data 0.000 (0.002)	Loss 0.1740 (0.1797)	Acc@1 100.000 (99.621)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 0.117 (0.123)	Data 0.000 (0.001)	Loss 0.1969 (0.1797)	Acc@1 98.828 (99.617)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.155 (0.155)	Data 0.286 (0.286)	Loss 0.1696 (0.1696)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.124 (0.123)	Data 0.000 (0.005)	Loss 0.1746 (0.1789)	Acc@1 100.000 (99.681)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.139 (0.124)	Data 0.000 (0.002)	Loss 0.1805 (0.1795)	Acc@1 99.609 (99.606)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.126 (0.124)	Data 0.000 (0.002)	Loss 0.1817 (0.1800)	Acc@1 99.609 (99.599)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.164 (0.164)	Data 0.320 (0.320)	Loss 0.1735 (0.1735)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.122 (0.124)	Data 0.000 (0.005)	Loss 0.1743 (0.1804)	Acc@1 100.000 (99.531)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.126 (0.124)	Data 0.000 (0.003)	Loss 0.1731 (0.1800)	Acc@1 100.000 (99.573)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.117 (0.123)	Data 0.000 (0.002)	Loss 0.1793 (0.1799)	Acc@1 99.609 (99.585)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.9195648
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.165 (0.165)	Data 0.283 (0.283)	Loss 0.1780 (0.1780)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.121 (0.125)	Data 0.000 (0.005)	Loss 0.1689 (0.1786)	Acc@1 99.609 (99.579)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.120 (0.123)	Data 0.000 (0.002)	Loss 0.1684 (0.1788)	Acc@1 100.000 (99.612)	Acc@5 100.000 (99.997)
Epoch: [180][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 0.1732 (0.1793)	Acc@1 99.609 (99.575)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.9195648
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 29, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(29, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(28, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(10, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(43, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(43, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.45
Max memory: 87.3167872
 24.419s  Thres 0.0001 5
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7084
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.223 (0.223)	Data 0.309 (0.309)	Loss 3.3422 (3.3422)	Acc@1 8.984 (8.984)	Acc@5 53.125 (53.125)
Epoch: [1][64/196]	Time 0.121 (0.130)	Data 0.000 (0.005)	Loss 2.4825 (2.6671)	Acc@1 33.984 (25.457)	Acc@5 85.156 (78.221)
Epoch: [1][128/196]	Time 0.127 (0.129)	Data 0.000 (0.003)	Loss 2.2429 (2.4992)	Acc@1 40.625 (30.587)	Acc@5 87.500 (83.194)
Epoch: [1][192/196]	Time 0.124 (0.129)	Data 0.000 (0.002)	Loss 2.1587 (2.3790)	Acc@1 41.797 (34.660)	Acc@5 91.016 (85.881)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.169 (0.169)	Data 0.337 (0.337)	Loss 1.9971 (1.9971)	Acc@1 47.266 (47.266)	Acc@5 91.797 (91.797)
Epoch: [2][64/196]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 1.9177 (1.9568)	Acc@1 48.828 (49.669)	Acc@5 91.406 (93.179)
Epoch: [2][128/196]	Time 0.145 (0.132)	Data 0.000 (0.003)	Loss 1.6879 (1.8705)	Acc@1 57.031 (52.619)	Acc@5 96.875 (94.129)
Epoch: [2][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 1.6969 (1.7960)	Acc@1 58.203 (55.070)	Acc@5 94.922 (94.780)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.186 (0.186)	Data 0.262 (0.262)	Loss 1.5439 (1.5439)	Acc@1 61.328 (61.328)	Acc@5 97.266 (97.266)
Epoch: [3][64/196]	Time 0.128 (0.135)	Data 0.000 (0.004)	Loss 1.4843 (1.5222)	Acc@1 65.234 (64.002)	Acc@5 96.094 (96.647)
Epoch: [3][128/196]	Time 0.140 (0.135)	Data 0.000 (0.002)	Loss 1.4243 (1.4795)	Acc@1 62.500 (65.059)	Acc@5 98.828 (97.035)
Epoch: [3][192/196]	Time 0.139 (0.134)	Data 0.000 (0.002)	Loss 1.3239 (1.4371)	Acc@1 67.969 (66.358)	Acc@5 97.656 (97.264)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.180 (0.180)	Data 0.286 (0.286)	Loss 1.2547 (1.2547)	Acc@1 71.484 (71.484)	Acc@5 98.047 (98.047)
Epoch: [4][64/196]	Time 0.135 (0.134)	Data 0.000 (0.005)	Loss 1.1266 (1.2643)	Acc@1 76.172 (71.599)	Acc@5 99.609 (98.203)
Epoch: [4][128/196]	Time 0.127 (0.134)	Data 0.000 (0.002)	Loss 1.0789 (1.2383)	Acc@1 78.516 (72.353)	Acc@5 99.219 (98.189)
Epoch: [4][192/196]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 1.1946 (1.2214)	Acc@1 73.828 (72.840)	Acc@5 98.828 (98.197)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.171 (0.171)	Data 0.293 (0.293)	Loss 1.1388 (1.1388)	Acc@1 75.000 (75.000)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.129 (0.134)	Data 0.000 (0.005)	Loss 1.0918 (1.1402)	Acc@1 78.516 (74.982)	Acc@5 99.219 (98.371)
Epoch: [5][128/196]	Time 0.135 (0.134)	Data 0.000 (0.002)	Loss 0.9380 (1.1159)	Acc@1 83.203 (75.578)	Acc@5 100.000 (98.483)
Epoch: [5][192/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 1.0959 (1.0955)	Acc@1 75.391 (76.046)	Acc@5 99.609 (98.551)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  72.89
Max memory: 103.3835008
 26.649s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8556
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
lr: 0.1
1

Epoch: [6 | 10] LR: 0.100000
batch Size 256
Epoch: [6][0/196]	Time 0.212 (0.212)	Data 0.262 (0.262)	Loss 1.1821 (1.1821)	Acc@1 73.828 (73.828)	Acc@5 97.656 (97.656)
Epoch: [6][64/196]	Time 0.143 (0.132)	Data 0.000 (0.004)	Loss 1.1648 (1.0262)	Acc@1 74.219 (78.035)	Acc@5 98.828 (98.648)
Epoch: [6][128/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.9276 (1.0073)	Acc@1 80.469 (78.513)	Acc@5 99.219 (98.749)
Epoch: [6][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 1.1454 (0.9967)	Acc@1 72.266 (78.568)	Acc@5 98.828 (98.782)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [7 | 10] LR: 0.100000
batch Size 256
Epoch: [7][0/196]	Time 0.184 (0.184)	Data 0.256 (0.256)	Loss 0.9780 (0.9780)	Acc@1 78.125 (78.125)	Acc@5 100.000 (100.000)
Epoch: [7][64/196]	Time 0.138 (0.134)	Data 0.000 (0.004)	Loss 0.9265 (0.9561)	Acc@1 82.031 (79.225)	Acc@5 98.438 (98.894)
Epoch: [7][128/196]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 0.7872 (0.9486)	Acc@1 85.156 (79.439)	Acc@5 99.219 (98.898)
Epoch: [7][192/196]	Time 0.136 (0.134)	Data 0.000 (0.001)	Loss 0.9227 (0.9485)	Acc@1 80.859 (79.323)	Acc@5 99.219 (98.867)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [8 | 10] LR: 0.100000
batch Size 256
Epoch: [8][0/196]	Time 0.174 (0.174)	Data 0.303 (0.303)	Loss 0.8907 (0.8907)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [8][64/196]	Time 0.130 (0.138)	Data 0.000 (0.005)	Loss 0.9737 (0.9136)	Acc@1 75.000 (80.090)	Acc@5 97.266 (98.894)
Epoch: [8][128/196]	Time 0.138 (0.137)	Data 0.000 (0.003)	Loss 0.8848 (0.9111)	Acc@1 81.250 (80.027)	Acc@5 98.047 (98.889)
Epoch: [8][192/196]	Time 0.132 (0.136)	Data 0.000 (0.002)	Loss 0.8883 (0.9017)	Acc@1 80.469 (80.250)	Acc@5 99.219 (98.952)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [9 | 10] LR: 0.100000
batch Size 256
Epoch: [9][0/196]	Time 0.182 (0.182)	Data 0.270 (0.270)	Loss 0.9153 (0.9153)	Acc@1 79.688 (79.688)	Acc@5 99.219 (99.219)
Epoch: [9][64/196]	Time 0.148 (0.135)	Data 0.000 (0.004)	Loss 0.8267 (0.8663)	Acc@1 79.297 (81.202)	Acc@5 98.047 (98.972)
Epoch: [9][128/196]	Time 0.141 (0.136)	Data 0.000 (0.002)	Loss 0.8437 (0.8674)	Acc@1 85.547 (80.990)	Acc@5 97.656 (98.949)
Epoch: [9][192/196]	Time 0.131 (0.135)	Data 0.000 (0.002)	Loss 0.7412 (0.8667)	Acc@1 84.766 (81.019)	Acc@5 99.609 (98.984)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [10 | 10] LR: 0.100000
batch Size 256
Epoch: [10][0/196]	Time 0.168 (0.168)	Data 0.290 (0.290)	Loss 0.8068 (0.8068)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.135 (0.134)	Data 0.000 (0.005)	Loss 0.7436 (0.8341)	Acc@1 87.109 (81.785)	Acc@5 100.000 (99.111)
Epoch: [10][128/196]	Time 0.138 (0.135)	Data 0.000 (0.002)	Loss 0.8419 (0.8342)	Acc@1 82.422 (81.847)	Acc@5 98.438 (99.089)
Epoch: [10][192/196]	Time 0.134 (0.135)	Data 0.000 (0.002)	Loss 0.8590 (0.8349)	Acc@1 78.906 (81.784)	Acc@5 98.828 (99.081)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  67.56
Max memory: 103.3833984
 26.758s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6092
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
lr: 0.1
1

Epoch: [11 | 15] LR: 0.100000
batch Size 256
Epoch: [11][0/196]	Time 0.209 (0.209)	Data 0.279 (0.279)	Loss 0.7976 (0.7976)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [11][64/196]	Time 0.132 (0.135)	Data 0.000 (0.004)	Loss 0.7614 (0.8267)	Acc@1 82.422 (81.863)	Acc@5 99.609 (99.117)
Epoch: [11][128/196]	Time 0.136 (0.134)	Data 0.000 (0.002)	Loss 0.8566 (0.8234)	Acc@1 80.078 (81.959)	Acc@5 98.438 (99.116)
Epoch: [11][192/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.8303 (0.8219)	Acc@1 82.031 (82.003)	Acc@5 99.219 (99.105)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [12 | 15] LR: 0.100000
batch Size 256
Epoch: [12][0/196]	Time 0.172 (0.172)	Data 0.300 (0.300)	Loss 0.8113 (0.8113)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [12][64/196]	Time 0.156 (0.137)	Data 0.000 (0.005)	Loss 0.8439 (0.8088)	Acc@1 80.469 (82.452)	Acc@5 100.000 (99.117)
Epoch: [12][128/196]	Time 0.129 (0.136)	Data 0.000 (0.002)	Loss 0.7838 (0.8080)	Acc@1 85.156 (82.591)	Acc@5 98.828 (99.152)
Epoch: [12][192/196]	Time 0.136 (0.136)	Data 0.000 (0.002)	Loss 0.7504 (0.8120)	Acc@1 82.812 (82.294)	Acc@5 99.609 (99.081)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [13 | 15] LR: 0.100000
batch Size 256
Epoch: [13][0/196]	Time 0.192 (0.192)	Data 0.292 (0.292)	Loss 0.7854 (0.7854)	Acc@1 83.203 (83.203)	Acc@5 98.828 (98.828)
Epoch: [13][64/196]	Time 0.139 (0.138)	Data 0.000 (0.005)	Loss 0.8247 (0.8090)	Acc@1 82.422 (82.398)	Acc@5 99.219 (99.183)
Epoch: [13][128/196]	Time 0.136 (0.137)	Data 0.000 (0.002)	Loss 0.8182 (0.8089)	Acc@1 83.203 (82.325)	Acc@5 99.609 (99.155)
Epoch: [13][192/196]	Time 0.131 (0.137)	Data 0.000 (0.002)	Loss 0.8001 (0.8054)	Acc@1 82.812 (82.468)	Acc@5 98.828 (99.136)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [14 | 15] LR: 0.100000
batch Size 256
Epoch: [14][0/196]	Time 0.180 (0.180)	Data 0.298 (0.298)	Loss 0.7582 (0.7582)	Acc@1 86.328 (86.328)	Acc@5 98.438 (98.438)
Epoch: [14][64/196]	Time 0.140 (0.136)	Data 0.000 (0.005)	Loss 0.7525 (0.7934)	Acc@1 83.594 (82.825)	Acc@5 99.609 (99.123)
Epoch: [14][128/196]	Time 0.130 (0.137)	Data 0.000 (0.002)	Loss 0.8290 (0.7939)	Acc@1 80.859 (82.722)	Acc@5 98.828 (99.137)
Epoch: [14][192/196]	Time 0.133 (0.136)	Data 0.000 (0.002)	Loss 0.7740 (0.7938)	Acc@1 84.766 (82.792)	Acc@5 98.828 (99.138)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [15 | 15] LR: 0.100000
batch Size 256
Epoch: [15][0/196]	Time 0.183 (0.183)	Data 0.267 (0.267)	Loss 0.6717 (0.6717)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 0.136 (0.138)	Data 0.000 (0.004)	Loss 0.7615 (0.7694)	Acc@1 83.984 (83.702)	Acc@5 99.219 (99.321)
Epoch: [15][128/196]	Time 0.132 (0.137)	Data 0.000 (0.002)	Loss 0.7624 (0.7766)	Acc@1 84.766 (83.464)	Acc@5 99.609 (99.258)
Epoch: [15][192/196]	Time 0.132 (0.137)	Data 0.000 (0.002)	Loss 0.6724 (0.7816)	Acc@1 88.281 (83.341)	Acc@5 100.000 (99.253)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  77.18
Max memory: 103.3833984
 27.208s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6312
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
lr: 0.1
1

Epoch: [16 | 20] LR: 0.100000
batch Size 256
Epoch: [16][0/196]	Time 0.207 (0.207)	Data 0.295 (0.295)	Loss 0.7764 (0.7764)	Acc@1 80.469 (80.469)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.127 (0.132)	Data 0.000 (0.005)	Loss 0.8289 (0.7649)	Acc@1 82.031 (83.792)	Acc@5 98.828 (99.255)
Epoch: [16][128/196]	Time 0.139 (0.132)	Data 0.000 (0.002)	Loss 0.8137 (0.7712)	Acc@1 84.375 (83.600)	Acc@5 98.047 (99.213)
Epoch: [16][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7588 (0.7763)	Acc@1 85.938 (83.347)	Acc@5 97.656 (99.211)
Max memory in training epoch: 66.6466816
lr: 0.1
1

Epoch: [17 | 20] LR: 0.100000
batch Size 256
Epoch: [17][0/196]	Time 0.171 (0.171)	Data 0.298 (0.298)	Loss 0.6930 (0.6930)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [17][64/196]	Time 0.133 (0.133)	Data 0.000 (0.005)	Loss 0.7308 (0.7756)	Acc@1 86.328 (83.678)	Acc@5 98.828 (99.279)
Epoch: [17][128/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7917 (0.7713)	Acc@1 84.375 (83.730)	Acc@5 98.828 (99.198)
Epoch: [17][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7881 (0.7742)	Acc@1 82.031 (83.565)	Acc@5 99.609 (99.211)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [18 | 20] LR: 0.100000
batch Size 256
Epoch: [18][0/196]	Time 0.187 (0.187)	Data 0.283 (0.283)	Loss 0.7790 (0.7790)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.161 (0.138)	Data 0.000 (0.005)	Loss 0.8271 (0.7756)	Acc@1 83.594 (83.612)	Acc@5 98.438 (99.279)
Epoch: [18][128/196]	Time 0.133 (0.136)	Data 0.000 (0.002)	Loss 0.7493 (0.7753)	Acc@1 83.594 (83.542)	Acc@5 100.000 (99.258)
Epoch: [18][192/196]	Time 0.132 (0.135)	Data 0.000 (0.002)	Loss 0.8473 (0.7752)	Acc@1 78.125 (83.582)	Acc@5 99.219 (99.271)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [19 | 20] LR: 0.100000
batch Size 256
Epoch: [19][0/196]	Time 0.182 (0.182)	Data 0.312 (0.312)	Loss 0.7429 (0.7429)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.136 (0.136)	Data 0.000 (0.005)	Loss 0.8457 (0.7578)	Acc@1 80.859 (84.267)	Acc@5 98.828 (99.243)
Epoch: [19][128/196]	Time 0.127 (0.135)	Data 0.000 (0.003)	Loss 0.7346 (0.7586)	Acc@1 82.812 (84.139)	Acc@5 99.219 (99.258)
Epoch: [19][192/196]	Time 0.134 (0.135)	Data 0.000 (0.002)	Loss 0.8608 (0.7666)	Acc@1 80.469 (83.857)	Acc@5 99.219 (99.233)
Max memory in training epoch: 66.541824
lr: 0.1
1

Epoch: [20 | 20] LR: 0.100000
batch Size 256
Epoch: [20][0/196]	Time 0.172 (0.172)	Data 0.266 (0.266)	Loss 0.7479 (0.7479)	Acc@1 87.109 (87.109)	Acc@5 98.047 (98.047)
Epoch: [20][64/196]	Time 0.131 (0.137)	Data 0.000 (0.004)	Loss 0.7774 (0.7657)	Acc@1 80.078 (84.237)	Acc@5 99.609 (99.219)
Epoch: [20][128/196]	Time 0.123 (0.135)	Data 0.000 (0.002)	Loss 0.8504 (0.7688)	Acc@1 78.516 (83.903)	Acc@5 98.828 (99.264)
Epoch: [20][192/196]	Time 0.138 (0.135)	Data 0.000 (0.002)	Loss 0.7408 (0.7669)	Acc@1 84.375 (83.982)	Acc@5 99.219 (99.253)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 486232 ; 487386 ; 0.9976322668275248
[INFO] Storing checkpoint...
  66.07
Max memory: 103.3833984
 26.744s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3575
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.2020864
lr: 0.1
1

Epoch: [21 | 25] LR: 0.100000
batch Size 256
Epoch: [21][0/196]	Time 0.173 (0.173)	Data 0.286 (0.286)	Loss 0.7691 (0.7691)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [21][64/196]	Time 0.133 (0.131)	Data 0.000 (0.005)	Loss 0.7730 (0.7277)	Acc@1 82.812 (85.379)	Acc@5 98.828 (99.309)
Epoch: [21][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.8629 (0.7402)	Acc@1 80.859 (84.893)	Acc@5 98.828 (99.279)
Epoch: [21][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.8580 (0.7565)	Acc@1 81.641 (84.286)	Acc@5 97.656 (99.215)
Max memory in training epoch: 66.6450432
lr: 0.1
1

Epoch: [22 | 25] LR: 0.100000
batch Size 256
Epoch: [22][0/196]	Time 0.182 (0.182)	Data 0.267 (0.267)	Loss 0.8450 (0.8450)	Acc@1 81.250 (81.250)	Acc@5 98.828 (98.828)
Epoch: [22][64/196]	Time 0.127 (0.135)	Data 0.000 (0.004)	Loss 0.6986 (0.7501)	Acc@1 85.156 (84.555)	Acc@5 100.000 (99.387)
Epoch: [22][128/196]	Time 0.156 (0.134)	Data 0.000 (0.002)	Loss 0.7466 (0.7504)	Acc@1 85.547 (84.417)	Acc@5 99.609 (99.340)
Epoch: [22][192/196]	Time 0.139 (0.134)	Data 0.000 (0.002)	Loss 0.9498 (0.7572)	Acc@1 75.781 (84.225)	Acc@5 99.609 (99.298)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [23 | 25] LR: 0.100000
batch Size 256
Epoch: [23][0/196]	Time 0.160 (0.160)	Data 0.279 (0.279)	Loss 0.7426 (0.7426)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.133 (0.136)	Data 0.000 (0.004)	Loss 0.8585 (0.7375)	Acc@1 80.859 (84.826)	Acc@5 98.047 (99.231)
Epoch: [23][128/196]	Time 0.132 (0.134)	Data 0.000 (0.002)	Loss 0.7505 (0.7465)	Acc@1 83.203 (84.578)	Acc@5 98.047 (99.237)
Epoch: [23][192/196]	Time 0.139 (0.133)	Data 0.000 (0.002)	Loss 0.7464 (0.7463)	Acc@1 83.984 (84.581)	Acc@5 99.219 (99.269)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [24 | 25] LR: 0.100000
batch Size 256
Epoch: [24][0/196]	Time 0.189 (0.189)	Data 0.284 (0.284)	Loss 0.7865 (0.7865)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [24][64/196]	Time 0.139 (0.134)	Data 0.000 (0.005)	Loss 0.7518 (0.7398)	Acc@1 81.641 (84.573)	Acc@5 100.000 (99.303)
Epoch: [24][128/196]	Time 0.137 (0.133)	Data 0.000 (0.002)	Loss 0.7110 (0.7419)	Acc@1 84.766 (84.529)	Acc@5 100.000 (99.325)
Epoch: [24][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.6706 (0.7476)	Acc@1 88.281 (84.420)	Acc@5 100.000 (99.306)
Max memory in training epoch: 66.5401856
lr: 0.1
1

Epoch: [25 | 25] LR: 0.100000
batch Size 256
Epoch: [25][0/196]	Time 0.189 (0.189)	Data 0.262 (0.262)	Loss 0.6547 (0.6547)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [25][64/196]	Time 0.125 (0.137)	Data 0.000 (0.004)	Loss 0.8057 (0.7390)	Acc@1 82.422 (84.808)	Acc@5 99.219 (99.447)
Epoch: [25][128/196]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.7438 (0.7462)	Acc@1 84.375 (84.663)	Acc@5 99.609 (99.349)
Epoch: [25][192/196]	Time 0.138 (0.134)	Data 0.000 (0.002)	Loss 0.7552 (0.7466)	Acc@1 85.156 (84.565)	Acc@5 98.828 (99.352)
Max memory in training epoch: 66.5401856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 478152 ; 486232 ; 0.983382418269468
[INFO] Storing checkpoint...
  77.19
Max memory: 103.3821696
 26.643s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3561
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.198912
lr: 0.1
1

Epoch: [26 | 30] LR: 0.100000
batch Size 256
Epoch: [26][0/196]	Time 0.204 (0.204)	Data 0.290 (0.290)	Loss 0.6816 (0.6816)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.137 (0.135)	Data 0.000 (0.005)	Loss 0.7314 (0.6941)	Acc@1 87.109 (86.412)	Acc@5 100.000 (99.549)
Epoch: [26][128/196]	Time 0.130 (0.134)	Data 0.000 (0.002)	Loss 0.6986 (0.7156)	Acc@1 87.109 (85.626)	Acc@5 98.828 (99.400)
Epoch: [26][192/196]	Time 0.134 (0.134)	Data 0.000 (0.002)	Loss 0.8159 (0.7325)	Acc@1 82.031 (85.156)	Acc@5 100.000 (99.314)
Max memory in training epoch: 66.6323456
lr: 0.1
1

Epoch: [27 | 30] LR: 0.100000
batch Size 256
Epoch: [27][0/196]	Time 0.199 (0.199)	Data 0.256 (0.256)	Loss 0.7121 (0.7121)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.133 (0.135)	Data 0.000 (0.004)	Loss 0.7705 (0.7447)	Acc@1 83.984 (84.489)	Acc@5 99.609 (99.309)
Epoch: [27][128/196]	Time 0.133 (0.135)	Data 0.000 (0.002)	Loss 0.7045 (0.7401)	Acc@1 85.156 (84.754)	Acc@5 99.219 (99.325)
Epoch: [27][192/196]	Time 0.139 (0.135)	Data 0.000 (0.001)	Loss 0.8175 (0.7413)	Acc@1 82.812 (84.652)	Acc@5 100.000 (99.344)
Max memory in training epoch: 66.4750592
lr: 0.1
1

Epoch: [28 | 30] LR: 0.100000
batch Size 256
Epoch: [28][0/196]	Time 0.166 (0.166)	Data 0.291 (0.291)	Loss 0.6857 (0.6857)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [28][64/196]	Time 0.131 (0.138)	Data 0.000 (0.005)	Loss 0.6776 (0.7195)	Acc@1 85.156 (85.517)	Acc@5 99.609 (99.357)
Epoch: [28][128/196]	Time 0.130 (0.137)	Data 0.000 (0.002)	Loss 0.7040 (0.7223)	Acc@1 84.766 (85.389)	Acc@5 100.000 (99.355)
Epoch: [28][192/196]	Time 0.140 (0.136)	Data 0.000 (0.002)	Loss 0.7502 (0.7331)	Acc@1 84.375 (85.047)	Acc@5 99.219 (99.334)
Max memory in training epoch: 66.4750592
lr: 0.1
1

Epoch: [29 | 30] LR: 0.100000
batch Size 256
Epoch: [29][0/196]	Time 0.174 (0.174)	Data 0.269 (0.269)	Loss 0.6316 (0.6316)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.128 (0.138)	Data 0.000 (0.004)	Loss 0.6795 (0.7281)	Acc@1 85.938 (85.397)	Acc@5 99.219 (99.411)
Epoch: [29][128/196]	Time 0.142 (0.137)	Data 0.000 (0.002)	Loss 0.6893 (0.7306)	Acc@1 84.766 (85.114)	Acc@5 99.219 (99.370)
Epoch: [29][192/196]	Time 0.138 (0.137)	Data 0.000 (0.002)	Loss 0.6677 (0.7309)	Acc@1 87.109 (85.073)	Acc@5 100.000 (99.344)
Max memory in training epoch: 66.4750592
lr: 0.1
1

Epoch: [30 | 30] LR: 0.100000
batch Size 256
Epoch: [30][0/196]	Time 0.191 (0.191)	Data 0.260 (0.260)	Loss 0.6555 (0.6555)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [30][64/196]	Time 0.133 (0.136)	Data 0.000 (0.004)	Loss 0.7703 (0.7296)	Acc@1 81.250 (85.138)	Acc@5 100.000 (99.393)
Epoch: [30][128/196]	Time 0.132 (0.135)	Data 0.000 (0.002)	Loss 0.7308 (0.7275)	Acc@1 85.547 (85.065)	Acc@5 97.656 (99.373)
Epoch: [30][192/196]	Time 0.133 (0.136)	Data 0.000 (0.002)	Loss 0.7393 (0.7291)	Acc@1 87.500 (85.069)	Acc@5 98.828 (99.354)
Max memory in training epoch: 66.4750592
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 461992 ; 478152 ; 0.9662032157138316
[INFO] Storing checkpoint...
  77.26
Max memory: 103.3316864
 26.881s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4853
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1924608
lr: 0.1
1

Epoch: [31 | 35] LR: 0.100000
batch Size 256
Epoch: [31][0/196]	Time 0.218 (0.218)	Data 0.283 (0.283)	Loss 0.7607 (0.7607)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [31][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.7433 (0.7147)	Acc@1 84.766 (85.661)	Acc@5 99.609 (99.387)
Epoch: [31][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6380 (0.7191)	Acc@1 87.891 (85.450)	Acc@5 99.609 (99.370)
Epoch: [31][192/196]	Time 0.136 (0.131)	Data 0.000 (0.002)	Loss 0.6328 (0.7238)	Acc@1 87.109 (85.197)	Acc@5 99.609 (99.312)
Max memory in training epoch: 66.09536
lr: 0.1
1

Epoch: [32 | 35] LR: 0.100000
batch Size 256
Epoch: [32][0/196]	Time 0.172 (0.172)	Data 0.266 (0.266)	Loss 0.6400 (0.6400)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.6022 (0.7114)	Acc@1 89.844 (85.781)	Acc@5 100.000 (99.309)
Epoch: [32][128/196]	Time 0.129 (0.134)	Data 0.000 (0.002)	Loss 0.7384 (0.7199)	Acc@1 84.766 (85.495)	Acc@5 98.828 (99.322)
Epoch: [32][192/196]	Time 0.141 (0.134)	Data 0.000 (0.002)	Loss 0.7627 (0.7247)	Acc@1 82.812 (85.225)	Acc@5 98.438 (99.328)
Max memory in training epoch: 66.0036096
lr: 0.1
1

Epoch: [33 | 35] LR: 0.100000
batch Size 256
Epoch: [33][0/196]	Time 0.179 (0.179)	Data 0.262 (0.262)	Loss 0.6666 (0.6666)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.138 (0.135)	Data 0.000 (0.004)	Loss 0.7332 (0.7269)	Acc@1 86.328 (85.312)	Acc@5 98.828 (99.405)
Epoch: [33][128/196]	Time 0.131 (0.135)	Data 0.000 (0.002)	Loss 0.7405 (0.7270)	Acc@1 84.375 (85.296)	Acc@5 99.219 (99.425)
Epoch: [33][192/196]	Time 0.135 (0.134)	Data 0.000 (0.002)	Loss 0.6511 (0.7297)	Acc@1 87.891 (85.183)	Acc@5 100.000 (99.405)
Max memory in training epoch: 66.0036096
lr: 0.1
1

Epoch: [34 | 35] LR: 0.100000
batch Size 256
Epoch: [34][0/196]	Time 0.191 (0.191)	Data 0.303 (0.303)	Loss 0.6886 (0.6886)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.134 (0.135)	Data 0.000 (0.005)	Loss 0.6882 (0.7283)	Acc@1 85.547 (85.216)	Acc@5 100.000 (99.429)
Epoch: [34][128/196]	Time 0.134 (0.133)	Data 0.000 (0.003)	Loss 0.7915 (0.7358)	Acc@1 84.766 (84.902)	Acc@5 100.000 (99.394)
Epoch: [34][192/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 0.6995 (0.7310)	Acc@1 88.281 (85.083)	Acc@5 100.000 (99.393)
Max memory in training epoch: 66.0036096
lr: 0.1
1

Epoch: [35 | 35] LR: 0.100000
batch Size 256
Epoch: [35][0/196]	Time 0.188 (0.188)	Data 0.332 (0.332)	Loss 0.7674 (0.7674)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [35][64/196]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.7061 (0.7134)	Acc@1 83.594 (85.451)	Acc@5 98.828 (99.459)
Epoch: [35][128/196]	Time 0.132 (0.132)	Data 0.000 (0.003)	Loss 0.6357 (0.7175)	Acc@1 88.672 (85.456)	Acc@5 100.000 (99.428)
Epoch: [35][192/196]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.7156 (0.7192)	Acc@1 85.547 (85.472)	Acc@5 98.828 (99.399)
Max memory in training epoch: 66.0036096
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 445536 ; 461992 ; 0.9643803355902266
[INFO] Storing checkpoint...
  81.96
Max memory: 102.8032
 26.449s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3604
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1860096
lr: 0.1
1

Epoch: [36 | 40] LR: 0.100000
batch Size 256
Epoch: [36][0/196]	Time 0.190 (0.190)	Data 0.284 (0.284)	Loss 0.6196 (0.6196)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [36][64/196]	Time 0.128 (0.131)	Data 0.000 (0.005)	Loss 0.8121 (0.6865)	Acc@1 81.641 (86.671)	Acc@5 100.000 (99.489)
Epoch: [36][128/196]	Time 0.138 (0.132)	Data 0.000 (0.002)	Loss 0.7047 (0.6949)	Acc@1 85.156 (86.237)	Acc@5 99.219 (99.467)
Epoch: [36][192/196]	Time 0.131 (0.132)	Data 0.000 (0.002)	Loss 0.7424 (0.7068)	Acc@1 83.594 (85.836)	Acc@5 99.609 (99.439)
Max memory in training epoch: 65.4469632
lr: 0.1
1

Epoch: [37 | 40] LR: 0.100000
batch Size 256
Epoch: [37][0/196]	Time 0.172 (0.172)	Data 0.292 (0.292)	Loss 0.6564 (0.6564)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.128 (0.134)	Data 0.000 (0.005)	Loss 0.7370 (0.7214)	Acc@1 85.547 (85.270)	Acc@5 99.219 (99.315)
Epoch: [37][128/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7350 (0.7194)	Acc@1 84.375 (85.486)	Acc@5 99.219 (99.361)
Epoch: [37][192/196]	Time 0.126 (0.135)	Data 0.000 (0.002)	Loss 0.7633 (0.7213)	Acc@1 84.766 (85.393)	Acc@5 99.609 (99.383)
Max memory in training epoch: 65.5911424
lr: 0.1
1

Epoch: [38 | 40] LR: 0.100000
batch Size 256
Epoch: [38][0/196]	Time 0.178 (0.178)	Data 0.338 (0.338)	Loss 0.6845 (0.6845)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [38][64/196]	Time 0.141 (0.135)	Data 0.000 (0.005)	Loss 0.8766 (0.7068)	Acc@1 82.812 (86.040)	Acc@5 98.828 (99.549)
Epoch: [38][128/196]	Time 0.127 (0.135)	Data 0.000 (0.003)	Loss 0.6985 (0.7174)	Acc@1 87.500 (85.544)	Acc@5 98.828 (99.461)
Epoch: [38][192/196]	Time 0.139 (0.135)	Data 0.000 (0.002)	Loss 0.7420 (0.7186)	Acc@1 85.547 (85.525)	Acc@5 98.828 (99.427)
Max memory in training epoch: 65.5911424
lr: 0.1
1

Epoch: [39 | 40] LR: 0.100000
batch Size 256
Epoch: [39][0/196]	Time 0.174 (0.174)	Data 0.327 (0.327)	Loss 0.6365 (0.6365)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [39][64/196]	Time 0.131 (0.134)	Data 0.000 (0.005)	Loss 0.6939 (0.7132)	Acc@1 85.156 (85.439)	Acc@5 99.219 (99.537)
Epoch: [39][128/196]	Time 0.134 (0.135)	Data 0.000 (0.003)	Loss 0.7339 (0.7166)	Acc@1 82.812 (85.274)	Acc@5 98.828 (99.425)
Epoch: [39][192/196]	Time 0.144 (0.135)	Data 0.000 (0.002)	Loss 0.7749 (0.7132)	Acc@1 82.812 (85.442)	Acc@5 99.219 (99.405)
Max memory in training epoch: 65.5911424
lr: 0.1
1

Epoch: [40 | 40] LR: 0.100000
batch Size 256
Epoch: [40][0/196]	Time 0.191 (0.191)	Data 0.270 (0.270)	Loss 0.6997 (0.6997)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.134 (0.135)	Data 0.000 (0.004)	Loss 0.7169 (0.7106)	Acc@1 83.594 (85.691)	Acc@5 99.609 (99.495)
Epoch: [40][128/196]	Time 0.137 (0.135)	Data 0.000 (0.002)	Loss 0.6397 (0.7061)	Acc@1 87.500 (85.832)	Acc@5 99.219 (99.491)
Epoch: [40][192/196]	Time 0.136 (0.135)	Data 0.000 (0.002)	Loss 0.8501 (0.7114)	Acc@1 82.812 (85.618)	Acc@5 99.219 (99.452)
Max memory in training epoch: 65.5911424
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 431824 ; 445536 ; 0.9692235868706457
[INFO] Storing checkpoint...
  76.38
Max memory: 101.6068608
 26.842s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4872
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1805312
lr: 0.1
1

Epoch: [41 | 45] LR: 0.100000
batch Size 256
Epoch: [41][0/196]	Time 0.210 (0.210)	Data 0.288 (0.288)	Loss 0.7583 (0.7583)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [41][64/196]	Time 0.127 (0.131)	Data 0.000 (0.005)	Loss 0.7285 (0.6754)	Acc@1 84.766 (86.779)	Acc@5 99.219 (99.483)
Epoch: [41][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7662 (0.7061)	Acc@1 83.594 (85.865)	Acc@5 99.219 (99.425)
Epoch: [41][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6591 (0.7104)	Acc@1 85.547 (85.703)	Acc@5 99.609 (99.403)
Max memory in training epoch: 64.8417792
lr: 0.1
1

Epoch: [42 | 45] LR: 0.100000
batch Size 256
Epoch: [42][0/196]	Time 0.170 (0.170)	Data 0.312 (0.312)	Loss 0.6205 (0.6205)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [42][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.7524 (0.6958)	Acc@1 84.766 (86.100)	Acc@5 99.219 (99.507)
Epoch: [42][128/196]	Time 0.132 (0.133)	Data 0.000 (0.003)	Loss 0.6434 (0.6986)	Acc@1 87.109 (86.080)	Acc@5 99.219 (99.443)
Epoch: [42][192/196]	Time 0.131 (0.134)	Data 0.000 (0.002)	Loss 0.7403 (0.7032)	Acc@1 85.938 (85.946)	Acc@5 99.609 (99.435)
Max memory in training epoch: 64.8811008
lr: 0.1
1

Epoch: [43 | 45] LR: 0.100000
batch Size 256
Epoch: [43][0/196]	Time 0.170 (0.170)	Data 0.292 (0.292)	Loss 0.6650 (0.6650)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.128 (0.134)	Data 0.000 (0.005)	Loss 0.7268 (0.7010)	Acc@1 87.500 (85.956)	Acc@5 99.219 (99.429)
Epoch: [43][128/196]	Time 0.141 (0.133)	Data 0.000 (0.002)	Loss 0.6771 (0.7069)	Acc@1 89.453 (85.801)	Acc@5 100.000 (99.410)
Epoch: [43][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.6967 (0.7084)	Acc@1 86.328 (85.640)	Acc@5 99.609 (99.429)
Max memory in training epoch: 64.8811008
lr: 0.1
1

Epoch: [44 | 45] LR: 0.100000
batch Size 256
Epoch: [44][0/196]	Time 0.187 (0.187)	Data 0.286 (0.286)	Loss 0.6999 (0.6999)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.135 (0.133)	Data 0.000 (0.005)	Loss 0.6209 (0.7021)	Acc@1 87.891 (85.715)	Acc@5 99.219 (99.441)
Epoch: [44][128/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.7290 (0.6994)	Acc@1 84.375 (85.828)	Acc@5 98.828 (99.431)
Epoch: [44][192/196]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.6643 (0.6993)	Acc@1 85.938 (85.889)	Acc@5 99.609 (99.401)
Max memory in training epoch: 64.8811008
lr: 0.1
1

Epoch: [45 | 45] LR: 0.100000
batch Size 256
Epoch: [45][0/196]	Time 0.175 (0.175)	Data 0.302 (0.302)	Loss 0.6411 (0.6411)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [45][64/196]	Time 0.142 (0.133)	Data 0.000 (0.005)	Loss 0.6969 (0.7068)	Acc@1 85.156 (85.907)	Acc@5 99.609 (99.501)
Epoch: [45][128/196]	Time 0.127 (0.133)	Data 0.000 (0.002)	Loss 0.6655 (0.7065)	Acc@1 86.328 (85.674)	Acc@5 99.219 (99.461)
Epoch: [45][192/196]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.6746 (0.7072)	Acc@1 83.984 (85.575)	Acc@5 99.609 (99.427)
Max memory in training epoch: 64.8811008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 416232 ; 431824 ; 0.9638926970247138
[INFO] Storing checkpoint...
  72.31
Max memory: 100.7304704
 26.357s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4247
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1743872
lr: 0.1
1

Epoch: [46 | 50] LR: 0.100000
batch Size 256
Epoch: [46][0/196]	Time 0.209 (0.209)	Data 0.289 (0.289)	Loss 0.7229 (0.7229)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [46][64/196]	Time 0.136 (0.130)	Data 0.000 (0.005)	Loss 0.7169 (0.6632)	Acc@1 86.719 (87.121)	Acc@5 99.609 (99.591)
Epoch: [46][128/196]	Time 0.123 (0.130)	Data 0.000 (0.002)	Loss 0.7117 (0.6841)	Acc@1 84.375 (86.443)	Acc@5 99.609 (99.506)
Epoch: [46][192/196]	Time 0.129 (0.130)	Data 0.000 (0.002)	Loss 0.7567 (0.6920)	Acc@1 85.547 (86.168)	Acc@5 98.438 (99.447)
Max memory in training epoch: 63.9914496
lr: 0.1
1

Epoch: [47 | 50] LR: 0.100000
batch Size 256
Epoch: [47][0/196]	Time 0.187 (0.187)	Data 0.259 (0.259)	Loss 0.7566 (0.7566)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [47][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.7127 (0.7018)	Acc@1 86.328 (85.962)	Acc@5 99.219 (99.495)
Epoch: [47][128/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6999 (0.7093)	Acc@1 84.766 (85.789)	Acc@5 99.609 (99.437)
Epoch: [47][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6339 (0.7075)	Acc@1 91.406 (85.770)	Acc@5 99.219 (99.419)
Max memory in training epoch: 63.788288
lr: 0.1
1

Epoch: [48 | 50] LR: 0.100000
batch Size 256
Epoch: [48][0/196]	Time 0.187 (0.187)	Data 0.289 (0.289)	Loss 0.6646 (0.6646)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [48][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 0.6755 (0.6919)	Acc@1 85.938 (85.986)	Acc@5 99.609 (99.531)
Epoch: [48][128/196]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.6954 (0.7001)	Acc@1 86.719 (85.947)	Acc@5 99.609 (99.406)
Epoch: [48][192/196]	Time 0.131 (0.133)	Data 0.000 (0.002)	Loss 0.7485 (0.7000)	Acc@1 83.984 (85.855)	Acc@5 99.219 (99.417)
Max memory in training epoch: 63.7948416
lr: 0.1
1

Epoch: [49 | 50] LR: 0.100000
batch Size 256
Epoch: [49][0/196]	Time 0.155 (0.155)	Data 0.307 (0.307)	Loss 0.6456 (0.6456)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.126 (0.133)	Data 0.000 (0.005)	Loss 0.6606 (0.6958)	Acc@1 88.672 (85.950)	Acc@5 99.609 (99.417)
Epoch: [49][128/196]	Time 0.138 (0.132)	Data 0.000 (0.003)	Loss 0.6653 (0.6974)	Acc@1 87.500 (85.716)	Acc@5 98.828 (99.467)
Epoch: [49][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.7282 (0.6955)	Acc@1 85.547 (85.852)	Acc@5 99.219 (99.474)
Max memory in training epoch: 63.7948416
lr: 0.1
1

Epoch: [50 | 50] LR: 0.100000
batch Size 256
Epoch: [50][0/196]	Time 0.178 (0.178)	Data 0.258 (0.258)	Loss 0.6744 (0.6744)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 0.132 (0.132)	Data 0.000 (0.004)	Loss 0.8218 (0.6904)	Acc@1 82.031 (86.232)	Acc@5 100.000 (99.531)
Epoch: [50][128/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.7290 (0.6911)	Acc@1 86.719 (86.216)	Acc@5 100.000 (99.491)
Epoch: [50][192/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.7763 (0.6935)	Acc@1 85.938 (86.130)	Acc@5 98.438 (99.468)
Max memory in training epoch: 63.7948416
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 402226 ; 416232 ; 0.9663504968383018
[INFO] Storing checkpoint...
  80.27
Max memory: 99.0644224
 26.217s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8591
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1688064
lr: 0.1
1

Epoch: [51 | 55] LR: 0.100000
batch Size 256
Epoch: [51][0/196]	Time 0.187 (0.187)	Data 0.261 (0.261)	Loss 0.6253 (0.6253)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [51][64/196]	Time 0.129 (0.130)	Data 0.000 (0.004)	Loss 0.7279 (0.6611)	Acc@1 85.156 (86.923)	Acc@5 98.828 (99.603)
Epoch: [51][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 0.7085 (0.6799)	Acc@1 84.375 (86.389)	Acc@5 99.219 (99.506)
Epoch: [51][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.6511 (0.6891)	Acc@1 88.281 (86.120)	Acc@5 99.609 (99.474)
Max memory in training epoch: 63.3661952
lr: 0.1
1

Epoch: [52 | 55] LR: 0.100000
batch Size 256
Epoch: [52][0/196]	Time 0.181 (0.181)	Data 0.304 (0.304)	Loss 0.5776 (0.5776)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 0.122 (0.131)	Data 0.000 (0.005)	Loss 0.7974 (0.6958)	Acc@1 83.203 (86.058)	Acc@5 98.828 (99.405)
Epoch: [52][128/196]	Time 0.137 (0.132)	Data 0.000 (0.003)	Loss 0.6827 (0.6885)	Acc@1 86.328 (86.304)	Acc@5 99.609 (99.434)
Epoch: [52][192/196]	Time 0.147 (0.133)	Data 0.000 (0.002)	Loss 0.6996 (0.6922)	Acc@1 83.984 (86.201)	Acc@5 98.828 (99.393)
Max memory in training epoch: 63.2351232
lr: 0.1
1

Epoch: [53 | 55] LR: 0.100000
batch Size 256
Epoch: [53][0/196]	Time 0.194 (0.194)	Data 0.263 (0.263)	Loss 0.6610 (0.6610)	Acc@1 88.281 (88.281)	Acc@5 98.828 (98.828)
Epoch: [53][64/196]	Time 0.132 (0.131)	Data 0.000 (0.004)	Loss 0.9063 (0.6858)	Acc@1 82.812 (86.244)	Acc@5 99.219 (99.519)
Epoch: [53][128/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.6698 (0.6851)	Acc@1 88.281 (86.343)	Acc@5 99.609 (99.509)
Epoch: [53][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.6241 (0.6899)	Acc@1 89.062 (86.093)	Acc@5 99.609 (99.502)
Max memory in training epoch: 63.2351232
lr: 0.1
1

Epoch: [54 | 55] LR: 0.100000
batch Size 256
Epoch: [54][0/196]	Time 0.185 (0.185)	Data 0.257 (0.257)	Loss 0.6859 (0.6859)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.135 (0.131)	Data 0.000 (0.004)	Loss 0.6500 (0.6794)	Acc@1 87.109 (86.569)	Acc@5 99.609 (99.411)
Epoch: [54][128/196]	Time 0.143 (0.131)	Data 0.000 (0.002)	Loss 0.7220 (0.6929)	Acc@1 83.594 (86.037)	Acc@5 99.609 (99.410)
Epoch: [54][192/196]	Time 0.126 (0.132)	Data 0.000 (0.001)	Loss 0.7515 (0.6915)	Acc@1 83.984 (86.101)	Acc@5 98.828 (99.427)
Max memory in training epoch: 63.2351232
lr: 0.1
1

Epoch: [55 | 55] LR: 0.100000
batch Size 256
Epoch: [55][0/196]	Time 0.175 (0.175)	Data 0.299 (0.299)	Loss 0.7655 (0.7655)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.6539 (0.6936)	Acc@1 89.062 (86.052)	Acc@5 100.000 (99.447)
Epoch: [55][128/196]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.6203 (0.6878)	Acc@1 89.453 (86.255)	Acc@5 99.219 (99.388)
Epoch: [55][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.7711 (0.6904)	Acc@1 83.203 (86.136)	Acc@5 98.828 (99.403)
Max memory in training epoch: 63.2351232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 394570 ; 402226 ; 0.9809659246294372
[INFO] Storing checkpoint...
  74.49
Max memory: 97.6822784
 26.239s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7466
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1657856
lr: 0.1
1

Epoch: [56 | 60] LR: 0.100000
batch Size 256
Epoch: [56][0/196]	Time 0.192 (0.192)	Data 0.278 (0.278)	Loss 0.6760 (0.6760)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.128 (0.129)	Data 0.000 (0.004)	Loss 0.6784 (0.6437)	Acc@1 85.547 (87.488)	Acc@5 100.000 (99.549)
Epoch: [56][128/196]	Time 0.121 (0.129)	Data 0.000 (0.002)	Loss 0.6776 (0.6710)	Acc@1 86.719 (86.685)	Acc@5 99.219 (99.482)
Epoch: [56][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6343 (0.6788)	Acc@1 87.500 (86.433)	Acc@5 99.609 (99.480)
Max memory in training epoch: 62.305536
lr: 0.1
1

Epoch: [57 | 60] LR: 0.100000
batch Size 256
Epoch: [57][0/196]	Time 0.161 (0.161)	Data 0.285 (0.285)	Loss 0.6033 (0.6033)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.131 (0.130)	Data 0.000 (0.005)	Loss 0.6945 (0.6896)	Acc@1 85.938 (86.178)	Acc@5 99.609 (99.375)
Epoch: [57][128/196]	Time 0.138 (0.131)	Data 0.000 (0.002)	Loss 0.6888 (0.6911)	Acc@1 86.719 (86.131)	Acc@5 99.219 (99.428)
Epoch: [57][192/196]	Time 0.126 (0.132)	Data 0.000 (0.002)	Loss 0.7801 (0.6929)	Acc@1 82.422 (86.124)	Acc@5 99.219 (99.409)
Max memory in training epoch: 62.1810176
lr: 0.1
1

Epoch: [58 | 60] LR: 0.100000
batch Size 256
Epoch: [58][0/196]	Time 0.156 (0.156)	Data 0.282 (0.282)	Loss 0.6377 (0.6377)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [58][64/196]	Time 0.131 (0.131)	Data 0.000 (0.005)	Loss 0.7160 (0.6839)	Acc@1 82.031 (86.316)	Acc@5 100.000 (99.387)
Epoch: [58][128/196]	Time 0.136 (0.131)	Data 0.000 (0.002)	Loss 0.6342 (0.6811)	Acc@1 87.500 (86.449)	Acc@5 99.609 (99.431)
Epoch: [58][192/196]	Time 0.129 (0.131)	Data 0.000 (0.002)	Loss 0.7242 (0.6871)	Acc@1 86.328 (86.150)	Acc@5 98.828 (99.449)
Max memory in training epoch: 62.1810176
lr: 0.1
1

Epoch: [59 | 60] LR: 0.100000
batch Size 256
Epoch: [59][0/196]	Time 0.177 (0.177)	Data 0.264 (0.264)	Loss 0.6358 (0.6358)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [59][64/196]	Time 0.143 (0.132)	Data 0.000 (0.004)	Loss 0.6852 (0.6777)	Acc@1 85.938 (86.334)	Acc@5 100.000 (99.507)
Epoch: [59][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6980 (0.6838)	Acc@1 86.719 (86.010)	Acc@5 99.609 (99.491)
Epoch: [59][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.6862 (0.6910)	Acc@1 86.328 (85.857)	Acc@5 99.609 (99.462)
Max memory in training epoch: 62.1810176
lr: 0.1
1

Epoch: [60 | 60] LR: 0.100000
batch Size 256
Epoch: [60][0/196]	Time 0.173 (0.173)	Data 0.273 (0.273)	Loss 0.6525 (0.6525)	Acc@1 88.672 (88.672)	Acc@5 98.438 (98.438)
Epoch: [60][64/196]	Time 0.130 (0.132)	Data 0.000 (0.004)	Loss 0.7014 (0.6736)	Acc@1 82.422 (86.683)	Acc@5 99.609 (99.405)
Epoch: [60][128/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.6973 (0.6778)	Acc@1 84.375 (86.422)	Acc@5 99.219 (99.431)
Epoch: [60][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.7412 (0.6784)	Acc@1 83.984 (86.439)	Acc@5 99.219 (99.415)
Max memory in training epoch: 62.1810176
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 383600 ; 394570 ; 0.9721975821780673
[INFO] Storing checkpoint...
  73.49
Max memory: 96.85504
 25.982s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9071
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1613824
lr: 0.1
1

Epoch: [61 | 65] LR: 0.100000
batch Size 256
Epoch: [61][0/196]	Time 0.176 (0.176)	Data 0.295 (0.295)	Loss 0.6091 (0.6091)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.126 (0.129)	Data 0.000 (0.005)	Loss 0.7967 (0.6576)	Acc@1 80.469 (86.893)	Acc@5 98.828 (99.471)
Epoch: [61][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.7996 (0.6670)	Acc@1 79.688 (86.558)	Acc@5 100.000 (99.482)
Epoch: [61][192/196]	Time 0.144 (0.130)	Data 0.000 (0.002)	Loss 0.7330 (0.6786)	Acc@1 85.156 (86.188)	Acc@5 99.219 (99.452)
Max memory in training epoch: 61.9733504
lr: 0.1
1

Epoch: [62 | 65] LR: 0.100000
batch Size 256
Epoch: [62][0/196]	Time 0.186 (0.186)	Data 0.262 (0.262)	Loss 0.6611 (0.6611)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.134 (0.132)	Data 0.000 (0.004)	Loss 0.6136 (0.6855)	Acc@1 88.672 (86.364)	Acc@5 99.219 (99.345)
Epoch: [62][128/196]	Time 0.152 (0.132)	Data 0.000 (0.002)	Loss 0.7710 (0.6825)	Acc@1 83.203 (86.222)	Acc@5 99.609 (99.410)
Epoch: [62][192/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 0.6559 (0.6833)	Acc@1 88.281 (86.231)	Acc@5 99.609 (99.383)
Max memory in training epoch: 61.7701888
lr: 0.1
1

Epoch: [63 | 65] LR: 0.100000
batch Size 256
Epoch: [63][0/196]	Time 0.171 (0.171)	Data 0.299 (0.299)	Loss 0.7088 (0.7088)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.125 (0.133)	Data 0.000 (0.005)	Loss 0.6370 (0.6746)	Acc@1 86.719 (86.430)	Acc@5 99.219 (99.471)
Epoch: [63][128/196]	Time 0.134 (0.132)	Data 0.000 (0.002)	Loss 0.5990 (0.6821)	Acc@1 88.281 (86.162)	Acc@5 99.219 (99.458)
Epoch: [63][192/196]	Time 0.139 (0.132)	Data 0.000 (0.002)	Loss 0.6166 (0.6809)	Acc@1 88.672 (86.217)	Acc@5 100.000 (99.456)
Max memory in training epoch: 61.7701888
lr: 0.1
1

Epoch: [64 | 65] LR: 0.100000
batch Size 256
Epoch: [64][0/196]	Time 0.179 (0.179)	Data 0.305 (0.305)	Loss 0.6489 (0.6489)	Acc@1 88.281 (88.281)	Acc@5 98.047 (98.047)
Epoch: [64][64/196]	Time 0.143 (0.133)	Data 0.000 (0.005)	Loss 0.7363 (0.6817)	Acc@1 83.594 (86.424)	Acc@5 99.219 (99.411)
Epoch: [64][128/196]	Time 0.139 (0.133)	Data 0.000 (0.003)	Loss 0.6294 (0.6789)	Acc@1 88.281 (86.413)	Acc@5 99.609 (99.452)
Epoch: [64][192/196]	Time 0.134 (0.133)	Data 0.000 (0.002)	Loss 0.7082 (0.6816)	Acc@1 86.328 (86.276)	Acc@5 99.609 (99.472)
Max memory in training epoch: 61.7701888
lr: 0.1
1

Epoch: [65 | 65] LR: 0.100000
batch Size 256
Epoch: [65][0/196]	Time 0.183 (0.183)	Data 0.274 (0.274)	Loss 0.5936 (0.5936)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.131 (0.132)	Data 0.000 (0.004)	Loss 0.7252 (0.6930)	Acc@1 82.812 (85.691)	Acc@5 99.609 (99.507)
Epoch: [65][128/196]	Time 0.124 (0.131)	Data 0.000 (0.002)	Loss 0.6996 (0.6909)	Acc@1 85.156 (85.822)	Acc@5 100.000 (99.440)
Epoch: [65][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7760 (0.6863)	Acc@1 83.984 (85.956)	Acc@5 99.609 (99.454)
Max memory in training epoch: 61.7701888
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 376526 ; 383600 ; 0.9815589155370177
[INFO] Storing checkpoint...
  79.56
Max memory: 95.8372864
 26.077s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7587
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1586176
lr: 0.1
1

Epoch: [66 | 70] LR: 0.100000
batch Size 256
Epoch: [66][0/196]	Time 0.200 (0.200)	Data 0.279 (0.279)	Loss 0.6471 (0.6471)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.129 (0.129)	Data 0.000 (0.004)	Loss 0.7386 (0.6386)	Acc@1 85.938 (87.752)	Acc@5 98.828 (99.621)
Epoch: [66][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6807 (0.6623)	Acc@1 86.328 (86.903)	Acc@5 100.000 (99.525)
Epoch: [66][192/196]	Time 0.137 (0.129)	Data 0.000 (0.002)	Loss 0.6872 (0.6705)	Acc@1 84.375 (86.492)	Acc@5 99.219 (99.510)
Max memory in training epoch: 61.8574336
lr: 0.1
1

Epoch: [67 | 70] LR: 0.100000
batch Size 256
Epoch: [67][0/196]	Time 0.150 (0.150)	Data 0.299 (0.299)	Loss 0.6084 (0.6084)	Acc@1 91.016 (91.016)	Acc@5 99.219 (99.219)
Epoch: [67][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 0.6812 (0.6740)	Acc@1 84.766 (86.556)	Acc@5 99.219 (99.573)
Epoch: [67][128/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 0.5879 (0.6701)	Acc@1 90.234 (86.797)	Acc@5 100.000 (99.516)
Epoch: [67][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.7211 (0.6770)	Acc@1 83.984 (86.454)	Acc@5 99.609 (99.480)
Max memory in training epoch: 61.5625216
lr: 0.1
1

Epoch: [68 | 70] LR: 0.100000
batch Size 256
Epoch: [68][0/196]	Time 0.181 (0.181)	Data 0.270 (0.270)	Loss 0.5368 (0.5368)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.125 (0.131)	Data 0.000 (0.004)	Loss 0.6806 (0.6770)	Acc@1 87.500 (86.214)	Acc@5 100.000 (99.507)
Epoch: [68][128/196]	Time 0.125 (0.132)	Data 0.000 (0.002)	Loss 0.6342 (0.6731)	Acc@1 87.109 (86.419)	Acc@5 99.609 (99.482)
Epoch: [68][192/196]	Time 0.133 (0.132)	Data 0.000 (0.002)	Loss 0.6843 (0.6764)	Acc@1 86.328 (86.328)	Acc@5 98.438 (99.482)
Max memory in training epoch: 61.5625216
lr: 0.1
1

Epoch: [69 | 70] LR: 0.100000
batch Size 256
Epoch: [69][0/196]	Time 0.169 (0.169)	Data 0.298 (0.298)	Loss 0.5963 (0.5963)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [69][64/196]	Time 0.127 (0.130)	Data 0.000 (0.005)	Loss 0.5205 (0.6507)	Acc@1 92.578 (87.188)	Acc@5 100.000 (99.495)
Epoch: [69][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 0.7215 (0.6668)	Acc@1 84.766 (86.646)	Acc@5 99.609 (99.497)
Epoch: [69][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 0.6919 (0.6761)	Acc@1 85.547 (86.367)	Acc@5 99.219 (99.449)
Max memory in training epoch: 61.5625216
lr: 0.1
1

Epoch: [70 | 70] LR: 0.100000
batch Size 256
Epoch: [70][0/196]	Time 0.152 (0.152)	Data 0.296 (0.296)	Loss 0.6417 (0.6417)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [70][64/196]	Time 0.145 (0.132)	Data 0.000 (0.005)	Loss 0.5941 (0.6606)	Acc@1 89.062 (86.953)	Acc@5 100.000 (99.507)
Epoch: [70][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 0.7473 (0.6580)	Acc@1 84.375 (86.873)	Acc@5 98.828 (99.549)
Epoch: [70][192/196]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.6348 (0.6663)	Acc@1 87.500 (86.595)	Acc@5 99.609 (99.537)
Max memory in training epoch: 61.5625216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 372486 ; 376526 ; 0.9892703292734101
[INFO] Storing checkpoint...
  80.29
Max memory: 95.2203264
 26.164s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2770
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1570816
lr: 0.1
1

Epoch: [71 | 75] LR: 0.100000
batch Size 256
Epoch: [71][0/196]	Time 0.203 (0.203)	Data 0.284 (0.284)	Loss 0.6077 (0.6077)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.6349 (0.6380)	Acc@1 87.891 (87.500)	Acc@5 100.000 (99.579)
Epoch: [71][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 0.6547 (0.6592)	Acc@1 88.281 (86.734)	Acc@5 99.609 (99.534)
Epoch: [71][192/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.6534 (0.6664)	Acc@1 86.719 (86.565)	Acc@5 100.000 (99.522)
Max memory in training epoch: 61.4777344
lr: 0.1
1

Epoch: [72 | 75] LR: 0.100000
batch Size 256
Epoch: [72][0/196]	Time 0.172 (0.172)	Data 0.259 (0.259)	Loss 0.6429 (0.6429)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.121 (0.131)	Data 0.000 (0.004)	Loss 0.7312 (0.6804)	Acc@1 82.812 (86.358)	Acc@5 100.000 (99.411)
Epoch: [72][128/196]	Time 0.139 (0.132)	Data 0.000 (0.002)	Loss 0.6280 (0.6731)	Acc@1 88.672 (86.658)	Acc@5 99.609 (99.425)
Epoch: [72][192/196]	Time 0.127 (0.132)	Data 0.000 (0.002)	Loss 0.5672 (0.6696)	Acc@1 91.016 (86.674)	Acc@5 99.609 (99.437)
Max memory in training epoch: 61.2811264
lr: 0.1
1

Epoch: [73 | 75] LR: 0.100000
batch Size 256
Epoch: [73][0/196]	Time 0.181 (0.181)	Data 0.284 (0.284)	Loss 0.6442 (0.6442)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [73][64/196]	Time 0.124 (0.133)	Data 0.000 (0.005)	Loss 0.7542 (0.6657)	Acc@1 84.375 (86.641)	Acc@5 99.219 (99.501)
Epoch: [73][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6235 (0.6759)	Acc@1 89.453 (86.234)	Acc@5 99.609 (99.461)
Epoch: [73][192/196]	Time 0.133 (0.133)	Data 0.000 (0.002)	Loss 0.6398 (0.6783)	Acc@1 89.844 (86.207)	Acc@5 99.219 (99.460)
Max memory in training epoch: 61.2811264
lr: 0.1
1

Epoch: [74 | 75] LR: 0.100000
batch Size 256
Epoch: [74][0/196]	Time 0.186 (0.186)	Data 0.294 (0.294)	Loss 0.6749 (0.6749)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.130 (0.132)	Data 0.000 (0.005)	Loss 0.6758 (0.6621)	Acc@1 84.375 (86.989)	Acc@5 99.609 (99.453)
Epoch: [74][128/196]	Time 0.155 (0.132)	Data 0.000 (0.002)	Loss 0.5943 (0.6655)	Acc@1 89.062 (86.885)	Acc@5 100.000 (99.479)
Epoch: [74][192/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 0.7818 (0.6718)	Acc@1 83.203 (86.642)	Acc@5 98.828 (99.458)
Max memory in training epoch: 61.2811264
lr: 0.1
1

Epoch: [75 | 75] LR: 0.100000
batch Size 256
Epoch: [75][0/196]	Time 0.169 (0.169)	Data 0.274 (0.274)	Loss 0.6405 (0.6405)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [75][64/196]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 0.6353 (0.6552)	Acc@1 87.891 (87.344)	Acc@5 99.609 (99.495)
Epoch: [75][128/196]	Time 0.129 (0.132)	Data 0.000 (0.002)	Loss 0.6494 (0.6680)	Acc@1 88.281 (86.807)	Acc@5 100.000 (99.491)
Epoch: [75][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 0.6400 (0.6686)	Acc@1 87.500 (86.790)	Acc@5 99.609 (99.488)
Max memory in training epoch: 61.2811264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 368154 ; 372486 ; 0.9883700326992155
[INFO] Storing checkpoint...
  82.59
Max memory: 95.0928384
 26.264s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1389
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1554432
lr: 0.1
1

Epoch: [76 | 80] LR: 0.100000
batch Size 256
Epoch: [76][0/196]	Time 0.209 (0.209)	Data 0.263 (0.263)	Loss 0.6584 (0.6584)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.122 (0.131)	Data 0.000 (0.004)	Loss 0.6947 (0.6412)	Acc@1 87.109 (87.680)	Acc@5 98.828 (99.603)
Epoch: [76][128/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 0.6479 (0.6596)	Acc@1 85.547 (86.934)	Acc@5 99.609 (99.570)
Epoch: [76][192/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 0.6955 (0.6631)	Acc@1 86.328 (86.707)	Acc@5 99.609 (99.504)
Max memory in training epoch: 61.0124288
lr: 0.1
1

Epoch: [77 | 80] LR: 0.100000
batch Size 256
Epoch: [77][0/196]	Time 0.172 (0.172)	Data 0.298 (0.298)	Loss 0.6441 (0.6441)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.135 (0.129)	Data 0.000 (0.005)	Loss 0.7714 (0.6522)	Acc@1 83.984 (87.260)	Acc@5 98.047 (99.507)
Epoch: [77][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.5511 (0.6629)	Acc@1 89.844 (86.755)	Acc@5 99.609 (99.549)
Epoch: [77][192/196]	Time 0.123 (0.131)	Data 0.000 (0.002)	Loss 0.6617 (0.6649)	Acc@1 87.891 (86.688)	Acc@5 99.219 (99.500)
Max memory in training epoch: 60.8158208
lr: 0.1
1

Epoch: [78 | 80] LR: 0.100000
batch Size 256
Epoch: [78][0/196]	Time 0.174 (0.174)	Data 0.298 (0.298)	Loss 0.6822 (0.6822)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.132 (0.130)	Data 0.000 (0.005)	Loss 0.5443 (0.6690)	Acc@1 91.016 (86.388)	Acc@5 99.609 (99.549)
Epoch: [78][128/196]	Time 0.131 (0.130)	Data 0.000 (0.002)	Loss 0.6143 (0.6722)	Acc@1 89.844 (86.470)	Acc@5 100.000 (99.528)
Epoch: [78][192/196]	Time 0.132 (0.131)	Data 0.000 (0.002)	Loss 0.6151 (0.6735)	Acc@1 89.453 (86.456)	Acc@5 99.609 (99.520)
Max memory in training epoch: 60.8158208
lr: 0.1
1

Epoch: [79 | 80] LR: 0.100000
batch Size 256
Epoch: [79][0/196]	Time 0.167 (0.167)	Data 0.272 (0.272)	Loss 0.7288 (0.7288)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [79][64/196]	Time 0.133 (0.131)	Data 0.000 (0.004)	Loss 0.6584 (0.6611)	Acc@1 87.109 (86.737)	Acc@5 99.609 (99.453)
Epoch: [79][128/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 0.6832 (0.6653)	Acc@1 86.719 (86.737)	Acc@5 98.828 (99.449)
Epoch: [79][192/196]	Time 0.133 (0.131)	Data 0.000 (0.002)	Loss 0.6944 (0.6630)	Acc@1 85.156 (86.798)	Acc@5 100.000 (99.498)
Max memory in training epoch: 60.8158208
lr: 0.1
1

Epoch: [80 | 80] LR: 0.100000
batch Size 256
Epoch: [80][0/196]	Time 0.190 (0.190)	Data 0.260 (0.260)	Loss 0.6432 (0.6432)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [80][64/196]	Time 0.127 (0.130)	Data 0.000 (0.004)	Loss 0.7108 (0.6717)	Acc@1 85.156 (86.430)	Acc@5 98.828 (99.519)
Epoch: [80][128/196]	Time 0.134 (0.131)	Data 0.000 (0.002)	Loss 0.6798 (0.6664)	Acc@1 87.500 (86.661)	Acc@5 98.047 (99.491)
Epoch: [80][192/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 0.6944 (0.6654)	Acc@1 86.328 (86.622)	Acc@5 98.828 (99.504)
Max memory in training epoch: 60.8158208
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv19.weight

 RM:  module.conv20.weight

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
Count: 363114 ; 368154 ; 0.9863100767613553
[INFO] Storing checkpoint...
  77.28
Max memory: 94.513664
 26.034s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6206
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1522688
lr: 0.1
1

Epoch: [81 | 85] LR: 0.100000
batch Size 256
Epoch: [81][0/196]	Time 0.188 (0.188)	Data 0.286 (0.286)	Loss 0.6366 (0.6366)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [81][64/196]	Time 0.123 (0.117)	Data 0.000 (0.005)	Loss 0.6929 (0.6462)	Acc@1 85.938 (87.338)	Acc@5 99.219 (99.477)
Epoch: [81][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.6225 (0.6593)	Acc@1 90.234 (86.876)	Acc@5 99.219 (99.449)
Epoch: [81][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.6826 (0.6623)	Acc@1 86.328 (86.816)	Acc@5 98.828 (99.470)
Max memory in training epoch: 56.55168
lr: 0.1
1

Epoch: [82 | 85] LR: 0.100000
batch Size 256
Epoch: [82][0/196]	Time 0.149 (0.149)	Data 0.258 (0.258)	Loss 0.7167 (0.7167)	Acc@1 85.547 (85.547)	Acc@5 98.438 (98.438)
Epoch: [82][64/196]	Time 0.108 (0.117)	Data 0.000 (0.004)	Loss 0.6560 (0.6420)	Acc@1 85.547 (87.368)	Acc@5 98.438 (99.555)
Epoch: [82][128/196]	Time 0.130 (0.118)	Data 0.000 (0.002)	Loss 0.6907 (0.6527)	Acc@1 85.547 (86.982)	Acc@5 100.000 (99.470)
Epoch: [82][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.7071 (0.6659)	Acc@1 84.375 (86.569)	Acc@5 99.219 (99.439)
Max memory in training epoch: 56.4730368
lr: 0.1
1

Epoch: [83 | 85] LR: 0.100000
batch Size 256
Epoch: [83][0/196]	Time 0.152 (0.152)	Data 0.303 (0.303)	Loss 0.6737 (0.6737)	Acc@1 86.719 (86.719)	Acc@5 98.047 (98.047)
Epoch: [83][64/196]	Time 0.135 (0.121)	Data 0.000 (0.005)	Loss 0.7204 (0.6591)	Acc@1 83.203 (86.797)	Acc@5 100.000 (99.501)
Epoch: [83][128/196]	Time 0.118 (0.121)	Data 0.000 (0.003)	Loss 0.6640 (0.6602)	Acc@1 86.328 (86.855)	Acc@5 99.609 (99.509)
Epoch: [83][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.6970 (0.6641)	Acc@1 86.328 (86.759)	Acc@5 100.000 (99.504)
Max memory in training epoch: 56.4730368
lr: 0.1
1

Epoch: [84 | 85] LR: 0.100000
batch Size 256
Epoch: [84][0/196]	Time 0.163 (0.163)	Data 0.261 (0.261)	Loss 0.7373 (0.7373)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [84][64/196]	Time 0.114 (0.121)	Data 0.000 (0.004)	Loss 0.7248 (0.6636)	Acc@1 83.203 (86.514)	Acc@5 100.000 (99.537)
Epoch: [84][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.6392 (0.6679)	Acc@1 87.891 (86.374)	Acc@5 100.000 (99.500)
Epoch: [84][192/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.7003 (0.6702)	Acc@1 85.938 (86.450)	Acc@5 99.609 (99.490)
Max memory in training epoch: 56.4730368
lr: 0.1
1

Epoch: [85 | 85] LR: 0.100000
batch Size 256
Epoch: [85][0/196]	Time 0.156 (0.156)	Data 0.293 (0.293)	Loss 0.6091 (0.6091)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.112 (0.119)	Data 0.000 (0.005)	Loss 0.6712 (0.6470)	Acc@1 84.766 (87.554)	Acc@5 100.000 (99.489)
Epoch: [85][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.7120 (0.6624)	Acc@1 85.938 (86.961)	Acc@5 99.219 (99.458)
Epoch: [85][192/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.6245 (0.6655)	Acc@1 86.719 (86.723)	Acc@5 99.609 (99.458)
Max memory in training epoch: 56.4730368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 358060 ; 363114 ; 0.9860815060834889
[INFO] Storing checkpoint...
  81.13
Max memory: 87.7709312
 23.589s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1984
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1503744
lr: 0.1
1

Epoch: [86 | 90] LR: 0.100000
batch Size 256
Epoch: [86][0/196]	Time 0.183 (0.183)	Data 0.281 (0.281)	Loss 0.6202 (0.6202)	Acc@1 89.062 (89.062)	Acc@5 98.828 (98.828)
Epoch: [86][64/196]	Time 0.114 (0.116)	Data 0.000 (0.005)	Loss 0.7040 (0.6308)	Acc@1 84.766 (87.782)	Acc@5 98.828 (99.507)
Epoch: [86][128/196]	Time 0.109 (0.115)	Data 0.000 (0.002)	Loss 0.7100 (0.6465)	Acc@1 85.547 (87.336)	Acc@5 99.609 (99.467)
Epoch: [86][192/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.6744 (0.6507)	Acc@1 86.328 (87.200)	Acc@5 99.219 (99.486)
Max memory in training epoch: 56.1443328
lr: 0.1
1

Epoch: [87 | 90] LR: 0.100000
batch Size 256
Epoch: [87][0/196]	Time 0.143 (0.143)	Data 0.290 (0.290)	Loss 0.6325 (0.6325)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.107 (0.119)	Data 0.000 (0.005)	Loss 0.6563 (0.6502)	Acc@1 88.281 (87.061)	Acc@5 98.828 (99.507)
Epoch: [87][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.6380 (0.6549)	Acc@1 89.453 (86.991)	Acc@5 99.609 (99.522)
Epoch: [87][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.7719 (0.6591)	Acc@1 83.984 (86.954)	Acc@5 98.828 (99.510)
Max memory in training epoch: 56.4130304
lr: 0.1
1

Epoch: [88 | 90] LR: 0.100000
batch Size 256
Epoch: [88][0/196]	Time 0.162 (0.162)	Data 0.298 (0.298)	Loss 0.5810 (0.5810)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.120 (0.118)	Data 0.000 (0.005)	Loss 0.6193 (0.6705)	Acc@1 86.719 (86.406)	Acc@5 99.609 (99.435)
Epoch: [88][128/196]	Time 0.118 (0.119)	Data 0.000 (0.003)	Loss 0.6929 (0.6635)	Acc@1 87.109 (86.761)	Acc@5 99.219 (99.503)
Epoch: [88][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.6221 (0.6603)	Acc@1 89.062 (86.883)	Acc@5 100.000 (99.508)
Max memory in training epoch: 56.2098688
lr: 0.1
1

Epoch: [89 | 90] LR: 0.100000
batch Size 256
Epoch: [89][0/196]	Time 0.157 (0.157)	Data 0.302 (0.302)	Loss 0.7166 (0.7166)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 0.7190 (0.6527)	Acc@1 84.766 (87.139)	Acc@5 99.219 (99.495)
Epoch: [89][128/196]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.6228 (0.6577)	Acc@1 85.938 (86.882)	Acc@5 99.219 (99.497)
Epoch: [89][192/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.7247 (0.6636)	Acc@1 82.812 (86.668)	Acc@5 99.609 (99.490)
Max memory in training epoch: 56.2098688
lr: 0.1
1

Epoch: [90 | 90] LR: 0.100000
batch Size 256
Epoch: [90][0/196]	Time 0.148 (0.148)	Data 0.300 (0.300)	Loss 0.6560 (0.6560)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [90][64/196]	Time 0.109 (0.119)	Data 0.000 (0.005)	Loss 0.5853 (0.6496)	Acc@1 89.453 (87.151)	Acc@5 100.000 (99.531)
Epoch: [90][128/196]	Time 0.115 (0.118)	Data 0.000 (0.003)	Loss 0.6955 (0.6536)	Acc@1 87.109 (86.955)	Acc@5 99.609 (99.525)
Epoch: [90][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.6939 (0.6558)	Acc@1 85.938 (86.915)	Acc@5 99.609 (99.549)
Max memory in training epoch: 56.2098688
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356616 ; 358060 ; 0.9959671563425124
[INFO] Storing checkpoint...
  79.18
Max memory: 86.9452288
 23.425s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4329
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.14976
lr: 0.1
1

Epoch: [91 | 95] LR: 0.100000
batch Size 256
Epoch: [91][0/196]	Time 0.172 (0.172)	Data 0.298 (0.298)	Loss 0.5750 (0.5750)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.120 (0.119)	Data 0.000 (0.005)	Loss 0.6431 (0.6411)	Acc@1 86.328 (87.302)	Acc@5 100.000 (99.543)
Epoch: [91][128/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.7192 (0.6552)	Acc@1 85.547 (86.916)	Acc@5 99.609 (99.531)
Epoch: [91][192/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.6336 (0.6571)	Acc@1 87.891 (86.826)	Acc@5 99.609 (99.555)
Max memory in training epoch: 56.030464
lr: 0.1
1

Epoch: [92 | 95] LR: 0.100000
batch Size 256
Epoch: [92][0/196]	Time 0.154 (0.154)	Data 0.290 (0.290)	Loss 0.6274 (0.6274)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.117 (0.120)	Data 0.000 (0.005)	Loss 0.6330 (0.6586)	Acc@1 88.281 (86.827)	Acc@5 99.219 (99.393)
Epoch: [92][128/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.5756 (0.6569)	Acc@1 90.234 (86.773)	Acc@5 100.000 (99.479)
Epoch: [92][192/196]	Time 0.118 (0.121)	Data 0.000 (0.002)	Loss 0.5745 (0.6632)	Acc@1 90.625 (86.646)	Acc@5 99.609 (99.472)
Max memory in training epoch: 56.4105728
lr: 0.1
1

Epoch: [93 | 95] LR: 0.010000
batch Size 256
Epoch: [93][0/196]	Time 0.162 (0.162)	Data 0.278 (0.278)	Loss 0.6455 (0.6455)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [93][64/196]	Time 0.125 (0.120)	Data 0.000 (0.004)	Loss 0.4885 (0.5771)	Acc@1 93.359 (89.838)	Acc@5 100.000 (99.645)
Epoch: [93][128/196]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.4861 (0.5485)	Acc@1 92.969 (90.779)	Acc@5 100.000 (99.721)
Epoch: [93][192/196]	Time 0.118 (0.120)	Data 0.000 (0.002)	Loss 0.5249 (0.5300)	Acc@1 92.578 (91.350)	Acc@5 100.000 (99.773)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [94 | 95] LR: 0.010000
batch Size 256
Epoch: [94][0/196]	Time 0.180 (0.180)	Data 0.271 (0.271)	Loss 0.4614 (0.4614)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.128 (0.124)	Data 0.000 (0.004)	Loss 0.4821 (0.4812)	Acc@1 92.578 (92.849)	Acc@5 100.000 (99.838)
Epoch: [94][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 0.5414 (0.4787)	Acc@1 91.016 (93.011)	Acc@5 99.219 (99.824)
Epoch: [94][192/196]	Time 0.109 (0.122)	Data 0.000 (0.002)	Loss 0.5041 (0.4746)	Acc@1 91.797 (93.114)	Acc@5 100.000 (99.828)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [95 | 95] LR: 0.010000
batch Size 256
Epoch: [95][0/196]	Time 0.155 (0.155)	Data 0.319 (0.319)	Loss 0.4609 (0.4609)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.4428 (0.4533)	Acc@1 94.141 (93.594)	Acc@5 100.000 (99.880)
Epoch: [95][128/196]	Time 0.121 (0.122)	Data 0.000 (0.003)	Loss 0.3786 (0.4542)	Acc@1 96.484 (93.544)	Acc@5 100.000 (99.858)
Epoch: [95][192/196]	Time 0.129 (0.121)	Data 0.000 (0.002)	Loss 0.4351 (0.4501)	Acc@1 93.750 (93.671)	Acc@5 100.000 (99.858)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.97
Max memory: 86.7901952
 24.134s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2386
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [96 | 100] LR: 0.010000
batch Size 256
Epoch: [96][0/196]	Time 0.210 (0.210)	Data 0.264 (0.264)	Loss 0.4053 (0.4053)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.111 (0.119)	Data 0.000 (0.004)	Loss 0.4178 (0.4330)	Acc@1 94.531 (94.087)	Acc@5 100.000 (99.922)
Epoch: [96][128/196]	Time 0.109 (0.118)	Data 0.000 (0.002)	Loss 0.4108 (0.4340)	Acc@1 96.094 (94.038)	Acc@5 100.000 (99.885)
Epoch: [96][192/196]	Time 0.123 (0.118)	Data 0.000 (0.002)	Loss 0.4687 (0.4307)	Acc@1 91.797 (94.094)	Acc@5 100.000 (99.879)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [97 | 100] LR: 0.010000
batch Size 256
Epoch: [97][0/196]	Time 0.178 (0.178)	Data 0.267 (0.267)	Loss 0.3897 (0.3897)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.110 (0.119)	Data 0.000 (0.004)	Loss 0.4486 (0.4225)	Acc@1 93.359 (94.267)	Acc@5 100.000 (99.892)
Epoch: [97][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.4418 (0.4172)	Acc@1 92.578 (94.410)	Acc@5 100.000 (99.891)
Epoch: [97][192/196]	Time 0.125 (0.118)	Data 0.000 (0.002)	Loss 0.3899 (0.4176)	Acc@1 94.922 (94.363)	Acc@5 100.000 (99.909)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [98 | 100] LR: 0.010000
batch Size 256
Epoch: [98][0/196]	Time 0.160 (0.160)	Data 0.298 (0.298)	Loss 0.3803 (0.3803)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.111 (0.118)	Data 0.000 (0.005)	Loss 0.3972 (0.4012)	Acc@1 94.922 (94.868)	Acc@5 100.000 (99.928)
Epoch: [98][128/196]	Time 0.124 (0.117)	Data 0.000 (0.002)	Loss 0.4224 (0.4040)	Acc@1 94.141 (94.755)	Acc@5 100.000 (99.936)
Epoch: [98][192/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.3959 (0.4061)	Acc@1 95.703 (94.681)	Acc@5 100.000 (99.917)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [99 | 100] LR: 0.010000
batch Size 256
Epoch: [99][0/196]	Time 0.159 (0.159)	Data 0.288 (0.288)	Loss 0.3656 (0.3656)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.3651 (0.3891)	Acc@1 94.141 (95.054)	Acc@5 100.000 (99.958)
Epoch: [99][128/196]	Time 0.122 (0.119)	Data 0.000 (0.002)	Loss 0.3598 (0.3919)	Acc@1 95.703 (95.052)	Acc@5 100.000 (99.930)
Epoch: [99][192/196]	Time 0.122 (0.120)	Data 0.000 (0.002)	Loss 0.4230 (0.3935)	Acc@1 94.141 (95.007)	Acc@5 100.000 (99.927)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [100 | 100] LR: 0.010000
batch Size 256
Epoch: [100][0/196]	Time 0.158 (0.158)	Data 0.303 (0.303)	Loss 0.3777 (0.3777)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.114 (0.120)	Data 0.000 (0.005)	Loss 0.4074 (0.3781)	Acc@1 92.969 (95.325)	Acc@5 100.000 (99.946)
Epoch: [100][128/196]	Time 0.115 (0.119)	Data 0.000 (0.003)	Loss 0.4052 (0.3774)	Acc@1 94.141 (95.246)	Acc@5 100.000 (99.927)
Epoch: [100][192/196]	Time 0.111 (0.118)	Data 0.000 (0.002)	Loss 0.4823 (0.3822)	Acc@1 91.797 (95.090)	Acc@5 99.609 (99.911)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.02
Max memory: 86.7901952
 23.527s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 627
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [101 | 105] LR: 0.010000
batch Size 256
Epoch: [101][0/196]	Time 0.194 (0.194)	Data 0.280 (0.280)	Loss 0.3455 (0.3455)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.113 (0.115)	Data 0.000 (0.004)	Loss 0.3861 (0.3740)	Acc@1 94.531 (95.487)	Acc@5 99.609 (99.922)
Epoch: [101][128/196]	Time 0.118 (0.115)	Data 0.000 (0.002)	Loss 0.3526 (0.3737)	Acc@1 96.484 (95.279)	Acc@5 100.000 (99.918)
Epoch: [101][192/196]	Time 0.117 (0.116)	Data 0.000 (0.002)	Loss 0.3565 (0.3738)	Acc@1 96.094 (95.280)	Acc@5 99.609 (99.919)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [102 | 105] LR: 0.010000
batch Size 256
Epoch: [102][0/196]	Time 0.140 (0.140)	Data 0.311 (0.311)	Loss 0.3943 (0.3943)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.117 (0.118)	Data 0.000 (0.005)	Loss 0.3566 (0.3577)	Acc@1 94.922 (95.907)	Acc@5 100.000 (99.946)
Epoch: [102][128/196]	Time 0.112 (0.118)	Data 0.000 (0.003)	Loss 0.3381 (0.3627)	Acc@1 96.094 (95.603)	Acc@5 100.000 (99.927)
Epoch: [102][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3340 (0.3624)	Acc@1 95.703 (95.549)	Acc@5 100.000 (99.927)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [103 | 105] LR: 0.010000
batch Size 256
Epoch: [103][0/196]	Time 0.156 (0.156)	Data 0.289 (0.289)	Loss 0.3204 (0.3204)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.3707 (0.3584)	Acc@1 94.531 (95.601)	Acc@5 100.000 (99.946)
Epoch: [103][128/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3751 (0.3580)	Acc@1 96.094 (95.534)	Acc@5 100.000 (99.942)
Epoch: [103][192/196]	Time 0.120 (0.117)	Data 0.000 (0.002)	Loss 0.3291 (0.3587)	Acc@1 96.875 (95.485)	Acc@5 99.609 (99.941)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [104 | 105] LR: 0.010000
batch Size 256
Epoch: [104][0/196]	Time 0.155 (0.155)	Data 0.303 (0.303)	Loss 0.3359 (0.3359)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.121 (0.117)	Data 0.000 (0.005)	Loss 0.3599 (0.3389)	Acc@1 96.484 (96.238)	Acc@5 100.000 (99.970)
Epoch: [104][128/196]	Time 0.120 (0.117)	Data 0.000 (0.003)	Loss 0.3244 (0.3440)	Acc@1 96.875 (95.970)	Acc@5 100.000 (99.949)
Epoch: [104][192/196]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.3879 (0.3480)	Acc@1 94.531 (95.821)	Acc@5 99.609 (99.943)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [105 | 105] LR: 0.010000
batch Size 256
Epoch: [105][0/196]	Time 0.165 (0.165)	Data 0.329 (0.329)	Loss 0.3164 (0.3164)	Acc@1 97.266 (97.266)	Acc@5 99.609 (99.609)
Epoch: [105][64/196]	Time 0.122 (0.118)	Data 0.000 (0.005)	Loss 0.3600 (0.3375)	Acc@1 95.703 (96.172)	Acc@5 100.000 (99.970)
Epoch: [105][128/196]	Time 0.117 (0.118)	Data 0.000 (0.003)	Loss 0.3483 (0.3429)	Acc@1 96.875 (95.873)	Acc@5 100.000 (99.952)
Epoch: [105][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.3487 (0.3447)	Acc@1 95.703 (95.792)	Acc@5 100.000 (99.947)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.17
Max memory: 86.7901952
 23.420s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6634
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [106 | 110] LR: 0.010000
batch Size 256
Epoch: [106][0/196]	Time 0.209 (0.209)	Data 0.305 (0.305)	Loss 0.3349 (0.3349)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.112 (0.119)	Data 0.000 (0.005)	Loss 0.2841 (0.3298)	Acc@1 97.656 (96.094)	Acc@5 100.000 (99.934)
Epoch: [106][128/196]	Time 0.115 (0.117)	Data 0.000 (0.003)	Loss 0.3354 (0.3318)	Acc@1 95.703 (96.100)	Acc@5 100.000 (99.930)
Epoch: [106][192/196]	Time 0.111 (0.117)	Data 0.000 (0.002)	Loss 0.3046 (0.3337)	Acc@1 97.266 (95.986)	Acc@5 100.000 (99.931)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [107 | 110] LR: 0.010000
batch Size 256
Epoch: [107][0/196]	Time 0.184 (0.184)	Data 0.262 (0.262)	Loss 0.3084 (0.3084)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.3106 (0.3218)	Acc@1 97.266 (96.508)	Acc@5 99.609 (99.964)
Epoch: [107][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.3448 (0.3290)	Acc@1 94.922 (96.130)	Acc@5 100.000 (99.949)
Epoch: [107][192/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.4129 (0.3322)	Acc@1 93.750 (95.958)	Acc@5 100.000 (99.949)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [108 | 110] LR: 0.010000
batch Size 256
Epoch: [108][0/196]	Time 0.153 (0.153)	Data 0.270 (0.270)	Loss 0.2962 (0.2962)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.134 (0.118)	Data 0.000 (0.004)	Loss 0.2939 (0.3221)	Acc@1 97.266 (96.148)	Acc@5 100.000 (99.988)
Epoch: [108][128/196]	Time 0.129 (0.118)	Data 0.000 (0.002)	Loss 0.3265 (0.3267)	Acc@1 95.703 (95.936)	Acc@5 100.000 (99.976)
Epoch: [108][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3590 (0.3277)	Acc@1 94.922 (95.891)	Acc@5 99.609 (99.966)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [109 | 110] LR: 0.010000
batch Size 256
Epoch: [109][0/196]	Time 0.151 (0.151)	Data 0.331 (0.331)	Loss 0.3299 (0.3299)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [109][64/196]	Time 0.115 (0.119)	Data 0.000 (0.005)	Loss 0.2760 (0.3193)	Acc@1 98.047 (96.154)	Acc@5 100.000 (99.964)
Epoch: [109][128/196]	Time 0.112 (0.119)	Data 0.000 (0.003)	Loss 0.3394 (0.3208)	Acc@1 94.922 (96.091)	Acc@5 100.000 (99.961)
Epoch: [109][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3506 (0.3209)	Acc@1 95.312 (96.057)	Acc@5 100.000 (99.964)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [110 | 110] LR: 0.010000
batch Size 256
Epoch: [110][0/196]	Time 0.147 (0.147)	Data 0.303 (0.303)	Loss 0.3353 (0.3353)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.116 (0.120)	Data 0.000 (0.005)	Loss 0.3185 (0.3142)	Acc@1 96.094 (96.202)	Acc@5 100.000 (99.970)
Epoch: [110][128/196]	Time 0.122 (0.119)	Data 0.000 (0.003)	Loss 0.2927 (0.3164)	Acc@1 97.266 (96.188)	Acc@5 100.000 (99.964)
Epoch: [110][192/196]	Time 0.112 (0.119)	Data 0.000 (0.002)	Loss 0.2984 (0.3189)	Acc@1 96.094 (96.100)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.62
Max memory: 86.7901952
 23.761s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1017
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [111 | 115] LR: 0.010000
batch Size 256
Epoch: [111][0/196]	Time 0.188 (0.188)	Data 0.261 (0.261)	Loss 0.3042 (0.3042)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.109 (0.117)	Data 0.000 (0.004)	Loss 0.2960 (0.3041)	Acc@1 96.484 (96.599)	Acc@5 100.000 (99.952)
Epoch: [111][128/196]	Time 0.110 (0.116)	Data 0.000 (0.002)	Loss 0.3140 (0.3103)	Acc@1 96.484 (96.291)	Acc@5 100.000 (99.961)
Epoch: [111][192/196]	Time 0.116 (0.117)	Data 0.000 (0.002)	Loss 0.3258 (0.3104)	Acc@1 94.922 (96.290)	Acc@5 100.000 (99.966)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [112 | 115] LR: 0.010000
batch Size 256
Epoch: [112][0/196]	Time 0.159 (0.159)	Data 0.299 (0.299)	Loss 0.2898 (0.2898)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [112][64/196]	Time 0.114 (0.117)	Data 0.000 (0.005)	Loss 0.3020 (0.3082)	Acc@1 96.484 (96.298)	Acc@5 100.000 (99.958)
Epoch: [112][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.2805 (0.3090)	Acc@1 96.484 (96.221)	Acc@5 100.000 (99.952)
Epoch: [112][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.3121 (0.3114)	Acc@1 96.094 (96.187)	Acc@5 100.000 (99.951)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [113 | 115] LR: 0.010000
batch Size 256
Epoch: [113][0/196]	Time 0.161 (0.161)	Data 0.256 (0.256)	Loss 0.3124 (0.3124)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.108 (0.117)	Data 0.000 (0.004)	Loss 0.3107 (0.2992)	Acc@1 96.484 (96.490)	Acc@5 100.000 (99.970)
Epoch: [113][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.3455 (0.3068)	Acc@1 94.141 (96.236)	Acc@5 99.609 (99.958)
Epoch: [113][192/196]	Time 0.112 (0.117)	Data 0.000 (0.001)	Loss 0.3301 (0.3091)	Acc@1 96.094 (96.134)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [114 | 115] LR: 0.010000
batch Size 256
Epoch: [114][0/196]	Time 0.171 (0.171)	Data 0.302 (0.302)	Loss 0.3218 (0.3218)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.113 (0.118)	Data 0.000 (0.005)	Loss 0.2813 (0.3052)	Acc@1 97.266 (96.310)	Acc@5 100.000 (99.976)
Epoch: [114][128/196]	Time 0.111 (0.118)	Data 0.000 (0.003)	Loss 0.2805 (0.3056)	Acc@1 96.094 (96.218)	Acc@5 100.000 (99.964)
Epoch: [114][192/196]	Time 0.121 (0.118)	Data 0.000 (0.002)	Loss 0.2891 (0.3095)	Acc@1 96.484 (96.045)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [115 | 115] LR: 0.010000
batch Size 256
Epoch: [115][0/196]	Time 0.157 (0.157)	Data 0.298 (0.298)	Loss 0.2672 (0.2672)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.3132 (0.2999)	Acc@1 96.094 (96.286)	Acc@5 100.000 (99.958)
Epoch: [115][128/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.3278 (0.3026)	Acc@1 94.531 (96.182)	Acc@5 99.609 (99.955)
Epoch: [115][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2629 (0.3054)	Acc@1 98.047 (96.088)	Acc@5 100.000 (99.953)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  89.98
Max memory: 86.7901952
 23.334s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1413
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [116 | 120] LR: 0.010000
batch Size 256
Epoch: [116][0/196]	Time 0.179 (0.179)	Data 0.299 (0.299)	Loss 0.2745 (0.2745)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.116 (0.117)	Data 0.000 (0.005)	Loss 0.3236 (0.2860)	Acc@1 96.094 (96.785)	Acc@5 100.000 (99.976)
Epoch: [116][128/196]	Time 0.113 (0.117)	Data 0.000 (0.003)	Loss 0.3528 (0.2926)	Acc@1 93.359 (96.566)	Acc@5 99.609 (99.979)
Epoch: [116][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2821 (0.2998)	Acc@1 96.875 (96.260)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [117 | 120] LR: 0.010000
batch Size 256
Epoch: [117][0/196]	Time 0.145 (0.145)	Data 0.295 (0.295)	Loss 0.2926 (0.2926)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.116 (0.119)	Data 0.000 (0.005)	Loss 0.2933 (0.2993)	Acc@1 96.484 (96.388)	Acc@5 100.000 (99.946)
Epoch: [117][128/196]	Time 0.133 (0.118)	Data 0.000 (0.002)	Loss 0.2807 (0.2998)	Acc@1 97.656 (96.348)	Acc@5 100.000 (99.945)
Epoch: [117][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3389 (0.3036)	Acc@1 93.750 (96.128)	Acc@5 100.000 (99.955)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [118 | 120] LR: 0.010000
batch Size 256
Epoch: [118][0/196]	Time 0.152 (0.152)	Data 0.298 (0.298)	Loss 0.3514 (0.3514)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.112 (0.118)	Data 0.000 (0.005)	Loss 0.3570 (0.3015)	Acc@1 95.312 (95.998)	Acc@5 100.000 (99.988)
Epoch: [118][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2562 (0.2992)	Acc@1 97.656 (96.115)	Acc@5 100.000 (99.970)
Epoch: [118][192/196]	Time 0.130 (0.118)	Data 0.000 (0.002)	Loss 0.2780 (0.3003)	Acc@1 97.656 (96.080)	Acc@5 100.000 (99.970)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [119 | 120] LR: 0.010000
batch Size 256
Epoch: [119][0/196]	Time 0.164 (0.164)	Data 0.273 (0.273)	Loss 0.3117 (0.3117)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.118 (0.117)	Data 0.000 (0.004)	Loss 0.2887 (0.2970)	Acc@1 96.484 (96.178)	Acc@5 100.000 (99.976)
Epoch: [119][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.4098 (0.3030)	Acc@1 92.188 (95.979)	Acc@5 100.000 (99.961)
Epoch: [119][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2971 (0.3040)	Acc@1 94.531 (95.956)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [120 | 120] LR: 0.010000
batch Size 256
Epoch: [120][0/196]	Time 0.171 (0.171)	Data 0.263 (0.263)	Loss 0.3053 (0.3053)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.116 (0.119)	Data 0.000 (0.004)	Loss 0.2782 (0.2963)	Acc@1 96.875 (96.106)	Acc@5 100.000 (99.946)
Epoch: [120][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3305 (0.3001)	Acc@1 93.750 (96.000)	Acc@5 100.000 (99.955)
Epoch: [120][192/196]	Time 0.122 (0.118)	Data 0.000 (0.002)	Loss 0.3152 (0.3009)	Acc@1 94.922 (95.976)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.78
Max memory: 86.7901952
 23.462s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5652
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [121 | 125] LR: 0.010000
batch Size 256
Epoch: [121][0/196]	Time 0.174 (0.174)	Data 0.297 (0.297)	Loss 0.2522 (0.2522)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.120 (0.118)	Data 0.000 (0.005)	Loss 0.3349 (0.2863)	Acc@1 94.531 (96.538)	Acc@5 100.000 (99.964)
Epoch: [121][128/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2751 (0.2929)	Acc@1 97.266 (96.194)	Acc@5 100.000 (99.967)
Epoch: [121][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3154 (0.2980)	Acc@1 94.141 (95.984)	Acc@5 100.000 (99.962)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [122 | 125] LR: 0.010000
batch Size 256
Epoch: [122][0/196]	Time 0.171 (0.171)	Data 0.286 (0.286)	Loss 0.2755 (0.2755)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.116 (0.119)	Data 0.000 (0.005)	Loss 0.2934 (0.2926)	Acc@1 96.484 (96.196)	Acc@5 100.000 (99.964)
Epoch: [122][128/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.3103 (0.2956)	Acc@1 95.312 (96.027)	Acc@5 100.000 (99.970)
Epoch: [122][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2811 (0.2969)	Acc@1 95.312 (95.974)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [123 | 125] LR: 0.010000
batch Size 256
Epoch: [123][0/196]	Time 0.156 (0.156)	Data 0.273 (0.273)	Loss 0.2705 (0.2705)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.109 (0.119)	Data 0.000 (0.004)	Loss 0.2643 (0.2872)	Acc@1 97.266 (96.316)	Acc@5 100.000 (99.970)
Epoch: [123][128/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3061 (0.2888)	Acc@1 95.312 (96.257)	Acc@5 100.000 (99.970)
Epoch: [123][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2955 (0.2937)	Acc@1 96.484 (96.063)	Acc@5 100.000 (99.968)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [124 | 125] LR: 0.010000
batch Size 256
Epoch: [124][0/196]	Time 0.162 (0.162)	Data 0.258 (0.258)	Loss 0.2647 (0.2647)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.117 (0.120)	Data 0.000 (0.004)	Loss 0.3015 (0.2913)	Acc@1 95.312 (96.214)	Acc@5 100.000 (99.976)
Epoch: [124][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3415 (0.2923)	Acc@1 95.312 (96.172)	Acc@5 100.000 (99.982)
Epoch: [124][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.3421 (0.2967)	Acc@1 94.531 (95.942)	Acc@5 100.000 (99.978)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [125 | 125] LR: 0.010000
batch Size 256
Epoch: [125][0/196]	Time 0.162 (0.162)	Data 0.285 (0.285)	Loss 0.2682 (0.2682)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.120 (0.121)	Data 0.000 (0.005)	Loss 0.2945 (0.2847)	Acc@1 96.094 (96.400)	Acc@5 100.000 (99.970)
Epoch: [125][128/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3212 (0.2892)	Acc@1 94.922 (96.212)	Acc@5 99.609 (99.973)
Epoch: [125][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.3063 (0.2935)	Acc@1 96.484 (96.025)	Acc@5 100.000 (99.960)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  88.36
Max memory: 86.7901952
 23.614s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6246
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.14976
lr: 0.010000000000000002
1

Epoch: [126 | 130] LR: 0.010000
batch Size 256
Epoch: [126][0/196]	Time 0.181 (0.181)	Data 0.326 (0.326)	Loss 0.3019 (0.3019)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.110 (0.118)	Data 0.000 (0.005)	Loss 0.2958 (0.2743)	Acc@1 96.094 (96.731)	Acc@5 100.000 (99.982)
Epoch: [126][128/196]	Time 0.112 (0.116)	Data 0.000 (0.003)	Loss 0.2906 (0.2817)	Acc@1 95.312 (96.415)	Acc@5 100.000 (99.973)
Epoch: [126][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2978 (0.2867)	Acc@1 95.312 (96.207)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.030464
lr: 0.010000000000000002
1

Epoch: [127 | 130] LR: 0.010000
batch Size 256
Epoch: [127][0/196]	Time 0.161 (0.161)	Data 0.263 (0.263)	Loss 0.2438 (0.2438)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.112 (0.119)	Data 0.000 (0.004)	Loss 0.2989 (0.2903)	Acc@1 95.312 (96.154)	Acc@5 100.000 (99.982)
Epoch: [127][128/196]	Time 0.117 (0.119)	Data 0.000 (0.002)	Loss 0.2924 (0.2925)	Acc@1 94.922 (96.076)	Acc@5 100.000 (99.979)
Epoch: [127][192/196]	Time 0.117 (0.118)	Data 0.000 (0.002)	Loss 0.2795 (0.2950)	Acc@1 96.484 (95.968)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.4105728
lr: 0.010000000000000002
1

Epoch: [128 | 130] LR: 0.010000
batch Size 256
Epoch: [128][0/196]	Time 0.161 (0.161)	Data 0.302 (0.302)	Loss 0.3067 (0.3067)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.119 (0.117)	Data 0.000 (0.005)	Loss 0.2952 (0.2830)	Acc@1 95.703 (96.220)	Acc@5 100.000 (99.970)
Epoch: [128][128/196]	Time 0.132 (0.118)	Data 0.000 (0.003)	Loss 0.3000 (0.2900)	Acc@1 95.312 (96.024)	Acc@5 100.000 (99.961)
Epoch: [128][192/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.2945 (0.2960)	Acc@1 95.703 (95.764)	Acc@5 100.000 (99.957)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [129 | 130] LR: 0.010000
batch Size 256
Epoch: [129][0/196]	Time 0.157 (0.157)	Data 0.293 (0.293)	Loss 0.2856 (0.2856)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.108 (0.117)	Data 0.000 (0.005)	Loss 0.2717 (0.2867)	Acc@1 96.484 (96.280)	Acc@5 100.000 (99.970)
Epoch: [129][128/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2715 (0.2889)	Acc@1 96.484 (96.133)	Acc@5 100.000 (99.982)
Epoch: [129][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.2607 (0.2928)	Acc@1 98.047 (95.972)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.2074112
lr: 0.010000000000000002
1

Epoch: [130 | 130] LR: 0.010000
batch Size 256
Epoch: [130][0/196]	Time 0.176 (0.176)	Data 0.262 (0.262)	Loss 0.2802 (0.2802)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.125 (0.121)	Data 0.000 (0.004)	Loss 0.2693 (0.2890)	Acc@1 97.266 (96.100)	Acc@5 100.000 (99.970)
Epoch: [130][128/196]	Time 0.147 (0.119)	Data 0.000 (0.002)	Loss 0.2532 (0.2864)	Acc@1 96.875 (96.151)	Acc@5 100.000 (99.982)
Epoch: [130][192/196]	Time 0.128 (0.119)	Data 0.000 (0.002)	Loss 0.3154 (0.2915)	Acc@1 95.312 (95.991)	Acc@5 100.000 (99.976)
Max memory in training epoch: 56.2074112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 356182 ; 356616 ; 0.9987830046885166
[INFO] Storing checkpoint...
  90.31
Max memory: 86.7901952
 23.679s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2064
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1496064
lr: 0.010000000000000002
1

Epoch: [131 | 135] LR: 0.010000
batch Size 256
Epoch: [131][0/196]	Time 0.202 (0.202)	Data 0.270 (0.270)	Loss 0.2672 (0.2672)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.134 (0.117)	Data 0.000 (0.004)	Loss 0.2772 (0.2791)	Acc@1 96.094 (96.448)	Acc@5 99.609 (99.964)
Epoch: [131][128/196]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.3177 (0.2847)	Acc@1 96.094 (96.269)	Acc@5 100.000 (99.961)
Epoch: [131][192/196]	Time 0.132 (0.116)	Data 0.000 (0.002)	Loss 0.3170 (0.2908)	Acc@1 95.312 (95.986)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.9774208
lr: 0.010000000000000002
1

Epoch: [132 | 135] LR: 0.010000
batch Size 256
Epoch: [132][0/196]	Time 0.179 (0.179)	Data 0.276 (0.276)	Loss 0.2708 (0.2708)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.119 (0.118)	Data 0.000 (0.004)	Loss 0.2402 (0.2859)	Acc@1 97.656 (96.100)	Acc@5 100.000 (99.976)
Epoch: [132][128/196]	Time 0.123 (0.119)	Data 0.000 (0.002)	Loss 0.2792 (0.2923)	Acc@1 95.312 (95.867)	Acc@5 100.000 (99.985)
Epoch: [132][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.2451 (0.2940)	Acc@1 98.438 (95.861)	Acc@5 100.000 (99.974)
Max memory in training epoch: 56.2330112
lr: 0.010000000000000002
1

Epoch: [133 | 135] LR: 0.010000
batch Size 256
Epoch: [133][0/196]	Time 0.169 (0.169)	Data 0.310 (0.310)	Loss 0.2958 (0.2958)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.119 (0.118)	Data 0.000 (0.005)	Loss 0.2986 (0.2951)	Acc@1 96.875 (95.697)	Acc@5 100.000 (99.982)
Epoch: [133][128/196]	Time 0.120 (0.118)	Data 0.000 (0.003)	Loss 0.2857 (0.2920)	Acc@1 96.484 (95.864)	Acc@5 100.000 (99.979)
Epoch: [133][192/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2553 (0.2915)	Acc@1 97.656 (95.899)	Acc@5 100.000 (99.972)
Max memory in training epoch: 56.2330112
lr: 0.010000000000000002
1

Epoch: [134 | 135] LR: 0.010000
batch Size 256
Epoch: [134][0/196]	Time 0.140 (0.140)	Data 0.301 (0.301)	Loss 0.2987 (0.2987)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.110 (0.118)	Data 0.000 (0.005)	Loss 0.2904 (0.2898)	Acc@1 96.094 (95.835)	Acc@5 100.000 (99.964)
Epoch: [134][128/196]	Time 0.114 (0.118)	Data 0.000 (0.003)	Loss 0.4029 (0.2949)	Acc@1 92.969 (95.782)	Acc@5 100.000 (99.967)
Epoch: [134][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.2908 (0.2987)	Acc@1 96.484 (95.636)	Acc@5 99.609 (99.966)
Max memory in training epoch: 56.2330112
lr: 0.010000000000000002
1

Epoch: [135 | 135] LR: 0.010000
batch Size 256
Epoch: [135][0/196]	Time 0.151 (0.151)	Data 0.293 (0.293)	Loss 0.2515 (0.2515)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.116 (0.121)	Data 0.000 (0.005)	Loss 0.2821 (0.2872)	Acc@1 96.875 (96.028)	Acc@5 100.000 (99.952)
Epoch: [135][128/196]	Time 0.107 (0.119)	Data 0.000 (0.002)	Loss 0.3273 (0.2924)	Acc@1 95.703 (95.797)	Acc@5 99.609 (99.964)
Epoch: [135][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.3517 (0.2950)	Acc@1 94.531 (95.721)	Acc@5 99.609 (99.970)
Max memory in training epoch: 56.2330112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 355892 ; 356182 ; 0.9991858095018838
[INFO] Storing checkpoint...
  89.12
Max memory: 86.6758656
 23.522s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7335
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.149504
lr: 0.010000000000000002
1

Epoch: [136 | 140] LR: 0.010000
batch Size 256
Epoch: [136][0/196]	Time 0.192 (0.192)	Data 0.290 (0.290)	Loss 0.2897 (0.2897)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.109 (0.116)	Data 0.000 (0.005)	Loss 0.2916 (0.2807)	Acc@1 96.094 (96.286)	Acc@5 100.000 (99.958)
Epoch: [136][128/196]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.3362 (0.2868)	Acc@1 94.141 (96.085)	Acc@5 99.609 (99.973)
Epoch: [136][192/196]	Time 0.116 (0.116)	Data 0.000 (0.002)	Loss 0.2789 (0.2922)	Acc@1 96.094 (95.823)	Acc@5 100.000 (99.970)
Max memory in training epoch: 55.6755456
lr: 0.010000000000000002
1

Epoch: [137 | 140] LR: 0.010000
batch Size 256
Epoch: [137][0/196]	Time 0.168 (0.168)	Data 0.255 (0.255)	Loss 0.2595 (0.2595)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.116 (0.117)	Data 0.000 (0.004)	Loss 0.3096 (0.2986)	Acc@1 94.922 (95.649)	Acc@5 100.000 (99.976)
Epoch: [137][128/196]	Time 0.109 (0.116)	Data 0.000 (0.002)	Loss 0.2889 (0.2953)	Acc@1 94.922 (95.749)	Acc@5 100.000 (99.961)
Epoch: [137][192/196]	Time 0.113 (0.117)	Data 0.000 (0.001)	Loss 0.2913 (0.3005)	Acc@1 95.703 (95.527)	Acc@5 100.000 (99.960)
Max memory in training epoch: 55.9114752
lr: 0.010000000000000002
1

Epoch: [138 | 140] LR: 0.010000
batch Size 256
Epoch: [138][0/196]	Time 0.195 (0.195)	Data 0.303 (0.303)	Loss 0.3126 (0.3126)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.121 (0.119)	Data 0.000 (0.005)	Loss 0.2904 (0.2840)	Acc@1 96.094 (96.058)	Acc@5 100.000 (99.970)
Epoch: [138][128/196]	Time 0.129 (0.120)	Data 0.000 (0.003)	Loss 0.2960 (0.2871)	Acc@1 95.703 (96.054)	Acc@5 100.000 (99.964)
Epoch: [138][192/196]	Time 0.116 (0.119)	Data 0.000 (0.002)	Loss 0.3409 (0.2937)	Acc@1 93.750 (95.816)	Acc@5 100.000 (99.962)
Max memory in training epoch: 55.8131712
lr: 0.010000000000000002
1

Epoch: [139 | 140] LR: 0.010000
batch Size 256
Epoch: [139][0/196]	Time 0.157 (0.157)	Data 0.280 (0.280)	Loss 0.2844 (0.2844)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.130 (0.119)	Data 0.000 (0.004)	Loss 0.2765 (0.2917)	Acc@1 96.484 (95.853)	Acc@5 99.609 (99.976)
Epoch: [139][128/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.2947 (0.2942)	Acc@1 95.703 (95.824)	Acc@5 100.000 (99.982)
Epoch: [139][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2981 (0.2956)	Acc@1 97.266 (95.780)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.8131712
lr: 0.010000000000000002
1

Epoch: [140 | 140] LR: 0.010000
batch Size 256
Epoch: [140][0/196]	Time 0.160 (0.160)	Data 0.298 (0.298)	Loss 0.2738 (0.2738)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.122 (0.119)	Data 0.000 (0.005)	Loss 0.2949 (0.2863)	Acc@1 94.922 (95.992)	Acc@5 100.000 (99.976)
Epoch: [140][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.3234 (0.2912)	Acc@1 95.312 (95.891)	Acc@5 99.609 (99.964)
Epoch: [140][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3265 (0.2981)	Acc@1 94.922 (95.634)	Acc@5 99.609 (99.966)
Max memory in training epoch: 55.8131712
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  90.51
Max memory: 86.2280704
 23.484s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3968
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.149504
lr: 0.010000000000000002
1

Epoch: [141 | 145] LR: 0.010000
batch Size 256
Epoch: [141][0/196]	Time 0.169 (0.169)	Data 0.301 (0.301)	Loss 0.2407 (0.2407)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.114 (0.114)	Data 0.000 (0.005)	Loss 0.2842 (0.2728)	Acc@1 96.484 (96.683)	Acc@5 99.609 (99.982)
Epoch: [141][128/196]	Time 0.111 (0.115)	Data 0.000 (0.002)	Loss 0.2780 (0.2813)	Acc@1 96.875 (96.260)	Acc@5 100.000 (99.976)
Epoch: [141][192/196]	Time 0.119 (0.115)	Data 0.000 (0.002)	Loss 0.3696 (0.2888)	Acc@1 92.578 (96.003)	Acc@5 100.000 (99.964)
Max memory in training epoch: 55.6755456
lr: 0.010000000000000002
1

Epoch: [142 | 145] LR: 0.010000
batch Size 256
Epoch: [142][0/196]	Time 0.167 (0.167)	Data 0.292 (0.292)	Loss 0.3411 (0.3411)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.121 (0.116)	Data 0.000 (0.005)	Loss 0.3175 (0.2883)	Acc@1 95.312 (95.944)	Acc@5 100.000 (99.964)
Epoch: [142][128/196]	Time 0.132 (0.116)	Data 0.000 (0.002)	Loss 0.2959 (0.2880)	Acc@1 94.531 (95.961)	Acc@5 100.000 (99.967)
Epoch: [142][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.2573 (0.2924)	Acc@1 96.484 (95.780)	Acc@5 100.000 (99.968)
Max memory in training epoch: 55.9114752
lr: 0.010000000000000002
1

Epoch: [143 | 145] LR: 0.010000
batch Size 256
Epoch: [143][0/196]	Time 0.136 (0.136)	Data 0.298 (0.298)	Loss 0.2834 (0.2834)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.111 (0.116)	Data 0.000 (0.005)	Loss 0.3065 (0.2875)	Acc@1 94.531 (95.931)	Acc@5 100.000 (99.988)
Epoch: [143][128/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2901 (0.2913)	Acc@1 95.312 (95.842)	Acc@5 100.000 (99.976)
Epoch: [143][192/196]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.3240 (0.2936)	Acc@1 94.141 (95.731)	Acc@5 99.609 (99.974)
Max memory in training epoch: 55.8131712
lr: 0.010000000000000002
1

Epoch: [144 | 145] LR: 0.010000
batch Size 256
Epoch: [144][0/196]	Time 0.150 (0.150)	Data 0.286 (0.286)	Loss 0.2400 (0.2400)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.2588 (0.2822)	Acc@1 98.047 (96.196)	Acc@5 100.000 (99.964)
Epoch: [144][128/196]	Time 0.118 (0.118)	Data 0.000 (0.002)	Loss 0.3177 (0.2904)	Acc@1 94.531 (95.873)	Acc@5 100.000 (99.967)
Epoch: [144][192/196]	Time 0.114 (0.117)	Data 0.000 (0.002)	Loss 0.3368 (0.2933)	Acc@1 94.141 (95.804)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.8131712
lr: 0.010000000000000002
1

Epoch: [145 | 145] LR: 0.010000
batch Size 256
Epoch: [145][0/196]	Time 0.159 (0.159)	Data 0.292 (0.292)	Loss 0.3085 (0.3085)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.117 (0.121)	Data 0.000 (0.005)	Loss 0.2668 (0.2931)	Acc@1 95.703 (95.901)	Acc@5 100.000 (99.988)
Epoch: [145][128/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2623 (0.2904)	Acc@1 96.875 (95.976)	Acc@5 99.609 (99.970)
Epoch: [145][192/196]	Time 0.119 (0.117)	Data 0.000 (0.002)	Loss 0.3394 (0.2936)	Acc@1 94.922 (95.808)	Acc@5 100.000 (99.966)
Max memory in training epoch: 55.8131712
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
Count: 355602 ; 355892 ; 0.999185146055545
[INFO] Storing checkpoint...
  90.3
Max memory: 86.2280704
 23.390s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8653
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.1494016
lr: 0.010000000000000002
1

Epoch: [146 | 150] LR: 0.010000
batch Size 256
Epoch: [146][0/196]	Time 0.180 (0.180)	Data 0.303 (0.303)	Loss 0.2767 (0.2767)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.109 (0.118)	Data 0.000 (0.005)	Loss 0.2749 (0.2734)	Acc@1 96.875 (96.587)	Acc@5 100.000 (99.982)
Epoch: [146][128/196]	Time 0.117 (0.117)	Data 0.000 (0.003)	Loss 0.3295 (0.2799)	Acc@1 94.922 (96.369)	Acc@5 100.000 (99.982)
Epoch: [146][192/196]	Time 0.125 (0.117)	Data 0.000 (0.002)	Loss 0.3223 (0.2878)	Acc@1 95.703 (96.055)	Acc@5 100.000 (99.978)
Max memory in training epoch: 55.3081344
lr: 0.010000000000000002
1

Epoch: [147 | 150] LR: 0.010000
batch Size 256
Epoch: [147][0/196]	Time 0.174 (0.174)	Data 0.289 (0.289)	Loss 0.2674 (0.2674)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.141 (0.122)	Data 0.000 (0.005)	Loss 0.2681 (0.2832)	Acc@1 96.875 (96.256)	Acc@5 100.000 (99.946)
Epoch: [147][128/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.3088 (0.2908)	Acc@1 93.750 (95.970)	Acc@5 100.000 (99.958)
Epoch: [147][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.2844 (0.2928)	Acc@1 95.703 (95.859)	Acc@5 100.000 (99.957)
Max memory in training epoch: 55.544064
lr: 0.010000000000000002
1

Epoch: [148 | 150] LR: 0.010000
batch Size 256
Epoch: [148][0/196]	Time 0.154 (0.154)	Data 0.303 (0.303)	Loss 0.2702 (0.2702)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.118 (0.119)	Data 0.000 (0.005)	Loss 0.2404 (0.2768)	Acc@1 97.266 (96.358)	Acc@5 100.000 (99.964)
Epoch: [148][128/196]	Time 0.125 (0.118)	Data 0.000 (0.003)	Loss 0.3176 (0.2846)	Acc@1 96.094 (96.048)	Acc@5 100.000 (99.976)
Epoch: [148][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.3333 (0.2895)	Acc@1 94.141 (95.867)	Acc@5 100.000 (99.974)
Max memory in training epoch: 55.544064
lr: 0.010000000000000002
1

Epoch: [149 | 150] LR: 0.010000
batch Size 256
Epoch: [149][0/196]	Time 0.162 (0.162)	Data 0.314 (0.314)	Loss 0.2956 (0.2956)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.143 (0.120)	Data 0.000 (0.005)	Loss 0.2737 (0.2875)	Acc@1 97.266 (95.913)	Acc@5 100.000 (99.976)
Epoch: [149][128/196]	Time 0.127 (0.119)	Data 0.000 (0.003)	Loss 0.2916 (0.2911)	Acc@1 96.094 (95.715)	Acc@5 100.000 (99.976)
Epoch: [149][192/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.2864 (0.2944)	Acc@1 95.703 (95.661)	Acc@5 100.000 (99.978)
Max memory in training epoch: 55.544064
lr: 0.010000000000000002
1

Epoch: [150 | 150] LR: 0.001000
batch Size 256
Epoch: [150][0/196]	Time 0.172 (0.172)	Data 0.269 (0.269)	Loss 0.2887 (0.2887)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.111 (0.121)	Data 0.000 (0.004)	Loss 0.2535 (0.2646)	Acc@1 97.266 (96.917)	Acc@5 100.000 (100.000)
Epoch: [150][128/196]	Time 0.110 (0.120)	Data 0.000 (0.002)	Loss 0.2004 (0.2554)	Acc@1 99.609 (97.244)	Acc@5 100.000 (99.991)
Epoch: [150][192/196]	Time 0.115 (0.119)	Data 0.000 (0.002)	Loss 0.2711 (0.2521)	Acc@1 97.266 (97.371)	Acc@5 100.000 (99.990)
Max memory in training epoch: 55.544064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  91.94
Max memory: 85.8722304
 23.778s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 979
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.1494016
lr: 0.0010000000000000002
1

Epoch: [151 | 155] LR: 0.001000
batch Size 256
Epoch: [151][0/196]	Time 0.175 (0.175)	Data 0.282 (0.282)	Loss 0.2382 (0.2382)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.107 (0.116)	Data 0.000 (0.005)	Loss 0.2401 (0.2335)	Acc@1 98.438 (97.993)	Acc@5 100.000 (99.988)
Epoch: [151][128/196]	Time 0.113 (0.116)	Data 0.000 (0.002)	Loss 0.2245 (0.2309)	Acc@1 97.656 (98.074)	Acc@5 100.000 (99.988)
Epoch: [151][192/196]	Time 0.108 (0.116)	Data 0.000 (0.002)	Loss 0.2448 (0.2301)	Acc@1 98.047 (98.158)	Acc@5 100.000 (99.988)
Max memory in training epoch: 55.3081344
lr: 0.0010000000000000002
1

Epoch: [152 | 155] LR: 0.001000
batch Size 256
Epoch: [152][0/196]	Time 0.143 (0.143)	Data 0.287 (0.287)	Loss 0.2107 (0.2107)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.114 (0.116)	Data 0.000 (0.005)	Loss 0.2287 (0.2239)	Acc@1 98.438 (98.450)	Acc@5 100.000 (100.000)
Epoch: [152][128/196]	Time 0.119 (0.116)	Data 0.000 (0.002)	Loss 0.1964 (0.2215)	Acc@1 99.609 (98.495)	Acc@5 100.000 (99.997)
Epoch: [152][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.2455 (0.2213)	Acc@1 98.438 (98.527)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [153 | 155] LR: 0.001000
batch Size 256
Epoch: [153][0/196]	Time 0.137 (0.137)	Data 0.288 (0.288)	Loss 0.2072 (0.2072)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.119 (0.116)	Data 0.000 (0.005)	Loss 0.2286 (0.2181)	Acc@1 97.656 (98.546)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.2135 (0.2163)	Acc@1 98.828 (98.622)	Acc@5 100.000 (99.997)
Epoch: [153][192/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.2135 (0.2154)	Acc@1 98.438 (98.713)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [154 | 155] LR: 0.001000
batch Size 256
Epoch: [154][0/196]	Time 0.160 (0.160)	Data 0.309 (0.309)	Loss 0.2012 (0.2012)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.111 (0.117)	Data 0.000 (0.005)	Loss 0.1974 (0.2118)	Acc@1 99.609 (98.864)	Acc@5 100.000 (100.000)
Epoch: [154][128/196]	Time 0.118 (0.117)	Data 0.000 (0.003)	Loss 0.2126 (0.2118)	Acc@1 98.438 (98.798)	Acc@5 100.000 (99.997)
Epoch: [154][192/196]	Time 0.138 (0.117)	Data 0.000 (0.002)	Loss 0.1979 (0.2132)	Acc@1 98.828 (98.780)	Acc@5 100.000 (99.994)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [155 | 155] LR: 0.001000
batch Size 256
Epoch: [155][0/196]	Time 0.150 (0.150)	Data 0.289 (0.289)	Loss 0.2077 (0.2077)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.1983 (0.2094)	Acc@1 99.219 (98.900)	Acc@5 100.000 (99.994)
Epoch: [155][128/196]	Time 0.113 (0.118)	Data 0.000 (0.002)	Loss 0.1985 (0.2099)	Acc@1 99.609 (98.883)	Acc@5 100.000 (99.997)
Epoch: [155][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1959 (0.2105)	Acc@1 99.609 (98.863)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.45
Max memory: 85.8722304
 23.422s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2587
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.1494016
lr: 0.0010000000000000002
1

Epoch: [156 | 160] LR: 0.001000
batch Size 256
Epoch: [156][0/196]	Time 0.198 (0.198)	Data 0.269 (0.269)	Loss 0.2117 (0.2117)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.115 (0.118)	Data 0.000 (0.004)	Loss 0.1949 (0.2067)	Acc@1 99.219 (98.930)	Acc@5 100.000 (100.000)
Epoch: [156][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2253 (0.2077)	Acc@1 98.438 (98.931)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.111 (0.116)	Data 0.000 (0.002)	Loss 0.2094 (0.2075)	Acc@1 98.438 (98.925)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.3081344
lr: 0.0010000000000000002
1

Epoch: [157 | 160] LR: 0.001000
batch Size 256
Epoch: [157][0/196]	Time 0.164 (0.164)	Data 0.301 (0.301)	Loss 0.1926 (0.1926)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.116 (0.117)	Data 0.000 (0.005)	Loss 0.1928 (0.2043)	Acc@1 99.609 (99.075)	Acc@5 100.000 (99.988)
Epoch: [157][128/196]	Time 0.116 (0.117)	Data 0.000 (0.003)	Loss 0.1941 (0.2052)	Acc@1 99.219 (99.025)	Acc@5 100.000 (99.991)
Epoch: [157][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2001 (0.2058)	Acc@1 99.219 (98.972)	Acc@5 100.000 (99.992)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [158 | 160] LR: 0.001000
batch Size 256
Epoch: [158][0/196]	Time 0.166 (0.166)	Data 0.297 (0.297)	Loss 0.2046 (0.2046)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.114 (0.118)	Data 0.000 (0.005)	Loss 0.1914 (0.2024)	Acc@1 99.219 (99.111)	Acc@5 100.000 (99.994)
Epoch: [158][128/196]	Time 0.114 (0.118)	Data 0.000 (0.002)	Loss 0.2245 (0.2032)	Acc@1 97.656 (99.052)	Acc@5 100.000 (99.997)
Epoch: [158][192/196]	Time 0.116 (0.118)	Data 0.000 (0.002)	Loss 0.2063 (0.2025)	Acc@1 98.047 (99.059)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [159 | 160] LR: 0.001000
batch Size 256
Epoch: [159][0/196]	Time 0.141 (0.141)	Data 0.271 (0.271)	Loss 0.1921 (0.1921)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.116 (0.116)	Data 0.000 (0.004)	Loss 0.1955 (0.2021)	Acc@1 99.609 (99.093)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.2101 (0.2007)	Acc@1 98.828 (99.143)	Acc@5 100.000 (100.000)
Epoch: [159][192/196]	Time 0.114 (0.116)	Data 0.000 (0.002)	Loss 0.1953 (0.2011)	Acc@1 99.609 (99.101)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [160 | 160] LR: 0.001000
batch Size 256
Epoch: [160][0/196]	Time 0.158 (0.158)	Data 0.268 (0.268)	Loss 0.1950 (0.1950)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.110 (0.117)	Data 0.000 (0.004)	Loss 0.2274 (0.2008)	Acc@1 97.656 (99.111)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2140 (0.2001)	Acc@1 98.438 (99.152)	Acc@5 100.000 (99.997)
Epoch: [160][192/196]	Time 0.115 (0.117)	Data 0.000 (0.002)	Loss 0.1945 (0.1997)	Acc@1 99.609 (99.150)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.31
Max memory: 85.8722304
 23.321s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7782
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.1494016
lr: 0.0010000000000000002
1

Epoch: [161 | 165] LR: 0.001000
batch Size 256
Epoch: [161][0/196]	Time 0.179 (0.179)	Data 0.296 (0.296)	Loss 0.1845 (0.1845)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.114 (0.117)	Data 0.000 (0.005)	Loss 0.1937 (0.1975)	Acc@1 99.219 (99.171)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.120 (0.116)	Data 0.000 (0.002)	Loss 0.1851 (0.1977)	Acc@1 99.609 (99.173)	Acc@5 100.000 (99.997)
Epoch: [161][192/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.1879 (0.1979)	Acc@1 99.219 (99.174)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.3081344
lr: 0.0010000000000000002
1

Epoch: [162 | 165] LR: 0.001000
batch Size 256
Epoch: [162][0/196]	Time 0.164 (0.164)	Data 0.290 (0.290)	Loss 0.1938 (0.1938)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.115 (0.118)	Data 0.000 (0.005)	Loss 0.1896 (0.1939)	Acc@1 99.609 (99.339)	Acc@5 100.000 (99.994)
Epoch: [162][128/196]	Time 0.121 (0.117)	Data 0.000 (0.002)	Loss 0.2087 (0.1954)	Acc@1 99.219 (99.282)	Acc@5 100.000 (99.997)
Epoch: [162][192/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.1973 (0.1962)	Acc@1 98.438 (99.217)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [163 | 165] LR: 0.001000
batch Size 256
Epoch: [163][0/196]	Time 0.165 (0.165)	Data 0.282 (0.282)	Loss 0.2042 (0.2042)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.108 (0.118)	Data 0.000 (0.005)	Loss 0.1843 (0.1965)	Acc@1 100.000 (99.285)	Acc@5 100.000 (99.994)
Epoch: [163][128/196]	Time 0.122 (0.118)	Data 0.000 (0.002)	Loss 0.1957 (0.1953)	Acc@1 99.609 (99.285)	Acc@5 100.000 (99.997)
Epoch: [163][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.1972 (0.1952)	Acc@1 99.219 (99.269)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [164 | 165] LR: 0.001000
batch Size 256
Epoch: [164][0/196]	Time 0.157 (0.157)	Data 0.323 (0.323)	Loss 0.1937 (0.1937)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.119 (0.119)	Data 0.000 (0.005)	Loss 0.1981 (0.1918)	Acc@1 98.828 (99.387)	Acc@5 100.000 (99.994)
Epoch: [164][128/196]	Time 0.110 (0.118)	Data 0.000 (0.003)	Loss 0.1928 (0.1932)	Acc@1 99.609 (99.319)	Acc@5 100.000 (99.997)
Epoch: [164][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.1874 (0.1934)	Acc@1 99.219 (99.298)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [165 | 165] LR: 0.001000
batch Size 256
Epoch: [165][0/196]	Time 0.168 (0.168)	Data 0.260 (0.260)	Loss 0.1986 (0.1986)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.109 (0.121)	Data 0.000 (0.004)	Loss 0.1997 (0.1916)	Acc@1 98.828 (99.351)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.118 (0.119)	Data 0.000 (0.002)	Loss 0.1935 (0.1923)	Acc@1 99.219 (99.322)	Acc@5 100.000 (99.994)
Epoch: [165][192/196]	Time 0.115 (0.118)	Data 0.000 (0.002)	Loss 0.1877 (0.1920)	Acc@1 99.219 (99.318)	Acc@5 100.000 (99.996)
Max memory in training epoch: 55.544064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.49
Max memory: 85.8722304
 23.549s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6230
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.1494016
lr: 0.0010000000000000002
1

Epoch: [166 | 170] LR: 0.001000
batch Size 256
Epoch: [166][0/196]	Time 0.173 (0.173)	Data 0.281 (0.281)	Loss 0.1927 (0.1927)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.110 (0.118)	Data 0.000 (0.004)	Loss 0.1826 (0.1895)	Acc@1 100.000 (99.441)	Acc@5 100.000 (100.000)
Epoch: [166][128/196]	Time 0.112 (0.117)	Data 0.000 (0.002)	Loss 0.1791 (0.1913)	Acc@1 99.609 (99.340)	Acc@5 100.000 (100.000)
Epoch: [166][192/196]	Time 0.118 (0.117)	Data 0.000 (0.002)	Loss 0.2085 (0.1914)	Acc@1 98.828 (99.354)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.3081344
lr: 0.0010000000000000002
1

Epoch: [167 | 170] LR: 0.001000
batch Size 256
Epoch: [167][0/196]	Time 0.138 (0.138)	Data 0.283 (0.283)	Loss 0.1966 (0.1966)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.111 (0.120)	Data 0.000 (0.005)	Loss 0.2060 (0.1917)	Acc@1 98.828 (99.249)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.120 (0.119)	Data 0.000 (0.002)	Loss 0.1957 (0.1911)	Acc@1 98.828 (99.319)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.119 (0.118)	Data 0.000 (0.002)	Loss 0.1811 (0.1902)	Acc@1 99.219 (99.326)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [168 | 170] LR: 0.001000
batch Size 256
Epoch: [168][0/196]	Time 0.166 (0.166)	Data 0.303 (0.303)	Loss 0.1999 (0.1999)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.114 (0.118)	Data 0.000 (0.005)	Loss 0.2077 (0.1904)	Acc@1 98.828 (99.291)	Acc@5 100.000 (100.000)
Epoch: [168][128/196]	Time 0.123 (0.119)	Data 0.000 (0.003)	Loss 0.1781 (0.1903)	Acc@1 100.000 (99.310)	Acc@5 100.000 (100.000)
Epoch: [168][192/196]	Time 0.120 (0.118)	Data 0.000 (0.002)	Loss 0.1910 (0.1896)	Acc@1 99.219 (99.377)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [169 | 170] LR: 0.001000
batch Size 256
Epoch: [169][0/196]	Time 0.168 (0.168)	Data 0.279 (0.279)	Loss 0.1819 (0.1819)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.113 (0.118)	Data 0.000 (0.004)	Loss 0.1834 (0.1876)	Acc@1 100.000 (99.411)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.117 (0.120)	Data 0.000 (0.002)	Loss 0.1772 (0.1874)	Acc@1 100.000 (99.422)	Acc@5 100.000 (99.997)
Epoch: [169][192/196]	Time 0.114 (0.119)	Data 0.000 (0.002)	Loss 0.1967 (0.1882)	Acc@1 99.219 (99.391)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [170 | 170] LR: 0.001000
batch Size 256
Epoch: [170][0/196]	Time 0.167 (0.167)	Data 0.262 (0.262)	Loss 0.1793 (0.1793)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.120 (0.120)	Data 0.000 (0.004)	Loss 0.1959 (0.1865)	Acc@1 98.828 (99.567)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 0.1958 (0.1860)	Acc@1 99.219 (99.522)	Acc@5 100.000 (100.000)
Epoch: [170][192/196]	Time 0.113 (0.119)	Data 0.000 (0.002)	Loss 0.1731 (0.1866)	Acc@1 100.000 (99.458)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.544064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.62
Max memory: 85.8722304
 23.751s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6149
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.1494016
lr: 0.0010000000000000002
1

Epoch: [171 | 175] LR: 0.001000
batch Size 256
Epoch: [171][0/196]	Time 0.202 (0.202)	Data 0.293 (0.293)	Loss 0.1799 (0.1799)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.126 (0.120)	Data 0.000 (0.005)	Loss 0.1879 (0.1840)	Acc@1 99.609 (99.591)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.126 (0.119)	Data 0.000 (0.002)	Loss 0.1824 (0.1846)	Acc@1 99.219 (99.531)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1890 (0.1854)	Acc@1 99.219 (99.480)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.3081344
lr: 0.0010000000000000002
1

Epoch: [172 | 175] LR: 0.001000
batch Size 256
Epoch: [172][0/196]	Time 0.169 (0.169)	Data 0.286 (0.286)	Loss 0.1768 (0.1768)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.127 (0.122)	Data 0.000 (0.005)	Loss 0.1730 (0.1826)	Acc@1 100.000 (99.621)	Acc@5 100.000 (99.994)
Epoch: [172][128/196]	Time 0.110 (0.121)	Data 0.000 (0.002)	Loss 0.1843 (0.1832)	Acc@1 99.609 (99.552)	Acc@5 100.000 (99.997)
Epoch: [172][192/196]	Time 0.132 (0.121)	Data 0.000 (0.002)	Loss 0.1836 (0.1836)	Acc@1 99.609 (99.545)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [173 | 175] LR: 0.001000
batch Size 256
Epoch: [173][0/196]	Time 0.154 (0.154)	Data 0.289 (0.289)	Loss 0.1889 (0.1889)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.127 (0.120)	Data 0.000 (0.005)	Loss 0.1813 (0.1845)	Acc@1 99.219 (99.453)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.125 (0.120)	Data 0.000 (0.002)	Loss 0.1976 (0.1838)	Acc@1 98.438 (99.479)	Acc@5 100.000 (100.000)
Epoch: [173][192/196]	Time 0.139 (0.120)	Data 0.000 (0.002)	Loss 0.1792 (0.1836)	Acc@1 99.609 (99.510)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [174 | 175] LR: 0.001000
batch Size 256
Epoch: [174][0/196]	Time 0.179 (0.179)	Data 0.279 (0.279)	Loss 0.2022 (0.2022)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.113 (0.121)	Data 0.000 (0.004)	Loss 0.1841 (0.1840)	Acc@1 99.219 (99.477)	Acc@5 100.000 (99.994)
Epoch: [174][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 0.1768 (0.1828)	Acc@1 100.000 (99.519)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.121 (0.120)	Data 0.000 (0.002)	Loss 0.1927 (0.1830)	Acc@1 99.609 (99.520)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [175 | 175] LR: 0.001000
batch Size 256
Epoch: [175][0/196]	Time 0.143 (0.143)	Data 0.337 (0.337)	Loss 0.1783 (0.1783)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.135 (0.122)	Data 0.000 (0.005)	Loss 0.1862 (0.1812)	Acc@1 99.609 (99.537)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.116 (0.121)	Data 0.000 (0.003)	Loss 0.2066 (0.1817)	Acc@1 98.438 (99.522)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.115 (0.120)	Data 0.000 (0.002)	Loss 0.1815 (0.1817)	Acc@1 99.609 (99.532)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.544064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  92.51
Max memory: 85.8722304
 23.979s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2738
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.1494016
lr: 0.0010000000000000002
1

Epoch: [176 | 180] LR: 0.001000
batch Size 256
Epoch: [176][0/196]	Time 0.205 (0.205)	Data 0.256 (0.256)	Loss 0.1797 (0.1797)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.112 (0.118)	Data 0.000 (0.004)	Loss 0.1757 (0.1821)	Acc@1 100.000 (99.507)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.115 (0.116)	Data 0.000 (0.002)	Loss 0.1734 (0.1823)	Acc@1 99.609 (99.503)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.113 (0.117)	Data 0.000 (0.002)	Loss 0.1867 (0.1824)	Acc@1 99.219 (99.484)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.3081344
lr: 0.0010000000000000002
1

Epoch: [177 | 180] LR: 0.001000
batch Size 256
Epoch: [177][0/196]	Time 0.160 (0.160)	Data 0.300 (0.300)	Loss 0.1743 (0.1743)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.118 (0.119)	Data 0.000 (0.005)	Loss 0.1814 (0.1818)	Acc@1 99.609 (99.501)	Acc@5 100.000 (99.994)
Epoch: [177][128/196]	Time 0.119 (0.119)	Data 0.000 (0.003)	Loss 0.1791 (0.1813)	Acc@1 99.609 (99.534)	Acc@5 100.000 (99.997)
Epoch: [177][192/196]	Time 0.119 (0.119)	Data 0.000 (0.002)	Loss 0.1696 (0.1806)	Acc@1 100.000 (99.565)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [178 | 180] LR: 0.001000
batch Size 256
Epoch: [178][0/196]	Time 0.188 (0.188)	Data 0.283 (0.283)	Loss 0.1955 (0.1955)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.122 (0.120)	Data 0.000 (0.005)	Loss 0.1714 (0.1782)	Acc@1 100.000 (99.645)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.124 (0.120)	Data 0.000 (0.002)	Loss 0.1811 (0.1785)	Acc@1 99.219 (99.588)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.111 (0.120)	Data 0.000 (0.002)	Loss 0.1678 (0.1786)	Acc@1 100.000 (99.571)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [179 | 180] LR: 0.001000
batch Size 256
Epoch: [179][0/196]	Time 0.173 (0.173)	Data 0.270 (0.270)	Loss 0.1802 (0.1802)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.1705 (0.1785)	Acc@1 100.000 (99.621)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.127 (0.121)	Data 0.000 (0.002)	Loss 0.1767 (0.1790)	Acc@1 99.609 (99.591)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.113 (0.120)	Data 0.000 (0.002)	Loss 0.1716 (0.1793)	Acc@1 99.609 (99.575)	Acc@5 100.000 (100.000)
Max memory in training epoch: 55.544064
lr: 0.0010000000000000002
1

Epoch: [180 | 180] LR: 0.001000
batch Size 256
Epoch: [180][0/196]	Time 0.174 (0.174)	Data 0.268 (0.268)	Loss 0.1894 (0.1894)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.115 (0.120)	Data 0.000 (0.004)	Loss 0.1684 (0.1786)	Acc@1 99.609 (99.627)	Acc@5 100.000 (99.994)
Epoch: [180][128/196]	Time 0.126 (0.119)	Data 0.000 (0.002)	Loss 0.1823 (0.1792)	Acc@1 99.609 (99.546)	Acc@5 100.000 (99.997)
Epoch: [180][192/196]	Time 0.121 (0.119)	Data 0.000 (0.002)	Loss 0.1733 (0.1788)	Acc@1 100.000 (99.547)	Acc@5 100.000 (99.998)
Max memory in training epoch: 55.544064
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 26, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(63, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 49, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(49, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(49, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(10, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): AdaptiveAvgPool2d(output_size=(1, 1))
    (59): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  92.4
Max memory: 85.8722304
 23.588s  Thres 0.00001 1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7582
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.215 (0.215)	Data 0.307 (0.307)	Loss 3.3711 (3.3711)	Acc@1 9.766 (9.766)	Acc@5 57.031 (57.031)
Epoch: [1][64/196]	Time 0.125 (0.134)	Data 0.000 (0.005)	Loss 2.4282 (2.7307)	Acc@1 32.812 (23.203)	Acc@5 84.375 (76.484)
Epoch: [1][128/196]	Time 0.139 (0.133)	Data 0.000 (0.003)	Loss 2.2281 (2.5495)	Acc@1 37.891 (28.861)	Acc@5 88.672 (82.043)
Epoch: [1][192/196]	Time 0.135 (0.133)	Data 0.000 (0.002)	Loss 2.0353 (2.4302)	Acc@1 49.609 (32.936)	Acc@5 94.531 (84.938)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.186 (0.186)	Data 0.290 (0.290)	Loss 2.0070 (2.0070)	Acc@1 51.953 (51.953)	Acc@5 92.188 (92.188)
Epoch: [2][64/196]	Time 0.131 (0.136)	Data 0.000 (0.005)	Loss 1.8220 (1.9976)	Acc@1 57.422 (48.317)	Acc@5 94.531 (92.782)
Epoch: [2][128/196]	Time 0.136 (0.136)	Data 0.000 (0.002)	Loss 1.8106 (1.9075)	Acc@1 60.156 (51.287)	Acc@5 93.359 (93.505)
Epoch: [2][192/196]	Time 0.139 (0.136)	Data 0.000 (0.002)	Loss 1.6871 (1.8355)	Acc@1 59.766 (53.684)	Acc@5 94.922 (94.226)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.188 (0.188)	Data 0.294 (0.294)	Loss 1.6564 (1.6564)	Acc@1 59.375 (59.375)	Acc@5 96.094 (96.094)
Epoch: [3][64/196]	Time 0.132 (0.138)	Data 0.000 (0.005)	Loss 1.6249 (1.5932)	Acc@1 57.812 (61.178)	Acc@5 95.703 (96.034)
Epoch: [3][128/196]	Time 0.143 (0.137)	Data 0.000 (0.002)	Loss 1.4361 (1.5371)	Acc@1 66.016 (63.066)	Acc@5 96.484 (96.481)
Epoch: [3][192/196]	Time 0.140 (0.137)	Data 0.000 (0.002)	Loss 1.3770 (1.4927)	Acc@1 67.578 (64.425)	Acc@5 98.438 (96.772)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.184 (0.184)	Data 0.324 (0.324)	Loss 1.2459 (1.2459)	Acc@1 74.219 (74.219)	Acc@5 99.219 (99.219)
Epoch: [4][64/196]	Time 0.134 (0.139)	Data 0.000 (0.005)	Loss 1.3032 (1.3332)	Acc@1 67.188 (69.231)	Acc@5 96.484 (97.608)
Epoch: [4][128/196]	Time 0.131 (0.138)	Data 0.000 (0.003)	Loss 1.2212 (1.3020)	Acc@1 72.266 (70.216)	Acc@5 98.828 (97.789)
Epoch: [4][192/196]	Time 0.148 (0.138)	Data 0.000 (0.002)	Loss 1.3189 (1.2717)	Acc@1 67.578 (71.021)	Acc@5 94.531 (97.915)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.161 (0.161)	Data 0.321 (0.321)	Loss 1.1265 (1.1265)	Acc@1 75.000 (75.000)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.139 (0.136)	Data 0.000 (0.005)	Loss 1.1635 (1.1600)	Acc@1 73.047 (73.972)	Acc@5 99.609 (98.209)
Epoch: [5][128/196]	Time 0.140 (0.137)	Data 0.000 (0.003)	Loss 1.2136 (1.1512)	Acc@1 74.219 (74.191)	Acc@5 97.656 (98.168)
Epoch: [5][192/196]	Time 0.144 (0.137)	Data 0.000 (0.002)	Loss 1.1308 (1.1328)	Acc@1 73.438 (74.749)	Acc@5 97.656 (98.251)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  56.07
Max memory: 103.3835008
 27.219s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8878
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9242
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8465
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7689
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6942
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8880
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8246
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2778
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1025
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1366
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3494
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6103
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6281
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4146
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2185
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9694
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3234
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3732
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7808
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6421
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6229
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3807
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1112
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6114
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5437
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5063
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 647
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1766
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4128
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9859
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8618
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1913
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6091
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1471
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5683
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
Thres 0.00001 2
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 92
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.195 (0.195)	Data 0.278 (0.278)	Loss 3.0046 (3.0046)	Acc@1 10.156 (10.156)	Acc@5 48.828 (48.828)
Epoch: [1][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 2.1810 (2.5836)	Acc@1 39.453 (25.883)	Acc@5 92.969 (78.732)
Epoch: [1][128/196]	Time 0.151 (0.130)	Data 0.000 (0.002)	Loss 2.0123 (2.3862)	Acc@1 44.922 (32.740)	Acc@5 93.750 (84.324)
Epoch: [1][192/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.9027 (2.2619)	Acc@1 47.656 (37.358)	Acc@5 93.359 (86.881)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.167 (0.167)	Data 0.275 (0.275)	Loss 1.9107 (1.9107)	Acc@1 50.000 (50.000)	Acc@5 94.531 (94.531)
Epoch: [2][64/196]	Time 0.129 (0.131)	Data 0.000 (0.004)	Loss 1.7954 (1.8273)	Acc@1 53.516 (52.416)	Acc@5 95.312 (94.273)
Epoch: [2][128/196]	Time 0.121 (0.131)	Data 0.000 (0.002)	Loss 1.5130 (1.7498)	Acc@1 63.672 (55.541)	Acc@5 95.703 (94.985)
Epoch: [2][192/196]	Time 0.130 (0.131)	Data 0.000 (0.002)	Loss 1.5839 (1.6874)	Acc@1 58.984 (57.521)	Acc@5 95.703 (95.323)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.174 (0.174)	Data 0.281 (0.281)	Loss 1.4577 (1.4577)	Acc@1 66.797 (66.797)	Acc@5 96.875 (96.875)
Epoch: [3][64/196]	Time 0.128 (0.130)	Data 0.000 (0.005)	Loss 1.3935 (1.4665)	Acc@1 69.922 (64.645)	Acc@5 96.484 (96.947)
Epoch: [3][128/196]	Time 0.133 (0.130)	Data 0.000 (0.002)	Loss 1.3122 (1.4191)	Acc@1 64.453 (66.203)	Acc@5 98.438 (97.141)
Epoch: [3][192/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 1.3078 (1.3788)	Acc@1 69.922 (67.434)	Acc@5 98.047 (97.328)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.177 (0.177)	Data 0.277 (0.277)	Loss 1.2805 (1.2805)	Acc@1 70.703 (70.703)	Acc@5 97.656 (97.656)
Epoch: [4][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 1.1150 (1.2285)	Acc@1 74.219 (71.749)	Acc@5 99.219 (98.179)
Epoch: [4][128/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 1.1324 (1.2102)	Acc@1 74.219 (72.287)	Acc@5 98.438 (98.117)
Epoch: [4][192/196]	Time 0.128 (0.131)	Data 0.000 (0.002)	Loss 1.0578 (1.1876)	Acc@1 76.562 (72.804)	Acc@5 98.828 (98.195)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.182 (0.182)	Data 0.244 (0.244)	Loss 1.0778 (1.0778)	Acc@1 75.781 (75.781)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.133 (0.132)	Data 0.000 (0.004)	Loss 1.0828 (1.0959)	Acc@1 76.562 (75.571)	Acc@5 98.828 (98.570)
Epoch: [5][128/196]	Time 0.155 (0.133)	Data 0.000 (0.002)	Loss 1.0360 (1.0771)	Acc@1 75.000 (75.918)	Acc@5 99.609 (98.565)
Epoch: [5][192/196]	Time 0.137 (0.132)	Data 0.000 (0.001)	Loss 0.9423 (1.0575)	Acc@1 81.250 (76.585)	Acc@5 99.219 (98.543)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
  68.22
Max memory: 103.3835008
 26.262s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4740
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2400
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1054
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5911
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9119
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4570
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2494
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6163
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4703
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9244
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3497
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 985
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6147
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8071
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7665
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8045
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3887
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9237
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2675
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2553
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1493
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1687
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9307
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5924
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3871
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4278
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3568
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 860
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4856
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7166
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9757
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5753
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4288
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5152
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1217
Files already downloaded and verified
==> Resuming from checkpoint..
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 330, in main
    args.lr = checkpoint['lr']
KeyError: 'lr'
Thres 0.00001 3
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4798
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.201 (0.201)	Data 0.275 (0.275)	Loss 3.2133 (3.2133)	Acc@1 12.109 (12.109)	Acc@5 46.094 (46.094)
Epoch: [1][64/196]	Time 0.143 (0.129)	Data 0.000 (0.004)	Loss 2.3144 (2.6491)	Acc@1 30.469 (24.387)	Acc@5 87.891 (79.231)
Epoch: [1][128/196]	Time 0.128 (0.129)	Data 0.000 (0.002)	Loss 2.2408 (2.4748)	Acc@1 39.453 (29.812)	Acc@5 89.844 (83.927)
Epoch: [1][192/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 2.0566 (2.3641)	Acc@1 44.531 (33.701)	Acc@5 92.969 (86.261)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.182 (0.182)	Data 0.244 (0.244)	Loss 2.0772 (2.0772)	Acc@1 43.750 (43.750)	Acc@5 92.188 (92.188)
Epoch: [2][64/196]	Time 0.139 (0.131)	Data 0.000 (0.004)	Loss 2.0192 (1.9960)	Acc@1 48.047 (46.244)	Acc@5 92.969 (92.608)
Epoch: [2][128/196]	Time 0.128 (0.130)	Data 0.000 (0.002)	Loss 1.8624 (1.9287)	Acc@1 48.047 (48.665)	Acc@5 93.359 (93.181)
Epoch: [2][192/196]	Time 0.128 (0.131)	Data 0.000 (0.001)	Loss 1.6900 (1.8622)	Acc@1 58.594 (51.231)	Acc@5 93.750 (93.813)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.161 (0.161)	Data 0.252 (0.252)	Loss 1.6443 (1.6443)	Acc@1 53.516 (53.516)	Acc@5 96.875 (96.875)
Epoch: [3][64/196]	Time 0.148 (0.135)	Data 0.000 (0.004)	Loss 1.5746 (1.6190)	Acc@1 59.766 (59.513)	Acc@5 94.531 (95.962)
Epoch: [3][128/196]	Time 0.130 (0.133)	Data 0.000 (0.002)	Loss 1.3613 (1.5738)	Acc@1 70.703 (60.950)	Acc@5 97.656 (96.224)
Epoch: [3][192/196]	Time 0.135 (0.133)	Data 0.000 (0.001)	Loss 1.5016 (1.5351)	Acc@1 63.672 (62.217)	Acc@5 97.266 (96.359)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.185 (0.185)	Data 0.280 (0.280)	Loss 1.3153 (1.3153)	Acc@1 69.922 (69.922)	Acc@5 98.047 (98.047)
Epoch: [4][64/196]	Time 0.126 (0.134)	Data 0.000 (0.004)	Loss 1.4211 (1.3682)	Acc@1 67.188 (67.254)	Acc@5 96.484 (97.356)
Epoch: [4][128/196]	Time 0.132 (0.133)	Data 0.000 (0.002)	Loss 1.5258 (1.3421)	Acc@1 62.891 (68.020)	Acc@5 96.875 (97.508)
Epoch: [4][192/196]	Time 0.136 (0.133)	Data 0.000 (0.002)	Loss 1.2735 (1.3126)	Acc@1 68.750 (68.772)	Acc@5 96.484 (97.624)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.174 (0.174)	Data 0.265 (0.265)	Loss 1.2075 (1.2075)	Acc@1 69.922 (69.922)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.153 (0.135)	Data 0.000 (0.004)	Loss 1.1550 (1.1843)	Acc@1 73.828 (72.482)	Acc@5 96.875 (98.185)
Epoch: [5][128/196]	Time 0.131 (0.135)	Data 0.000 (0.002)	Loss 1.1164 (1.1611)	Acc@1 73.828 (72.959)	Acc@5 98.438 (98.286)
Epoch: [5][192/196]	Time 0.150 (0.135)	Data 0.000 (0.002)	Loss 1.1157 (1.1410)	Acc@1 73.047 (73.533)	Acc@5 98.047 (98.318)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 620, in main
    torch.save(model, args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 525
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5897
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7689
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1571
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6673
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5364
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8462
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8743
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8525
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1463
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8522
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1086
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1717
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4067
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2010
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8535
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6927
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 201
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 445
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3933
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2845
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3669
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6309
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6889
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5429
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4775
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8841
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5307
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6836
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6540
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5576
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 648
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5560
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7813
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1646
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_3/model.nn'
Thres 0.00001 4
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3940
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.220 (0.220)	Data 0.272 (0.272)	Loss 3.3027 (3.3027)	Acc@1 13.672 (13.672)	Acc@5 50.000 (50.000)
Epoch: [1][64/196]	Time 0.126 (0.131)	Data 0.000 (0.004)	Loss 2.5066 (2.7204)	Acc@1 28.125 (22.043)	Acc@5 85.156 (76.743)
Epoch: [1][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 2.1864 (2.5544)	Acc@1 37.500 (27.304)	Acc@5 91.016 (81.762)
Epoch: [1][192/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 2.0188 (2.4300)	Acc@1 46.875 (31.867)	Acc@5 91.406 (84.590)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.183 (0.183)	Data 0.278 (0.278)	Loss 2.1569 (2.1569)	Acc@1 40.625 (40.625)	Acc@5 90.625 (90.625)
Epoch: [2][64/196]	Time 0.124 (0.130)	Data 0.000 (0.004)	Loss 1.8051 (1.9738)	Acc@1 55.859 (47.903)	Acc@5 95.703 (92.921)
Epoch: [2][128/196]	Time 0.126 (0.129)	Data 0.000 (0.002)	Loss 1.8475 (1.9004)	Acc@1 53.125 (50.699)	Acc@5 94.922 (93.759)
Epoch: [2][192/196]	Time 0.123 (0.129)	Data 0.000 (0.002)	Loss 1.4583 (1.8244)	Acc@1 64.453 (53.412)	Acc@5 97.266 (94.466)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.148 (0.148)	Data 0.287 (0.287)	Loss 1.6341 (1.6341)	Acc@1 59.375 (59.375)	Acc@5 97.266 (97.266)
Epoch: [3][64/196]	Time 0.134 (0.131)	Data 0.000 (0.005)	Loss 1.5401 (1.5477)	Acc@1 62.500 (62.452)	Acc@5 96.484 (96.514)
Epoch: [3][128/196]	Time 0.127 (0.130)	Data 0.000 (0.002)	Loss 1.3558 (1.5093)	Acc@1 68.750 (63.636)	Acc@5 98.047 (96.733)
Epoch: [3][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 1.3641 (1.4699)	Acc@1 66.406 (64.913)	Acc@5 97.656 (96.966)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.181 (0.181)	Data 0.286 (0.286)	Loss 1.3032 (1.3032)	Acc@1 69.922 (69.922)	Acc@5 98.828 (98.828)
Epoch: [4][64/196]	Time 0.131 (0.128)	Data 0.000 (0.005)	Loss 1.2045 (1.3273)	Acc@1 67.578 (68.666)	Acc@5 98.828 (97.728)
Epoch: [4][128/196]	Time 0.133 (0.129)	Data 0.000 (0.002)	Loss 1.3248 (1.2961)	Acc@1 67.188 (69.755)	Acc@5 98.828 (97.789)
Epoch: [4][192/196]	Time 0.134 (0.130)	Data 0.000 (0.002)	Loss 1.3011 (1.2666)	Acc@1 72.266 (70.764)	Acc@5 97.656 (97.857)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.175 (0.175)	Data 0.280 (0.280)	Loss 1.2293 (1.2293)	Acc@1 69.141 (69.141)	Acc@5 98.828 (98.828)
Epoch: [5][64/196]	Time 0.128 (0.132)	Data 0.000 (0.005)	Loss 1.0534 (1.1611)	Acc@1 75.391 (73.954)	Acc@5 99.609 (98.317)
Epoch: [5][128/196]	Time 0.130 (0.132)	Data 0.000 (0.002)	Loss 1.1128 (1.1381)	Acc@1 76.953 (74.358)	Acc@5 97.266 (98.325)
Epoch: [5][192/196]	Time 0.128 (0.132)	Data 0.000 (0.002)	Loss 1.0714 (1.1229)	Acc@1 75.391 (74.640)	Acc@5 99.219 (98.350)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 620, in main
    torch.save(model, args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8772
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2696
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1610
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7496
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 441
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3658
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1519
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6395
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5023
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5347
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4778
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4091
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6086
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 348
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2645
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8708
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1943
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9731
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7647
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6060
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2766
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5681
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 714
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3301
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2511
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1073
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9763
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3054
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5008
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1559
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2375
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8809
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 989
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6687
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3401
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_4/model.nn'
Thres 0.00001 5
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 731
Files already downloaded and verified
numoFStages: 3
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
lr: 0.1
1

Epoch: [1 | 5] LR: 0.100000
batch Size 256
Epoch: [1][0/196]	Time 0.226 (0.226)	Data 0.249 (0.249)	Loss 3.3190 (3.3190)	Acc@1 9.375 (9.375)	Acc@5 45.703 (45.703)
Epoch: [1][64/196]	Time 0.130 (0.133)	Data 0.000 (0.004)	Loss 2.3711 (2.6274)	Acc@1 30.859 (25.595)	Acc@5 90.234 (78.678)
Epoch: [1][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 2.1880 (2.4659)	Acc@1 39.844 (30.996)	Acc@5 89.062 (83.576)
Epoch: [1][192/196]	Time 0.128 (0.130)	Data 0.000 (0.001)	Loss 1.9747 (2.3441)	Acc@1 53.516 (35.399)	Acc@5 90.625 (86.429)
Max memory in training epoch: 66.646784
lr: 0.1
1

Epoch: [2 | 5] LR: 0.100000
batch Size 256
Epoch: [2][0/196]	Time 0.184 (0.184)	Data 0.286 (0.286)	Loss 2.0020 (2.0020)	Acc@1 51.172 (51.172)	Acc@5 90.625 (90.625)
Epoch: [2][64/196]	Time 0.132 (0.132)	Data 0.000 (0.005)	Loss 1.7501 (1.9068)	Acc@1 57.031 (51.358)	Acc@5 96.094 (94.105)
Epoch: [2][128/196]	Time 0.125 (0.131)	Data 0.000 (0.002)	Loss 1.7043 (1.8288)	Acc@1 58.203 (54.218)	Acc@5 94.922 (94.628)
Epoch: [2][192/196]	Time 0.126 (0.130)	Data 0.000 (0.002)	Loss 1.5663 (1.7698)	Acc@1 64.062 (55.993)	Acc@5 93.750 (95.019)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [3 | 5] LR: 0.100000
batch Size 256
Epoch: [3][0/196]	Time 0.179 (0.179)	Data 0.251 (0.251)	Loss 1.5829 (1.5829)	Acc@1 62.109 (62.109)	Acc@5 95.703 (95.703)
Epoch: [3][64/196]	Time 0.131 (0.132)	Data 0.000 (0.004)	Loss 1.5575 (1.5384)	Acc@1 58.203 (63.444)	Acc@5 97.266 (96.683)
Epoch: [3][128/196]	Time 0.147 (0.130)	Data 0.000 (0.002)	Loss 1.3644 (1.5006)	Acc@1 67.578 (64.556)	Acc@5 97.656 (96.908)
Epoch: [3][192/196]	Time 0.127 (0.130)	Data 0.000 (0.001)	Loss 1.3127 (1.4618)	Acc@1 68.359 (65.631)	Acc@5 98.828 (97.090)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [4 | 5] LR: 0.100000
batch Size 256
Epoch: [4][0/196]	Time 0.180 (0.180)	Data 0.279 (0.279)	Loss 1.3198 (1.3198)	Acc@1 69.922 (69.922)	Acc@5 97.266 (97.266)
Epoch: [4][64/196]	Time 0.126 (0.130)	Data 0.000 (0.004)	Loss 1.3664 (1.2982)	Acc@1 65.234 (70.306)	Acc@5 97.266 (97.921)
Epoch: [4][128/196]	Time 0.137 (0.130)	Data 0.000 (0.002)	Loss 1.2226 (1.2711)	Acc@1 75.000 (71.194)	Acc@5 96.094 (97.920)
Epoch: [4][192/196]	Time 0.131 (0.131)	Data 0.000 (0.002)	Loss 1.3035 (1.2523)	Acc@1 64.453 (71.638)	Acc@5 98.438 (97.966)
Max memory in training epoch: 66.5419264
lr: 0.1
1

Epoch: [5 | 5] LR: 0.100000
batch Size 256
Epoch: [5][0/196]	Time 0.166 (0.166)	Data 0.286 (0.286)	Loss 1.2547 (1.2547)	Acc@1 71.875 (71.875)	Acc@5 98.047 (98.047)
Epoch: [5][64/196]	Time 0.136 (0.135)	Data 0.000 (0.005)	Loss 1.0771 (1.1432)	Acc@1 77.344 (74.724)	Acc@5 99.609 (98.413)
Epoch: [5][128/196]	Time 0.132 (0.135)	Data 0.000 (0.002)	Loss 1.1038 (1.1325)	Acc@1 76.953 (74.812)	Acc@5 97.656 (98.371)
Epoch: [5][192/196]	Time 0.138 (0.135)	Data 0.000 (0.002)	Loss 1.1639 (1.1151)	Acc@1 74.219 (75.182)	Acc@5 98.047 (98.444)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
[INFO] Storing checkpoint...
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 620, in main
    torch.save(model, args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8818
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6231
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4707
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5193
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9387
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2927
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1021
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9225
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1761
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 324
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9933
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 385
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2732
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4969
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6164
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3257
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3456
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8790
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 1834
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3709
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8414
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8569
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 8391
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 43
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9340
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7378
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4254
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 9440
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 4174
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 989
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 6204
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 3789
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 7911
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 2712
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
random number: 5499
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 941, in <module>
    main()
  File "main.py", line 317, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_5/model.nn'
