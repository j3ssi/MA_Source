Net2Net 1
j: 1 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 9185
Files already downloaded and verified
width: 8

Arch Num:  [[2, 2, 2, 2, 2], [3, 2, 2, 2, 2], [3, 2, 2, 2, 2]]
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=32, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.0573952
lr: 0.1
lr: 0.1
1
Epoche:1/5; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.155 (0.155)	Data 0.264 (0.264)	Loss 2.9887 (2.9887)	Acc@1 10.938 (10.938)	Acc@5 46.875 (46.875)
Epoch: [1][64/196]	Time 0.083 (0.090)	Data 0.000 (0.004)	Loss 1.8264 (2.1158)	Acc@1 26.953 (20.956)	Acc@5 86.328 (72.879)
Epoch: [1][128/196]	Time 0.093 (0.088)	Data 0.000 (0.002)	Loss 1.7285 (1.9443)	Acc@1 32.812 (26.590)	Acc@5 87.891 (79.463)
Epoch: [1][192/196]	Time 0.087 (0.087)	Data 0.000 (0.002)	Loss 1.5865 (1.8506)	Acc@1 38.281 (29.758)	Acc@5 91.406 (82.479)
Max memory in training epoch: 33.3018624
lr: 0.1
lr: 0.1
1
Epoche:2/5; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.129 (0.129)	Data 0.316 (0.316)	Loss 1.7251 (1.7251)	Acc@1 38.281 (38.281)	Acc@5 88.281 (88.281)
Epoch: [2][64/196]	Time 0.084 (0.089)	Data 0.000 (0.005)	Loss 1.5001 (1.5134)	Acc@1 45.703 (44.597)	Acc@5 91.406 (91.286)
Epoch: [2][128/196]	Time 0.088 (0.087)	Data 0.000 (0.003)	Loss 1.2255 (1.4533)	Acc@1 55.859 (46.678)	Acc@5 93.750 (92.097)
Epoch: [2][192/196]	Time 0.083 (0.087)	Data 0.000 (0.002)	Loss 1.2678 (1.4016)	Acc@1 56.250 (48.731)	Acc@5 95.312 (92.742)
Max memory in training epoch: 33.3018624
lr: 0.1
lr: 0.1
1
Epoche:3/5; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.125 (0.125)	Data 0.287 (0.287)	Loss 1.2304 (1.2304)	Acc@1 58.984 (58.984)	Acc@5 94.531 (94.531)
Epoch: [3][64/196]	Time 0.084 (0.087)	Data 0.000 (0.005)	Loss 1.1893 (1.1608)	Acc@1 57.812 (58.588)	Acc@5 94.141 (95.343)
Epoch: [3][128/196]	Time 0.091 (0.087)	Data 0.000 (0.002)	Loss 1.0709 (1.1335)	Acc@1 61.719 (59.557)	Acc@5 94.922 (95.673)
Epoch: [3][192/196]	Time 0.082 (0.087)	Data 0.000 (0.002)	Loss 0.9114 (1.0947)	Acc@1 66.016 (60.933)	Acc@5 97.656 (95.999)
Max memory in training epoch: 33.3018624
lr: 0.1
lr: 0.1
1
Epoche:4/5; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.118 (0.118)	Data 0.296 (0.296)	Loss 0.8649 (0.8649)	Acc@1 67.188 (67.188)	Acc@5 97.656 (97.656)
Epoch: [4][64/196]	Time 0.084 (0.088)	Data 0.000 (0.005)	Loss 0.8198 (0.9691)	Acc@1 69.922 (65.264)	Acc@5 97.656 (96.839)
Epoch: [4][128/196]	Time 0.087 (0.087)	Data 0.000 (0.003)	Loss 0.8058 (0.9468)	Acc@1 72.656 (66.476)	Acc@5 96.875 (97.093)
Epoch: [4][192/196]	Time 0.086 (0.087)	Data 0.000 (0.002)	Loss 0.8462 (0.9243)	Acc@1 71.875 (67.202)	Acc@5 98.828 (97.298)
Max memory in training epoch: 33.3018624
lr: 0.1
lr: 0.1
1
Epoche:5/5; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.133 (0.133)	Data 0.289 (0.289)	Loss 0.8542 (0.8542)	Acc@1 71.875 (71.875)	Acc@5 97.656 (97.656)
Epoch: [5][64/196]	Time 0.084 (0.088)	Data 0.000 (0.005)	Loss 0.7272 (0.8463)	Acc@1 75.000 (70.463)	Acc@5 98.438 (97.861)
Epoch: [5][128/196]	Time 0.090 (0.087)	Data 0.000 (0.002)	Loss 0.8680 (0.8275)	Acc@1 73.047 (71.030)	Acc@5 96.094 (97.902)
Epoch: [5][192/196]	Time 0.089 (0.087)	Data 0.000 (0.002)	Loss 0.8057 (0.8204)	Acc@1 70.312 (71.256)	Acc@5 98.828 (97.905)
Max memory in training epoch: 33.3018624
[INFO] Storing checkpoint...
  67.49
Max memory: 51.3858048
 17.381s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 1918
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:6/10; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 0.164 (0.164)	Data 0.269 (0.269)	Loss 0.8159 (0.8159)	Acc@1 73.438 (73.438)	Acc@5 97.266 (97.266)
Epoch: [6][64/196]	Time 0.084 (0.089)	Data 0.000 (0.004)	Loss 0.7485 (0.7447)	Acc@1 75.000 (74.105)	Acc@5 98.047 (98.251)
Epoch: [6][128/196]	Time 0.087 (0.089)	Data 0.000 (0.002)	Loss 0.6995 (0.7378)	Acc@1 77.734 (74.252)	Acc@5 98.828 (98.307)
Epoch: [6][192/196]	Time 0.088 (0.088)	Data 0.000 (0.002)	Loss 0.7106 (0.7388)	Acc@1 76.172 (74.095)	Acc@5 99.219 (98.288)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:7/10; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 0.118 (0.118)	Data 0.313 (0.313)	Loss 0.7106 (0.7106)	Acc@1 76.562 (76.562)	Acc@5 96.875 (96.875)
Epoch: [7][64/196]	Time 0.082 (0.088)	Data 0.000 (0.005)	Loss 0.5996 (0.7137)	Acc@1 81.641 (74.916)	Acc@5 98.828 (98.263)
Epoch: [7][128/196]	Time 0.083 (0.088)	Data 0.000 (0.003)	Loss 0.7000 (0.7029)	Acc@1 76.172 (75.433)	Acc@5 99.219 (98.413)
Epoch: [7][192/196]	Time 0.084 (0.088)	Data 0.000 (0.002)	Loss 0.6358 (0.7009)	Acc@1 76.172 (75.480)	Acc@5 99.609 (98.464)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:8/10; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 0.137 (0.137)	Data 0.271 (0.271)	Loss 0.7184 (0.7184)	Acc@1 72.656 (72.656)	Acc@5 98.828 (98.828)
Epoch: [8][64/196]	Time 0.085 (0.090)	Data 0.000 (0.004)	Loss 0.6303 (0.6496)	Acc@1 80.078 (77.434)	Acc@5 97.266 (98.738)
Epoch: [8][128/196]	Time 0.090 (0.089)	Data 0.000 (0.002)	Loss 0.6514 (0.6564)	Acc@1 76.562 (77.171)	Acc@5 99.219 (98.707)
Epoch: [8][192/196]	Time 0.084 (0.088)	Data 0.000 (0.002)	Loss 0.6023 (0.6592)	Acc@1 78.906 (76.965)	Acc@5 99.219 (98.674)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:9/10; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 0.148 (0.148)	Data 0.272 (0.272)	Loss 0.6688 (0.6688)	Acc@1 77.734 (77.734)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.085 (0.090)	Data 0.000 (0.004)	Loss 0.6694 (0.6551)	Acc@1 76.562 (77.542)	Acc@5 99.609 (98.606)
Epoch: [9][128/196]	Time 0.084 (0.089)	Data 0.000 (0.002)	Loss 0.7007 (0.6496)	Acc@1 76.562 (77.659)	Acc@5 99.609 (98.683)
Epoch: [9][192/196]	Time 0.083 (0.088)	Data 0.000 (0.002)	Loss 0.5185 (0.6441)	Acc@1 83.203 (77.827)	Acc@5 99.219 (98.676)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:10/10; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 0.115 (0.115)	Data 0.294 (0.294)	Loss 0.6595 (0.6595)	Acc@1 80.469 (80.469)	Acc@5 98.828 (98.828)
Epoch: [10][64/196]	Time 0.091 (0.090)	Data 0.000 (0.005)	Loss 0.5645 (0.6323)	Acc@1 80.859 (78.401)	Acc@5 100.000 (98.774)
Epoch: [10][128/196]	Time 0.090 (0.089)	Data 0.000 (0.002)	Loss 0.6405 (0.6212)	Acc@1 75.391 (78.464)	Acc@5 98.828 (98.792)
Epoch: [10][192/196]	Time 0.085 (0.089)	Data 0.000 (0.002)	Loss 0.4582 (0.6195)	Acc@1 84.375 (78.479)	Acc@5 100.000 (98.776)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  74.53
Max memory: 51.4381312
 17.746s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6365
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:11/15; Lr: 0.1
batch Size 256
Epoch: [11][0/196]	Time 0.152 (0.152)	Data 0.295 (0.295)	Loss 0.6444 (0.6444)	Acc@1 74.219 (74.219)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 0.081 (0.089)	Data 0.000 (0.005)	Loss 0.5705 (0.5937)	Acc@1 82.422 (79.519)	Acc@5 98.828 (98.948)
Epoch: [11][128/196]	Time 0.093 (0.088)	Data 0.000 (0.002)	Loss 0.6857 (0.5967)	Acc@1 73.828 (79.394)	Acc@5 98.828 (98.916)
Epoch: [11][192/196]	Time 0.081 (0.087)	Data 0.000 (0.002)	Loss 0.6594 (0.5945)	Acc@1 82.031 (79.602)	Acc@5 98.438 (98.913)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:12/15; Lr: 0.1
batch Size 256
Epoch: [12][0/196]	Time 0.107 (0.107)	Data 0.299 (0.299)	Loss 0.5424 (0.5424)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.085 (0.088)	Data 0.000 (0.005)	Loss 0.7155 (0.5996)	Acc@1 75.000 (79.099)	Acc@5 98.047 (99.069)
Epoch: [12][128/196]	Time 0.083 (0.087)	Data 0.000 (0.003)	Loss 0.4866 (0.5960)	Acc@1 83.984 (79.473)	Acc@5 98.828 (98.931)
Epoch: [12][192/196]	Time 0.083 (0.087)	Data 0.000 (0.002)	Loss 0.5963 (0.5911)	Acc@1 78.125 (79.534)	Acc@5 99.219 (98.895)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:13/15; Lr: 0.1
batch Size 256
Epoch: [13][0/196]	Time 0.137 (0.137)	Data 0.266 (0.266)	Loss 0.4851 (0.4851)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.083 (0.088)	Data 0.000 (0.004)	Loss 0.6315 (0.5596)	Acc@1 78.906 (80.571)	Acc@5 98.438 (99.050)
Epoch: [13][128/196]	Time 0.094 (0.088)	Data 0.000 (0.002)	Loss 0.6817 (0.5656)	Acc@1 74.609 (80.351)	Acc@5 99.609 (98.986)
Epoch: [13][192/196]	Time 0.085 (0.087)	Data 0.000 (0.002)	Loss 0.6822 (0.5647)	Acc@1 78.125 (80.418)	Acc@5 98.438 (99.010)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:14/15; Lr: 0.1
batch Size 256
Epoch: [14][0/196]	Time 0.128 (0.128)	Data 0.312 (0.312)	Loss 0.6104 (0.6104)	Acc@1 82.031 (82.031)	Acc@5 98.047 (98.047)
Epoch: [14][64/196]	Time 0.086 (0.088)	Data 0.000 (0.005)	Loss 0.5461 (0.5723)	Acc@1 79.688 (80.270)	Acc@5 99.609 (98.948)
Epoch: [14][128/196]	Time 0.085 (0.088)	Data 0.000 (0.003)	Loss 0.6062 (0.5640)	Acc@1 77.344 (80.587)	Acc@5 98.047 (98.952)
Epoch: [14][192/196]	Time 0.085 (0.087)	Data 0.000 (0.002)	Loss 0.5387 (0.5596)	Acc@1 80.078 (80.706)	Acc@5 98.828 (98.974)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:15/15; Lr: 0.1
batch Size 256
Epoch: [15][0/196]	Time 0.117 (0.117)	Data 0.271 (0.271)	Loss 0.5668 (0.5668)	Acc@1 79.297 (79.297)	Acc@5 98.828 (98.828)
Epoch: [15][64/196]	Time 0.095 (0.089)	Data 0.000 (0.004)	Loss 0.4566 (0.5281)	Acc@1 84.766 (81.562)	Acc@5 98.828 (99.062)
Epoch: [15][128/196]	Time 0.080 (0.088)	Data 0.000 (0.002)	Loss 0.5819 (0.5396)	Acc@1 76.562 (81.301)	Acc@5 99.609 (99.073)
Epoch: [15][192/196]	Time 0.082 (0.087)	Data 0.000 (0.002)	Loss 0.6114 (0.5436)	Acc@1 79.688 (81.212)	Acc@5 98.438 (99.033)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  74.12
Max memory: 51.4381312
 17.469s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2987
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:16/20; Lr: 0.1
batch Size 256
Epoch: [16][0/196]	Time 0.154 (0.154)	Data 0.254 (0.254)	Loss 0.5267 (0.5267)	Acc@1 80.469 (80.469)	Acc@5 99.609 (99.609)
Epoch: [16][64/196]	Time 0.082 (0.088)	Data 0.000 (0.004)	Loss 0.4979 (0.5201)	Acc@1 86.328 (82.019)	Acc@5 99.219 (99.129)
Epoch: [16][128/196]	Time 0.084 (0.087)	Data 0.000 (0.002)	Loss 0.5899 (0.5323)	Acc@1 76.172 (81.589)	Acc@5 98.438 (99.095)
Epoch: [16][192/196]	Time 0.086 (0.088)	Data 0.000 (0.001)	Loss 0.5784 (0.5395)	Acc@1 80.859 (81.458)	Acc@5 98.047 (99.063)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:17/20; Lr: 0.1
batch Size 256
Epoch: [17][0/196]	Time 0.121 (0.121)	Data 0.295 (0.295)	Loss 0.5940 (0.5940)	Acc@1 79.688 (79.688)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.091 (0.089)	Data 0.000 (0.005)	Loss 0.5401 (0.5339)	Acc@1 79.297 (81.526)	Acc@5 99.609 (99.062)
Epoch: [17][128/196]	Time 0.087 (0.088)	Data 0.000 (0.003)	Loss 0.4768 (0.5355)	Acc@1 83.594 (81.504)	Acc@5 98.828 (99.076)
Epoch: [17][192/196]	Time 0.084 (0.088)	Data 0.000 (0.002)	Loss 0.5335 (0.5388)	Acc@1 80.859 (81.341)	Acc@5 100.000 (99.085)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:18/20; Lr: 0.1
batch Size 256
Epoch: [18][0/196]	Time 0.134 (0.134)	Data 0.290 (0.290)	Loss 0.5461 (0.5461)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.093 (0.091)	Data 0.000 (0.005)	Loss 0.5358 (0.5303)	Acc@1 83.203 (81.977)	Acc@5 98.438 (99.117)
Epoch: [18][128/196]	Time 0.082 (0.090)	Data 0.000 (0.003)	Loss 0.5173 (0.5270)	Acc@1 82.031 (81.859)	Acc@5 99.219 (99.137)
Epoch: [18][192/196]	Time 0.089 (0.089)	Data 0.000 (0.002)	Loss 0.5814 (0.5248)	Acc@1 78.906 (81.914)	Acc@5 98.828 (99.124)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:19/20; Lr: 0.1
batch Size 256
Epoch: [19][0/196]	Time 0.141 (0.141)	Data 0.298 (0.298)	Loss 0.5078 (0.5078)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.083 (0.090)	Data 0.000 (0.005)	Loss 0.4725 (0.5246)	Acc@1 84.766 (81.881)	Acc@5 99.609 (99.135)
Epoch: [19][128/196]	Time 0.084 (0.088)	Data 0.000 (0.003)	Loss 0.5454 (0.5211)	Acc@1 83.203 (82.074)	Acc@5 98.828 (99.104)
Epoch: [19][192/196]	Time 0.081 (0.088)	Data 0.000 (0.002)	Loss 0.5077 (0.5253)	Acc@1 85.156 (81.843)	Acc@5 98.047 (99.077)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:20/20; Lr: 0.1
batch Size 256
Epoch: [20][0/196]	Time 0.126 (0.126)	Data 0.298 (0.298)	Loss 0.4209 (0.4209)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [20][64/196]	Time 0.092 (0.089)	Data 0.000 (0.005)	Loss 0.4975 (0.5106)	Acc@1 82.812 (82.320)	Acc@5 99.219 (99.183)
Epoch: [20][128/196]	Time 0.086 (0.088)	Data 0.000 (0.003)	Loss 0.4975 (0.5120)	Acc@1 83.203 (82.404)	Acc@5 98.438 (99.161)
Epoch: [20][192/196]	Time 0.087 (0.088)	Data 0.000 (0.002)	Loss 0.5492 (0.5115)	Acc@1 81.641 (82.404)	Acc@5 98.438 (99.166)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  76.67
Max memory: 51.4381312
 17.587s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 4526
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:21/25; Lr: 0.1
batch Size 256
Epoch: [21][0/196]	Time 0.166 (0.166)	Data 0.353 (0.353)	Loss 0.4870 (0.4870)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [21][64/196]	Time 0.088 (0.098)	Data 0.000 (0.006)	Loss 0.5546 (0.4864)	Acc@1 80.469 (83.161)	Acc@5 98.828 (99.231)
Epoch: [21][128/196]	Time 0.096 (0.097)	Data 0.000 (0.003)	Loss 0.5537 (0.4959)	Acc@1 82.031 (82.894)	Acc@5 98.828 (99.188)
Epoch: [21][192/196]	Time 0.109 (0.097)	Data 0.000 (0.002)	Loss 0.5161 (0.5036)	Acc@1 80.469 (82.594)	Acc@5 98.047 (99.203)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:22/25; Lr: 0.1
batch Size 256
Epoch: [22][0/196]	Time 0.172 (0.172)	Data 0.352 (0.352)	Loss 0.5559 (0.5559)	Acc@1 78.516 (78.516)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 0.098 (0.098)	Data 0.000 (0.006)	Loss 0.5988 (0.5129)	Acc@1 79.297 (81.989)	Acc@5 99.609 (99.237)
Epoch: [22][128/196]	Time 0.114 (0.097)	Data 0.000 (0.003)	Loss 0.4789 (0.5074)	Acc@1 82.812 (82.340)	Acc@5 99.609 (99.170)
Epoch: [22][192/196]	Time 0.092 (0.095)	Data 0.000 (0.002)	Loss 0.5228 (0.5028)	Acc@1 82.812 (82.477)	Acc@5 98.828 (99.219)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:23/25; Lr: 0.1
batch Size 256
Epoch: [23][0/196]	Time 0.139 (0.139)	Data 0.284 (0.284)	Loss 0.5528 (0.5528)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.110 (0.093)	Data 0.000 (0.005)	Loss 0.5640 (0.4966)	Acc@1 79.297 (82.812)	Acc@5 99.219 (99.267)
Epoch: [23][128/196]	Time 0.093 (0.095)	Data 0.000 (0.002)	Loss 0.4589 (0.4961)	Acc@1 84.375 (82.876)	Acc@5 100.000 (99.237)
Epoch: [23][192/196]	Time 0.089 (0.094)	Data 0.000 (0.002)	Loss 0.5197 (0.4969)	Acc@1 80.078 (82.853)	Acc@5 99.219 (99.251)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:24/25; Lr: 0.1
batch Size 256
Epoch: [24][0/196]	Time 0.148 (0.148)	Data 0.294 (0.294)	Loss 0.4971 (0.4971)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [24][64/196]	Time 0.104 (0.102)	Data 0.000 (0.005)	Loss 0.4593 (0.4958)	Acc@1 84.766 (82.975)	Acc@5 100.000 (99.285)
Epoch: [24][128/196]	Time 0.091 (0.100)	Data 0.000 (0.003)	Loss 0.4793 (0.4861)	Acc@1 84.375 (83.218)	Acc@5 99.219 (99.310)
Epoch: [24][192/196]	Time 0.102 (0.099)	Data 0.000 (0.002)	Loss 0.5453 (0.4904)	Acc@1 80.078 (82.995)	Acc@5 98.438 (99.288)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:25/25; Lr: 0.1
batch Size 256
Epoch: [25][0/196]	Time 0.135 (0.135)	Data 0.324 (0.324)	Loss 0.4663 (0.4663)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [25][64/196]	Time 0.089 (0.098)	Data 0.000 (0.005)	Loss 0.5162 (0.4872)	Acc@1 81.641 (82.782)	Acc@5 99.609 (99.303)
Epoch: [25][128/196]	Time 0.080 (0.092)	Data 0.000 (0.003)	Loss 0.4813 (0.4855)	Acc@1 80.469 (83.064)	Acc@5 99.609 (99.301)
Epoch: [25][192/196]	Time 0.087 (0.092)	Data 0.000 (0.002)	Loss 0.3745 (0.4907)	Acc@1 86.719 (82.991)	Acc@5 100.000 (99.243)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  73.03
Max memory: 51.4381312
 18.517s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 421
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:26/30; Lr: 0.1
batch Size 256
Epoch: [26][0/196]	Time 0.148 (0.148)	Data 0.415 (0.415)	Loss 0.4712 (0.4712)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 0.092 (0.097)	Data 0.000 (0.007)	Loss 0.5129 (0.4517)	Acc@1 82.812 (84.279)	Acc@5 98.047 (99.387)
Epoch: [26][128/196]	Time 0.090 (0.097)	Data 0.000 (0.003)	Loss 0.4359 (0.4752)	Acc@1 84.375 (83.382)	Acc@5 99.609 (99.282)
Epoch: [26][192/196]	Time 0.086 (0.096)	Data 0.000 (0.002)	Loss 0.5264 (0.4805)	Acc@1 82.422 (83.325)	Acc@5 98.828 (99.273)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:27/30; Lr: 0.1
batch Size 256
Epoch: [27][0/196]	Time 0.164 (0.164)	Data 0.365 (0.365)	Loss 0.4653 (0.4653)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 0.088 (0.100)	Data 0.000 (0.006)	Loss 0.4219 (0.4815)	Acc@1 85.156 (83.522)	Acc@5 98.828 (99.261)
Epoch: [27][128/196]	Time 0.085 (0.094)	Data 0.000 (0.003)	Loss 0.4659 (0.4781)	Acc@1 86.719 (83.533)	Acc@5 98.047 (99.267)
Epoch: [27][192/196]	Time 0.092 (0.094)	Data 0.000 (0.002)	Loss 0.5533 (0.4836)	Acc@1 80.078 (83.221)	Acc@5 99.219 (99.284)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:28/30; Lr: 0.1
batch Size 256
Epoch: [28][0/196]	Time 0.148 (0.148)	Data 0.340 (0.340)	Loss 0.3883 (0.3883)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.084 (0.097)	Data 0.000 (0.005)	Loss 0.5290 (0.4859)	Acc@1 81.641 (83.161)	Acc@5 99.609 (99.273)
Epoch: [28][128/196]	Time 0.109 (0.095)	Data 0.000 (0.003)	Loss 0.4054 (0.4857)	Acc@1 85.547 (83.370)	Acc@5 100.000 (99.237)
Epoch: [28][192/196]	Time 0.095 (0.096)	Data 0.000 (0.002)	Loss 0.4979 (0.4848)	Acc@1 80.469 (83.316)	Acc@5 99.219 (99.271)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:29/30; Lr: 0.1
batch Size 256
Epoch: [29][0/196]	Time 0.152 (0.152)	Data 0.297 (0.297)	Loss 0.4507 (0.4507)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.087 (0.099)	Data 0.000 (0.005)	Loss 0.4156 (0.4807)	Acc@1 86.328 (83.600)	Acc@5 98.828 (99.249)
Epoch: [29][128/196]	Time 0.092 (0.099)	Data 0.000 (0.003)	Loss 0.4611 (0.4759)	Acc@1 84.766 (83.718)	Acc@5 100.000 (99.276)
Epoch: [29][192/196]	Time 0.085 (0.097)	Data 0.000 (0.002)	Loss 0.5173 (0.4745)	Acc@1 83.203 (83.741)	Acc@5 98.828 (99.249)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:30/30; Lr: 0.1
batch Size 256
Epoch: [30][0/196]	Time 0.130 (0.130)	Data 0.319 (0.319)	Loss 0.4442 (0.4442)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [30][64/196]	Time 0.091 (0.093)	Data 0.000 (0.005)	Loss 0.5374 (0.4625)	Acc@1 83.203 (84.525)	Acc@5 99.219 (99.261)
Epoch: [30][128/196]	Time 0.093 (0.096)	Data 0.000 (0.003)	Loss 0.4627 (0.4664)	Acc@1 84.766 (84.033)	Acc@5 99.219 (99.231)
Epoch: [30][192/196]	Time 0.093 (0.097)	Data 0.000 (0.002)	Loss 0.4254 (0.4666)	Acc@1 84.766 (83.944)	Acc@5 99.609 (99.225)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  75.21
Max memory: 51.4381312
 19.322s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 9071
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:31/35; Lr: 0.1
batch Size 256
Epoch: [31][0/196]	Time 0.194 (0.194)	Data 0.334 (0.334)	Loss 0.4478 (0.4478)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.087 (0.100)	Data 0.000 (0.005)	Loss 0.6324 (0.4596)	Acc@1 78.125 (84.267)	Acc@5 99.219 (99.279)
Epoch: [31][128/196]	Time 0.089 (0.100)	Data 0.000 (0.003)	Loss 0.6032 (0.4629)	Acc@1 78.516 (84.136)	Acc@5 97.656 (99.279)
Epoch: [31][192/196]	Time 0.080 (0.097)	Data 0.000 (0.002)	Loss 0.5813 (0.4650)	Acc@1 79.688 (84.067)	Acc@5 98.828 (99.271)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:32/35; Lr: 0.1
batch Size 256
Epoch: [32][0/196]	Time 0.106 (0.106)	Data 0.267 (0.267)	Loss 0.5421 (0.5421)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.094 (0.090)	Data 0.000 (0.004)	Loss 0.4075 (0.4614)	Acc@1 85.156 (84.291)	Acc@5 99.219 (99.369)
Epoch: [32][128/196]	Time 0.094 (0.094)	Data 0.000 (0.002)	Loss 0.5516 (0.4653)	Acc@1 79.297 (84.054)	Acc@5 99.609 (99.316)
Epoch: [32][192/196]	Time 0.105 (0.092)	Data 0.000 (0.002)	Loss 0.4272 (0.4648)	Acc@1 85.938 (83.976)	Acc@5 99.609 (99.271)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:33/35; Lr: 0.1
batch Size 256
Epoch: [33][0/196]	Time 0.156 (0.156)	Data 0.316 (0.316)	Loss 0.4217 (0.4217)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.109 (0.101)	Data 0.000 (0.005)	Loss 0.4394 (0.4581)	Acc@1 86.328 (84.411)	Acc@5 99.219 (99.255)
Epoch: [33][128/196]	Time 0.094 (0.100)	Data 0.000 (0.003)	Loss 0.4218 (0.4621)	Acc@1 85.156 (84.190)	Acc@5 99.219 (99.273)
Epoch: [33][192/196]	Time 0.093 (0.100)	Data 0.000 (0.002)	Loss 0.3734 (0.4612)	Acc@1 87.500 (84.197)	Acc@5 98.438 (99.279)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:34/35; Lr: 0.1
batch Size 256
Epoch: [34][0/196]	Time 0.130 (0.130)	Data 0.361 (0.361)	Loss 0.4601 (0.4601)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [34][64/196]	Time 0.105 (0.100)	Data 0.000 (0.006)	Loss 0.4653 (0.4683)	Acc@1 83.984 (84.081)	Acc@5 99.609 (99.333)
Epoch: [34][128/196]	Time 0.102 (0.094)	Data 0.000 (0.003)	Loss 0.3901 (0.4616)	Acc@1 89.062 (84.151)	Acc@5 99.219 (99.294)
Epoch: [34][192/196]	Time 0.085 (0.093)	Data 0.000 (0.002)	Loss 0.5142 (0.4634)	Acc@1 83.203 (84.007)	Acc@5 99.219 (99.316)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:35/35; Lr: 0.1
batch Size 256
Epoch: [35][0/196]	Time 0.153 (0.153)	Data 0.334 (0.334)	Loss 0.4108 (0.4108)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [35][64/196]	Time 0.106 (0.102)	Data 0.000 (0.005)	Loss 0.4053 (0.4519)	Acc@1 86.328 (84.345)	Acc@5 99.219 (99.279)
Epoch: [35][128/196]	Time 0.121 (0.099)	Data 0.000 (0.003)	Loss 0.4123 (0.4605)	Acc@1 88.672 (84.057)	Acc@5 99.219 (99.273)
Epoch: [35][192/196]	Time 0.083 (0.098)	Data 0.000 (0.002)	Loss 0.4683 (0.4569)	Acc@1 85.547 (84.179)	Acc@5 99.219 (99.275)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  77.15
Max memory: 51.4381312
 19.520s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2373
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:36/40; Lr: 0.1
batch Size 256
Epoch: [36][0/196]	Time 0.172 (0.172)	Data 0.387 (0.387)	Loss 0.5004 (0.5004)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.086 (0.099)	Data 0.000 (0.006)	Loss 0.3659 (0.4265)	Acc@1 85.938 (85.343)	Acc@5 99.609 (99.393)
Epoch: [36][128/196]	Time 0.084 (0.093)	Data 0.000 (0.003)	Loss 0.5267 (0.4398)	Acc@1 82.031 (84.941)	Acc@5 99.609 (99.379)
Epoch: [36][192/196]	Time 0.103 (0.092)	Data 0.000 (0.002)	Loss 0.4412 (0.4465)	Acc@1 83.984 (84.626)	Acc@5 99.609 (99.348)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:37/40; Lr: 0.1
batch Size 256
Epoch: [37][0/196]	Time 0.167 (0.167)	Data 0.372 (0.372)	Loss 0.4920 (0.4920)	Acc@1 81.250 (81.250)	Acc@5 98.828 (98.828)
Epoch: [37][64/196]	Time 0.097 (0.094)	Data 0.000 (0.006)	Loss 0.3457 (0.4463)	Acc@1 87.109 (84.543)	Acc@5 99.609 (99.321)
Epoch: [37][128/196]	Time 0.092 (0.095)	Data 0.000 (0.003)	Loss 0.4913 (0.4534)	Acc@1 83.203 (84.287)	Acc@5 99.609 (99.367)
Epoch: [37][192/196]	Time 0.095 (0.096)	Data 0.000 (0.002)	Loss 0.5320 (0.4522)	Acc@1 83.203 (84.375)	Acc@5 98.047 (99.320)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:38/40; Lr: 0.1
batch Size 256
Epoch: [38][0/196]	Time 0.132 (0.132)	Data 0.320 (0.320)	Loss 0.4037 (0.4037)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [38][64/196]	Time 0.109 (0.103)	Data 0.000 (0.005)	Loss 0.4932 (0.4608)	Acc@1 82.031 (84.105)	Acc@5 99.609 (99.381)
Epoch: [38][128/196]	Time 0.098 (0.101)	Data 0.000 (0.003)	Loss 0.3967 (0.4647)	Acc@1 86.328 (84.009)	Acc@5 99.609 (99.361)
Epoch: [38][192/196]	Time 0.080 (0.098)	Data 0.000 (0.002)	Loss 0.4792 (0.4605)	Acc@1 84.375 (84.173)	Acc@5 100.000 (99.344)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:39/40; Lr: 0.1
batch Size 256
Epoch: [39][0/196]	Time 0.120 (0.120)	Data 0.306 (0.306)	Loss 0.4809 (0.4809)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.086 (0.090)	Data 0.000 (0.005)	Loss 0.5589 (0.4463)	Acc@1 80.859 (84.585)	Acc@5 99.609 (99.369)
Epoch: [39][128/196]	Time 0.103 (0.093)	Data 0.000 (0.003)	Loss 0.4282 (0.4529)	Acc@1 86.719 (84.320)	Acc@5 99.219 (99.316)
Epoch: [39][192/196]	Time 0.095 (0.095)	Data 0.000 (0.002)	Loss 0.4741 (0.4517)	Acc@1 83.203 (84.391)	Acc@5 99.609 (99.352)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:40/40; Lr: 0.1
batch Size 256
Epoch: [40][0/196]	Time 0.144 (0.144)	Data 0.382 (0.382)	Loss 0.4874 (0.4874)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [40][64/196]	Time 0.111 (0.098)	Data 0.000 (0.006)	Loss 0.5294 (0.4433)	Acc@1 83.203 (84.730)	Acc@5 99.219 (99.333)
Epoch: [40][128/196]	Time 0.098 (0.098)	Data 0.000 (0.003)	Loss 0.3759 (0.4486)	Acc@1 86.719 (84.526)	Acc@5 99.609 (99.279)
Epoch: [40][192/196]	Time 0.087 (0.098)	Data 0.000 (0.002)	Loss 0.5122 (0.4513)	Acc@1 81.250 (84.496)	Acc@5 98.438 (99.279)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  78.64
Max memory: 51.4381312
 19.598s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 7050
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:41/45; Lr: 0.1
batch Size 256
Epoch: [41][0/196]	Time 0.138 (0.138)	Data 0.299 (0.299)	Loss 0.3624 (0.3624)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [41][64/196]	Time 0.082 (0.091)	Data 0.000 (0.005)	Loss 0.4625 (0.4264)	Acc@1 83.594 (85.174)	Acc@5 98.828 (99.399)
Epoch: [41][128/196]	Time 0.094 (0.093)	Data 0.000 (0.003)	Loss 0.5276 (0.4336)	Acc@1 83.203 (85.132)	Acc@5 99.609 (99.425)
Epoch: [41][192/196]	Time 0.092 (0.093)	Data 0.000 (0.002)	Loss 0.5125 (0.4367)	Acc@1 84.375 (84.940)	Acc@5 98.828 (99.449)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:42/45; Lr: 0.1
batch Size 256
Epoch: [42][0/196]	Time 0.150 (0.150)	Data 0.350 (0.350)	Loss 0.3329 (0.3329)	Acc@1 90.234 (90.234)	Acc@5 98.438 (98.438)
Epoch: [42][64/196]	Time 0.105 (0.101)	Data 0.000 (0.006)	Loss 0.5090 (0.4262)	Acc@1 81.641 (85.337)	Acc@5 98.438 (99.393)
Epoch: [42][128/196]	Time 0.092 (0.099)	Data 0.000 (0.003)	Loss 0.4623 (0.4375)	Acc@1 85.547 (84.965)	Acc@5 99.219 (99.373)
Epoch: [42][192/196]	Time 0.098 (0.098)	Data 0.000 (0.002)	Loss 0.4050 (0.4403)	Acc@1 85.938 (84.756)	Acc@5 99.609 (99.344)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:43/45; Lr: 0.1
batch Size 256
Epoch: [43][0/196]	Time 0.136 (0.136)	Data 0.367 (0.367)	Loss 0.4672 (0.4672)	Acc@1 85.156 (85.156)	Acc@5 98.047 (98.047)
Epoch: [43][64/196]	Time 0.091 (0.100)	Data 0.000 (0.006)	Loss 0.3987 (0.4343)	Acc@1 86.328 (84.970)	Acc@5 99.609 (99.309)
Epoch: [43][128/196]	Time 0.081 (0.095)	Data 0.000 (0.003)	Loss 0.4919 (0.4396)	Acc@1 83.203 (84.887)	Acc@5 99.609 (99.319)
Epoch: [43][192/196]	Time 0.090 (0.093)	Data 0.000 (0.002)	Loss 0.4628 (0.4408)	Acc@1 85.938 (84.758)	Acc@5 98.828 (99.344)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:44/45; Lr: 0.1
batch Size 256
Epoch: [44][0/196]	Time 0.145 (0.145)	Data 0.376 (0.376)	Loss 0.4477 (0.4477)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.094 (0.101)	Data 0.000 (0.006)	Loss 0.3127 (0.4440)	Acc@1 91.406 (84.525)	Acc@5 100.000 (99.357)
Epoch: [44][128/196]	Time 0.086 (0.100)	Data 0.000 (0.003)	Loss 0.4412 (0.4394)	Acc@1 85.938 (84.859)	Acc@5 98.438 (99.319)
Epoch: [44][192/196]	Time 0.107 (0.099)	Data 0.000 (0.002)	Loss 0.3705 (0.4427)	Acc@1 87.109 (84.709)	Acc@5 98.828 (99.354)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:45/45; Lr: 0.1
batch Size 256
Epoch: [45][0/196]	Time 0.130 (0.130)	Data 0.304 (0.304)	Loss 0.4126 (0.4126)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [45][64/196]	Time 0.094 (0.099)	Data 0.000 (0.005)	Loss 0.3579 (0.4230)	Acc@1 85.938 (85.186)	Acc@5 100.000 (99.519)
Epoch: [45][128/196]	Time 0.108 (0.099)	Data 0.000 (0.003)	Loss 0.3591 (0.4363)	Acc@1 87.891 (84.941)	Acc@5 99.609 (99.413)
Epoch: [45][192/196]	Time 0.085 (0.098)	Data 0.000 (0.002)	Loss 0.4204 (0.4388)	Acc@1 84.766 (84.841)	Acc@5 99.609 (99.395)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  79.19
Max memory: 51.4381312
 19.484s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 6924
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:46/50; Lr: 0.1
batch Size 256
Epoch: [46][0/196]	Time 0.168 (0.168)	Data 0.297 (0.297)	Loss 0.4715 (0.4715)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.099 (0.093)	Data 0.000 (0.005)	Loss 0.4389 (0.4122)	Acc@1 83.984 (85.715)	Acc@5 99.609 (99.459)
Epoch: [46][128/196]	Time 0.106 (0.095)	Data 0.000 (0.002)	Loss 0.4462 (0.4262)	Acc@1 84.766 (85.326)	Acc@5 99.609 (99.416)
Epoch: [46][192/196]	Time 0.087 (0.095)	Data 0.000 (0.002)	Loss 0.5189 (0.4358)	Acc@1 83.594 (85.069)	Acc@5 98.828 (99.336)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:47/50; Lr: 0.1
batch Size 256
Epoch: [47][0/196]	Time 0.159 (0.159)	Data 0.317 (0.317)	Loss 0.5673 (0.5673)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [47][64/196]	Time 0.100 (0.101)	Data 0.000 (0.005)	Loss 0.5410 (0.4343)	Acc@1 79.688 (84.946)	Acc@5 98.828 (99.399)
Epoch: [47][128/196]	Time 0.091 (0.100)	Data 0.000 (0.003)	Loss 0.4805 (0.4327)	Acc@1 81.641 (85.008)	Acc@5 100.000 (99.376)
Epoch: [47][192/196]	Time 0.078 (0.098)	Data 0.000 (0.002)	Loss 0.5747 (0.4383)	Acc@1 78.125 (84.845)	Acc@5 99.609 (99.366)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:48/50; Lr: 0.1
batch Size 256
Epoch: [48][0/196]	Time 0.128 (0.128)	Data 0.298 (0.298)	Loss 0.5099 (0.5099)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.079 (0.089)	Data 0.000 (0.005)	Loss 0.5401 (0.4408)	Acc@1 82.812 (85.024)	Acc@5 98.438 (99.381)
Epoch: [48][128/196]	Time 0.099 (0.093)	Data 0.000 (0.003)	Loss 0.5759 (0.4367)	Acc@1 79.297 (84.941)	Acc@5 98.047 (99.394)
Epoch: [48][192/196]	Time 0.089 (0.095)	Data 0.000 (0.002)	Loss 0.5847 (0.4395)	Acc@1 78.906 (84.960)	Acc@5 99.609 (99.381)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:49/50; Lr: 0.1
batch Size 256
Epoch: [49][0/196]	Time 0.138 (0.138)	Data 0.361 (0.361)	Loss 0.4103 (0.4103)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.083 (0.100)	Data 0.000 (0.006)	Loss 0.3571 (0.4107)	Acc@1 87.891 (86.070)	Acc@5 99.219 (99.441)
Epoch: [49][128/196]	Time 0.101 (0.098)	Data 0.000 (0.003)	Loss 0.4651 (0.4281)	Acc@1 84.766 (85.329)	Acc@5 99.219 (99.376)
Epoch: [49][192/196]	Time 0.094 (0.098)	Data 0.000 (0.002)	Loss 0.4173 (0.4318)	Acc@1 85.547 (85.146)	Acc@5 99.219 (99.375)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:50/50; Lr: 0.1
batch Size 256
Epoch: [50][0/196]	Time 0.162 (0.162)	Data 0.285 (0.285)	Loss 0.4503 (0.4503)	Acc@1 84.766 (84.766)	Acc@5 98.047 (98.047)
Epoch: [50][64/196]	Time 0.102 (0.100)	Data 0.000 (0.005)	Loss 0.5226 (0.4290)	Acc@1 84.375 (85.547)	Acc@5 99.609 (99.297)
Epoch: [50][128/196]	Time 0.089 (0.094)	Data 0.000 (0.003)	Loss 0.4461 (0.4329)	Acc@1 83.984 (85.180)	Acc@5 99.609 (99.331)
Epoch: [50][192/196]	Time 0.094 (0.092)	Data 0.000 (0.002)	Loss 0.3268 (0.4327)	Acc@1 87.500 (85.203)	Acc@5 99.609 (99.364)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  75.75
Max memory: 51.4381312
 18.504s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 1577
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:51/55; Lr: 0.1
batch Size 256
Epoch: [51][0/196]	Time 0.182 (0.182)	Data 0.341 (0.341)	Loss 0.3460 (0.3460)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [51][64/196]	Time 0.096 (0.099)	Data 0.000 (0.005)	Loss 0.4274 (0.4192)	Acc@1 85.547 (85.703)	Acc@5 99.219 (99.459)
Epoch: [51][128/196]	Time 0.090 (0.098)	Data 0.000 (0.003)	Loss 0.4543 (0.4205)	Acc@1 83.984 (85.656)	Acc@5 99.219 (99.434)
Epoch: [51][192/196]	Time 0.085 (0.097)	Data 0.000 (0.002)	Loss 0.3447 (0.4218)	Acc@1 87.891 (85.490)	Acc@5 100.000 (99.415)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:52/55; Lr: 0.1
batch Size 256
Epoch: [52][0/196]	Time 0.153 (0.153)	Data 0.315 (0.315)	Loss 0.4504 (0.4504)	Acc@1 87.500 (87.500)	Acc@5 98.047 (98.047)
Epoch: [52][64/196]	Time 0.096 (0.102)	Data 0.000 (0.005)	Loss 0.4404 (0.4388)	Acc@1 86.328 (84.742)	Acc@5 98.828 (99.345)
Epoch: [52][128/196]	Time 0.092 (0.096)	Data 0.000 (0.003)	Loss 0.3876 (0.4287)	Acc@1 87.891 (85.174)	Acc@5 99.609 (99.376)
Epoch: [52][192/196]	Time 0.089 (0.094)	Data 0.000 (0.002)	Loss 0.4423 (0.4309)	Acc@1 86.328 (85.132)	Acc@5 100.000 (99.334)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:53/55; Lr: 0.1
batch Size 256
Epoch: [53][0/196]	Time 0.151 (0.151)	Data 0.361 (0.361)	Loss 0.4318 (0.4318)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.095 (0.101)	Data 0.000 (0.006)	Loss 0.4534 (0.4341)	Acc@1 83.594 (84.856)	Acc@5 98.828 (99.399)
Epoch: [53][128/196]	Time 0.101 (0.100)	Data 0.000 (0.003)	Loss 0.5186 (0.4360)	Acc@1 81.641 (84.811)	Acc@5 98.438 (99.334)
Epoch: [53][192/196]	Time 0.094 (0.099)	Data 0.000 (0.002)	Loss 0.3935 (0.4347)	Acc@1 85.547 (84.836)	Acc@5 99.609 (99.354)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:54/55; Lr: 0.1
batch Size 256
Epoch: [54][0/196]	Time 0.115 (0.115)	Data 0.316 (0.316)	Loss 0.4150 (0.4150)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.099 (0.100)	Data 0.000 (0.005)	Loss 0.4126 (0.4219)	Acc@1 84.766 (85.421)	Acc@5 98.828 (99.381)
Epoch: [54][128/196]	Time 0.107 (0.098)	Data 0.000 (0.003)	Loss 0.4155 (0.4286)	Acc@1 85.938 (85.220)	Acc@5 99.609 (99.379)
Epoch: [54][192/196]	Time 0.113 (0.097)	Data 0.000 (0.002)	Loss 0.3751 (0.4295)	Acc@1 87.500 (85.237)	Acc@5 100.000 (99.395)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:55/55; Lr: 0.1
batch Size 256
Epoch: [55][0/196]	Time 0.118 (0.118)	Data 0.268 (0.268)	Loss 0.4216 (0.4216)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.089 (0.088)	Data 0.000 (0.004)	Loss 0.4803 (0.4252)	Acc@1 81.250 (85.331)	Acc@5 99.219 (99.459)
Epoch: [55][128/196]	Time 0.092 (0.090)	Data 0.000 (0.002)	Loss 0.3768 (0.4216)	Acc@1 85.938 (85.411)	Acc@5 99.609 (99.452)
Epoch: [55][192/196]	Time 0.077 (0.091)	Data 0.000 (0.002)	Loss 0.5370 (0.4256)	Acc@1 82.422 (85.298)	Acc@5 97.656 (99.443)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  81.94
Max memory: 51.4381312
 18.163s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3884
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:56/60; Lr: 0.1
batch Size 256
Epoch: [56][0/196]	Time 0.188 (0.188)	Data 0.317 (0.317)	Loss 0.4155 (0.4155)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.099 (0.099)	Data 0.000 (0.005)	Loss 0.4035 (0.4081)	Acc@1 85.547 (85.763)	Acc@5 99.609 (99.417)
Epoch: [56][128/196]	Time 0.101 (0.099)	Data 0.000 (0.003)	Loss 0.5128 (0.4183)	Acc@1 83.594 (85.559)	Acc@5 98.047 (99.361)
Epoch: [56][192/196]	Time 0.089 (0.098)	Data 0.000 (0.002)	Loss 0.5568 (0.4197)	Acc@1 81.250 (85.496)	Acc@5 99.219 (99.391)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:57/60; Lr: 0.1
batch Size 256
Epoch: [57][0/196]	Time 0.144 (0.144)	Data 0.240 (0.240)	Loss 0.3698 (0.3698)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.086 (0.090)	Data 0.000 (0.004)	Loss 0.3912 (0.4219)	Acc@1 87.109 (85.499)	Acc@5 99.609 (99.351)
Epoch: [57][128/196]	Time 0.102 (0.093)	Data 0.000 (0.002)	Loss 0.4779 (0.4279)	Acc@1 82.812 (85.205)	Acc@5 98.828 (99.419)
Epoch: [57][192/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.5205 (0.4239)	Acc@1 80.078 (85.434)	Acc@5 99.219 (99.405)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:58/60; Lr: 0.1
batch Size 256
Epoch: [58][0/196]	Time 0.158 (0.158)	Data 0.352 (0.352)	Loss 0.4636 (0.4636)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [58][64/196]	Time 0.100 (0.101)	Data 0.000 (0.006)	Loss 0.4769 (0.4265)	Acc@1 80.078 (85.252)	Acc@5 100.000 (99.399)
Epoch: [58][128/196]	Time 0.085 (0.098)	Data 0.000 (0.003)	Loss 0.5232 (0.4299)	Acc@1 83.984 (85.299)	Acc@5 99.609 (99.358)
Epoch: [58][192/196]	Time 0.096 (0.098)	Data 0.000 (0.002)	Loss 0.4143 (0.4292)	Acc@1 85.547 (85.344)	Acc@5 99.219 (99.387)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:59/60; Lr: 0.1
batch Size 256
Epoch: [59][0/196]	Time 0.136 (0.136)	Data 0.340 (0.340)	Loss 0.4579 (0.4579)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.094 (0.102)	Data 0.000 (0.005)	Loss 0.3880 (0.4171)	Acc@1 88.672 (85.733)	Acc@5 99.219 (99.339)
Epoch: [59][128/196]	Time 0.094 (0.097)	Data 0.000 (0.003)	Loss 0.4124 (0.4234)	Acc@1 85.547 (85.344)	Acc@5 99.609 (99.394)
Epoch: [59][192/196]	Time 0.107 (0.094)	Data 0.000 (0.002)	Loss 0.5030 (0.4274)	Acc@1 81.250 (85.193)	Acc@5 98.438 (99.419)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:60/60; Lr: 0.1
batch Size 256
Epoch: [60][0/196]	Time 0.144 (0.144)	Data 0.237 (0.237)	Loss 0.4406 (0.4406)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [60][64/196]	Time 0.092 (0.098)	Data 0.000 (0.004)	Loss 0.4417 (0.4041)	Acc@1 84.375 (85.998)	Acc@5 99.609 (99.555)
Epoch: [60][128/196]	Time 0.102 (0.100)	Data 0.000 (0.002)	Loss 0.4041 (0.4149)	Acc@1 86.719 (85.556)	Acc@5 99.219 (99.416)
Epoch: [60][192/196]	Time 0.094 (0.100)	Data 0.000 (0.001)	Loss 0.5172 (0.4192)	Acc@1 84.375 (85.486)	Acc@5 99.219 (99.405)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  77.2
Max memory: 51.4381312
 19.824s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 2940
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:61/65; Lr: 0.1
batch Size 256
Epoch: [61][0/196]	Time 0.203 (0.203)	Data 0.314 (0.314)	Loss 0.4212 (0.4212)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.099 (0.102)	Data 0.000 (0.005)	Loss 0.4405 (0.4050)	Acc@1 84.375 (85.793)	Acc@5 98.828 (99.513)
Epoch: [61][128/196]	Time 0.085 (0.096)	Data 0.000 (0.003)	Loss 0.4299 (0.4122)	Acc@1 82.422 (85.610)	Acc@5 100.000 (99.455)
Epoch: [61][192/196]	Time 0.108 (0.094)	Data 0.000 (0.002)	Loss 0.3726 (0.4164)	Acc@1 85.938 (85.508)	Acc@5 99.609 (99.460)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:62/65; Lr: 0.1
batch Size 256
Epoch: [62][0/196]	Time 0.155 (0.155)	Data 0.369 (0.369)	Loss 0.4819 (0.4819)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [62][64/196]	Time 0.098 (0.103)	Data 0.000 (0.006)	Loss 0.4701 (0.4298)	Acc@1 83.203 (85.216)	Acc@5 98.828 (99.471)
Epoch: [62][128/196]	Time 0.097 (0.100)	Data 0.000 (0.003)	Loss 0.3482 (0.4267)	Acc@1 86.719 (85.238)	Acc@5 99.219 (99.413)
Epoch: [62][192/196]	Time 0.093 (0.100)	Data 0.000 (0.002)	Loss 0.4528 (0.4266)	Acc@1 81.250 (85.272)	Acc@5 99.609 (99.403)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:63/65; Lr: 0.1
batch Size 256
Epoch: [63][0/196]	Time 0.172 (0.172)	Data 0.318 (0.318)	Loss 0.3999 (0.3999)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [63][64/196]	Time 0.104 (0.102)	Data 0.000 (0.005)	Loss 0.3813 (0.4138)	Acc@1 86.719 (85.841)	Acc@5 98.828 (99.501)
Epoch: [63][128/196]	Time 0.087 (0.101)	Data 0.000 (0.003)	Loss 0.3991 (0.4128)	Acc@1 83.594 (85.786)	Acc@5 99.609 (99.446)
Epoch: [63][192/196]	Time 0.087 (0.100)	Data 0.000 (0.002)	Loss 0.4817 (0.4186)	Acc@1 84.766 (85.614)	Acc@5 99.219 (99.407)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:64/65; Lr: 0.1
batch Size 256
Epoch: [64][0/196]	Time 0.116 (0.116)	Data 0.256 (0.256)	Loss 0.4168 (0.4168)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [64][64/196]	Time 0.085 (0.087)	Data 0.000 (0.004)	Loss 0.5057 (0.4171)	Acc@1 82.812 (85.655)	Acc@5 99.609 (99.435)
Epoch: [64][128/196]	Time 0.100 (0.091)	Data 0.000 (0.002)	Loss 0.3598 (0.4199)	Acc@1 88.672 (85.508)	Acc@5 99.609 (99.391)
Epoch: [64][192/196]	Time 0.091 (0.094)	Data 0.000 (0.002)	Loss 0.3845 (0.4173)	Acc@1 86.328 (85.559)	Acc@5 99.609 (99.423)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:65/65; Lr: 0.1
batch Size 256
Epoch: [65][0/196]	Time 0.149 (0.149)	Data 0.347 (0.347)	Loss 0.2973 (0.2973)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [65][64/196]	Time 0.085 (0.101)	Data 0.000 (0.006)	Loss 0.3889 (0.4260)	Acc@1 85.547 (85.162)	Acc@5 100.000 (99.357)
Epoch: [65][128/196]	Time 0.092 (0.099)	Data 0.000 (0.003)	Loss 0.4319 (0.4175)	Acc@1 85.938 (85.520)	Acc@5 99.219 (99.419)
Epoch: [65][192/196]	Time 0.091 (0.099)	Data 0.000 (0.002)	Loss 0.4405 (0.4230)	Acc@1 83.203 (85.237)	Acc@5 97.656 (99.389)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  79.44
Max memory: 51.4381312
 19.814s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 9918
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:66/70; Lr: 0.1
batch Size 256
Epoch: [66][0/196]	Time 0.173 (0.173)	Data 0.284 (0.284)	Loss 0.3366 (0.3366)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [66][64/196]	Time 0.087 (0.091)	Data 0.000 (0.005)	Loss 0.4366 (0.3927)	Acc@1 87.109 (86.526)	Acc@5 100.000 (99.399)
Epoch: [66][128/196]	Time 0.089 (0.094)	Data 0.000 (0.002)	Loss 0.3455 (0.4031)	Acc@1 87.109 (86.101)	Acc@5 100.000 (99.422)
Epoch: [66][192/196]	Time 0.091 (0.095)	Data 0.000 (0.002)	Loss 0.4113 (0.4101)	Acc@1 83.203 (85.875)	Acc@5 99.609 (99.433)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:67/70; Lr: 0.1
batch Size 256
Epoch: [67][0/196]	Time 0.162 (0.162)	Data 0.354 (0.354)	Loss 0.4977 (0.4977)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [67][64/196]	Time 0.099 (0.099)	Data 0.000 (0.006)	Loss 0.4840 (0.4154)	Acc@1 83.203 (85.493)	Acc@5 99.609 (99.513)
Epoch: [67][128/196]	Time 0.098 (0.098)	Data 0.000 (0.003)	Loss 0.5310 (0.4192)	Acc@1 81.250 (85.471)	Acc@5 98.828 (99.497)
Epoch: [67][192/196]	Time 0.105 (0.097)	Data 0.000 (0.002)	Loss 0.5132 (0.4194)	Acc@1 81.641 (85.383)	Acc@5 99.219 (99.447)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:68/70; Lr: 0.1
batch Size 256
Epoch: [68][0/196]	Time 0.173 (0.173)	Data 0.451 (0.451)	Loss 0.4346 (0.4346)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.088 (0.101)	Data 0.000 (0.007)	Loss 0.3888 (0.4179)	Acc@1 85.547 (85.559)	Acc@5 100.000 (99.435)
Epoch: [68][128/196]	Time 0.084 (0.095)	Data 0.000 (0.004)	Loss 0.4475 (0.4091)	Acc@1 85.156 (85.880)	Acc@5 99.609 (99.488)
Epoch: [68][192/196]	Time 0.087 (0.093)	Data 0.000 (0.003)	Loss 0.4378 (0.4134)	Acc@1 83.984 (85.693)	Acc@5 99.219 (99.470)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:69/70; Lr: 0.1
batch Size 256
Epoch: [69][0/196]	Time 0.165 (0.165)	Data 0.412 (0.412)	Loss 0.4010 (0.4010)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.104 (0.098)	Data 0.000 (0.007)	Loss 0.3998 (0.4090)	Acc@1 83.594 (85.835)	Acc@5 100.000 (99.435)
Epoch: [69][128/196]	Time 0.090 (0.098)	Data 0.000 (0.003)	Loss 0.4179 (0.4198)	Acc@1 84.766 (85.456)	Acc@5 100.000 (99.403)
Epoch: [69][192/196]	Time 0.082 (0.095)	Data 0.000 (0.002)	Loss 0.4391 (0.4191)	Acc@1 82.812 (85.567)	Acc@5 99.609 (99.401)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:70/70; Lr: 0.1
batch Size 256
Epoch: [70][0/196]	Time 0.129 (0.129)	Data 0.299 (0.299)	Loss 0.4059 (0.4059)	Acc@1 87.891 (87.891)	Acc@5 98.047 (98.047)
Epoch: [70][64/196]	Time 0.084 (0.089)	Data 0.000 (0.005)	Loss 0.3625 (0.4091)	Acc@1 87.500 (86.022)	Acc@5 100.000 (99.483)
Epoch: [70][128/196]	Time 0.098 (0.091)	Data 0.000 (0.003)	Loss 0.5172 (0.4086)	Acc@1 80.859 (86.040)	Acc@5 99.219 (99.416)
Epoch: [70][192/196]	Time 0.095 (0.093)	Data 0.000 (0.002)	Loss 0.4239 (0.4153)	Acc@1 85.938 (85.784)	Acc@5 99.219 (99.395)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  78.57
Max memory: 51.4381312
 18.523s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 5122
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:71/75; Lr: 0.1
batch Size 256
Epoch: [71][0/196]	Time 0.171 (0.171)	Data 0.388 (0.388)	Loss 0.4047 (0.4047)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.092 (0.101)	Data 0.000 (0.006)	Loss 0.4256 (0.3863)	Acc@1 88.281 (86.683)	Acc@5 98.438 (99.525)
Epoch: [71][128/196]	Time 0.090 (0.099)	Data 0.000 (0.003)	Loss 0.4027 (0.4007)	Acc@1 85.547 (86.152)	Acc@5 99.609 (99.464)
Epoch: [71][192/196]	Time 0.089 (0.098)	Data 0.000 (0.002)	Loss 0.3891 (0.4069)	Acc@1 85.547 (85.935)	Acc@5 99.609 (99.484)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:72/75; Lr: 0.1
batch Size 256
Epoch: [72][0/196]	Time 0.126 (0.126)	Data 0.283 (0.283)	Loss 0.3638 (0.3638)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.087 (0.089)	Data 0.000 (0.005)	Loss 0.4550 (0.4215)	Acc@1 82.031 (85.727)	Acc@5 99.609 (99.417)
Epoch: [72][128/196]	Time 0.092 (0.090)	Data 0.000 (0.002)	Loss 0.5229 (0.4218)	Acc@1 78.906 (85.692)	Acc@5 99.219 (99.403)
Epoch: [72][192/196]	Time 0.094 (0.093)	Data 0.000 (0.002)	Loss 0.4484 (0.4201)	Acc@1 85.547 (85.713)	Acc@5 99.609 (99.385)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:73/75; Lr: 0.1
batch Size 256
Epoch: [73][0/196]	Time 0.141 (0.141)	Data 0.295 (0.295)	Loss 0.4219 (0.4219)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.097 (0.097)	Data 0.000 (0.005)	Loss 0.4208 (0.4153)	Acc@1 86.328 (86.010)	Acc@5 99.609 (99.471)
Epoch: [73][128/196]	Time 0.095 (0.097)	Data 0.000 (0.003)	Loss 0.3826 (0.4065)	Acc@1 87.109 (86.134)	Acc@5 99.219 (99.503)
Epoch: [73][192/196]	Time 0.092 (0.096)	Data 0.000 (0.002)	Loss 0.4334 (0.4108)	Acc@1 85.938 (85.929)	Acc@5 99.609 (99.449)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:74/75; Lr: 0.1
batch Size 256
Epoch: [74][0/196]	Time 0.140 (0.140)	Data 0.336 (0.336)	Loss 0.4051 (0.4051)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [74][64/196]	Time 0.104 (0.100)	Data 0.000 (0.005)	Loss 0.4225 (0.4046)	Acc@1 82.812 (85.980)	Acc@5 99.609 (99.351)
Epoch: [74][128/196]	Time 0.083 (0.097)	Data 0.000 (0.003)	Loss 0.4462 (0.4084)	Acc@1 83.203 (85.756)	Acc@5 99.219 (99.419)
Epoch: [74][192/196]	Time 0.088 (0.094)	Data 0.000 (0.002)	Loss 0.4066 (0.4148)	Acc@1 86.328 (85.689)	Acc@5 99.609 (99.369)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:75/75; Lr: 0.1
batch Size 256
Epoch: [75][0/196]	Time 0.165 (0.165)	Data 0.323 (0.323)	Loss 0.3746 (0.3746)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.087 (0.100)	Data 0.000 (0.005)	Loss 0.4558 (0.4049)	Acc@1 83.984 (86.130)	Acc@5 100.000 (99.459)
Epoch: [75][128/196]	Time 0.104 (0.099)	Data 0.000 (0.003)	Loss 0.3440 (0.4108)	Acc@1 87.109 (85.835)	Acc@5 99.609 (99.413)
Epoch: [75][192/196]	Time 0.087 (0.098)	Data 0.000 (0.002)	Loss 0.3670 (0.4056)	Acc@1 88.672 (86.023)	Acc@5 99.219 (99.433)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  79.57
Max memory: 51.4381312
 19.612s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3508
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:76/80; Lr: 0.1
batch Size 256
Epoch: [76][0/196]	Time 0.208 (0.208)	Data 0.299 (0.299)	Loss 0.4306 (0.4306)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [76][64/196]	Time 0.098 (0.099)	Data 0.000 (0.005)	Loss 0.3861 (0.3829)	Acc@1 85.547 (86.719)	Acc@5 99.609 (99.465)
Epoch: [76][128/196]	Time 0.097 (0.096)	Data 0.000 (0.003)	Loss 0.3639 (0.3983)	Acc@1 88.281 (86.243)	Acc@5 100.000 (99.385)
Epoch: [76][192/196]	Time 0.089 (0.094)	Data 0.000 (0.002)	Loss 0.4127 (0.4058)	Acc@1 87.500 (85.942)	Acc@5 99.219 (99.395)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:77/80; Lr: 0.1
batch Size 256
Epoch: [77][0/196]	Time 0.129 (0.129)	Data 0.374 (0.374)	Loss 0.3738 (0.3738)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [77][64/196]	Time 0.085 (0.099)	Data 0.000 (0.006)	Loss 0.4228 (0.4099)	Acc@1 84.766 (85.841)	Acc@5 99.609 (99.459)
Epoch: [77][128/196]	Time 0.097 (0.097)	Data 0.000 (0.003)	Loss 0.4664 (0.4123)	Acc@1 82.812 (85.838)	Acc@5 99.219 (99.434)
Epoch: [77][192/196]	Time 0.085 (0.097)	Data 0.000 (0.002)	Loss 0.3254 (0.4162)	Acc@1 88.672 (85.668)	Acc@5 100.000 (99.484)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:78/80; Lr: 0.1
batch Size 256
Epoch: [78][0/196]	Time 0.150 (0.150)	Data 0.399 (0.399)	Loss 0.3782 (0.3782)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [78][64/196]	Time 0.084 (0.100)	Data 0.000 (0.006)	Loss 0.4705 (0.4224)	Acc@1 83.203 (85.355)	Acc@5 99.219 (99.339)
Epoch: [78][128/196]	Time 0.092 (0.098)	Data 0.000 (0.003)	Loss 0.4061 (0.4216)	Acc@1 85.156 (85.377)	Acc@5 100.000 (99.337)
Epoch: [78][192/196]	Time 0.091 (0.098)	Data 0.000 (0.002)	Loss 0.4416 (0.4162)	Acc@1 85.156 (85.486)	Acc@5 99.219 (99.373)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:79/80; Lr: 0.1
batch Size 256
Epoch: [79][0/196]	Time 0.130 (0.130)	Data 0.309 (0.309)	Loss 0.4764 (0.4764)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [79][64/196]	Time 0.084 (0.091)	Data 0.000 (0.005)	Loss 0.5207 (0.3997)	Acc@1 82.812 (86.238)	Acc@5 99.609 (99.501)
Epoch: [79][128/196]	Time 0.097 (0.092)	Data 0.000 (0.003)	Loss 0.3846 (0.4042)	Acc@1 85.938 (86.080)	Acc@5 99.219 (99.425)
Epoch: [79][192/196]	Time 0.102 (0.095)	Data 0.000 (0.002)	Loss 0.4400 (0.4056)	Acc@1 84.766 (86.031)	Acc@5 98.828 (99.397)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:80/80; Lr: 0.1
batch Size 256
Epoch: [80][0/196]	Time 0.143 (0.143)	Data 0.404 (0.404)	Loss 0.3736 (0.3736)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [80][64/196]	Time 0.093 (0.102)	Data 0.000 (0.006)	Loss 0.5460 (0.4097)	Acc@1 80.859 (85.757)	Acc@5 99.219 (99.489)
Epoch: [80][128/196]	Time 0.089 (0.101)	Data 0.000 (0.003)	Loss 0.4028 (0.4093)	Acc@1 86.719 (85.968)	Acc@5 100.000 (99.479)
Epoch: [80][192/196]	Time 0.080 (0.100)	Data 0.000 (0.002)	Loss 0.3863 (0.4090)	Acc@1 84.766 (85.923)	Acc@5 99.609 (99.470)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  81.57
Max memory: 51.4381312
 20.159s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 299
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:81/85; Lr: 0.1
batch Size 256
Epoch: [81][0/196]	Time 0.139 (0.139)	Data 0.290 (0.290)	Loss 0.3932 (0.3932)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.096 (0.091)	Data 0.000 (0.005)	Loss 0.2765 (0.3974)	Acc@1 89.844 (86.262)	Acc@5 100.000 (99.489)
Epoch: [81][128/196]	Time 0.084 (0.093)	Data 0.000 (0.002)	Loss 0.4303 (0.4009)	Acc@1 83.594 (86.186)	Acc@5 99.609 (99.461)
Epoch: [81][192/196]	Time 0.095 (0.092)	Data 0.000 (0.002)	Loss 0.4358 (0.4053)	Acc@1 84.766 (86.095)	Acc@5 99.609 (99.454)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:82/85; Lr: 0.1
batch Size 256
Epoch: [82][0/196]	Time 0.129 (0.129)	Data 0.416 (0.416)	Loss 0.4001 (0.4001)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [82][64/196]	Time 0.110 (0.100)	Data 0.000 (0.007)	Loss 0.3307 (0.4136)	Acc@1 87.500 (85.727)	Acc@5 99.609 (99.429)
Epoch: [82][128/196]	Time 0.101 (0.100)	Data 0.000 (0.003)	Loss 0.3404 (0.4192)	Acc@1 88.281 (85.520)	Acc@5 99.219 (99.440)
Epoch: [82][192/196]	Time 0.095 (0.100)	Data 0.000 (0.002)	Loss 0.3390 (0.4104)	Acc@1 87.109 (85.788)	Acc@5 99.219 (99.468)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:83/85; Lr: 0.1
batch Size 256
Epoch: [83][0/196]	Time 0.164 (0.164)	Data 0.373 (0.373)	Loss 0.4107 (0.4107)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [83][64/196]	Time 0.099 (0.104)	Data 0.000 (0.006)	Loss 0.3789 (0.4150)	Acc@1 88.281 (85.709)	Acc@5 100.000 (99.507)
Epoch: [83][128/196]	Time 0.084 (0.098)	Data 0.000 (0.003)	Loss 0.4864 (0.4140)	Acc@1 82.812 (85.732)	Acc@5 99.219 (99.464)
Epoch: [83][192/196]	Time 0.082 (0.095)	Data 0.000 (0.002)	Loss 0.4020 (0.4163)	Acc@1 87.891 (85.638)	Acc@5 99.219 (99.437)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:84/85; Lr: 0.1
batch Size 256
Epoch: [84][0/196]	Time 0.136 (0.136)	Data 0.359 (0.359)	Loss 0.4025 (0.4025)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [84][64/196]	Time 0.100 (0.101)	Data 0.000 (0.006)	Loss 0.3516 (0.4009)	Acc@1 88.281 (86.388)	Acc@5 100.000 (99.489)
Epoch: [84][128/196]	Time 0.090 (0.099)	Data 0.000 (0.003)	Loss 0.3952 (0.4040)	Acc@1 85.156 (86.280)	Acc@5 100.000 (99.470)
Epoch: [84][192/196]	Time 0.094 (0.099)	Data 0.000 (0.002)	Loss 0.3228 (0.4102)	Acc@1 89.062 (86.079)	Acc@5 99.609 (99.452)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:85/85; Lr: 0.1
batch Size 256
Epoch: [85][0/196]	Time 0.141 (0.141)	Data 0.390 (0.390)	Loss 0.4036 (0.4036)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [85][64/196]	Time 0.087 (0.099)	Data 0.000 (0.006)	Loss 0.4146 (0.3865)	Acc@1 83.984 (86.857)	Acc@5 99.219 (99.471)
Epoch: [85][128/196]	Time 0.109 (0.098)	Data 0.000 (0.003)	Loss 0.3512 (0.3991)	Acc@1 89.453 (86.280)	Acc@5 100.000 (99.458)
Epoch: [85][192/196]	Time 0.088 (0.098)	Data 0.000 (0.002)	Loss 0.3522 (0.4057)	Acc@1 89.062 (86.037)	Acc@5 100.000 (99.433)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  70.28
Max memory: 51.4381312
 19.750s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 1362
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:86/90; Lr: 0.1
batch Size 256
Epoch: [86][0/196]	Time 0.148 (0.148)	Data 0.267 (0.267)	Loss 0.3838 (0.3838)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [86][64/196]	Time 0.087 (0.096)	Data 0.000 (0.004)	Loss 0.4630 (0.3900)	Acc@1 84.766 (86.508)	Acc@5 99.609 (99.513)
Epoch: [86][128/196]	Time 0.098 (0.097)	Data 0.000 (0.002)	Loss 0.2756 (0.3872)	Acc@1 90.234 (86.607)	Acc@5 99.609 (99.525)
Epoch: [86][192/196]	Time 0.093 (0.098)	Data 0.000 (0.002)	Loss 0.3663 (0.4008)	Acc@1 87.500 (86.243)	Acc@5 99.609 (99.452)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:87/90; Lr: 0.1
batch Size 256
Epoch: [87][0/196]	Time 0.147 (0.147)	Data 0.365 (0.365)	Loss 0.4941 (0.4941)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [87][64/196]	Time 0.114 (0.099)	Data 0.000 (0.006)	Loss 0.3824 (0.4063)	Acc@1 88.281 (86.022)	Acc@5 99.609 (99.447)
Epoch: [87][128/196]	Time 0.085 (0.099)	Data 0.000 (0.003)	Loss 0.2785 (0.4001)	Acc@1 91.797 (86.367)	Acc@5 100.000 (99.458)
Epoch: [87][192/196]	Time 0.097 (0.098)	Data 0.000 (0.002)	Loss 0.3110 (0.4058)	Acc@1 90.234 (86.193)	Acc@5 99.609 (99.449)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:88/90; Lr: 0.1
batch Size 256
Epoch: [88][0/196]	Time 0.115 (0.115)	Data 0.282 (0.282)	Loss 0.4699 (0.4699)	Acc@1 83.984 (83.984)	Acc@5 100.000 (100.000)
Epoch: [88][64/196]	Time 0.079 (0.089)	Data 0.000 (0.005)	Loss 0.4388 (0.4080)	Acc@1 84.766 (85.799)	Acc@5 100.000 (99.525)
Epoch: [88][128/196]	Time 0.096 (0.092)	Data 0.000 (0.002)	Loss 0.3773 (0.4120)	Acc@1 87.500 (85.850)	Acc@5 99.609 (99.509)
Epoch: [88][192/196]	Time 0.093 (0.093)	Data 0.000 (0.002)	Loss 0.3842 (0.4096)	Acc@1 87.500 (85.873)	Acc@5 98.828 (99.506)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:89/90; Lr: 0.1
batch Size 256
Epoch: [89][0/196]	Time 0.140 (0.140)	Data 0.423 (0.423)	Loss 0.3898 (0.3898)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [89][64/196]	Time 0.089 (0.100)	Data 0.000 (0.007)	Loss 0.3274 (0.4125)	Acc@1 90.234 (85.793)	Acc@5 98.828 (99.417)
Epoch: [89][128/196]	Time 0.090 (0.098)	Data 0.000 (0.004)	Loss 0.3438 (0.4055)	Acc@1 86.328 (86.001)	Acc@5 99.609 (99.431)
Epoch: [89][192/196]	Time 0.087 (0.098)	Data 0.000 (0.002)	Loss 0.4019 (0.4092)	Acc@1 84.375 (85.745)	Acc@5 99.609 (99.466)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:90/90; Lr: 0.1
batch Size 256
Epoch: [90][0/196]	Time 0.144 (0.144)	Data 0.292 (0.292)	Loss 0.4276 (0.4276)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.110 (0.100)	Data 0.000 (0.005)	Loss 0.3448 (0.4033)	Acc@1 87.109 (86.016)	Acc@5 99.609 (99.453)
Epoch: [90][128/196]	Time 0.093 (0.096)	Data 0.000 (0.002)	Loss 0.3383 (0.4040)	Acc@1 88.281 (86.025)	Acc@5 99.609 (99.449)
Epoch: [90][192/196]	Time 0.083 (0.093)	Data 0.000 (0.002)	Loss 0.4245 (0.4106)	Acc@1 85.156 (85.834)	Acc@5 100.000 (99.433)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  75.54
Max memory: 51.4381312
 18.544s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3698
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1097216
lr: 0.1
lr: 0.1
1
Epoche:91/95; Lr: 0.1
batch Size 256
Epoch: [91][0/196]	Time 0.202 (0.202)	Data 0.323 (0.323)	Loss 0.3862 (0.3862)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.095 (0.101)	Data 0.000 (0.005)	Loss 0.3284 (0.3773)	Acc@1 87.500 (87.055)	Acc@5 100.000 (99.525)
Epoch: [91][128/196]	Time 0.085 (0.099)	Data 0.000 (0.003)	Loss 0.4584 (0.3889)	Acc@1 86.328 (86.740)	Acc@5 98.828 (99.488)
Epoch: [91][192/196]	Time 0.098 (0.098)	Data 0.000 (0.002)	Loss 0.4036 (0.3978)	Acc@1 85.938 (86.286)	Acc@5 99.609 (99.478)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:92/95; Lr: 0.1
batch Size 256
Epoch: [92][0/196]	Time 0.124 (0.124)	Data 0.387 (0.387)	Loss 0.3816 (0.3816)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.092 (0.095)	Data 0.000 (0.006)	Loss 0.3976 (0.4111)	Acc@1 87.500 (85.925)	Acc@5 98.828 (99.333)
Epoch: [92][128/196]	Time 0.092 (0.094)	Data 0.000 (0.003)	Loss 0.4530 (0.4066)	Acc@1 82.812 (85.913)	Acc@5 98.828 (99.388)
Epoch: [92][192/196]	Time 0.088 (0.092)	Data 0.000 (0.002)	Loss 0.3418 (0.4060)	Acc@1 87.500 (85.950)	Acc@5 99.609 (99.425)
Max memory in training epoch: 33.3541888
lr: 0.1
lr: 0.1
1
Epoche:93/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [93][0/196]	Time 0.148 (0.148)	Data 0.295 (0.295)	Loss 0.4467 (0.4467)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [93][64/196]	Time 0.110 (0.101)	Data 0.000 (0.005)	Loss 0.3413 (0.3234)	Acc@1 88.281 (88.954)	Acc@5 99.609 (99.627)
Epoch: [93][128/196]	Time 0.102 (0.099)	Data 0.000 (0.003)	Loss 0.2755 (0.3005)	Acc@1 91.797 (89.759)	Acc@5 99.609 (99.682)
Epoch: [93][192/196]	Time 0.110 (0.098)	Data 0.000 (0.002)	Loss 0.2788 (0.2889)	Acc@1 88.672 (90.164)	Acc@5 99.609 (99.696)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:94/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [94][0/196]	Time 0.141 (0.141)	Data 0.398 (0.398)	Loss 0.3193 (0.3193)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.083 (0.101)	Data 0.000 (0.006)	Loss 0.2389 (0.2504)	Acc@1 92.188 (91.647)	Acc@5 100.000 (99.802)
Epoch: [94][128/196]	Time 0.109 (0.099)	Data 0.000 (0.003)	Loss 0.2379 (0.2530)	Acc@1 91.406 (91.467)	Acc@5 100.000 (99.800)
Epoch: [94][192/196]	Time 0.099 (0.099)	Data 0.000 (0.002)	Loss 0.2575 (0.2510)	Acc@1 91.406 (91.469)	Acc@5 100.000 (99.802)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:95/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [95][0/196]	Time 0.160 (0.160)	Data 0.343 (0.343)	Loss 0.2121 (0.2121)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.084 (0.089)	Data 0.000 (0.005)	Loss 0.1765 (0.2355)	Acc@1 94.141 (91.875)	Acc@5 100.000 (99.772)
Epoch: [95][128/196]	Time 0.102 (0.089)	Data 0.000 (0.003)	Loss 0.2576 (0.2310)	Acc@1 93.359 (92.085)	Acc@5 100.000 (99.785)
Epoch: [95][192/196]	Time 0.090 (0.090)	Data 0.000 (0.002)	Loss 0.1612 (0.2352)	Acc@1 96.484 (91.973)	Acc@5 100.000 (99.785)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  89.23
Max memory: 51.4381312
 18.140s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 3515
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1097216
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:96/100; Lr: 0.010000000000000002
batch Size 256
/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'src.n2n.N2N' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
Epoch: [96][0/196]	Time 0.173 (0.173)	Data 0.320 (0.320)	Loss 0.1934 (0.1934)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.097 (0.098)	Data 0.000 (0.005)	Loss 0.1841 (0.2213)	Acc@1 94.141 (92.470)	Acc@5 99.609 (99.868)
Epoch: [96][128/196]	Time 0.100 (0.098)	Data 0.000 (0.003)	Loss 0.2513 (0.2232)	Acc@1 91.016 (92.424)	Acc@5 99.609 (99.815)
Epoch: [96][192/196]	Time 0.083 (0.097)	Data 0.000 (0.002)	Loss 0.1661 (0.2258)	Acc@1 94.141 (92.317)	Acc@5 100.000 (99.810)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:97/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [97][0/196]	Time 0.146 (0.146)	Data 0.300 (0.300)	Loss 0.2472 (0.2472)	Acc@1 92.578 (92.578)	Acc@5 99.219 (99.219)
Epoch: [97][64/196]	Time 0.106 (0.099)	Data 0.000 (0.005)	Loss 0.1916 (0.2134)	Acc@1 94.141 (92.782)	Acc@5 100.000 (99.838)
Epoch: [97][128/196]	Time 0.098 (0.099)	Data 0.000 (0.003)	Loss 0.1832 (0.2154)	Acc@1 94.922 (92.723)	Acc@5 100.000 (99.818)
Epoch: [97][192/196]	Time 0.088 (0.098)	Data 0.000 (0.002)	Loss 0.2046 (0.2185)	Acc@1 92.969 (92.552)	Acc@5 99.609 (99.808)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:98/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [98][0/196]	Time 0.127 (0.127)	Data 0.269 (0.269)	Loss 0.1806 (0.1806)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.092 (0.091)	Data 0.000 (0.004)	Loss 0.1586 (0.2172)	Acc@1 94.531 (92.512)	Acc@5 100.000 (99.856)
Epoch: [98][128/196]	Time 0.091 (0.094)	Data 0.000 (0.002)	Loss 0.1931 (0.2155)	Acc@1 93.359 (92.560)	Acc@5 100.000 (99.843)
Epoch: [98][192/196]	Time 0.108 (0.095)	Data 0.000 (0.002)	Loss 0.2520 (0.2150)	Acc@1 92.578 (92.657)	Acc@5 99.609 (99.822)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:99/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [99][0/196]	Time 0.145 (0.145)	Data 0.351 (0.351)	Loss 0.1541 (0.1541)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.102 (0.102)	Data 0.000 (0.006)	Loss 0.2315 (0.2087)	Acc@1 92.969 (92.843)	Acc@5 100.000 (99.784)
Epoch: [99][128/196]	Time 0.087 (0.100)	Data 0.000 (0.003)	Loss 0.2295 (0.2090)	Acc@1 90.234 (92.781)	Acc@5 100.000 (99.803)
Epoch: [99][192/196]	Time 0.095 (0.097)	Data 0.000 (0.002)	Loss 0.3114 (0.2094)	Acc@1 89.062 (92.807)	Acc@5 100.000 (99.832)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:100/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [100][0/196]	Time 0.124 (0.124)	Data 0.358 (0.358)	Loss 0.2655 (0.2655)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.083 (0.100)	Data 0.000 (0.006)	Loss 0.1539 (0.1955)	Acc@1 94.922 (93.462)	Acc@5 100.000 (99.862)
Epoch: [100][128/196]	Time 0.081 (0.095)	Data 0.000 (0.003)	Loss 0.1518 (0.2006)	Acc@1 96.094 (93.202)	Acc@5 100.000 (99.843)
Epoch: [100][192/196]	Time 0.088 (0.094)	Data 0.000 (0.002)	Loss 0.2275 (0.2021)	Acc@1 91.406 (93.125)	Acc@5 100.000 (99.834)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  89.48
Max memory: 51.4381312
 18.820s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 7566
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1097216
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:101/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [101][0/196]	Time 0.198 (0.198)	Data 0.319 (0.319)	Loss 0.2198 (0.2198)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [101][64/196]	Time 0.099 (0.103)	Data 0.000 (0.005)	Loss 0.1719 (0.1994)	Acc@1 94.141 (93.167)	Acc@5 100.000 (99.832)
Epoch: [101][128/196]	Time 0.089 (0.101)	Data 0.000 (0.003)	Loss 0.2049 (0.2004)	Acc@1 92.188 (93.202)	Acc@5 100.000 (99.855)
Epoch: [101][192/196]	Time 0.093 (0.099)	Data 0.000 (0.002)	Loss 0.2688 (0.2003)	Acc@1 89.453 (93.187)	Acc@5 99.609 (99.842)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:102/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [102][0/196]	Time 0.132 (0.132)	Data 0.250 (0.250)	Loss 0.2509 (0.2509)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.098 (0.103)	Data 0.000 (0.004)	Loss 0.1679 (0.1930)	Acc@1 94.141 (93.281)	Acc@5 99.609 (99.862)
Epoch: [102][128/196]	Time 0.103 (0.097)	Data 0.000 (0.002)	Loss 0.1797 (0.1987)	Acc@1 93.750 (93.141)	Acc@5 100.000 (99.849)
Epoch: [102][192/196]	Time 0.082 (0.095)	Data 0.000 (0.002)	Loss 0.2017 (0.1988)	Acc@1 94.531 (93.163)	Acc@5 99.609 (99.848)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:103/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [103][0/196]	Time 0.162 (0.162)	Data 0.308 (0.308)	Loss 0.2056 (0.2056)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [103][64/196]	Time 0.096 (0.099)	Data 0.000 (0.005)	Loss 0.2122 (0.1920)	Acc@1 93.750 (93.462)	Acc@5 99.609 (99.826)
Epoch: [103][128/196]	Time 0.111 (0.100)	Data 0.000 (0.003)	Loss 0.1969 (0.1935)	Acc@1 94.531 (93.356)	Acc@5 100.000 (99.833)
Epoch: [103][192/196]	Time 0.102 (0.099)	Data 0.000 (0.002)	Loss 0.2290 (0.1946)	Acc@1 92.578 (93.319)	Acc@5 99.609 (99.848)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:104/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [104][0/196]	Time 0.160 (0.160)	Data 0.327 (0.327)	Loss 0.2243 (0.2243)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 0.097 (0.099)	Data 0.000 (0.005)	Loss 0.1889 (0.1879)	Acc@1 91.016 (93.552)	Acc@5 100.000 (99.892)
Epoch: [104][128/196]	Time 0.096 (0.098)	Data 0.000 (0.003)	Loss 0.1760 (0.1884)	Acc@1 94.531 (93.465)	Acc@5 99.609 (99.885)
Epoch: [104][192/196]	Time 0.101 (0.098)	Data 0.000 (0.002)	Loss 0.2601 (0.1889)	Acc@1 92.188 (93.446)	Acc@5 100.000 (99.883)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:105/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [105][0/196]	Time 0.126 (0.126)	Data 0.289 (0.289)	Loss 0.1998 (0.1998)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.083 (0.090)	Data 0.000 (0.005)	Loss 0.1433 (0.1888)	Acc@1 94.141 (93.413)	Acc@5 99.609 (99.850)
Epoch: [105][128/196]	Time 0.093 (0.092)	Data 0.000 (0.002)	Loss 0.1994 (0.1885)	Acc@1 92.188 (93.514)	Acc@5 100.000 (99.855)
Epoch: [105][192/196]	Time 0.092 (0.093)	Data 0.000 (0.002)	Loss 0.1977 (0.1884)	Acc@1 92.578 (93.481)	Acc@5 100.000 (99.866)
Max memory in training epoch: 33.3541888
[INFO] Storing checkpoint...
  89.63
Max memory: 51.4381312
 18.605s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
[8, 16, 32]
random number: 188
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1097216
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:106/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [106][0/196]	Time 0.190 (0.190)	Data 0.382 (0.382)	Loss 0.1462 (0.1462)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.100 (0.102)	Data 0.000 (0.006)	Loss 0.2190 (0.1798)	Acc@1 93.359 (93.876)	Acc@5 99.609 (99.886)
Epoch: [106][128/196]	Time 0.102 (0.101)	Data 0.000 (0.003)	Loss 0.2465 (0.1839)	Acc@1 93.750 (93.750)	Acc@5 100.000 (99.876)
Epoch: [106][192/196]	Time 0.084 (0.100)	Data 0.000 (0.002)	Loss 0.2793 (0.1846)	Acc@1 88.672 (93.598)	Acc@5 99.609 (99.875)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:107/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [107][0/196]	Time 0.138 (0.138)	Data 0.289 (0.289)	Loss 0.1962 (0.1962)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [107][64/196]	Time 0.089 (0.092)	Data 0.000 (0.005)	Loss 0.1760 (0.1829)	Acc@1 92.578 (93.906)	Acc@5 100.000 (99.856)
Epoch: [107][128/196]	Time 0.094 (0.094)	Data 0.000 (0.002)	Loss 0.1803 (0.1860)	Acc@1 94.141 (93.762)	Acc@5 100.000 (99.867)
Epoch: [107][192/196]	Time 0.099 (0.096)	Data 0.000 (0.002)	Loss 0.1673 (0.1845)	Acc@1 94.922 (93.768)	Acc@5 99.609 (99.877)
Max memory in training epoch: 33.3541888
lr: 0.010000000000000002
lr: 0.010000000000000002
1
Epoche:108/110; Lr: 0.010000000000000002
batch Size 256
