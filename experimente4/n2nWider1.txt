Net2Net 1
j: 1 bis 5
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4268
Files already downloaded and verified
width: 8
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): AdaptiveAvgPool2d(output_size=(1, 1))
    (43): Linear(in_features=32, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.0348672
lr: 0.1
1
Epoche:1/5; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.167 (0.167)	Data 0.340 (0.340)	Loss 2.5206 (2.5206)	Acc@1 9.766 (9.766)	Acc@5 48.047 (48.047)
Epoch: [1][64/196]	Time 0.065 (0.066)	Data 0.000 (0.005)	Loss 1.7844 (1.9516)	Acc@1 32.812 (25.992)	Acc@5 83.203 (79.141)
Epoch: [1][128/196]	Time 0.064 (0.066)	Data 0.000 (0.003)	Loss 1.5838 (1.7947)	Acc@1 39.453 (31.889)	Acc@5 91.406 (84.208)
Epoch: [1][192/196]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 1.3122 (1.6709)	Acc@1 52.734 (37.081)	Acc@5 94.141 (87.061)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:2/5; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.079 (0.079)	Data 0.332 (0.332)	Loss 1.5106 (1.5106)	Acc@1 41.016 (41.016)	Acc@5 93.750 (93.750)
Epoch: [2][64/196]	Time 0.066 (0.068)	Data 0.000 (0.005)	Loss 1.2575 (1.3144)	Acc@1 55.469 (51.689)	Acc@5 94.141 (94.099)
Epoch: [2][128/196]	Time 0.063 (0.067)	Data 0.000 (0.003)	Loss 1.1468 (1.2634)	Acc@1 59.766 (53.734)	Acc@5 95.703 (94.640)
Epoch: [2][192/196]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.9924 (1.2232)	Acc@1 64.453 (55.335)	Acc@5 95.703 (94.977)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:3/5; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.093 (0.093)	Data 0.389 (0.389)	Loss 1.0505 (1.0505)	Acc@1 59.375 (59.375)	Acc@5 96.875 (96.875)
Epoch: [3][64/196]	Time 0.066 (0.067)	Data 0.000 (0.006)	Loss 1.0856 (1.0888)	Acc@1 60.938 (60.433)	Acc@5 93.750 (95.962)
Epoch: [3][128/196]	Time 0.066 (0.066)	Data 0.000 (0.003)	Loss 1.1492 (1.0542)	Acc@1 60.156 (62.061)	Acc@5 96.094 (96.260)
Epoch: [3][192/196]	Time 0.062 (0.065)	Data 0.000 (0.002)	Loss 0.9010 (1.0330)	Acc@1 67.188 (62.885)	Acc@5 97.266 (96.389)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:4/5; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.102 (0.102)	Data 0.303 (0.303)	Loss 0.9146 (0.9146)	Acc@1 70.312 (70.312)	Acc@5 97.656 (97.656)
Epoch: [4][64/196]	Time 0.067 (0.062)	Data 0.000 (0.005)	Loss 0.9328 (0.9530)	Acc@1 65.625 (65.601)	Acc@5 97.656 (97.236)
Epoch: [4][128/196]	Time 0.062 (0.063)	Data 0.000 (0.003)	Loss 1.0629 (0.9322)	Acc@1 62.109 (66.594)	Acc@5 94.922 (97.293)
Epoch: [4][192/196]	Time 0.059 (0.063)	Data 0.000 (0.002)	Loss 0.7465 (0.9177)	Acc@1 74.219 (67.200)	Acc@5 98.828 (97.336)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:5/5; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.094 (0.094)	Data 0.312 (0.312)	Loss 0.7339 (0.7339)	Acc@1 71.094 (71.094)	Acc@5 99.219 (99.219)
Epoch: [5][64/196]	Time 0.067 (0.065)	Data 0.000 (0.005)	Loss 0.9441 (0.8355)	Acc@1 67.578 (70.457)	Acc@5 97.266 (97.969)
Epoch: [5][128/196]	Time 0.065 (0.064)	Data 0.000 (0.003)	Loss 0.8596 (0.8357)	Acc@1 70.703 (70.346)	Acc@5 97.656 (97.759)
Epoch: [5][192/196]	Time 0.061 (0.064)	Data 0.000 (0.002)	Loss 0.8799 (0.8359)	Acc@1 70.703 (70.476)	Acc@5 98.438 (97.818)
Max memory in training epoch: 21.4926848
[INFO] Storing checkpoint...
  61.27
Max memory: 33.0373632
 12.950s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2596
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.0665088
lr: 0.1
1
Epoche:6/10; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 0.120 (0.120)	Data 0.374 (0.374)	Loss 0.8498 (0.8498)	Acc@1 66.797 (66.797)	Acc@5 97.656 (97.656)
Epoch: [6][64/196]	Time 0.070 (0.069)	Data 0.000 (0.006)	Loss 0.8504 (0.7840)	Acc@1 67.188 (72.434)	Acc@5 98.828 (97.987)
Epoch: [6][128/196]	Time 0.067 (0.069)	Data 0.000 (0.003)	Loss 0.7358 (0.7853)	Acc@1 76.562 (72.414)	Acc@5 98.438 (98.026)
Epoch: [6][192/196]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.6523 (0.7831)	Acc@1 78.906 (72.462)	Acc@5 98.828 (98.073)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:7/10; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 0.099 (0.099)	Data 0.285 (0.285)	Loss 0.7339 (0.7339)	Acc@1 76.562 (76.562)	Acc@5 98.047 (98.047)
Epoch: [7][64/196]	Time 0.069 (0.066)	Data 0.000 (0.005)	Loss 0.6850 (0.7626)	Acc@1 77.734 (73.371)	Acc@5 99.609 (98.263)
Epoch: [7][128/196]	Time 0.065 (0.065)	Data 0.000 (0.003)	Loss 0.7681 (0.7545)	Acc@1 70.703 (73.622)	Acc@5 98.047 (98.259)
Epoch: [7][192/196]	Time 0.065 (0.065)	Data 0.000 (0.002)	Loss 0.6660 (0.7424)	Acc@1 76.953 (74.124)	Acc@5 98.828 (98.304)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:8/10; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 0.090 (0.090)	Data 0.361 (0.361)	Loss 0.7893 (0.7893)	Acc@1 73.438 (73.438)	Acc@5 98.047 (98.047)
Epoch: [8][64/196]	Time 0.065 (0.067)	Data 0.000 (0.006)	Loss 0.7589 (0.7071)	Acc@1 73.828 (75.180)	Acc@5 98.047 (98.456)
Epoch: [8][128/196]	Time 0.067 (0.066)	Data 0.000 (0.003)	Loss 0.6711 (0.7128)	Acc@1 76.953 (75.039)	Acc@5 98.828 (98.425)
Epoch: [8][192/196]	Time 0.059 (0.066)	Data 0.000 (0.002)	Loss 0.6852 (0.7100)	Acc@1 79.297 (75.279)	Acc@5 98.438 (98.385)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:9/10; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 0.091 (0.091)	Data 0.360 (0.360)	Loss 0.7439 (0.7439)	Acc@1 72.656 (72.656)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.072 (0.067)	Data 0.000 (0.006)	Loss 0.6942 (0.6751)	Acc@1 76.172 (76.490)	Acc@5 98.047 (98.600)
Epoch: [9][128/196]	Time 0.071 (0.067)	Data 0.000 (0.003)	Loss 0.6123 (0.6730)	Acc@1 75.781 (76.578)	Acc@5 100.000 (98.607)
Epoch: [9][192/196]	Time 0.058 (0.067)	Data 0.000 (0.002)	Loss 0.6697 (0.6722)	Acc@1 76.562 (76.617)	Acc@5 99.219 (98.587)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:10/10; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 0.081 (0.081)	Data 0.347 (0.347)	Loss 0.6553 (0.6553)	Acc@1 74.219 (74.219)	Acc@5 98.047 (98.047)
Epoch: [10][64/196]	Time 0.061 (0.062)	Data 0.000 (0.006)	Loss 0.6525 (0.6715)	Acc@1 77.734 (76.460)	Acc@5 98.047 (98.642)
Epoch: [10][128/196]	Time 0.084 (0.064)	Data 0.000 (0.003)	Loss 0.5487 (0.6550)	Acc@1 78.906 (77.080)	Acc@5 99.609 (98.728)
Epoch: [10][192/196]	Time 0.082 (0.065)	Data 0.000 (0.002)	Loss 0.6441 (0.6550)	Acc@1 78.906 (77.131)	Acc@5 98.047 (98.672)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  68.75
Max memory: 33.0690048
 13.131s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3552
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.0665088
lr: 0.1
1
Epoche:11/15; Lr: 0.1
batch Size 256
Epoch: [11][0/196]	Time 0.158 (0.158)	Data 0.321 (0.321)	Loss 0.5851 (0.5851)	Acc@1 80.078 (80.078)	Acc@5 98.828 (98.828)
Epoch: [11][64/196]	Time 0.068 (0.069)	Data 0.000 (0.005)	Loss 0.7159 (0.6226)	Acc@1 74.219 (78.558)	Acc@5 99.609 (98.708)
Epoch: [11][128/196]	Time 0.061 (0.067)	Data 0.000 (0.003)	Loss 0.7912 (0.6309)	Acc@1 74.219 (78.107)	Acc@5 97.656 (98.701)
Epoch: [11][192/196]	Time 0.063 (0.065)	Data 0.000 (0.002)	Loss 0.6374 (0.6355)	Acc@1 78.516 (77.987)	Acc@5 99.219 (98.739)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:12/15; Lr: 0.1
batch Size 256
Epoch: [12][0/196]	Time 0.087 (0.087)	Data 0.319 (0.319)	Loss 0.5829 (0.5829)	Acc@1 80.469 (80.469)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.067 (0.067)	Data 0.000 (0.005)	Loss 0.6602 (0.6276)	Acc@1 79.688 (78.161)	Acc@5 97.656 (98.726)
Epoch: [12][128/196]	Time 0.061 (0.067)	Data 0.000 (0.003)	Loss 0.5450 (0.6219)	Acc@1 81.250 (78.346)	Acc@5 98.828 (98.758)
Epoch: [12][192/196]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.6255 (0.6185)	Acc@1 78.516 (78.433)	Acc@5 98.047 (98.808)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:13/15; Lr: 0.1
batch Size 256
Epoch: [13][0/196]	Time 0.090 (0.090)	Data 0.306 (0.306)	Loss 0.6326 (0.6326)	Acc@1 80.078 (80.078)	Acc@5 97.656 (97.656)
Epoch: [13][64/196]	Time 0.061 (0.066)	Data 0.000 (0.005)	Loss 0.5434 (0.6070)	Acc@1 80.859 (78.924)	Acc@5 98.438 (98.702)
Epoch: [13][128/196]	Time 0.067 (0.065)	Data 0.000 (0.003)	Loss 0.5804 (0.6119)	Acc@1 80.469 (78.749)	Acc@5 99.609 (98.734)
Epoch: [13][192/196]	Time 0.059 (0.065)	Data 0.000 (0.002)	Loss 0.6038 (0.6086)	Acc@1 78.516 (78.809)	Acc@5 98.047 (98.765)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:14/15; Lr: 0.1
batch Size 256
Epoch: [14][0/196]	Time 0.085 (0.085)	Data 0.324 (0.324)	Loss 0.5759 (0.5759)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 0.061 (0.068)	Data 0.000 (0.005)	Loss 0.7125 (0.6013)	Acc@1 74.219 (78.894)	Acc@5 99.609 (98.894)
Epoch: [14][128/196]	Time 0.062 (0.065)	Data 0.000 (0.003)	Loss 0.5157 (0.5975)	Acc@1 78.125 (79.064)	Acc@5 99.609 (98.867)
Epoch: [14][192/196]	Time 0.059 (0.065)	Data 0.000 (0.002)	Loss 0.6672 (0.5956)	Acc@1 78.516 (79.299)	Acc@5 99.219 (98.852)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:15/15; Lr: 0.1
batch Size 256
Epoch: [15][0/196]	Time 0.093 (0.093)	Data 0.362 (0.362)	Loss 0.5643 (0.5643)	Acc@1 82.422 (82.422)	Acc@5 98.438 (98.438)
Epoch: [15][64/196]	Time 0.067 (0.067)	Data 0.000 (0.006)	Loss 0.5721 (0.5802)	Acc@1 77.344 (79.934)	Acc@5 99.609 (99.093)
Epoch: [15][128/196]	Time 0.072 (0.067)	Data 0.000 (0.003)	Loss 0.5290 (0.5858)	Acc@1 83.203 (79.681)	Acc@5 98.828 (99.031)
Epoch: [15][192/196]	Time 0.058 (0.066)	Data 0.000 (0.002)	Loss 0.5723 (0.5841)	Acc@1 81.250 (79.732)	Acc@5 98.438 (99.000)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  71.47
Max memory: 33.0690048
 13.255s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3530
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.0665088
lr: 0.1
1
Epoche:16/20; Lr: 0.1
batch Size 256
Epoch: [16][0/196]	Time 0.115 (0.115)	Data 0.359 (0.359)	Loss 0.6652 (0.6652)	Acc@1 77.734 (77.734)	Acc@5 97.656 (97.656)
Epoch: [16][64/196]	Time 0.066 (0.068)	Data 0.000 (0.006)	Loss 0.6675 (0.5757)	Acc@1 76.562 (80.156)	Acc@5 98.047 (98.954)
Epoch: [16][128/196]	Time 0.074 (0.067)	Data 0.000 (0.003)	Loss 0.5874 (0.5728)	Acc@1 76.562 (80.329)	Acc@5 99.609 (98.934)
Epoch: [16][192/196]	Time 0.074 (0.067)	Data 0.000 (0.002)	Loss 0.5031 (0.5721)	Acc@1 83.594 (80.309)	Acc@5 98.047 (98.905)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:17/20; Lr: 0.1
batch Size 256
Epoch: [17][0/196]	Time 0.081 (0.081)	Data 0.344 (0.344)	Loss 0.5479 (0.5479)	Acc@1 79.297 (79.297)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.067 (0.067)	Data 0.000 (0.006)	Loss 0.5463 (0.5664)	Acc@1 81.641 (80.162)	Acc@5 99.219 (99.062)
Epoch: [17][128/196]	Time 0.078 (0.066)	Data 0.000 (0.003)	Loss 0.4665 (0.5671)	Acc@1 82.422 (80.266)	Acc@5 99.609 (98.992)
Epoch: [17][192/196]	Time 0.056 (0.065)	Data 0.000 (0.002)	Loss 0.6028 (0.5649)	Acc@1 77.344 (80.412)	Acc@5 98.828 (98.982)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:18/20; Lr: 0.1
batch Size 256
Epoch: [18][0/196]	Time 0.088 (0.088)	Data 0.312 (0.312)	Loss 0.5235 (0.5235)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.061 (0.067)	Data 0.000 (0.005)	Loss 0.5915 (0.5624)	Acc@1 79.688 (80.673)	Acc@5 99.609 (99.008)
Epoch: [18][128/196]	Time 0.068 (0.066)	Data 0.000 (0.003)	Loss 0.6193 (0.5688)	Acc@1 79.688 (80.263)	Acc@5 98.828 (98.989)
Epoch: [18][192/196]	Time 0.066 (0.065)	Data 0.000 (0.002)	Loss 0.6061 (0.5678)	Acc@1 78.125 (80.240)	Acc@5 98.828 (98.992)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:19/20; Lr: 0.1
batch Size 256
Epoch: [19][0/196]	Time 0.088 (0.088)	Data 0.306 (0.306)	Loss 0.4518 (0.4518)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.067 (0.067)	Data 0.000 (0.005)	Loss 0.4892 (0.5643)	Acc@1 82.812 (80.469)	Acc@5 99.219 (99.075)
Epoch: [19][128/196]	Time 0.063 (0.067)	Data 0.000 (0.003)	Loss 0.5743 (0.5572)	Acc@1 81.641 (80.735)	Acc@5 98.828 (99.079)
Epoch: [19][192/196]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.4937 (0.5585)	Acc@1 83.984 (80.554)	Acc@5 99.609 (99.026)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:20/20; Lr: 0.1
batch Size 256
Epoch: [20][0/196]	Time 0.096 (0.096)	Data 0.297 (0.297)	Loss 0.4642 (0.4642)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.067 (0.066)	Data 0.000 (0.005)	Loss 0.5917 (0.5430)	Acc@1 80.469 (81.082)	Acc@5 97.656 (99.050)
Epoch: [20][128/196]	Time 0.074 (0.065)	Data 0.000 (0.003)	Loss 0.5091 (0.5438)	Acc@1 83.984 (81.077)	Acc@5 99.219 (99.067)
Epoch: [20][192/196]	Time 0.065 (0.064)	Data 0.000 (0.002)	Loss 0.5444 (0.5442)	Acc@1 82.812 (81.183)	Acc@5 98.438 (99.045)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  73.76
Max memory: 33.0690048
 13.019s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3707
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.0665088
lr: 0.1
1
Epoche:21/25; Lr: 0.1
batch Size 256
Epoch: [21][0/196]	Time 0.129 (0.129)	Data 0.257 (0.257)	Loss 0.5593 (0.5593)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [21][64/196]	Time 0.058 (0.068)	Data 0.000 (0.004)	Loss 0.5539 (0.5148)	Acc@1 79.297 (82.458)	Acc@5 99.609 (99.171)
Epoch: [21][128/196]	Time 0.056 (0.065)	Data 0.000 (0.002)	Loss 0.5546 (0.5285)	Acc@1 79.297 (81.710)	Acc@5 99.219 (99.110)
Epoch: [21][192/196]	Time 0.068 (0.066)	Data 0.000 (0.002)	Loss 0.5845 (0.5357)	Acc@1 80.469 (81.475)	Acc@5 99.219 (99.047)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:22/25; Lr: 0.1
batch Size 256
Epoch: [22][0/196]	Time 0.087 (0.087)	Data 0.358 (0.358)	Loss 0.4888 (0.4888)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [22][64/196]	Time 0.065 (0.069)	Data 0.000 (0.006)	Loss 0.4631 (0.5378)	Acc@1 85.156 (81.172)	Acc@5 100.000 (99.123)
Epoch: [22][128/196]	Time 0.060 (0.068)	Data 0.000 (0.003)	Loss 0.4803 (0.5414)	Acc@1 84.375 (81.283)	Acc@5 99.609 (99.055)
Epoch: [22][192/196]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.5525 (0.5377)	Acc@1 82.031 (81.335)	Acc@5 97.656 (99.055)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:23/25; Lr: 0.1
batch Size 256
Epoch: [23][0/196]	Time 0.078 (0.078)	Data 0.289 (0.289)	Loss 0.5045 (0.5045)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [23][64/196]	Time 0.064 (0.070)	Data 0.000 (0.005)	Loss 0.4754 (0.5286)	Acc@1 83.594 (81.436)	Acc@5 98.438 (99.165)
Epoch: [23][128/196]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.4862 (0.5369)	Acc@1 82.422 (81.341)	Acc@5 99.609 (99.116)
Epoch: [23][192/196]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.4815 (0.5381)	Acc@1 81.641 (81.351)	Acc@5 98.438 (99.089)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:24/25; Lr: 0.1
batch Size 256
Epoch: [24][0/196]	Time 0.117 (0.117)	Data 0.346 (0.346)	Loss 0.5240 (0.5240)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.058 (0.067)	Data 0.000 (0.006)	Loss 0.5073 (0.5246)	Acc@1 82.812 (81.358)	Acc@5 99.219 (99.105)
Epoch: [24][128/196]	Time 0.062 (0.066)	Data 0.000 (0.003)	Loss 0.4307 (0.5204)	Acc@1 86.328 (81.786)	Acc@5 100.000 (99.122)
Epoch: [24][192/196]	Time 0.062 (0.065)	Data 0.000 (0.002)	Loss 0.6806 (0.5269)	Acc@1 77.734 (81.592)	Acc@5 98.438 (99.122)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:25/25; Lr: 0.1
batch Size 256
Epoch: [25][0/196]	Time 0.094 (0.094)	Data 0.368 (0.368)	Loss 0.5765 (0.5765)	Acc@1 78.516 (78.516)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 0.069 (0.071)	Data 0.000 (0.006)	Loss 0.5067 (0.5144)	Acc@1 80.078 (81.839)	Acc@5 98.828 (99.147)
Epoch: [25][128/196]	Time 0.072 (0.069)	Data 0.000 (0.003)	Loss 0.5859 (0.5237)	Acc@1 78.125 (81.695)	Acc@5 98.438 (99.137)
Epoch: [25][192/196]	Time 0.062 (0.067)	Data 0.000 (0.002)	Loss 0.5609 (0.5252)	Acc@1 82.031 (81.671)	Acc@5 98.828 (99.136)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  77.18
Max memory: 33.0690048
 13.652s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1079
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.0665088
lr: 0.1
1
Epoche:26/30; Lr: 0.1
batch Size 256
Epoch: [26][0/196]	Time 0.114 (0.114)	Data 0.355 (0.355)	Loss 0.4988 (0.4988)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.065 (0.070)	Data 0.000 (0.006)	Loss 0.5080 (0.5195)	Acc@1 83.594 (82.163)	Acc@5 100.000 (99.014)
Epoch: [26][128/196]	Time 0.063 (0.068)	Data 0.000 (0.003)	Loss 0.5152 (0.5172)	Acc@1 83.594 (82.104)	Acc@5 99.219 (99.119)
Epoch: [26][192/196]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.5591 (0.5184)	Acc@1 79.297 (82.017)	Acc@5 98.047 (99.081)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:27/30; Lr: 0.1
batch Size 256
Epoch: [27][0/196]	Time 0.095 (0.095)	Data 0.308 (0.308)	Loss 0.6197 (0.6197)	Acc@1 77.344 (77.344)	Acc@5 98.828 (98.828)
Epoch: [27][64/196]	Time 0.072 (0.066)	Data 0.000 (0.005)	Loss 0.5442 (0.5223)	Acc@1 82.031 (81.887)	Acc@5 100.000 (99.093)
Epoch: [27][128/196]	Time 0.065 (0.068)	Data 0.000 (0.003)	Loss 0.5570 (0.5181)	Acc@1 81.250 (82.004)	Acc@5 99.219 (99.082)
Epoch: [27][192/196]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.4293 (0.5186)	Acc@1 85.156 (82.025)	Acc@5 100.000 (99.077)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:28/30; Lr: 0.1
batch Size 256
Epoch: [28][0/196]	Time 0.092 (0.092)	Data 0.363 (0.363)	Loss 0.5818 (0.5818)	Acc@1 79.297 (79.297)	Acc@5 98.828 (98.828)
Epoch: [28][64/196]	Time 0.067 (0.069)	Data 0.000 (0.006)	Loss 0.5204 (0.5064)	Acc@1 82.422 (82.620)	Acc@5 99.609 (99.183)
Epoch: [28][128/196]	Time 0.064 (0.068)	Data 0.000 (0.003)	Loss 0.5625 (0.5174)	Acc@1 80.078 (82.062)	Acc@5 98.828 (99.122)
Epoch: [28][192/196]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.4678 (0.5157)	Acc@1 85.156 (82.228)	Acc@5 99.219 (99.116)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:29/30; Lr: 0.1
batch Size 256
Epoch: [29][0/196]	Time 0.103 (0.103)	Data 0.322 (0.322)	Loss 0.4935 (0.4935)	Acc@1 80.859 (80.859)	Acc@5 98.828 (98.828)
Epoch: [29][64/196]	Time 0.069 (0.071)	Data 0.000 (0.005)	Loss 0.5348 (0.5123)	Acc@1 80.859 (82.548)	Acc@5 98.828 (99.141)
Epoch: [29][128/196]	Time 0.067 (0.069)	Data 0.000 (0.003)	Loss 0.5913 (0.5196)	Acc@1 78.516 (82.062)	Acc@5 98.438 (99.067)
Epoch: [29][192/196]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5684 (0.5203)	Acc@1 80.859 (82.120)	Acc@5 99.219 (99.091)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:30/30; Lr: 0.1
batch Size 256
Epoch: [30][0/196]	Time 0.093 (0.093)	Data 0.369 (0.369)	Loss 0.5167 (0.5167)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 0.066 (0.069)	Data 0.000 (0.006)	Loss 0.6203 (0.5057)	Acc@1 78.516 (82.668)	Acc@5 98.438 (99.177)
Epoch: [30][128/196]	Time 0.078 (0.070)	Data 0.000 (0.003)	Loss 0.4383 (0.5096)	Acc@1 85.547 (82.443)	Acc@5 99.219 (99.137)
Epoch: [30][192/196]	Time 0.063 (0.069)	Data 0.000 (0.002)	Loss 0.5523 (0.5127)	Acc@1 79.688 (82.309)	Acc@5 98.438 (99.144)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  73.0
Max memory: 33.0690048
 13.901s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9636
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0665088
lr: 0.1
1
Epoche:31/35; Lr: 0.1
batch Size 256
Epoch: [31][0/196]	Time 0.144 (0.144)	Data 0.357 (0.357)	Loss 0.4770 (0.4770)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.068 (0.071)	Data 0.000 (0.006)	Loss 0.4644 (0.4839)	Acc@1 84.766 (83.227)	Acc@5 98.828 (99.201)
Epoch: [31][128/196]	Time 0.065 (0.069)	Data 0.000 (0.003)	Loss 0.4455 (0.4968)	Acc@1 83.594 (82.797)	Acc@5 98.047 (99.198)
Epoch: [31][192/196]	Time 0.065 (0.068)	Data 0.000 (0.002)	Loss 0.5459 (0.5064)	Acc@1 79.297 (82.509)	Acc@5 99.609 (99.201)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:32/35; Lr: 0.1
batch Size 256
Epoch: [32][0/196]	Time 0.091 (0.091)	Data 0.340 (0.340)	Loss 0.5081 (0.5081)	Acc@1 81.641 (81.641)	Acc@5 99.609 (99.609)
Epoch: [32][64/196]	Time 0.065 (0.069)	Data 0.000 (0.005)	Loss 0.4214 (0.4997)	Acc@1 86.719 (82.698)	Acc@5 99.609 (99.123)
Epoch: [32][128/196]	Time 0.057 (0.067)	Data 0.000 (0.003)	Loss 0.5153 (0.5051)	Acc@1 82.031 (82.697)	Acc@5 99.609 (99.164)
Epoch: [32][192/196]	Time 0.058 (0.066)	Data 0.000 (0.002)	Loss 0.4950 (0.5003)	Acc@1 84.766 (82.770)	Acc@5 98.828 (99.192)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:33/35; Lr: 0.1
batch Size 256
Epoch: [33][0/196]	Time 0.075 (0.075)	Data 0.272 (0.272)	Loss 0.4387 (0.4387)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [33][64/196]	Time 0.067 (0.063)	Data 0.000 (0.004)	Loss 0.5037 (0.5030)	Acc@1 85.156 (82.218)	Acc@5 99.219 (99.309)
Epoch: [33][128/196]	Time 0.069 (0.064)	Data 0.000 (0.002)	Loss 0.5048 (0.5054)	Acc@1 82.422 (82.328)	Acc@5 98.438 (99.195)
Epoch: [33][192/196]	Time 0.061 (0.065)	Data 0.000 (0.002)	Loss 0.5608 (0.5032)	Acc@1 83.203 (82.509)	Acc@5 98.438 (99.188)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:34/35; Lr: 0.1
batch Size 256
Epoch: [34][0/196]	Time 0.128 (0.128)	Data 0.335 (0.335)	Loss 0.4622 (0.4622)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.069 (0.070)	Data 0.000 (0.005)	Loss 0.4728 (0.4935)	Acc@1 82.812 (82.957)	Acc@5 100.000 (99.279)
Epoch: [34][128/196]	Time 0.068 (0.069)	Data 0.000 (0.003)	Loss 0.4601 (0.5034)	Acc@1 85.938 (82.761)	Acc@5 98.438 (99.179)
Epoch: [34][192/196]	Time 0.061 (0.068)	Data 0.000 (0.002)	Loss 0.5528 (0.4980)	Acc@1 84.766 (82.867)	Acc@5 98.438 (99.207)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:35/35; Lr: 0.1
batch Size 256
Epoch: [35][0/196]	Time 0.088 (0.088)	Data 0.332 (0.332)	Loss 0.5144 (0.5144)	Acc@1 82.422 (82.422)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.059 (0.068)	Data 0.000 (0.005)	Loss 0.5232 (0.4940)	Acc@1 82.812 (83.095)	Acc@5 99.219 (99.177)
Epoch: [35][128/196]	Time 0.058 (0.068)	Data 0.000 (0.003)	Loss 0.4873 (0.5049)	Acc@1 84.375 (82.667)	Acc@5 98.828 (99.134)
Epoch: [35][192/196]	Time 0.072 (0.068)	Data 0.000 (0.002)	Loss 0.6487 (0.5064)	Acc@1 77.734 (82.574)	Acc@5 98.047 (99.150)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  71.87
Max memory: 33.0690048
 13.663s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 559
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.0665088
lr: 0.1
1
Epoche:36/40; Lr: 0.1
batch Size 256
Epoch: [36][0/196]	Time 0.114 (0.114)	Data 0.372 (0.372)	Loss 0.5581 (0.5581)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [36][64/196]	Time 0.067 (0.066)	Data 0.000 (0.006)	Loss 0.4498 (0.4774)	Acc@1 85.156 (83.936)	Acc@5 100.000 (99.291)
Epoch: [36][128/196]	Time 0.062 (0.066)	Data 0.000 (0.003)	Loss 0.4652 (0.4877)	Acc@1 85.547 (83.348)	Acc@5 98.438 (99.231)
Epoch: [36][192/196]	Time 0.071 (0.066)	Data 0.000 (0.002)	Loss 0.5440 (0.4917)	Acc@1 79.688 (83.207)	Acc@5 99.609 (99.168)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:37/40; Lr: 0.1
batch Size 256
Epoch: [37][0/196]	Time 0.112 (0.112)	Data 0.359 (0.359)	Loss 0.5110 (0.5110)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.077 (0.069)	Data 0.000 (0.006)	Loss 0.4206 (0.4910)	Acc@1 83.203 (82.999)	Acc@5 100.000 (99.279)
Epoch: [37][128/196]	Time 0.073 (0.068)	Data 0.000 (0.003)	Loss 0.4500 (0.5005)	Acc@1 83.594 (82.643)	Acc@5 100.000 (99.246)
Epoch: [37][192/196]	Time 0.073 (0.067)	Data 0.000 (0.002)	Loss 0.4857 (0.4973)	Acc@1 84.766 (82.810)	Acc@5 98.828 (99.229)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:38/40; Lr: 0.1
batch Size 256
Epoch: [38][0/196]	Time 0.103 (0.103)	Data 0.300 (0.300)	Loss 0.5061 (0.5061)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [38][64/196]	Time 0.080 (0.068)	Data 0.000 (0.005)	Loss 0.5117 (0.4969)	Acc@1 80.469 (82.969)	Acc@5 97.656 (99.153)
Epoch: [38][128/196]	Time 0.061 (0.067)	Data 0.000 (0.003)	Loss 0.4783 (0.4886)	Acc@1 82.031 (83.233)	Acc@5 99.219 (99.204)
Epoch: [38][192/196]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.5579 (0.4904)	Acc@1 80.469 (83.049)	Acc@5 98.438 (99.196)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:39/40; Lr: 0.1
batch Size 256
Epoch: [39][0/196]	Time 0.081 (0.081)	Data 0.260 (0.260)	Loss 0.5029 (0.5029)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [39][64/196]	Time 0.069 (0.066)	Data 0.000 (0.004)	Loss 0.4913 (0.4972)	Acc@1 83.203 (83.029)	Acc@5 99.609 (99.002)
Epoch: [39][128/196]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4635 (0.4965)	Acc@1 83.203 (83.015)	Acc@5 99.609 (99.064)
Epoch: [39][192/196]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3853 (0.4940)	Acc@1 85.547 (83.019)	Acc@5 99.609 (99.118)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:40/40; Lr: 0.1
batch Size 256
Epoch: [40][0/196]	Time 0.097 (0.097)	Data 0.401 (0.401)	Loss 0.4887 (0.4887)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.057 (0.069)	Data 0.000 (0.006)	Loss 0.3897 (0.4786)	Acc@1 87.500 (83.762)	Acc@5 100.000 (99.243)
Epoch: [40][128/196]	Time 0.068 (0.068)	Data 0.000 (0.003)	Loss 0.5413 (0.4835)	Acc@1 80.469 (83.445)	Acc@5 99.219 (99.213)
Epoch: [40][192/196]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.4909 (0.4845)	Acc@1 82.812 (83.341)	Acc@5 99.609 (99.233)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  77.6
Max memory: 33.0690048
 13.772s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4969
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.0665088
lr: 0.1
1
Epoche:41/45; Lr: 0.1
batch Size 256
Epoch: [41][0/196]	Time 0.112 (0.112)	Data 0.292 (0.292)	Loss 0.5888 (0.5888)	Acc@1 80.078 (80.078)	Acc@5 98.438 (98.438)
Epoch: [41][64/196]	Time 0.063 (0.069)	Data 0.000 (0.005)	Loss 0.5057 (0.4769)	Acc@1 80.859 (83.648)	Acc@5 98.828 (99.237)
Epoch: [41][128/196]	Time 0.071 (0.068)	Data 0.000 (0.002)	Loss 0.4549 (0.4848)	Acc@1 83.594 (83.137)	Acc@5 98.828 (99.210)
Epoch: [41][192/196]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.5502 (0.4879)	Acc@1 81.641 (83.080)	Acc@5 98.828 (99.199)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:42/45; Lr: 0.1
batch Size 256
Epoch: [42][0/196]	Time 0.071 (0.071)	Data 0.326 (0.326)	Loss 0.4713 (0.4713)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.060 (0.068)	Data 0.000 (0.005)	Loss 0.3955 (0.4758)	Acc@1 86.328 (83.600)	Acc@5 99.609 (99.273)
Epoch: [42][128/196]	Time 0.065 (0.068)	Data 0.000 (0.003)	Loss 0.4359 (0.4864)	Acc@1 85.547 (83.164)	Acc@5 99.609 (99.201)
Epoch: [42][192/196]	Time 0.058 (0.066)	Data 0.000 (0.002)	Loss 0.5456 (0.4900)	Acc@1 82.422 (82.946)	Acc@5 98.047 (99.188)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:43/45; Lr: 0.1
batch Size 256
Epoch: [43][0/196]	Time 0.096 (0.096)	Data 0.275 (0.275)	Loss 0.5207 (0.5207)	Acc@1 82.031 (82.031)	Acc@5 98.828 (98.828)
Epoch: [43][64/196]	Time 0.073 (0.070)	Data 0.000 (0.004)	Loss 0.5805 (0.4871)	Acc@1 80.469 (83.185)	Acc@5 97.656 (99.165)
Epoch: [43][128/196]	Time 0.059 (0.068)	Data 0.000 (0.002)	Loss 0.5265 (0.4849)	Acc@1 80.859 (83.188)	Acc@5 99.609 (99.198)
Epoch: [43][192/196]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5238 (0.4879)	Acc@1 80.078 (83.063)	Acc@5 98.828 (99.196)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:44/45; Lr: 0.1
batch Size 256
Epoch: [44][0/196]	Time 0.084 (0.084)	Data 0.318 (0.318)	Loss 0.4737 (0.4737)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.069 (0.067)	Data 0.000 (0.005)	Loss 0.4461 (0.4805)	Acc@1 83.203 (83.552)	Acc@5 98.438 (99.273)
Epoch: [44][128/196]	Time 0.065 (0.067)	Data 0.000 (0.003)	Loss 0.5261 (0.4788)	Acc@1 82.031 (83.530)	Acc@5 99.219 (99.270)
Epoch: [44][192/196]	Time 0.056 (0.066)	Data 0.000 (0.002)	Loss 0.5059 (0.4848)	Acc@1 82.422 (83.288)	Acc@5 99.219 (99.247)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:45/45; Lr: 0.1
batch Size 256
Epoch: [45][0/196]	Time 0.084 (0.084)	Data 0.265 (0.265)	Loss 0.3869 (0.3869)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [45][64/196]	Time 0.069 (0.067)	Data 0.000 (0.004)	Loss 0.4493 (0.4691)	Acc@1 86.328 (84.141)	Acc@5 99.219 (99.243)
Epoch: [45][128/196]	Time 0.057 (0.067)	Data 0.000 (0.002)	Loss 0.4349 (0.4782)	Acc@1 83.594 (83.566)	Acc@5 99.609 (99.210)
Epoch: [45][192/196]	Time 0.059 (0.066)	Data 0.000 (0.002)	Loss 0.4292 (0.4821)	Acc@1 83.594 (83.426)	Acc@5 99.609 (99.172)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  78.21
Max memory: 33.0690048
 13.298s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2268
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.0665088
lr: 0.1
1
Epoche:46/50; Lr: 0.1
batch Size 256
Epoch: [46][0/196]	Time 0.141 (0.141)	Data 0.379 (0.379)	Loss 0.3290 (0.3290)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.072 (0.068)	Data 0.000 (0.006)	Loss 0.4022 (0.4660)	Acc@1 87.891 (84.002)	Acc@5 99.219 (99.189)
Epoch: [46][128/196]	Time 0.066 (0.065)	Data 0.000 (0.003)	Loss 0.5470 (0.4732)	Acc@1 80.469 (83.772)	Acc@5 100.000 (99.240)
Epoch: [46][192/196]	Time 0.059 (0.064)	Data 0.000 (0.002)	Loss 0.4486 (0.4785)	Acc@1 85.156 (83.533)	Acc@5 99.219 (99.190)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:47/50; Lr: 0.1
batch Size 256
Epoch: [47][0/196]	Time 0.094 (0.094)	Data 0.350 (0.350)	Loss 0.3663 (0.3663)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.082 (0.066)	Data 0.000 (0.006)	Loss 0.4614 (0.4773)	Acc@1 85.156 (83.498)	Acc@5 100.000 (99.231)
Epoch: [47][128/196]	Time 0.068 (0.064)	Data 0.000 (0.003)	Loss 0.5558 (0.4753)	Acc@1 80.078 (83.609)	Acc@5 98.828 (99.201)
Epoch: [47][192/196]	Time 0.053 (0.065)	Data 0.000 (0.002)	Loss 0.5043 (0.4783)	Acc@1 81.250 (83.503)	Acc@5 99.609 (99.243)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:48/50; Lr: 0.1
batch Size 256
Epoch: [48][0/196]	Time 0.097 (0.097)	Data 0.337 (0.337)	Loss 0.4159 (0.4159)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [48][64/196]	Time 0.071 (0.066)	Data 0.000 (0.005)	Loss 0.5490 (0.4733)	Acc@1 81.641 (83.456)	Acc@5 98.828 (99.387)
Epoch: [48][128/196]	Time 0.082 (0.067)	Data 0.000 (0.003)	Loss 0.5573 (0.4755)	Acc@1 79.297 (83.252)	Acc@5 99.219 (99.279)
Epoch: [48][192/196]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.5239 (0.4787)	Acc@1 82.812 (83.341)	Acc@5 99.219 (99.247)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:49/50; Lr: 0.1
batch Size 256
Epoch: [49][0/196]	Time 0.095 (0.095)	Data 0.345 (0.345)	Loss 0.4543 (0.4543)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [49][64/196]	Time 0.059 (0.067)	Data 0.000 (0.006)	Loss 0.3435 (0.4805)	Acc@1 89.844 (83.365)	Acc@5 98.828 (99.267)
Epoch: [49][128/196]	Time 0.060 (0.066)	Data 0.000 (0.003)	Loss 0.5266 (0.4768)	Acc@1 80.859 (83.391)	Acc@5 98.828 (99.234)
Epoch: [49][192/196]	Time 0.060 (0.066)	Data 0.000 (0.002)	Loss 0.4067 (0.4764)	Acc@1 85.156 (83.466)	Acc@5 100.000 (99.255)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:50/50; Lr: 0.1
batch Size 256
Epoch: [50][0/196]	Time 0.083 (0.083)	Data 0.288 (0.288)	Loss 0.4835 (0.4835)	Acc@1 80.078 (80.078)	Acc@5 98.828 (98.828)
Epoch: [50][64/196]	Time 0.067 (0.068)	Data 0.000 (0.005)	Loss 0.5036 (0.4763)	Acc@1 83.594 (83.612)	Acc@5 98.828 (99.177)
Epoch: [50][128/196]	Time 0.070 (0.067)	Data 0.000 (0.002)	Loss 0.4744 (0.4818)	Acc@1 81.641 (83.273)	Acc@5 99.609 (99.164)
Epoch: [50][192/196]	Time 0.055 (0.065)	Data 0.000 (0.002)	Loss 0.4685 (0.4824)	Acc@1 81.250 (83.240)	Acc@5 99.609 (99.213)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  74.96
Max memory: 33.0690048
 13.138s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8558
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.0665088
lr: 0.1
1
Epoche:51/55; Lr: 0.1
batch Size 256
Epoch: [51][0/196]	Time 0.117 (0.117)	Data 0.357 (0.357)	Loss 0.4501 (0.4501)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [51][64/196]	Time 0.062 (0.069)	Data 0.000 (0.006)	Loss 0.4731 (0.4608)	Acc@1 83.594 (84.117)	Acc@5 100.000 (99.231)
Epoch: [51][128/196]	Time 0.057 (0.068)	Data 0.000 (0.003)	Loss 0.4059 (0.4684)	Acc@1 86.719 (83.821)	Acc@5 99.219 (99.252)
Epoch: [51][192/196]	Time 0.062 (0.068)	Data 0.000 (0.002)	Loss 0.5090 (0.4695)	Acc@1 83.594 (83.814)	Acc@5 100.000 (99.263)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:52/55; Lr: 0.1
batch Size 256
Epoch: [52][0/196]	Time 0.104 (0.104)	Data 0.340 (0.340)	Loss 0.4525 (0.4525)	Acc@1 85.547 (85.547)	Acc@5 98.438 (98.438)
Epoch: [52][64/196]	Time 0.063 (0.068)	Data 0.000 (0.005)	Loss 0.4866 (0.4597)	Acc@1 81.641 (84.087)	Acc@5 99.219 (99.351)
Epoch: [52][128/196]	Time 0.065 (0.068)	Data 0.000 (0.003)	Loss 0.4155 (0.4682)	Acc@1 87.500 (83.748)	Acc@5 99.219 (99.331)
Epoch: [52][192/196]	Time 0.071 (0.068)	Data 0.000 (0.002)	Loss 0.4250 (0.4699)	Acc@1 85.156 (83.721)	Acc@5 99.609 (99.302)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:53/55; Lr: 0.1
batch Size 256
Epoch: [53][0/196]	Time 0.085 (0.085)	Data 0.352 (0.352)	Loss 0.5006 (0.5006)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.078 (0.068)	Data 0.000 (0.006)	Loss 0.4520 (0.4679)	Acc@1 83.594 (83.546)	Acc@5 98.828 (99.237)
Epoch: [53][128/196]	Time 0.062 (0.067)	Data 0.000 (0.003)	Loss 0.4983 (0.4743)	Acc@1 84.375 (83.563)	Acc@5 99.219 (99.243)
Epoch: [53][192/196]	Time 0.057 (0.066)	Data 0.000 (0.002)	Loss 0.4427 (0.4777)	Acc@1 83.203 (83.448)	Acc@5 99.219 (99.213)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:54/55; Lr: 0.1
batch Size 256
Epoch: [54][0/196]	Time 0.098 (0.098)	Data 0.302 (0.302)	Loss 0.4430 (0.4430)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [54][64/196]	Time 0.055 (0.067)	Data 0.000 (0.005)	Loss 0.4267 (0.4770)	Acc@1 84.766 (83.504)	Acc@5 98.828 (99.243)
Epoch: [54][128/196]	Time 0.061 (0.066)	Data 0.000 (0.003)	Loss 0.5110 (0.4712)	Acc@1 81.250 (83.797)	Acc@5 100.000 (99.201)
Epoch: [54][192/196]	Time 0.058 (0.065)	Data 0.000 (0.002)	Loss 0.4705 (0.4764)	Acc@1 82.812 (83.545)	Acc@5 99.219 (99.247)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:55/55; Lr: 0.1
batch Size 256
Epoch: [55][0/196]	Time 0.076 (0.076)	Data 0.347 (0.347)	Loss 0.4761 (0.4761)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.063 (0.069)	Data 0.000 (0.006)	Loss 0.4640 (0.4729)	Acc@1 84.375 (83.618)	Acc@5 100.000 (99.279)
Epoch: [55][128/196]	Time 0.059 (0.068)	Data 0.000 (0.003)	Loss 0.5093 (0.4689)	Acc@1 83.203 (83.772)	Acc@5 99.609 (99.249)
Epoch: [55][192/196]	Time 0.059 (0.067)	Data 0.000 (0.002)	Loss 0.4834 (0.4674)	Acc@1 83.594 (83.920)	Acc@5 98.438 (99.259)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  77.13
Max memory: 33.0690048
 13.550s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6641
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.0665088
lr: 0.1
1
Epoche:56/60; Lr: 0.1
batch Size 256
Epoch: [56][0/196]	Time 0.115 (0.115)	Data 0.298 (0.298)	Loss 0.4441 (0.4441)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.064 (0.069)	Data 0.000 (0.005)	Loss 0.4550 (0.4522)	Acc@1 85.547 (84.249)	Acc@5 99.219 (99.255)
Epoch: [56][128/196]	Time 0.062 (0.068)	Data 0.000 (0.003)	Loss 0.4193 (0.4620)	Acc@1 86.719 (83.972)	Acc@5 98.828 (99.240)
Epoch: [56][192/196]	Time 0.069 (0.068)	Data 0.000 (0.002)	Loss 0.4697 (0.4668)	Acc@1 84.375 (83.859)	Acc@5 100.000 (99.257)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:57/60; Lr: 0.1
batch Size 256
Epoch: [57][0/196]	Time 0.099 (0.099)	Data 0.329 (0.329)	Loss 0.4588 (0.4588)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.060 (0.068)	Data 0.000 (0.005)	Loss 0.5086 (0.4642)	Acc@1 83.203 (83.744)	Acc@5 99.609 (99.321)
Epoch: [57][128/196]	Time 0.061 (0.067)	Data 0.000 (0.003)	Loss 0.4398 (0.4630)	Acc@1 85.547 (83.954)	Acc@5 99.609 (99.319)
Epoch: [57][192/196]	Time 0.057 (0.066)	Data 0.000 (0.002)	Loss 0.4917 (0.4673)	Acc@1 85.547 (83.851)	Acc@5 98.438 (99.306)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:58/60; Lr: 0.1
batch Size 256
Epoch: [58][0/196]	Time 0.089 (0.089)	Data 0.320 (0.320)	Loss 0.4360 (0.4360)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [58][64/196]	Time 0.067 (0.067)	Data 0.000 (0.005)	Loss 0.4306 (0.4663)	Acc@1 86.719 (83.786)	Acc@5 98.438 (99.333)
Epoch: [58][128/196]	Time 0.063 (0.067)	Data 0.000 (0.003)	Loss 0.4927 (0.4688)	Acc@1 81.641 (83.633)	Acc@5 99.609 (99.288)
Epoch: [58][192/196]	Time 0.067 (0.066)	Data 0.000 (0.002)	Loss 0.5209 (0.4660)	Acc@1 78.125 (83.784)	Acc@5 99.219 (99.269)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:59/60; Lr: 0.1
batch Size 256
Epoch: [59][0/196]	Time 0.091 (0.091)	Data 0.377 (0.377)	Loss 0.4468 (0.4468)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [59][64/196]	Time 0.081 (0.067)	Data 0.000 (0.006)	Loss 0.4552 (0.4520)	Acc@1 83.594 (84.537)	Acc@5 98.828 (99.411)
Epoch: [59][128/196]	Time 0.060 (0.066)	Data 0.000 (0.003)	Loss 0.5738 (0.4606)	Acc@1 81.250 (84.227)	Acc@5 98.438 (99.346)
Epoch: [59][192/196]	Time 0.056 (0.066)	Data 0.000 (0.002)	Loss 0.4446 (0.4604)	Acc@1 82.812 (84.169)	Acc@5 100.000 (99.334)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:60/60; Lr: 0.1
batch Size 256
Epoch: [60][0/196]	Time 0.084 (0.084)	Data 0.359 (0.359)	Loss 0.4518 (0.4518)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [60][64/196]	Time 0.058 (0.068)	Data 0.000 (0.006)	Loss 0.4361 (0.4618)	Acc@1 84.375 (83.828)	Acc@5 99.609 (99.255)
Epoch: [60][128/196]	Time 0.070 (0.068)	Data 0.000 (0.003)	Loss 0.5086 (0.4713)	Acc@1 81.641 (83.570)	Acc@5 99.219 (99.207)
Epoch: [60][192/196]	Time 0.057 (0.068)	Data 0.000 (0.002)	Loss 0.5214 (0.4719)	Acc@1 82.031 (83.626)	Acc@5 98.828 (99.223)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  75.4
Max memory: 33.0690048
 13.662s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1617
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.0665088
lr: 0.1
1
Epoche:61/65; Lr: 0.1
batch Size 256
Epoch: [61][0/196]	Time 0.108 (0.108)	Data 0.345 (0.345)	Loss 0.4392 (0.4392)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [61][64/196]	Time 0.067 (0.069)	Data 0.000 (0.005)	Loss 0.4840 (0.4335)	Acc@1 80.859 (85.078)	Acc@5 99.219 (99.285)
Epoch: [61][128/196]	Time 0.070 (0.068)	Data 0.000 (0.003)	Loss 0.4333 (0.4471)	Acc@1 84.766 (84.747)	Acc@5 99.609 (99.325)
Epoch: [61][192/196]	Time 0.058 (0.066)	Data 0.000 (0.002)	Loss 0.4535 (0.4526)	Acc@1 84.766 (84.476)	Acc@5 98.047 (99.275)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:62/65; Lr: 0.1
batch Size 256
Epoch: [62][0/196]	Time 0.088 (0.088)	Data 0.314 (0.314)	Loss 0.4088 (0.4088)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [62][64/196]	Time 0.071 (0.069)	Data 0.000 (0.005)	Loss 0.4727 (0.4490)	Acc@1 84.375 (84.621)	Acc@5 99.609 (99.225)
Epoch: [62][128/196]	Time 0.076 (0.067)	Data 0.000 (0.003)	Loss 0.4476 (0.4547)	Acc@1 83.984 (84.336)	Acc@5 99.609 (99.282)
Epoch: [62][192/196]	Time 0.072 (0.066)	Data 0.000 (0.002)	Loss 0.5148 (0.4593)	Acc@1 81.250 (84.215)	Acc@5 99.219 (99.245)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:63/65; Lr: 0.1
batch Size 256
Epoch: [63][0/196]	Time 0.091 (0.091)	Data 0.323 (0.323)	Loss 0.4303 (0.4303)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [63][64/196]	Time 0.072 (0.067)	Data 0.000 (0.005)	Loss 0.4354 (0.4558)	Acc@1 83.984 (84.417)	Acc@5 99.609 (99.315)
Epoch: [63][128/196]	Time 0.065 (0.067)	Data 0.000 (0.003)	Loss 0.4672 (0.4604)	Acc@1 84.766 (84.230)	Acc@5 99.219 (99.288)
Epoch: [63][192/196]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5194 (0.4605)	Acc@1 84.375 (84.231)	Acc@5 98.828 (99.306)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:64/65; Lr: 0.1
batch Size 256
Epoch: [64][0/196]	Time 0.092 (0.092)	Data 0.341 (0.341)	Loss 0.4441 (0.4441)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.068 (0.069)	Data 0.000 (0.005)	Loss 0.5081 (0.4489)	Acc@1 82.031 (84.453)	Acc@5 99.219 (99.267)
Epoch: [64][128/196]	Time 0.073 (0.068)	Data 0.000 (0.003)	Loss 0.4594 (0.4540)	Acc@1 83.984 (84.342)	Acc@5 99.219 (99.261)
Epoch: [64][192/196]	Time 0.070 (0.068)	Data 0.000 (0.002)	Loss 0.4558 (0.4582)	Acc@1 82.422 (84.278)	Acc@5 100.000 (99.284)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:65/65; Lr: 0.1
batch Size 256
Epoch: [65][0/196]	Time 0.082 (0.082)	Data 0.289 (0.289)	Loss 0.4153 (0.4153)	Acc@1 85.547 (85.547)	Acc@5 98.828 (98.828)
Epoch: [65][64/196]	Time 0.070 (0.068)	Data 0.000 (0.005)	Loss 0.4630 (0.4483)	Acc@1 83.203 (84.537)	Acc@5 100.000 (99.267)
Epoch: [65][128/196]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.5472 (0.4585)	Acc@1 79.688 (84.184)	Acc@5 98.828 (99.279)
Epoch: [65][192/196]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4038 (0.4633)	Acc@1 85.547 (84.051)	Acc@5 99.609 (99.257)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  75.71
Max memory: 33.0690048
 13.543s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 115
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.0665088
lr: 0.1
1
Epoche:66/70; Lr: 0.1
batch Size 256
Epoch: [66][0/196]	Time 0.130 (0.130)	Data 0.347 (0.347)	Loss 0.4509 (0.4509)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.062 (0.069)	Data 0.000 (0.006)	Loss 0.5262 (0.4338)	Acc@1 82.031 (85.349)	Acc@5 99.609 (99.363)
Epoch: [66][128/196]	Time 0.069 (0.067)	Data 0.000 (0.003)	Loss 0.5054 (0.4421)	Acc@1 82.812 (85.014)	Acc@5 99.219 (99.337)
Epoch: [66][192/196]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.5204 (0.4535)	Acc@1 81.641 (84.505)	Acc@5 98.828 (99.288)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:67/70; Lr: 0.1
batch Size 256
Epoch: [67][0/196]	Time 0.091 (0.091)	Data 0.356 (0.356)	Loss 0.4398 (0.4398)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.070 (0.068)	Data 0.000 (0.006)	Loss 0.4218 (0.4547)	Acc@1 85.156 (84.327)	Acc@5 99.219 (99.309)
Epoch: [67][128/196]	Time 0.057 (0.067)	Data 0.000 (0.003)	Loss 0.4565 (0.4573)	Acc@1 86.719 (84.351)	Acc@5 100.000 (99.261)
Epoch: [67][192/196]	Time 0.056 (0.063)	Data 0.000 (0.002)	Loss 0.5304 (0.4630)	Acc@1 81.641 (84.092)	Acc@5 98.438 (99.245)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:68/70; Lr: 0.1
batch Size 256
Epoch: [68][0/196]	Time 0.068 (0.068)	Data 0.311 (0.311)	Loss 0.3567 (0.3567)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [68][64/196]	Time 0.070 (0.065)	Data 0.000 (0.005)	Loss 0.3934 (0.4494)	Acc@1 85.547 (84.489)	Acc@5 100.000 (99.309)
Epoch: [68][128/196]	Time 0.065 (0.066)	Data 0.000 (0.003)	Loss 0.6132 (0.4578)	Acc@1 77.344 (84.172)	Acc@5 98.438 (99.291)
Epoch: [68][192/196]	Time 0.060 (0.066)	Data 0.000 (0.002)	Loss 0.4857 (0.4526)	Acc@1 83.984 (84.294)	Acc@5 99.609 (99.324)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:69/70; Lr: 0.1
batch Size 256
Epoch: [69][0/196]	Time 0.099 (0.099)	Data 0.336 (0.336)	Loss 0.5163 (0.5163)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.062 (0.069)	Data 0.000 (0.005)	Loss 0.4300 (0.4600)	Acc@1 84.766 (84.099)	Acc@5 99.219 (99.189)
Epoch: [69][128/196]	Time 0.067 (0.067)	Data 0.000 (0.003)	Loss 0.3860 (0.4576)	Acc@1 84.375 (83.963)	Acc@5 100.000 (99.291)
Epoch: [69][192/196]	Time 0.060 (0.066)	Data 0.000 (0.002)	Loss 0.4023 (0.4585)	Acc@1 87.891 (83.966)	Acc@5 98.828 (99.292)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:70/70; Lr: 0.1
batch Size 256
Epoch: [70][0/196]	Time 0.105 (0.105)	Data 0.341 (0.341)	Loss 0.4707 (0.4707)	Acc@1 83.203 (83.203)	Acc@5 98.438 (98.438)
Epoch: [70][64/196]	Time 0.061 (0.067)	Data 0.000 (0.005)	Loss 0.4895 (0.4627)	Acc@1 82.812 (83.732)	Acc@5 100.000 (99.255)
Epoch: [70][128/196]	Time 0.060 (0.067)	Data 0.000 (0.003)	Loss 0.4251 (0.4595)	Acc@1 86.719 (83.981)	Acc@5 99.609 (99.307)
Epoch: [70][192/196]	Time 0.057 (0.067)	Data 0.000 (0.002)	Loss 0.4368 (0.4598)	Acc@1 83.203 (84.021)	Acc@5 99.609 (99.310)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  74.87
Max memory: 33.0690048
 13.500s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6169
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.0665088
lr: 0.1
1
Epoche:71/75; Lr: 0.1
batch Size 256
Epoch: [71][0/196]	Time 0.135 (0.135)	Data 0.366 (0.366)	Loss 0.4582 (0.4582)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [71][64/196]	Time 0.070 (0.068)	Data 0.000 (0.006)	Loss 0.3855 (0.4391)	Acc@1 87.500 (84.880)	Acc@5 99.219 (99.369)
Epoch: [71][128/196]	Time 0.065 (0.067)	Data 0.000 (0.003)	Loss 0.4078 (0.4425)	Acc@1 87.891 (84.675)	Acc@5 99.219 (99.373)
Epoch: [71][192/196]	Time 0.055 (0.067)	Data 0.000 (0.002)	Loss 0.3805 (0.4508)	Acc@1 88.281 (84.484)	Acc@5 99.219 (99.304)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:72/75; Lr: 0.1
batch Size 256
Epoch: [72][0/196]	Time 0.095 (0.095)	Data 0.372 (0.372)	Loss 0.4287 (0.4287)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.068 (0.068)	Data 0.000 (0.006)	Loss 0.3744 (0.4473)	Acc@1 87.109 (84.429)	Acc@5 100.000 (99.429)
Epoch: [72][128/196]	Time 0.059 (0.067)	Data 0.000 (0.003)	Loss 0.4835 (0.4586)	Acc@1 83.203 (84.157)	Acc@5 99.609 (99.340)
Epoch: [72][192/196]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.4935 (0.4585)	Acc@1 84.766 (84.207)	Acc@5 98.438 (99.332)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:73/75; Lr: 0.1
batch Size 256
Epoch: [73][0/196]	Time 0.092 (0.092)	Data 0.376 (0.376)	Loss 0.4393 (0.4393)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [73][64/196]	Time 0.070 (0.066)	Data 0.000 (0.006)	Loss 0.4621 (0.4467)	Acc@1 86.328 (84.700)	Acc@5 97.656 (99.339)
Epoch: [73][128/196]	Time 0.056 (0.065)	Data 0.000 (0.003)	Loss 0.5247 (0.4482)	Acc@1 78.516 (84.617)	Acc@5 98.438 (99.319)
Epoch: [73][192/196]	Time 0.065 (0.065)	Data 0.000 (0.002)	Loss 0.4183 (0.4528)	Acc@1 87.500 (84.442)	Acc@5 99.219 (99.324)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:74/75; Lr: 0.1
batch Size 256
Epoch: [74][0/196]	Time 0.084 (0.084)	Data 0.276 (0.276)	Loss 0.4918 (0.4918)	Acc@1 80.469 (80.469)	Acc@5 99.609 (99.609)
Epoch: [74][64/196]	Time 0.061 (0.065)	Data 0.000 (0.004)	Loss 0.4027 (0.4472)	Acc@1 87.109 (84.297)	Acc@5 99.219 (99.345)
Epoch: [74][128/196]	Time 0.059 (0.065)	Data 0.000 (0.002)	Loss 0.4259 (0.4483)	Acc@1 84.766 (84.293)	Acc@5 99.219 (99.319)
Epoch: [74][192/196]	Time 0.064 (0.065)	Data 0.000 (0.002)	Loss 0.4751 (0.4556)	Acc@1 80.078 (84.130)	Acc@5 100.000 (99.294)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:75/75; Lr: 0.1
batch Size 256
Epoch: [75][0/196]	Time 0.097 (0.097)	Data 0.293 (0.293)	Loss 0.4352 (0.4352)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.061 (0.063)	Data 0.000 (0.005)	Loss 0.4534 (0.4380)	Acc@1 86.719 (84.483)	Acc@5 99.609 (99.369)
Epoch: [75][128/196]	Time 0.066 (0.064)	Data 0.000 (0.002)	Loss 0.3419 (0.4452)	Acc@1 89.062 (84.393)	Acc@5 99.609 (99.343)
Epoch: [75][192/196]	Time 0.058 (0.064)	Data 0.000 (0.002)	Loss 0.4540 (0.4514)	Acc@1 83.984 (84.247)	Acc@5 99.609 (99.312)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  73.89
Max memory: 33.0690048
 12.861s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5503
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.0665088
lr: 0.1
1
Epoche:76/80; Lr: 0.1
batch Size 256
Epoch: [76][0/196]	Time 0.108 (0.108)	Data 0.297 (0.297)	Loss 0.4418 (0.4418)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.072 (0.068)	Data 0.000 (0.005)	Loss 0.4773 (0.4228)	Acc@1 82.422 (85.433)	Acc@5 99.609 (99.363)
Epoch: [76][128/196]	Time 0.067 (0.067)	Data 0.000 (0.003)	Loss 0.4396 (0.4447)	Acc@1 85.938 (84.623)	Acc@5 99.609 (99.331)
Epoch: [76][192/196]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.3897 (0.4518)	Acc@1 86.719 (84.314)	Acc@5 100.000 (99.369)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:77/80; Lr: 0.1
batch Size 256
Epoch: [77][0/196]	Time 0.092 (0.092)	Data 0.296 (0.296)	Loss 0.3278 (0.3278)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.061 (0.067)	Data 0.000 (0.005)	Loss 0.4908 (0.4429)	Acc@1 83.984 (84.766)	Acc@5 98.828 (99.285)
Epoch: [77][128/196]	Time 0.066 (0.067)	Data 0.000 (0.003)	Loss 0.4593 (0.4552)	Acc@1 83.594 (84.345)	Acc@5 99.219 (99.288)
Epoch: [77][192/196]	Time 0.065 (0.067)	Data 0.000 (0.002)	Loss 0.4045 (0.4520)	Acc@1 88.672 (84.438)	Acc@5 100.000 (99.340)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:78/80; Lr: 0.1
batch Size 256
Epoch: [78][0/196]	Time 0.093 (0.093)	Data 0.308 (0.308)	Loss 0.3771 (0.3771)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [78][64/196]	Time 0.070 (0.068)	Data 0.000 (0.005)	Loss 0.5523 (0.4613)	Acc@1 79.688 (83.768)	Acc@5 99.609 (99.291)
Epoch: [78][128/196]	Time 0.062 (0.066)	Data 0.000 (0.003)	Loss 0.4521 (0.4543)	Acc@1 83.203 (84.033)	Acc@5 98.438 (99.307)
Epoch: [78][192/196]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.4195 (0.4548)	Acc@1 84.375 (84.211)	Acc@5 99.219 (99.300)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:79/80; Lr: 0.1
batch Size 256
Epoch: [79][0/196]	Time 0.092 (0.092)	Data 0.306 (0.306)	Loss 0.3726 (0.3726)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [79][64/196]	Time 0.064 (0.068)	Data 0.000 (0.005)	Loss 0.3766 (0.4485)	Acc@1 83.203 (84.459)	Acc@5 99.609 (99.345)
Epoch: [79][128/196]	Time 0.070 (0.068)	Data 0.000 (0.003)	Loss 0.4058 (0.4510)	Acc@1 88.281 (84.466)	Acc@5 99.219 (99.252)
Epoch: [79][192/196]	Time 0.061 (0.067)	Data 0.000 (0.002)	Loss 0.6024 (0.4532)	Acc@1 76.562 (84.357)	Acc@5 100.000 (99.269)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:80/80; Lr: 0.1
batch Size 256
Epoch: [80][0/196]	Time 0.085 (0.085)	Data 0.252 (0.252)	Loss 0.4798 (0.4798)	Acc@1 84.766 (84.766)	Acc@5 98.047 (98.047)
Epoch: [80][64/196]	Time 0.066 (0.067)	Data 0.006 (0.004)	Loss 0.5304 (0.4474)	Acc@1 83.594 (84.543)	Acc@5 99.219 (99.207)
Epoch: [80][128/196]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.4515 (0.4531)	Acc@1 83.203 (84.272)	Acc@5 100.000 (99.234)
Epoch: [80][192/196]	Time 0.058 (0.065)	Data 0.000 (0.002)	Loss 0.4893 (0.4488)	Acc@1 82.422 (84.557)	Acc@5 98.438 (99.219)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  76.62
Max memory: 33.0690048
 13.158s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3719
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.0665088
lr: 0.1
1
Epoche:81/85; Lr: 0.1
batch Size 256
Epoch: [81][0/196]	Time 0.117 (0.117)	Data 0.317 (0.317)	Loss 0.4594 (0.4594)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [81][64/196]	Time 0.070 (0.072)	Data 0.000 (0.005)	Loss 0.5206 (0.4206)	Acc@1 83.984 (85.523)	Acc@5 99.219 (99.417)
Epoch: [81][128/196]	Time 0.074 (0.070)	Data 0.000 (0.003)	Loss 0.4643 (0.4405)	Acc@1 83.984 (84.729)	Acc@5 100.000 (99.397)
Epoch: [81][192/196]	Time 0.055 (0.068)	Data 0.000 (0.002)	Loss 0.4183 (0.4491)	Acc@1 83.594 (84.393)	Acc@5 99.609 (99.381)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:82/85; Lr: 0.1
batch Size 256
Epoch: [82][0/196]	Time 0.103 (0.103)	Data 0.343 (0.343)	Loss 0.4577 (0.4577)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.067 (0.070)	Data 0.000 (0.005)	Loss 0.4444 (0.4583)	Acc@1 85.156 (84.081)	Acc@5 99.219 (99.423)
Epoch: [82][128/196]	Time 0.074 (0.070)	Data 0.000 (0.003)	Loss 0.4300 (0.4564)	Acc@1 83.594 (84.087)	Acc@5 99.219 (99.376)
Epoch: [82][192/196]	Time 0.071 (0.069)	Data 0.000 (0.002)	Loss 0.3715 (0.4562)	Acc@1 85.938 (84.179)	Acc@5 99.609 (99.318)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:83/85; Lr: 0.1
batch Size 256
Epoch: [83][0/196]	Time 0.087 (0.087)	Data 0.320 (0.320)	Loss 0.3578 (0.3578)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [83][64/196]	Time 0.067 (0.071)	Data 0.000 (0.005)	Loss 0.3478 (0.4476)	Acc@1 87.891 (84.826)	Acc@5 99.219 (99.357)
Epoch: [83][128/196]	Time 0.068 (0.069)	Data 0.000 (0.003)	Loss 0.4850 (0.4494)	Acc@1 81.641 (84.726)	Acc@5 99.219 (99.294)
Epoch: [83][192/196]	Time 0.073 (0.068)	Data 0.000 (0.002)	Loss 0.4100 (0.4516)	Acc@1 85.938 (84.668)	Acc@5 100.000 (99.318)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:84/85; Lr: 0.1
batch Size 256
Epoch: [84][0/196]	Time 0.088 (0.088)	Data 0.339 (0.339)	Loss 0.5286 (0.5286)	Acc@1 84.766 (84.766)	Acc@5 98.828 (98.828)
Epoch: [84][64/196]	Time 0.065 (0.069)	Data 0.000 (0.005)	Loss 0.4763 (0.4444)	Acc@1 83.203 (84.862)	Acc@5 99.219 (99.351)
Epoch: [84][128/196]	Time 0.065 (0.068)	Data 0.000 (0.003)	Loss 0.2682 (0.4470)	Acc@1 92.578 (84.754)	Acc@5 100.000 (99.328)
Epoch: [84][192/196]	Time 0.064 (0.068)	Data 0.000 (0.002)	Loss 0.3492 (0.4502)	Acc@1 86.719 (84.462)	Acc@5 99.219 (99.342)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:85/85; Lr: 0.1
batch Size 256
Epoch: [85][0/196]	Time 0.089 (0.089)	Data 0.332 (0.332)	Loss 0.4183 (0.4183)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.063 (0.070)	Data 0.000 (0.005)	Loss 0.4308 (0.4497)	Acc@1 87.109 (84.760)	Acc@5 99.609 (99.285)
Epoch: [85][128/196]	Time 0.061 (0.068)	Data 0.000 (0.003)	Loss 0.4335 (0.4463)	Acc@1 86.719 (84.760)	Acc@5 98.438 (99.301)
Epoch: [85][192/196]	Time 0.056 (0.066)	Data 0.000 (0.002)	Loss 0.5072 (0.4451)	Acc@1 81.250 (84.733)	Acc@5 100.000 (99.362)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  74.94
Max memory: 33.0690048
 13.350s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3599
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.0665088
lr: 0.1
1
Epoche:86/90; Lr: 0.1
batch Size 256
Epoch: [86][0/196]	Time 0.139 (0.139)	Data 0.369 (0.369)	Loss 0.6222 (0.6222)	Acc@1 80.469 (80.469)	Acc@5 98.438 (98.438)
Epoch: [86][64/196]	Time 0.067 (0.068)	Data 0.000 (0.006)	Loss 0.4352 (0.4413)	Acc@1 83.594 (84.465)	Acc@5 98.828 (99.369)
Epoch: [86][128/196]	Time 0.068 (0.068)	Data 0.000 (0.003)	Loss 0.4799 (0.4533)	Acc@1 81.641 (84.160)	Acc@5 99.219 (99.322)
Epoch: [86][192/196]	Time 0.060 (0.067)	Data 0.000 (0.002)	Loss 0.4328 (0.4536)	Acc@1 85.156 (84.205)	Acc@5 99.609 (99.330)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:87/90; Lr: 0.1
batch Size 256
Epoch: [87][0/196]	Time 0.107 (0.107)	Data 0.296 (0.296)	Loss 0.4077 (0.4077)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.070 (0.068)	Data 0.000 (0.005)	Loss 0.3886 (0.4421)	Acc@1 87.891 (84.844)	Acc@5 99.219 (99.303)
Epoch: [87][128/196]	Time 0.062 (0.067)	Data 0.000 (0.003)	Loss 0.4622 (0.4455)	Acc@1 83.984 (84.775)	Acc@5 99.219 (99.343)
Epoch: [87][192/196]	Time 0.064 (0.067)	Data 0.000 (0.002)	Loss 0.5462 (0.4500)	Acc@1 81.641 (84.529)	Acc@5 98.828 (99.312)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:88/90; Lr: 0.1
batch Size 256
Epoch: [88][0/196]	Time 0.090 (0.090)	Data 0.290 (0.290)	Loss 0.4567 (0.4567)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [88][64/196]	Time 0.061 (0.069)	Data 0.000 (0.005)	Loss 0.4146 (0.4567)	Acc@1 82.031 (84.087)	Acc@5 99.219 (99.327)
Epoch: [88][128/196]	Time 0.068 (0.067)	Data 0.000 (0.002)	Loss 0.4428 (0.4458)	Acc@1 84.375 (84.651)	Acc@5 99.219 (99.322)
Epoch: [88][192/196]	Time 0.063 (0.067)	Data 0.000 (0.002)	Loss 0.4026 (0.4441)	Acc@1 85.547 (84.677)	Acc@5 99.609 (99.332)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:89/90; Lr: 0.1
batch Size 256
Epoch: [89][0/196]	Time 0.091 (0.091)	Data 0.290 (0.290)	Loss 0.4200 (0.4200)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.066 (0.064)	Data 0.000 (0.005)	Loss 0.3675 (0.4399)	Acc@1 86.719 (84.790)	Acc@5 99.609 (99.327)
Epoch: [89][128/196]	Time 0.061 (0.065)	Data 0.000 (0.002)	Loss 0.3408 (0.4459)	Acc@1 88.281 (84.545)	Acc@5 100.000 (99.322)
Epoch: [89][192/196]	Time 0.058 (0.064)	Data 0.000 (0.002)	Loss 0.3847 (0.4467)	Acc@1 86.328 (84.531)	Acc@5 100.000 (99.324)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:90/90; Lr: 0.1
batch Size 256
Epoch: [90][0/196]	Time 0.088 (0.088)	Data 0.307 (0.307)	Loss 0.4113 (0.4113)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [90][64/196]	Time 0.066 (0.069)	Data 0.000 (0.005)	Loss 0.3991 (0.4470)	Acc@1 86.719 (84.387)	Acc@5 100.000 (99.321)
Epoch: [90][128/196]	Time 0.059 (0.068)	Data 0.000 (0.003)	Loss 0.4008 (0.4491)	Acc@1 87.109 (84.357)	Acc@5 99.609 (99.322)
Epoch: [90][192/196]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.4755 (0.4511)	Acc@1 83.594 (84.292)	Acc@5 99.219 (99.346)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  80.71
Max memory: 33.0690048
 13.552s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9660
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.0665088
lr: 0.1
1
Epoche:91/95; Lr: 0.1
batch Size 256
Epoch: [91][0/196]	Time 0.120 (0.120)	Data 0.253 (0.253)	Loss 0.4273 (0.4273)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [91][64/196]	Time 0.064 (0.064)	Data 0.000 (0.004)	Loss 0.3250 (0.4240)	Acc@1 87.500 (85.433)	Acc@5 99.219 (99.417)
Epoch: [91][128/196]	Time 0.087 (0.066)	Data 0.000 (0.002)	Loss 0.4463 (0.4387)	Acc@1 83.594 (84.893)	Acc@5 99.609 (99.331)
Epoch: [91][192/196]	Time 0.065 (0.066)	Data 0.000 (0.002)	Loss 0.3802 (0.4407)	Acc@1 86.719 (84.826)	Acc@5 100.000 (99.338)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:92/95; Lr: 0.1
batch Size 256
Epoch: [92][0/196]	Time 0.091 (0.091)	Data 0.343 (0.343)	Loss 0.5446 (0.5446)	Acc@1 79.688 (79.688)	Acc@5 99.219 (99.219)
Epoch: [92][64/196]	Time 0.061 (0.069)	Data 0.000 (0.006)	Loss 0.4098 (0.4422)	Acc@1 84.375 (84.663)	Acc@5 99.609 (99.303)
Epoch: [92][128/196]	Time 0.062 (0.068)	Data 0.000 (0.003)	Loss 0.4196 (0.4453)	Acc@1 84.766 (84.493)	Acc@5 100.000 (99.325)
Epoch: [92][192/196]	Time 0.058 (0.067)	Data 0.000 (0.002)	Loss 0.3445 (0.4521)	Acc@1 90.234 (84.377)	Acc@5 99.609 (99.290)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:93/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [93][0/196]	Time 0.083 (0.083)	Data 0.330 (0.330)	Loss 0.4105 (0.4105)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.063 (0.068)	Data 0.000 (0.005)	Loss 0.3774 (0.3779)	Acc@1 87.109 (86.779)	Acc@5 99.609 (99.507)
Epoch: [93][128/196]	Time 0.063 (0.068)	Data 0.000 (0.003)	Loss 0.3549 (0.3541)	Acc@1 87.891 (87.727)	Acc@5 100.000 (99.618)
Epoch: [93][192/196]	Time 0.058 (0.068)	Data 0.000 (0.002)	Loss 0.2961 (0.3399)	Acc@1 89.453 (88.255)	Acc@5 99.609 (99.624)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:94/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [94][0/196]	Time 0.088 (0.088)	Data 0.313 (0.313)	Loss 0.3276 (0.3276)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.066 (0.068)	Data 0.000 (0.005)	Loss 0.2791 (0.3091)	Acc@1 89.453 (89.423)	Acc@5 100.000 (99.718)
Epoch: [94][128/196]	Time 0.058 (0.068)	Data 0.000 (0.003)	Loss 0.2828 (0.3034)	Acc@1 89.062 (89.777)	Acc@5 100.000 (99.706)
Epoch: [94][192/196]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2972 (0.3011)	Acc@1 87.891 (89.767)	Acc@5 99.609 (99.700)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:95/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [95][0/196]	Time 0.083 (0.083)	Data 0.384 (0.384)	Loss 0.2846 (0.2846)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.067 (0.069)	Data 0.000 (0.006)	Loss 0.3312 (0.2928)	Acc@1 89.062 (90.060)	Acc@5 100.000 (99.639)
Epoch: [95][128/196]	Time 0.064 (0.068)	Data 0.000 (0.003)	Loss 0.3696 (0.2925)	Acc@1 88.281 (89.916)	Acc@5 99.219 (99.652)
Epoch: [95][192/196]	Time 0.057 (0.067)	Data 0.000 (0.002)	Loss 0.2503 (0.2888)	Acc@1 90.625 (90.028)	Acc@5 99.609 (99.664)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.15
Max memory: 33.0690048
 13.630s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2567
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:96/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [96][0/196]	Time 0.118 (0.118)	Data 0.346 (0.346)	Loss 0.2347 (0.2347)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.067 (0.068)	Data 0.000 (0.006)	Loss 0.2290 (0.2720)	Acc@1 91.406 (90.956)	Acc@5 100.000 (99.802)
Epoch: [96][128/196]	Time 0.060 (0.066)	Data 0.000 (0.003)	Loss 0.2907 (0.2778)	Acc@1 90.234 (90.561)	Acc@5 99.609 (99.764)
Epoch: [96][192/196]	Time 0.056 (0.065)	Data 0.000 (0.002)	Loss 0.2507 (0.2774)	Acc@1 92.188 (90.582)	Acc@5 99.219 (99.727)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:97/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [97][0/196]	Time 0.087 (0.087)	Data 0.299 (0.299)	Loss 0.2561 (0.2561)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.071 (0.069)	Data 0.000 (0.005)	Loss 0.2750 (0.2630)	Acc@1 91.016 (91.076)	Acc@5 99.609 (99.772)
Epoch: [97][128/196]	Time 0.058 (0.069)	Data 0.000 (0.003)	Loss 0.2684 (0.2689)	Acc@1 92.188 (90.752)	Acc@5 99.609 (99.761)
Epoch: [97][192/196]	Time 0.066 (0.067)	Data 0.000 (0.002)	Loss 0.2977 (0.2728)	Acc@1 89.844 (90.680)	Acc@5 98.828 (99.757)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:98/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [98][0/196]	Time 0.085 (0.085)	Data 0.318 (0.318)	Loss 0.2219 (0.2219)	Acc@1 92.188 (92.188)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.064 (0.066)	Data 0.000 (0.005)	Loss 0.2688 (0.2680)	Acc@1 88.672 (90.757)	Acc@5 100.000 (99.784)
Epoch: [98][128/196]	Time 0.077 (0.066)	Data 0.000 (0.003)	Loss 0.3174 (0.2668)	Acc@1 89.453 (90.849)	Acc@5 99.219 (99.752)
Epoch: [98][192/196]	Time 0.064 (0.065)	Data 0.000 (0.002)	Loss 0.3242 (0.2672)	Acc@1 89.453 (90.789)	Acc@5 99.609 (99.767)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:99/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [99][0/196]	Time 0.086 (0.086)	Data 0.339 (0.339)	Loss 0.2188 (0.2188)	Acc@1 91.797 (91.797)	Acc@5 99.219 (99.219)
Epoch: [99][64/196]	Time 0.066 (0.067)	Data 0.000 (0.005)	Loss 0.2586 (0.2617)	Acc@1 91.406 (90.974)	Acc@5 99.609 (99.754)
Epoch: [99][128/196]	Time 0.059 (0.066)	Data 0.000 (0.003)	Loss 0.2675 (0.2621)	Acc@1 91.016 (91.085)	Acc@5 99.609 (99.764)
Epoch: [99][192/196]	Time 0.061 (0.066)	Data 0.000 (0.002)	Loss 0.2241 (0.2612)	Acc@1 92.578 (91.052)	Acc@5 99.609 (99.769)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:100/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [100][0/196]	Time 0.075 (0.075)	Data 0.304 (0.304)	Loss 0.2535 (0.2535)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.068 (0.067)	Data 0.000 (0.005)	Loss 0.1875 (0.2514)	Acc@1 94.922 (91.274)	Acc@5 99.609 (99.802)
Epoch: [100][128/196]	Time 0.067 (0.066)	Data 0.000 (0.003)	Loss 0.2503 (0.2565)	Acc@1 91.406 (91.131)	Acc@5 100.000 (99.773)
Epoch: [100][192/196]	Time 0.060 (0.066)	Data 0.000 (0.002)	Loss 0.2286 (0.2583)	Acc@1 92.578 (91.070)	Acc@5 99.609 (99.781)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.07
Max memory: 33.0690048
 13.288s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6067
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:101/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [101][0/196]	Time 0.114 (0.114)	Data 0.301 (0.301)	Loss 0.2060 (0.2060)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [101][64/196]	Time 0.062 (0.069)	Data 0.000 (0.005)	Loss 0.2382 (0.2604)	Acc@1 91.016 (90.944)	Acc@5 100.000 (99.790)
Epoch: [101][128/196]	Time 0.058 (0.067)	Data 0.000 (0.003)	Loss 0.2799 (0.2542)	Acc@1 90.234 (91.170)	Acc@5 100.000 (99.785)
Epoch: [101][192/196]	Time 0.063 (0.066)	Data 0.000 (0.002)	Loss 0.3137 (0.2558)	Acc@1 90.234 (91.176)	Acc@5 99.609 (99.765)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:102/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [102][0/196]	Time 0.107 (0.107)	Data 0.314 (0.314)	Loss 0.2485 (0.2485)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.059 (0.070)	Data 0.000 (0.005)	Loss 0.2569 (0.2420)	Acc@1 92.969 (91.743)	Acc@5 99.609 (99.748)
Epoch: [102][128/196]	Time 0.077 (0.069)	Data 0.000 (0.003)	Loss 0.2807 (0.2464)	Acc@1 90.234 (91.485)	Acc@5 99.609 (99.752)
Epoch: [102][192/196]	Time 0.054 (0.066)	Data 0.000 (0.002)	Loss 0.2677 (0.2495)	Acc@1 90.625 (91.473)	Acc@5 100.000 (99.749)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:103/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [103][0/196]	Time 0.066 (0.066)	Data 0.264 (0.264)	Loss 0.2125 (0.2125)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.068 (0.062)	Data 0.000 (0.004)	Loss 0.1967 (0.2462)	Acc@1 93.359 (91.382)	Acc@5 100.000 (99.778)
Epoch: [103][128/196]	Time 0.067 (0.065)	Data 0.000 (0.002)	Loss 0.3240 (0.2522)	Acc@1 87.891 (91.188)	Acc@5 99.609 (99.782)
Epoch: [103][192/196]	Time 0.075 (0.066)	Data 0.000 (0.002)	Loss 0.2310 (0.2533)	Acc@1 91.406 (91.184)	Acc@5 99.609 (99.781)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:104/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [104][0/196]	Time 0.085 (0.085)	Data 0.342 (0.342)	Loss 0.3258 (0.3258)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.066 (0.068)	Data 0.000 (0.005)	Loss 0.3219 (0.2377)	Acc@1 87.891 (91.893)	Acc@5 99.609 (99.826)
Epoch: [104][128/196]	Time 0.067 (0.067)	Data 0.000 (0.003)	Loss 0.2464 (0.2465)	Acc@1 91.797 (91.549)	Acc@5 99.609 (99.815)
Epoch: [104][192/196]	Time 0.057 (0.066)	Data 0.000 (0.002)	Loss 0.2270 (0.2474)	Acc@1 92.969 (91.524)	Acc@5 99.609 (99.796)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:105/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [105][0/196]	Time 0.087 (0.087)	Data 0.318 (0.318)	Loss 0.2276 (0.2276)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [105][64/196]	Time 0.065 (0.069)	Data 0.000 (0.005)	Loss 0.2292 (0.2388)	Acc@1 90.234 (91.701)	Acc@5 100.000 (99.814)
Epoch: [105][128/196]	Time 0.066 (0.067)	Data 0.000 (0.003)	Loss 0.2429 (0.2443)	Acc@1 89.844 (91.530)	Acc@5 100.000 (99.770)
Epoch: [105][192/196]	Time 0.072 (0.067)	Data 0.000 (0.002)	Loss 0.3113 (0.2451)	Acc@1 88.281 (91.437)	Acc@5 100.000 (99.773)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.44
Max memory: 33.0690048
 13.509s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7699
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:106/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [106][0/196]	Time 0.110 (0.110)	Data 0.397 (0.397)	Loss 0.2063 (0.2063)	Acc@1 94.922 (94.922)	Acc@5 99.219 (99.219)
Epoch: [106][64/196]	Time 0.074 (0.068)	Data 0.000 (0.006)	Loss 0.2515 (0.2389)	Acc@1 91.797 (91.923)	Acc@5 99.609 (99.712)
Epoch: [106][128/196]	Time 0.061 (0.067)	Data 0.000 (0.003)	Loss 0.2240 (0.2405)	Acc@1 90.234 (91.754)	Acc@5 99.609 (99.761)
Epoch: [106][192/196]	Time 0.068 (0.067)	Data 0.000 (0.002)	Loss 0.3043 (0.2421)	Acc@1 89.844 (91.694)	Acc@5 100.000 (99.771)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:107/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [107][0/196]	Time 0.089 (0.089)	Data 0.363 (0.363)	Loss 0.2424 (0.2424)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [107][64/196]	Time 0.069 (0.068)	Data 0.000 (0.006)	Loss 0.2260 (0.2430)	Acc@1 92.188 (91.731)	Acc@5 100.000 (99.790)
Epoch: [107][128/196]	Time 0.067 (0.067)	Data 0.000 (0.003)	Loss 0.2612 (0.2405)	Acc@1 92.969 (91.773)	Acc@5 100.000 (99.797)
Epoch: [107][192/196]	Time 0.064 (0.066)	Data 0.000 (0.002)	Loss 0.2721 (0.2428)	Acc@1 90.234 (91.609)	Acc@5 99.219 (99.767)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:108/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [108][0/196]	Time 0.089 (0.089)	Data 0.293 (0.293)	Loss 0.2621 (0.2621)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [108][64/196]	Time 0.058 (0.068)	Data 0.000 (0.005)	Loss 0.2544 (0.2331)	Acc@1 89.453 (91.983)	Acc@5 100.000 (99.778)
Epoch: [108][128/196]	Time 0.073 (0.067)	Data 0.000 (0.002)	Loss 0.2915 (0.2381)	Acc@1 90.625 (91.736)	Acc@5 99.219 (99.782)
Epoch: [108][192/196]	Time 0.062 (0.066)	Data 0.000 (0.002)	Loss 0.2743 (0.2416)	Acc@1 91.016 (91.635)	Acc@5 100.000 (99.796)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:109/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [109][0/196]	Time 0.065 (0.065)	Data 0.290 (0.290)	Loss 0.2517 (0.2517)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.068 (0.063)	Data 0.000 (0.005)	Loss 0.2394 (0.2310)	Acc@1 91.406 (92.103)	Acc@5 100.000 (99.832)
Epoch: [109][128/196]	Time 0.066 (0.065)	Data 0.000 (0.002)	Loss 0.2531 (0.2377)	Acc@1 91.016 (91.876)	Acc@5 100.000 (99.800)
Epoch: [109][192/196]	Time 0.065 (0.065)	Data 0.000 (0.002)	Loss 0.2534 (0.2393)	Acc@1 91.016 (91.746)	Acc@5 99.609 (99.787)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:110/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [110][0/196]	Time 0.088 (0.088)	Data 0.318 (0.318)	Loss 0.2440 (0.2440)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.060 (0.065)	Data 0.000 (0.005)	Loss 0.2364 (0.2272)	Acc@1 91.406 (91.953)	Acc@5 99.609 (99.886)
Epoch: [110][128/196]	Time 0.061 (0.064)	Data 0.000 (0.003)	Loss 0.2539 (0.2299)	Acc@1 91.406 (91.973)	Acc@5 100.000 (99.870)
Epoch: [110][192/196]	Time 0.066 (0.065)	Data 0.000 (0.002)	Loss 0.2871 (0.2336)	Acc@1 90.234 (91.876)	Acc@5 99.609 (99.840)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.37
Max memory: 33.0690048
 13.074s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7674
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:111/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [111][0/196]	Time 0.108 (0.108)	Data 0.321 (0.321)	Loss 0.2518 (0.2518)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.070 (0.069)	Data 0.000 (0.005)	Loss 0.2135 (0.2270)	Acc@1 91.797 (92.073)	Acc@5 100.000 (99.862)
Epoch: [111][128/196]	Time 0.063 (0.067)	Data 0.000 (0.003)	Loss 0.1677 (0.2273)	Acc@1 94.922 (92.066)	Acc@5 100.000 (99.830)
Epoch: [111][192/196]	Time 0.063 (0.068)	Data 0.000 (0.002)	Loss 0.2628 (0.2297)	Acc@1 90.625 (92.036)	Acc@5 100.000 (99.812)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:112/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [112][0/196]	Time 0.099 (0.099)	Data 0.374 (0.374)	Loss 0.2599 (0.2599)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [112][64/196]	Time 0.073 (0.073)	Data 0.000 (0.006)	Loss 0.2478 (0.2328)	Acc@1 92.578 (92.091)	Acc@5 99.219 (99.796)
Epoch: [112][128/196]	Time 0.179 (0.100)	Data 0.000 (0.003)	Loss 0.2430 (0.2345)	Acc@1 90.625 (91.918)	Acc@5 99.609 (99.803)
Epoch: [112][192/196]	Time 0.179 (0.112)	Data 0.000 (0.002)	Loss 0.1952 (0.2358)	Acc@1 94.531 (91.864)	Acc@5 100.000 (99.818)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:113/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [113][0/196]	Time 0.165 (0.165)	Data 0.332 (0.332)	Loss 0.2030 (0.2030)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [113][64/196]	Time 0.131 (0.144)	Data 0.000 (0.005)	Loss 0.2136 (0.2323)	Acc@1 92.188 (91.809)	Acc@5 99.609 (99.766)
Epoch: [113][128/196]	Time 0.074 (0.143)	Data 0.000 (0.003)	Loss 0.2495 (0.2352)	Acc@1 90.625 (91.836)	Acc@5 99.609 (99.800)
Epoch: [113][192/196]	Time 0.208 (0.143)	Data 0.000 (0.002)	Loss 0.2557 (0.2363)	Acc@1 92.188 (91.797)	Acc@5 100.000 (99.808)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:114/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [114][0/196]	Time 0.129 (0.129)	Data 0.383 (0.383)	Loss 0.1827 (0.1827)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [114][64/196]	Time 0.096 (0.143)	Data 0.000 (0.006)	Loss 0.2268 (0.2206)	Acc@1 91.797 (92.416)	Acc@5 100.000 (99.844)
Epoch: [114][128/196]	Time 0.188 (0.146)	Data 0.000 (0.003)	Loss 0.2579 (0.2282)	Acc@1 91.797 (92.115)	Acc@5 99.219 (99.821)
Epoch: [114][192/196]	Time 0.126 (0.146)	Data 0.000 (0.002)	Loss 0.2048 (0.2289)	Acc@1 92.969 (92.115)	Acc@5 100.000 (99.834)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:115/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [115][0/196]	Time 0.138 (0.138)	Data 0.370 (0.370)	Loss 0.2108 (0.2108)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.208 (0.149)	Data 0.000 (0.006)	Loss 0.1976 (0.2254)	Acc@1 94.141 (92.242)	Acc@5 100.000 (99.808)
Epoch: [115][128/196]	Time 0.131 (0.149)	Data 0.000 (0.003)	Loss 0.2153 (0.2295)	Acc@1 92.578 (92.054)	Acc@5 99.609 (99.806)
Epoch: [115][192/196]	Time 0.083 (0.149)	Data 0.000 (0.002)	Loss 0.1644 (0.2328)	Acc@1 95.703 (91.951)	Acc@5 99.219 (99.806)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.79
Max memory: 33.0690048
 29.631s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1939
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:116/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [116][0/196]	Time 0.230 (0.230)	Data 0.348 (0.348)	Loss 0.1915 (0.1915)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.177 (0.143)	Data 0.000 (0.006)	Loss 0.3243 (0.2303)	Acc@1 88.281 (92.031)	Acc@5 99.609 (99.838)
Epoch: [116][128/196]	Time 0.178 (0.145)	Data 0.000 (0.003)	Loss 0.2439 (0.2283)	Acc@1 92.969 (92.042)	Acc@5 99.609 (99.849)
Epoch: [116][192/196]	Time 0.095 (0.141)	Data 0.000 (0.002)	Loss 0.1832 (0.2292)	Acc@1 92.969 (91.930)	Acc@5 100.000 (99.830)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:117/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [117][0/196]	Time 0.122 (0.122)	Data 0.324 (0.324)	Loss 0.2921 (0.2921)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [117][64/196]	Time 0.092 (0.148)	Data 0.000 (0.005)	Loss 0.1936 (0.2240)	Acc@1 93.359 (92.194)	Acc@5 100.000 (99.796)
Epoch: [117][128/196]	Time 0.197 (0.146)	Data 0.000 (0.003)	Loss 0.2796 (0.2305)	Acc@1 89.062 (92.003)	Acc@5 99.609 (99.803)
Epoch: [117][192/196]	Time 0.177 (0.147)	Data 0.000 (0.002)	Loss 0.1801 (0.2325)	Acc@1 92.969 (91.856)	Acc@5 99.219 (99.808)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:118/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [118][0/196]	Time 0.188 (0.188)	Data 0.371 (0.371)	Loss 0.2099 (0.2099)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.171 (0.147)	Data 0.000 (0.006)	Loss 0.2259 (0.2308)	Acc@1 93.750 (91.815)	Acc@5 99.219 (99.802)
Epoch: [118][128/196]	Time 0.198 (0.148)	Data 0.000 (0.003)	Loss 0.2416 (0.2259)	Acc@1 90.234 (92.127)	Acc@5 100.000 (99.824)
Epoch: [118][192/196]	Time 0.194 (0.148)	Data 0.000 (0.002)	Loss 0.2072 (0.2267)	Acc@1 91.406 (92.062)	Acc@5 99.609 (99.806)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:119/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [119][0/196]	Time 0.110 (0.110)	Data 0.323 (0.323)	Loss 0.2467 (0.2467)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.214 (0.150)	Data 0.000 (0.005)	Loss 0.1601 (0.2190)	Acc@1 93.359 (92.416)	Acc@5 100.000 (99.874)
Epoch: [119][128/196]	Time 0.177 (0.140)	Data 0.000 (0.003)	Loss 0.2949 (0.2206)	Acc@1 87.891 (92.336)	Acc@5 100.000 (99.846)
Epoch: [119][192/196]	Time 0.182 (0.142)	Data 0.000 (0.002)	Loss 0.2475 (0.2255)	Acc@1 91.016 (92.098)	Acc@5 99.609 (99.822)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:120/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [120][0/196]	Time 0.238 (0.238)	Data 0.291 (0.291)	Loss 0.1867 (0.1867)	Acc@1 94.922 (94.922)	Acc@5 99.219 (99.219)
Epoch: [120][64/196]	Time 0.206 (0.148)	Data 0.000 (0.005)	Loss 0.2518 (0.2221)	Acc@1 92.188 (92.212)	Acc@5 99.609 (99.856)
Epoch: [120][128/196]	Time 0.201 (0.147)	Data 0.000 (0.002)	Loss 0.1544 (0.2218)	Acc@1 94.141 (92.215)	Acc@5 99.609 (99.849)
Epoch: [120][192/196]	Time 0.118 (0.146)	Data 0.000 (0.002)	Loss 0.1995 (0.2252)	Acc@1 94.531 (92.127)	Acc@5 100.000 (99.838)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.93
Max memory: 33.0690048
 29.055s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8063
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:121/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [121][0/196]	Time 0.242 (0.242)	Data 0.339 (0.339)	Loss 0.2102 (0.2102)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [121][64/196]	Time 0.074 (0.142)	Data 0.000 (0.005)	Loss 0.2382 (0.2232)	Acc@1 92.578 (92.218)	Acc@5 100.000 (99.886)
Epoch: [121][128/196]	Time 0.202 (0.134)	Data 0.000 (0.003)	Loss 0.1934 (0.2207)	Acc@1 92.578 (92.236)	Acc@5 100.000 (99.858)
Epoch: [121][192/196]	Time 0.064 (0.138)	Data 0.000 (0.002)	Loss 0.2056 (0.2241)	Acc@1 92.188 (92.159)	Acc@5 100.000 (99.832)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:122/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [122][0/196]	Time 0.222 (0.222)	Data 0.319 (0.319)	Loss 0.1798 (0.1798)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.175 (0.144)	Data 0.000 (0.005)	Loss 0.1965 (0.2196)	Acc@1 92.969 (92.602)	Acc@5 100.000 (99.850)
Epoch: [122][128/196]	Time 0.061 (0.144)	Data 0.000 (0.003)	Loss 0.2384 (0.2220)	Acc@1 92.188 (92.387)	Acc@5 100.000 (99.858)
Epoch: [122][192/196]	Time 0.114 (0.145)	Data 0.000 (0.002)	Loss 0.1622 (0.2239)	Acc@1 94.531 (92.270)	Acc@5 99.609 (99.840)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:123/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [123][0/196]	Time 0.128 (0.128)	Data 0.386 (0.386)	Loss 0.3550 (0.3550)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [123][64/196]	Time 0.149 (0.146)	Data 0.000 (0.006)	Loss 0.2607 (0.2294)	Acc@1 91.406 (91.935)	Acc@5 99.219 (99.796)
Epoch: [123][128/196]	Time 0.185 (0.147)	Data 0.000 (0.003)	Loss 0.2577 (0.2278)	Acc@1 89.844 (91.963)	Acc@5 100.000 (99.806)
Epoch: [123][192/196]	Time 0.057 (0.147)	Data 0.000 (0.002)	Loss 0.2532 (0.2282)	Acc@1 90.234 (91.916)	Acc@5 100.000 (99.806)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:124/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [124][0/196]	Time 0.159 (0.159)	Data 0.359 (0.359)	Loss 0.2075 (0.2075)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [124][64/196]	Time 0.142 (0.125)	Data 0.000 (0.006)	Loss 0.1684 (0.2239)	Acc@1 94.141 (92.115)	Acc@5 100.000 (99.856)
Epoch: [124][128/196]	Time 0.079 (0.132)	Data 0.000 (0.003)	Loss 0.2341 (0.2263)	Acc@1 90.625 (92.060)	Acc@5 100.000 (99.836)
Epoch: [124][192/196]	Time 0.096 (0.135)	Data 0.000 (0.002)	Loss 0.2420 (0.2238)	Acc@1 92.188 (92.121)	Acc@5 100.000 (99.822)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:125/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [125][0/196]	Time 0.198 (0.198)	Data 0.413 (0.413)	Loss 0.2049 (0.2049)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.196 (0.140)	Data 0.000 (0.007)	Loss 0.2402 (0.2134)	Acc@1 89.844 (92.740)	Acc@5 100.000 (99.874)
Epoch: [125][128/196]	Time 0.194 (0.139)	Data 0.000 (0.003)	Loss 0.2338 (0.2150)	Acc@1 90.625 (92.560)	Acc@5 100.000 (99.849)
Epoch: [125][192/196]	Time 0.181 (0.138)	Data 0.000 (0.002)	Loss 0.2376 (0.2209)	Acc@1 91.797 (92.376)	Acc@5 100.000 (99.836)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.75
Max memory: 33.0690048
 27.587s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2207
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:126/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [126][0/196]	Time 0.259 (0.259)	Data 0.433 (0.433)	Loss 0.2624 (0.2624)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.063 (0.136)	Data 0.000 (0.007)	Loss 0.2513 (0.2105)	Acc@1 91.797 (92.837)	Acc@5 100.000 (99.856)
Epoch: [126][128/196]	Time 0.174 (0.137)	Data 0.000 (0.004)	Loss 0.2606 (0.2164)	Acc@1 92.188 (92.560)	Acc@5 100.000 (99.849)
Epoch: [126][192/196]	Time 0.132 (0.136)	Data 0.000 (0.002)	Loss 0.2483 (0.2209)	Acc@1 91.406 (92.319)	Acc@5 100.000 (99.834)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:127/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [127][0/196]	Time 0.111 (0.111)	Data 0.368 (0.368)	Loss 0.1515 (0.1515)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.119 (0.135)	Data 0.000 (0.006)	Loss 0.2369 (0.2195)	Acc@1 91.797 (92.806)	Acc@5 99.609 (99.844)
Epoch: [127][128/196]	Time 0.065 (0.137)	Data 0.000 (0.003)	Loss 0.2701 (0.2244)	Acc@1 91.406 (92.366)	Acc@5 99.609 (99.843)
Epoch: [127][192/196]	Time 0.136 (0.138)	Data 0.000 (0.002)	Loss 0.2578 (0.2238)	Acc@1 91.406 (92.242)	Acc@5 100.000 (99.844)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:128/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [128][0/196]	Time 0.182 (0.182)	Data 0.388 (0.388)	Loss 0.3223 (0.3223)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.074 (0.138)	Data 0.000 (0.006)	Loss 0.2563 (0.2210)	Acc@1 89.453 (92.212)	Acc@5 99.219 (99.808)
Epoch: [128][128/196]	Time 0.148 (0.130)	Data 0.000 (0.003)	Loss 0.2690 (0.2221)	Acc@1 90.234 (92.163)	Acc@5 100.000 (99.833)
Epoch: [128][192/196]	Time 0.174 (0.134)	Data 0.000 (0.002)	Loss 0.3200 (0.2211)	Acc@1 90.625 (92.218)	Acc@5 99.609 (99.832)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:129/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [129][0/196]	Time 0.178 (0.178)	Data 0.368 (0.368)	Loss 0.2607 (0.2607)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.058 (0.139)	Data 0.000 (0.006)	Loss 0.1686 (0.2155)	Acc@1 93.359 (92.506)	Acc@5 100.000 (99.856)
Epoch: [129][128/196]	Time 0.178 (0.140)	Data 0.000 (0.003)	Loss 0.2246 (0.2180)	Acc@1 91.406 (92.460)	Acc@5 99.609 (99.836)
Epoch: [129][192/196]	Time 0.087 (0.141)	Data 0.000 (0.002)	Loss 0.1779 (0.2195)	Acc@1 94.531 (92.349)	Acc@5 99.609 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:130/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [130][0/196]	Time 0.106 (0.106)	Data 0.361 (0.361)	Loss 0.1556 (0.1556)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.186 (0.140)	Data 0.000 (0.006)	Loss 0.2171 (0.2252)	Acc@1 92.188 (92.290)	Acc@5 100.000 (99.820)
Epoch: [130][128/196]	Time 0.152 (0.139)	Data 0.000 (0.003)	Loss 0.2159 (0.2213)	Acc@1 92.188 (92.348)	Acc@5 100.000 (99.840)
Epoch: [130][192/196]	Time 0.202 (0.139)	Data 0.000 (0.002)	Loss 0.2791 (0.2218)	Acc@1 90.234 (92.321)	Acc@5 100.000 (99.848)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  84.88
Max memory: 33.0690048
 27.688s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9632
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:131/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [131][0/196]	Time 0.253 (0.253)	Data 0.346 (0.346)	Loss 0.1951 (0.1951)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [131][64/196]	Time 0.063 (0.137)	Data 0.000 (0.006)	Loss 0.1732 (0.2213)	Acc@1 92.578 (92.049)	Acc@5 100.000 (99.850)
Epoch: [131][128/196]	Time 0.106 (0.135)	Data 0.000 (0.003)	Loss 0.2522 (0.2192)	Acc@1 90.625 (92.142)	Acc@5 100.000 (99.888)
Epoch: [131][192/196]	Time 0.102 (0.135)	Data 0.000 (0.002)	Loss 0.2758 (0.2208)	Acc@1 90.234 (92.165)	Acc@5 99.609 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:132/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [132][0/196]	Time 0.143 (0.143)	Data 0.344 (0.344)	Loss 0.2026 (0.2026)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.151 (0.138)	Data 0.000 (0.006)	Loss 0.2139 (0.2239)	Acc@1 92.969 (92.290)	Acc@5 99.609 (99.838)
Epoch: [132][128/196]	Time 0.185 (0.138)	Data 0.000 (0.003)	Loss 0.1186 (0.2240)	Acc@1 94.922 (92.115)	Acc@5 100.000 (99.830)
Epoch: [132][192/196]	Time 0.116 (0.133)	Data 0.000 (0.002)	Loss 0.2088 (0.2234)	Acc@1 92.969 (92.113)	Acc@5 100.000 (99.848)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:133/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [133][0/196]	Time 0.189 (0.189)	Data 0.317 (0.317)	Loss 0.2207 (0.2207)	Acc@1 92.578 (92.578)	Acc@5 99.609 (99.609)
Epoch: [133][64/196]	Time 0.141 (0.144)	Data 0.000 (0.005)	Loss 0.2291 (0.2207)	Acc@1 90.625 (92.055)	Acc@5 100.000 (99.850)
Epoch: [133][128/196]	Time 0.185 (0.140)	Data 0.000 (0.003)	Loss 0.2238 (0.2201)	Acc@1 91.797 (92.191)	Acc@5 100.000 (99.843)
Epoch: [133][192/196]	Time 0.174 (0.139)	Data 0.000 (0.002)	Loss 0.2727 (0.2233)	Acc@1 89.062 (92.123)	Acc@5 100.000 (99.838)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:134/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [134][0/196]	Time 0.133 (0.133)	Data 0.322 (0.322)	Loss 0.2525 (0.2525)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.092 (0.141)	Data 0.000 (0.005)	Loss 0.2044 (0.2260)	Acc@1 91.797 (92.188)	Acc@5 100.000 (99.820)
Epoch: [134][128/196]	Time 0.209 (0.140)	Data 0.000 (0.003)	Loss 0.1701 (0.2251)	Acc@1 92.969 (92.157)	Acc@5 100.000 (99.824)
Epoch: [134][192/196]	Time 0.158 (0.139)	Data 0.000 (0.002)	Loss 0.1908 (0.2231)	Acc@1 92.188 (92.260)	Acc@5 100.000 (99.824)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:135/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [135][0/196]	Time 0.095 (0.095)	Data 0.393 (0.393)	Loss 0.2361 (0.2361)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.089 (0.128)	Data 0.000 (0.006)	Loss 0.2702 (0.2116)	Acc@1 88.672 (92.776)	Acc@5 100.000 (99.874)
Epoch: [135][128/196]	Time 0.059 (0.128)	Data 0.000 (0.003)	Loss 0.1857 (0.2189)	Acc@1 92.188 (92.366)	Acc@5 99.219 (99.879)
Epoch: [135][192/196]	Time 0.192 (0.131)	Data 0.000 (0.002)	Loss 0.2391 (0.2192)	Acc@1 90.625 (92.366)	Acc@5 99.609 (99.872)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.17
Max memory: 33.0690048
 26.249s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6571
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:136/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [136][0/196]	Time 0.242 (0.242)	Data 0.335 (0.335)	Loss 0.1618 (0.1618)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.136 (0.136)	Data 0.000 (0.005)	Loss 0.2570 (0.2138)	Acc@1 88.672 (92.560)	Acc@5 100.000 (99.850)
Epoch: [136][128/196]	Time 0.169 (0.135)	Data 0.000 (0.003)	Loss 0.2867 (0.2167)	Acc@1 90.234 (92.439)	Acc@5 100.000 (99.855)
Epoch: [136][192/196]	Time 0.159 (0.135)	Data 0.000 (0.002)	Loss 0.2051 (0.2196)	Acc@1 93.750 (92.364)	Acc@5 99.609 (99.840)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:137/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [137][0/196]	Time 0.094 (0.094)	Data 0.303 (0.303)	Loss 0.1973 (0.1973)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.177 (0.129)	Data 0.000 (0.005)	Loss 0.2081 (0.2139)	Acc@1 91.797 (92.542)	Acc@5 99.219 (99.868)
Epoch: [137][128/196]	Time 0.066 (0.133)	Data 0.000 (0.003)	Loss 0.2099 (0.2184)	Acc@1 92.578 (92.327)	Acc@5 100.000 (99.864)
Epoch: [137][192/196]	Time 0.063 (0.134)	Data 0.000 (0.002)	Loss 0.2314 (0.2215)	Acc@1 91.406 (92.256)	Acc@5 99.609 (99.864)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:138/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [138][0/196]	Time 0.162 (0.162)	Data 0.341 (0.341)	Loss 0.2591 (0.2591)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [138][64/196]	Time 0.145 (0.139)	Data 0.000 (0.005)	Loss 0.2078 (0.2229)	Acc@1 92.969 (92.043)	Acc@5 99.609 (99.862)
Epoch: [138][128/196]	Time 0.166 (0.140)	Data 0.000 (0.003)	Loss 0.2178 (0.2253)	Acc@1 92.188 (92.042)	Acc@5 100.000 (99.867)
Epoch: [138][192/196]	Time 0.159 (0.139)	Data 0.000 (0.002)	Loss 0.2256 (0.2252)	Acc@1 91.406 (92.066)	Acc@5 99.609 (99.856)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:139/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [139][0/196]	Time 0.153 (0.153)	Data 0.351 (0.351)	Loss 0.1778 (0.1778)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.068 (0.138)	Data 0.000 (0.006)	Loss 0.2468 (0.2170)	Acc@1 91.406 (92.368)	Acc@5 100.000 (99.814)
Epoch: [139][128/196]	Time 0.096 (0.132)	Data 0.000 (0.003)	Loss 0.1746 (0.2205)	Acc@1 93.750 (92.381)	Acc@5 99.609 (99.824)
Epoch: [139][192/196]	Time 0.197 (0.134)	Data 0.000 (0.002)	Loss 0.2172 (0.2234)	Acc@1 91.406 (92.194)	Acc@5 100.000 (99.828)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:140/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [140][0/196]	Time 0.173 (0.173)	Data 0.324 (0.324)	Loss 0.1978 (0.1978)	Acc@1 93.359 (93.359)	Acc@5 99.609 (99.609)
Epoch: [140][64/196]	Time 0.166 (0.140)	Data 0.000 (0.005)	Loss 0.2732 (0.2190)	Acc@1 91.406 (92.512)	Acc@5 99.219 (99.826)
Epoch: [140][128/196]	Time 0.184 (0.139)	Data 0.000 (0.003)	Loss 0.2153 (0.2234)	Acc@1 93.750 (92.297)	Acc@5 99.609 (99.824)
Epoch: [140][192/196]	Time 0.069 (0.138)	Data 0.000 (0.002)	Loss 0.2649 (0.2232)	Acc@1 91.016 (92.303)	Acc@5 99.609 (99.826)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.76
Max memory: 33.0690048
 27.458s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6337
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:141/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [141][0/196]	Time 0.270 (0.270)	Data 0.354 (0.354)	Loss 0.1175 (0.1175)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.115 (0.118)	Data 0.000 (0.006)	Loss 0.2048 (0.2147)	Acc@1 93.359 (92.590)	Acc@5 99.609 (99.814)
Epoch: [141][128/196]	Time 0.171 (0.126)	Data 0.000 (0.003)	Loss 0.2126 (0.2206)	Acc@1 91.797 (92.348)	Acc@5 99.609 (99.840)
Epoch: [141][192/196]	Time 0.118 (0.129)	Data 0.000 (0.002)	Loss 0.1754 (0.2212)	Acc@1 94.922 (92.204)	Acc@5 100.000 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:142/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [142][0/196]	Time 0.149 (0.149)	Data 0.343 (0.343)	Loss 0.1874 (0.1874)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.160 (0.137)	Data 0.000 (0.005)	Loss 0.2632 (0.2145)	Acc@1 89.844 (92.452)	Acc@5 98.828 (99.874)
Epoch: [142][128/196]	Time 0.190 (0.137)	Data 0.000 (0.003)	Loss 0.3407 (0.2180)	Acc@1 87.109 (92.396)	Acc@5 100.000 (99.849)
Epoch: [142][192/196]	Time 0.178 (0.137)	Data 0.000 (0.002)	Loss 0.2440 (0.2221)	Acc@1 91.016 (92.228)	Acc@5 100.000 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:143/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [143][0/196]	Time 0.151 (0.151)	Data 0.374 (0.374)	Loss 0.1652 (0.1652)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.197 (0.141)	Data 0.000 (0.006)	Loss 0.2120 (0.2116)	Acc@1 91.797 (92.476)	Acc@5 100.000 (99.868)
Epoch: [143][128/196]	Time 0.163 (0.139)	Data 0.000 (0.003)	Loss 0.2451 (0.2166)	Acc@1 90.625 (92.409)	Acc@5 99.219 (99.855)
Epoch: [143][192/196]	Time 0.146 (0.134)	Data 0.000 (0.002)	Loss 0.2719 (0.2195)	Acc@1 91.406 (92.341)	Acc@5 99.609 (99.842)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:144/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [144][0/196]	Time 0.173 (0.173)	Data 0.345 (0.345)	Loss 0.1522 (0.1522)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.110 (0.136)	Data 0.000 (0.006)	Loss 0.2673 (0.2151)	Acc@1 89.453 (92.488)	Acc@5 100.000 (99.850)
Epoch: [144][128/196]	Time 0.094 (0.136)	Data 0.000 (0.003)	Loss 0.2345 (0.2187)	Acc@1 91.406 (92.336)	Acc@5 100.000 (99.821)
Epoch: [144][192/196]	Time 0.178 (0.137)	Data 0.000 (0.002)	Loss 0.2010 (0.2204)	Acc@1 92.188 (92.226)	Acc@5 99.609 (99.846)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:145/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [145][0/196]	Time 0.135 (0.135)	Data 0.387 (0.387)	Loss 0.1856 (0.1856)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.095 (0.136)	Data 0.000 (0.006)	Loss 0.2591 (0.2166)	Acc@1 90.625 (92.512)	Acc@5 100.000 (99.814)
Epoch: [145][128/196]	Time 0.180 (0.138)	Data 0.000 (0.003)	Loss 0.2071 (0.2155)	Acc@1 91.406 (92.575)	Acc@5 100.000 (99.846)
Epoch: [145][192/196]	Time 0.111 (0.137)	Data 0.000 (0.002)	Loss 0.2862 (0.2217)	Acc@1 91.016 (92.287)	Acc@5 99.609 (99.846)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  86.41
Max memory: 33.0690048
 27.300s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6026
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:146/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [146][0/196]	Time 0.254 (0.254)	Data 0.385 (0.385)	Loss 0.1993 (0.1993)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.137 (0.135)	Data 0.000 (0.006)	Loss 0.2299 (0.2143)	Acc@1 91.406 (92.512)	Acc@5 100.000 (99.862)
Epoch: [146][128/196]	Time 0.102 (0.135)	Data 0.000 (0.003)	Loss 0.1706 (0.2193)	Acc@1 93.359 (92.194)	Acc@5 99.609 (99.858)
Epoch: [146][192/196]	Time 0.145 (0.135)	Data 0.000 (0.002)	Loss 0.2442 (0.2227)	Acc@1 91.406 (92.206)	Acc@5 99.609 (99.826)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:147/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [147][0/196]	Time 0.104 (0.104)	Data 0.371 (0.371)	Loss 0.2085 (0.2085)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [147][64/196]	Time 0.173 (0.137)	Data 0.000 (0.006)	Loss 0.2231 (0.2152)	Acc@1 94.141 (92.548)	Acc@5 99.609 (99.874)
Epoch: [147][128/196]	Time 0.097 (0.137)	Data 0.000 (0.003)	Loss 0.2456 (0.2181)	Acc@1 91.016 (92.475)	Acc@5 100.000 (99.836)
Epoch: [147][192/196]	Time 0.160 (0.137)	Data 0.000 (0.002)	Loss 0.1788 (0.2228)	Acc@1 95.703 (92.228)	Acc@5 99.609 (99.818)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:148/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [148][0/196]	Time 0.110 (0.110)	Data 0.295 (0.295)	Loss 0.2029 (0.2029)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [148][64/196]	Time 0.072 (0.122)	Data 0.000 (0.005)	Loss 0.2415 (0.2168)	Acc@1 91.797 (92.368)	Acc@5 100.000 (99.844)
Epoch: [148][128/196]	Time 0.121 (0.130)	Data 0.000 (0.002)	Loss 0.2130 (0.2171)	Acc@1 92.188 (92.399)	Acc@5 100.000 (99.846)
Epoch: [148][192/196]	Time 0.102 (0.133)	Data 0.000 (0.002)	Loss 0.2239 (0.2220)	Acc@1 91.016 (92.192)	Acc@5 100.000 (99.844)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:149/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [149][0/196]	Time 0.175 (0.175)	Data 0.319 (0.319)	Loss 0.2100 (0.2100)	Acc@1 93.750 (93.750)	Acc@5 98.828 (98.828)
Epoch: [149][64/196]	Time 0.165 (0.136)	Data 0.000 (0.005)	Loss 0.2279 (0.2170)	Acc@1 92.969 (92.392)	Acc@5 100.000 (99.802)
Epoch: [149][128/196]	Time 0.189 (0.136)	Data 0.000 (0.003)	Loss 0.1844 (0.2184)	Acc@1 93.750 (92.396)	Acc@5 100.000 (99.846)
Epoch: [149][192/196]	Time 0.198 (0.137)	Data 0.000 (0.002)	Loss 0.2025 (0.2211)	Acc@1 93.750 (92.317)	Acc@5 100.000 (99.844)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:150/150; Lr: 0.0010000000000000002
batch Size 256
Epoch: [150][0/196]	Time 0.114 (0.114)	Data 0.347 (0.347)	Loss 0.1874 (0.1874)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.163 (0.137)	Data 0.000 (0.006)	Loss 0.1487 (0.2056)	Acc@1 96.484 (92.987)	Acc@5 100.000 (99.934)
Epoch: [150][128/196]	Time 0.095 (0.135)	Data 0.000 (0.003)	Loss 0.2245 (0.1977)	Acc@1 91.797 (93.214)	Acc@5 100.000 (99.891)
Epoch: [150][192/196]	Time 0.137 (0.132)	Data 0.000 (0.002)	Loss 0.1947 (0.1906)	Acc@1 93.359 (93.542)	Acc@5 100.000 (99.891)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.65
Max memory: 33.0690048
 26.201s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2466
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:151/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [151][0/196]	Time 0.151 (0.151)	Data 0.428 (0.428)	Loss 0.1985 (0.1985)	Acc@1 92.188 (92.188)	Acc@5 99.609 (99.609)
Epoch: [151][64/196]	Time 0.188 (0.137)	Data 0.000 (0.007)	Loss 0.1781 (0.1807)	Acc@1 93.750 (93.780)	Acc@5 100.000 (99.928)
Epoch: [151][128/196]	Time 0.190 (0.135)	Data 0.000 (0.003)	Loss 0.1768 (0.1790)	Acc@1 93.750 (93.983)	Acc@5 99.609 (99.921)
Epoch: [151][192/196]	Time 0.076 (0.135)	Data 0.000 (0.002)	Loss 0.1690 (0.1770)	Acc@1 93.750 (94.110)	Acc@5 100.000 (99.911)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:152/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [152][0/196]	Time 0.128 (0.128)	Data 0.314 (0.314)	Loss 0.1935 (0.1935)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.059 (0.128)	Data 0.000 (0.005)	Loss 0.1282 (0.1754)	Acc@1 96.094 (93.984)	Acc@5 100.000 (99.880)
Epoch: [152][128/196]	Time 0.196 (0.129)	Data 0.000 (0.003)	Loss 0.1798 (0.1764)	Acc@1 93.750 (93.977)	Acc@5 100.000 (99.879)
Epoch: [152][192/196]	Time 0.055 (0.132)	Data 0.000 (0.002)	Loss 0.1799 (0.1749)	Acc@1 92.969 (94.027)	Acc@5 100.000 (99.881)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:153/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [153][0/196]	Time 0.142 (0.142)	Data 0.315 (0.315)	Loss 0.1630 (0.1630)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.167 (0.139)	Data 0.000 (0.005)	Loss 0.1192 (0.1649)	Acc@1 97.266 (94.405)	Acc@5 100.000 (99.922)
Epoch: [153][128/196]	Time 0.175 (0.138)	Data 0.000 (0.003)	Loss 0.1563 (0.1673)	Acc@1 94.141 (94.298)	Acc@5 100.000 (99.918)
Epoch: [153][192/196]	Time 0.187 (0.138)	Data 0.000 (0.002)	Loss 0.1483 (0.1684)	Acc@1 96.094 (94.327)	Acc@5 100.000 (99.913)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:154/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [154][0/196]	Time 0.141 (0.141)	Data 0.377 (0.377)	Loss 0.1472 (0.1472)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.065 (0.137)	Data 0.000 (0.006)	Loss 0.2269 (0.1678)	Acc@1 92.969 (94.405)	Acc@5 100.000 (99.910)
Epoch: [154][128/196]	Time 0.133 (0.139)	Data 0.000 (0.003)	Loss 0.1335 (0.1676)	Acc@1 96.094 (94.328)	Acc@5 100.000 (99.906)
Epoch: [154][192/196]	Time 0.138 (0.133)	Data 0.000 (0.002)	Loss 0.1829 (0.1678)	Acc@1 94.141 (94.347)	Acc@5 100.000 (99.909)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:155/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [155][0/196]	Time 0.198 (0.198)	Data 0.334 (0.334)	Loss 0.2040 (0.2040)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [155][64/196]	Time 0.160 (0.136)	Data 0.000 (0.005)	Loss 0.1854 (0.1722)	Acc@1 94.531 (94.159)	Acc@5 100.000 (99.880)
Epoch: [155][128/196]	Time 0.171 (0.137)	Data 0.000 (0.003)	Loss 0.1565 (0.1658)	Acc@1 94.141 (94.446)	Acc@5 100.000 (99.888)
Epoch: [155][192/196]	Time 0.133 (0.137)	Data 0.000 (0.002)	Loss 0.1684 (0.1671)	Acc@1 93.750 (94.394)	Acc@5 100.000 (99.901)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.73
Max memory: 33.0690048
 27.224s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8748
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:156/160; Lr: 0.0010000000000000002
batch Size 256
Epoch: [156][0/196]	Time 0.186 (0.186)	Data 0.312 (0.312)	Loss 0.1528 (0.1528)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.179 (0.137)	Data 0.000 (0.005)	Loss 0.1843 (0.1623)	Acc@1 92.969 (94.633)	Acc@5 99.609 (99.874)
Epoch: [156][128/196]	Time 0.079 (0.129)	Data 0.000 (0.003)	Loss 0.1411 (0.1635)	Acc@1 96.094 (94.552)	Acc@5 100.000 (99.891)
Epoch: [156][192/196]	Time 0.126 (0.131)	Data 0.000 (0.002)	Loss 0.1732 (0.1638)	Acc@1 93.750 (94.450)	Acc@5 100.000 (99.903)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:157/160; Lr: 0.0010000000000000002
batch Size 256
Epoch: [157][0/196]	Time 0.146 (0.146)	Data 0.359 (0.359)	Loss 0.1506 (0.1506)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.153 (0.139)	Data 0.000 (0.006)	Loss 0.1774 (0.1601)	Acc@1 94.141 (94.651)	Acc@5 100.000 (99.904)
Epoch: [157][128/196]	Time 0.074 (0.138)	Data 0.000 (0.003)	Loss 0.1269 (0.1633)	Acc@1 95.703 (94.607)	Acc@5 100.000 (99.900)
Epoch: [157][192/196]	Time 0.186 (0.138)	Data 0.000 (0.002)	Loss 0.1890 (0.1630)	Acc@1 94.531 (94.574)	Acc@5 100.000 (99.911)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:158/160; Lr: 0.0010000000000000002
batch Size 256
Epoch: [158][0/196]	Time 0.131 (0.131)	Data 0.303 (0.303)	Loss 0.2021 (0.2021)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.185 (0.138)	Data 0.000 (0.005)	Loss 0.1809 (0.1614)	Acc@1 93.359 (94.700)	Acc@5 100.000 (99.916)
Epoch: [158][128/196]	Time 0.071 (0.136)	Data 0.000 (0.003)	Loss 0.1395 (0.1610)	Acc@1 95.312 (94.752)	Acc@5 100.000 (99.915)
Epoch: [158][192/196]	Time 0.104 (0.137)	Data 0.000 (0.002)	Loss 0.1448 (0.1622)	Acc@1 94.922 (94.616)	Acc@5 100.000 (99.915)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:159/160; Lr: 0.0010000000000000002
batch Size 256
Epoch: [159][0/196]	Time 0.198 (0.198)	Data 0.334 (0.334)	Loss 0.1986 (0.1986)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.191 (0.122)	Data 0.000 (0.005)	Loss 0.1729 (0.1557)	Acc@1 93.359 (94.645)	Acc@5 100.000 (99.922)
Epoch: [159][128/196]	Time 0.167 (0.129)	Data 0.000 (0.003)	Loss 0.1537 (0.1559)	Acc@1 94.922 (94.701)	Acc@5 100.000 (99.918)
Epoch: [159][192/196]	Time 0.139 (0.132)	Data 0.000 (0.002)	Loss 0.1824 (0.1593)	Acc@1 93.359 (94.596)	Acc@5 100.000 (99.915)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:160/160; Lr: 0.0010000000000000002
batch Size 256
Epoch: [160][0/196]	Time 0.217 (0.217)	Data 0.426 (0.426)	Loss 0.1557 (0.1557)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.163 (0.138)	Data 0.000 (0.007)	Loss 0.1373 (0.1633)	Acc@1 96.484 (94.453)	Acc@5 99.609 (99.940)
Epoch: [160][128/196]	Time 0.055 (0.137)	Data 0.000 (0.004)	Loss 0.1534 (0.1619)	Acc@1 94.141 (94.465)	Acc@5 100.000 (99.912)
Epoch: [160][192/196]	Time 0.181 (0.137)	Data 0.000 (0.002)	Loss 0.1724 (0.1606)	Acc@1 93.359 (94.612)	Acc@5 100.000 (99.903)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.77
Max memory: 33.0690048
 27.373s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2704
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:161/165; Lr: 0.0010000000000000002
batch Size 256
Epoch: [161][0/196]	Time 0.299 (0.299)	Data 0.350 (0.350)	Loss 0.1764 (0.1764)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.106 (0.136)	Data 0.000 (0.006)	Loss 0.1325 (0.1556)	Acc@1 95.703 (94.645)	Acc@5 100.000 (99.940)
Epoch: [161][128/196]	Time 0.166 (0.136)	Data 0.000 (0.003)	Loss 0.1568 (0.1590)	Acc@1 93.359 (94.492)	Acc@5 100.000 (99.912)
Epoch: [161][192/196]	Time 0.058 (0.135)	Data 0.000 (0.002)	Loss 0.1667 (0.1594)	Acc@1 94.141 (94.529)	Acc@5 100.000 (99.921)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:162/165; Lr: 0.0010000000000000002
batch Size 256
Epoch: [162][0/196]	Time 0.211 (0.211)	Data 0.409 (0.409)	Loss 0.1117 (0.1117)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.175 (0.135)	Data 0.000 (0.007)	Loss 0.1861 (0.1560)	Acc@1 93.750 (94.706)	Acc@5 99.609 (99.904)
Epoch: [162][128/196]	Time 0.062 (0.136)	Data 0.000 (0.003)	Loss 0.1752 (0.1565)	Acc@1 95.312 (94.692)	Acc@5 100.000 (99.912)
Epoch: [162][192/196]	Time 0.122 (0.136)	Data 0.000 (0.002)	Loss 0.2722 (0.1588)	Acc@1 89.844 (94.594)	Acc@5 100.000 (99.915)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:163/165; Lr: 0.0010000000000000002
batch Size 256
Epoch: [163][0/196]	Time 0.105 (0.105)	Data 0.387 (0.387)	Loss 0.1749 (0.1749)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.125 (0.138)	Data 0.000 (0.006)	Loss 0.0822 (0.1543)	Acc@1 97.266 (94.796)	Acc@5 100.000 (99.940)
Epoch: [163][128/196]	Time 0.154 (0.131)	Data 0.000 (0.003)	Loss 0.2057 (0.1537)	Acc@1 92.578 (94.840)	Acc@5 100.000 (99.930)
Epoch: [163][192/196]	Time 0.174 (0.133)	Data 0.000 (0.002)	Loss 0.1630 (0.1557)	Acc@1 94.141 (94.766)	Acc@5 100.000 (99.917)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:164/165; Lr: 0.0010000000000000002
batch Size 256
Epoch: [164][0/196]	Time 0.212 (0.212)	Data 0.314 (0.314)	Loss 0.1577 (0.1577)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.140 (0.138)	Data 0.000 (0.005)	Loss 0.1613 (0.1495)	Acc@1 92.578 (94.940)	Acc@5 100.000 (99.940)
Epoch: [164][128/196]	Time 0.185 (0.136)	Data 0.000 (0.003)	Loss 0.1423 (0.1504)	Acc@1 94.922 (94.979)	Acc@5 100.000 (99.939)
Epoch: [164][192/196]	Time 0.062 (0.136)	Data 0.000 (0.002)	Loss 0.1834 (0.1549)	Acc@1 92.969 (94.790)	Acc@5 100.000 (99.929)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:165/165; Lr: 0.0010000000000000002
batch Size 256
Epoch: [165][0/196]	Time 0.169 (0.169)	Data 0.363 (0.363)	Loss 0.1875 (0.1875)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.155 (0.138)	Data 0.000 (0.006)	Loss 0.1813 (0.1571)	Acc@1 94.922 (94.700)	Acc@5 100.000 (99.940)
Epoch: [165][128/196]	Time 0.175 (0.138)	Data 0.000 (0.003)	Loss 0.1907 (0.1565)	Acc@1 93.750 (94.683)	Acc@5 99.609 (99.936)
Epoch: [165][192/196]	Time 0.174 (0.137)	Data 0.000 (0.002)	Loss 0.1527 (0.1556)	Acc@1 94.922 (94.697)	Acc@5 100.000 (99.939)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.87
Max memory: 33.0690048
 27.289s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7254
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:166/170; Lr: 0.0010000000000000002
batch Size 256
Epoch: [166][0/196]	Time 0.194 (0.194)	Data 0.367 (0.367)	Loss 0.1549 (0.1549)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.065 (0.135)	Data 0.000 (0.006)	Loss 0.2015 (0.1574)	Acc@1 93.750 (94.663)	Acc@5 99.609 (99.934)
Epoch: [166][128/196]	Time 0.199 (0.135)	Data 0.000 (0.003)	Loss 0.1597 (0.1579)	Acc@1 93.750 (94.628)	Acc@5 100.000 (99.918)
Epoch: [166][192/196]	Time 0.061 (0.135)	Data 0.000 (0.002)	Loss 0.1629 (0.1559)	Acc@1 94.922 (94.685)	Acc@5 99.609 (99.923)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:167/170; Lr: 0.0010000000000000002
batch Size 256
Epoch: [167][0/196]	Time 0.100 (0.100)	Data 0.308 (0.308)	Loss 0.1424 (0.1424)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.097 (0.137)	Data 0.000 (0.005)	Loss 0.1619 (0.1507)	Acc@1 94.141 (94.742)	Acc@5 100.000 (99.952)
Epoch: [167][128/196]	Time 0.178 (0.137)	Data 0.000 (0.003)	Loss 0.1342 (0.1524)	Acc@1 95.312 (94.728)	Acc@5 100.000 (99.939)
Epoch: [167][192/196]	Time 0.176 (0.132)	Data 0.000 (0.002)	Loss 0.1662 (0.1545)	Acc@1 93.750 (94.719)	Acc@5 99.609 (99.917)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:168/170; Lr: 0.0010000000000000002
batch Size 256
Epoch: [168][0/196]	Time 0.190 (0.190)	Data 0.345 (0.345)	Loss 0.1113 (0.1113)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.193 (0.138)	Data 0.000 (0.006)	Loss 0.1253 (0.1478)	Acc@1 94.141 (95.012)	Acc@5 100.000 (99.934)
Epoch: [168][128/196]	Time 0.188 (0.137)	Data 0.000 (0.003)	Loss 0.1467 (0.1494)	Acc@1 96.094 (95.022)	Acc@5 99.609 (99.924)
Epoch: [168][192/196]	Time 0.189 (0.138)	Data 0.000 (0.002)	Loss 0.1478 (0.1547)	Acc@1 95.703 (94.847)	Acc@5 100.000 (99.909)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:169/170; Lr: 0.0010000000000000002
batch Size 256
Epoch: [169][0/196]	Time 0.097 (0.097)	Data 0.374 (0.374)	Loss 0.1298 (0.1298)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.119 (0.135)	Data 0.000 (0.006)	Loss 0.1065 (0.1565)	Acc@1 94.922 (94.814)	Acc@5 100.000 (99.922)
Epoch: [169][128/196]	Time 0.187 (0.136)	Data 0.000 (0.003)	Loss 0.1158 (0.1576)	Acc@1 96.484 (94.801)	Acc@5 100.000 (99.906)
Epoch: [169][192/196]	Time 0.145 (0.136)	Data 0.000 (0.002)	Loss 0.1457 (0.1559)	Acc@1 94.922 (94.835)	Acc@5 100.000 (99.909)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:170/170; Lr: 0.0010000000000000002
batch Size 256
Epoch: [170][0/196]	Time 0.111 (0.111)	Data 0.327 (0.327)	Loss 0.1305 (0.1305)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.181 (0.122)	Data 0.000 (0.005)	Loss 0.2211 (0.1535)	Acc@1 92.188 (94.916)	Acc@5 100.000 (99.910)
Epoch: [170][128/196]	Time 0.060 (0.130)	Data 0.000 (0.003)	Loss 0.1369 (0.1546)	Acc@1 96.875 (94.825)	Acc@5 99.609 (99.909)
Epoch: [170][192/196]	Time 0.185 (0.133)	Data 0.000 (0.002)	Loss 0.1764 (0.1531)	Acc@1 94.141 (94.889)	Acc@5 100.000 (99.913)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.77
Max memory: 33.0690048
 26.445s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 219
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:171/175; Lr: 0.0010000000000000002
batch Size 256
Epoch: [171][0/196]	Time 0.181 (0.181)	Data 0.385 (0.385)	Loss 0.1103 (0.1103)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.080 (0.135)	Data 0.000 (0.006)	Loss 0.0726 (0.1453)	Acc@1 99.609 (95.264)	Acc@5 100.000 (99.910)
Epoch: [171][128/196]	Time 0.188 (0.136)	Data 0.000 (0.003)	Loss 0.1171 (0.1519)	Acc@1 94.922 (94.922)	Acc@5 100.000 (99.900)
Epoch: [171][192/196]	Time 0.060 (0.135)	Data 0.000 (0.002)	Loss 0.1814 (0.1522)	Acc@1 93.359 (94.900)	Acc@5 100.000 (99.911)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:172/175; Lr: 0.0010000000000000002
batch Size 256
Epoch: [172][0/196]	Time 0.228 (0.228)	Data 0.380 (0.380)	Loss 0.1215 (0.1215)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.197 (0.140)	Data 0.000 (0.006)	Loss 0.1895 (0.1535)	Acc@1 94.141 (94.856)	Acc@5 99.219 (99.934)
Epoch: [172][128/196]	Time 0.096 (0.139)	Data 0.000 (0.003)	Loss 0.1204 (0.1511)	Acc@1 96.484 (94.973)	Acc@5 100.000 (99.933)
Epoch: [172][192/196]	Time 0.128 (0.139)	Data 0.000 (0.002)	Loss 0.1646 (0.1542)	Acc@1 94.531 (94.855)	Acc@5 100.000 (99.929)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:173/175; Lr: 0.0010000000000000002
batch Size 256
Epoch: [173][0/196]	Time 0.216 (0.216)	Data 0.431 (0.431)	Loss 0.1790 (0.1790)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.083 (0.140)	Data 0.000 (0.007)	Loss 0.1398 (0.1574)	Acc@1 96.094 (94.651)	Acc@5 100.000 (99.916)
Epoch: [173][128/196]	Time 0.120 (0.140)	Data 0.000 (0.004)	Loss 0.1523 (0.1567)	Acc@1 94.531 (94.698)	Acc@5 99.609 (99.909)
Epoch: [173][192/196]	Time 0.070 (0.139)	Data 0.000 (0.002)	Loss 0.1384 (0.1565)	Acc@1 94.531 (94.683)	Acc@5 100.000 (99.909)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:174/175; Lr: 0.0010000000000000002
batch Size 256
Epoch: [174][0/196]	Time 0.147 (0.147)	Data 0.404 (0.404)	Loss 0.1769 (0.1769)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.140 (0.138)	Data 0.000 (0.006)	Loss 0.1153 (0.1519)	Acc@1 96.094 (94.748)	Acc@5 100.000 (99.910)
Epoch: [174][128/196]	Time 0.199 (0.130)	Data 0.000 (0.003)	Loss 0.2098 (0.1492)	Acc@1 91.406 (95.049)	Acc@5 100.000 (99.909)
Epoch: [174][192/196]	Time 0.196 (0.134)	Data 0.000 (0.002)	Loss 0.1808 (0.1510)	Acc@1 92.578 (94.956)	Acc@5 100.000 (99.903)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:175/175; Lr: 0.0010000000000000002
batch Size 256
Epoch: [175][0/196]	Time 0.103 (0.103)	Data 0.328 (0.328)	Loss 0.1749 (0.1749)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.197 (0.137)	Data 0.000 (0.005)	Loss 0.1422 (0.1561)	Acc@1 95.703 (94.639)	Acc@5 100.000 (99.880)
Epoch: [175][128/196]	Time 0.100 (0.138)	Data 0.000 (0.003)	Loss 0.2062 (0.1527)	Acc@1 91.797 (94.716)	Acc@5 100.000 (99.897)
Epoch: [175][192/196]	Time 0.061 (0.138)	Data 0.000 (0.002)	Loss 0.1751 (0.1528)	Acc@1 94.531 (94.758)	Acc@5 99.609 (99.901)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.74
Max memory: 33.0690048
 27.326s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7984
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:176/180; Lr: 0.0010000000000000002
batch Size 256
Epoch: [176][0/196]	Time 0.209 (0.209)	Data 0.383 (0.383)	Loss 0.1449 (0.1449)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.153 (0.137)	Data 0.000 (0.006)	Loss 0.1407 (0.1469)	Acc@1 94.922 (95.168)	Acc@5 100.000 (99.934)
Epoch: [176][128/196]	Time 0.132 (0.128)	Data 0.000 (0.003)	Loss 0.1640 (0.1514)	Acc@1 94.531 (94.861)	Acc@5 100.000 (99.918)
Epoch: [176][192/196]	Time 0.157 (0.131)	Data 0.000 (0.002)	Loss 0.1345 (0.1514)	Acc@1 92.969 (94.835)	Acc@5 100.000 (99.913)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:177/180; Lr: 0.0010000000000000002
batch Size 256
Epoch: [177][0/196]	Time 0.134 (0.134)	Data 0.362 (0.362)	Loss 0.1716 (0.1716)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.198 (0.137)	Data 0.000 (0.006)	Loss 0.1266 (0.1526)	Acc@1 94.922 (94.730)	Acc@5 100.000 (99.928)
Epoch: [177][128/196]	Time 0.064 (0.136)	Data 0.000 (0.003)	Loss 0.1541 (0.1531)	Acc@1 94.531 (94.658)	Acc@5 100.000 (99.918)
Epoch: [177][192/196]	Time 0.080 (0.136)	Data 0.000 (0.002)	Loss 0.1838 (0.1532)	Acc@1 94.531 (94.722)	Acc@5 99.609 (99.921)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:178/180; Lr: 0.0010000000000000002
batch Size 256
Epoch: [178][0/196]	Time 0.195 (0.195)	Data 0.459 (0.459)	Loss 0.1430 (0.1430)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.172 (0.138)	Data 0.000 (0.007)	Loss 0.1732 (0.1477)	Acc@1 94.531 (95.156)	Acc@5 100.000 (99.940)
Epoch: [178][128/196]	Time 0.144 (0.137)	Data 0.000 (0.004)	Loss 0.1010 (0.1491)	Acc@1 96.094 (95.061)	Acc@5 100.000 (99.939)
Epoch: [178][192/196]	Time 0.057 (0.137)	Data 0.000 (0.003)	Loss 0.1287 (0.1500)	Acc@1 97.266 (95.045)	Acc@5 100.000 (99.935)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:179/180; Lr: 0.0010000000000000002
batch Size 256
Epoch: [179][0/196]	Time 0.139 (0.139)	Data 0.309 (0.309)	Loss 0.1585 (0.1585)	Acc@1 93.359 (93.359)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.170 (0.118)	Data 0.000 (0.005)	Loss 0.1633 (0.1549)	Acc@1 94.531 (94.688)	Acc@5 100.000 (99.946)
Epoch: [179][128/196]	Time 0.110 (0.127)	Data 0.000 (0.003)	Loss 0.1372 (0.1544)	Acc@1 95.312 (94.686)	Acc@5 100.000 (99.927)
Epoch: [179][192/196]	Time 0.188 (0.131)	Data 0.000 (0.002)	Loss 0.1283 (0.1528)	Acc@1 94.922 (94.744)	Acc@5 100.000 (99.929)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:180/180; Lr: 0.0010000000000000002
batch Size 256
Epoch: [180][0/196]	Time 0.171 (0.171)	Data 0.433 (0.433)	Loss 0.1041 (0.1041)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.067 (0.138)	Data 0.000 (0.007)	Loss 0.1237 (0.1534)	Acc@1 95.312 (94.730)	Acc@5 100.000 (99.928)
Epoch: [180][128/196]	Time 0.082 (0.138)	Data 0.000 (0.004)	Loss 0.1306 (0.1496)	Acc@1 94.922 (94.879)	Acc@5 100.000 (99.933)
Epoch: [180][192/196]	Time 0.169 (0.137)	Data 0.000 (0.002)	Loss 0.1411 (0.1518)	Acc@1 95.703 (94.821)	Acc@5 99.609 (99.935)
Max memory in training epoch: 21.5243264
Stage: 3
width of Layers: [8, 16, 32]
width: 8
stage: 3; tobestage: 1
width: 8
stage: 3; tobestage: 1
width: 8
stage: 3; tobestage: 1
width: 8
stage: 3; tobestage: 1
width: 8
stage: 3; tobestage: 1
width: 8
stage: 3; tobestage: 1
width: 8
stage: 3; tobestage: 1
width: 16
stage: 3; tobestage: 2
width: 16
stage: 3; tobestage: 2
width: 16
stage: 3; tobestage: 2
width: 16
stage: 3; tobestage: 2
width: 16
stage: 3; tobestage: 2
width: 16
stage: 3; tobestage: 2
width: 16
stage: 3; tobestage: 2
width: 32
stage: 3; tobestage: 3
Num: 15
width: 32
stage: 3; tobestage: 3
Num: 16
width: 32
stage: 3; tobestage: 3
Num: 17
width: 32
stage: 3; tobestage: 3
Num: 18
width: 32
stage: 3; tobestage: 3
Num: 19
width: 32
stage: 3; tobestage: 3
Num: 20
width: 32
stage: 3; tobestage: 3
Num: 21
altList: ['module.conv1.weight', 'module.bn1.weight', 'module.bn1.bias', 'module.conv2.weight', 'module.bn2.weight', 'module.bn2.bias', 'module.conv3.weight', 'module.bn3.weight', 'module.bn3.bias', 'module.conv4.weight', 'module.bn4.weight', 'module.bn4.bias', 'module.conv5.weight', 'module.bn5.weight', 'module.bn5.bias', 'module.conv6.weight', 'module.bn6.weight', 'module.bn6.bias', 'module.conv7.weight', 'module.bn7.weight', 'module.bn7.bias', 'module.conv8.weight', 'module.bn8.weight', 'module.bn8.bias', 'module.conv9.weight', 'module.bn9.weight', 'module.bn9.bias', 'module.conv10.weight', 'module.bn10.weight', 'module.bn10.bias', 'module.conv11.weight', 'module.bn11.weight', 'module.bn11.bias', 'module.conv12.weight', 'module.bn12.weight', 'module.bn12.bias', 'module.conv13.weight', 'module.bn13.weight', 'module.bn13.bias', 'module.conv14.weight', 'module.bn14.weight', 'module.bn14.bias', 'module.conv15.weight', 'module.bn15.weight', 'module.bn15.bias', 'module.conv16.weight', 'module.bn16.weight', 'module.bn16.bias', 'module.conv17.weight', 'module.bn17.weight', 'module.bn17.bias', 'module.conv18.weight', 'module.bn18.weight', 'module.bn18.bias', 'module.conv19.weight', 'module.bn19.weight', 'module.bn19.bias', 'module.conv20.weight', 'module.bn20.weight', 'module.bn20.bias', 'module.conv21.weight', 'module.bn21.weight', 'module.bn21.bias', 'module.fc22.weight', 'module.fc22.bias']
Residual ListI: [15, 16, 17, 18, 19, 20, 21]
Residual ListO: [15, 16, 17, 18, 19, 20, 21]
j: 15
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 32; new width: 64
j: 16
Resiudual I
new width: 64; old width: 32
Residual O
old width1: 32; new width: 64
j: 17
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 32; new width: 64
j: 18
Resiudual I
new width: 64; old width: 32
Residual O
old width1: 32; new width: 64
j: 19
Resiudual I
new width: 64; old width: 32
Residual O
old width1: 32; new width: 64
j: 20
Resiudual I
new width: 64; old width: 32
Residual O
old width1: 32; new width: 64
j: 21
Resiudual I
new width: 64; old width: 32
Residual O
old width1: 32; new width: 64
size: 320
old width: 32
idx: 7
idx: 18
idx: 6
idx: 15
idx: 0
idx: 17
idx: 2
idx: 11
idx: 13
idx: 20
idx: 12
idx: 27
idx: 4
idx: 23
idx: 29
idx: 4
idx: 14
idx: 14
idx: 29
idx: 31
idx: 4
idx: 18
idx: 8
idx: 11
idx: 19
idx: 29
idx: 13
idx: 16
idx: 13
idx: 21
idx: 9
idx: 2
Stage: 2
width of Layers: [8, 16, 32]
width: 8
stage: 2; tobestage: 1
width: 8
stage: 2; tobestage: 1
width: 8
stage: 2; tobestage: 1
width: 8
stage: 2; tobestage: 1
width: 8
stage: 2; tobestage: 1
width: 8
stage: 2; tobestage: 1
width: 8
stage: 2; tobestage: 1
width: 16
stage: 2; tobestage: 2
Num: 8
width: 16
stage: 2; tobestage: 2
Num: 9
width: 16
stage: 2; tobestage: 2
Num: 10
width: 16
stage: 2; tobestage: 2
Num: 11
width: 16
stage: 2; tobestage: 2
Num: 12
width: 16
stage: 2; tobestage: 2
Num: 13
width: 16
stage: 2; tobestage: 2
Num: 14
width: 64
width: 64
width: 64
width: 64
width: 64
width: 64
width: 64
altList: ['module.conv1.weight', 'module.bn1.weight', 'module.bn1.bias', 'module.conv2.weight', 'module.bn2.weight', 'module.bn2.bias', 'module.conv3.weight', 'module.bn3.weight', 'module.bn3.bias', 'module.conv4.weight', 'module.bn4.weight', 'module.bn4.bias', 'module.conv5.weight', 'module.bn5.weight', 'module.bn5.bias', 'module.conv6.weight', 'module.bn6.weight', 'module.bn6.bias', 'module.conv7.weight', 'module.bn7.weight', 'module.bn7.bias', 'module.conv8.weight', 'module.bn8.weight', 'module.bn8.bias', 'module.conv9.weight', 'module.bn9.weight', 'module.bn9.bias', 'module.conv10.weight', 'module.bn10.weight', 'module.bn10.bias', 'module.conv11.weight', 'module.bn11.weight', 'module.bn11.bias', 'module.conv12.weight', 'module.bn12.weight', 'module.bn12.bias', 'module.conv13.weight', 'module.bn13.weight', 'module.bn13.bias', 'module.conv14.weight', 'module.bn14.weight', 'module.bn14.bias', 'module.conv15.weight', 'module.bn15.weight', 'module.bn15.bias', 'module.conv16.weight', 'module.bn16.weight', 'module.bn16.bias', 'module.conv17.weight', 'module.bn17.weight', 'module.bn17.bias', 'module.conv18.weight', 'module.bn18.weight', 'module.bn18.bias', 'module.conv19.weight', 'module.bn19.weight', 'module.bn19.bias', 'module.conv20.weight', 'module.bn20.weight', 'module.bn20.bias', 'module.conv21.weight', 'module.bn21.weight', 'module.bn21.bias', 'module.fc22.weight', 'module.fc22.bias']
Residual ListI: [8, 9, 10, 11, 12, 13, 14]
Residual ListO: [8, 9, 10, 11, 12, 13, 14]
j: 8
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 16; new width: 32
j: 9
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 16; new width: 32
j: 10
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 16; new width: 32
j: 11
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 16; new width: 32
j: 12
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 16; new width: 32
j: 13
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 16; new width: 32
j: 14
Resiudual I
new width: 32; old width: 16
Residual O
old width1: 16; new width: 32
Stage: 1
width of Layers: [8, 16, 32]
width: 8
stage: 1; tobestage: 1
Num: 1
width: 8
stage: 1; tobestage: 1
Num: 2
width: 8
stage: 1; tobestage: 1
Num: 3
width: 8
stage: 1; tobestage: 1
Num: 4
width: 8
stage: 1; tobestage: 1
Num: 5
width: 8
stage: 1; tobestage: 1
Num: 6
width: 8
stage: 1; tobestage: 1
Num: 7
width: 32
stage: 1; tobestage: 3
width: 32
stage: 1; tobestage: 3
width: 32
stage: 1; tobestage: 3
width: 32
stage: 1; tobestage: 3
width: 32
stage: 1; tobestage: 3
width: 32
stage: 1; tobestage: 3
width: 32
stage: 1; tobestage: 3
width: 64
width: 64
width: 64
width: 64
width: 64
width: 64
width: 64
altList: ['module.conv1.weight', 'module.bn1.weight', 'module.bn1.bias', 'module.conv2.weight', 'module.bn2.weight', 'module.bn2.bias', 'module.conv3.weight', 'module.bn3.weight', 'module.bn3.bias', 'module.conv4.weight', 'module.bn4.weight', 'module.bn4.bias', 'module.conv5.weight', 'module.bn5.weight', 'module.bn5.bias', 'module.conv6.weight', 'module.bn6.weight', 'module.bn6.bias', 'module.conv7.weight', 'module.bn7.weight', 'module.bn7.bias', 'module.conv8.weight', 'module.bn8.weight', 'module.bn8.bias', 'module.conv9.weight', 'module.bn9.weight', 'module.bn9.bias', 'module.conv10.weight', 'module.bn10.weight', 'module.bn10.bias', 'module.conv11.weight', 'module.bn11.weight', 'module.bn11.bias', 'module.conv12.weight', 'module.bn12.weight', 'module.bn12.bias', 'module.conv13.weight', 'module.bn13.weight', 'module.bn13.bias', 'module.conv14.weight', 'module.bn14.weight', 'module.bn14.bias', 'module.conv15.weight', 'module.bn15.weight', 'module.bn15.bias', 'module.conv16.weight', 'module.bn16.weight', 'module.bn16.bias', 'module.conv17.weight', 'module.bn17.weight', 'module.bn17.bias', 'module.conv18.weight', 'module.bn18.weight', 'module.bn18.bias', 'module.conv19.weight', 'module.bn19.weight', 'module.bn19.bias', 'module.conv20.weight', 'module.bn20.weight', 'module.bn20.bias', 'module.conv21.weight', 'module.bn21.weight', 'module.bn21.bias', 'module.fc22.weight', 'module.fc22.bias']
Residual ListI: [1, 2, 3, 4, 5, 6, 7]
Residual ListO: [1, 2, 3, 4, 5, 6, 7]
j: 1
Residual O
old width1: 8; new width: 16
j: 2
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 8; new width: 16
j: 3
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 8; new width: 16
j: 4
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 8; new width: 16
j: 5
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 8; new width: 16
j: 6
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 8; new width: 16
j: 7
Resiudual I
new width: 16; old width: 8
Residual O
old width1: 8; new width: 16
width: 8
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (19): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (29): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): AdaptiveAvgPool2d(output_size=(1, 1))
    (43): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (19): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (29): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): AdaptiveAvgPool2d(output_size=(1, 1))
    (43): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...
  88.88
Max memory: 33.0690048
 27.392s  j: 181 bis 185
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1307
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1220096
lr: 0.01
Epoche:6/10; Lr: 0.01
batch Size 256
Epoch: [6][0/196]	Time 0.223 (0.223)	Data 0.364 (0.364)	Loss 5.5497 (5.5497)	Acc@1 9.766 (9.766)	Acc@5 49.609 (49.609)
Epoch: [6][64/196]	Time 0.116 (0.135)	Data 0.000 (0.006)	Loss 1.2468 (1.7718)	Acc@1 53.125 (40.619)	Acc@5 94.922 (88.095)
Epoch: [6][128/196]	Time 0.204 (0.144)	Data 0.000 (0.003)	Loss 1.0735 (1.4690)	Acc@1 60.547 (49.310)	Acc@5 97.266 (91.627)
Epoch: [6][192/196]	Time 0.216 (0.147)	Data 0.000 (0.002)	Loss 0.9369 (1.2976)	Acc@1 67.578 (54.752)	Acc@5 98.438 (93.501)
Max memory in training epoch: 42.725632
lr: 0.01
Epoche:7/10; Lr: [0.01]
batch Size 256
Epoch: [7][0/196]	Time 0.206 (0.206)	Data 0.371 (0.371)	Loss 0.9217 (0.9217)	Acc@1 68.359 (68.359)	Acc@5 97.266 (97.266)
Epoch: [7][64/196]	Time 0.196 (0.153)	Data 0.000 (0.006)	Loss 0.7276 (0.8107)	Acc@1 73.438 (71.490)	Acc@5 98.047 (97.849)
Epoch: [7][128/196]	Time 0.199 (0.152)	Data 0.000 (0.003)	Loss 0.7346 (0.7654)	Acc@1 75.391 (73.044)	Acc@5 98.047 (98.162)
Epoch: [7][192/196]	Time 0.113 (0.153)	Data 0.000 (0.002)	Loss 0.5639 (0.7275)	Acc@1 80.469 (74.470)	Acc@5 99.609 (98.344)
Max memory in training epoch: 42.6207744
lr: 0.01
Epoche:8/10; Lr: [0.01]
batch Size 256
Epoch: [8][0/196]	Time 0.129 (0.129)	Data 0.314 (0.314)	Loss 0.6669 (0.6669)	Acc@1 76.562 (76.562)	Acc@5 99.609 (99.609)
Epoch: [8][64/196]	Time 0.183 (0.154)	Data 0.000 (0.005)	Loss 0.5381 (0.5867)	Acc@1 81.250 (79.225)	Acc@5 98.828 (98.996)
Epoch: [8][128/196]	Time 0.103 (0.150)	Data 0.000 (0.003)	Loss 0.4736 (0.5556)	Acc@1 85.156 (80.672)	Acc@5 98.828 (99.028)
Epoch: [8][192/196]	Time 0.203 (0.150)	Data 0.000 (0.002)	Loss 0.5339 (0.5377)	Acc@1 80.078 (81.183)	Acc@5 99.219 (99.071)
Max memory in training epoch: 42.6207744
lr: 0.01
Epoche:9/10; Lr: [0.01]
batch Size 256
Epoch: [9][0/196]	Time 0.195 (0.195)	Data 0.358 (0.358)	Loss 0.5172 (0.5172)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 0.132 (0.153)	Data 0.000 (0.006)	Loss 0.4947 (0.4598)	Acc@1 83.203 (84.038)	Acc@5 99.219 (99.231)
Epoch: [9][128/196]	Time 0.208 (0.154)	Data 0.000 (0.003)	Loss 0.3407 (0.4430)	Acc@1 87.109 (84.696)	Acc@5 100.000 (99.337)
Epoch: [9][192/196]	Time 0.193 (0.153)	Data 0.000 (0.002)	Loss 0.4405 (0.4343)	Acc@1 85.156 (84.950)	Acc@5 99.219 (99.395)
Max memory in training epoch: 42.6207744
lr: 0.01
Epoche:10/10; Lr: [0.01]
batch Size 256
Epoch: [10][0/196]	Time 0.176 (0.176)	Data 0.420 (0.420)	Loss 0.3511 (0.3511)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.152 (0.151)	Data 0.000 (0.007)	Loss 0.3986 (0.3777)	Acc@1 87.891 (86.647)	Acc@5 99.609 (99.585)
Epoch: [10][128/196]	Time 0.185 (0.153)	Data 0.000 (0.003)	Loss 0.4129 (0.3777)	Acc@1 87.109 (86.861)	Acc@5 99.609 (99.564)
Epoch: [10][192/196]	Time 0.213 (0.153)	Data 0.000 (0.002)	Loss 0.3318 (0.3723)	Acc@1 87.891 (87.055)	Acc@5 100.000 (99.567)
Max memory in training epoch: 42.6207744
[INFO] Storing checkpoint...
  83.22
Max memory: 66.1308928
 30.494s  j: 186 bis 190
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6910
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 191 bis 195
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7156
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 196 bis 200
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5900
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 201 bis 205
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4634
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 206 bis 210
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6040
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 211 bis 215
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3730
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 216 bis 220
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7900
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 221 bis 225
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8118
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 226 bis 230
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6159
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 231 bis 235
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4636
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 236 bis 240
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3249
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 241 bis 245
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5785
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 246 bis 250
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9902
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 251 bis 255
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 142
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 256 bis 260
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2470
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 261 bis 265
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1089
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 266 bis 270
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3095
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 271 bis 275
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1062
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 276 bis 280
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8507
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 281 bis 285
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9590
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 286 bis 290
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3179
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 291 bis 295
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 833
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 296 bis 300
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6271
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 301 bis 305
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6690
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 306 bis 310
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4947
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 311 bis 315
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 193
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 316 bis 320
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9978
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 321 bis 325
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 914
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 326 bis 330
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4353
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 331 bis 335
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1811
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 336 bis 340
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9313
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 341 bis 345
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5066
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 346 bis 350
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8952
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 351 bis 355
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 680
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
j: 356 bis 360
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2806
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.2407936
Traceback (most recent call last):
  File "main.py", line 962, in <module>
    main()
  File "main.py", line 400, in main
    args.lr = float(args.lr)
TypeError: float() argument must be a string or a number, not 'list'
Net2Net 2
j: 1 bis 5
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9298
Files already downloaded and verified
width: 8
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): AdaptiveAvgPool2d(output_size=(1, 1))
    (43): Linear(in_features=32, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.0348672
lr: 0.1
1
Epoche:1/5; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.168 (0.168)	Data 0.416 (0.416)	Loss 2.3843 (2.3843)	Acc@1 11.328 (11.328)	Acc@5 51.562 (51.562)
Epoch: [1][64/196]	Time 0.156 (0.118)	Data 0.000 (0.007)	Loss 1.7851 (1.9367)	Acc@1 29.297 (25.793)	Acc@5 88.672 (79.994)
Epoch: [1][128/196]	Time 0.164 (0.125)	Data 0.000 (0.003)	Loss 1.6190 (1.8090)	Acc@1 39.453 (30.708)	Acc@5 90.625 (84.142)
Epoch: [1][192/196]	Time 0.167 (0.127)	Data 0.000 (0.002)	Loss 1.4542 (1.7203)	Acc@1 46.875 (34.650)	Acc@5 92.578 (86.383)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:2/5; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.111 (0.111)	Data 0.413 (0.413)	Loss 1.5282 (1.5282)	Acc@1 41.406 (41.406)	Acc@5 94.531 (94.531)
Epoch: [2][64/196]	Time 0.195 (0.130)	Data 0.000 (0.007)	Loss 1.3955 (1.4099)	Acc@1 45.703 (48.029)	Acc@5 93.750 (93.035)
Epoch: [2][128/196]	Time 0.187 (0.130)	Data 0.000 (0.003)	Loss 1.2620 (1.3432)	Acc@1 55.078 (50.784)	Acc@5 95.703 (93.596)
Epoch: [2][192/196]	Time 0.170 (0.131)	Data 0.000 (0.002)	Loss 1.1764 (1.2876)	Acc@1 57.422 (52.886)	Acc@5 95.703 (94.183)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:3/5; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.071 (0.071)	Data 0.379 (0.379)	Loss 1.1116 (1.1116)	Acc@1 59.375 (59.375)	Acc@5 97.656 (97.656)
Epoch: [3][64/196]	Time 0.157 (0.132)	Data 0.000 (0.006)	Loss 1.1362 (1.1223)	Acc@1 61.328 (59.609)	Acc@5 96.484 (95.841)
Epoch: [3][128/196]	Time 0.162 (0.133)	Data 0.000 (0.003)	Loss 1.0244 (1.0946)	Acc@1 63.281 (60.877)	Acc@5 96.484 (95.970)
Epoch: [3][192/196]	Time 0.148 (0.128)	Data 0.000 (0.002)	Loss 0.9154 (1.0634)	Acc@1 67.188 (61.933)	Acc@5 98.047 (96.302)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:4/5; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.188 (0.188)	Data 0.265 (0.265)	Loss 0.9364 (0.9364)	Acc@1 65.625 (65.625)	Acc@5 97.266 (97.266)
Epoch: [4][64/196]	Time 0.190 (0.137)	Data 0.000 (0.004)	Loss 1.0640 (0.9711)	Acc@1 58.984 (65.174)	Acc@5 96.875 (97.025)
Epoch: [4][128/196]	Time 0.161 (0.137)	Data 0.000 (0.002)	Loss 0.9515 (0.9642)	Acc@1 64.062 (65.265)	Acc@5 96.484 (97.078)
Epoch: [4][192/196]	Time 0.171 (0.137)	Data 0.000 (0.002)	Loss 0.9310 (0.9447)	Acc@1 67.969 (66.032)	Acc@5 96.484 (97.134)
Max memory in training epoch: 21.4926848
lr: 0.1
1
Epoche:5/5; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.082 (0.082)	Data 0.350 (0.350)	Loss 0.8666 (0.8666)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [5][64/196]	Time 0.138 (0.140)	Data 0.000 (0.006)	Loss 0.8742 (0.8859)	Acc@1 65.625 (68.612)	Acc@5 98.047 (97.644)
Epoch: [5][128/196]	Time 0.188 (0.139)	Data 0.000 (0.003)	Loss 0.6709 (0.8716)	Acc@1 78.125 (68.956)	Acc@5 98.828 (97.626)
Epoch: [5][192/196]	Time 0.194 (0.140)	Data 0.000 (0.002)	Loss 0.7203 (0.8553)	Acc@1 72.266 (69.740)	Acc@5 98.438 (97.662)
Max memory in training epoch: 21.4926848
[INFO] Storing checkpoint...
  66.94
Max memory: 33.0373632
 27.850s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5528
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.0665088
lr: 0.1
1
Epoche:6/10; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 0.207 (0.207)	Data 0.323 (0.323)	Loss 0.7597 (0.7597)	Acc@1 72.266 (72.266)	Acc@5 98.828 (98.828)
Epoch: [6][64/196]	Time 0.171 (0.138)	Data 0.000 (0.005)	Loss 0.8093 (0.7882)	Acc@1 69.922 (71.905)	Acc@5 98.047 (98.119)
Epoch: [6][128/196]	Time 0.173 (0.138)	Data 0.000 (0.003)	Loss 0.7039 (0.7870)	Acc@1 73.828 (72.217)	Acc@5 98.438 (98.011)
Epoch: [6][192/196]	Time 0.147 (0.138)	Data 0.000 (0.002)	Loss 0.7427 (0.7815)	Acc@1 74.219 (72.533)	Acc@5 98.438 (98.087)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:7/10; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 0.138 (0.138)	Data 0.390 (0.390)	Loss 0.6788 (0.6788)	Acc@1 75.781 (75.781)	Acc@5 99.219 (99.219)
Epoch: [7][64/196]	Time 0.083 (0.139)	Data 0.000 (0.006)	Loss 0.8623 (0.7512)	Acc@1 70.312 (73.612)	Acc@5 97.656 (98.263)
Epoch: [7][128/196]	Time 0.070 (0.140)	Data 0.000 (0.003)	Loss 0.7568 (0.7467)	Acc@1 73.047 (73.819)	Acc@5 99.609 (98.310)
Epoch: [7][192/196]	Time 0.199 (0.141)	Data 0.000 (0.002)	Loss 0.6447 (0.7392)	Acc@1 78.516 (74.182)	Acc@5 98.438 (98.288)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:8/10; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 0.110 (0.110)	Data 0.349 (0.349)	Loss 0.7875 (0.7875)	Acc@1 72.266 (72.266)	Acc@5 98.047 (98.047)
Epoch: [8][64/196]	Time 0.163 (0.141)	Data 0.000 (0.006)	Loss 0.7575 (0.7023)	Acc@1 77.344 (75.913)	Acc@5 96.875 (98.329)
Epoch: [8][128/196]	Time 0.202 (0.140)	Data 0.000 (0.003)	Loss 0.6806 (0.6919)	Acc@1 75.391 (76.014)	Acc@5 98.047 (98.510)
Epoch: [8][192/196]	Time 0.163 (0.140)	Data 0.000 (0.002)	Loss 0.6875 (0.6914)	Acc@1 76.953 (75.990)	Acc@5 96.875 (98.545)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:9/10; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 0.094 (0.094)	Data 0.320 (0.320)	Loss 0.6848 (0.6848)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [9][64/196]	Time 0.131 (0.139)	Data 0.000 (0.005)	Loss 0.6258 (0.6698)	Acc@1 79.297 (76.737)	Acc@5 98.828 (98.576)
Epoch: [9][128/196]	Time 0.064 (0.139)	Data 0.000 (0.003)	Loss 0.6754 (0.6715)	Acc@1 75.391 (76.756)	Acc@5 98.438 (98.565)
Epoch: [9][192/196]	Time 0.083 (0.139)	Data 0.000 (0.002)	Loss 0.5952 (0.6652)	Acc@1 76.562 (76.990)	Acc@5 98.828 (98.559)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:10/10; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 0.160 (0.160)	Data 0.384 (0.384)	Loss 0.6161 (0.6161)	Acc@1 79.688 (79.688)	Acc@5 99.219 (99.219)
Epoch: [10][64/196]	Time 0.154 (0.138)	Data 0.000 (0.006)	Loss 0.6059 (0.6574)	Acc@1 77.734 (77.079)	Acc@5 98.828 (98.678)
Epoch: [10][128/196]	Time 0.198 (0.131)	Data 0.000 (0.003)	Loss 0.6350 (0.6450)	Acc@1 76.953 (77.531)	Acc@5 98.047 (98.646)
Epoch: [10][192/196]	Time 0.095 (0.133)	Data 0.000 (0.002)	Loss 0.6491 (0.6441)	Acc@1 77.734 (77.581)	Acc@5 98.438 (98.709)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  70.77
Max memory: 33.0690048
 26.627s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9512
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.0665088
lr: 0.1
1
Epoche:11/15; Lr: 0.1
batch Size 256
Epoch: [11][0/196]	Time 0.176 (0.176)	Data 0.403 (0.403)	Loss 0.5585 (0.5585)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [11][64/196]	Time 0.126 (0.137)	Data 0.000 (0.006)	Loss 0.6205 (0.6063)	Acc@1 82.422 (79.105)	Acc@5 99.219 (98.726)
Epoch: [11][128/196]	Time 0.178 (0.138)	Data 0.000 (0.003)	Loss 0.6833 (0.6189)	Acc@1 76.172 (78.637)	Acc@5 96.875 (98.722)
Epoch: [11][192/196]	Time 0.165 (0.137)	Data 0.000 (0.002)	Loss 0.6457 (0.6227)	Acc@1 77.734 (78.501)	Acc@5 98.438 (98.739)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:12/15; Lr: 0.1
batch Size 256
Epoch: [12][0/196]	Time 0.144 (0.144)	Data 0.391 (0.391)	Loss 0.7327 (0.7327)	Acc@1 76.562 (76.562)	Acc@5 98.047 (98.047)
Epoch: [12][64/196]	Time 0.163 (0.122)	Data 0.000 (0.006)	Loss 0.6348 (0.6263)	Acc@1 77.344 (78.606)	Acc@5 99.219 (98.762)
Epoch: [12][128/196]	Time 0.064 (0.130)	Data 0.000 (0.003)	Loss 0.4895 (0.6123)	Acc@1 83.984 (79.076)	Acc@5 99.219 (98.874)
Epoch: [12][192/196]	Time 0.071 (0.132)	Data 0.000 (0.002)	Loss 0.7113 (0.6135)	Acc@1 76.953 (78.985)	Acc@5 98.047 (98.850)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:13/15; Lr: 0.1
batch Size 256
Epoch: [13][0/196]	Time 0.106 (0.106)	Data 0.333 (0.333)	Loss 0.6183 (0.6183)	Acc@1 79.297 (79.297)	Acc@5 98.438 (98.438)
Epoch: [13][64/196]	Time 0.071 (0.137)	Data 0.000 (0.005)	Loss 0.5982 (0.6027)	Acc@1 78.125 (79.189)	Acc@5 98.828 (98.780)
Epoch: [13][128/196]	Time 0.058 (0.138)	Data 0.000 (0.003)	Loss 0.5069 (0.5972)	Acc@1 80.859 (79.300)	Acc@5 99.219 (98.871)
Epoch: [13][192/196]	Time 0.210 (0.139)	Data 0.000 (0.002)	Loss 0.5850 (0.5997)	Acc@1 78.906 (79.204)	Acc@5 100.000 (98.895)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:14/15; Lr: 0.1
batch Size 256
Epoch: [14][0/196]	Time 0.208 (0.208)	Data 0.359 (0.359)	Loss 0.5353 (0.5353)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 0.117 (0.137)	Data 0.000 (0.006)	Loss 0.6397 (0.5765)	Acc@1 78.125 (80.331)	Acc@5 98.828 (98.978)
Epoch: [14][128/196]	Time 0.120 (0.138)	Data 0.000 (0.003)	Loss 0.5869 (0.5831)	Acc@1 80.078 (79.981)	Acc@5 98.828 (98.937)
Epoch: [14][192/196]	Time 0.115 (0.133)	Data 0.000 (0.002)	Loss 0.5426 (0.5838)	Acc@1 83.203 (79.991)	Acc@5 99.219 (98.927)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:15/15; Lr: 0.1
batch Size 256
Epoch: [15][0/196]	Time 0.230 (0.230)	Data 0.336 (0.336)	Loss 0.6817 (0.6817)	Acc@1 74.609 (74.609)	Acc@5 98.047 (98.047)
Epoch: [15][64/196]	Time 0.054 (0.137)	Data 0.000 (0.005)	Loss 0.5173 (0.5849)	Acc@1 84.375 (79.844)	Acc@5 98.438 (98.906)
Epoch: [15][128/196]	Time 0.062 (0.136)	Data 0.000 (0.003)	Loss 0.6396 (0.5863)	Acc@1 77.734 (79.578)	Acc@5 98.047 (98.855)
Epoch: [15][192/196]	Time 0.107 (0.137)	Data 0.000 (0.002)	Loss 0.6562 (0.5839)	Acc@1 78.125 (79.631)	Acc@5 99.609 (98.873)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  73.43
Max memory: 33.0690048
 27.285s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8716
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.0665088
lr: 0.1
1
Epoche:16/20; Lr: 0.1
batch Size 256
Epoch: [16][0/196]	Time 0.259 (0.259)	Data 0.267 (0.267)	Loss 0.6257 (0.6257)	Acc@1 76.172 (76.172)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.140 (0.134)	Data 0.000 (0.004)	Loss 0.5849 (0.5509)	Acc@1 80.859 (80.986)	Acc@5 99.609 (99.075)
Epoch: [16][128/196]	Time 0.056 (0.126)	Data 0.000 (0.002)	Loss 0.4852 (0.5577)	Acc@1 83.203 (80.732)	Acc@5 99.219 (99.019)
Epoch: [16][192/196]	Time 0.163 (0.129)	Data 0.000 (0.002)	Loss 0.5541 (0.5697)	Acc@1 82.031 (80.283)	Acc@5 98.828 (98.988)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:17/20; Lr: 0.1
batch Size 256
Epoch: [17][0/196]	Time 0.108 (0.108)	Data 0.324 (0.324)	Loss 0.5329 (0.5329)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [17][64/196]	Time 0.191 (0.137)	Data 0.000 (0.005)	Loss 0.5351 (0.5609)	Acc@1 82.422 (80.517)	Acc@5 97.266 (99.020)
Epoch: [17][128/196]	Time 0.193 (0.137)	Data 0.000 (0.003)	Loss 0.5008 (0.5692)	Acc@1 82.422 (80.142)	Acc@5 98.828 (99.010)
Epoch: [17][192/196]	Time 0.060 (0.136)	Data 0.000 (0.002)	Loss 0.5187 (0.5675)	Acc@1 80.078 (80.349)	Acc@5 99.219 (99.016)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:18/20; Lr: 0.1
batch Size 256
Epoch: [18][0/196]	Time 0.185 (0.185)	Data 0.360 (0.360)	Loss 0.4790 (0.4790)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.183 (0.135)	Data 0.000 (0.006)	Loss 0.4171 (0.5685)	Acc@1 86.719 (80.505)	Acc@5 100.000 (99.026)
Epoch: [18][128/196]	Time 0.199 (0.137)	Data 0.000 (0.003)	Loss 0.6628 (0.5609)	Acc@1 76.953 (80.720)	Acc@5 98.828 (99.025)
Epoch: [18][192/196]	Time 0.141 (0.137)	Data 0.000 (0.002)	Loss 0.7266 (0.5605)	Acc@1 73.047 (80.712)	Acc@5 98.047 (99.002)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:19/20; Lr: 0.1
batch Size 256
Epoch: [19][0/196]	Time 0.203 (0.203)	Data 0.334 (0.334)	Loss 0.5616 (0.5616)	Acc@1 80.078 (80.078)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 0.082 (0.121)	Data 0.000 (0.005)	Loss 0.5159 (0.5554)	Acc@1 82.422 (80.661)	Acc@5 99.609 (98.972)
Epoch: [19][128/196]	Time 0.071 (0.129)	Data 0.000 (0.003)	Loss 0.5481 (0.5473)	Acc@1 82.031 (81.038)	Acc@5 99.219 (98.980)
Epoch: [19][192/196]	Time 0.099 (0.132)	Data 0.000 (0.002)	Loss 0.4825 (0.5516)	Acc@1 83.594 (80.938)	Acc@5 98.828 (98.974)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:20/20; Lr: 0.1
batch Size 256
Epoch: [20][0/196]	Time 0.120 (0.120)	Data 0.379 (0.379)	Loss 0.5465 (0.5465)	Acc@1 81.641 (81.641)	Acc@5 98.438 (98.438)
Epoch: [20][64/196]	Time 0.181 (0.137)	Data 0.000 (0.006)	Loss 0.5583 (0.5484)	Acc@1 82.812 (81.262)	Acc@5 98.047 (99.117)
Epoch: [20][128/196]	Time 0.148 (0.136)	Data 0.000 (0.003)	Loss 0.5051 (0.5453)	Acc@1 82.031 (81.162)	Acc@5 99.609 (99.092)
Epoch: [20][192/196]	Time 0.124 (0.136)	Data 0.000 (0.002)	Loss 0.5418 (0.5432)	Acc@1 79.297 (81.270)	Acc@5 98.828 (99.095)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  64.62
Max memory: 33.0690048
 27.299s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6769
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.0665088
lr: 0.1
1
Epoche:21/25; Lr: 0.1
batch Size 256
Epoch: [21][0/196]	Time 0.183 (0.183)	Data 0.368 (0.368)	Loss 0.5263 (0.5263)	Acc@1 80.859 (80.859)	Acc@5 99.609 (99.609)
Epoch: [21][64/196]	Time 0.159 (0.134)	Data 0.000 (0.006)	Loss 0.5165 (0.5221)	Acc@1 83.203 (81.929)	Acc@5 99.219 (99.279)
Epoch: [21][128/196]	Time 0.182 (0.134)	Data 0.000 (0.003)	Loss 0.5413 (0.5299)	Acc@1 81.641 (81.701)	Acc@5 98.828 (99.176)
Epoch: [21][192/196]	Time 0.193 (0.135)	Data 0.000 (0.002)	Loss 0.5130 (0.5345)	Acc@1 82.422 (81.539)	Acc@5 99.219 (99.162)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:22/25; Lr: 0.1
batch Size 256
Epoch: [22][0/196]	Time 0.093 (0.093)	Data 0.402 (0.402)	Loss 0.4496 (0.4496)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 0.180 (0.134)	Data 0.000 (0.006)	Loss 0.5604 (0.5537)	Acc@1 81.641 (80.817)	Acc@5 98.828 (98.942)
Epoch: [22][128/196]	Time 0.147 (0.135)	Data 0.000 (0.003)	Loss 0.5345 (0.5438)	Acc@1 82.031 (81.410)	Acc@5 98.438 (98.946)
Epoch: [22][192/196]	Time 0.149 (0.135)	Data 0.000 (0.002)	Loss 0.4990 (0.5393)	Acc@1 81.641 (81.495)	Acc@5 99.219 (98.978)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:23/25; Lr: 0.1
batch Size 256
Epoch: [23][0/196]	Time 0.168 (0.168)	Data 0.389 (0.389)	Loss 0.5021 (0.5021)	Acc@1 83.984 (83.984)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.088 (0.135)	Data 0.000 (0.006)	Loss 0.5447 (0.5103)	Acc@1 80.078 (82.452)	Acc@5 98.438 (99.105)
Epoch: [23][128/196]	Time 0.172 (0.128)	Data 0.000 (0.003)	Loss 0.5349 (0.5239)	Acc@1 82.422 (81.856)	Acc@5 100.000 (99.076)
Epoch: [23][192/196]	Time 0.191 (0.132)	Data 0.000 (0.002)	Loss 0.4504 (0.5267)	Acc@1 85.156 (81.784)	Acc@5 99.609 (99.101)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:24/25; Lr: 0.1
batch Size 256
Epoch: [24][0/196]	Time 0.125 (0.125)	Data 0.253 (0.253)	Loss 0.4326 (0.4326)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 0.171 (0.138)	Data 0.000 (0.004)	Loss 0.4837 (0.4996)	Acc@1 83.984 (82.488)	Acc@5 100.000 (99.231)
Epoch: [24][128/196]	Time 0.191 (0.139)	Data 0.000 (0.002)	Loss 0.4419 (0.5095)	Acc@1 85.156 (82.052)	Acc@5 100.000 (99.137)
Epoch: [24][192/196]	Time 0.182 (0.138)	Data 0.000 (0.002)	Loss 0.6019 (0.5171)	Acc@1 78.906 (81.977)	Acc@5 98.047 (99.116)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:25/25; Lr: 0.1
batch Size 256
Epoch: [25][0/196]	Time 0.129 (0.129)	Data 0.428 (0.428)	Loss 0.4873 (0.4873)	Acc@1 82.812 (82.812)	Acc@5 97.656 (97.656)
Epoch: [25][64/196]	Time 0.193 (0.138)	Data 0.000 (0.007)	Loss 0.5249 (0.5253)	Acc@1 85.938 (82.109)	Acc@5 98.438 (99.026)
Epoch: [25][128/196]	Time 0.195 (0.137)	Data 0.000 (0.004)	Loss 0.4873 (0.5199)	Acc@1 80.859 (82.171)	Acc@5 99.219 (99.104)
Epoch: [25][192/196]	Time 0.108 (0.137)	Data 0.000 (0.002)	Loss 0.5853 (0.5207)	Acc@1 78.125 (82.060)	Acc@5 99.609 (99.134)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  77.86
Max memory: 33.0690048
 27.142s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 105
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.0665088
lr: 0.1
1
Epoche:26/30; Lr: 0.1
batch Size 256
Epoch: [26][0/196]	Time 0.224 (0.224)	Data 0.451 (0.451)	Loss 0.4556 (0.4556)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 0.108 (0.137)	Data 0.000 (0.007)	Loss 0.5452 (0.5104)	Acc@1 80.078 (82.200)	Acc@5 100.000 (99.087)
Epoch: [26][128/196]	Time 0.159 (0.135)	Data 0.000 (0.004)	Loss 0.4981 (0.5147)	Acc@1 85.156 (82.155)	Acc@5 99.609 (99.137)
Epoch: [26][192/196]	Time 0.179 (0.136)	Data 0.000 (0.003)	Loss 0.4592 (0.5145)	Acc@1 84.766 (82.187)	Acc@5 98.828 (99.099)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:27/30; Lr: 0.1
batch Size 256
Epoch: [27][0/196]	Time 0.106 (0.106)	Data 0.328 (0.328)	Loss 0.5667 (0.5667)	Acc@1 79.297 (79.297)	Acc@5 99.609 (99.609)
Epoch: [27][64/196]	Time 0.071 (0.137)	Data 0.000 (0.005)	Loss 0.4952 (0.5041)	Acc@1 83.203 (82.488)	Acc@5 98.438 (99.189)
Epoch: [27][128/196]	Time 0.095 (0.134)	Data 0.000 (0.003)	Loss 0.6025 (0.5217)	Acc@1 79.297 (81.998)	Acc@5 97.656 (99.155)
Epoch: [27][192/196]	Time 0.101 (0.131)	Data 0.000 (0.002)	Loss 0.4472 (0.5197)	Acc@1 83.984 (82.092)	Acc@5 99.609 (99.122)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:28/30; Lr: 0.1
batch Size 256
Epoch: [28][0/196]	Time 0.206 (0.206)	Data 0.327 (0.327)	Loss 0.6142 (0.6142)	Acc@1 79.688 (79.688)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.177 (0.138)	Data 0.000 (0.005)	Loss 0.5937 (0.5224)	Acc@1 80.469 (82.133)	Acc@5 99.609 (99.129)
Epoch: [28][128/196]	Time 0.094 (0.137)	Data 0.000 (0.003)	Loss 0.5201 (0.5210)	Acc@1 81.641 (82.207)	Acc@5 99.219 (99.140)
Epoch: [28][192/196]	Time 0.195 (0.137)	Data 0.000 (0.002)	Loss 0.6094 (0.5170)	Acc@1 77.344 (82.323)	Acc@5 98.828 (99.168)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:29/30; Lr: 0.1
batch Size 256
Epoch: [29][0/196]	Time 0.183 (0.183)	Data 0.346 (0.346)	Loss 0.5071 (0.5071)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [29][64/196]	Time 0.184 (0.136)	Data 0.000 (0.006)	Loss 0.5460 (0.5128)	Acc@1 82.812 (82.512)	Acc@5 98.828 (99.105)
Epoch: [29][128/196]	Time 0.063 (0.136)	Data 0.000 (0.003)	Loss 0.5306 (0.5071)	Acc@1 81.641 (82.773)	Acc@5 98.828 (99.122)
Epoch: [29][192/196]	Time 0.170 (0.136)	Data 0.000 (0.002)	Loss 0.4058 (0.5062)	Acc@1 85.938 (82.738)	Acc@5 100.000 (99.126)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:30/30; Lr: 0.1
batch Size 256
Epoch: [30][0/196]	Time 0.144 (0.144)	Data 0.374 (0.374)	Loss 0.4383 (0.4383)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [30][64/196]	Time 0.065 (0.121)	Data 0.000 (0.006)	Loss 0.4707 (0.4889)	Acc@1 83.984 (82.987)	Acc@5 98.828 (99.177)
Epoch: [30][128/196]	Time 0.177 (0.129)	Data 0.000 (0.003)	Loss 0.4455 (0.5007)	Acc@1 82.422 (82.643)	Acc@5 99.219 (99.125)
Epoch: [30][192/196]	Time 0.151 (0.132)	Data 0.000 (0.002)	Loss 0.5080 (0.5050)	Acc@1 83.203 (82.594)	Acc@5 98.828 (99.116)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  74.75
Max memory: 33.0690048
 26.327s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5404
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0665088
lr: 0.1
1
Epoche:31/35; Lr: 0.1
batch Size 256
Epoch: [31][0/196]	Time 0.140 (0.140)	Data 0.446 (0.446)	Loss 0.5104 (0.5104)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [31][64/196]	Time 0.073 (0.134)	Data 0.000 (0.007)	Loss 0.4016 (0.4889)	Acc@1 86.328 (83.305)	Acc@5 100.000 (99.123)
Epoch: [31][128/196]	Time 0.176 (0.134)	Data 0.000 (0.004)	Loss 0.4126 (0.4980)	Acc@1 87.891 (82.991)	Acc@5 99.219 (99.095)
Epoch: [31][192/196]	Time 0.102 (0.133)	Data 0.000 (0.003)	Loss 0.5132 (0.5017)	Acc@1 82.812 (82.752)	Acc@5 99.219 (99.154)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:32/35; Lr: 0.1
batch Size 256
Epoch: [32][0/196]	Time 0.179 (0.179)	Data 0.337 (0.337)	Loss 0.5184 (0.5184)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.063 (0.134)	Data 0.000 (0.005)	Loss 0.5822 (0.4985)	Acc@1 78.906 (82.897)	Acc@5 99.219 (99.111)
Epoch: [32][128/196]	Time 0.194 (0.137)	Data 0.000 (0.003)	Loss 0.5290 (0.5005)	Acc@1 80.078 (82.679)	Acc@5 99.609 (99.179)
Epoch: [32][192/196]	Time 0.154 (0.137)	Data 0.000 (0.002)	Loss 0.4627 (0.5003)	Acc@1 83.594 (82.804)	Acc@5 98.438 (99.184)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:33/35; Lr: 0.1
batch Size 256
Epoch: [33][0/196]	Time 0.230 (0.230)	Data 0.363 (0.363)	Loss 0.5497 (0.5497)	Acc@1 81.250 (81.250)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.069 (0.137)	Data 0.000 (0.006)	Loss 0.4543 (0.4909)	Acc@1 83.594 (83.209)	Acc@5 98.438 (99.147)
Epoch: [33][128/196]	Time 0.183 (0.139)	Data 0.000 (0.003)	Loss 0.5082 (0.4922)	Acc@1 85.156 (83.043)	Acc@5 99.219 (99.146)
Epoch: [33][192/196]	Time 0.078 (0.138)	Data 0.000 (0.002)	Loss 0.4984 (0.4974)	Acc@1 80.859 (82.784)	Acc@5 98.828 (99.170)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:34/35; Lr: 0.1
batch Size 256
Epoch: [34][0/196]	Time 0.193 (0.193)	Data 0.287 (0.287)	Loss 0.5606 (0.5606)	Acc@1 80.078 (80.078)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.139 (0.138)	Data 0.000 (0.005)	Loss 0.4788 (0.5004)	Acc@1 82.812 (82.626)	Acc@5 99.609 (99.123)
Epoch: [34][128/196]	Time 0.171 (0.131)	Data 0.000 (0.002)	Loss 0.3782 (0.4926)	Acc@1 89.453 (82.991)	Acc@5 99.219 (99.191)
Epoch: [34][192/196]	Time 0.205 (0.133)	Data 0.000 (0.002)	Loss 0.5286 (0.5010)	Acc@1 81.641 (82.784)	Acc@5 99.219 (99.148)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:35/35; Lr: 0.1
batch Size 256
Epoch: [35][0/196]	Time 0.199 (0.199)	Data 0.334 (0.334)	Loss 0.4398 (0.4398)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 0.186 (0.140)	Data 0.000 (0.005)	Loss 0.4537 (0.5023)	Acc@1 83.984 (82.758)	Acc@5 99.609 (99.219)
Epoch: [35][128/196]	Time 0.088 (0.140)	Data 0.000 (0.003)	Loss 0.5359 (0.5015)	Acc@1 80.859 (82.719)	Acc@5 99.609 (99.222)
Epoch: [35][192/196]	Time 0.076 (0.139)	Data 0.000 (0.002)	Loss 0.5491 (0.4977)	Acc@1 80.859 (82.827)	Acc@5 98.828 (99.213)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  70.97
Max memory: 33.0690048
 27.730s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 414
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.0665088
lr: 0.1
1
Epoche:36/40; Lr: 0.1
batch Size 256
Epoch: [36][0/196]	Time 0.194 (0.194)	Data 0.432 (0.432)	Loss 0.4854 (0.4854)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [36][64/196]	Time 0.139 (0.116)	Data 0.000 (0.007)	Loss 0.5322 (0.4664)	Acc@1 82.812 (83.918)	Acc@5 99.219 (99.351)
Epoch: [36][128/196]	Time 0.068 (0.125)	Data 0.000 (0.004)	Loss 0.5298 (0.4833)	Acc@1 78.906 (83.197)	Acc@5 99.609 (99.273)
Epoch: [36][192/196]	Time 0.177 (0.128)	Data 0.000 (0.002)	Loss 0.4684 (0.4905)	Acc@1 83.984 (83.023)	Acc@5 100.000 (99.237)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:37/40; Lr: 0.1
batch Size 256
Epoch: [37][0/196]	Time 0.136 (0.136)	Data 0.338 (0.338)	Loss 0.3503 (0.3503)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 0.062 (0.137)	Data 0.000 (0.005)	Loss 0.5359 (0.4801)	Acc@1 82.031 (83.401)	Acc@5 99.219 (99.171)
Epoch: [37][128/196]	Time 0.196 (0.137)	Data 0.000 (0.003)	Loss 0.5419 (0.4886)	Acc@1 80.469 (83.024)	Acc@5 99.609 (99.270)
Epoch: [37][192/196]	Time 0.137 (0.137)	Data 0.000 (0.002)	Loss 0.4701 (0.4948)	Acc@1 83.594 (82.841)	Acc@5 98.438 (99.203)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:38/40; Lr: 0.1
batch Size 256
Epoch: [38][0/196]	Time 0.199 (0.199)	Data 0.373 (0.373)	Loss 0.5036 (0.5036)	Acc@1 81.641 (81.641)	Acc@5 99.219 (99.219)
Epoch: [38][64/196]	Time 0.195 (0.140)	Data 0.000 (0.006)	Loss 0.5348 (0.4789)	Acc@1 82.422 (83.564)	Acc@5 98.047 (99.225)
Epoch: [38][128/196]	Time 0.059 (0.139)	Data 0.000 (0.003)	Loss 0.5302 (0.4887)	Acc@1 81.641 (83.088)	Acc@5 98.828 (99.191)
Epoch: [38][192/196]	Time 0.192 (0.133)	Data 0.000 (0.002)	Loss 0.4539 (0.4883)	Acc@1 84.766 (83.189)	Acc@5 99.609 (99.233)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:39/40; Lr: 0.1
batch Size 256
Epoch: [39][0/196]	Time 0.093 (0.093)	Data 0.406 (0.406)	Loss 0.4684 (0.4684)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [39][64/196]	Time 0.194 (0.137)	Data 0.000 (0.006)	Loss 0.5332 (0.4859)	Acc@1 85.156 (83.167)	Acc@5 98.438 (99.231)
Epoch: [39][128/196]	Time 0.123 (0.135)	Data 0.000 (0.003)	Loss 0.4003 (0.4835)	Acc@1 83.594 (83.315)	Acc@5 99.609 (99.228)
Epoch: [39][192/196]	Time 0.061 (0.136)	Data 0.000 (0.002)	Loss 0.4958 (0.4832)	Acc@1 83.203 (83.321)	Acc@5 98.828 (99.209)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:40/40; Lr: 0.1
batch Size 256
Epoch: [40][0/196]	Time 0.094 (0.094)	Data 0.375 (0.375)	Loss 0.4811 (0.4811)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [40][64/196]	Time 0.094 (0.137)	Data 0.000 (0.006)	Loss 0.5046 (0.4770)	Acc@1 83.203 (83.419)	Acc@5 99.609 (99.297)
Epoch: [40][128/196]	Time 0.061 (0.138)	Data 0.000 (0.003)	Loss 0.5801 (0.4914)	Acc@1 81.250 (82.931)	Acc@5 98.828 (99.207)
Epoch: [40][192/196]	Time 0.161 (0.138)	Data 0.000 (0.002)	Loss 0.5388 (0.4891)	Acc@1 80.469 (83.005)	Acc@5 98.828 (99.249)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  76.33
Max memory: 33.0690048
 27.450s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5003
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.0665088
lr: 0.1
1
Epoche:41/45; Lr: 0.1
batch Size 256
Epoch: [41][0/196]	Time 0.185 (0.185)	Data 0.406 (0.406)	Loss 0.5341 (0.5341)	Acc@1 80.469 (80.469)	Acc@5 98.828 (98.828)
Epoch: [41][64/196]	Time 0.158 (0.135)	Data 0.000 (0.006)	Loss 0.5007 (0.4616)	Acc@1 82.031 (84.038)	Acc@5 99.219 (99.249)
Epoch: [41][128/196]	Time 0.078 (0.134)	Data 0.000 (0.003)	Loss 0.4953 (0.4728)	Acc@1 81.641 (83.594)	Acc@5 99.219 (99.313)
Epoch: [41][192/196]	Time 0.178 (0.134)	Data 0.000 (0.002)	Loss 0.4447 (0.4797)	Acc@1 85.547 (83.383)	Acc@5 100.000 (99.263)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:42/45; Lr: 0.1
batch Size 256
Epoch: [42][0/196]	Time 0.207 (0.207)	Data 0.422 (0.422)	Loss 0.5919 (0.5919)	Acc@1 80.859 (80.859)	Acc@5 98.828 (98.828)
Epoch: [42][64/196]	Time 0.156 (0.136)	Data 0.000 (0.007)	Loss 0.4342 (0.4832)	Acc@1 86.719 (83.401)	Acc@5 99.219 (99.297)
Epoch: [42][128/196]	Time 0.068 (0.135)	Data 0.000 (0.003)	Loss 0.5740 (0.4865)	Acc@1 80.859 (83.140)	Acc@5 99.219 (99.301)
Epoch: [42][192/196]	Time 0.187 (0.136)	Data 0.000 (0.002)	Loss 0.4513 (0.4887)	Acc@1 86.719 (83.072)	Acc@5 99.219 (99.257)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:43/45; Lr: 0.1
batch Size 256
Epoch: [43][0/196]	Time 0.112 (0.112)	Data 0.376 (0.376)	Loss 0.3931 (0.3931)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [43][64/196]	Time 0.148 (0.131)	Data 0.000 (0.006)	Loss 0.3959 (0.4719)	Acc@1 88.281 (83.918)	Acc@5 100.000 (99.387)
Epoch: [43][128/196]	Time 0.196 (0.134)	Data 0.000 (0.003)	Loss 0.4694 (0.4769)	Acc@1 83.594 (83.830)	Acc@5 99.219 (99.316)
Epoch: [43][192/196]	Time 0.064 (0.135)	Data 0.000 (0.002)	Loss 0.4240 (0.4769)	Acc@1 85.547 (83.665)	Acc@5 98.828 (99.298)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:44/45; Lr: 0.1
batch Size 256
Epoch: [44][0/196]	Time 0.107 (0.107)	Data 0.389 (0.389)	Loss 0.4441 (0.4441)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [44][64/196]	Time 0.075 (0.137)	Data 0.000 (0.006)	Loss 0.3995 (0.4880)	Acc@1 85.547 (82.957)	Acc@5 99.609 (99.213)
Epoch: [44][128/196]	Time 0.160 (0.136)	Data 0.000 (0.003)	Loss 0.4251 (0.4808)	Acc@1 86.328 (83.336)	Acc@5 99.609 (99.213)
Epoch: [44][192/196]	Time 0.123 (0.137)	Data 0.000 (0.002)	Loss 0.4746 (0.4826)	Acc@1 84.375 (83.391)	Acc@5 98.438 (99.178)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:45/45; Lr: 0.1
batch Size 256
Epoch: [45][0/196]	Time 0.149 (0.149)	Data 0.376 (0.376)	Loss 0.5621 (0.5621)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [45][64/196]	Time 0.115 (0.139)	Data 0.000 (0.006)	Loss 0.4908 (0.4613)	Acc@1 81.641 (84.081)	Acc@5 99.609 (99.231)
Epoch: [45][128/196]	Time 0.071 (0.133)	Data 0.000 (0.003)	Loss 0.5782 (0.4727)	Acc@1 79.688 (83.736)	Acc@5 99.219 (99.264)
Epoch: [45][192/196]	Time 0.153 (0.133)	Data 0.000 (0.002)	Loss 0.5154 (0.4765)	Acc@1 82.031 (83.691)	Acc@5 98.828 (99.235)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  74.96
Max memory: 33.0690048
 26.666s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6632
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.0665088
lr: 0.1
1
Epoche:46/50; Lr: 0.1
batch Size 256
Epoch: [46][0/196]	Time 0.174 (0.174)	Data 0.381 (0.381)	Loss 0.4677 (0.4677)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 0.177 (0.134)	Data 0.000 (0.006)	Loss 0.4618 (0.4615)	Acc@1 83.594 (84.069)	Acc@5 99.609 (99.393)
Epoch: [46][128/196]	Time 0.066 (0.133)	Data 0.000 (0.003)	Loss 0.4486 (0.4732)	Acc@1 84.375 (83.591)	Acc@5 99.609 (99.267)
Epoch: [46][192/196]	Time 0.187 (0.134)	Data 0.000 (0.002)	Loss 0.4905 (0.4773)	Acc@1 82.422 (83.428)	Acc@5 99.219 (99.211)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:47/50; Lr: 0.1
batch Size 256
Epoch: [47][0/196]	Time 0.180 (0.180)	Data 0.354 (0.354)	Loss 0.4894 (0.4894)	Acc@1 82.812 (82.812)	Acc@5 98.828 (98.828)
Epoch: [47][64/196]	Time 0.101 (0.127)	Data 0.000 (0.006)	Loss 0.5338 (0.4755)	Acc@1 80.859 (83.852)	Acc@5 99.219 (99.279)
Epoch: [47][128/196]	Time 0.108 (0.128)	Data 0.000 (0.003)	Loss 0.5520 (0.4721)	Acc@1 82.422 (83.788)	Acc@5 98.047 (99.294)
Epoch: [47][192/196]	Time 0.185 (0.131)	Data 0.000 (0.002)	Loss 0.4657 (0.4768)	Acc@1 85.156 (83.665)	Acc@5 99.219 (99.257)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:48/50; Lr: 0.1
batch Size 256
Epoch: [48][0/196]	Time 0.167 (0.167)	Data 0.373 (0.373)	Loss 0.3649 (0.3649)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [48][64/196]	Time 0.061 (0.133)	Data 0.000 (0.006)	Loss 0.4743 (0.4717)	Acc@1 83.203 (83.600)	Acc@5 99.609 (99.279)
Epoch: [48][128/196]	Time 0.070 (0.134)	Data 0.000 (0.003)	Loss 0.5035 (0.4741)	Acc@1 83.984 (83.554)	Acc@5 99.609 (99.304)
Epoch: [48][192/196]	Time 0.185 (0.135)	Data 0.000 (0.002)	Loss 0.4320 (0.4759)	Acc@1 84.375 (83.567)	Acc@5 99.609 (99.263)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:49/50; Lr: 0.1
batch Size 256
Epoch: [49][0/196]	Time 0.183 (0.183)	Data 0.426 (0.426)	Loss 0.6462 (0.6462)	Acc@1 77.734 (77.734)	Acc@5 98.438 (98.438)
Epoch: [49][64/196]	Time 0.078 (0.136)	Data 0.000 (0.007)	Loss 0.4201 (0.4606)	Acc@1 84.766 (83.984)	Acc@5 98.047 (99.213)
Epoch: [49][128/196]	Time 0.069 (0.136)	Data 0.000 (0.004)	Loss 0.5421 (0.4812)	Acc@1 79.688 (83.327)	Acc@5 99.219 (99.161)
Epoch: [49][192/196]	Time 0.098 (0.134)	Data 0.000 (0.002)	Loss 0.5345 (0.4807)	Acc@1 81.250 (83.219)	Acc@5 98.828 (99.207)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:50/50; Lr: 0.1
batch Size 256
Epoch: [50][0/196]	Time 0.200 (0.200)	Data 0.312 (0.312)	Loss 0.3671 (0.3671)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [50][64/196]	Time 0.112 (0.136)	Data 0.000 (0.005)	Loss 0.5456 (0.4659)	Acc@1 81.250 (83.570)	Acc@5 98.438 (99.321)
Epoch: [50][128/196]	Time 0.155 (0.136)	Data 0.000 (0.003)	Loss 0.4434 (0.4604)	Acc@1 83.984 (83.863)	Acc@5 100.000 (99.279)
Epoch: [50][192/196]	Time 0.173 (0.137)	Data 0.000 (0.002)	Loss 0.5485 (0.4689)	Acc@1 78.906 (83.642)	Acc@5 99.609 (99.239)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  76.56
Max memory: 33.0690048
 27.303s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5890
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.0665088
lr: 0.1
1
Epoche:51/55; Lr: 0.1
batch Size 256
Epoch: [51][0/196]	Time 0.157 (0.157)	Data 0.431 (0.431)	Loss 0.4986 (0.4986)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [51][64/196]	Time 0.186 (0.134)	Data 0.000 (0.007)	Loss 0.4820 (0.4415)	Acc@1 82.422 (84.922)	Acc@5 98.438 (99.267)
Epoch: [51][128/196]	Time 0.143 (0.126)	Data 0.000 (0.004)	Loss 0.4962 (0.4644)	Acc@1 83.984 (83.993)	Acc@5 99.609 (99.252)
Epoch: [51][192/196]	Time 0.201 (0.129)	Data 0.000 (0.002)	Loss 0.5425 (0.4641)	Acc@1 81.250 (83.964)	Acc@5 98.828 (99.279)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:52/55; Lr: 0.1
batch Size 256
Epoch: [52][0/196]	Time 0.101 (0.101)	Data 0.352 (0.352)	Loss 0.4255 (0.4255)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [52][64/196]	Time 0.067 (0.136)	Data 0.000 (0.006)	Loss 0.4151 (0.4577)	Acc@1 84.766 (84.153)	Acc@5 100.000 (99.339)
Epoch: [52][128/196]	Time 0.094 (0.137)	Data 0.000 (0.003)	Loss 0.5567 (0.4617)	Acc@1 79.688 (83.996)	Acc@5 98.828 (99.267)
Epoch: [52][192/196]	Time 0.070 (0.137)	Data 0.000 (0.002)	Loss 0.4334 (0.4653)	Acc@1 84.766 (83.912)	Acc@5 99.219 (99.253)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:53/55; Lr: 0.1
batch Size 256
Epoch: [53][0/196]	Time 0.200 (0.200)	Data 0.356 (0.356)	Loss 0.5171 (0.5171)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [53][64/196]	Time 0.136 (0.140)	Data 0.000 (0.006)	Loss 0.3731 (0.4755)	Acc@1 87.109 (83.486)	Acc@5 100.000 (99.303)
Epoch: [53][128/196]	Time 0.190 (0.139)	Data 0.000 (0.003)	Loss 0.4282 (0.4750)	Acc@1 84.766 (83.491)	Acc@5 99.219 (99.294)
Epoch: [53][192/196]	Time 0.174 (0.139)	Data 0.000 (0.002)	Loss 0.4937 (0.4797)	Acc@1 82.031 (83.397)	Acc@5 100.000 (99.284)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:54/55; Lr: 0.1
batch Size 256
Epoch: [54][0/196]	Time 0.114 (0.114)	Data 0.418 (0.418)	Loss 0.4898 (0.4898)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [54][64/196]	Time 0.182 (0.125)	Data 0.000 (0.007)	Loss 0.4390 (0.4665)	Acc@1 82.031 (83.924)	Acc@5 100.000 (99.363)
Epoch: [54][128/196]	Time 0.073 (0.133)	Data 0.000 (0.003)	Loss 0.4935 (0.4673)	Acc@1 84.375 (83.887)	Acc@5 98.828 (99.337)
Epoch: [54][192/196]	Time 0.162 (0.135)	Data 0.000 (0.002)	Loss 0.4002 (0.4661)	Acc@1 87.109 (83.883)	Acc@5 99.609 (99.300)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:55/55; Lr: 0.1
batch Size 256
Epoch: [55][0/196]	Time 0.231 (0.231)	Data 0.451 (0.451)	Loss 0.5280 (0.5280)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [55][64/196]	Time 0.077 (0.139)	Data 0.000 (0.007)	Loss 0.4898 (0.4824)	Acc@1 82.031 (83.431)	Acc@5 99.219 (99.273)
Epoch: [55][128/196]	Time 0.143 (0.138)	Data 0.000 (0.004)	Loss 0.5386 (0.4768)	Acc@1 82.422 (83.603)	Acc@5 99.219 (99.285)
Epoch: [55][192/196]	Time 0.145 (0.139)	Data 0.000 (0.003)	Loss 0.4217 (0.4753)	Acc@1 83.984 (83.703)	Acc@5 99.609 (99.251)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  75.34
Max memory: 33.0690048
 27.789s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 1000
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.0665088
lr: 0.1
1
Epoche:56/60; Lr: 0.1
batch Size 256
Epoch: [56][0/196]	Time 0.227 (0.227)	Data 0.380 (0.380)	Loss 0.4398 (0.4398)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [56][64/196]	Time 0.129 (0.133)	Data 0.000 (0.006)	Loss 0.3318 (0.4418)	Acc@1 89.062 (84.772)	Acc@5 100.000 (99.327)
Epoch: [56][128/196]	Time 0.054 (0.133)	Data 0.000 (0.003)	Loss 0.3468 (0.4537)	Acc@1 88.672 (84.408)	Acc@5 100.000 (99.294)
Epoch: [56][192/196]	Time 0.079 (0.134)	Data 0.000 (0.002)	Loss 0.3726 (0.4599)	Acc@1 88.281 (84.175)	Acc@5 100.000 (99.255)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:57/60; Lr: 0.1
batch Size 256
Epoch: [57][0/196]	Time 0.088 (0.088)	Data 0.317 (0.317)	Loss 0.4497 (0.4497)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.194 (0.136)	Data 0.000 (0.005)	Loss 0.5263 (0.4689)	Acc@1 80.859 (83.660)	Acc@5 98.828 (99.267)
Epoch: [57][128/196]	Time 0.076 (0.135)	Data 0.000 (0.003)	Loss 0.5653 (0.4788)	Acc@1 80.469 (83.358)	Acc@5 100.000 (99.231)
Epoch: [57][192/196]	Time 0.116 (0.135)	Data 0.000 (0.002)	Loss 0.3648 (0.4781)	Acc@1 86.328 (83.339)	Acc@5 99.609 (99.231)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:58/60; Lr: 0.1
batch Size 256
Epoch: [58][0/196]	Time 0.190 (0.190)	Data 0.403 (0.403)	Loss 0.3936 (0.3936)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 0.062 (0.134)	Data 0.000 (0.006)	Loss 0.4782 (0.4634)	Acc@1 82.031 (84.399)	Acc@5 99.609 (99.297)
Epoch: [58][128/196]	Time 0.150 (0.129)	Data 0.000 (0.003)	Loss 0.4488 (0.4630)	Acc@1 83.594 (84.272)	Acc@5 100.000 (99.288)
Epoch: [58][192/196]	Time 0.181 (0.131)	Data 0.000 (0.002)	Loss 0.4823 (0.4665)	Acc@1 84.375 (84.108)	Acc@5 99.219 (99.304)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:59/60; Lr: 0.1
batch Size 256
Epoch: [59][0/196]	Time 0.205 (0.205)	Data 0.380 (0.380)	Loss 0.5093 (0.5093)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.064 (0.135)	Data 0.000 (0.006)	Loss 0.3415 (0.4647)	Acc@1 88.281 (83.918)	Acc@5 100.000 (99.237)
Epoch: [59][128/196]	Time 0.187 (0.137)	Data 0.000 (0.003)	Loss 0.4810 (0.4622)	Acc@1 84.766 (84.142)	Acc@5 98.047 (99.243)
Epoch: [59][192/196]	Time 0.068 (0.136)	Data 0.000 (0.002)	Loss 0.5738 (0.4669)	Acc@1 82.031 (83.901)	Acc@5 99.219 (99.235)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:60/60; Lr: 0.1
batch Size 256
Epoch: [60][0/196]	Time 0.219 (0.219)	Data 0.420 (0.420)	Loss 0.3511 (0.3511)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [60][64/196]	Time 0.194 (0.138)	Data 0.000 (0.007)	Loss 0.3664 (0.4516)	Acc@1 87.500 (84.519)	Acc@5 98.828 (99.351)
Epoch: [60][128/196]	Time 0.072 (0.137)	Data 0.000 (0.003)	Loss 0.4662 (0.4594)	Acc@1 83.984 (84.248)	Acc@5 99.219 (99.343)
Epoch: [60][192/196]	Time 0.086 (0.135)	Data 0.000 (0.002)	Loss 0.4266 (0.4645)	Acc@1 84.766 (84.029)	Acc@5 99.219 (99.326)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  76.49
Max memory: 33.0690048
 26.863s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4806
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.0665088
lr: 0.1
1
Epoche:61/65; Lr: 0.1
batch Size 256
Epoch: [61][0/196]	Time 0.197 (0.197)	Data 0.308 (0.308)	Loss 0.5058 (0.5058)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [61][64/196]	Time 0.181 (0.137)	Data 0.000 (0.005)	Loss 0.4330 (0.4493)	Acc@1 85.938 (84.639)	Acc@5 99.609 (99.273)
Epoch: [61][128/196]	Time 0.154 (0.135)	Data 0.000 (0.003)	Loss 0.4112 (0.4575)	Acc@1 85.938 (84.363)	Acc@5 99.609 (99.291)
Epoch: [61][192/196]	Time 0.057 (0.135)	Data 0.000 (0.002)	Loss 0.5427 (0.4628)	Acc@1 81.250 (84.122)	Acc@5 98.828 (99.296)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:62/65; Lr: 0.1
batch Size 256
Epoch: [62][0/196]	Time 0.108 (0.108)	Data 0.413 (0.413)	Loss 0.4500 (0.4500)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.188 (0.136)	Data 0.000 (0.007)	Loss 0.4724 (0.4576)	Acc@1 84.766 (84.225)	Acc@5 99.219 (99.213)
Epoch: [62][128/196]	Time 0.085 (0.131)	Data 0.000 (0.003)	Loss 0.4068 (0.4639)	Acc@1 85.938 (84.124)	Acc@5 98.828 (99.252)
Epoch: [62][192/196]	Time 0.198 (0.131)	Data 0.000 (0.002)	Loss 0.4084 (0.4628)	Acc@1 86.328 (84.245)	Acc@5 99.219 (99.263)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:63/65; Lr: 0.1
batch Size 256
Epoch: [63][0/196]	Time 0.133 (0.133)	Data 0.324 (0.324)	Loss 0.3885 (0.3885)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [63][64/196]	Time 0.184 (0.138)	Data 0.000 (0.005)	Loss 0.4826 (0.4554)	Acc@1 85.547 (84.381)	Acc@5 97.266 (99.201)
Epoch: [63][128/196]	Time 0.074 (0.136)	Data 0.000 (0.003)	Loss 0.4508 (0.4615)	Acc@1 85.547 (84.027)	Acc@5 100.000 (99.252)
Epoch: [63][192/196]	Time 0.143 (0.136)	Data 0.000 (0.002)	Loss 0.5288 (0.4640)	Acc@1 82.812 (83.984)	Acc@5 99.219 (99.261)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:64/65; Lr: 0.1
batch Size 256
Epoch: [64][0/196]	Time 0.131 (0.131)	Data 0.384 (0.384)	Loss 0.5323 (0.5323)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [64][64/196]	Time 0.195 (0.137)	Data 0.000 (0.006)	Loss 0.4851 (0.4670)	Acc@1 84.375 (83.708)	Acc@5 99.219 (99.369)
Epoch: [64][128/196]	Time 0.185 (0.137)	Data 0.000 (0.003)	Loss 0.4332 (0.4675)	Acc@1 86.719 (83.785)	Acc@5 98.828 (99.279)
Epoch: [64][192/196]	Time 0.150 (0.137)	Data 0.000 (0.002)	Loss 0.4474 (0.4625)	Acc@1 87.109 (83.950)	Acc@5 98.828 (99.290)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:65/65; Lr: 0.1
batch Size 256
Epoch: [65][0/196]	Time 0.127 (0.127)	Data 0.375 (0.375)	Loss 0.3750 (0.3750)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.073 (0.123)	Data 0.000 (0.006)	Loss 0.4210 (0.4489)	Acc@1 86.719 (84.706)	Acc@5 98.828 (99.375)
Epoch: [65][128/196]	Time 0.166 (0.130)	Data 0.000 (0.003)	Loss 0.5209 (0.4583)	Acc@1 82.812 (84.402)	Acc@5 97.656 (99.246)
Epoch: [65][192/196]	Time 0.174 (0.132)	Data 0.000 (0.002)	Loss 0.4208 (0.4611)	Acc@1 83.984 (84.171)	Acc@5 99.609 (99.237)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  64.3
Max memory: 33.0690048
 26.359s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 778
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.0665088
lr: 0.1
1
Epoche:66/70; Lr: 0.1
batch Size 256
Epoch: [66][0/196]	Time 0.209 (0.209)	Data 0.317 (0.317)	Loss 0.4107 (0.4107)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.158 (0.135)	Data 0.000 (0.005)	Loss 0.3791 (0.4322)	Acc@1 88.281 (85.228)	Acc@5 98.828 (99.375)
Epoch: [66][128/196]	Time 0.063 (0.134)	Data 0.000 (0.003)	Loss 0.3885 (0.4552)	Acc@1 85.938 (84.281)	Acc@5 98.828 (99.252)
Epoch: [66][192/196]	Time 0.094 (0.131)	Data 0.000 (0.002)	Loss 0.4815 (0.4574)	Acc@1 84.375 (84.181)	Acc@5 100.000 (99.277)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:67/70; Lr: 0.1
batch Size 256
Epoch: [67][0/196]	Time 0.193 (0.193)	Data 0.388 (0.388)	Loss 0.4485 (0.4485)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.099 (0.137)	Data 0.000 (0.006)	Loss 0.4033 (0.4516)	Acc@1 84.766 (84.561)	Acc@5 99.219 (99.237)
Epoch: [67][128/196]	Time 0.187 (0.137)	Data 0.000 (0.003)	Loss 0.4380 (0.4546)	Acc@1 85.547 (84.423)	Acc@5 99.609 (99.228)
Epoch: [67][192/196]	Time 0.143 (0.137)	Data 0.000 (0.002)	Loss 0.4958 (0.4593)	Acc@1 81.250 (84.270)	Acc@5 99.609 (99.245)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:68/70; Lr: 0.1
batch Size 256
Epoch: [68][0/196]	Time 0.112 (0.112)	Data 0.363 (0.363)	Loss 0.5459 (0.5459)	Acc@1 79.297 (79.297)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.160 (0.139)	Data 0.000 (0.006)	Loss 0.4307 (0.4567)	Acc@1 85.938 (84.375)	Acc@5 98.438 (99.291)
Epoch: [68][128/196]	Time 0.079 (0.139)	Data 0.000 (0.003)	Loss 0.5112 (0.4608)	Acc@1 82.812 (84.066)	Acc@5 99.609 (99.313)
Epoch: [68][192/196]	Time 0.191 (0.138)	Data 0.000 (0.002)	Loss 0.4793 (0.4625)	Acc@1 85.156 (84.033)	Acc@5 99.609 (99.265)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:69/70; Lr: 0.1
batch Size 256
Epoch: [69][0/196]	Time 0.171 (0.171)	Data 0.343 (0.343)	Loss 0.4187 (0.4187)	Acc@1 83.594 (83.594)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.189 (0.138)	Data 0.000 (0.006)	Loss 0.3697 (0.4499)	Acc@1 87.500 (84.309)	Acc@5 99.609 (99.249)
Epoch: [69][128/196]	Time 0.159 (0.129)	Data 0.000 (0.003)	Loss 0.4958 (0.4559)	Acc@1 81.641 (84.172)	Acc@5 99.609 (99.273)
Epoch: [69][192/196]	Time 0.199 (0.132)	Data 0.000 (0.002)	Loss 0.5061 (0.4604)	Acc@1 80.859 (84.114)	Acc@5 99.609 (99.257)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:70/70; Lr: 0.1
batch Size 256
Epoch: [70][0/196]	Time 0.147 (0.147)	Data 0.380 (0.380)	Loss 0.3950 (0.3950)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [70][64/196]	Time 0.066 (0.138)	Data 0.000 (0.006)	Loss 0.3524 (0.4516)	Acc@1 90.625 (84.585)	Acc@5 99.219 (99.159)
Epoch: [70][128/196]	Time 0.185 (0.139)	Data 0.000 (0.003)	Loss 0.4369 (0.4504)	Acc@1 85.156 (84.560)	Acc@5 99.219 (99.240)
Epoch: [70][192/196]	Time 0.182 (0.138)	Data 0.000 (0.002)	Loss 0.4880 (0.4498)	Acc@1 82.812 (84.598)	Acc@5 99.219 (99.290)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  78.68
Max memory: 33.0690048
 27.686s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8563
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.0665088
lr: 0.1
1
Epoche:71/75; Lr: 0.1
batch Size 256
Epoch: [71][0/196]	Time 0.183 (0.183)	Data 0.362 (0.362)	Loss 0.4325 (0.4325)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [71][64/196]	Time 0.177 (0.119)	Data 0.000 (0.006)	Loss 0.4250 (0.4315)	Acc@1 85.938 (84.922)	Acc@5 100.000 (99.531)
Epoch: [71][128/196]	Time 0.060 (0.126)	Data 0.000 (0.003)	Loss 0.5852 (0.4524)	Acc@1 81.641 (84.351)	Acc@5 98.438 (99.346)
Epoch: [71][192/196]	Time 0.178 (0.129)	Data 0.000 (0.002)	Loss 0.3694 (0.4557)	Acc@1 85.938 (84.335)	Acc@5 100.000 (99.342)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:72/75; Lr: 0.1
batch Size 256
Epoch: [72][0/196]	Time 0.080 (0.080)	Data 0.295 (0.295)	Loss 0.4401 (0.4401)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [72][64/196]	Time 0.190 (0.137)	Data 0.000 (0.005)	Loss 0.4965 (0.4553)	Acc@1 84.375 (84.207)	Acc@5 99.219 (99.309)
Epoch: [72][128/196]	Time 0.174 (0.136)	Data 0.000 (0.003)	Loss 0.5125 (0.4605)	Acc@1 83.984 (84.175)	Acc@5 99.219 (99.270)
Epoch: [72][192/196]	Time 0.172 (0.137)	Data 0.000 (0.002)	Loss 0.4828 (0.4590)	Acc@1 83.984 (84.314)	Acc@5 99.219 (99.294)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:73/75; Lr: 0.1
batch Size 256
Epoch: [73][0/196]	Time 0.194 (0.194)	Data 0.330 (0.330)	Loss 0.4613 (0.4613)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.174 (0.137)	Data 0.000 (0.005)	Loss 0.4460 (0.4614)	Acc@1 84.375 (84.123)	Acc@5 99.609 (99.261)
Epoch: [73][128/196]	Time 0.155 (0.138)	Data 0.000 (0.003)	Loss 0.4647 (0.4529)	Acc@1 85.938 (84.499)	Acc@5 100.000 (99.301)
Epoch: [73][192/196]	Time 0.172 (0.132)	Data 0.000 (0.002)	Loss 0.3759 (0.4564)	Acc@1 85.547 (84.377)	Acc@5 100.000 (99.318)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:74/75; Lr: 0.1
batch Size 256
Epoch: [74][0/196]	Time 0.195 (0.195)	Data 0.325 (0.325)	Loss 0.5495 (0.5495)	Acc@1 81.641 (81.641)	Acc@5 98.047 (98.047)
Epoch: [74][64/196]	Time 0.172 (0.138)	Data 0.000 (0.005)	Loss 0.5128 (0.4424)	Acc@1 82.031 (84.748)	Acc@5 99.609 (99.303)
Epoch: [74][128/196]	Time 0.106 (0.138)	Data 0.000 (0.003)	Loss 0.3992 (0.4595)	Acc@1 86.719 (84.060)	Acc@5 99.219 (99.240)
Epoch: [74][192/196]	Time 0.163 (0.137)	Data 0.000 (0.002)	Loss 0.4845 (0.4585)	Acc@1 85.547 (84.175)	Acc@5 98.438 (99.245)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:75/75; Lr: 0.1
batch Size 256
Epoch: [75][0/196]	Time 0.207 (0.207)	Data 0.365 (0.365)	Loss 0.4179 (0.4179)	Acc@1 85.156 (85.156)	Acc@5 98.828 (98.828)
Epoch: [75][64/196]	Time 0.168 (0.137)	Data 0.000 (0.006)	Loss 0.4368 (0.4589)	Acc@1 86.719 (84.321)	Acc@5 99.609 (99.255)
Epoch: [75][128/196]	Time 0.071 (0.136)	Data 0.000 (0.003)	Loss 0.3989 (0.4550)	Acc@1 85.156 (84.369)	Acc@5 99.609 (99.322)
Epoch: [75][192/196]	Time 0.061 (0.136)	Data 0.000 (0.002)	Loss 0.4611 (0.4565)	Acc@1 83.203 (84.337)	Acc@5 97.656 (99.288)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  77.19
Max memory: 33.0690048
 27.117s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7212
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.0665088
lr: 0.1
1
Epoche:76/80; Lr: 0.1
batch Size 256
Epoch: [76][0/196]	Time 0.267 (0.267)	Data 0.366 (0.366)	Loss 0.3853 (0.3853)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.190 (0.135)	Data 0.000 (0.006)	Loss 0.4392 (0.4358)	Acc@1 83.203 (85.030)	Acc@5 99.219 (99.339)
Epoch: [76][128/196]	Time 0.081 (0.133)	Data 0.000 (0.003)	Loss 0.4862 (0.4445)	Acc@1 83.984 (84.732)	Acc@5 99.609 (99.291)
Epoch: [76][192/196]	Time 0.057 (0.133)	Data 0.000 (0.002)	Loss 0.4045 (0.4493)	Acc@1 83.594 (84.488)	Acc@5 99.609 (99.257)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:77/80; Lr: 0.1
batch Size 256
Epoch: [77][0/196]	Time 0.116 (0.116)	Data 0.299 (0.299)	Loss 0.4307 (0.4307)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [77][64/196]	Time 0.171 (0.136)	Data 0.000 (0.005)	Loss 0.5092 (0.4469)	Acc@1 82.812 (84.603)	Acc@5 98.828 (99.327)
Epoch: [77][128/196]	Time 0.057 (0.134)	Data 0.000 (0.003)	Loss 0.4201 (0.4537)	Acc@1 88.281 (84.535)	Acc@5 99.219 (99.340)
Epoch: [77][192/196]	Time 0.180 (0.135)	Data 0.000 (0.002)	Loss 0.4043 (0.4587)	Acc@1 85.547 (84.373)	Acc@5 100.000 (99.320)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:78/80; Lr: 0.1
batch Size 256
Epoch: [78][0/196]	Time 0.105 (0.105)	Data 0.443 (0.443)	Loss 0.3324 (0.3324)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.167 (0.134)	Data 0.000 (0.007)	Loss 0.3601 (0.4404)	Acc@1 87.109 (84.730)	Acc@5 100.000 (99.357)
Epoch: [78][128/196]	Time 0.180 (0.135)	Data 0.000 (0.004)	Loss 0.3631 (0.4508)	Acc@1 87.109 (84.448)	Acc@5 99.219 (99.291)
Epoch: [78][192/196]	Time 0.096 (0.136)	Data 0.000 (0.003)	Loss 0.4340 (0.4536)	Acc@1 84.375 (84.282)	Acc@5 99.219 (99.314)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:79/80; Lr: 0.1
batch Size 256
Epoch: [79][0/196]	Time 0.156 (0.156)	Data 0.366 (0.366)	Loss 0.3944 (0.3944)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [79][64/196]	Time 0.060 (0.134)	Data 0.000 (0.006)	Loss 0.4969 (0.4361)	Acc@1 80.859 (84.645)	Acc@5 99.219 (99.363)
Epoch: [79][128/196]	Time 0.056 (0.134)	Data 0.000 (0.003)	Loss 0.3185 (0.4506)	Acc@1 90.625 (84.296)	Acc@5 100.000 (99.304)
Epoch: [79][192/196]	Time 0.199 (0.136)	Data 0.000 (0.002)	Loss 0.5433 (0.4538)	Acc@1 77.734 (84.183)	Acc@5 99.609 (99.292)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:80/80; Lr: 0.1
batch Size 256
Epoch: [80][0/196]	Time 0.181 (0.181)	Data 0.456 (0.456)	Loss 0.5126 (0.5126)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.193 (0.138)	Data 0.000 (0.007)	Loss 0.4489 (0.4422)	Acc@1 82.422 (84.772)	Acc@5 99.219 (99.363)
Epoch: [80][128/196]	Time 0.087 (0.130)	Data 0.000 (0.004)	Loss 0.4751 (0.4448)	Acc@1 82.031 (84.645)	Acc@5 99.219 (99.310)
Epoch: [80][192/196]	Time 0.056 (0.130)	Data 0.000 (0.003)	Loss 0.3821 (0.4453)	Acc@1 88.281 (84.636)	Acc@5 99.219 (99.356)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  74.51
Max memory: 33.0690048
 26.083s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8395
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.0665088
lr: 0.1
1
Epoche:81/85; Lr: 0.1
batch Size 256
Epoch: [81][0/196]	Time 0.228 (0.228)	Data 0.334 (0.334)	Loss 0.3530 (0.3530)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [81][64/196]	Time 0.062 (0.132)	Data 0.000 (0.005)	Loss 0.4491 (0.4317)	Acc@1 84.375 (85.126)	Acc@5 99.219 (99.411)
Epoch: [81][128/196]	Time 0.070 (0.133)	Data 0.000 (0.003)	Loss 0.4229 (0.4469)	Acc@1 83.984 (84.584)	Acc@5 99.609 (99.385)
Epoch: [81][192/196]	Time 0.185 (0.135)	Data 0.000 (0.002)	Loss 0.4993 (0.4488)	Acc@1 84.375 (84.513)	Acc@5 98.828 (99.371)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:82/85; Lr: 0.1
batch Size 256
Epoch: [82][0/196]	Time 0.125 (0.125)	Data 0.332 (0.332)	Loss 0.4829 (0.4829)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [82][64/196]	Time 0.091 (0.121)	Data 0.000 (0.005)	Loss 0.4524 (0.4589)	Acc@1 86.328 (84.375)	Acc@5 99.609 (99.387)
Epoch: [82][128/196]	Time 0.139 (0.129)	Data 0.000 (0.003)	Loss 0.3912 (0.4457)	Acc@1 86.328 (84.660)	Acc@5 99.609 (99.394)
Epoch: [82][192/196]	Time 0.063 (0.131)	Data 0.000 (0.002)	Loss 0.4964 (0.4517)	Acc@1 82.422 (84.458)	Acc@5 98.438 (99.350)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:83/85; Lr: 0.1
batch Size 256
Epoch: [83][0/196]	Time 0.127 (0.127)	Data 0.396 (0.396)	Loss 0.3841 (0.3841)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [83][64/196]	Time 0.148 (0.136)	Data 0.000 (0.006)	Loss 0.5071 (0.4607)	Acc@1 80.859 (84.273)	Acc@5 100.000 (99.363)
Epoch: [83][128/196]	Time 0.151 (0.137)	Data 0.000 (0.003)	Loss 0.4137 (0.4591)	Acc@1 83.984 (84.351)	Acc@5 100.000 (99.340)
Epoch: [83][192/196]	Time 0.193 (0.137)	Data 0.000 (0.002)	Loss 0.3761 (0.4598)	Acc@1 86.719 (84.278)	Acc@5 99.609 (99.322)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:84/85; Lr: 0.1
batch Size 256
Epoch: [84][0/196]	Time 0.202 (0.202)	Data 0.431 (0.431)	Loss 0.4925 (0.4925)	Acc@1 81.250 (81.250)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.190 (0.138)	Data 0.000 (0.007)	Loss 0.4383 (0.4517)	Acc@1 84.766 (84.399)	Acc@5 99.609 (99.363)
Epoch: [84][128/196]	Time 0.065 (0.137)	Data 0.000 (0.004)	Loss 0.4588 (0.4495)	Acc@1 82.422 (84.493)	Acc@5 99.219 (99.343)
Epoch: [84][192/196]	Time 0.155 (0.132)	Data 0.000 (0.002)	Loss 0.4881 (0.4551)	Acc@1 83.984 (84.300)	Acc@5 99.219 (99.296)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:85/85; Lr: 0.1
batch Size 256
Epoch: [85][0/196]	Time 0.190 (0.190)	Data 0.369 (0.369)	Loss 0.4379 (0.4379)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [85][64/196]	Time 0.088 (0.138)	Data 0.000 (0.006)	Loss 0.3859 (0.4356)	Acc@1 86.719 (85.072)	Acc@5 99.219 (99.345)
Epoch: [85][128/196]	Time 0.192 (0.138)	Data 0.000 (0.003)	Loss 0.4315 (0.4457)	Acc@1 84.766 (84.729)	Acc@5 99.219 (99.313)
Epoch: [85][192/196]	Time 0.199 (0.138)	Data 0.000 (0.002)	Loss 0.4850 (0.4462)	Acc@1 80.078 (84.594)	Acc@5 98.828 (99.324)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  72.3
Max memory: 33.0690048
 27.434s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6081
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.0665088
lr: 0.1
1
Epoche:86/90; Lr: 0.1
batch Size 256
Epoch: [86][0/196]	Time 0.185 (0.185)	Data 0.426 (0.426)	Loss 0.5037 (0.5037)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [86][64/196]	Time 0.069 (0.135)	Data 0.000 (0.007)	Loss 0.5130 (0.4288)	Acc@1 82.422 (85.306)	Acc@5 98.828 (99.351)
Epoch: [86][128/196]	Time 0.152 (0.128)	Data 0.000 (0.004)	Loss 0.4513 (0.4374)	Acc@1 84.375 (84.996)	Acc@5 99.219 (99.334)
Epoch: [86][192/196]	Time 0.101 (0.129)	Data 0.000 (0.002)	Loss 0.5126 (0.4495)	Acc@1 83.203 (84.618)	Acc@5 99.219 (99.300)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:87/90; Lr: 0.1
batch Size 256
Epoch: [87][0/196]	Time 0.083 (0.083)	Data 0.342 (0.342)	Loss 0.5003 (0.5003)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [87][64/196]	Time 0.177 (0.135)	Data 0.000 (0.005)	Loss 0.5214 (0.4500)	Acc@1 82.031 (84.465)	Acc@5 99.609 (99.345)
Epoch: [87][128/196]	Time 0.181 (0.134)	Data 0.000 (0.003)	Loss 0.4173 (0.4506)	Acc@1 85.547 (84.496)	Acc@5 100.000 (99.304)
Epoch: [87][192/196]	Time 0.144 (0.135)	Data 0.000 (0.002)	Loss 0.3604 (0.4491)	Acc@1 88.672 (84.606)	Acc@5 99.219 (99.302)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:88/90; Lr: 0.1
batch Size 256
Epoch: [88][0/196]	Time 0.164 (0.164)	Data 0.335 (0.335)	Loss 0.4243 (0.4243)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.177 (0.139)	Data 0.000 (0.005)	Loss 0.4911 (0.4506)	Acc@1 85.156 (84.381)	Acc@5 98.828 (99.387)
Epoch: [88][128/196]	Time 0.063 (0.139)	Data 0.000 (0.003)	Loss 0.4156 (0.4507)	Acc@1 84.375 (84.330)	Acc@5 100.000 (99.319)
Epoch: [88][192/196]	Time 0.173 (0.138)	Data 0.000 (0.002)	Loss 0.3772 (0.4515)	Acc@1 88.281 (84.345)	Acc@5 100.000 (99.342)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:89/90; Lr: 0.1
batch Size 256
Epoch: [89][0/196]	Time 0.106 (0.106)	Data 0.347 (0.347)	Loss 0.3799 (0.3799)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.109 (0.123)	Data 0.000 (0.006)	Loss 0.4719 (0.4428)	Acc@1 83.594 (84.579)	Acc@5 99.219 (99.417)
Epoch: [89][128/196]	Time 0.059 (0.129)	Data 0.000 (0.003)	Loss 0.5707 (0.4472)	Acc@1 79.297 (84.375)	Acc@5 100.000 (99.406)
Epoch: [89][192/196]	Time 0.058 (0.131)	Data 0.000 (0.002)	Loss 0.5263 (0.4523)	Acc@1 81.250 (84.247)	Acc@5 99.219 (99.360)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:90/90; Lr: 0.1
batch Size 256
Epoch: [90][0/196]	Time 0.194 (0.194)	Data 0.355 (0.355)	Loss 0.3388 (0.3388)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [90][64/196]	Time 0.177 (0.136)	Data 0.000 (0.006)	Loss 0.4441 (0.4303)	Acc@1 84.375 (84.922)	Acc@5 99.609 (99.417)
Epoch: [90][128/196]	Time 0.072 (0.136)	Data 0.000 (0.003)	Loss 0.4806 (0.4500)	Acc@1 83.203 (84.263)	Acc@5 98.438 (99.340)
Epoch: [90][192/196]	Time 0.076 (0.136)	Data 0.000 (0.002)	Loss 0.3993 (0.4524)	Acc@1 86.719 (84.381)	Acc@5 99.219 (99.356)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  75.99
Max memory: 33.0690048
 27.173s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 3551
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.0665088
lr: 0.1
1
Epoche:91/95; Lr: 0.1
batch Size 256
Epoch: [91][0/196]	Time 0.134 (0.134)	Data 0.323 (0.323)	Loss 0.4234 (0.4234)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [91][64/196]	Time 0.190 (0.136)	Data 0.000 (0.005)	Loss 0.4264 (0.4165)	Acc@1 84.766 (85.517)	Acc@5 98.828 (99.411)
Epoch: [91][128/196]	Time 0.134 (0.135)	Data 0.000 (0.003)	Loss 0.4744 (0.4369)	Acc@1 81.641 (84.999)	Acc@5 99.219 (99.319)
Epoch: [91][192/196]	Time 0.057 (0.135)	Data 0.000 (0.002)	Loss 0.4285 (0.4438)	Acc@1 83.984 (84.804)	Acc@5 100.000 (99.328)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:92/95; Lr: 0.1
batch Size 256
Epoch: [92][0/196]	Time 0.201 (0.201)	Data 0.363 (0.363)	Loss 0.3777 (0.3777)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [92][64/196]	Time 0.059 (0.136)	Data 0.000 (0.006)	Loss 0.4432 (0.4424)	Acc@1 85.938 (84.880)	Acc@5 98.438 (99.255)
Epoch: [92][128/196]	Time 0.193 (0.137)	Data 0.000 (0.003)	Loss 0.4939 (0.4473)	Acc@1 80.859 (84.645)	Acc@5 99.219 (99.258)
Epoch: [92][192/196]	Time 0.181 (0.137)	Data 0.000 (0.002)	Loss 0.4661 (0.4536)	Acc@1 83.984 (84.468)	Acc@5 99.609 (99.275)
Max memory in training epoch: 21.5243264
lr: 0.1
1
Epoche:93/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [93][0/196]	Time 0.111 (0.111)	Data 0.299 (0.299)	Loss 0.3571 (0.3571)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.098 (0.133)	Data 0.000 (0.005)	Loss 0.3499 (0.3711)	Acc@1 90.234 (87.206)	Acc@5 99.219 (99.543)
Epoch: [93][128/196]	Time 0.195 (0.130)	Data 0.000 (0.003)	Loss 0.2938 (0.3504)	Acc@1 89.844 (88.112)	Acc@5 100.000 (99.597)
Epoch: [93][192/196]	Time 0.195 (0.132)	Data 0.000 (0.002)	Loss 0.3095 (0.3429)	Acc@1 87.500 (88.316)	Acc@5 100.000 (99.611)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:94/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [94][0/196]	Time 0.188 (0.188)	Data 0.328 (0.328)	Loss 0.3755 (0.3755)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [94][64/196]	Time 0.183 (0.138)	Data 0.000 (0.005)	Loss 0.3253 (0.3044)	Acc@1 88.281 (89.669)	Acc@5 99.609 (99.694)
Epoch: [94][128/196]	Time 0.085 (0.138)	Data 0.000 (0.003)	Loss 0.2845 (0.3051)	Acc@1 91.406 (89.474)	Acc@5 99.609 (99.688)
Epoch: [94][192/196]	Time 0.062 (0.137)	Data 0.000 (0.002)	Loss 0.3354 (0.3036)	Acc@1 88.281 (89.593)	Acc@5 99.609 (99.668)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:95/95; Lr: 0.010000000000000002
batch Size 256
Epoch: [95][0/196]	Time 0.220 (0.220)	Data 0.385 (0.385)	Loss 0.2879 (0.2879)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [95][64/196]	Time 0.190 (0.137)	Data 0.000 (0.006)	Loss 0.3192 (0.2928)	Acc@1 88.281 (90.048)	Acc@5 100.000 (99.724)
Epoch: [95][128/196]	Time 0.079 (0.137)	Data 0.000 (0.003)	Loss 0.2200 (0.2919)	Acc@1 91.797 (89.968)	Acc@5 100.000 (99.712)
Epoch: [95][192/196]	Time 0.099 (0.134)	Data 0.000 (0.002)	Loss 0.3125 (0.2897)	Acc@1 89.453 (90.093)	Acc@5 99.609 (99.707)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.97
Max memory: 33.0690048
 26.611s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9533
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:96/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [96][0/196]	Time 0.194 (0.194)	Data 0.383 (0.383)	Loss 0.3696 (0.3696)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [96][64/196]	Time 0.172 (0.134)	Data 0.000 (0.006)	Loss 0.2240 (0.2802)	Acc@1 93.359 (90.709)	Acc@5 100.000 (99.748)
Epoch: [96][128/196]	Time 0.076 (0.132)	Data 0.000 (0.003)	Loss 0.2543 (0.2834)	Acc@1 91.406 (90.437)	Acc@5 100.000 (99.724)
Epoch: [96][192/196]	Time 0.174 (0.133)	Data 0.000 (0.002)	Loss 0.2177 (0.2822)	Acc@1 92.578 (90.455)	Acc@5 99.219 (99.737)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:97/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [97][0/196]	Time 0.158 (0.158)	Data 0.311 (0.311)	Loss 0.2429 (0.2429)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.109 (0.137)	Data 0.000 (0.005)	Loss 0.2916 (0.2712)	Acc@1 91.016 (90.787)	Acc@5 99.219 (99.778)
Epoch: [97][128/196]	Time 0.060 (0.132)	Data 0.000 (0.003)	Loss 0.2888 (0.2772)	Acc@1 90.625 (90.519)	Acc@5 100.000 (99.749)
Epoch: [97][192/196]	Time 0.060 (0.130)	Data 0.000 (0.002)	Loss 0.2481 (0.2781)	Acc@1 89.844 (90.410)	Acc@5 100.000 (99.741)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:98/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [98][0/196]	Time 0.166 (0.166)	Data 0.407 (0.407)	Loss 0.2897 (0.2897)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [98][64/196]	Time 0.143 (0.135)	Data 0.000 (0.006)	Loss 0.2960 (0.2758)	Acc@1 89.453 (90.529)	Acc@5 100.000 (99.700)
Epoch: [98][128/196]	Time 0.057 (0.136)	Data 0.000 (0.003)	Loss 0.2233 (0.2698)	Acc@1 91.406 (90.804)	Acc@5 100.000 (99.730)
Epoch: [98][192/196]	Time 0.183 (0.137)	Data 0.000 (0.002)	Loss 0.3083 (0.2722)	Acc@1 89.062 (90.704)	Acc@5 99.609 (99.727)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:99/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [99][0/196]	Time 0.185 (0.185)	Data 0.353 (0.353)	Loss 0.2273 (0.2273)	Acc@1 92.188 (92.188)	Acc@5 99.609 (99.609)
Epoch: [99][64/196]	Time 0.171 (0.136)	Data 0.000 (0.006)	Loss 0.3164 (0.2686)	Acc@1 88.672 (90.625)	Acc@5 100.000 (99.712)
Epoch: [99][128/196]	Time 0.175 (0.136)	Data 0.000 (0.003)	Loss 0.2277 (0.2697)	Acc@1 93.359 (90.734)	Acc@5 100.000 (99.709)
Epoch: [99][192/196]	Time 0.183 (0.136)	Data 0.000 (0.002)	Loss 0.3192 (0.2690)	Acc@1 89.062 (90.767)	Acc@5 99.219 (99.727)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:100/100; Lr: 0.010000000000000002
batch Size 256
Epoch: [100][0/196]	Time 0.240 (0.240)	Data 0.464 (0.464)	Loss 0.1822 (0.1822)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [100][64/196]	Time 0.111 (0.122)	Data 0.000 (0.007)	Loss 0.2248 (0.2582)	Acc@1 92.578 (91.202)	Acc@5 100.000 (99.718)
Epoch: [100][128/196]	Time 0.167 (0.131)	Data 0.000 (0.004)	Loss 0.3306 (0.2647)	Acc@1 87.891 (90.861)	Acc@5 100.000 (99.734)
Epoch: [100][192/196]	Time 0.188 (0.133)	Data 0.000 (0.003)	Loss 0.2616 (0.2632)	Acc@1 90.234 (90.933)	Acc@5 100.000 (99.731)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.9
Max memory: 33.0690048
 26.634s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4398
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:101/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [101][0/196]	Time 0.286 (0.286)	Data 0.338 (0.338)	Loss 0.1841 (0.1841)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.064 (0.137)	Data 0.000 (0.005)	Loss 0.1790 (0.2582)	Acc@1 94.141 (91.208)	Acc@5 100.000 (99.784)
Epoch: [101][128/196]	Time 0.210 (0.137)	Data 0.000 (0.003)	Loss 0.2844 (0.2617)	Acc@1 89.453 (90.964)	Acc@5 99.609 (99.761)
Epoch: [101][192/196]	Time 0.183 (0.132)	Data 0.000 (0.002)	Loss 0.2849 (0.2622)	Acc@1 89.453 (90.914)	Acc@5 99.609 (99.769)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:102/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [102][0/196]	Time 0.092 (0.092)	Data 0.346 (0.346)	Loss 0.2635 (0.2635)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [102][64/196]	Time 0.101 (0.137)	Data 0.000 (0.006)	Loss 0.2524 (0.2534)	Acc@1 92.969 (91.214)	Acc@5 100.000 (99.748)
Epoch: [102][128/196]	Time 0.170 (0.137)	Data 0.000 (0.003)	Loss 0.2161 (0.2514)	Acc@1 92.188 (91.324)	Acc@5 100.000 (99.740)
Epoch: [102][192/196]	Time 0.169 (0.138)	Data 0.000 (0.002)	Loss 0.2644 (0.2544)	Acc@1 89.453 (91.232)	Acc@5 100.000 (99.745)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:103/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [103][0/196]	Time 0.104 (0.104)	Data 0.317 (0.317)	Loss 0.1950 (0.1950)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [103][64/196]	Time 0.148 (0.136)	Data 0.000 (0.005)	Loss 0.3445 (0.2506)	Acc@1 89.844 (91.611)	Acc@5 99.219 (99.712)
Epoch: [103][128/196]	Time 0.192 (0.137)	Data 0.000 (0.003)	Loss 0.2975 (0.2493)	Acc@1 87.500 (91.409)	Acc@5 100.000 (99.752)
Epoch: [103][192/196]	Time 0.116 (0.136)	Data 0.000 (0.002)	Loss 0.2606 (0.2545)	Acc@1 91.016 (91.216)	Acc@5 99.609 (99.733)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:104/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [104][0/196]	Time 0.219 (0.219)	Data 0.278 (0.278)	Loss 0.2760 (0.2760)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [104][64/196]	Time 0.093 (0.138)	Data 0.000 (0.004)	Loss 0.2035 (0.2436)	Acc@1 91.797 (91.430)	Acc@5 99.609 (99.748)
Epoch: [104][128/196]	Time 0.131 (0.129)	Data 0.000 (0.002)	Loss 0.2241 (0.2466)	Acc@1 91.797 (91.424)	Acc@5 100.000 (99.785)
Epoch: [104][192/196]	Time 0.098 (0.132)	Data 0.000 (0.002)	Loss 0.2763 (0.2498)	Acc@1 88.672 (91.321)	Acc@5 100.000 (99.771)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:105/105; Lr: 0.010000000000000002
batch Size 256
Epoch: [105][0/196]	Time 0.151 (0.151)	Data 0.297 (0.297)	Loss 0.1988 (0.1988)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.077 (0.139)	Data 0.000 (0.005)	Loss 0.2853 (0.2519)	Acc@1 91.016 (91.442)	Acc@5 99.609 (99.742)
Epoch: [105][128/196]	Time 0.137 (0.138)	Data 0.000 (0.003)	Loss 0.2177 (0.2536)	Acc@1 93.359 (91.409)	Acc@5 99.609 (99.761)
Epoch: [105][192/196]	Time 0.181 (0.137)	Data 0.000 (0.002)	Loss 0.2680 (0.2515)	Acc@1 90.625 (91.453)	Acc@5 99.219 (99.759)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.29
Max memory: 33.0690048
 27.280s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 2246
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:106/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [106][0/196]	Time 0.168 (0.168)	Data 0.343 (0.343)	Loss 0.2081 (0.2081)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.118 (0.117)	Data 0.000 (0.006)	Loss 0.2532 (0.2393)	Acc@1 92.578 (91.803)	Acc@5 99.609 (99.820)
Epoch: [106][128/196]	Time 0.063 (0.124)	Data 0.000 (0.003)	Loss 0.2627 (0.2470)	Acc@1 89.844 (91.467)	Acc@5 100.000 (99.824)
Epoch: [106][192/196]	Time 0.091 (0.127)	Data 0.000 (0.002)	Loss 0.1757 (0.2454)	Acc@1 94.922 (91.594)	Acc@5 99.609 (99.824)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:107/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [107][0/196]	Time 0.198 (0.198)	Data 0.391 (0.391)	Loss 0.2384 (0.2384)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [107][64/196]	Time 0.099 (0.136)	Data 0.000 (0.006)	Loss 0.2784 (0.2431)	Acc@1 91.406 (91.653)	Acc@5 99.219 (99.742)
Epoch: [107][128/196]	Time 0.140 (0.136)	Data 0.000 (0.003)	Loss 0.2676 (0.2406)	Acc@1 91.406 (91.812)	Acc@5 99.219 (99.800)
Epoch: [107][192/196]	Time 0.188 (0.136)	Data 0.000 (0.002)	Loss 0.3187 (0.2444)	Acc@1 89.844 (91.631)	Acc@5 99.219 (99.798)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:108/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [108][0/196]	Time 0.210 (0.210)	Data 0.348 (0.348)	Loss 0.2415 (0.2415)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.190 (0.138)	Data 0.000 (0.006)	Loss 0.1915 (0.2410)	Acc@1 92.188 (91.695)	Acc@5 100.000 (99.826)
Epoch: [108][128/196]	Time 0.086 (0.136)	Data 0.000 (0.003)	Loss 0.2236 (0.2398)	Acc@1 91.406 (91.733)	Acc@5 100.000 (99.824)
Epoch: [108][192/196]	Time 0.066 (0.131)	Data 0.000 (0.002)	Loss 0.2621 (0.2437)	Acc@1 91.016 (91.601)	Acc@5 100.000 (99.816)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:109/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [109][0/196]	Time 0.199 (0.199)	Data 0.361 (0.361)	Loss 0.2637 (0.2637)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.113 (0.138)	Data 0.000 (0.006)	Loss 0.1952 (0.2397)	Acc@1 94.531 (91.875)	Acc@5 100.000 (99.766)
Epoch: [109][128/196]	Time 0.191 (0.137)	Data 0.000 (0.003)	Loss 0.2364 (0.2422)	Acc@1 91.406 (91.733)	Acc@5 100.000 (99.758)
Epoch: [109][192/196]	Time 0.176 (0.137)	Data 0.000 (0.002)	Loss 0.2598 (0.2433)	Acc@1 91.406 (91.641)	Acc@5 100.000 (99.794)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:110/110; Lr: 0.010000000000000002
batch Size 256
Epoch: [110][0/196]	Time 0.134 (0.134)	Data 0.330 (0.330)	Loss 0.1747 (0.1747)	Acc@1 93.750 (93.750)	Acc@5 99.609 (99.609)
Epoch: [110][64/196]	Time 0.177 (0.135)	Data 0.000 (0.005)	Loss 0.2812 (0.2432)	Acc@1 92.188 (91.659)	Acc@5 99.609 (99.742)
Epoch: [110][128/196]	Time 0.152 (0.136)	Data 0.000 (0.003)	Loss 0.2827 (0.2428)	Acc@1 89.062 (91.688)	Acc@5 99.219 (99.764)
Epoch: [110][192/196]	Time 0.190 (0.136)	Data 0.000 (0.002)	Loss 0.2593 (0.2435)	Acc@1 91.406 (91.645)	Acc@5 100.000 (99.785)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.0
Max memory: 33.0690048
 27.159s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9918
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:111/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [111][0/196]	Time 0.238 (0.238)	Data 0.357 (0.357)	Loss 0.1978 (0.1978)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.147 (0.132)	Data 0.000 (0.006)	Loss 0.2350 (0.2326)	Acc@1 91.797 (92.302)	Acc@5 99.609 (99.760)
Epoch: [111][128/196]	Time 0.181 (0.132)	Data 0.000 (0.003)	Loss 0.2108 (0.2357)	Acc@1 92.969 (92.139)	Acc@5 99.609 (99.800)
Epoch: [111][192/196]	Time 0.195 (0.132)	Data 0.000 (0.002)	Loss 0.2187 (0.2389)	Acc@1 92.578 (91.884)	Acc@5 100.000 (99.820)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:112/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [112][0/196]	Time 0.163 (0.163)	Data 0.327 (0.327)	Loss 0.2925 (0.2925)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [112][64/196]	Time 0.177 (0.137)	Data 0.000 (0.005)	Loss 0.2994 (0.2338)	Acc@1 89.062 (91.785)	Acc@5 99.609 (99.772)
Epoch: [112][128/196]	Time 0.166 (0.136)	Data 0.000 (0.003)	Loss 0.2720 (0.2344)	Acc@1 91.797 (91.909)	Acc@5 100.000 (99.800)
Epoch: [112][192/196]	Time 0.078 (0.134)	Data 0.000 (0.002)	Loss 0.2793 (0.2389)	Acc@1 91.797 (91.762)	Acc@5 100.000 (99.787)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:113/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [113][0/196]	Time 0.129 (0.129)	Data 0.383 (0.383)	Loss 0.2159 (0.2159)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.093 (0.137)	Data 0.000 (0.006)	Loss 0.2267 (0.2361)	Acc@1 92.578 (91.905)	Acc@5 100.000 (99.814)
Epoch: [113][128/196]	Time 0.191 (0.138)	Data 0.000 (0.003)	Loss 0.2285 (0.2324)	Acc@1 92.188 (92.006)	Acc@5 99.609 (99.809)
Epoch: [113][192/196]	Time 0.174 (0.137)	Data 0.000 (0.002)	Loss 0.2546 (0.2367)	Acc@1 92.578 (91.799)	Acc@5 100.000 (99.816)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:114/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [114][0/196]	Time 0.151 (0.151)	Data 0.306 (0.306)	Loss 0.3037 (0.3037)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [114][64/196]	Time 0.118 (0.138)	Data 0.000 (0.005)	Loss 0.2115 (0.2384)	Acc@1 91.406 (91.677)	Acc@5 100.000 (99.760)
Epoch: [114][128/196]	Time 0.098 (0.137)	Data 0.000 (0.003)	Loss 0.1985 (0.2394)	Acc@1 94.922 (91.621)	Acc@5 99.609 (99.761)
Epoch: [114][192/196]	Time 0.064 (0.136)	Data 0.000 (0.002)	Loss 0.2471 (0.2384)	Acc@1 90.234 (91.661)	Acc@5 100.000 (99.790)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:115/115; Lr: 0.010000000000000002
batch Size 256
Epoch: [115][0/196]	Time 0.096 (0.096)	Data 0.377 (0.377)	Loss 0.2409 (0.2409)	Acc@1 90.625 (90.625)	Acc@5 99.609 (99.609)
Epoch: [115][64/196]	Time 0.156 (0.138)	Data 0.000 (0.006)	Loss 0.2508 (0.2339)	Acc@1 91.016 (91.959)	Acc@5 100.000 (99.808)
Epoch: [115][128/196]	Time 0.126 (0.128)	Data 0.000 (0.003)	Loss 0.3186 (0.2327)	Acc@1 87.500 (91.921)	Acc@5 100.000 (99.809)
Epoch: [115][192/196]	Time 0.164 (0.132)	Data 0.000 (0.002)	Loss 0.2415 (0.2363)	Acc@1 89.844 (91.771)	Acc@5 100.000 (99.822)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.51
Max memory: 33.0690048
 26.308s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9769
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:116/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [116][0/196]	Time 0.291 (0.291)	Data 0.436 (0.436)	Loss 0.2294 (0.2294)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.132 (0.134)	Data 0.000 (0.007)	Loss 0.2883 (0.2240)	Acc@1 89.844 (92.302)	Acc@5 99.219 (99.844)
Epoch: [116][128/196]	Time 0.163 (0.135)	Data 0.000 (0.004)	Loss 0.2360 (0.2306)	Acc@1 91.016 (92.075)	Acc@5 100.000 (99.864)
Epoch: [116][192/196]	Time 0.074 (0.134)	Data 0.000 (0.002)	Loss 0.2675 (0.2328)	Acc@1 89.453 (91.977)	Acc@5 100.000 (99.848)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:117/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [117][0/196]	Time 0.177 (0.177)	Data 0.428 (0.428)	Loss 0.2438 (0.2438)	Acc@1 91.016 (91.016)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.177 (0.123)	Data 0.000 (0.007)	Loss 0.2458 (0.2287)	Acc@1 90.625 (91.893)	Acc@5 99.609 (99.820)
Epoch: [117][128/196]	Time 0.172 (0.129)	Data 0.000 (0.004)	Loss 0.1846 (0.2333)	Acc@1 93.750 (91.812)	Acc@5 99.609 (99.818)
Epoch: [117][192/196]	Time 0.185 (0.131)	Data 0.000 (0.002)	Loss 0.1813 (0.2328)	Acc@1 94.531 (91.868)	Acc@5 100.000 (99.834)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:118/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [118][0/196]	Time 0.221 (0.221)	Data 0.375 (0.375)	Loss 0.2803 (0.2803)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.081 (0.139)	Data 0.000 (0.006)	Loss 0.2550 (0.2278)	Acc@1 91.406 (92.019)	Acc@5 99.219 (99.796)
Epoch: [118][128/196]	Time 0.070 (0.138)	Data 0.000 (0.003)	Loss 0.2144 (0.2282)	Acc@1 92.969 (92.109)	Acc@5 100.000 (99.803)
Epoch: [118][192/196]	Time 0.145 (0.138)	Data 0.000 (0.002)	Loss 0.2395 (0.2321)	Acc@1 90.234 (91.945)	Acc@5 99.609 (99.798)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:119/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [119][0/196]	Time 0.151 (0.151)	Data 0.411 (0.411)	Loss 0.2065 (0.2065)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.060 (0.137)	Data 0.000 (0.007)	Loss 0.2361 (0.2210)	Acc@1 90.625 (92.230)	Acc@5 100.000 (99.820)
Epoch: [119][128/196]	Time 0.150 (0.138)	Data 0.000 (0.003)	Loss 0.2141 (0.2302)	Acc@1 93.750 (92.033)	Acc@5 100.000 (99.806)
Epoch: [119][192/196]	Time 0.160 (0.132)	Data 0.000 (0.002)	Loss 0.2703 (0.2302)	Acc@1 92.969 (92.064)	Acc@5 99.609 (99.840)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:120/120; Lr: 0.010000000000000002
batch Size 256
Epoch: [120][0/196]	Time 0.193 (0.193)	Data 0.315 (0.315)	Loss 0.2881 (0.2881)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.064 (0.136)	Data 0.000 (0.005)	Loss 0.2012 (0.2260)	Acc@1 93.359 (92.085)	Acc@5 100.000 (99.850)
Epoch: [120][128/196]	Time 0.074 (0.137)	Data 0.000 (0.003)	Loss 0.1669 (0.2271)	Acc@1 95.703 (92.130)	Acc@5 100.000 (99.870)
Epoch: [120][192/196]	Time 0.153 (0.137)	Data 0.000 (0.002)	Loss 0.2122 (0.2309)	Acc@1 91.406 (91.969)	Acc@5 100.000 (99.840)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.29
Max memory: 33.0690048
 27.230s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 656
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:121/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [121][0/196]	Time 0.280 (0.280)	Data 0.341 (0.341)	Loss 0.2122 (0.2122)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.084 (0.135)	Data 0.000 (0.005)	Loss 0.2380 (0.2231)	Acc@1 90.234 (92.416)	Acc@5 100.000 (99.862)
Epoch: [121][128/196]	Time 0.111 (0.125)	Data 0.000 (0.003)	Loss 0.2092 (0.2275)	Acc@1 93.359 (92.181)	Acc@5 100.000 (99.830)
Epoch: [121][192/196]	Time 0.166 (0.129)	Data 0.000 (0.002)	Loss 0.2133 (0.2302)	Acc@1 92.969 (91.975)	Acc@5 99.609 (99.834)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:122/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [122][0/196]	Time 0.210 (0.210)	Data 0.328 (0.328)	Loss 0.1445 (0.1445)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [122][64/196]	Time 0.158 (0.137)	Data 0.000 (0.005)	Loss 0.2130 (0.2255)	Acc@1 91.797 (92.097)	Acc@5 100.000 (99.790)
Epoch: [122][128/196]	Time 0.171 (0.137)	Data 0.000 (0.003)	Loss 0.2200 (0.2331)	Acc@1 91.797 (91.891)	Acc@5 100.000 (99.803)
Epoch: [122][192/196]	Time 0.149 (0.137)	Data 0.000 (0.002)	Loss 0.1956 (0.2314)	Acc@1 95.703 (91.955)	Acc@5 100.000 (99.812)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:123/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [123][0/196]	Time 0.173 (0.173)	Data 0.377 (0.377)	Loss 0.1717 (0.1717)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.079 (0.137)	Data 0.000 (0.006)	Loss 0.2122 (0.2194)	Acc@1 91.016 (92.470)	Acc@5 100.000 (99.808)
Epoch: [123][128/196]	Time 0.185 (0.137)	Data 0.000 (0.003)	Loss 0.3153 (0.2261)	Acc@1 89.844 (92.109)	Acc@5 99.219 (99.824)
Epoch: [123][192/196]	Time 0.095 (0.137)	Data 0.000 (0.002)	Loss 0.2317 (0.2286)	Acc@1 92.578 (92.064)	Acc@5 100.000 (99.832)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:124/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [124][0/196]	Time 0.150 (0.150)	Data 0.399 (0.399)	Loss 0.1887 (0.1887)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.185 (0.139)	Data 0.000 (0.006)	Loss 0.2836 (0.2237)	Acc@1 90.234 (92.145)	Acc@5 100.000 (99.838)
Epoch: [124][128/196]	Time 0.173 (0.138)	Data 0.000 (0.003)	Loss 0.2403 (0.2240)	Acc@1 92.969 (92.184)	Acc@5 99.609 (99.843)
Epoch: [124][192/196]	Time 0.062 (0.137)	Data 0.000 (0.002)	Loss 0.2102 (0.2281)	Acc@1 92.969 (92.113)	Acc@5 100.000 (99.822)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:125/125; Lr: 0.010000000000000002
batch Size 256
Epoch: [125][0/196]	Time 0.094 (0.094)	Data 0.390 (0.390)	Loss 0.2503 (0.2503)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [125][64/196]	Time 0.162 (0.134)	Data 0.000 (0.006)	Loss 0.2702 (0.2240)	Acc@1 89.062 (92.188)	Acc@5 100.000 (99.772)
Epoch: [125][128/196]	Time 0.054 (0.136)	Data 0.000 (0.003)	Loss 0.1854 (0.2285)	Acc@1 95.312 (91.951)	Acc@5 100.000 (99.809)
Epoch: [125][192/196]	Time 0.196 (0.136)	Data 0.000 (0.002)	Loss 0.2270 (0.2294)	Acc@1 91.406 (91.965)	Acc@5 100.000 (99.808)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.51
Max memory: 33.0690048
 27.158s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 4789
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:126/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [126][0/196]	Time 0.200 (0.200)	Data 0.384 (0.384)	Loss 0.2120 (0.2120)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.178 (0.136)	Data 0.000 (0.006)	Loss 0.1882 (0.2112)	Acc@1 94.531 (92.698)	Acc@5 99.609 (99.880)
Epoch: [126][128/196]	Time 0.152 (0.134)	Data 0.000 (0.003)	Loss 0.2580 (0.2196)	Acc@1 91.016 (92.402)	Acc@5 99.219 (99.846)
Epoch: [126][192/196]	Time 0.075 (0.134)	Data 0.000 (0.002)	Loss 0.1884 (0.2258)	Acc@1 93.750 (92.119)	Acc@5 100.000 (99.824)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:127/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [127][0/196]	Time 0.101 (0.101)	Data 0.337 (0.337)	Loss 0.1289 (0.1289)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.190 (0.136)	Data 0.000 (0.005)	Loss 0.1717 (0.2239)	Acc@1 93.359 (92.506)	Acc@5 99.609 (99.844)
Epoch: [127][128/196]	Time 0.068 (0.135)	Data 0.000 (0.003)	Loss 0.1804 (0.2226)	Acc@1 94.531 (92.415)	Acc@5 100.000 (99.888)
Epoch: [127][192/196]	Time 0.095 (0.135)	Data 0.000 (0.002)	Loss 0.1839 (0.2272)	Acc@1 94.531 (92.212)	Acc@5 100.000 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:128/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [128][0/196]	Time 0.089 (0.089)	Data 0.364 (0.364)	Loss 0.2270 (0.2270)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [128][64/196]	Time 0.179 (0.121)	Data 0.000 (0.006)	Loss 0.2449 (0.2211)	Acc@1 92.578 (92.308)	Acc@5 100.000 (99.844)
Epoch: [128][128/196]	Time 0.187 (0.128)	Data 0.000 (0.003)	Loss 0.1868 (0.2205)	Acc@1 94.141 (92.433)	Acc@5 100.000 (99.849)
Epoch: [128][192/196]	Time 0.062 (0.130)	Data 0.000 (0.002)	Loss 0.3229 (0.2246)	Acc@1 89.062 (92.171)	Acc@5 99.219 (99.844)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:129/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [129][0/196]	Time 0.095 (0.095)	Data 0.382 (0.382)	Loss 0.1969 (0.1969)	Acc@1 94.141 (94.141)	Acc@5 99.219 (99.219)
Epoch: [129][64/196]	Time 0.190 (0.135)	Data 0.000 (0.006)	Loss 0.2188 (0.2308)	Acc@1 91.406 (91.863)	Acc@5 100.000 (99.820)
Epoch: [129][128/196]	Time 0.184 (0.136)	Data 0.000 (0.003)	Loss 0.2446 (0.2279)	Acc@1 89.844 (92.136)	Acc@5 100.000 (99.803)
Epoch: [129][192/196]	Time 0.179 (0.136)	Data 0.000 (0.002)	Loss 0.2492 (0.2306)	Acc@1 91.406 (92.032)	Acc@5 100.000 (99.804)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:130/130; Lr: 0.010000000000000002
batch Size 256
Epoch: [130][0/196]	Time 0.098 (0.098)	Data 0.347 (0.347)	Loss 0.1608 (0.1608)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [130][64/196]	Time 0.071 (0.134)	Data 0.000 (0.006)	Loss 0.2410 (0.2230)	Acc@1 90.625 (92.236)	Acc@5 99.609 (99.838)
Epoch: [130][128/196]	Time 0.197 (0.136)	Data 0.000 (0.003)	Loss 0.1636 (0.2287)	Acc@1 94.141 (92.151)	Acc@5 100.000 (99.846)
Epoch: [130][192/196]	Time 0.057 (0.131)	Data 0.000 (0.002)	Loss 0.1655 (0.2273)	Acc@1 94.531 (92.218)	Acc@5 100.000 (99.838)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.16
Max memory: 33.0690048
 26.186s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 5539
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:131/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [131][0/196]	Time 0.187 (0.187)	Data 0.405 (0.405)	Loss 0.2519 (0.2519)	Acc@1 91.797 (91.797)	Acc@5 99.609 (99.609)
Epoch: [131][64/196]	Time 0.083 (0.136)	Data 0.000 (0.006)	Loss 0.2344 (0.2185)	Acc@1 92.969 (92.380)	Acc@5 100.000 (99.892)
Epoch: [131][128/196]	Time 0.144 (0.134)	Data 0.000 (0.003)	Loss 0.2056 (0.2215)	Acc@1 91.797 (92.293)	Acc@5 100.000 (99.867)
Epoch: [131][192/196]	Time 0.182 (0.135)	Data 0.000 (0.002)	Loss 0.2181 (0.2266)	Acc@1 93.359 (92.048)	Acc@5 99.219 (99.842)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:132/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [132][0/196]	Time 0.162 (0.162)	Data 0.438 (0.438)	Loss 0.2081 (0.2081)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [132][64/196]	Time 0.156 (0.138)	Data 0.000 (0.007)	Loss 0.1738 (0.2260)	Acc@1 92.578 (92.284)	Acc@5 100.000 (99.844)
Epoch: [132][128/196]	Time 0.170 (0.129)	Data 0.000 (0.004)	Loss 0.2994 (0.2265)	Acc@1 88.281 (92.142)	Acc@5 100.000 (99.846)
Epoch: [132][192/196]	Time 0.168 (0.131)	Data 0.000 (0.002)	Loss 0.1777 (0.2298)	Acc@1 94.531 (92.005)	Acc@5 100.000 (99.844)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:133/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [133][0/196]	Time 0.103 (0.103)	Data 0.394 (0.394)	Loss 0.2055 (0.2055)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.059 (0.136)	Data 0.000 (0.006)	Loss 0.1777 (0.2195)	Acc@1 93.359 (92.320)	Acc@5 100.000 (99.850)
Epoch: [133][128/196]	Time 0.199 (0.135)	Data 0.000 (0.003)	Loss 0.2941 (0.2265)	Acc@1 89.844 (92.103)	Acc@5 99.609 (99.849)
Epoch: [133][192/196]	Time 0.189 (0.135)	Data 0.000 (0.002)	Loss 0.2094 (0.2249)	Acc@1 92.578 (92.094)	Acc@5 100.000 (99.848)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:134/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [134][0/196]	Time 0.154 (0.154)	Data 0.377 (0.377)	Loss 0.1921 (0.1921)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.113 (0.135)	Data 0.000 (0.006)	Loss 0.1638 (0.2186)	Acc@1 94.922 (92.416)	Acc@5 99.609 (99.796)
Epoch: [134][128/196]	Time 0.062 (0.134)	Data 0.000 (0.003)	Loss 0.2565 (0.2247)	Acc@1 89.844 (92.142)	Acc@5 100.000 (99.846)
Epoch: [134][192/196]	Time 0.152 (0.135)	Data 0.000 (0.002)	Loss 0.1792 (0.2265)	Acc@1 95.312 (92.088)	Acc@5 100.000 (99.830)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:135/135; Lr: 0.010000000000000002
batch Size 256
Epoch: [135][0/196]	Time 0.186 (0.186)	Data 0.284 (0.284)	Loss 0.2136 (0.2136)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.161 (0.136)	Data 0.000 (0.005)	Loss 0.2651 (0.2183)	Acc@1 90.625 (92.302)	Acc@5 100.000 (99.838)
Epoch: [135][128/196]	Time 0.066 (0.135)	Data 0.000 (0.002)	Loss 0.2087 (0.2268)	Acc@1 93.359 (92.197)	Acc@5 99.609 (99.824)
Epoch: [135][192/196]	Time 0.109 (0.136)	Data 0.000 (0.002)	Loss 0.2279 (0.2271)	Acc@1 92.969 (92.165)	Acc@5 100.000 (99.830)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.03
Max memory: 33.0690048
 26.903s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 8150
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:136/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [136][0/196]	Time 0.217 (0.217)	Data 0.374 (0.374)	Loss 0.1685 (0.1685)	Acc@1 94.922 (94.922)	Acc@5 99.609 (99.609)
Epoch: [136][64/196]	Time 0.064 (0.133)	Data 0.000 (0.006)	Loss 0.2048 (0.2172)	Acc@1 92.188 (92.536)	Acc@5 100.000 (99.838)
Epoch: [136][128/196]	Time 0.087 (0.130)	Data 0.000 (0.003)	Loss 0.2236 (0.2240)	Acc@1 93.750 (92.224)	Acc@5 99.609 (99.849)
Epoch: [136][192/196]	Time 0.065 (0.129)	Data 0.000 (0.002)	Loss 0.2479 (0.2278)	Acc@1 91.016 (92.074)	Acc@5 99.219 (99.840)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:137/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [137][0/196]	Time 0.165 (0.165)	Data 0.410 (0.410)	Loss 0.1534 (0.1534)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.189 (0.137)	Data 0.000 (0.007)	Loss 0.2405 (0.2221)	Acc@1 91.797 (92.410)	Acc@5 100.000 (99.856)
Epoch: [137][128/196]	Time 0.161 (0.136)	Data 0.000 (0.003)	Loss 0.2237 (0.2224)	Acc@1 93.750 (92.390)	Acc@5 100.000 (99.879)
Epoch: [137][192/196]	Time 0.144 (0.136)	Data 0.000 (0.002)	Loss 0.1825 (0.2261)	Acc@1 92.188 (92.252)	Acc@5 100.000 (99.862)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:138/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [138][0/196]	Time 0.122 (0.122)	Data 0.382 (0.382)	Loss 0.2037 (0.2037)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.177 (0.136)	Data 0.000 (0.006)	Loss 0.2341 (0.2202)	Acc@1 91.016 (92.278)	Acc@5 99.609 (99.856)
Epoch: [138][128/196]	Time 0.066 (0.134)	Data 0.000 (0.003)	Loss 0.2534 (0.2239)	Acc@1 92.188 (92.145)	Acc@5 99.609 (99.830)
Epoch: [138][192/196]	Time 0.193 (0.135)	Data 0.000 (0.002)	Loss 0.2479 (0.2240)	Acc@1 91.016 (92.208)	Acc@5 100.000 (99.812)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:139/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [139][0/196]	Time 0.213 (0.213)	Data 0.344 (0.344)	Loss 0.2232 (0.2232)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.170 (0.122)	Data 0.000 (0.005)	Loss 0.2770 (0.2265)	Acc@1 91.797 (92.175)	Acc@5 99.609 (99.850)
Epoch: [139][128/196]	Time 0.174 (0.129)	Data 0.000 (0.003)	Loss 0.2193 (0.2303)	Acc@1 92.188 (92.075)	Acc@5 100.000 (99.830)
Epoch: [139][192/196]	Time 0.151 (0.131)	Data 0.000 (0.002)	Loss 0.2528 (0.2271)	Acc@1 89.062 (92.185)	Acc@5 100.000 (99.826)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:140/140; Lr: 0.010000000000000002
batch Size 256
Epoch: [140][0/196]	Time 0.176 (0.176)	Data 0.364 (0.364)	Loss 0.2095 (0.2095)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.191 (0.137)	Data 0.000 (0.006)	Loss 0.2375 (0.2246)	Acc@1 92.969 (92.133)	Acc@5 99.609 (99.868)
Epoch: [140][128/196]	Time 0.190 (0.136)	Data 0.000 (0.003)	Loss 0.2138 (0.2246)	Acc@1 92.969 (92.072)	Acc@5 100.000 (99.867)
Epoch: [140][192/196]	Time 0.183 (0.136)	Data 0.000 (0.002)	Loss 0.2197 (0.2281)	Acc@1 92.188 (91.989)	Acc@5 99.609 (99.844)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  86.43
Max memory: 33.0690048
 27.235s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 7367
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:141/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [141][0/196]	Time 0.170 (0.170)	Data 0.361 (0.361)	Loss 0.2390 (0.2390)	Acc@1 92.578 (92.578)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.196 (0.134)	Data 0.000 (0.006)	Loss 0.1816 (0.2182)	Acc@1 93.359 (92.392)	Acc@5 100.000 (99.856)
Epoch: [141][128/196]	Time 0.198 (0.133)	Data 0.000 (0.003)	Loss 0.2245 (0.2236)	Acc@1 91.406 (92.094)	Acc@5 99.609 (99.861)
Epoch: [141][192/196]	Time 0.059 (0.132)	Data 0.000 (0.002)	Loss 0.2324 (0.2237)	Acc@1 91.797 (92.141)	Acc@5 100.000 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:142/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [142][0/196]	Time 0.113 (0.113)	Data 0.394 (0.394)	Loss 0.2021 (0.2021)	Acc@1 92.578 (92.578)	Acc@5 99.609 (99.609)
Epoch: [142][64/196]	Time 0.189 (0.135)	Data 0.000 (0.006)	Loss 0.2060 (0.2191)	Acc@1 93.359 (92.656)	Acc@5 100.000 (99.802)
Epoch: [142][128/196]	Time 0.078 (0.135)	Data 0.000 (0.003)	Loss 0.2209 (0.2228)	Acc@1 93.359 (92.396)	Acc@5 99.609 (99.833)
Epoch: [142][192/196]	Time 0.054 (0.135)	Data 0.000 (0.002)	Loss 0.2296 (0.2241)	Acc@1 90.234 (92.277)	Acc@5 100.000 (99.834)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:143/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [143][0/196]	Time 0.211 (0.211)	Data 0.338 (0.338)	Loss 0.1936 (0.1936)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.101 (0.134)	Data 0.000 (0.005)	Loss 0.2382 (0.2174)	Acc@1 90.625 (92.602)	Acc@5 99.609 (99.814)
Epoch: [143][128/196]	Time 0.055 (0.127)	Data 0.000 (0.003)	Loss 0.2289 (0.2220)	Acc@1 93.359 (92.342)	Acc@5 100.000 (99.840)
Epoch: [143][192/196]	Time 0.089 (0.130)	Data 0.000 (0.002)	Loss 0.2251 (0.2273)	Acc@1 91.406 (92.113)	Acc@5 99.609 (99.814)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:144/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [144][0/196]	Time 0.135 (0.135)	Data 0.341 (0.341)	Loss 0.2472 (0.2472)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.105 (0.136)	Data 0.000 (0.005)	Loss 0.1840 (0.2191)	Acc@1 95.312 (92.302)	Acc@5 100.000 (99.820)
Epoch: [144][128/196]	Time 0.159 (0.136)	Data 0.000 (0.003)	Loss 0.2152 (0.2226)	Acc@1 92.969 (92.230)	Acc@5 99.609 (99.824)
Epoch: [144][192/196]	Time 0.060 (0.135)	Data 0.000 (0.002)	Loss 0.2475 (0.2277)	Acc@1 90.625 (92.015)	Acc@5 99.609 (99.834)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:145/145; Lr: 0.010000000000000002
batch Size 256
Epoch: [145][0/196]	Time 0.209 (0.209)	Data 0.336 (0.336)	Loss 0.2307 (0.2307)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.140 (0.139)	Data 0.000 (0.005)	Loss 0.2209 (0.2250)	Acc@1 92.969 (92.194)	Acc@5 100.000 (99.820)
Epoch: [145][128/196]	Time 0.175 (0.138)	Data 0.000 (0.003)	Loss 0.1566 (0.2240)	Acc@1 94.141 (92.066)	Acc@5 100.000 (99.836)
Epoch: [145][192/196]	Time 0.089 (0.136)	Data 0.000 (0.002)	Loss 0.2192 (0.2262)	Acc@1 92.969 (92.044)	Acc@5 100.000 (99.844)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  87.13
Max memory: 33.0690048
 26.914s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 71
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.0665088
lr: 0.010000000000000002
1
Epoche:146/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [146][0/196]	Time 0.250 (0.250)	Data 0.375 (0.375)	Loss 0.1478 (0.1478)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.114 (0.132)	Data 0.000 (0.006)	Loss 0.1794 (0.2125)	Acc@1 94.141 (92.686)	Acc@5 100.000 (99.868)
Epoch: [146][128/196]	Time 0.124 (0.133)	Data 0.000 (0.003)	Loss 0.2036 (0.2217)	Acc@1 93.359 (92.169)	Acc@5 100.000 (99.855)
Epoch: [146][192/196]	Time 0.073 (0.133)	Data 0.000 (0.002)	Loss 0.2705 (0.2229)	Acc@1 90.234 (92.129)	Acc@5 100.000 (99.852)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:147/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [147][0/196]	Time 0.089 (0.089)	Data 0.379 (0.379)	Loss 0.2528 (0.2528)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [147][64/196]	Time 0.184 (0.134)	Data 0.000 (0.006)	Loss 0.1852 (0.2146)	Acc@1 93.359 (92.446)	Acc@5 100.000 (99.898)
Epoch: [147][128/196]	Time 0.109 (0.132)	Data 0.000 (0.003)	Loss 0.2305 (0.2196)	Acc@1 90.625 (92.303)	Acc@5 100.000 (99.864)
Epoch: [147][192/196]	Time 0.090 (0.130)	Data 0.000 (0.002)	Loss 0.2624 (0.2243)	Acc@1 88.672 (92.163)	Acc@5 100.000 (99.850)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:148/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [148][0/196]	Time 0.083 (0.083)	Data 0.352 (0.352)	Loss 0.2369 (0.2369)	Acc@1 89.453 (89.453)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.185 (0.136)	Data 0.000 (0.006)	Loss 0.2315 (0.2304)	Acc@1 91.797 (91.965)	Acc@5 99.609 (99.856)
Epoch: [148][128/196]	Time 0.091 (0.135)	Data 0.000 (0.003)	Loss 0.2420 (0.2287)	Acc@1 92.969 (91.903)	Acc@5 100.000 (99.849)
Epoch: [148][192/196]	Time 0.145 (0.136)	Data 0.000 (0.002)	Loss 0.2133 (0.2287)	Acc@1 91.406 (91.858)	Acc@5 100.000 (99.856)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:149/150; Lr: 0.010000000000000002
batch Size 256
Epoch: [149][0/196]	Time 0.146 (0.146)	Data 0.447 (0.447)	Loss 0.1729 (0.1729)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.064 (0.138)	Data 0.000 (0.007)	Loss 0.1910 (0.2176)	Acc@1 93.750 (92.344)	Acc@5 100.000 (99.874)
Epoch: [149][128/196]	Time 0.192 (0.137)	Data 0.000 (0.004)	Loss 0.2040 (0.2229)	Acc@1 92.969 (92.224)	Acc@5 100.000 (99.827)
Epoch: [149][192/196]	Time 0.195 (0.137)	Data 0.000 (0.003)	Loss 0.2181 (0.2253)	Acc@1 91.406 (92.088)	Acc@5 100.000 (99.832)
Max memory in training epoch: 21.5243264
lr: 0.010000000000000002
1
Epoche:150/150; Lr: 0.0010000000000000002
batch Size 256
Epoch: [150][0/196]	Time 0.195 (0.195)	Data 0.361 (0.361)	Loss 0.1499 (0.1499)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.062 (0.120)	Data 0.000 (0.006)	Loss 0.1854 (0.2116)	Acc@1 94.141 (92.800)	Acc@5 100.000 (99.868)
Epoch: [150][128/196]	Time 0.170 (0.129)	Data 0.000 (0.003)	Loss 0.1834 (0.2043)	Acc@1 94.141 (92.902)	Acc@5 100.000 (99.867)
Epoch: [150][192/196]	Time 0.067 (0.130)	Data 0.000 (0.002)	Loss 0.1412 (0.1959)	Acc@1 96.875 (93.167)	Acc@5 100.000 (99.887)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  88.81
Max memory: 33.0690048
 26.051s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 9537
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:151/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [151][0/196]	Time 0.233 (0.233)	Data 0.407 (0.407)	Loss 0.2112 (0.2112)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.066 (0.135)	Data 0.000 (0.006)	Loss 0.1899 (0.1829)	Acc@1 92.188 (93.624)	Acc@5 100.000 (99.886)
Epoch: [151][128/196]	Time 0.072 (0.134)	Data 0.000 (0.003)	Loss 0.1130 (0.1817)	Acc@1 96.094 (93.735)	Acc@5 100.000 (99.894)
Epoch: [151][192/196]	Time 0.182 (0.129)	Data 0.000 (0.002)	Loss 0.1424 (0.1811)	Acc@1 94.922 (93.788)	Acc@5 99.609 (99.885)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:152/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [152][0/196]	Time 0.165 (0.165)	Data 0.386 (0.386)	Loss 0.1868 (0.1868)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 0.069 (0.136)	Data 0.000 (0.006)	Loss 0.1618 (0.1766)	Acc@1 94.141 (94.105)	Acc@5 100.000 (99.868)
Epoch: [152][128/196]	Time 0.183 (0.136)	Data 0.000 (0.003)	Loss 0.1593 (0.1782)	Acc@1 94.531 (93.980)	Acc@5 99.609 (99.879)
Epoch: [152][192/196]	Time 0.173 (0.136)	Data 0.000 (0.002)	Loss 0.1509 (0.1776)	Acc@1 94.531 (94.001)	Acc@5 100.000 (99.891)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:153/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [153][0/196]	Time 0.124 (0.124)	Data 0.444 (0.444)	Loss 0.1838 (0.1838)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.064 (0.135)	Data 0.000 (0.007)	Loss 0.1365 (0.1744)	Acc@1 94.922 (94.056)	Acc@5 100.000 (99.898)
Epoch: [153][128/196]	Time 0.186 (0.137)	Data 0.000 (0.004)	Loss 0.2352 (0.1761)	Acc@1 92.188 (94.089)	Acc@5 99.609 (99.891)
Epoch: [153][192/196]	Time 0.064 (0.136)	Data 0.000 (0.003)	Loss 0.1468 (0.1746)	Acc@1 96.094 (94.116)	Acc@5 100.000 (99.893)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:154/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [154][0/196]	Time 0.215 (0.215)	Data 0.435 (0.435)	Loss 0.1922 (0.1922)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.093 (0.131)	Data 0.000 (0.007)	Loss 0.1925 (0.1688)	Acc@1 94.531 (94.543)	Acc@5 100.000 (99.928)
Epoch: [154][128/196]	Time 0.066 (0.129)	Data 0.000 (0.004)	Loss 0.1954 (0.1717)	Acc@1 94.141 (94.274)	Acc@5 99.609 (99.927)
Epoch: [154][192/196]	Time 0.186 (0.132)	Data 0.000 (0.002)	Loss 0.1990 (0.1711)	Acc@1 92.578 (94.258)	Acc@5 100.000 (99.921)
Max memory in training epoch: 21.5243264
lr: 0.0010000000000000002
1
Epoche:155/155; Lr: 0.0010000000000000002
batch Size 256
Epoch: [155][0/196]	Time 0.164 (0.164)	Data 0.387 (0.387)	Loss 0.1955 (0.1955)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.182 (0.137)	Data 0.000 (0.006)	Loss 0.1323 (0.1718)	Acc@1 94.922 (94.183)	Acc@5 100.000 (99.904)
Epoch: [155][128/196]	Time 0.125 (0.136)	Data 0.000 (0.003)	Loss 0.1372 (0.1698)	Acc@1 95.703 (94.189)	Acc@5 100.000 (99.921)
Epoch: [155][192/196]	Time 0.157 (0.136)	Data 0.000 (0.002)	Loss 0.1378 (0.1697)	Acc@1 95.312 (94.218)	Acc@5 100.000 (99.923)
Max memory in training epoch: 21.5243264
[INFO] Storing checkpoint...
  89.24
Max memory: 33.0690048
 27.134s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[3, 3, 3]
[8, 16, 32]
random number: 6110
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.0665088
lr: 0.0010000000000000002
1
Epoche:156/160; Lr: 0.0010000000000000002
batch Size 256
