j: 1 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
[4, 8, 16]
random number: 5000
Files already downloaded and verified
Modell Erstellung
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=16, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.021504
lr: 0.1
Epoche:1/5; Lr: 0.1
batch Size 256
Epoch: [1][0/196]	Time 0.326 (0.326)	Data 0.515 (0.515)	Loss 2.4671 (2.4671)	Acc@1 12.109 (12.109)	Acc@5 51.562 (51.562)
Epoch: [1][64/196]	Time 0.276 (0.284)	Data 0.000 (0.008)	Loss 2.0299 (2.1704)	Acc@1 23.438 (17.608)	Acc@5 71.875 (65.950)
Epoch: [1][128/196]	Time 0.295 (0.257)	Data 0.000 (0.004)	Loss 1.7027 (2.0055)	Acc@1 36.719 (23.365)	Acc@5 85.938 (74.858)
Epoch: [1][192/196]	Time 0.297 (0.261)	Data 0.000 (0.003)	Loss 1.6457 (1.8990)	Acc@1 42.578 (27.504)	Acc@5 90.234 (79.467)
Max memory in training epoch: 16.8364032
lr: 0.1
Epoche:2/5; Lr: 0.1
batch Size 256
Epoch: [2][0/196]	Time 0.323 (0.323)	Data 0.499 (0.499)	Loss 1.6069 (1.6069)	Acc@1 42.578 (42.578)	Acc@5 91.406 (91.406)
Epoch: [2][64/196]	Time 0.295 (0.283)	Data 0.000 (0.008)	Loss 1.4334 (1.5607)	Acc@1 42.969 (41.869)	Acc@5 90.625 (90.553)
Epoch: [2][128/196]	Time 0.193 (0.267)	Data 0.000 (0.004)	Loss 1.4995 (1.5173)	Acc@1 49.219 (44.007)	Acc@5 91.797 (91.367)
Epoch: [2][192/196]	Time 0.298 (0.267)	Data 0.000 (0.003)	Loss 1.3806 (1.4726)	Acc@1 50.781 (45.867)	Acc@5 96.484 (91.999)
Max memory in training epoch: 16.8364032
lr: 0.1
Epoche:3/5; Lr: 0.1
batch Size 256
Epoch: [3][0/196]	Time 0.269 (0.269)	Data 0.530 (0.530)	Loss 1.3497 (1.3497)	Acc@1 50.000 (50.000)	Acc@5 94.141 (94.141)
Epoch: [3][64/196]	Time 0.271 (0.274)	Data 0.000 (0.008)	Loss 1.2464 (1.3025)	Acc@1 58.984 (53.119)	Acc@5 93.750 (93.966)
Epoch: [3][128/196]	Time 0.156 (0.264)	Data 0.000 (0.004)	Loss 1.1031 (1.2654)	Acc@1 58.984 (54.445)	Acc@5 96.094 (94.489)
Epoch: [3][192/196]	Time 0.275 (0.260)	Data 0.000 (0.003)	Loss 1.0657 (1.2382)	Acc@1 60.156 (55.442)	Acc@5 96.484 (94.760)
Max memory in training epoch: 16.8364032
lr: 0.1
Epoche:4/5; Lr: 0.1
batch Size 256
Epoch: [4][0/196]	Time 0.315 (0.315)	Data 0.568 (0.568)	Loss 1.1601 (1.1601)	Acc@1 57.031 (57.031)	Acc@5 96.484 (96.484)
Epoch: [4][64/196]	Time 0.307 (0.278)	Data 0.000 (0.009)	Loss 1.1583 (1.1508)	Acc@1 58.594 (58.864)	Acc@5 95.703 (95.523)
Epoch: [4][128/196]	Time 0.092 (0.275)	Data 0.000 (0.005)	Loss 1.1555 (1.1323)	Acc@1 58.984 (59.566)	Acc@5 94.922 (95.615)
Epoch: [4][192/196]	Time 0.292 (0.264)	Data 0.000 (0.003)	Loss 1.1175 (1.1202)	Acc@1 58.594 (59.909)	Acc@5 96.484 (95.699)
Max memory in training epoch: 16.8364032
lr: 0.1
Epoche:5/5; Lr: 0.1
batch Size 256
Epoch: [5][0/196]	Time 0.292 (0.292)	Data 0.537 (0.537)	Loss 1.1972 (1.1972)	Acc@1 58.984 (58.984)	Acc@5 95.312 (95.312)
Epoch: [5][64/196]	Time 0.289 (0.271)	Data 0.000 (0.009)	Loss 1.1186 (1.0699)	Acc@1 61.328 (61.550)	Acc@5 96.875 (96.082)
Epoch: [5][128/196]	Time 0.287 (0.275)	Data 0.000 (0.004)	Loss 1.0349 (1.0616)	Acc@1 66.016 (62.003)	Acc@5 94.922 (96.303)
Epoch: [5][192/196]	Time 0.096 (0.229)	Data 0.000 (0.003)	Loss 1.0417 (1.0504)	Acc@1 66.406 (62.435)	Acc@5 95.703 (96.347)
Max memory in training epoch: 16.8364032
[INFO] Storing checkpoint...
  55.11
Max memory: 26.0278272
 45.141s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
[4, 8, 16]
random number: 3720
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.0379392
lr: 0.1
Epoche:6/10; Lr: 0.1
batch Size 256
Epoch: [6][0/196]	Time 0.216 (0.216)	Data 0.471 (0.471)	Loss 1.0570 (1.0570)	Acc@1 63.281 (63.281)	Acc@5 96.094 (96.094)
Epoch: [6][64/196]	Time 0.142 (0.114)	Data 0.000 (0.007)	Loss 1.0101 (0.9858)	Acc@1 66.016 (65.282)	Acc@5 97.266 (96.779)
Epoch: [6][128/196]	Time 0.254 (0.180)	Data 0.000 (0.004)	Loss 0.9930 (0.9984)	Acc@1 64.453 (64.889)	Acc@5 96.484 (96.569)
Epoch: [6][192/196]	Time 0.237 (0.209)	Data 0.000 (0.003)	Loss 0.9773 (0.9988)	Acc@1 63.281 (64.840)	Acc@5 96.875 (96.523)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:7/10; Lr: 0.1
batch Size 256
Epoch: [7][0/196]	Time 0.328 (0.328)	Data 0.416 (0.416)	Loss 0.8788 (0.8788)	Acc@1 71.094 (71.094)	Acc@5 96.875 (96.875)
Epoch: [7][64/196]	Time 0.110 (0.268)	Data 0.000 (0.007)	Loss 0.9002 (0.9645)	Acc@1 65.625 (65.349)	Acc@5 96.094 (96.965)
Epoch: [7][128/196]	Time 0.307 (0.250)	Data 0.001 (0.004)	Loss 0.9893 (0.9482)	Acc@1 65.234 (66.406)	Acc@5 95.703 (96.972)
Epoch: [7][192/196]	Time 0.306 (0.256)	Data 0.000 (0.003)	Loss 1.0007 (0.9500)	Acc@1 64.844 (66.501)	Acc@5 97.656 (96.972)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:8/10; Lr: 0.1
batch Size 256
Epoch: [8][0/196]	Time 0.353 (0.353)	Data 0.486 (0.486)	Loss 0.8851 (0.8851)	Acc@1 71.094 (71.094)	Acc@5 96.094 (96.094)
Epoch: [8][64/196]	Time 0.334 (0.279)	Data 0.000 (0.008)	Loss 0.8974 (0.9139)	Acc@1 67.188 (67.969)	Acc@5 97.656 (97.157)
Epoch: [8][128/196]	Time 0.229 (0.282)	Data 0.000 (0.004)	Loss 0.8438 (0.9134)	Acc@1 70.703 (67.932)	Acc@5 96.875 (97.229)
Epoch: [8][192/196]	Time 0.372 (0.317)	Data 0.000 (0.003)	Loss 0.9242 (0.9085)	Acc@1 66.797 (68.167)	Acc@5 97.266 (97.243)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:9/10; Lr: 0.1
batch Size 256
Epoch: [9][0/196]	Time 0.560 (0.560)	Data 0.549 (0.549)	Loss 0.8115 (0.8115)	Acc@1 72.266 (72.266)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 0.279 (0.426)	Data 0.000 (0.009)	Loss 1.0375 (0.8788)	Acc@1 66.016 (69.207)	Acc@5 96.094 (97.554)
Epoch: [9][128/196]	Time 0.472 (0.408)	Data 0.000 (0.005)	Loss 1.0156 (0.8623)	Acc@1 61.328 (69.761)	Acc@5 97.656 (97.620)
Epoch: [9][192/196]	Time 0.457 (0.411)	Data 0.000 (0.003)	Loss 0.9343 (0.8612)	Acc@1 68.359 (69.839)	Acc@5 95.703 (97.521)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:10/10; Lr: 0.1
batch Size 256
Epoch: [10][0/196]	Time 0.444 (0.444)	Data 0.512 (0.512)	Loss 0.8413 (0.8413)	Acc@1 71.094 (71.094)	Acc@5 97.656 (97.656)
Epoch: [10][64/196]	Time 0.405 (0.413)	Data 0.000 (0.008)	Loss 0.9387 (0.8542)	Acc@1 68.359 (70.174)	Acc@5 98.438 (97.843)
Epoch: [10][128/196]	Time 0.471 (0.399)	Data 0.000 (0.004)	Loss 0.9050 (0.8437)	Acc@1 67.969 (70.543)	Acc@5 97.266 (97.832)
Epoch: [10][192/196]	Time 0.431 (0.405)	Data 0.000 (0.003)	Loss 0.7791 (0.8365)	Acc@1 75.391 (70.770)	Acc@5 98.438 (97.766)
Max memory in training epoch: 16.8528384
[INFO] Storing checkpoint...
  62.46
Max memory: 26.0442624
 80.085s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
[4, 8, 16]
random number: 9365
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.0379392
lr: 0.1
Epoche:11/15; Lr: 0.1
batch Size 256
Epoch: [11][0/196]	Time 0.478 (0.478)	Data 0.491 (0.491)	Loss 0.7805 (0.7805)	Acc@1 69.922 (69.922)	Acc@5 98.828 (98.828)
Epoch: [11][64/196]	Time 0.237 (0.388)	Data 0.000 (0.008)	Loss 0.7039 (0.8187)	Acc@1 78.125 (71.520)	Acc@5 97.656 (97.560)
Epoch: [11][128/196]	Time 0.201 (0.292)	Data 0.000 (0.004)	Loss 0.8146 (0.8177)	Acc@1 68.359 (71.551)	Acc@5 99.219 (97.656)
Epoch: [11][192/196]	Time 0.267 (0.265)	Data 0.000 (0.003)	Loss 0.8314 (0.8144)	Acc@1 70.312 (71.594)	Acc@5 98.828 (97.784)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:12/15; Lr: 0.1
batch Size 256
Epoch: [12][0/196]	Time 0.483 (0.483)	Data 0.517 (0.517)	Loss 0.7594 (0.7594)	Acc@1 70.703 (70.703)	Acc@5 98.828 (98.828)
Epoch: [12][64/196]	Time 0.397 (0.411)	Data 0.000 (0.008)	Loss 0.8191 (0.8093)	Acc@1 71.484 (71.454)	Acc@5 98.438 (97.879)
Epoch: [12][128/196]	Time 0.399 (0.413)	Data 0.000 (0.004)	Loss 0.7957 (0.8103)	Acc@1 74.609 (71.609)	Acc@5 98.438 (97.826)
Epoch: [12][192/196]	Time 0.400 (0.412)	Data 0.000 (0.003)	Loss 0.7117 (0.8016)	Acc@1 76.562 (71.982)	Acc@5 98.828 (97.905)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:13/15; Lr: 0.1
batch Size 256
Epoch: [13][0/196]	Time 0.448 (0.448)	Data 0.440 (0.440)	Loss 0.6571 (0.6571)	Acc@1 80.078 (80.078)	Acc@5 99.219 (99.219)
Epoch: [13][64/196]	Time 0.396 (0.420)	Data 0.000 (0.007)	Loss 0.7336 (0.7707)	Acc@1 75.000 (73.281)	Acc@5 98.047 (98.023)
Epoch: [13][128/196]	Time 0.408 (0.422)	Data 0.000 (0.004)	Loss 0.7000 (0.7795)	Acc@1 73.438 (73.083)	Acc@5 99.219 (97.998)
Epoch: [13][192/196]	Time 0.447 (0.420)	Data 0.000 (0.003)	Loss 0.7899 (0.7788)	Acc@1 69.531 (73.087)	Acc@5 98.047 (97.988)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:14/15; Lr: 0.1
batch Size 256
Epoch: [14][0/196]	Time 0.210 (0.210)	Data 0.445 (0.445)	Loss 0.7986 (0.7986)	Acc@1 74.219 (74.219)	Acc@5 97.656 (97.656)
Epoch: [14][64/196]	Time 0.443 (0.420)	Data 0.000 (0.007)	Loss 0.9080 (0.7526)	Acc@1 71.094 (73.894)	Acc@5 98.438 (98.095)
Epoch: [14][128/196]	Time 0.442 (0.421)	Data 0.000 (0.004)	Loss 0.6298 (0.7644)	Acc@1 78.125 (73.428)	Acc@5 99.609 (98.023)
Epoch: [14][192/196]	Time 0.427 (0.425)	Data 0.000 (0.003)	Loss 0.8075 (0.7625)	Acc@1 72.656 (73.484)	Acc@5 97.266 (98.071)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:15/15; Lr: 0.1
batch Size 256
Epoch: [15][0/196]	Time 0.433 (0.433)	Data 0.502 (0.502)	Loss 0.8077 (0.8077)	Acc@1 72.656 (72.656)	Acc@5 97.266 (97.266)
Epoch: [15][64/196]	Time 0.391 (0.415)	Data 0.000 (0.008)	Loss 0.8030 (0.7642)	Acc@1 73.047 (73.269)	Acc@5 98.438 (98.263)
Epoch: [15][128/196]	Time 0.100 (0.415)	Data 0.000 (0.004)	Loss 0.7330 (0.7595)	Acc@1 75.000 (73.450)	Acc@5 100.000 (98.186)
Epoch: [15][192/196]	Time 0.175 (0.349)	Data 0.000 (0.003)	Loss 0.6839 (0.7574)	Acc@1 78.516 (73.731)	Acc@5 96.875 (98.069)
Max memory in training epoch: 16.8528384
[INFO] Storing checkpoint...
  57.47
Max memory: 26.0442624
 68.543s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
[4, 8, 16]
random number: 6114
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.0379392
lr: 0.1
Epoche:16/20; Lr: 0.1
batch Size 256
Epoch: [16][0/196]	Time 0.202 (0.202)	Data 0.287 (0.287)	Loss 0.6237 (0.6237)	Acc@1 76.172 (76.172)	Acc@5 99.219 (99.219)
Epoch: [16][64/196]	Time 0.150 (0.208)	Data 0.000 (0.005)	Loss 0.8300 (0.7325)	Acc@1 73.828 (74.591)	Acc@5 97.266 (98.233)
Epoch: [16][128/196]	Time 0.279 (0.208)	Data 0.000 (0.002)	Loss 0.7620 (0.7391)	Acc@1 73.828 (74.346)	Acc@5 98.828 (98.204)
Epoch: [16][192/196]	Time 0.293 (0.207)	Data 0.000 (0.002)	Loss 0.7082 (0.7449)	Acc@1 73.438 (74.205)	Acc@5 98.047 (98.166)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:17/20; Lr: 0.1
batch Size 256
Epoch: [17][0/196]	Time 0.209 (0.209)	Data 0.449 (0.449)	Loss 0.6991 (0.6991)	Acc@1 76.172 (76.172)	Acc@5 98.047 (98.047)
Epoch: [17][64/196]	Time 0.119 (0.204)	Data 0.000 (0.007)	Loss 0.6811 (0.7144)	Acc@1 76.172 (75.222)	Acc@5 98.828 (98.323)
Epoch: [17][128/196]	Time 0.116 (0.202)	Data 0.000 (0.004)	Loss 0.7937 (0.7217)	Acc@1 73.438 (74.964)	Acc@5 98.047 (98.159)
Epoch: [17][192/196]	Time 0.300 (0.203)	Data 0.000 (0.003)	Loss 0.6968 (0.7300)	Acc@1 78.125 (74.615)	Acc@5 97.266 (98.189)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:18/20; Lr: 0.1
batch Size 256
Epoch: [18][0/196]	Time 0.153 (0.153)	Data 0.319 (0.319)	Loss 0.8124 (0.8124)	Acc@1 73.828 (73.828)	Acc@5 98.438 (98.438)
Epoch: [18][64/196]	Time 0.161 (0.211)	Data 0.000 (0.005)	Loss 0.7855 (0.7332)	Acc@1 75.000 (74.766)	Acc@5 98.047 (98.281)
Epoch: [18][128/196]	Time 0.190 (0.211)	Data 0.000 (0.003)	Loss 0.6781 (0.7319)	Acc@1 76.172 (74.737)	Acc@5 96.875 (98.271)
Epoch: [18][192/196]	Time 0.263 (0.212)	Data 0.000 (0.002)	Loss 0.7333 (0.7312)	Acc@1 74.219 (74.763)	Acc@5 98.047 (98.203)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:19/20; Lr: 0.1
batch Size 256
Epoch: [19][0/196]	Time 0.340 (0.340)	Data 0.446 (0.446)	Loss 0.7347 (0.7347)	Acc@1 75.781 (75.781)	Acc@5 98.047 (98.047)
Epoch: [19][64/196]	Time 0.135 (0.213)	Data 0.000 (0.007)	Loss 0.7540 (0.7213)	Acc@1 71.875 (75.096)	Acc@5 97.266 (98.095)
Epoch: [19][128/196]	Time 0.236 (0.203)	Data 0.000 (0.004)	Loss 0.6407 (0.7217)	Acc@1 79.297 (75.118)	Acc@5 100.000 (98.189)
Epoch: [19][192/196]	Time 0.295 (0.207)	Data 0.000 (0.003)	Loss 0.6596 (0.7150)	Acc@1 75.781 (75.239)	Acc@5 97.656 (98.294)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:20/20; Lr: 0.1
batch Size 256
Epoch: [20][0/196]	Time 0.251 (0.251)	Data 0.309 (0.309)	Loss 0.6948 (0.6948)	Acc@1 72.266 (72.266)	Acc@5 98.047 (98.047)
Epoch: [20][64/196]	Time 0.306 (0.216)	Data 0.000 (0.005)	Loss 0.7112 (0.7071)	Acc@1 76.172 (75.505)	Acc@5 97.656 (98.263)
Epoch: [20][128/196]	Time 0.258 (0.214)	Data 0.000 (0.003)	Loss 0.7083 (0.7097)	Acc@1 75.391 (75.224)	Acc@5 98.047 (98.328)
Epoch: [20][192/196]	Time 0.150 (0.214)	Data 0.000 (0.002)	Loss 0.6415 (0.7085)	Acc@1 79.297 (75.346)	Acc@5 97.656 (98.340)
Max memory in training epoch: 16.8528384
[INFO] Storing checkpoint...
  66.87
Max memory: 26.0442624
 42.372s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
[4, 8, 16]
random number: 1972
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.0379392
lr: 0.1
Epoche:21/25; Lr: 0.1
batch Size 256
Epoch: [21][0/196]	Time 0.334 (0.334)	Data 0.392 (0.392)	Loss 0.6492 (0.6492)	Acc@1 78.516 (78.516)	Acc@5 96.875 (96.875)
Epoch: [21][64/196]	Time 0.098 (0.203)	Data 0.000 (0.006)	Loss 0.6726 (0.6980)	Acc@1 74.609 (76.094)	Acc@5 98.047 (98.275)
Epoch: [21][128/196]	Time 0.182 (0.207)	Data 0.000 (0.003)	Loss 0.7181 (0.7023)	Acc@1 77.734 (75.760)	Acc@5 97.266 (98.292)
Epoch: [21][192/196]	Time 0.244 (0.207)	Data 0.000 (0.002)	Loss 0.7633 (0.7057)	Acc@1 72.266 (75.603)	Acc@5 98.047 (98.308)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:22/25; Lr: 0.1
batch Size 256
Epoch: [22][0/196]	Time 0.294 (0.294)	Data 0.484 (0.484)	Loss 0.6601 (0.6601)	Acc@1 77.734 (77.734)	Acc@5 98.828 (98.828)
Epoch: [22][64/196]	Time 0.140 (0.213)	Data 0.000 (0.008)	Loss 0.7172 (0.7086)	Acc@1 77.344 (75.180)	Acc@5 99.609 (98.293)
Epoch: [22][128/196]	Time 0.301 (0.205)	Data 0.000 (0.004)	Loss 0.6676 (0.7051)	Acc@1 75.000 (75.385)	Acc@5 98.438 (98.307)
Epoch: [22][192/196]	Time 0.193 (0.206)	Data 0.000 (0.003)	Loss 0.7257 (0.7018)	Acc@1 75.781 (75.524)	Acc@5 99.609 (98.336)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:23/25; Lr: 0.1
batch Size 256
Epoch: [23][0/196]	Time 0.255 (0.255)	Data 0.467 (0.467)	Loss 0.6461 (0.6461)	Acc@1 75.781 (75.781)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.212 (0.209)	Data 0.000 (0.007)	Loss 0.6042 (0.7031)	Acc@1 75.781 (75.409)	Acc@5 99.219 (98.389)
Epoch: [23][128/196]	Time 0.293 (0.210)	Data 0.000 (0.004)	Loss 0.7743 (0.7004)	Acc@1 74.219 (75.760)	Acc@5 97.266 (98.416)
Epoch: [23][192/196]	Time 0.172 (0.211)	Data 0.000 (0.003)	Loss 0.7152 (0.7019)	Acc@1 76.953 (75.686)	Acc@5 98.438 (98.425)
Max memory in training epoch: 16.8528384
lr: 0.1
Epoche:24/25; Lr: 0.1
batch Size 256
