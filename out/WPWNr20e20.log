no display found. Using non-interactive Agg backend
Files already downloaded and verified
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [1][0/391]	Time 0.202 (0.202)	Data 0.169 (0.169)	Loss 4.6179 (4.6179)	Acc@1 1.562 (1.562)	Acc@5 7.031 (7.031)
Epoch: [1][10/391]	Time 0.079 (0.092)	Data 0.001 (0.016)	Loss 4.6039 (4.6258)	Acc@1 1.562 (0.710)	Acc@5 7.812 (5.398)
Epoch: [1][20/391]	Time 0.081 (0.086)	Data 0.001 (0.009)	Loss 4.6240 (4.6226)	Acc@1 0.781 (0.670)	Acc@5 4.688 (5.134)
Epoch: [1][30/391]	Time 0.084 (0.084)	Data 0.001 (0.007)	Loss 4.5819 (4.6149)	Acc@1 1.562 (0.756)	Acc@5 9.375 (5.494)
Epoch: [1][40/391]	Time 0.078 (0.083)	Data 0.001 (0.005)	Loss 4.6095 (4.6093)	Acc@1 0.000 (0.857)	Acc@5 3.906 (5.450)
Epoch: [1][50/391]	Time 0.079 (0.082)	Data 0.001 (0.004)	Loss 4.5432 (4.6005)	Acc@1 3.125 (1.164)	Acc@5 8.594 (6.219)
Epoch: [1][60/391]	Time 0.080 (0.082)	Data 0.001 (0.004)	Loss 4.5394 (4.5904)	Acc@1 0.781 (1.447)	Acc@5 7.031 (6.980)
Epoch: [1][70/391]	Time 0.080 (0.082)	Data 0.001 (0.004)	Loss 4.5074 (4.5761)	Acc@1 2.344 (1.673)	Acc@5 15.625 (7.812)
Epoch: [1][80/391]	Time 0.081 (0.082)	Data 0.001 (0.003)	Loss 4.3912 (4.5604)	Acc@1 2.344 (1.823)	Acc@5 11.719 (8.488)
Epoch: [1][90/391]	Time 0.079 (0.082)	Data 0.001 (0.003)	Loss 4.4149 (4.5429)	Acc@1 3.125 (1.992)	Acc@5 15.625 (8.980)
Epoch: [1][100/391]	Time 0.078 (0.082)	Data 0.001 (0.003)	Loss 4.3675 (4.5288)	Acc@1 3.906 (2.119)	Acc@5 15.625 (9.623)
Epoch: [1][110/391]	Time 0.085 (0.081)	Data 0.001 (0.003)	Loss 4.3776 (4.5122)	Acc@1 3.906 (2.287)	Acc@5 13.281 (10.107)
Epoch: [1][120/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 4.3323 (4.4977)	Acc@1 3.125 (2.428)	Acc@5 17.188 (10.550)
Epoch: [1][130/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 4.3566 (4.4825)	Acc@1 2.344 (2.511)	Acc@5 15.625 (10.854)
Epoch: [1][140/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 4.2662 (4.4663)	Acc@1 4.688 (2.682)	Acc@5 16.406 (11.359)
Epoch: [1][150/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 4.2700 (4.4513)	Acc@1 1.562 (2.856)	Acc@5 13.281 (11.869)
Epoch: [1][160/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 4.2863 (4.4390)	Acc@1 3.906 (2.975)	Acc@5 16.406 (12.253)
Epoch: [1][170/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 4.3277 (4.4269)	Acc@1 4.688 (3.070)	Acc@5 17.188 (12.500)
Epoch: [1][180/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 4.2410 (4.4141)	Acc@1 6.250 (3.203)	Acc@5 18.750 (12.914)
Epoch: [1][190/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 4.2125 (4.4025)	Acc@1 4.688 (3.256)	Acc@5 15.625 (13.277)
Epoch: [1][200/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 4.1582 (4.3913)	Acc@1 7.031 (3.354)	Acc@5 25.781 (13.596)
Epoch: [1][210/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 4.2246 (4.3803)	Acc@1 5.469 (3.495)	Acc@5 17.188 (13.937)
Epoch: [1][220/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 4.1650 (4.3701)	Acc@1 3.125 (3.602)	Acc@5 16.406 (14.222)
Epoch: [1][230/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 4.0964 (4.3621)	Acc@1 7.031 (3.632)	Acc@5 25.000 (14.424)
Epoch: [1][240/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 4.1080 (4.3517)	Acc@1 8.594 (3.728)	Acc@5 21.094 (14.750)
Epoch: [1][250/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 4.2096 (4.3412)	Acc@1 4.688 (3.760)	Acc@5 16.406 (14.974)
Epoch: [1][260/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 4.0456 (4.3320)	Acc@1 4.688 (3.834)	Acc@5 27.344 (15.200)
Epoch: [1][270/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 4.0903 (4.3217)	Acc@1 5.469 (3.906)	Acc@5 24.219 (15.515)
Epoch: [1][280/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 4.0472 (4.3136)	Acc@1 3.906 (3.948)	Acc@5 25.781 (15.742)
Epoch: [1][290/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 4.1318 (4.3051)	Acc@1 9.375 (4.035)	Acc@5 21.094 (15.987)
Epoch: [1][300/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.9499 (4.2972)	Acc@1 10.156 (4.106)	Acc@5 28.125 (16.219)
Epoch: [1][310/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 4.0530 (4.2888)	Acc@1 7.812 (4.208)	Acc@5 26.562 (16.497)
Epoch: [1][320/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 4.0543 (4.2810)	Acc@1 3.125 (4.259)	Acc@5 22.656 (16.720)
Epoch: [1][330/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.9723 (4.2730)	Acc@1 2.344 (4.270)	Acc@5 24.219 (16.909)
Epoch: [1][340/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 4.1268 (4.2663)	Acc@1 7.812 (4.316)	Acc@5 20.312 (17.084)
Epoch: [1][350/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.8500 (4.2590)	Acc@1 9.375 (4.398)	Acc@5 32.812 (17.366)
Epoch: [1][360/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 3.9302 (4.2514)	Acc@1 10.156 (4.486)	Acc@5 28.125 (17.601)
Epoch: [1][370/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.9195 (4.2429)	Acc@1 9.375 (4.620)	Acc@5 27.344 (17.868)
Epoch: [1][380/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 4.0584 (4.2369)	Acc@1 4.688 (4.653)	Acc@5 26.562 (18.020)
Epoch: [1][390/391]	Time 0.132 (0.081)	Data 0.001 (0.002)	Loss 3.7671 (4.2289)	Acc@1 5.000 (4.748)	Acc@5 32.500 (18.270)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [2][0/391]	Time 0.090 (0.090)	Data 0.165 (0.165)	Loss 3.9481 (3.9481)	Acc@1 7.812 (7.812)	Acc@5 24.219 (24.219)
Epoch: [2][10/391]	Time 0.082 (0.083)	Data 0.001 (0.016)	Loss 4.0066 (3.9640)	Acc@1 3.906 (6.747)	Acc@5 27.344 (27.202)
Epoch: [2][20/391]	Time 0.081 (0.081)	Data 0.001 (0.009)	Loss 3.8795 (3.9327)	Acc@1 9.375 (7.626)	Acc@5 26.562 (27.902)
Epoch: [2][30/391]	Time 0.088 (0.081)	Data 0.001 (0.006)	Loss 3.9072 (3.9347)	Acc@1 10.156 (7.812)	Acc@5 29.688 (27.646)
Epoch: [2][40/391]	Time 0.081 (0.081)	Data 0.001 (0.005)	Loss 3.9407 (3.9214)	Acc@1 6.250 (7.793)	Acc@5 27.344 (27.763)
Epoch: [2][50/391]	Time 0.077 (0.081)	Data 0.001 (0.004)	Loss 3.9887 (3.9162)	Acc@1 4.688 (7.736)	Acc@5 26.562 (28.094)
Epoch: [2][60/391]	Time 0.077 (0.081)	Data 0.001 (0.004)	Loss 4.0092 (3.9033)	Acc@1 8.594 (8.120)	Acc@5 19.531 (28.484)
Epoch: [2][70/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 3.7225 (3.8933)	Acc@1 7.812 (7.945)	Acc@5 35.938 (28.653)
Epoch: [2][80/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 3.8334 (3.8902)	Acc@1 9.375 (8.189)	Acc@5 33.594 (28.771)
Epoch: [2][90/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 3.9107 (3.8874)	Acc@1 6.250 (8.293)	Acc@5 30.469 (28.958)
Epoch: [2][100/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 3.8589 (3.8841)	Acc@1 5.469 (8.308)	Acc@5 32.031 (29.169)
Epoch: [2][110/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 3.8242 (3.8761)	Acc@1 5.469 (8.319)	Acc@5 32.031 (29.441)
Epoch: [2][120/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.9829 (3.8746)	Acc@1 8.594 (8.361)	Acc@5 26.562 (29.390)
Epoch: [2][130/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 3.9463 (3.8727)	Acc@1 9.375 (8.457)	Acc@5 25.781 (29.509)
Epoch: [2][140/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.8112 (3.8657)	Acc@1 9.375 (8.527)	Acc@5 29.688 (29.804)
Epoch: [2][150/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.9672 (3.8635)	Acc@1 7.812 (8.625)	Acc@5 31.250 (29.946)
Epoch: [2][160/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.9403 (3.8642)	Acc@1 7.031 (8.594)	Acc@5 25.781 (29.833)
Epoch: [2][170/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.9127 (3.8618)	Acc@1 8.594 (8.667)	Acc@5 28.906 (29.925)
Epoch: [2][180/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 3.7128 (3.8599)	Acc@1 13.281 (8.702)	Acc@5 35.938 (29.990)
Epoch: [2][190/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 3.8663 (3.8580)	Acc@1 8.594 (8.729)	Acc@5 26.562 (30.068)
Epoch: [2][200/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.8060 (3.8546)	Acc@1 8.594 (8.773)	Acc@5 30.469 (30.134)
Epoch: [2][210/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 3.7440 (3.8523)	Acc@1 8.594 (8.823)	Acc@5 32.812 (30.210)
Epoch: [2][220/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.9047 (3.8468)	Acc@1 7.031 (8.912)	Acc@5 29.688 (30.416)
Epoch: [2][230/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 3.6878 (3.8418)	Acc@1 10.156 (9.000)	Acc@5 35.156 (30.543)
Epoch: [2][240/391]	Time 0.083 (0.081)	Data 0.002 (0.002)	Loss 3.7742 (3.8382)	Acc@1 9.375 (9.044)	Acc@5 37.500 (30.722)
Epoch: [2][250/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 3.5377 (3.8338)	Acc@1 17.188 (9.163)	Acc@5 38.281 (30.926)
Epoch: [2][260/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 3.5636 (3.8285)	Acc@1 15.625 (9.255)	Acc@5 40.625 (31.127)
Epoch: [2][270/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.8839 (3.8249)	Acc@1 7.812 (9.277)	Acc@5 30.469 (31.230)
Epoch: [2][280/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 3.5476 (3.8197)	Acc@1 10.938 (9.367)	Acc@5 44.531 (31.381)
Epoch: [2][290/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 3.8269 (3.8181)	Acc@1 10.938 (9.421)	Acc@5 35.156 (31.467)
Epoch: [2][300/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 3.6809 (3.8141)	Acc@1 5.469 (9.463)	Acc@5 35.156 (31.538)
Epoch: [2][310/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 3.6300 (3.8113)	Acc@1 11.719 (9.488)	Acc@5 33.594 (31.612)
Epoch: [2][320/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 3.6201 (3.8074)	Acc@1 15.625 (9.565)	Acc@5 35.938 (31.742)
Epoch: [2][330/391]	Time 0.086 (0.082)	Data 0.001 (0.002)	Loss 3.8384 (3.8058)	Acc@1 9.375 (9.625)	Acc@5 32.812 (31.831)
Epoch: [2][340/391]	Time 0.087 (0.082)	Data 0.001 (0.002)	Loss 3.9563 (3.8023)	Acc@1 9.375 (9.707)	Acc@5 26.562 (31.972)
Epoch: [2][350/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 3.6945 (3.7996)	Acc@1 8.594 (9.773)	Acc@5 34.375 (32.089)
Epoch: [2][360/391]	Time 0.087 (0.082)	Data 0.001 (0.002)	Loss 3.7690 (3.7942)	Acc@1 13.281 (9.866)	Acc@5 28.125 (32.248)
Epoch: [2][370/391]	Time 0.086 (0.082)	Data 0.001 (0.002)	Loss 3.6140 (3.7911)	Acc@1 9.375 (9.918)	Acc@5 38.281 (32.339)
Epoch: [2][380/391]	Time 0.086 (0.082)	Data 0.001 (0.002)	Loss 3.4522 (3.7862)	Acc@1 16.406 (9.986)	Acc@5 42.188 (32.470)
Epoch: [2][390/391]	Time 0.070 (0.082)	Data 0.002 (0.002)	Loss 3.5297 (3.7846)	Acc@1 12.500 (9.978)	Acc@5 42.500 (32.498)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [3][0/391]	Time 0.091 (0.091)	Data 0.160 (0.160)	Loss 3.6785 (3.6785)	Acc@1 12.500 (12.500)	Acc@5 34.375 (34.375)
Epoch: [3][10/391]	Time 0.079 (0.083)	Data 0.001 (0.016)	Loss 3.5900 (3.6404)	Acc@1 11.719 (12.074)	Acc@5 42.969 (37.003)
Epoch: [3][20/391]	Time 0.081 (0.081)	Data 0.001 (0.009)	Loss 3.7970 (3.6684)	Acc@1 7.812 (11.161)	Acc@5 31.250 (36.644)
Epoch: [3][30/391]	Time 0.079 (0.082)	Data 0.001 (0.006)	Loss 3.6020 (3.6481)	Acc@1 8.594 (11.517)	Acc@5 42.188 (37.777)
Epoch: [3][40/391]	Time 0.078 (0.081)	Data 0.001 (0.005)	Loss 3.6947 (3.6415)	Acc@1 14.062 (11.833)	Acc@5 39.844 (38.281)
Epoch: [3][50/391]	Time 0.087 (0.081)	Data 0.001 (0.004)	Loss 3.8162 (3.6547)	Acc@1 11.719 (11.596)	Acc@5 30.469 (37.454)
Epoch: [3][60/391]	Time 0.080 (0.081)	Data 0.001 (0.004)	Loss 3.7316 (3.6606)	Acc@1 14.844 (11.706)	Acc@5 30.469 (36.962)
Epoch: [3][70/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 3.4182 (3.6587)	Acc@1 15.625 (11.818)	Acc@5 45.312 (37.082)
Epoch: [3][80/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 3.8231 (3.6546)	Acc@1 7.812 (11.757)	Acc@5 33.594 (37.133)
Epoch: [3][90/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 3.5108 (3.6440)	Acc@1 13.281 (11.976)	Acc@5 46.094 (37.526)
Epoch: [3][100/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 3.3446 (3.6379)	Acc@1 17.969 (12.090)	Acc@5 44.531 (37.539)
Epoch: [3][110/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 3.5553 (3.6312)	Acc@1 12.500 (12.148)	Acc@5 42.188 (37.789)
Epoch: [3][120/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.3869 (3.6277)	Acc@1 20.312 (12.216)	Acc@5 42.969 (37.881)
Epoch: [3][130/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.6052 (3.6191)	Acc@1 16.406 (12.476)	Acc@5 42.969 (38.168)
Epoch: [3][140/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.5556 (3.6132)	Acc@1 10.156 (12.572)	Acc@5 41.406 (38.248)
Epoch: [3][150/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.6465 (3.6088)	Acc@1 11.719 (12.640)	Acc@5 36.719 (38.317)
Epoch: [3][160/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.7677 (3.6091)	Acc@1 12.500 (12.723)	Acc@5 33.594 (38.369)
Epoch: [3][170/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.5636 (3.6092)	Acc@1 15.625 (12.719)	Acc@5 42.188 (38.437)
Epoch: [3][180/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.5113 (3.6072)	Acc@1 11.719 (12.785)	Acc@5 42.969 (38.445)
Epoch: [3][190/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.4113 (3.6060)	Acc@1 15.625 (12.839)	Acc@5 45.312 (38.416)
Epoch: [3][200/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.5159 (3.6002)	Acc@1 15.625 (12.990)	Acc@5 38.281 (38.511)
Epoch: [3][210/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.3700 (3.5978)	Acc@1 15.625 (13.137)	Acc@5 42.188 (38.570)
Epoch: [3][220/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.4645 (3.5973)	Acc@1 10.938 (13.143)	Acc@5 39.062 (38.652)
Epoch: [3][230/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.6777 (3.5959)	Acc@1 17.188 (13.231)	Acc@5 40.625 (38.718)
Epoch: [3][240/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.4799 (3.5940)	Acc@1 11.719 (13.281)	Acc@5 42.969 (38.803)
Epoch: [3][250/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.6227 (3.5934)	Acc@1 13.281 (13.306)	Acc@5 39.844 (38.807)
Epoch: [3][260/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.5510 (3.5911)	Acc@1 14.062 (13.305)	Acc@5 39.062 (38.880)
Epoch: [3][270/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 3.5542 (3.5890)	Acc@1 10.938 (13.319)	Acc@5 39.062 (38.944)
Epoch: [3][280/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.5403 (3.5853)	Acc@1 17.969 (13.390)	Acc@5 39.844 (39.057)
Epoch: [3][290/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.3821 (3.5838)	Acc@1 20.312 (13.397)	Acc@5 45.312 (39.084)
Epoch: [3][300/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.4712 (3.5797)	Acc@1 7.812 (13.424)	Acc@5 45.312 (39.231)
Epoch: [3][310/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.5172 (3.5771)	Acc@1 13.281 (13.470)	Acc@5 42.188 (39.364)
Epoch: [3][320/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.4136 (3.5712)	Acc@1 15.625 (13.510)	Acc@5 41.406 (39.574)
Epoch: [3][330/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 3.9640 (3.5692)	Acc@1 10.156 (13.560)	Acc@5 30.469 (39.584)
Epoch: [3][340/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.4277 (3.5670)	Acc@1 14.844 (13.595)	Acc@5 36.719 (39.594)
Epoch: [3][350/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.9786 (3.5635)	Acc@1 28.125 (13.653)	Acc@5 59.375 (39.704)
Epoch: [3][360/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 3.4376 (3.5610)	Acc@1 18.750 (13.740)	Acc@5 45.312 (39.798)
Epoch: [3][370/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.3981 (3.5568)	Acc@1 13.281 (13.785)	Acc@5 45.312 (39.907)
Epoch: [3][380/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.2617 (3.5531)	Acc@1 21.875 (13.837)	Acc@5 45.312 (39.971)
Epoch: [3][390/391]	Time 0.068 (0.081)	Data 0.001 (0.002)	Loss 3.4065 (3.5515)	Acc@1 21.250 (13.850)	Acc@5 51.250 (40.042)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [4][0/391]	Time 0.089 (0.089)	Data 0.169 (0.169)	Loss 3.2355 (3.2355)	Acc@1 22.656 (22.656)	Acc@5 53.125 (53.125)
Epoch: [4][10/391]	Time 0.079 (0.081)	Data 0.001 (0.016)	Loss 3.4759 (3.3892)	Acc@1 14.062 (18.111)	Acc@5 45.312 (45.384)
Epoch: [4][20/391]	Time 0.078 (0.080)	Data 0.001 (0.009)	Loss 3.3857 (3.3983)	Acc@1 16.406 (16.555)	Acc@5 41.406 (43.601)
Epoch: [4][30/391]	Time 0.079 (0.081)	Data 0.001 (0.007)	Loss 3.4910 (3.3872)	Acc@1 9.375 (16.583)	Acc@5 37.500 (43.826)
Epoch: [4][40/391]	Time 0.080 (0.080)	Data 0.001 (0.005)	Loss 3.4619 (3.4093)	Acc@1 9.375 (16.063)	Acc@5 42.969 (43.350)
Epoch: [4][50/391]	Time 0.087 (0.080)	Data 0.001 (0.004)	Loss 3.2839 (3.4089)	Acc@1 15.625 (15.993)	Acc@5 45.312 (43.444)
Epoch: [4][60/391]	Time 0.078 (0.080)	Data 0.001 (0.004)	Loss 3.3012 (3.4095)	Acc@1 16.406 (16.112)	Acc@5 44.531 (43.391)
Epoch: [4][70/391]	Time 0.083 (0.080)	Data 0.002 (0.003)	Loss 3.3719 (3.4174)	Acc@1 17.188 (15.988)	Acc@5 42.969 (43.112)
Epoch: [4][80/391]	Time 0.080 (0.080)	Data 0.001 (0.003)	Loss 3.5690 (3.4194)	Acc@1 16.406 (16.001)	Acc@5 40.625 (43.171)
Epoch: [4][90/391]	Time 0.081 (0.080)	Data 0.001 (0.003)	Loss 3.2136 (3.4212)	Acc@1 19.531 (15.822)	Acc@5 43.750 (43.175)
Epoch: [4][100/391]	Time 0.080 (0.080)	Data 0.001 (0.003)	Loss 3.5169 (3.4102)	Acc@1 14.844 (16.066)	Acc@5 40.625 (43.464)
Epoch: [4][110/391]	Time 0.080 (0.080)	Data 0.001 (0.003)	Loss 3.1138 (3.3981)	Acc@1 22.656 (16.174)	Acc@5 53.125 (43.912)
Epoch: [4][120/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 3.2442 (3.3870)	Acc@1 16.406 (16.361)	Acc@5 46.094 (44.228)
Epoch: [4][130/391]	Time 0.085 (0.080)	Data 0.001 (0.002)	Loss 3.4152 (3.3896)	Acc@1 19.531 (16.400)	Acc@5 43.750 (44.156)
Epoch: [4][140/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 3.4290 (3.3898)	Acc@1 14.062 (16.345)	Acc@5 44.531 (44.188)
Epoch: [4][150/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.3879 (3.3857)	Acc@1 16.406 (16.380)	Acc@5 41.406 (44.309)
Epoch: [4][160/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.3589 (3.3833)	Acc@1 14.844 (16.562)	Acc@5 46.094 (44.337)
Epoch: [4][170/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.3187 (3.3760)	Acc@1 18.750 (16.658)	Acc@5 42.969 (44.527)
Epoch: [4][180/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.1486 (3.3714)	Acc@1 19.531 (16.747)	Acc@5 49.219 (44.566)
Epoch: [4][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.3144 (3.3693)	Acc@1 21.094 (16.762)	Acc@5 48.438 (44.752)
Epoch: [4][200/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.0497 (3.3636)	Acc@1 22.656 (16.849)	Acc@5 49.219 (44.811)
Epoch: [4][210/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.3762 (3.3647)	Acc@1 17.188 (16.858)	Acc@5 42.969 (44.768)
Epoch: [4][220/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 3.2905 (3.3663)	Acc@1 25.000 (16.852)	Acc@5 51.562 (44.761)
Epoch: [4][230/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.1435 (3.3647)	Acc@1 18.750 (16.819)	Acc@5 51.562 (44.856)
Epoch: [4][240/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.4127 (3.3595)	Acc@1 15.625 (16.941)	Acc@5 42.969 (45.018)
Epoch: [4][250/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.3336 (3.3572)	Acc@1 20.312 (16.963)	Acc@5 49.219 (45.042)
Epoch: [4][260/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.4029 (3.3509)	Acc@1 21.094 (17.071)	Acc@5 42.969 (45.223)
Epoch: [4][270/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.3886 (3.3479)	Acc@1 16.406 (17.164)	Acc@5 45.312 (45.341)
Epoch: [4][280/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.0793 (3.3439)	Acc@1 19.531 (17.232)	Acc@5 52.344 (45.443)
Epoch: [4][290/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 3.2692 (3.3421)	Acc@1 17.969 (17.249)	Acc@5 49.219 (45.508)
Epoch: [4][300/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 3.1934 (3.3381)	Acc@1 20.312 (17.369)	Acc@5 46.094 (45.671)
Epoch: [4][310/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.0656 (3.3350)	Acc@1 25.000 (17.464)	Acc@5 50.781 (45.727)
Epoch: [4][320/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.2834 (3.3330)	Acc@1 17.188 (17.438)	Acc@5 55.469 (45.814)
Epoch: [4][330/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.3109 (3.3295)	Acc@1 14.062 (17.464)	Acc@5 48.438 (45.912)
Epoch: [4][340/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.2047 (3.3266)	Acc@1 16.406 (17.538)	Acc@5 52.344 (46.034)
Epoch: [4][350/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.2070 (3.3232)	Acc@1 18.750 (17.606)	Acc@5 44.531 (46.123)
Epoch: [4][360/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.1738 (3.3201)	Acc@1 17.188 (17.659)	Acc@5 48.438 (46.191)
Epoch: [4][370/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.1766 (3.3192)	Acc@1 23.438 (17.737)	Acc@5 49.219 (46.256)
Epoch: [4][380/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.0976 (3.3163)	Acc@1 20.312 (17.766)	Acc@5 57.812 (46.377)
Epoch: [4][390/391]	Time 0.068 (0.081)	Data 0.001 (0.002)	Loss 3.3878 (3.3144)	Acc@1 17.500 (17.786)	Acc@5 45.000 (46.430)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [5][0/391]	Time 0.099 (0.099)	Data 0.203 (0.203)	Loss 3.0806 (3.0806)	Acc@1 23.438 (23.438)	Acc@5 53.125 (53.125)
Epoch: [5][10/391]	Time 0.081 (0.083)	Data 0.001 (0.019)	Loss 3.2561 (3.2691)	Acc@1 17.188 (17.685)	Acc@5 50.000 (46.875)
Epoch: [5][20/391]	Time 0.082 (0.082)	Data 0.001 (0.011)	Loss 3.2994 (3.2452)	Acc@1 18.750 (18.341)	Acc@5 47.656 (48.103)
Epoch: [5][30/391]	Time 0.080 (0.082)	Data 0.001 (0.008)	Loss 3.0265 (3.2098)	Acc@1 23.438 (18.826)	Acc@5 55.469 (48.866)
Epoch: [5][40/391]	Time 0.081 (0.081)	Data 0.001 (0.006)	Loss 3.1455 (3.1914)	Acc@1 18.750 (18.902)	Acc@5 51.562 (49.352)
Epoch: [5][50/391]	Time 0.078 (0.081)	Data 0.001 (0.005)	Loss 3.1796 (3.1926)	Acc@1 18.750 (18.719)	Acc@5 50.781 (49.403)
Epoch: [5][60/391]	Time 0.081 (0.081)	Data 0.001 (0.004)	Loss 3.2825 (3.1947)	Acc@1 20.312 (18.840)	Acc@5 45.312 (49.257)
Epoch: [5][70/391]	Time 0.081 (0.081)	Data 0.001 (0.004)	Loss 3.0266 (3.1840)	Acc@1 21.094 (19.124)	Acc@5 58.594 (49.714)
Epoch: [5][80/391]	Time 0.080 (0.081)	Data 0.001 (0.004)	Loss 3.2605 (3.1871)	Acc@1 17.969 (19.136)	Acc@5 53.125 (49.691)
Epoch: [5][90/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 3.0534 (3.1834)	Acc@1 19.531 (19.325)	Acc@5 51.562 (49.957)
Epoch: [5][100/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 3.2337 (3.1796)	Acc@1 24.219 (19.516)	Acc@5 47.656 (50.031)
Epoch: [5][110/391]	Time 0.084 (0.081)	Data 0.001 (0.003)	Loss 3.1896 (3.1839)	Acc@1 19.531 (19.672)	Acc@5 47.656 (49.958)
Epoch: [5][120/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 3.0445 (3.1796)	Acc@1 21.875 (19.744)	Acc@5 53.906 (50.090)
Epoch: [5][130/391]	Time 0.083 (0.081)	Data 0.001 (0.003)	Loss 3.3016 (3.1830)	Acc@1 21.094 (19.680)	Acc@5 49.219 (49.922)
Epoch: [5][140/391]	Time 0.084 (0.081)	Data 0.001 (0.003)	Loss 3.0070 (3.1833)	Acc@1 24.219 (19.747)	Acc@5 55.469 (50.000)
Epoch: [5][150/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 3.1080 (3.1815)	Acc@1 20.312 (19.847)	Acc@5 50.781 (50.135)
Epoch: [5][160/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.0894 (3.1763)	Acc@1 21.875 (19.847)	Acc@5 57.812 (50.364)
Epoch: [5][170/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.1986 (3.1739)	Acc@1 22.656 (19.942)	Acc@5 52.344 (50.292)
Epoch: [5][180/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8598 (3.1721)	Acc@1 22.656 (20.015)	Acc@5 53.125 (50.363)
Epoch: [5][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.2617 (3.1735)	Acc@1 19.531 (19.961)	Acc@5 52.344 (50.393)
Epoch: [5][200/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8527 (3.1695)	Acc@1 25.781 (20.025)	Acc@5 55.469 (50.443)
Epoch: [5][210/391]	Time 0.082 (0.081)	Data 0.002 (0.002)	Loss 3.0987 (3.1690)	Acc@1 23.438 (20.039)	Acc@5 50.781 (50.433)
Epoch: [5][220/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.3321 (3.1661)	Acc@1 19.531 (20.076)	Acc@5 51.562 (50.470)
Epoch: [5][230/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.8602 (3.1624)	Acc@1 25.000 (20.130)	Acc@5 57.031 (50.592)
Epoch: [5][240/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.1391 (3.1593)	Acc@1 24.219 (20.196)	Acc@5 51.562 (50.694)
Epoch: [5][250/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.1795 (3.1587)	Acc@1 18.750 (20.160)	Acc@5 49.219 (50.735)
Epoch: [5][260/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.3157 (3.1563)	Acc@1 17.188 (20.250)	Acc@5 45.312 (50.790)
Epoch: [5][270/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 3.2203 (3.1563)	Acc@1 26.562 (20.333)	Acc@5 48.438 (50.761)
Epoch: [5][280/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.5764 (3.1541)	Acc@1 12.500 (20.335)	Acc@5 43.750 (50.865)
Epoch: [5][290/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.0919 (3.1521)	Acc@1 21.094 (20.329)	Acc@5 57.031 (50.975)
Epoch: [5][300/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.9585 (3.1483)	Acc@1 22.656 (20.406)	Acc@5 52.344 (51.082)
Epoch: [5][310/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.2575 (3.1471)	Acc@1 14.844 (20.446)	Acc@5 50.781 (51.138)
Epoch: [5][320/391]	Time 0.076 (0.081)	Data 0.001 (0.002)	Loss 3.1103 (3.1456)	Acc@1 28.125 (20.544)	Acc@5 51.562 (51.205)
Epoch: [5][330/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.0237 (3.1457)	Acc@1 21.875 (20.544)	Acc@5 51.562 (51.166)
Epoch: [5][340/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.8874 (3.1454)	Acc@1 25.000 (20.514)	Acc@5 62.500 (51.217)
Epoch: [5][350/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 3.2701 (3.1454)	Acc@1 12.500 (20.526)	Acc@5 52.344 (51.249)
Epoch: [5][360/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.0335 (3.1444)	Acc@1 23.438 (20.583)	Acc@5 51.562 (51.234)
Epoch: [5][370/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.9963 (3.1441)	Acc@1 22.656 (20.620)	Acc@5 59.375 (51.213)
Epoch: [5][380/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.0216 (3.1422)	Acc@1 25.781 (20.688)	Acc@5 53.125 (51.245)
Epoch: [5][390/391]	Time 0.066 (0.081)	Data 0.001 (0.002)	Loss 2.9431 (3.1400)	Acc@1 26.250 (20.746)	Acc@5 58.750 (51.322)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [6][0/391]	Time 0.092 (0.092)	Data 0.164 (0.164)	Loss 3.0764 (3.0764)	Acc@1 22.656 (22.656)	Acc@5 52.344 (52.344)
Epoch: [6][10/391]	Time 0.079 (0.083)	Data 0.001 (0.016)	Loss 2.9764 (3.1143)	Acc@1 23.438 (20.312)	Acc@5 52.344 (50.000)
Epoch: [6][20/391]	Time 0.080 (0.081)	Data 0.001 (0.009)	Loss 3.0153 (3.0494)	Acc@1 23.438 (22.470)	Acc@5 52.344 (52.753)
Epoch: [6][30/391]	Time 0.081 (0.081)	Data 0.001 (0.006)	Loss 3.2724 (3.0571)	Acc@1 17.969 (22.329)	Acc@5 46.094 (52.823)
Epoch: [6][40/391]	Time 0.078 (0.080)	Data 0.001 (0.005)	Loss 2.9250 (3.0650)	Acc@1 25.781 (21.970)	Acc@5 57.031 (52.973)
Epoch: [6][50/391]	Time 0.076 (0.080)	Data 0.001 (0.004)	Loss 2.9259 (3.0677)	Acc@1 20.312 (22.059)	Acc@5 59.375 (52.849)
Epoch: [6][60/391]	Time 0.080 (0.080)	Data 0.001 (0.004)	Loss 3.0276 (3.0692)	Acc@1 17.188 (21.670)	Acc@5 52.344 (52.843)
Epoch: [6][70/391]	Time 0.081 (0.080)	Data 0.001 (0.003)	Loss 2.9327 (3.0742)	Acc@1 26.562 (21.556)	Acc@5 57.031 (52.982)
Epoch: [6][80/391]	Time 0.080 (0.080)	Data 0.001 (0.003)	Loss 3.0150 (3.0727)	Acc@1 20.312 (21.672)	Acc@5 60.156 (53.077)
Epoch: [6][90/391]	Time 0.081 (0.080)	Data 0.001 (0.003)	Loss 2.9904 (3.0659)	Acc@1 25.000 (21.720)	Acc@5 60.156 (53.357)
Epoch: [6][100/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 3.0032 (3.0606)	Acc@1 21.875 (21.720)	Acc@5 55.469 (53.442)
Epoch: [6][110/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 3.1897 (3.0560)	Acc@1 23.438 (21.875)	Acc@5 50.781 (53.625)
Epoch: [6][120/391]	Time 0.078 (0.080)	Data 0.001 (0.003)	Loss 2.8990 (3.0546)	Acc@1 24.219 (22.036)	Acc@5 54.688 (53.764)
Epoch: [6][130/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 3.0363 (3.0501)	Acc@1 21.094 (22.161)	Acc@5 50.781 (53.805)
Epoch: [6][140/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 3.2069 (3.0522)	Acc@1 25.000 (22.091)	Acc@5 48.438 (53.563)
Epoch: [6][150/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.8993 (3.0468)	Acc@1 28.906 (22.341)	Acc@5 57.031 (53.689)
Epoch: [6][160/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 2.8836 (3.0434)	Acc@1 22.656 (22.443)	Acc@5 60.938 (53.906)
Epoch: [6][170/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.9359 (3.0429)	Acc@1 22.656 (22.446)	Acc@5 54.688 (53.920)
Epoch: [6][180/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.7864 (3.0403)	Acc@1 32.031 (22.497)	Acc@5 58.594 (53.962)
Epoch: [6][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.0325 (3.0421)	Acc@1 21.094 (22.497)	Acc@5 53.125 (53.935)
Epoch: [6][200/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.0538 (3.0419)	Acc@1 17.969 (22.520)	Acc@5 50.781 (53.875)
Epoch: [6][210/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.1040 (3.0400)	Acc@1 22.656 (22.578)	Acc@5 49.219 (53.877)
Epoch: [6][220/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 3.1461 (3.0382)	Acc@1 19.531 (22.600)	Acc@5 53.125 (53.980)
Epoch: [6][230/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.1865 (3.0398)	Acc@1 17.969 (22.541)	Acc@5 50.781 (53.964)
Epoch: [6][240/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 2.9255 (3.0373)	Acc@1 23.438 (22.611)	Acc@5 57.031 (54.029)
Epoch: [6][250/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.8046 (3.0368)	Acc@1 26.562 (22.610)	Acc@5 63.281 (54.049)
Epoch: [6][260/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.7918 (3.0330)	Acc@1 34.375 (22.719)	Acc@5 57.812 (54.143)
Epoch: [6][270/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.8623 (3.0327)	Acc@1 22.656 (22.699)	Acc@5 56.250 (54.148)
Epoch: [6][280/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 3.2533 (3.0344)	Acc@1 14.844 (22.665)	Acc@5 48.438 (54.120)
Epoch: [6][290/391]	Time 0.080 (0.081)	Data 0.002 (0.002)	Loss 2.8797 (3.0323)	Acc@1 24.219 (22.675)	Acc@5 60.938 (54.188)
Epoch: [6][300/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8426 (3.0314)	Acc@1 21.875 (22.680)	Acc@5 57.031 (54.238)
Epoch: [6][310/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.0164 (3.0295)	Acc@1 24.219 (22.757)	Acc@5 56.250 (54.268)
Epoch: [6][320/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.0075 (3.0291)	Acc@1 14.844 (22.751)	Acc@5 48.438 (54.235)
Epoch: [6][330/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.9420 (3.0261)	Acc@1 21.875 (22.819)	Acc@5 57.031 (54.251)
Epoch: [6][340/391]	Time 0.088 (0.081)	Data 0.001 (0.002)	Loss 2.8690 (3.0237)	Acc@1 30.469 (22.851)	Acc@5 57.031 (54.303)
Epoch: [6][350/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.6923 (3.0213)	Acc@1 31.250 (22.912)	Acc@5 60.938 (54.367)
Epoch: [6][360/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.9620 (3.0185)	Acc@1 25.781 (22.959)	Acc@5 59.375 (54.469)
Epoch: [6][370/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 3.1679 (3.0156)	Acc@1 21.094 (22.991)	Acc@5 50.000 (54.498)
Epoch: [6][380/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 3.0426 (3.0141)	Acc@1 18.750 (23.007)	Acc@5 55.469 (54.548)
Epoch: [6][390/391]	Time 0.066 (0.081)	Data 0.001 (0.002)	Loss 3.0903 (3.0119)	Acc@1 21.250 (23.064)	Acc@5 52.500 (54.616)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [7][0/391]	Time 0.088 (0.088)	Data 0.186 (0.186)	Loss 3.1054 (3.1054)	Acc@1 17.969 (17.969)	Acc@5 56.250 (56.250)
Epoch: [7][10/391]	Time 0.088 (0.085)	Data 0.001 (0.018)	Loss 2.8480 (2.9404)	Acc@1 31.250 (24.290)	Acc@5 58.594 (55.824)
Epoch: [7][20/391]	Time 0.085 (0.085)	Data 0.001 (0.010)	Loss 2.6476 (2.8772)	Acc@1 31.250 (26.302)	Acc@5 60.938 (57.403)
Epoch: [7][30/391]	Time 0.082 (0.085)	Data 0.001 (0.007)	Loss 3.0152 (2.8878)	Acc@1 21.875 (25.756)	Acc@5 53.906 (57.132)
Epoch: [7][40/391]	Time 0.082 (0.085)	Data 0.001 (0.006)	Loss 2.9261 (2.8953)	Acc@1 25.781 (25.610)	Acc@5 60.156 (57.317)
Epoch: [7][50/391]	Time 0.083 (0.085)	Data 0.001 (0.005)	Loss 2.7140 (2.9055)	Acc@1 29.688 (25.061)	Acc@5 65.625 (57.430)
Epoch: [7][60/391]	Time 0.087 (0.084)	Data 0.001 (0.004)	Loss 2.8128 (2.9136)	Acc@1 24.219 (24.769)	Acc@5 60.156 (57.339)
Epoch: [7][70/391]	Time 0.086 (0.084)	Data 0.001 (0.004)	Loss 2.8071 (2.9134)	Acc@1 24.219 (24.802)	Acc@5 58.594 (57.350)
Epoch: [7][80/391]	Time 0.080 (0.084)	Data 0.001 (0.003)	Loss 2.7002 (2.9136)	Acc@1 30.469 (24.730)	Acc@5 64.062 (57.282)
Epoch: [7][90/391]	Time 0.084 (0.084)	Data 0.001 (0.003)	Loss 3.0196 (2.9139)	Acc@1 21.875 (24.708)	Acc@5 53.125 (57.229)
Epoch: [7][100/391]	Time 0.085 (0.084)	Data 0.001 (0.003)	Loss 3.0497 (2.9187)	Acc@1 23.438 (24.536)	Acc@5 54.688 (57.101)
Epoch: [7][110/391]	Time 0.084 (0.084)	Data 0.001 (0.003)	Loss 2.9991 (2.9257)	Acc@1 21.875 (24.345)	Acc@5 57.031 (57.003)
Epoch: [7][120/391]	Time 0.083 (0.084)	Data 0.001 (0.003)	Loss 2.7440 (2.9281)	Acc@1 32.812 (24.432)	Acc@5 61.719 (57.005)
Epoch: [7][130/391]	Time 0.082 (0.084)	Data 0.001 (0.003)	Loss 3.0635 (2.9287)	Acc@1 24.219 (24.487)	Acc@5 46.875 (56.972)
Epoch: [7][140/391]	Time 0.084 (0.084)	Data 0.001 (0.003)	Loss 2.9806 (2.9252)	Acc@1 22.656 (24.590)	Acc@5 52.344 (56.970)
Epoch: [7][150/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.9798 (2.9299)	Acc@1 23.438 (24.555)	Acc@5 58.594 (56.835)
Epoch: [7][160/391]	Time 0.083 (0.084)	Data 0.002 (0.002)	Loss 2.8226 (2.9285)	Acc@1 24.219 (24.505)	Acc@5 58.594 (56.929)
Epoch: [7][170/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.7230 (2.9254)	Acc@1 30.469 (24.648)	Acc@5 60.938 (57.031)
Epoch: [7][180/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.8237 (2.9227)	Acc@1 28.125 (24.624)	Acc@5 57.812 (57.070)
Epoch: [7][190/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.8457 (2.9243)	Acc@1 27.344 (24.583)	Acc@5 55.469 (56.982)
Epoch: [7][200/391]	Time 0.087 (0.084)	Data 0.001 (0.002)	Loss 2.9625 (2.9275)	Acc@1 25.781 (24.545)	Acc@5 47.656 (56.895)
Epoch: [7][210/391]	Time 0.087 (0.084)	Data 0.001 (0.002)	Loss 2.8735 (2.9266)	Acc@1 22.656 (24.478)	Acc@5 57.031 (56.950)
Epoch: [7][220/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 3.0240 (2.9283)	Acc@1 23.438 (24.463)	Acc@5 53.125 (56.908)
Epoch: [7][230/391]	Time 0.080 (0.084)	Data 0.001 (0.002)	Loss 3.0282 (2.9280)	Acc@1 25.781 (24.395)	Acc@5 56.250 (56.923)
Epoch: [7][240/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 3.0077 (2.9292)	Acc@1 17.969 (24.423)	Acc@5 52.344 (56.928)
Epoch: [7][250/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 3.1057 (2.9266)	Acc@1 24.219 (24.462)	Acc@5 52.344 (56.919)
Epoch: [7][260/391]	Time 0.089 (0.084)	Data 0.001 (0.002)	Loss 2.7355 (2.9250)	Acc@1 26.562 (24.503)	Acc@5 64.844 (56.953)
Epoch: [7][270/391]	Time 0.080 (0.084)	Data 0.001 (0.002)	Loss 2.9880 (2.9220)	Acc@1 25.781 (24.556)	Acc@5 56.250 (57.054)
Epoch: [7][280/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.8008 (2.9188)	Acc@1 25.781 (24.614)	Acc@5 60.156 (57.142)
Epoch: [7][290/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.8985 (2.9149)	Acc@1 25.781 (24.729)	Acc@5 60.156 (57.257)
Epoch: [7][300/391]	Time 0.083 (0.084)	Data 0.002 (0.002)	Loss 2.8211 (2.9131)	Acc@1 26.562 (24.756)	Acc@5 57.812 (57.340)
Epoch: [7][310/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.9111 (2.9126)	Acc@1 25.000 (24.759)	Acc@5 55.469 (57.325)
Epoch: [7][320/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.5674 (2.9115)	Acc@1 29.688 (24.793)	Acc@5 64.062 (57.357)
Epoch: [7][330/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.9799 (2.9120)	Acc@1 20.312 (24.698)	Acc@5 55.469 (57.366)
Epoch: [7][340/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.8945 (2.9115)	Acc@1 23.438 (24.757)	Acc@5 57.812 (57.377)
Epoch: [7][350/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.7920 (2.9134)	Acc@1 28.125 (24.711)	Acc@5 62.500 (57.314)
Epoch: [7][360/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 3.0289 (2.9130)	Acc@1 25.000 (24.742)	Acc@5 57.031 (57.378)
Epoch: [7][370/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.9677 (2.9142)	Acc@1 18.750 (24.693)	Acc@5 55.469 (57.339)
Epoch: [7][380/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.8932 (2.9126)	Acc@1 32.031 (24.781)	Acc@5 59.375 (57.368)
Epoch: [7][390/391]	Time 0.070 (0.084)	Data 0.001 (0.002)	Loss 2.7811 (2.9110)	Acc@1 30.000 (24.828)	Acc@5 63.750 (57.386)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [8][0/391]	Time 0.096 (0.096)	Data 0.171 (0.171)	Loss 2.9200 (2.9200)	Acc@1 24.219 (24.219)	Acc@5 54.688 (54.688)
Epoch: [8][10/391]	Time 0.081 (0.084)	Data 0.001 (0.016)	Loss 2.6545 (2.8243)	Acc@1 30.469 (26.705)	Acc@5 65.625 (58.878)
Epoch: [8][20/391]	Time 0.080 (0.084)	Data 0.001 (0.009)	Loss 3.2523 (2.8692)	Acc@1 21.875 (26.972)	Acc@5 50.000 (59.226)
Epoch: [8][30/391]	Time 0.086 (0.083)	Data 0.001 (0.007)	Loss 2.7461 (2.8685)	Acc@1 23.438 (26.285)	Acc@5 57.812 (58.821)
Epoch: [8][40/391]	Time 0.081 (0.083)	Data 0.001 (0.005)	Loss 2.7410 (2.8664)	Acc@1 26.562 (26.124)	Acc@5 57.812 (58.460)
Epoch: [8][50/391]	Time 0.079 (0.082)	Data 0.001 (0.004)	Loss 2.8937 (2.8553)	Acc@1 24.219 (26.271)	Acc@5 60.156 (58.747)
Epoch: [8][60/391]	Time 0.080 (0.082)	Data 0.001 (0.004)	Loss 2.8995 (2.8552)	Acc@1 28.125 (26.358)	Acc@5 53.906 (58.747)
Epoch: [8][70/391]	Time 0.082 (0.082)	Data 0.001 (0.004)	Loss 3.0626 (2.8655)	Acc@1 22.656 (26.166)	Acc@5 53.125 (58.528)
Epoch: [8][80/391]	Time 0.080 (0.082)	Data 0.001 (0.003)	Loss 2.9218 (2.8652)	Acc@1 21.875 (26.109)	Acc@5 62.500 (58.748)
Epoch: [8][90/391]	Time 0.086 (0.082)	Data 0.001 (0.003)	Loss 2.6641 (2.8607)	Acc@1 29.688 (26.262)	Acc@5 66.406 (58.783)
Epoch: [8][100/391]	Time 0.082 (0.082)	Data 0.001 (0.003)	Loss 2.7873 (2.8573)	Acc@1 24.219 (26.199)	Acc@5 60.938 (58.826)
Epoch: [8][110/391]	Time 0.080 (0.082)	Data 0.001 (0.003)	Loss 2.6339 (2.8563)	Acc@1 30.469 (26.253)	Acc@5 63.281 (58.784)
Epoch: [8][120/391]	Time 0.083 (0.082)	Data 0.001 (0.003)	Loss 2.9588 (2.8500)	Acc@1 25.000 (26.317)	Acc@5 56.250 (58.994)
Epoch: [8][130/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.7311 (2.8480)	Acc@1 21.875 (26.181)	Acc@5 63.281 (59.059)
Epoch: [8][140/391]	Time 0.087 (0.082)	Data 0.001 (0.002)	Loss 2.7397 (2.8502)	Acc@1 31.250 (26.136)	Acc@5 60.938 (58.959)
Epoch: [8][150/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 3.1846 (2.8489)	Acc@1 19.531 (26.149)	Acc@5 47.656 (58.946)
Epoch: [8][160/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.8208 (2.8532)	Acc@1 29.688 (26.184)	Acc@5 54.688 (58.798)
Epoch: [8][170/391]	Time 0.086 (0.082)	Data 0.001 (0.002)	Loss 2.6932 (2.8534)	Acc@1 31.250 (26.156)	Acc@5 63.281 (58.722)
Epoch: [8][180/391]	Time 0.077 (0.082)	Data 0.001 (0.002)	Loss 2.8716 (2.8507)	Acc@1 28.906 (26.226)	Acc@5 61.719 (58.805)
Epoch: [8][190/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.8427 (2.8502)	Acc@1 28.125 (26.223)	Acc@5 57.031 (58.831)
Epoch: [8][200/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 2.7002 (2.8517)	Acc@1 31.250 (26.182)	Acc@5 59.375 (58.765)
Epoch: [8][210/391]	Time 0.079 (0.082)	Data 0.001 (0.002)	Loss 2.7293 (2.8506)	Acc@1 30.469 (26.192)	Acc@5 60.156 (58.753)
Epoch: [8][220/391]	Time 0.077 (0.082)	Data 0.001 (0.002)	Loss 2.8172 (2.8488)	Acc@1 26.562 (26.220)	Acc@5 59.375 (58.806)
Epoch: [8][230/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 2.7813 (2.8431)	Acc@1 24.219 (26.295)	Acc@5 59.375 (58.966)
Epoch: [8][240/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 3.0161 (2.8455)	Acc@1 25.781 (26.264)	Acc@5 54.688 (58.882)
Epoch: [8][250/391]	Time 0.082 (0.082)	Data 0.001 (0.002)	Loss 2.7880 (2.8452)	Acc@1 30.469 (26.329)	Acc@5 60.938 (58.880)
Epoch: [8][260/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.6193 (2.8436)	Acc@1 34.375 (26.392)	Acc@5 64.062 (58.923)
Epoch: [8][270/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 2.6388 (2.8394)	Acc@1 30.469 (26.467)	Acc@5 66.406 (59.069)
Epoch: [8][280/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 2.7738 (2.8360)	Acc@1 26.562 (26.549)	Acc@5 59.375 (59.153)
Epoch: [8][290/391]	Time 0.079 (0.082)	Data 0.001 (0.002)	Loss 2.7983 (2.8342)	Acc@1 27.344 (26.517)	Acc@5 56.250 (59.225)
Epoch: [8][300/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.7296 (2.8323)	Acc@1 24.219 (26.518)	Acc@5 64.062 (59.289)
Epoch: [8][310/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.8663 (2.8339)	Acc@1 24.219 (26.527)	Acc@5 59.375 (59.285)
Epoch: [8][320/391]	Time 0.079 (0.082)	Data 0.001 (0.002)	Loss 2.9841 (2.8348)	Acc@1 17.969 (26.448)	Acc@5 54.688 (59.253)
Epoch: [8][330/391]	Time 0.082 (0.082)	Data 0.001 (0.002)	Loss 2.7980 (2.8347)	Acc@1 28.906 (26.461)	Acc@5 57.031 (59.248)
Epoch: [8][340/391]	Time 0.079 (0.082)	Data 0.001 (0.002)	Loss 2.6776 (2.8351)	Acc@1 28.906 (26.478)	Acc@5 61.719 (59.244)
Epoch: [8][350/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.7446 (2.8325)	Acc@1 28.125 (26.520)	Acc@5 59.375 (59.330)
Epoch: [8][360/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.7102 (2.8324)	Acc@1 27.344 (26.545)	Acc@5 62.500 (59.321)
Epoch: [8][370/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 2.9993 (2.8324)	Acc@1 28.125 (26.575)	Acc@5 57.031 (59.301)
Epoch: [8][380/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.9019 (2.8336)	Acc@1 21.094 (26.581)	Acc@5 57.031 (59.291)
Epoch: [8][390/391]	Time 0.068 (0.081)	Data 0.001 (0.002)	Loss 2.4916 (2.8325)	Acc@1 27.500 (26.554)	Acc@5 70.000 (59.318)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [9][0/391]	Time 0.097 (0.097)	Data 0.179 (0.179)	Loss 2.8328 (2.8328)	Acc@1 31.250 (31.250)	Acc@5 58.594 (58.594)
Epoch: [9][10/391]	Time 0.087 (0.086)	Data 0.001 (0.017)	Loss 2.7117 (2.7328)	Acc@1 28.125 (28.409)	Acc@5 63.281 (62.287)
Epoch: [9][20/391]	Time 0.085 (0.086)	Data 0.001 (0.010)	Loss 2.7958 (2.7354)	Acc@1 25.000 (27.604)	Acc@5 60.938 (62.091)
Epoch: [9][30/391]	Time 0.084 (0.086)	Data 0.001 (0.007)	Loss 2.9275 (2.7480)	Acc@1 25.781 (27.671)	Acc@5 54.688 (61.492)
Epoch: [9][40/391]	Time 0.086 (0.085)	Data 0.001 (0.006)	Loss 2.7583 (2.7475)	Acc@1 27.344 (27.496)	Acc@5 59.375 (61.376)
Epoch: [9][50/391]	Time 0.085 (0.085)	Data 0.001 (0.005)	Loss 2.7483 (2.7449)	Acc@1 25.000 (27.681)	Acc@5 61.719 (61.428)
Epoch: [9][60/391]	Time 0.081 (0.086)	Data 0.001 (0.004)	Loss 2.7295 (2.7530)	Acc@1 28.125 (27.792)	Acc@5 63.281 (61.258)
Epoch: [9][70/391]	Time 0.083 (0.086)	Data 0.001 (0.004)	Loss 2.7238 (2.7431)	Acc@1 25.000 (27.883)	Acc@5 64.062 (61.543)
Epoch: [9][80/391]	Time 0.084 (0.086)	Data 0.001 (0.003)	Loss 2.6698 (2.7403)	Acc@1 31.250 (28.029)	Acc@5 59.375 (61.632)
Epoch: [9][90/391]	Time 0.086 (0.086)	Data 0.002 (0.003)	Loss 2.5323 (2.7389)	Acc@1 35.156 (28.185)	Acc@5 65.625 (61.702)
Epoch: [9][100/391]	Time 0.083 (0.085)	Data 0.001 (0.003)	Loss 2.8405 (2.7448)	Acc@1 25.000 (28.179)	Acc@5 61.719 (61.572)
Epoch: [9][110/391]	Time 0.098 (0.086)	Data 0.002 (0.003)	Loss 2.7131 (2.7462)	Acc@1 30.469 (28.055)	Acc@5 64.844 (61.754)
Epoch: [9][120/391]	Time 0.083 (0.085)	Data 0.001 (0.003)	Loss 2.5977 (2.7472)	Acc@1 29.688 (28.093)	Acc@5 67.188 (61.719)
Epoch: [9][130/391]	Time 0.081 (0.085)	Data 0.001 (0.003)	Loss 2.9488 (2.7547)	Acc@1 23.438 (27.904)	Acc@5 59.375 (61.516)
Epoch: [9][140/391]	Time 0.084 (0.085)	Data 0.001 (0.003)	Loss 2.9437 (2.7556)	Acc@1 21.094 (27.981)	Acc@5 60.938 (61.630)
Epoch: [9][150/391]	Time 0.087 (0.085)	Data 0.001 (0.002)	Loss 2.7455 (2.7571)	Acc@1 27.344 (27.913)	Acc@5 64.062 (61.677)
Epoch: [9][160/391]	Time 0.085 (0.085)	Data 0.001 (0.002)	Loss 2.4799 (2.7564)	Acc@1 32.812 (27.907)	Acc@5 67.969 (61.699)
Epoch: [9][170/391]	Time 0.083 (0.085)	Data 0.002 (0.002)	Loss 2.6772 (2.7567)	Acc@1 31.250 (27.993)	Acc@5 60.156 (61.623)
Epoch: [9][180/391]	Time 0.083 (0.085)	Data 0.002 (0.002)	Loss 2.6980 (2.7542)	Acc@1 33.594 (28.043)	Acc@5 64.844 (61.619)
Epoch: [9][190/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.7299 (2.7525)	Acc@1 30.469 (28.100)	Acc@5 61.719 (61.682)
Epoch: [9][200/391]	Time 0.082 (0.085)	Data 0.001 (0.002)	Loss 2.8538 (2.7537)	Acc@1 27.344 (28.129)	Acc@5 59.375 (61.660)
Epoch: [9][210/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.8472 (2.7541)	Acc@1 23.438 (28.073)	Acc@5 58.594 (61.708)
Epoch: [9][220/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.5816 (2.7520)	Acc@1 30.469 (28.118)	Acc@5 66.406 (61.761)
Epoch: [9][230/391]	Time 0.086 (0.085)	Data 0.001 (0.002)	Loss 2.6431 (2.7537)	Acc@1 27.344 (28.084)	Acc@5 67.188 (61.736)
Epoch: [9][240/391]	Time 0.085 (0.085)	Data 0.001 (0.002)	Loss 2.7445 (2.7553)	Acc@1 32.812 (28.073)	Acc@5 54.688 (61.716)
Epoch: [9][250/391]	Time 0.088 (0.085)	Data 0.001 (0.002)	Loss 2.9064 (2.7566)	Acc@1 23.438 (28.075)	Acc@5 55.469 (61.703)
Epoch: [9][260/391]	Time 0.086 (0.085)	Data 0.002 (0.002)	Loss 2.7623 (2.7575)	Acc@1 31.250 (28.065)	Acc@5 62.500 (61.629)
Epoch: [9][270/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.5000 (2.7582)	Acc@1 31.250 (28.015)	Acc@5 71.875 (61.598)
Epoch: [9][280/391]	Time 0.085 (0.085)	Data 0.001 (0.002)	Loss 2.7324 (2.7594)	Acc@1 20.312 (27.955)	Acc@5 60.938 (61.549)
Epoch: [9][290/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.6908 (2.7584)	Acc@1 32.812 (27.961)	Acc@5 63.281 (61.560)
Epoch: [9][300/391]	Time 0.086 (0.085)	Data 0.001 (0.002)	Loss 2.7907 (2.7553)	Acc@1 28.125 (28.026)	Acc@5 63.281 (61.654)
Epoch: [9][310/391]	Time 0.086 (0.085)	Data 0.002 (0.002)	Loss 2.4457 (2.7534)	Acc@1 35.156 (28.047)	Acc@5 69.531 (61.663)
Epoch: [9][320/391]	Time 0.085 (0.085)	Data 0.001 (0.002)	Loss 2.6285 (2.7518)	Acc@1 33.594 (28.067)	Acc@5 64.062 (61.697)
Epoch: [9][330/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.8247 (2.7529)	Acc@1 27.344 (28.028)	Acc@5 58.594 (61.631)
Epoch: [9][340/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.8686 (2.7524)	Acc@1 26.562 (28.059)	Acc@5 56.250 (61.673)
Epoch: [9][350/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.9071 (2.7544)	Acc@1 27.344 (28.036)	Acc@5 55.469 (61.581)
Epoch: [9][360/391]	Time 0.092 (0.085)	Data 0.001 (0.002)	Loss 2.3445 (2.7535)	Acc@1 35.938 (28.073)	Acc@5 75.000 (61.593)
Epoch: [9][370/391]	Time 0.086 (0.085)	Data 0.001 (0.002)	Loss 2.6921 (2.7534)	Acc@1 27.344 (28.114)	Acc@5 60.938 (61.571)
Epoch: [9][380/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.6814 (2.7540)	Acc@1 26.562 (28.076)	Acc@5 65.625 (61.526)
Epoch: [9][390/391]	Time 0.071 (0.085)	Data 0.001 (0.002)	Loss 2.7355 (2.7551)	Acc@1 30.000 (28.110)	Acc@5 60.000 (61.500)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [10][0/391]	Time 0.090 (0.090)	Data 0.169 (0.169)	Loss 2.8335 (2.8335)	Acc@1 26.562 (26.562)	Acc@5 61.719 (61.719)
Epoch: [10][10/391]	Time 0.084 (0.082)	Data 0.001 (0.016)	Loss 2.7475 (2.7517)	Acc@1 29.688 (29.403)	Acc@5 63.281 (61.648)
Epoch: [10][20/391]	Time 0.079 (0.081)	Data 0.001 (0.009)	Loss 2.4041 (2.7095)	Acc@1 32.812 (29.688)	Acc@5 68.750 (62.388)
Epoch: [10][30/391]	Time 0.081 (0.081)	Data 0.001 (0.007)	Loss 2.7684 (2.7018)	Acc@1 28.906 (29.360)	Acc@5 61.719 (62.802)
Epoch: [10][40/391]	Time 0.078 (0.081)	Data 0.001 (0.005)	Loss 2.8471 (2.7257)	Acc@1 26.562 (28.735)	Acc@5 59.375 (61.966)
Epoch: [10][50/391]	Time 0.080 (0.081)	Data 0.001 (0.004)	Loss 2.4869 (2.7085)	Acc@1 28.906 (28.814)	Acc@5 67.188 (62.316)
Epoch: [10][60/391]	Time 0.081 (0.081)	Data 0.001 (0.004)	Loss 2.6591 (2.7096)	Acc@1 32.031 (28.689)	Acc@5 62.500 (62.474)
Epoch: [10][70/391]	Time 0.084 (0.080)	Data 0.001 (0.004)	Loss 2.5603 (2.7030)	Acc@1 25.781 (28.785)	Acc@5 65.625 (62.698)
Epoch: [10][80/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.8455 (2.7095)	Acc@1 30.469 (28.829)	Acc@5 58.594 (62.490)
Epoch: [10][90/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 2.7974 (2.7099)	Acc@1 27.344 (28.812)	Acc@5 59.375 (62.320)
Epoch: [10][100/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 2.8075 (2.7215)	Acc@1 28.906 (28.574)	Acc@5 61.719 (62.013)
Epoch: [10][110/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 2.7620 (2.7218)	Acc@1 29.688 (28.646)	Acc@5 60.156 (62.021)
Epoch: [10][120/391]	Time 0.083 (0.081)	Data 0.001 (0.003)	Loss 2.5324 (2.7243)	Acc@1 33.594 (28.700)	Acc@5 60.938 (61.971)
Epoch: [10][130/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8305 (2.7234)	Acc@1 21.094 (28.674)	Acc@5 60.938 (62.094)
Epoch: [10][140/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4483 (2.7190)	Acc@1 38.281 (28.679)	Acc@5 70.312 (62.212)
Epoch: [10][150/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.6071 (2.7206)	Acc@1 32.812 (28.591)	Acc@5 65.625 (62.200)
Epoch: [10][160/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.8945 (2.7242)	Acc@1 24.219 (28.562)	Acc@5 58.594 (62.097)
Epoch: [10][170/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.8320 (2.7229)	Acc@1 26.562 (28.573)	Acc@5 55.469 (62.007)
Epoch: [10][180/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6364 (2.7209)	Acc@1 34.375 (28.587)	Acc@5 61.719 (62.090)
Epoch: [10][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6805 (2.7258)	Acc@1 25.781 (28.514)	Acc@5 63.281 (62.030)
Epoch: [10][200/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 2.7535 (2.7259)	Acc@1 30.469 (28.483)	Acc@5 60.156 (62.030)
Epoch: [10][210/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.7374 (2.7263)	Acc@1 29.688 (28.514)	Acc@5 63.281 (62.089)
Epoch: [10][220/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8134 (2.7240)	Acc@1 25.781 (28.581)	Acc@5 58.594 (62.139)
Epoch: [10][230/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.6619 (2.7223)	Acc@1 32.812 (28.619)	Acc@5 61.719 (62.216)
Epoch: [10][240/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.6933 (2.7252)	Acc@1 27.344 (28.585)	Acc@5 57.031 (62.085)
Epoch: [10][250/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.7006 (2.7252)	Acc@1 32.812 (28.614)	Acc@5 58.594 (62.074)
Epoch: [10][260/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6851 (2.7268)	Acc@1 33.594 (28.604)	Acc@5 60.938 (62.054)
Epoch: [10][270/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.9271 (2.7281)	Acc@1 21.875 (28.580)	Acc@5 60.156 (62.096)
Epoch: [10][280/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.5179 (2.7302)	Acc@1 32.812 (28.556)	Acc@5 67.188 (62.055)
Epoch: [10][290/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.6515 (2.7292)	Acc@1 25.781 (28.573)	Acc@5 63.281 (62.103)
Epoch: [10][300/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 2.7343 (2.7261)	Acc@1 28.906 (28.644)	Acc@5 62.500 (62.217)
Epoch: [10][310/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.6602 (2.7254)	Acc@1 30.469 (28.602)	Acc@5 63.281 (62.259)
Epoch: [10][320/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8445 (2.7261)	Acc@1 27.344 (28.668)	Acc@5 52.344 (62.213)
Epoch: [10][330/391]	Time 0.087 (0.081)	Data 0.001 (0.002)	Loss 2.6503 (2.7258)	Acc@1 28.125 (28.654)	Acc@5 66.406 (62.226)
Epoch: [10][340/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5879 (2.7251)	Acc@1 37.500 (28.675)	Acc@5 62.500 (62.214)
Epoch: [10][350/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.8571 (2.7244)	Acc@1 25.781 (28.648)	Acc@5 57.031 (62.179)
Epoch: [10][360/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5166 (2.7240)	Acc@1 29.688 (28.681)	Acc@5 71.094 (62.204)
Epoch: [10][370/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.6725 (2.7239)	Acc@1 28.125 (28.715)	Acc@5 66.406 (62.220)
Epoch: [10][380/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.7406 (2.7232)	Acc@1 37.500 (28.744)	Acc@5 60.156 (62.256)
Epoch: [10][390/391]	Time 0.066 (0.081)	Data 0.001 (0.002)	Loss 2.5413 (2.7216)	Acc@1 32.500 (28.778)	Acc@5 65.000 (62.304)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [11][0/391]	Time 0.091 (0.091)	Data 0.171 (0.171)	Loss 2.7390 (2.7390)	Acc@1 21.875 (21.875)	Acc@5 63.281 (63.281)
Epoch: [11][10/391]	Time 0.081 (0.083)	Data 0.001 (0.016)	Loss 2.6880 (2.6481)	Acc@1 28.125 (29.403)	Acc@5 64.844 (65.341)
Epoch: [11][20/391]	Time 0.082 (0.083)	Data 0.001 (0.009)	Loss 2.4171 (2.6512)	Acc@1 35.156 (29.353)	Acc@5 70.312 (65.104)
Epoch: [11][30/391]	Time 0.087 (0.083)	Data 0.001 (0.007)	Loss 2.8077 (2.6833)	Acc@1 22.656 (29.209)	Acc@5 58.594 (63.936)
Epoch: [11][40/391]	Time 0.081 (0.082)	Data 0.001 (0.005)	Loss 2.6839 (2.6828)	Acc@1 23.438 (28.716)	Acc@5 64.844 (63.834)
Epoch: [11][50/391]	Time 0.085 (0.082)	Data 0.001 (0.004)	Loss 2.7603 (2.6689)	Acc@1 25.781 (28.998)	Acc@5 62.500 (64.369)
Epoch: [11][60/391]	Time 0.084 (0.082)	Data 0.001 (0.004)	Loss 2.8389 (2.6717)	Acc@1 20.312 (29.047)	Acc@5 59.375 (63.973)
Epoch: [11][70/391]	Time 0.081 (0.082)	Data 0.001 (0.004)	Loss 2.7773 (2.6717)	Acc@1 25.000 (29.203)	Acc@5 64.062 (63.710)
Epoch: [11][80/391]	Time 0.084 (0.082)	Data 0.001 (0.003)	Loss 2.8126 (2.6701)	Acc@1 25.781 (29.138)	Acc@5 58.594 (63.773)
Epoch: [11][90/391]	Time 0.082 (0.082)	Data 0.001 (0.003)	Loss 2.6219 (2.6703)	Acc@1 32.031 (29.232)	Acc@5 65.625 (63.736)
Epoch: [11][100/391]	Time 0.079 (0.082)	Data 0.001 (0.003)	Loss 2.5767 (2.6731)	Acc@1 31.250 (29.278)	Acc@5 67.188 (63.714)
Epoch: [11][110/391]	Time 0.079 (0.082)	Data 0.001 (0.003)	Loss 2.7723 (2.6682)	Acc@1 25.781 (29.385)	Acc@5 57.812 (63.704)
Epoch: [11][120/391]	Time 0.081 (0.082)	Data 0.001 (0.003)	Loss 2.7405 (2.6712)	Acc@1 28.125 (29.287)	Acc@5 65.625 (63.740)
Epoch: [11][130/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 2.4732 (2.6708)	Acc@1 35.156 (29.371)	Acc@5 67.188 (63.693)
Epoch: [11][140/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.8452 (2.6756)	Acc@1 28.125 (29.372)	Acc@5 57.812 (63.592)
Epoch: [11][150/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.4611 (2.6739)	Acc@1 29.688 (29.393)	Acc@5 62.500 (63.571)
Epoch: [11][160/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 2.6694 (2.6727)	Acc@1 27.344 (29.561)	Acc@5 63.281 (63.534)
Epoch: [11][170/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.8081 (2.6720)	Acc@1 25.781 (29.651)	Acc@5 61.719 (63.551)
Epoch: [11][180/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6884 (2.6739)	Acc@1 29.688 (29.631)	Acc@5 66.406 (63.553)
Epoch: [11][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4349 (2.6711)	Acc@1 29.688 (29.638)	Acc@5 72.656 (63.670)
Epoch: [11][200/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.6585 (2.6705)	Acc@1 30.469 (29.668)	Acc@5 60.156 (63.709)
Epoch: [11][210/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.8167 (2.6711)	Acc@1 26.562 (29.639)	Acc@5 60.156 (63.648)
Epoch: [11][220/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 2.7220 (2.6711)	Acc@1 33.594 (29.659)	Acc@5 60.156 (63.681)
Epoch: [11][230/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.5934 (2.6742)	Acc@1 26.562 (29.664)	Acc@5 67.188 (63.647)
Epoch: [11][240/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.5052 (2.6713)	Acc@1 31.250 (29.678)	Acc@5 70.312 (63.738)
Epoch: [11][250/391]	Time 0.082 (0.082)	Data 0.001 (0.002)	Loss 2.6041 (2.6726)	Acc@1 29.688 (29.663)	Acc@5 67.188 (63.751)
Epoch: [11][260/391]	Time 0.085 (0.082)	Data 0.001 (0.002)	Loss 2.6727 (2.6732)	Acc@1 32.812 (29.708)	Acc@5 60.938 (63.724)
Epoch: [11][270/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.7187 (2.6729)	Acc@1 32.031 (29.705)	Acc@5 61.719 (63.719)
Epoch: [11][280/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 2.6281 (2.6723)	Acc@1 32.031 (29.713)	Acc@5 63.281 (63.693)
Epoch: [11][290/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 2.7313 (2.6723)	Acc@1 26.562 (29.720)	Acc@5 60.938 (63.679)
Epoch: [11][300/391]	Time 0.091 (0.082)	Data 0.002 (0.002)	Loss 2.4305 (2.6687)	Acc@1 33.594 (29.771)	Acc@5 71.875 (63.774)
Epoch: [11][310/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 2.5626 (2.6699)	Acc@1 25.000 (29.725)	Acc@5 67.969 (63.716)
Epoch: [11][320/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 2.4795 (2.6661)	Acc@1 33.594 (29.821)	Acc@5 67.969 (63.822)
Epoch: [11][330/391]	Time 0.080 (0.082)	Data 0.001 (0.002)	Loss 2.9576 (2.6680)	Acc@1 24.219 (29.772)	Acc@5 56.250 (63.749)
Epoch: [11][340/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 2.4791 (2.6678)	Acc@1 35.156 (29.742)	Acc@5 67.969 (63.739)
Epoch: [11][350/391]	Time 0.082 (0.082)	Data 0.001 (0.002)	Loss 2.6397 (2.6680)	Acc@1 33.594 (29.765)	Acc@5 70.312 (63.731)
Epoch: [11][360/391]	Time 0.083 (0.082)	Data 0.001 (0.002)	Loss 2.5786 (2.6671)	Acc@1 28.125 (29.783)	Acc@5 68.750 (63.757)
Epoch: [11][370/391]	Time 0.081 (0.082)	Data 0.001 (0.002)	Loss 2.7288 (2.6680)	Acc@1 32.812 (29.765)	Acc@5 60.938 (63.715)
Epoch: [11][380/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 2.7365 (2.6688)	Acc@1 34.375 (29.743)	Acc@5 59.375 (63.667)
Epoch: [11][390/391]	Time 0.067 (0.081)	Data 0.001 (0.002)	Loss 2.4492 (2.6694)	Acc@1 28.750 (29.700)	Acc@5 71.250 (63.642)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [12][0/391]	Time 0.089 (0.089)	Data 0.163 (0.163)	Loss 2.6525 (2.6525)	Acc@1 30.469 (30.469)	Acc@5 65.625 (65.625)
Epoch: [12][10/391]	Time 0.081 (0.082)	Data 0.001 (0.016)	Loss 2.5298 (2.6244)	Acc@1 25.000 (30.256)	Acc@5 67.188 (65.128)
Epoch: [12][20/391]	Time 0.079 (0.081)	Data 0.001 (0.009)	Loss 2.7523 (2.6278)	Acc@1 31.250 (30.246)	Acc@5 64.844 (64.769)
Epoch: [12][30/391]	Time 0.080 (0.081)	Data 0.001 (0.006)	Loss 2.7051 (2.6089)	Acc@1 28.906 (30.393)	Acc@5 65.625 (64.667)
Epoch: [12][40/391]	Time 0.081 (0.081)	Data 0.001 (0.005)	Loss 2.5150 (2.6044)	Acc@1 38.281 (30.412)	Acc@5 63.281 (64.444)
Epoch: [12][50/391]	Time 0.079 (0.080)	Data 0.001 (0.004)	Loss 2.6315 (2.6148)	Acc@1 32.812 (30.132)	Acc@5 63.281 (64.231)
Epoch: [12][60/391]	Time 0.079 (0.080)	Data 0.001 (0.004)	Loss 2.2623 (2.6109)	Acc@1 35.938 (30.200)	Acc@5 75.781 (64.395)
Epoch: [12][70/391]	Time 0.078 (0.080)	Data 0.001 (0.003)	Loss 2.4973 (2.6116)	Acc@1 31.250 (30.205)	Acc@5 67.188 (64.536)
Epoch: [12][80/391]	Time 0.082 (0.080)	Data 0.001 (0.003)	Loss 2.6819 (2.6114)	Acc@1 30.469 (30.421)	Acc@5 61.719 (64.448)
Epoch: [12][90/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 2.7683 (2.6108)	Acc@1 27.344 (30.391)	Acc@5 57.812 (64.509)
Epoch: [12][100/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 2.8714 (2.6176)	Acc@1 28.906 (30.206)	Acc@5 62.500 (64.318)
Epoch: [12][110/391]	Time 0.080 (0.080)	Data 0.001 (0.003)	Loss 2.5103 (2.6158)	Acc@1 32.812 (30.314)	Acc@5 67.969 (64.555)
Epoch: [12][120/391]	Time 0.083 (0.080)	Data 0.001 (0.002)	Loss 2.4332 (2.6136)	Acc@1 35.938 (30.359)	Acc@5 68.750 (64.715)
Epoch: [12][130/391]	Time 0.078 (0.080)	Data 0.001 (0.002)	Loss 2.7323 (2.6192)	Acc@1 28.125 (30.248)	Acc@5 61.719 (64.635)
Epoch: [12][140/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.7701 (2.6206)	Acc@1 27.344 (30.314)	Acc@5 57.812 (64.506)
Epoch: [12][150/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4807 (2.6181)	Acc@1 38.281 (30.298)	Acc@5 65.625 (64.663)
Epoch: [12][160/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.8623 (2.6155)	Acc@1 28.906 (30.430)	Acc@5 57.812 (64.713)
Epoch: [12][170/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.6119 (2.6203)	Acc@1 32.031 (30.418)	Acc@5 70.312 (64.643)
Epoch: [12][180/391]	Time 0.078 (0.080)	Data 0.001 (0.002)	Loss 2.9277 (2.6278)	Acc@1 25.781 (30.374)	Acc@5 60.156 (64.503)
Epoch: [12][190/391]	Time 0.079 (0.080)	Data 0.001 (0.002)	Loss 2.6564 (2.6285)	Acc@1 29.688 (30.350)	Acc@5 63.281 (64.484)
Epoch: [12][200/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.5871 (2.6277)	Acc@1 33.594 (30.368)	Acc@5 66.406 (64.509)
Epoch: [12][210/391]	Time 0.076 (0.080)	Data 0.001 (0.002)	Loss 2.6674 (2.6299)	Acc@1 33.594 (30.417)	Acc@5 64.844 (64.396)
Epoch: [12][220/391]	Time 0.079 (0.080)	Data 0.001 (0.002)	Loss 2.3958 (2.6272)	Acc@1 35.938 (30.490)	Acc@5 69.531 (64.515)
Epoch: [12][230/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.6849 (2.6268)	Acc@1 32.812 (30.560)	Acc@5 63.281 (64.499)
Epoch: [12][240/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.6538 (2.6258)	Acc@1 28.906 (30.547)	Acc@5 64.844 (64.539)
Epoch: [12][250/391]	Time 0.083 (0.080)	Data 0.001 (0.002)	Loss 2.8145 (2.6281)	Acc@1 17.969 (30.459)	Acc@5 60.938 (64.495)
Epoch: [12][260/391]	Time 0.078 (0.080)	Data 0.001 (0.002)	Loss 2.4807 (2.6271)	Acc@1 33.594 (30.475)	Acc@5 67.969 (64.509)
Epoch: [12][270/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.5300 (2.6254)	Acc@1 28.125 (30.483)	Acc@5 67.188 (64.573)
Epoch: [12][280/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.5669 (2.6212)	Acc@1 32.031 (30.524)	Acc@5 71.094 (64.702)
Epoch: [12][290/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.5409 (2.6237)	Acc@1 35.156 (30.420)	Acc@5 64.844 (64.675)
Epoch: [12][300/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.6169 (2.6243)	Acc@1 27.344 (30.427)	Acc@5 65.625 (64.683)
Epoch: [12][310/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.5668 (2.6222)	Acc@1 35.156 (30.547)	Acc@5 71.875 (64.811)
Epoch: [12][320/391]	Time 0.086 (0.080)	Data 0.001 (0.002)	Loss 2.5468 (2.6205)	Acc@1 31.250 (30.607)	Acc@5 64.062 (64.805)
Epoch: [12][330/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.7165 (2.6213)	Acc@1 28.906 (30.580)	Acc@5 62.500 (64.806)
Epoch: [12][340/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.5943 (2.6214)	Acc@1 31.250 (30.574)	Acc@5 65.625 (64.775)
Epoch: [12][350/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.4971 (2.6219)	Acc@1 34.375 (30.593)	Acc@5 66.406 (64.737)
Epoch: [12][360/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.4346 (2.6221)	Acc@1 32.812 (30.564)	Acc@5 70.312 (64.738)
Epoch: [12][370/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5044 (2.6215)	Acc@1 28.906 (30.568)	Acc@5 67.969 (64.732)
Epoch: [12][380/391]	Time 0.086 (0.081)	Data 0.001 (0.002)	Loss 2.6852 (2.6211)	Acc@1 33.594 (30.618)	Acc@5 60.938 (64.725)
Epoch: [12][390/391]	Time 0.066 (0.080)	Data 0.001 (0.002)	Loss 2.6393 (2.6196)	Acc@1 25.000 (30.636)	Acc@5 63.750 (64.768)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [13][0/391]	Time 0.094 (0.094)	Data 0.181 (0.181)	Loss 2.5389 (2.5389)	Acc@1 31.250 (31.250)	Acc@5 70.312 (70.312)
Epoch: [13][10/391]	Time 0.084 (0.083)	Data 0.001 (0.017)	Loss 2.5933 (2.6279)	Acc@1 30.469 (31.250)	Acc@5 65.625 (62.429)
Epoch: [13][20/391]	Time 0.079 (0.082)	Data 0.001 (0.010)	Loss 2.3820 (2.6348)	Acc@1 38.281 (31.585)	Acc@5 72.656 (63.058)
Epoch: [13][30/391]	Time 0.082 (0.082)	Data 0.001 (0.007)	Loss 2.2863 (2.6223)	Acc@1 40.625 (31.603)	Acc@5 70.312 (63.483)
Epoch: [13][40/391]	Time 0.078 (0.081)	Data 0.001 (0.005)	Loss 2.6766 (2.5978)	Acc@1 35.938 (32.298)	Acc@5 66.406 (64.405)
Epoch: [13][50/391]	Time 0.079 (0.081)	Data 0.001 (0.005)	Loss 2.6933 (2.5955)	Acc@1 35.156 (32.644)	Acc@5 61.719 (64.828)
Epoch: [13][60/391]	Time 0.077 (0.081)	Data 0.001 (0.004)	Loss 2.3405 (2.5783)	Acc@1 40.625 (32.864)	Acc@5 69.531 (65.369)
Epoch: [13][70/391]	Time 0.079 (0.081)	Data 0.001 (0.004)	Loss 2.4203 (2.5677)	Acc@1 34.375 (32.713)	Acc@5 67.188 (65.790)
Epoch: [13][80/391]	Time 0.077 (0.081)	Data 0.001 (0.003)	Loss 2.4557 (2.5648)	Acc@1 33.594 (32.542)	Acc@5 71.094 (65.885)
Epoch: [13][90/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.6737 (2.5652)	Acc@1 30.469 (32.503)	Acc@5 59.375 (65.917)
Epoch: [13][100/391]	Time 0.083 (0.081)	Data 0.001 (0.003)	Loss 2.4462 (2.5689)	Acc@1 37.500 (32.209)	Acc@5 66.406 (65.865)
Epoch: [13][110/391]	Time 0.082 (0.081)	Data 0.001 (0.003)	Loss 2.8082 (2.5732)	Acc@1 23.438 (32.059)	Acc@5 60.156 (65.759)
Epoch: [13][120/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.4849 (2.5706)	Acc@1 35.156 (31.934)	Acc@5 67.188 (65.786)
Epoch: [13][130/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 2.6588 (2.5745)	Acc@1 31.250 (31.876)	Acc@5 64.844 (65.732)
Epoch: [13][140/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5092 (2.5781)	Acc@1 29.688 (31.832)	Acc@5 70.312 (65.691)
Epoch: [13][150/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6629 (2.5806)	Acc@1 32.031 (31.773)	Acc@5 62.500 (65.589)
Epoch: [13][160/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.3720 (2.5799)	Acc@1 35.938 (31.774)	Acc@5 70.312 (65.674)
Epoch: [13][170/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.7491 (2.5814)	Acc@1 27.344 (31.652)	Acc@5 60.156 (65.730)
Epoch: [13][180/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.8663 (2.5811)	Acc@1 30.469 (31.604)	Acc@5 59.375 (65.716)
Epoch: [13][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.5386 (2.5852)	Acc@1 38.281 (31.565)	Acc@5 65.625 (65.621)
Epoch: [13][200/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.6333 (2.5858)	Acc@1 28.906 (31.534)	Acc@5 64.062 (65.617)
Epoch: [13][210/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 2.5920 (2.5855)	Acc@1 29.688 (31.531)	Acc@5 65.625 (65.588)
Epoch: [13][220/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.7445 (2.5842)	Acc@1 32.031 (31.540)	Acc@5 63.281 (65.664)
Epoch: [13][230/391]	Time 0.082 (0.082)	Data 0.002 (0.002)	Loss 2.5458 (2.5849)	Acc@1 31.250 (31.500)	Acc@5 70.312 (65.676)
Epoch: [13][240/391]	Time 0.085 (0.082)	Data 0.001 (0.002)	Loss 2.6564 (2.5827)	Acc@1 24.219 (31.513)	Acc@5 68.750 (65.725)
Epoch: [13][250/391]	Time 0.091 (0.082)	Data 0.001 (0.002)	Loss 2.5413 (2.5813)	Acc@1 32.812 (31.567)	Acc@5 68.750 (65.765)
Epoch: [13][260/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 2.4883 (2.5805)	Acc@1 22.656 (31.534)	Acc@5 68.750 (65.790)
Epoch: [13][270/391]	Time 0.085 (0.082)	Data 0.001 (0.002)	Loss 2.5224 (2.5793)	Acc@1 32.812 (31.584)	Acc@5 66.406 (65.815)
Epoch: [13][280/391]	Time 0.084 (0.082)	Data 0.002 (0.002)	Loss 2.4223 (2.5804)	Acc@1 35.156 (31.550)	Acc@5 70.312 (65.822)
Epoch: [13][290/391]	Time 0.085 (0.082)	Data 0.001 (0.002)	Loss 2.4507 (2.5832)	Acc@1 37.500 (31.478)	Acc@5 67.969 (65.748)
Epoch: [13][300/391]	Time 0.089 (0.082)	Data 0.001 (0.002)	Loss 2.5499 (2.5825)	Acc@1 38.281 (31.512)	Acc@5 67.969 (65.814)
Epoch: [13][310/391]	Time 0.084 (0.082)	Data 0.001 (0.002)	Loss 2.3731 (2.5826)	Acc@1 29.688 (31.564)	Acc@5 71.875 (65.808)
Epoch: [13][320/391]	Time 0.082 (0.082)	Data 0.001 (0.002)	Loss 2.4848 (2.5806)	Acc@1 32.031 (31.605)	Acc@5 72.656 (65.866)
Epoch: [13][330/391]	Time 0.082 (0.082)	Data 0.001 (0.002)	Loss 2.5808 (2.5822)	Acc@1 31.250 (31.573)	Acc@5 67.188 (65.814)
Epoch: [13][340/391]	Time 0.083 (0.083)	Data 0.001 (0.002)	Loss 2.5916 (2.5829)	Acc@1 27.344 (31.534)	Acc@5 64.062 (65.760)
Epoch: [13][350/391]	Time 0.089 (0.083)	Data 0.001 (0.002)	Loss 2.5865 (2.5823)	Acc@1 30.469 (31.544)	Acc@5 62.500 (65.705)
Epoch: [13][360/391]	Time 0.083 (0.083)	Data 0.001 (0.002)	Loss 2.5694 (2.5832)	Acc@1 25.000 (31.564)	Acc@5 71.094 (65.720)
Epoch: [13][370/391]	Time 0.084 (0.083)	Data 0.001 (0.002)	Loss 2.4348 (2.5814)	Acc@1 28.125 (31.576)	Acc@5 72.656 (65.766)
Epoch: [13][380/391]	Time 0.085 (0.083)	Data 0.001 (0.002)	Loss 2.5626 (2.5838)	Acc@1 32.812 (31.543)	Acc@5 63.281 (65.715)
Epoch: [13][390/391]	Time 0.069 (0.083)	Data 0.001 (0.002)	Loss 2.8002 (2.5848)	Acc@1 21.250 (31.464)	Acc@5 63.750 (65.700)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [14][0/391]	Time 0.092 (0.092)	Data 0.171 (0.171)	Loss 2.5849 (2.5849)	Acc@1 31.250 (31.250)	Acc@5 64.062 (64.062)
Epoch: [14][10/391]	Time 0.080 (0.081)	Data 0.001 (0.017)	Loss 2.6064 (2.5689)	Acc@1 31.250 (31.463)	Acc@5 66.406 (65.696)
Epoch: [14][20/391]	Time 0.080 (0.081)	Data 0.001 (0.009)	Loss 2.6970 (2.5544)	Acc@1 32.031 (32.217)	Acc@5 57.812 (66.295)
Epoch: [14][30/391]	Time 0.079 (0.081)	Data 0.001 (0.007)	Loss 2.4710 (2.5442)	Acc@1 29.688 (31.830)	Acc@5 73.438 (66.683)
Epoch: [14][40/391]	Time 0.082 (0.081)	Data 0.001 (0.005)	Loss 2.4803 (2.5359)	Acc@1 32.031 (31.974)	Acc@5 67.969 (66.825)
Epoch: [14][50/391]	Time 0.082 (0.081)	Data 0.001 (0.005)	Loss 2.7053 (2.5394)	Acc@1 34.375 (31.909)	Acc@5 67.188 (66.805)
Epoch: [14][60/391]	Time 0.083 (0.081)	Data 0.001 (0.004)	Loss 2.6088 (2.5477)	Acc@1 30.469 (31.673)	Acc@5 64.844 (66.547)
Epoch: [14][70/391]	Time 0.081 (0.081)	Data 0.001 (0.004)	Loss 2.3270 (2.5492)	Acc@1 39.062 (31.580)	Acc@5 71.094 (66.538)
Epoch: [14][80/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.5258 (2.5474)	Acc@1 32.031 (31.327)	Acc@5 66.406 (66.763)
Epoch: [14][90/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 2.5083 (2.5465)	Acc@1 30.469 (31.559)	Acc@5 64.062 (66.750)
Epoch: [14][100/391]	Time 0.084 (0.081)	Data 0.001 (0.003)	Loss 2.4518 (2.5478)	Acc@1 32.812 (31.567)	Acc@5 71.094 (66.700)
Epoch: [14][110/391]	Time 0.083 (0.081)	Data 0.001 (0.003)	Loss 2.4870 (2.5407)	Acc@1 32.812 (31.665)	Acc@5 71.875 (66.906)
Epoch: [14][120/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 2.4167 (2.5395)	Acc@1 32.031 (31.663)	Acc@5 72.656 (66.897)
Epoch: [14][130/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.8245 (2.5481)	Acc@1 26.562 (31.471)	Acc@5 53.906 (66.645)
Epoch: [14][140/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 2.2915 (2.5460)	Acc@1 39.062 (31.516)	Acc@5 74.219 (66.606)
Epoch: [14][150/391]	Time 0.084 (0.081)	Data 0.001 (0.002)	Loss 2.5927 (2.5476)	Acc@1 32.812 (31.472)	Acc@5 63.281 (66.525)
Epoch: [14][160/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.3790 (2.5484)	Acc@1 37.500 (31.531)	Acc@5 74.219 (66.576)
Epoch: [14][170/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.8368 (2.5504)	Acc@1 26.562 (31.520)	Acc@5 58.594 (66.520)
Epoch: [14][180/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.1199 (2.5461)	Acc@1 39.844 (31.556)	Acc@5 75.781 (66.626)
Epoch: [14][190/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 2.6540 (2.5432)	Acc@1 24.219 (31.573)	Acc@5 70.312 (66.754)
Epoch: [14][200/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.6799 (2.5430)	Acc@1 29.688 (31.588)	Acc@5 67.969 (66.725)
Epoch: [14][210/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5561 (2.5480)	Acc@1 28.125 (31.565)	Acc@5 63.281 (66.580)
Epoch: [14][220/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.7116 (2.5482)	Acc@1 30.469 (31.596)	Acc@5 64.844 (66.618)
Epoch: [14][230/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 2.4171 (2.5487)	Acc@1 33.594 (31.565)	Acc@5 75.781 (66.602)
Epoch: [14][240/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.3267 (2.5444)	Acc@1 35.938 (31.707)	Acc@5 70.312 (66.737)
Epoch: [14][250/391]	Time 0.076 (0.081)	Data 0.001 (0.002)	Loss 2.7506 (2.5459)	Acc@1 23.438 (31.617)	Acc@5 62.500 (66.705)
Epoch: [14][260/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.9874 (2.5493)	Acc@1 19.531 (31.558)	Acc@5 56.250 (66.601)
Epoch: [14][270/391]	Time 0.095 (0.081)	Data 0.001 (0.002)	Loss 2.5265 (2.5490)	Acc@1 33.594 (31.631)	Acc@5 66.406 (66.637)
Epoch: [14][280/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4145 (2.5490)	Acc@1 31.250 (31.636)	Acc@5 70.312 (66.604)
Epoch: [14][290/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.4424 (2.5482)	Acc@1 38.281 (31.682)	Acc@5 71.094 (66.626)
Epoch: [14][300/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4355 (2.5490)	Acc@1 32.031 (31.696)	Acc@5 69.531 (66.578)
Epoch: [14][310/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.7920 (2.5505)	Acc@1 28.906 (31.654)	Acc@5 60.156 (66.565)
Epoch: [14][320/391]	Time 0.087 (0.081)	Data 0.001 (0.002)	Loss 2.3107 (2.5500)	Acc@1 37.500 (31.659)	Acc@5 75.000 (66.596)
Epoch: [14][330/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5686 (2.5522)	Acc@1 33.594 (31.628)	Acc@5 66.406 (66.531)
Epoch: [14][340/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.5266 (2.5524)	Acc@1 34.375 (31.662)	Acc@5 65.625 (66.532)
Epoch: [14][350/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4393 (2.5515)	Acc@1 34.375 (31.644)	Acc@5 75.000 (66.562)
Epoch: [14][360/391]	Time 0.087 (0.081)	Data 0.001 (0.002)	Loss 2.2560 (2.5509)	Acc@1 38.281 (31.648)	Acc@5 75.781 (66.545)
Epoch: [14][370/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.7495 (2.5502)	Acc@1 30.469 (31.734)	Acc@5 60.938 (66.566)
Epoch: [14][380/391]	Time 0.088 (0.081)	Data 0.001 (0.002)	Loss 2.5593 (2.5523)	Acc@1 32.031 (31.720)	Acc@5 66.406 (66.521)
Epoch: [14][390/391]	Time 0.070 (0.081)	Data 0.001 (0.002)	Loss 2.7949 (2.5552)	Acc@1 32.500 (31.738)	Acc@5 58.750 (66.464)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [15][0/391]	Time 0.093 (0.093)	Data 0.192 (0.192)	Loss 2.6716 (2.6716)	Acc@1 28.906 (28.906)	Acc@5 63.281 (63.281)
Epoch: [15][10/391]	Time 0.086 (0.087)	Data 0.001 (0.019)	Loss 2.5218 (2.5266)	Acc@1 32.812 (33.026)	Acc@5 68.750 (66.619)
Epoch: [15][20/391]	Time 0.084 (0.086)	Data 0.001 (0.010)	Loss 2.3993 (2.5072)	Acc@1 38.281 (33.557)	Acc@5 71.094 (67.299)
Epoch: [15][30/391]	Time 0.089 (0.085)	Data 0.001 (0.007)	Loss 2.5400 (2.5247)	Acc@1 31.250 (33.443)	Acc@5 64.844 (66.809)
Epoch: [15][40/391]	Time 0.083 (0.085)	Data 0.001 (0.006)	Loss 2.2960 (2.5314)	Acc@1 37.500 (33.194)	Acc@5 71.875 (66.673)
Epoch: [15][50/391]	Time 0.083 (0.085)	Data 0.001 (0.005)	Loss 2.2085 (2.5113)	Acc@1 40.625 (33.824)	Acc@5 76.562 (67.233)
Epoch: [15][60/391]	Time 0.083 (0.085)	Data 0.001 (0.004)	Loss 2.6984 (2.5015)	Acc@1 26.562 (34.004)	Acc@5 55.469 (67.175)
Epoch: [15][70/391]	Time 0.082 (0.085)	Data 0.001 (0.004)	Loss 2.6151 (2.5152)	Acc@1 29.688 (33.616)	Acc@5 60.938 (66.802)
Epoch: [15][80/391]	Time 0.087 (0.085)	Data 0.001 (0.004)	Loss 2.5388 (2.5302)	Acc@1 31.250 (33.275)	Acc@5 62.500 (66.406)
Epoch: [15][90/391]	Time 0.085 (0.085)	Data 0.001 (0.003)	Loss 2.7554 (2.5224)	Acc@1 25.781 (33.259)	Acc@5 60.156 (66.518)
Epoch: [15][100/391]	Time 0.084 (0.085)	Data 0.001 (0.003)	Loss 2.3059 (2.5186)	Acc@1 36.719 (33.354)	Acc@5 72.656 (66.808)
Epoch: [15][110/391]	Time 0.085 (0.085)	Data 0.001 (0.003)	Loss 2.5112 (2.5177)	Acc@1 32.031 (33.263)	Acc@5 68.750 (66.997)
Epoch: [15][120/391]	Time 0.091 (0.085)	Data 0.001 (0.003)	Loss 2.6213 (2.5170)	Acc@1 29.688 (33.187)	Acc@5 64.844 (67.052)
Epoch: [15][130/391]	Time 0.090 (0.085)	Data 0.001 (0.003)	Loss 2.6418 (2.5195)	Acc@1 23.438 (32.985)	Acc@5 60.938 (66.997)
Epoch: [15][140/391]	Time 0.086 (0.085)	Data 0.001 (0.003)	Loss 2.3364 (2.5230)	Acc@1 31.250 (32.740)	Acc@5 74.219 (66.866)
Epoch: [15][150/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.3716 (2.5208)	Acc@1 33.594 (32.776)	Acc@5 69.531 (66.929)
Epoch: [15][160/391]	Time 0.082 (0.085)	Data 0.001 (0.002)	Loss 2.6192 (2.5211)	Acc@1 33.594 (32.788)	Acc@5 67.969 (67.003)
Epoch: [15][170/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.6188 (2.5235)	Acc@1 26.562 (32.666)	Acc@5 69.531 (67.069)
Epoch: [15][180/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.5729 (2.5204)	Acc@1 30.469 (32.674)	Acc@5 67.969 (67.131)
Epoch: [15][190/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.3702 (2.5211)	Acc@1 38.281 (32.710)	Acc@5 66.406 (67.081)
Epoch: [15][200/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.4586 (2.5207)	Acc@1 33.594 (32.641)	Acc@5 70.312 (67.075)
Epoch: [15][210/391]	Time 0.088 (0.084)	Data 0.001 (0.002)	Loss 2.5033 (2.5221)	Acc@1 32.812 (32.631)	Acc@5 62.500 (67.051)
Epoch: [15][220/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.4370 (2.5229)	Acc@1 35.938 (32.593)	Acc@5 70.312 (67.067)
Epoch: [15][230/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.3602 (2.5178)	Acc@1 35.156 (32.745)	Acc@5 67.969 (67.194)
Epoch: [15][240/391]	Time 0.082 (0.084)	Data 0.001 (0.002)	Loss 2.4610 (2.5210)	Acc@1 37.500 (32.676)	Acc@5 67.969 (67.113)
Epoch: [15][250/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.6276 (2.5225)	Acc@1 28.906 (32.638)	Acc@5 61.719 (67.066)
Epoch: [15][260/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.7019 (2.5272)	Acc@1 28.906 (32.522)	Acc@5 60.156 (66.957)
Epoch: [15][270/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.5069 (2.5279)	Acc@1 33.594 (32.573)	Acc@5 67.188 (66.908)
Epoch: [15][280/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.7265 (2.5290)	Acc@1 29.688 (32.587)	Acc@5 63.281 (66.815)
Epoch: [15][290/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.5844 (2.5310)	Acc@1 32.031 (32.595)	Acc@5 64.062 (66.793)
Epoch: [15][300/391]	Time 0.087 (0.084)	Data 0.001 (0.002)	Loss 2.5515 (2.5294)	Acc@1 31.250 (32.576)	Acc@5 71.094 (66.858)
Epoch: [15][310/391]	Time 0.080 (0.084)	Data 0.001 (0.002)	Loss 2.5641 (2.5312)	Acc@1 31.250 (32.536)	Acc@5 69.531 (66.841)
Epoch: [15][320/391]	Time 0.088 (0.084)	Data 0.001 (0.002)	Loss 2.4613 (2.5305)	Acc@1 30.469 (32.552)	Acc@5 70.312 (66.883)
Epoch: [15][330/391]	Time 0.089 (0.084)	Data 0.001 (0.002)	Loss 2.5175 (2.5317)	Acc@1 33.594 (32.515)	Acc@5 68.750 (66.871)
Epoch: [15][340/391]	Time 0.082 (0.084)	Data 0.001 (0.002)	Loss 2.3862 (2.5314)	Acc@1 34.375 (32.508)	Acc@5 70.312 (66.901)
Epoch: [15][350/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.4653 (2.5304)	Acc@1 35.938 (32.510)	Acc@5 68.750 (66.905)
Epoch: [15][360/391]	Time 0.085 (0.085)	Data 0.001 (0.002)	Loss 2.3241 (2.5294)	Acc@1 33.594 (32.527)	Acc@5 71.094 (66.965)
Epoch: [15][370/391]	Time 0.082 (0.084)	Data 0.001 (0.002)	Loss 2.7272 (2.5292)	Acc@1 27.344 (32.522)	Acc@5 62.500 (66.983)
Epoch: [15][380/391]	Time 0.091 (0.084)	Data 0.001 (0.002)	Loss 2.4633 (2.5302)	Acc@1 32.812 (32.495)	Acc@5 67.188 (66.933)
Epoch: [15][390/391]	Time 0.070 (0.084)	Data 0.001 (0.002)	Loss 2.5727 (2.5311)	Acc@1 31.250 (32.502)	Acc@5 68.750 (66.884)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [16][0/391]	Time 0.090 (0.090)	Data 0.190 (0.190)	Loss 2.3408 (2.3408)	Acc@1 32.031 (32.031)	Acc@5 70.312 (70.312)
Epoch: [16][10/391]	Time 0.083 (0.085)	Data 0.001 (0.018)	Loss 2.5888 (2.4711)	Acc@1 32.812 (33.523)	Acc@5 63.281 (68.892)
Epoch: [16][20/391]	Time 0.083 (0.085)	Data 0.001 (0.010)	Loss 2.5047 (2.4960)	Acc@1 29.688 (32.812)	Acc@5 66.406 (67.894)
Epoch: [16][30/391]	Time 0.084 (0.084)	Data 0.001 (0.007)	Loss 2.5811 (2.4857)	Acc@1 33.594 (33.266)	Acc@5 64.844 (67.918)
Epoch: [16][40/391]	Time 0.082 (0.084)	Data 0.001 (0.006)	Loss 2.3020 (2.4834)	Acc@1 38.281 (33.556)	Acc@5 71.094 (67.912)
Epoch: [16][50/391]	Time 0.084 (0.084)	Data 0.001 (0.005)	Loss 2.3646 (2.4784)	Acc@1 38.281 (33.578)	Acc@5 65.625 (68.015)
Epoch: [16][60/391]	Time 0.082 (0.084)	Data 0.001 (0.004)	Loss 2.3595 (2.4856)	Acc@1 33.594 (33.338)	Acc@5 76.562 (67.802)
Epoch: [16][70/391]	Time 0.085 (0.084)	Data 0.001 (0.004)	Loss 2.4978 (2.4843)	Acc@1 28.906 (33.242)	Acc@5 67.188 (67.881)
Epoch: [16][80/391]	Time 0.082 (0.084)	Data 0.001 (0.004)	Loss 2.4192 (2.4907)	Acc@1 31.250 (33.160)	Acc@5 70.312 (67.747)
Epoch: [16][90/391]	Time 0.081 (0.084)	Data 0.001 (0.003)	Loss 2.5317 (2.5016)	Acc@1 32.812 (32.701)	Acc@5 67.188 (67.333)
Epoch: [16][100/391]	Time 0.083 (0.084)	Data 0.001 (0.003)	Loss 2.3799 (2.4957)	Acc@1 36.719 (33.122)	Acc@5 71.875 (67.450)
Epoch: [16][110/391]	Time 0.084 (0.084)	Data 0.001 (0.003)	Loss 2.5763 (2.4992)	Acc@1 31.250 (32.995)	Acc@5 68.750 (67.589)
Epoch: [16][120/391]	Time 0.088 (0.084)	Data 0.001 (0.003)	Loss 2.5820 (2.5019)	Acc@1 28.906 (32.916)	Acc@5 69.531 (67.627)
Epoch: [16][130/391]	Time 0.084 (0.084)	Data 0.001 (0.003)	Loss 2.4180 (2.4993)	Acc@1 39.844 (32.997)	Acc@5 68.750 (67.688)
Epoch: [16][140/391]	Time 0.088 (0.084)	Data 0.001 (0.003)	Loss 2.5342 (2.4980)	Acc@1 29.688 (32.962)	Acc@5 66.406 (67.803)
Epoch: [16][150/391]	Time 0.082 (0.084)	Data 0.001 (0.002)	Loss 2.7180 (2.5030)	Acc@1 28.906 (32.994)	Acc@5 63.281 (67.643)
Epoch: [16][160/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.4630 (2.5034)	Acc@1 34.375 (32.939)	Acc@5 68.750 (67.644)
Epoch: [16][170/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.5023 (2.5041)	Acc@1 31.250 (32.849)	Acc@5 62.500 (67.585)
Epoch: [16][180/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.4571 (2.5041)	Acc@1 39.062 (32.834)	Acc@5 67.969 (67.749)
Epoch: [16][190/391]	Time 0.082 (0.084)	Data 0.002 (0.002)	Loss 2.4326 (2.5052)	Acc@1 29.688 (32.804)	Acc@5 69.531 (67.797)
Epoch: [16][200/391]	Time 0.089 (0.084)	Data 0.001 (0.002)	Loss 2.3469 (2.5038)	Acc@1 42.188 (32.816)	Acc@5 72.656 (67.813)
Epoch: [16][210/391]	Time 0.081 (0.084)	Data 0.001 (0.002)	Loss 2.5667 (2.5055)	Acc@1 32.031 (32.938)	Acc@5 63.281 (67.680)
Epoch: [16][220/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.4436 (2.5073)	Acc@1 35.938 (32.904)	Acc@5 71.875 (67.704)
Epoch: [16][230/391]	Time 0.082 (0.084)	Data 0.001 (0.002)	Loss 2.4024 (2.5058)	Acc@1 35.938 (32.985)	Acc@5 69.531 (67.766)
Epoch: [16][240/391]	Time 0.090 (0.085)	Data 0.001 (0.002)	Loss 2.6848 (2.5071)	Acc@1 27.344 (33.033)	Acc@5 63.281 (67.735)
Epoch: [16][250/391]	Time 0.088 (0.085)	Data 0.001 (0.002)	Loss 2.2593 (2.5093)	Acc@1 34.375 (32.934)	Acc@5 70.312 (67.664)
Epoch: [16][260/391]	Time 0.082 (0.085)	Data 0.001 (0.002)	Loss 2.4248 (2.5076)	Acc@1 32.031 (32.974)	Acc@5 68.750 (67.690)
Epoch: [16][270/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.4625 (2.5067)	Acc@1 34.375 (32.960)	Acc@5 68.750 (67.701)
Epoch: [16][280/391]	Time 0.082 (0.084)	Data 0.001 (0.002)	Loss 2.4043 (2.5058)	Acc@1 38.281 (32.982)	Acc@5 69.531 (67.680)
Epoch: [16][290/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.3375 (2.5056)	Acc@1 34.375 (32.960)	Acc@5 70.312 (67.652)
Epoch: [16][300/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.6365 (2.5049)	Acc@1 30.469 (32.947)	Acc@5 64.062 (67.621)
Epoch: [16][310/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.5470 (2.5067)	Acc@1 34.375 (32.918)	Acc@5 64.062 (67.559)
Epoch: [16][320/391]	Time 0.086 (0.084)	Data 0.001 (0.002)	Loss 2.5021 (2.5063)	Acc@1 35.156 (32.907)	Acc@5 69.531 (67.594)
Epoch: [16][330/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.4660 (2.5070)	Acc@1 34.375 (32.905)	Acc@5 71.875 (67.615)
Epoch: [16][340/391]	Time 0.085 (0.084)	Data 0.002 (0.002)	Loss 2.6049 (2.5087)	Acc@1 34.375 (32.886)	Acc@5 64.062 (67.577)
Epoch: [16][350/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.6005 (2.5098)	Acc@1 29.688 (32.853)	Acc@5 60.938 (67.528)
Epoch: [16][360/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.3893 (2.5088)	Acc@1 32.812 (32.899)	Acc@5 66.406 (67.519)
Epoch: [16][370/391]	Time 0.084 (0.085)	Data 0.002 (0.002)	Loss 2.3707 (2.5089)	Acc@1 34.375 (32.928)	Acc@5 72.656 (67.510)
Epoch: [16][380/391]	Time 0.082 (0.085)	Data 0.001 (0.002)	Loss 2.5850 (2.5097)	Acc@1 27.344 (32.872)	Acc@5 67.188 (67.491)
Epoch: [16][390/391]	Time 0.076 (0.084)	Data 0.001 (0.002)	Loss 2.4457 (2.5090)	Acc@1 33.750 (32.914)	Acc@5 70.000 (67.502)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [17][0/391]	Time 0.088 (0.088)	Data 0.176 (0.176)	Loss 2.2102 (2.2102)	Acc@1 43.750 (43.750)	Acc@5 71.094 (71.094)
Epoch: [17][10/391]	Time 0.082 (0.082)	Data 0.001 (0.017)	Loss 2.4697 (2.4392)	Acc@1 36.719 (35.369)	Acc@5 71.094 (68.182)
Epoch: [17][20/391]	Time 0.079 (0.081)	Data 0.001 (0.009)	Loss 2.3522 (2.4328)	Acc@1 40.625 (35.454)	Acc@5 67.188 (68.824)
Epoch: [17][30/391]	Time 0.078 (0.081)	Data 0.001 (0.007)	Loss 2.7662 (2.4513)	Acc@1 31.250 (34.577)	Acc@5 57.031 (68.120)
Epoch: [17][40/391]	Time 0.080 (0.081)	Data 0.001 (0.005)	Loss 2.5125 (2.4334)	Acc@1 26.562 (34.566)	Acc@5 69.531 (68.864)
Epoch: [17][50/391]	Time 0.077 (0.081)	Data 0.001 (0.005)	Loss 2.4314 (2.4355)	Acc@1 33.594 (34.773)	Acc@5 68.750 (68.827)
Epoch: [17][60/391]	Time 0.078 (0.081)	Data 0.001 (0.004)	Loss 2.4862 (2.4402)	Acc@1 35.156 (34.708)	Acc@5 64.844 (68.776)
Epoch: [17][70/391]	Time 0.077 (0.080)	Data 0.001 (0.004)	Loss 2.5869 (2.4518)	Acc@1 34.375 (34.485)	Acc@5 67.188 (68.519)
Epoch: [17][80/391]	Time 0.082 (0.081)	Data 0.001 (0.003)	Loss 2.5480 (2.4544)	Acc@1 28.125 (34.500)	Acc@5 68.750 (68.528)
Epoch: [17][90/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.3262 (2.4652)	Acc@1 42.969 (34.220)	Acc@5 76.562 (68.372)
Epoch: [17][100/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 2.5150 (2.4686)	Acc@1 26.562 (33.895)	Acc@5 70.312 (68.433)
Epoch: [17][110/391]	Time 0.080 (0.081)	Data 0.001 (0.003)	Loss 2.7885 (2.4765)	Acc@1 26.562 (33.657)	Acc@5 57.812 (68.074)
Epoch: [17][120/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.6667 (2.4773)	Acc@1 28.125 (33.697)	Acc@5 62.500 (68.059)
Epoch: [17][130/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.7295 (2.4824)	Acc@1 28.125 (33.618)	Acc@5 64.844 (67.975)
Epoch: [17][140/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.6419 (2.4872)	Acc@1 28.125 (33.461)	Acc@5 64.062 (67.791)
Epoch: [17][150/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.4048 (2.4891)	Acc@1 41.406 (33.402)	Acc@5 67.188 (67.798)
Epoch: [17][160/391]	Time 0.086 (0.081)	Data 0.001 (0.002)	Loss 2.3844 (2.4918)	Acc@1 32.031 (33.341)	Acc@5 70.312 (67.707)
Epoch: [17][170/391]	Time 0.082 (0.081)	Data 0.002 (0.002)	Loss 2.5098 (2.4909)	Acc@1 34.375 (33.320)	Acc@5 68.750 (67.736)
Epoch: [17][180/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5032 (2.4927)	Acc@1 29.688 (33.227)	Acc@5 66.406 (67.723)
Epoch: [17][190/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.3398 (2.4906)	Acc@1 35.938 (33.303)	Acc@5 75.000 (67.797)
Epoch: [17][200/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.4323 (2.4889)	Acc@1 33.594 (33.322)	Acc@5 69.531 (67.829)
Epoch: [17][210/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6643 (2.4861)	Acc@1 25.781 (33.294)	Acc@5 64.844 (67.950)
Epoch: [17][220/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.7259 (2.4862)	Acc@1 31.250 (33.279)	Acc@5 58.594 (67.969)
Epoch: [17][230/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 2.6123 (2.4858)	Acc@1 30.469 (33.374)	Acc@5 62.500 (67.959)
Epoch: [17][240/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.4364 (2.4867)	Acc@1 33.594 (33.383)	Acc@5 70.312 (67.927)
Epoch: [17][250/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4651 (2.4837)	Acc@1 35.938 (33.441)	Acc@5 67.969 (67.916)
Epoch: [17][260/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.3502 (2.4839)	Acc@1 38.281 (33.486)	Acc@5 71.094 (67.945)
Epoch: [17][270/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.4968 (2.4830)	Acc@1 33.594 (33.470)	Acc@5 66.406 (67.969)
Epoch: [17][280/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.4142 (2.4812)	Acc@1 36.719 (33.496)	Acc@5 70.312 (67.994)
Epoch: [17][290/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4673 (2.4826)	Acc@1 39.844 (33.449)	Acc@5 70.312 (68.009)
Epoch: [17][300/391]	Time 0.086 (0.081)	Data 0.001 (0.002)	Loss 2.7099 (2.4863)	Acc@1 29.688 (33.441)	Acc@5 62.500 (67.878)
Epoch: [17][310/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4488 (2.4846)	Acc@1 35.156 (33.435)	Acc@5 69.531 (67.891)
Epoch: [17][320/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.4914 (2.4847)	Acc@1 31.250 (33.416)	Acc@5 66.406 (67.871)
Epoch: [17][330/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.6820 (2.4862)	Acc@1 27.344 (33.362)	Acc@5 64.062 (67.811)
Epoch: [17][340/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.6975 (2.4856)	Acc@1 31.250 (33.470)	Acc@5 64.062 (67.811)
Epoch: [17][350/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.2557 (2.4852)	Acc@1 45.312 (33.438)	Acc@5 70.312 (67.853)
Epoch: [17][360/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.5867 (2.4845)	Acc@1 38.281 (33.470)	Acc@5 67.969 (67.917)
Epoch: [17][370/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.3876 (2.4848)	Acc@1 35.938 (33.432)	Acc@5 71.875 (67.929)
Epoch: [17][380/391]	Time 0.076 (0.081)	Data 0.001 (0.002)	Loss 2.2504 (2.4851)	Acc@1 37.500 (33.411)	Acc@5 72.656 (67.936)
Epoch: [17][390/391]	Time 0.068 (0.081)	Data 0.001 (0.002)	Loss 2.4698 (2.4830)	Acc@1 38.750 (33.480)	Acc@5 70.000 (67.994)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [18][0/391]	Time 0.087 (0.087)	Data 0.164 (0.164)	Loss 2.4690 (2.4690)	Acc@1 35.156 (35.156)	Acc@5 69.531 (69.531)
Epoch: [18][10/391]	Time 0.080 (0.081)	Data 0.001 (0.016)	Loss 2.5311 (2.4393)	Acc@1 32.812 (33.523)	Acc@5 67.188 (68.395)
Epoch: [18][20/391]	Time 0.079 (0.081)	Data 0.001 (0.009)	Loss 2.5662 (2.4741)	Acc@1 34.375 (33.705)	Acc@5 69.531 (68.080)
Epoch: [18][30/391]	Time 0.084 (0.082)	Data 0.001 (0.006)	Loss 2.5036 (2.4647)	Acc@1 37.500 (33.896)	Acc@5 71.094 (68.548)
Epoch: [18][40/391]	Time 0.077 (0.081)	Data 0.001 (0.005)	Loss 2.5352 (2.4625)	Acc@1 32.812 (34.146)	Acc@5 66.406 (68.140)
Epoch: [18][50/391]	Time 0.081 (0.082)	Data 0.001 (0.004)	Loss 2.7525 (2.4742)	Acc@1 26.562 (33.640)	Acc@5 60.156 (68.107)
Epoch: [18][60/391]	Time 0.080 (0.082)	Data 0.001 (0.004)	Loss 2.6180 (2.4715)	Acc@1 27.344 (33.658)	Acc@5 60.938 (68.186)
Epoch: [18][70/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 2.2601 (2.4648)	Acc@1 35.156 (33.770)	Acc@5 74.219 (68.519)
Epoch: [18][80/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 2.6800 (2.4620)	Acc@1 30.469 (33.854)	Acc@5 62.500 (68.499)
Epoch: [18][90/391]	Time 0.081 (0.081)	Data 0.001 (0.003)	Loss 2.3768 (2.4613)	Acc@1 32.812 (33.843)	Acc@5 72.656 (68.518)
Epoch: [18][100/391]	Time 0.082 (0.081)	Data 0.001 (0.003)	Loss 2.4412 (2.4567)	Acc@1 33.594 (33.911)	Acc@5 68.750 (68.680)
Epoch: [18][110/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 2.2323 (2.4487)	Acc@1 37.500 (34.079)	Acc@5 73.438 (68.912)
Epoch: [18][120/391]	Time 0.079 (0.081)	Data 0.001 (0.003)	Loss 2.3201 (2.4532)	Acc@1 35.156 (34.020)	Acc@5 67.188 (68.744)
Epoch: [18][130/391]	Time 0.083 (0.081)	Data 0.001 (0.002)	Loss 2.5007 (2.4555)	Acc@1 34.375 (34.011)	Acc@5 68.750 (68.655)
Epoch: [18][140/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.3058 (2.4601)	Acc@1 41.406 (33.926)	Acc@5 71.875 (68.490)
Epoch: [18][150/391]	Time 0.077 (0.081)	Data 0.001 (0.002)	Loss 2.3778 (2.4572)	Acc@1 31.250 (33.842)	Acc@5 69.531 (68.445)
Epoch: [18][160/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.3228 (2.4579)	Acc@1 35.938 (33.856)	Acc@5 69.531 (68.507)
Epoch: [18][170/391]	Time 0.078 (0.081)	Data 0.001 (0.002)	Loss 2.1358 (2.4603)	Acc@1 39.844 (33.758)	Acc@5 77.344 (68.480)
Epoch: [18][180/391]	Time 0.086 (0.081)	Data 0.001 (0.002)	Loss 2.4703 (2.4618)	Acc@1 38.281 (33.745)	Acc@5 68.750 (68.530)
Epoch: [18][190/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.2629 (2.4648)	Acc@1 40.625 (33.757)	Acc@5 73.438 (68.500)
Epoch: [18][200/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4242 (2.4671)	Acc@1 29.688 (33.726)	Acc@5 67.188 (68.466)
Epoch: [18][210/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.4734 (2.4652)	Acc@1 28.125 (33.716)	Acc@5 69.531 (68.554)
Epoch: [18][220/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.6388 (2.4655)	Acc@1 30.469 (33.742)	Acc@5 63.281 (68.524)
Epoch: [18][230/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.3997 (2.4643)	Acc@1 33.594 (33.783)	Acc@5 68.750 (68.537)
Epoch: [18][240/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.4700 (2.4672)	Acc@1 32.031 (33.749)	Acc@5 71.094 (68.478)
Epoch: [18][250/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4352 (2.4663)	Acc@1 38.281 (33.830)	Acc@5 66.406 (68.501)
Epoch: [18][260/391]	Time 0.085 (0.081)	Data 0.001 (0.002)	Loss 2.5066 (2.4654)	Acc@1 35.156 (33.869)	Acc@5 64.844 (68.499)
Epoch: [18][270/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.5887 (2.4659)	Acc@1 30.469 (33.827)	Acc@5 63.281 (68.450)
Epoch: [18][280/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.3769 (2.4670)	Acc@1 38.281 (33.816)	Acc@5 71.094 (68.341)
Epoch: [18][290/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.5352 (2.4660)	Acc@1 28.906 (33.825)	Acc@5 68.750 (68.374)
Epoch: [18][300/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.4656 (2.4666)	Acc@1 35.156 (33.812)	Acc@5 71.094 (68.343)
Epoch: [18][310/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.6981 (2.4698)	Acc@1 31.250 (33.714)	Acc@5 61.719 (68.285)
Epoch: [18][320/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.3307 (2.4690)	Acc@1 35.938 (33.728)	Acc@5 71.094 (68.339)
Epoch: [18][330/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.7799 (2.4695)	Acc@1 30.469 (33.735)	Acc@5 63.281 (68.377)
Epoch: [18][340/391]	Time 0.080 (0.081)	Data 0.001 (0.002)	Loss 2.3631 (2.4709)	Acc@1 41.406 (33.734)	Acc@5 70.312 (68.340)
Epoch: [18][350/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.4849 (2.4732)	Acc@1 28.125 (33.669)	Acc@5 70.312 (68.298)
Epoch: [18][360/391]	Time 0.081 (0.081)	Data 0.001 (0.002)	Loss 2.6010 (2.4734)	Acc@1 35.156 (33.717)	Acc@5 61.719 (68.278)
Epoch: [18][370/391]	Time 0.082 (0.081)	Data 0.001 (0.002)	Loss 2.4739 (2.4744)	Acc@1 31.250 (33.695)	Acc@5 65.625 (68.251)
Epoch: [18][380/391]	Time 0.079 (0.081)	Data 0.001 (0.002)	Loss 2.5907 (2.4752)	Acc@1 32.031 (33.631)	Acc@5 64.844 (68.229)
Epoch: [18][390/391]	Time 0.067 (0.081)	Data 0.002 (0.002)	Loss 2.4211 (2.4761)	Acc@1 37.500 (33.628)	Acc@5 71.250 (68.160)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [19][0/391]	Time 0.090 (0.090)	Data 0.182 (0.182)	Loss 2.3241 (2.3241)	Acc@1 35.156 (35.156)	Acc@5 75.000 (75.000)
Epoch: [19][10/391]	Time 0.082 (0.084)	Data 0.001 (0.018)	Loss 2.4881 (2.4275)	Acc@1 32.812 (33.097)	Acc@5 64.062 (69.389)
Epoch: [19][20/391]	Time 0.086 (0.084)	Data 0.001 (0.010)	Loss 2.5451 (2.3972)	Acc@1 28.125 (33.929)	Acc@5 70.312 (70.685)
Epoch: [19][30/391]	Time 0.082 (0.084)	Data 0.001 (0.007)	Loss 2.7154 (2.3955)	Acc@1 28.125 (34.451)	Acc@5 59.375 (70.867)
Epoch: [19][40/391]	Time 0.082 (0.084)	Data 0.001 (0.006)	Loss 2.4811 (2.4198)	Acc@1 39.062 (34.623)	Acc@5 69.531 (69.950)
Epoch: [19][50/391]	Time 0.087 (0.084)	Data 0.001 (0.005)	Loss 2.5425 (2.4158)	Acc@1 35.938 (34.804)	Acc@5 65.625 (70.037)
Epoch: [19][60/391]	Time 0.081 (0.084)	Data 0.001 (0.004)	Loss 2.4076 (2.4096)	Acc@1 32.812 (34.836)	Acc@5 68.750 (70.031)
Epoch: [19][70/391]	Time 0.083 (0.084)	Data 0.002 (0.004)	Loss 2.4956 (2.4178)	Acc@1 31.250 (34.584)	Acc@5 69.531 (69.740)
Epoch: [19][80/391]	Time 0.083 (0.084)	Data 0.001 (0.003)	Loss 2.2387 (2.4250)	Acc@1 35.938 (34.481)	Acc@5 73.438 (69.579)
Epoch: [19][90/391]	Time 0.085 (0.084)	Data 0.002 (0.003)	Loss 2.4198 (2.4271)	Acc@1 39.062 (34.495)	Acc@5 70.312 (69.634)
Epoch: [19][100/391]	Time 0.083 (0.084)	Data 0.001 (0.003)	Loss 2.6674 (2.4339)	Acc@1 29.688 (34.305)	Acc@5 63.281 (69.415)
Epoch: [19][110/391]	Time 0.085 (0.084)	Data 0.001 (0.003)	Loss 2.2714 (2.4398)	Acc@1 37.500 (34.199)	Acc@5 73.438 (69.524)
Epoch: [19][120/391]	Time 0.084 (0.084)	Data 0.001 (0.003)	Loss 2.4528 (2.4396)	Acc@1 37.500 (34.259)	Acc@5 68.750 (69.557)
Epoch: [19][130/391]	Time 0.081 (0.084)	Data 0.001 (0.003)	Loss 2.3019 (2.4388)	Acc@1 40.625 (34.494)	Acc@5 69.531 (69.454)
Epoch: [19][140/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.4043 (2.4445)	Acc@1 35.938 (34.369)	Acc@5 71.875 (69.221)
Epoch: [19][150/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.3888 (2.4480)	Acc@1 32.812 (34.163)	Acc@5 71.875 (69.091)
Epoch: [19][160/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.5585 (2.4492)	Acc@1 32.031 (34.094)	Acc@5 63.281 (68.997)
Epoch: [19][170/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.4065 (2.4521)	Acc@1 31.250 (34.060)	Acc@5 68.750 (68.933)
Epoch: [19][180/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.6798 (2.4536)	Acc@1 23.438 (33.956)	Acc@5 64.844 (68.849)
Epoch: [19][190/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.4049 (2.4526)	Acc@1 34.375 (33.974)	Acc@5 67.969 (68.860)
Epoch: [19][200/391]	Time 0.089 (0.084)	Data 0.002 (0.002)	Loss 2.5770 (2.4559)	Acc@1 32.031 (33.874)	Acc@5 66.406 (68.820)
Epoch: [19][210/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.3862 (2.4554)	Acc@1 31.250 (33.905)	Acc@5 68.750 (68.724)
Epoch: [19][220/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.4056 (2.4575)	Acc@1 31.250 (33.824)	Acc@5 71.094 (68.683)
Epoch: [19][230/391]	Time 0.085 (0.084)	Data 0.001 (0.002)	Loss 2.2652 (2.4580)	Acc@1 30.469 (33.858)	Acc@5 73.438 (68.699)
Epoch: [19][240/391]	Time 0.084 (0.085)	Data 0.001 (0.002)	Loss 2.5927 (2.4595)	Acc@1 33.594 (33.970)	Acc@5 70.312 (68.666)
Epoch: [19][250/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.3057 (2.4598)	Acc@1 35.938 (33.961)	Acc@5 72.656 (68.638)
Epoch: [19][260/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.5582 (2.4639)	Acc@1 25.000 (33.713)	Acc@5 66.406 (68.582)
Epoch: [19][270/391]	Time 0.082 (0.085)	Data 0.001 (0.002)	Loss 2.3181 (2.4625)	Acc@1 34.375 (33.692)	Acc@5 71.094 (68.597)
Epoch: [19][280/391]	Time 0.083 (0.085)	Data 0.001 (0.002)	Loss 2.5759 (2.4644)	Acc@1 31.250 (33.633)	Acc@5 64.844 (68.547)
Epoch: [19][290/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.6175 (2.4639)	Acc@1 32.812 (33.709)	Acc@5 61.719 (68.543)
Epoch: [19][300/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.2175 (2.4633)	Acc@1 34.375 (33.685)	Acc@5 78.125 (68.615)
Epoch: [19][310/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.3134 (2.4607)	Acc@1 33.594 (33.787)	Acc@5 72.656 (68.680)
Epoch: [19][320/391]	Time 0.081 (0.084)	Data 0.001 (0.002)	Loss 2.6733 (2.4628)	Acc@1 27.344 (33.754)	Acc@5 62.500 (68.628)
Epoch: [19][330/391]	Time 0.081 (0.084)	Data 0.001 (0.002)	Loss 2.7398 (2.4640)	Acc@1 26.562 (33.733)	Acc@5 64.844 (68.620)
Epoch: [19][340/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.4653 (2.4625)	Acc@1 33.594 (33.740)	Acc@5 66.406 (68.635)
Epoch: [19][350/391]	Time 0.083 (0.084)	Data 0.001 (0.002)	Loss 2.4154 (2.4615)	Acc@1 33.594 (33.727)	Acc@5 71.875 (68.659)
Epoch: [19][360/391]	Time 0.084 (0.084)	Data 0.001 (0.002)	Loss 2.3731 (2.4625)	Acc@1 35.938 (33.752)	Acc@5 68.750 (68.622)
Epoch: [19][370/391]	Time 0.081 (0.084)	Data 0.001 (0.002)	Loss 2.6811 (2.4630)	Acc@1 29.688 (33.764)	Acc@5 60.938 (68.598)
Epoch: [19][380/391]	Time 0.088 (0.084)	Data 0.001 (0.002)	Loss 2.3855 (2.4625)	Acc@1 35.156 (33.768)	Acc@5 70.312 (68.594)
Epoch: [19][390/391]	Time 0.076 (0.084)	Data 0.001 (0.002)	Loss 2.1911 (2.4630)	Acc@1 43.750 (33.786)	Acc@5 77.500 (68.594)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [20][0/391]	Time 0.092 (0.092)	Data 0.165 (0.165)	Loss 2.4501 (2.4501)	Acc@1 35.156 (35.156)	Acc@5 70.312 (70.312)
Epoch: [20][10/391]	Time 0.080 (0.083)	Data 0.001 (0.016)	Loss 2.4504 (2.4450)	Acc@1 35.156 (33.878)	Acc@5 73.438 (69.673)
Epoch: [20][20/391]	Time 0.078 (0.082)	Data 0.001 (0.009)	Loss 2.3246 (2.4571)	Acc@1 39.062 (33.594)	Acc@5 71.094 (69.196)
Epoch: [20][30/391]	Time 0.081 (0.081)	Data 0.001 (0.006)	Loss 2.3751 (2.4497)	Acc@1 34.375 (34.224)	Acc@5 70.312 (69.430)
Epoch: [20][40/391]	Time 0.081 (0.081)	Data 0.001 (0.005)	Loss 2.3248 (2.4337)	Acc@1 35.938 (34.813)	Acc@5 67.969 (69.474)
Epoch: [20][50/391]	Time 0.079 (0.081)	Data 0.001 (0.004)	Loss 2.5363 (2.4296)	Acc@1 35.938 (34.835)	Acc@5 60.156 (69.593)
Epoch: [20][60/391]	Time 0.086 (0.081)	Data 0.001 (0.004)	Loss 2.5436 (2.4327)	Acc@1 37.500 (34.810)	Acc@5 67.188 (69.301)
Epoch: [20][70/391]	Time 0.076 (0.081)	Data 0.001 (0.003)	Loss 2.6751 (2.4320)	Acc@1 32.031 (34.870)	Acc@5 61.719 (69.344)
Epoch: [20][80/391]	Time 0.077 (0.080)	Data 0.001 (0.003)	Loss 2.4376 (2.4373)	Acc@1 38.281 (34.655)	Acc@5 70.312 (69.232)
Epoch: [20][90/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 2.4993 (2.4415)	Acc@1 35.156 (34.435)	Acc@5 65.625 (69.093)
Epoch: [20][100/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 2.3370 (2.4406)	Acc@1 36.719 (34.398)	Acc@5 70.312 (69.036)
Epoch: [20][110/391]	Time 0.079 (0.080)	Data 0.001 (0.003)	Loss 2.3255 (2.4407)	Acc@1 43.750 (34.537)	Acc@5 71.094 (68.954)
Epoch: [20][120/391]	Time 0.080 (0.080)	Data 0.001 (0.003)	Loss 2.4170 (2.4376)	Acc@1 29.688 (34.556)	Acc@5 68.750 (68.937)
Epoch: [20][130/391]	Time 0.079 (0.080)	Data 0.001 (0.002)	Loss 2.4873 (2.4356)	Acc@1 33.594 (34.506)	Acc@5 68.750 (68.923)
Epoch: [20][140/391]	Time 0.085 (0.080)	Data 0.001 (0.002)	Loss 2.2793 (2.4405)	Acc@1 36.719 (34.314)	Acc@5 69.531 (68.761)
Epoch: [20][150/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.4734 (2.4388)	Acc@1 35.938 (34.396)	Acc@5 68.750 (68.910)
Epoch: [20][160/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.3755 (2.4360)	Acc@1 37.500 (34.545)	Acc@5 70.312 (68.978)
Epoch: [20][170/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.6079 (2.4350)	Acc@1 30.469 (34.562)	Acc@5 66.406 (68.860)
Epoch: [20][180/391]	Time 0.086 (0.080)	Data 0.001 (0.002)	Loss 2.5700 (2.4443)	Acc@1 28.906 (34.328)	Acc@5 66.406 (68.685)
Epoch: [20][190/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.4395 (2.4459)	Acc@1 35.938 (34.297)	Acc@5 67.188 (68.640)
Epoch: [20][200/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.4550 (2.4473)	Acc@1 30.469 (34.212)	Acc@5 71.094 (68.626)
Epoch: [20][210/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.4332 (2.4515)	Acc@1 35.156 (34.001)	Acc@5 67.188 (68.546)
Epoch: [20][220/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.2283 (2.4477)	Acc@1 35.156 (34.120)	Acc@5 74.219 (68.647)
Epoch: [20][230/391]	Time 0.077 (0.080)	Data 0.001 (0.002)	Loss 2.4093 (2.4448)	Acc@1 32.031 (34.145)	Acc@5 72.656 (68.726)
Epoch: [20][240/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.3197 (2.4378)	Acc@1 36.719 (34.239)	Acc@5 67.969 (68.867)
Epoch: [20][250/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.5538 (2.4378)	Acc@1 28.906 (34.291)	Acc@5 67.188 (68.899)
Epoch: [20][260/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.6649 (2.4379)	Acc@1 33.594 (34.315)	Acc@5 67.188 (68.891)
Epoch: [20][270/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.6357 (2.4373)	Acc@1 28.125 (34.286)	Acc@5 63.281 (68.888)
Epoch: [20][280/391]	Time 0.084 (0.080)	Data 0.001 (0.002)	Loss 2.7509 (2.4400)	Acc@1 28.125 (34.166)	Acc@5 58.594 (68.817)
Epoch: [20][290/391]	Time 0.081 (0.080)	Data 0.001 (0.002)	Loss 2.3803 (2.4423)	Acc@1 33.594 (34.120)	Acc@5 68.750 (68.774)
Epoch: [20][300/391]	Time 0.079 (0.080)	Data 0.001 (0.002)	Loss 2.4090 (2.4414)	Acc@1 30.469 (34.126)	Acc@5 71.875 (68.820)
Epoch: [20][310/391]	Time 0.078 (0.080)	Data 0.001 (0.002)	Loss 2.3927 (2.4433)	Acc@1 28.125 (34.094)	Acc@5 71.094 (68.813)
Epoch: [20][320/391]	Time 0.079 (0.080)	Data 0.001 (0.002)	Loss 2.6827 (2.4415)	Acc@1 32.812 (34.161)	Acc@5 64.062 (68.869)
Epoch: [20][330/391]	Time 0.083 (0.080)	Data 0.001 (0.002)	Loss 2.3539 (2.4441)	Acc@1 42.188 (34.111)	Acc@5 73.438 (68.851)
Epoch: [20][340/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.1767 (2.4421)	Acc@1 41.406 (34.183)	Acc@5 77.344 (68.887)
Epoch: [20][350/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.3303 (2.4409)	Acc@1 38.281 (34.233)	Acc@5 74.219 (68.930)
Epoch: [20][360/391]	Time 0.080 (0.080)	Data 0.001 (0.002)	Loss 2.4794 (2.4380)	Acc@1 31.250 (34.314)	Acc@5 70.312 (69.025)
Epoch: [20][370/391]	Time 0.083 (0.080)	Data 0.001 (0.002)	Loss 2.5799 (2.4383)	Acc@1 27.344 (34.312)	Acc@5 66.406 (68.996)
Epoch: [20][380/391]	Time 0.082 (0.080)	Data 0.001 (0.002)	Loss 2.1704 (2.4357)	Acc@1 42.969 (34.348)	Acc@5 74.219 (69.068)
Epoch: [20][390/391]	Time 0.068 (0.080)	Data 0.001 (0.002)	Loss 2.2841 (2.4357)	Acc@1 32.500 (34.350)	Acc@5 68.750 (69.038)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): AdaptiveAvgPool2d(output_size=(1, 1))
    (85): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Best acc:
26.73


now deeper
Epoch: [1][0/391]	Time 0.100 (0.100)	Data 0.162 (0.162)	Loss 2.7257 (2.7257)	Acc@1 26.562 (26.562)	Acc@5 62.500 (62.500)
Epoch: [1][10/391]	Time 0.091 (0.090)	Data 0.001 (0.016)	Loss 2.5407 (2.5997)	Acc@1 32.812 (29.332)	Acc@5 65.625 (66.406)
Epoch: [1][20/391]	Time 0.086 (0.088)	Data 0.001 (0.009)	Loss 2.4908 (2.5362)	Acc@1 27.344 (30.878)	Acc@5 70.312 (67.374)
Epoch: [1][30/391]	Time 0.088 (0.088)	Data 0.001 (0.006)	Loss 2.6260 (2.5077)	Acc@1 31.250 (31.830)	Acc@5 67.969 (67.742)
Epoch: [1][40/391]	Time 0.087 (0.089)	Data 0.001 (0.005)	Loss 2.3403 (2.5140)	Acc@1 40.625 (32.241)	Acc@5 75.000 (68.045)
Epoch: [1][50/391]	Time 0.086 (0.089)	Data 0.001 (0.004)	Loss 2.3887 (2.4923)	Acc@1 36.719 (32.966)	Acc@5 70.312 (68.444)
Epoch: [1][60/391]	Time 0.088 (0.089)	Data 0.001 (0.004)	Loss 2.2586 (2.4795)	Acc@1 41.406 (33.363)	Acc@5 71.875 (68.763)
Epoch: [1][70/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.5071 (2.4660)	Acc@1 37.500 (33.396)	Acc@5 68.750 (68.607)
Epoch: [1][80/391]	Time 0.086 (0.089)	Data 0.001 (0.003)	Loss 2.4154 (2.4588)	Acc@1 29.688 (33.439)	Acc@5 70.312 (68.798)
Epoch: [1][90/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.3945 (2.4634)	Acc@1 42.969 (33.542)	Acc@5 70.312 (68.681)
Epoch: [1][100/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.2098 (2.4592)	Acc@1 42.188 (33.586)	Acc@5 71.875 (68.727)
Epoch: [1][110/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.3522 (2.4584)	Acc@1 33.594 (33.622)	Acc@5 67.969 (68.637)
Epoch: [1][120/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4206 (2.4583)	Acc@1 32.812 (33.626)	Acc@5 70.312 (68.685)
Epoch: [1][130/391]	Time 0.095 (0.089)	Data 0.001 (0.002)	Loss 2.4913 (2.4591)	Acc@1 33.594 (33.492)	Acc@5 65.625 (68.839)
Epoch: [1][140/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4661 (2.4507)	Acc@1 31.250 (33.660)	Acc@5 70.312 (68.961)
Epoch: [1][150/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.5103 (2.4496)	Acc@1 35.938 (33.770)	Acc@5 70.312 (68.998)
Epoch: [1][160/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.5377 (2.4495)	Acc@1 35.156 (33.865)	Acc@5 65.625 (68.988)
Epoch: [1][170/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.6283 (2.4482)	Acc@1 26.562 (33.900)	Acc@5 68.750 (68.997)
Epoch: [1][180/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3281 (2.4476)	Acc@1 39.062 (33.982)	Acc@5 69.531 (69.000)
Epoch: [1][190/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.2159 (2.4447)	Acc@1 42.188 (34.015)	Acc@5 77.344 (69.122)
Epoch: [1][200/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.1894 (2.4450)	Acc@1 36.719 (34.060)	Acc@5 72.656 (69.092)
Epoch: [1][210/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.4752 (2.4456)	Acc@1 30.469 (34.020)	Acc@5 67.188 (69.054)
Epoch: [1][220/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3986 (2.4447)	Acc@1 37.500 (34.082)	Acc@5 67.969 (69.093)
Epoch: [1][230/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.7119 (2.4452)	Acc@1 29.688 (34.111)	Acc@5 61.719 (69.078)
Epoch: [1][240/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4089 (2.4461)	Acc@1 32.031 (34.054)	Acc@5 71.094 (69.042)
Epoch: [1][250/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3263 (2.4492)	Acc@1 35.938 (33.908)	Acc@5 69.531 (68.990)
Epoch: [1][260/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3528 (2.4486)	Acc@1 28.125 (33.902)	Acc@5 70.312 (68.986)
Epoch: [1][270/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.2549 (2.4490)	Acc@1 37.500 (33.882)	Acc@5 75.781 (69.027)
Epoch: [1][280/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4609 (2.4486)	Acc@1 32.812 (33.883)	Acc@5 69.531 (69.003)
Epoch: [1][290/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4670 (2.4489)	Acc@1 35.938 (33.908)	Acc@5 68.750 (69.005)
Epoch: [1][300/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.7033 (2.4468)	Acc@1 28.906 (33.936)	Acc@5 62.500 (69.051)
Epoch: [1][310/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3919 (2.4442)	Acc@1 34.375 (33.998)	Acc@5 67.969 (69.132)
Epoch: [1][320/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.3735 (2.4425)	Acc@1 35.156 (34.039)	Acc@5 71.094 (69.183)
Epoch: [1][330/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4469 (2.4433)	Acc@1 38.281 (33.988)	Acc@5 68.750 (69.151)
Epoch: [1][340/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.5747 (2.4439)	Acc@1 29.688 (34.002)	Acc@5 64.844 (69.119)
Epoch: [1][350/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4652 (2.4440)	Acc@1 32.812 (34.030)	Acc@5 71.094 (69.122)
Epoch: [1][360/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3882 (2.4427)	Acc@1 32.812 (34.109)	Acc@5 67.969 (69.116)
Epoch: [1][370/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.5670 (2.4423)	Acc@1 35.156 (34.110)	Acc@5 64.062 (69.112)
Epoch: [1][380/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4303 (2.4412)	Acc@1 29.688 (34.156)	Acc@5 75.781 (69.181)
Epoch: [1][390/391]	Time 0.075 (0.089)	Data 0.001 (0.002)	Loss 2.3147 (2.4398)	Acc@1 33.750 (34.210)	Acc@5 70.000 (69.188)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [2][0/391]	Time 0.128 (0.128)	Data 0.175 (0.175)	Loss 2.2012 (2.2012)	Acc@1 40.625 (40.625)	Acc@5 70.312 (70.312)
Epoch: [2][10/391]	Time 0.087 (0.092)	Data 0.001 (0.017)	Loss 2.1796 (2.3865)	Acc@1 39.062 (36.932)	Acc@5 76.562 (71.520)
Epoch: [2][20/391]	Time 0.089 (0.090)	Data 0.001 (0.009)	Loss 2.4288 (2.4105)	Acc@1 33.594 (34.747)	Acc@5 70.312 (70.536)
Epoch: [2][30/391]	Time 0.087 (0.090)	Data 0.001 (0.007)	Loss 2.4721 (2.4230)	Acc@1 31.250 (34.199)	Acc@5 60.156 (69.808)
Epoch: [2][40/391]	Time 0.086 (0.089)	Data 0.001 (0.005)	Loss 2.4369 (2.4189)	Acc@1 39.844 (34.527)	Acc@5 72.656 (69.874)
Epoch: [2][50/391]	Time 0.088 (0.089)	Data 0.001 (0.005)	Loss 2.4257 (2.4206)	Acc@1 38.281 (34.482)	Acc@5 69.531 (69.730)
Epoch: [2][60/391]	Time 0.088 (0.088)	Data 0.001 (0.004)	Loss 2.3861 (2.4132)	Acc@1 31.250 (34.465)	Acc@5 71.094 (69.775)
Epoch: [2][70/391]	Time 0.089 (0.088)	Data 0.001 (0.004)	Loss 2.4037 (2.4219)	Acc@1 33.594 (34.441)	Acc@5 71.094 (69.498)
Epoch: [2][80/391]	Time 0.088 (0.088)	Data 0.001 (0.003)	Loss 2.6590 (2.4258)	Acc@1 30.469 (34.394)	Acc@5 64.062 (69.493)
Epoch: [2][90/391]	Time 0.087 (0.088)	Data 0.001 (0.003)	Loss 2.3959 (2.4287)	Acc@1 35.156 (34.229)	Acc@5 74.219 (69.531)
Epoch: [2][100/391]	Time 0.090 (0.088)	Data 0.001 (0.003)	Loss 2.5113 (2.4250)	Acc@1 35.938 (34.445)	Acc@5 67.188 (69.562)
Epoch: [2][110/391]	Time 0.093 (0.088)	Data 0.001 (0.003)	Loss 2.3486 (2.4204)	Acc@1 30.469 (34.481)	Acc@5 68.750 (69.588)
Epoch: [2][120/391]	Time 0.101 (0.089)	Data 0.001 (0.003)	Loss 2.3200 (2.4186)	Acc@1 35.156 (34.620)	Acc@5 70.312 (69.660)
Epoch: [2][130/391]	Time 0.098 (0.089)	Data 0.002 (0.002)	Loss 2.6609 (2.4197)	Acc@1 28.906 (34.506)	Acc@5 64.062 (69.615)
Epoch: [2][140/391]	Time 0.096 (0.090)	Data 0.001 (0.002)	Loss 2.4452 (2.4187)	Acc@1 45.312 (34.558)	Acc@5 71.875 (69.620)
Epoch: [2][150/391]	Time 0.096 (0.090)	Data 0.001 (0.002)	Loss 2.6054 (2.4119)	Acc@1 27.344 (34.685)	Acc@5 65.625 (69.707)
Epoch: [2][160/391]	Time 0.096 (0.090)	Data 0.001 (0.002)	Loss 2.3478 (2.4085)	Acc@1 32.031 (34.700)	Acc@5 71.875 (69.895)
Epoch: [2][170/391]	Time 0.093 (0.090)	Data 0.001 (0.002)	Loss 2.3489 (2.4064)	Acc@1 39.062 (34.690)	Acc@5 69.531 (69.874)
Epoch: [2][180/391]	Time 0.094 (0.091)	Data 0.001 (0.002)	Loss 2.3972 (2.4070)	Acc@1 35.938 (34.759)	Acc@5 69.531 (69.838)
Epoch: [2][190/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.4044 (2.4073)	Acc@1 35.156 (34.788)	Acc@5 71.094 (69.818)
Epoch: [2][200/391]	Time 0.088 (0.091)	Data 0.001 (0.002)	Loss 2.6586 (2.4106)	Acc@1 29.688 (34.725)	Acc@5 62.500 (69.687)
Epoch: [2][210/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.5471 (2.4108)	Acc@1 33.594 (34.782)	Acc@5 70.312 (69.713)
Epoch: [2][220/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.3691 (2.4072)	Acc@1 32.812 (34.859)	Acc@5 68.750 (69.765)
Epoch: [2][230/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.5143 (2.4051)	Acc@1 34.375 (34.916)	Acc@5 64.844 (69.754)
Epoch: [2][240/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.3865 (2.4024)	Acc@1 38.281 (35.046)	Acc@5 67.969 (69.823)
Epoch: [2][250/391]	Time 0.094 (0.091)	Data 0.001 (0.002)	Loss 2.2459 (2.3999)	Acc@1 40.625 (35.119)	Acc@5 70.312 (69.880)
Epoch: [2][260/391]	Time 0.094 (0.091)	Data 0.001 (0.002)	Loss 2.6455 (2.4049)	Acc@1 35.156 (35.087)	Acc@5 64.844 (69.756)
Epoch: [2][270/391]	Time 0.092 (0.091)	Data 0.001 (0.002)	Loss 2.5705 (2.4060)	Acc@1 24.219 (35.055)	Acc@5 64.844 (69.727)
Epoch: [2][280/391]	Time 0.088 (0.091)	Data 0.001 (0.002)	Loss 2.4498 (2.4060)	Acc@1 35.156 (35.009)	Acc@5 68.750 (69.726)
Epoch: [2][290/391]	Time 0.093 (0.091)	Data 0.001 (0.002)	Loss 2.2397 (2.4040)	Acc@1 37.500 (35.068)	Acc@5 75.781 (69.781)
Epoch: [2][300/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.1311 (2.4040)	Acc@1 40.625 (35.078)	Acc@5 73.438 (69.791)
Epoch: [2][310/391]	Time 0.094 (0.091)	Data 0.001 (0.002)	Loss 2.1368 (2.4043)	Acc@1 35.938 (35.036)	Acc@5 76.562 (69.800)
Epoch: [2][320/391]	Time 0.092 (0.091)	Data 0.001 (0.002)	Loss 2.4089 (2.4042)	Acc@1 31.250 (35.008)	Acc@5 67.188 (69.818)
Epoch: [2][330/391]	Time 0.092 (0.091)	Data 0.001 (0.002)	Loss 2.4194 (2.4054)	Acc@1 37.500 (34.972)	Acc@5 64.844 (69.805)
Epoch: [2][340/391]	Time 0.088 (0.091)	Data 0.001 (0.002)	Loss 2.3284 (2.4069)	Acc@1 39.844 (35.005)	Acc@5 70.312 (69.763)
Epoch: [2][350/391]	Time 0.091 (0.091)	Data 0.001 (0.002)	Loss 2.3634 (2.4060)	Acc@1 28.125 (34.996)	Acc@5 70.312 (69.798)
Epoch: [2][360/391]	Time 0.092 (0.091)	Data 0.001 (0.002)	Loss 2.3322 (2.4078)	Acc@1 37.500 (34.966)	Acc@5 69.531 (69.733)
Epoch: [2][370/391]	Time 0.090 (0.091)	Data 0.001 (0.002)	Loss 2.2708 (2.4080)	Acc@1 32.812 (34.941)	Acc@5 73.438 (69.748)
Epoch: [2][380/391]	Time 0.092 (0.091)	Data 0.001 (0.002)	Loss 2.4714 (2.4097)	Acc@1 30.469 (34.902)	Acc@5 65.625 (69.665)
Epoch: [2][390/391]	Time 0.076 (0.091)	Data 0.001 (0.002)	Loss 2.4586 (2.4103)	Acc@1 33.750 (34.878)	Acc@5 68.750 (69.656)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [3][0/391]	Time 0.098 (0.098)	Data 0.191 (0.191)	Loss 2.3536 (2.3536)	Acc@1 38.281 (38.281)	Acc@5 73.438 (73.438)
Epoch: [3][10/391]	Time 0.089 (0.089)	Data 0.001 (0.018)	Loss 2.4746 (2.3787)	Acc@1 32.031 (34.233)	Acc@5 71.094 (70.810)
Epoch: [3][20/391]	Time 0.088 (0.089)	Data 0.001 (0.010)	Loss 2.5498 (2.3858)	Acc@1 33.594 (34.821)	Acc@5 65.625 (71.317)
Epoch: [3][30/391]	Time 0.088 (0.089)	Data 0.001 (0.007)	Loss 2.4534 (2.3949)	Acc@1 38.281 (35.181)	Acc@5 72.656 (70.539)
Epoch: [3][40/391]	Time 0.085 (0.089)	Data 0.001 (0.006)	Loss 2.5269 (2.3874)	Acc@1 35.156 (35.537)	Acc@5 64.844 (70.351)
Epoch: [3][50/391]	Time 0.087 (0.089)	Data 0.001 (0.005)	Loss 2.4850 (2.3904)	Acc@1 37.500 (35.555)	Acc@5 64.844 (70.175)
Epoch: [3][60/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.3501 (2.3983)	Acc@1 36.719 (35.233)	Acc@5 70.312 (70.044)
Epoch: [3][70/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.4093 (2.4055)	Acc@1 31.250 (35.057)	Acc@5 71.875 (69.883)
Epoch: [3][80/391]	Time 0.091 (0.089)	Data 0.001 (0.004)	Loss 2.3584 (2.4060)	Acc@1 41.406 (35.108)	Acc@5 75.000 (70.042)
Epoch: [3][90/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.4415 (2.3996)	Acc@1 32.812 (35.259)	Acc@5 68.750 (70.184)
Epoch: [3][100/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.2354 (2.3972)	Acc@1 34.375 (35.226)	Acc@5 72.656 (70.251)
Epoch: [3][110/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.5341 (2.3963)	Acc@1 36.719 (35.332)	Acc@5 67.969 (70.291)
Epoch: [3][120/391]	Time 0.094 (0.089)	Data 0.001 (0.003)	Loss 2.5504 (2.4017)	Acc@1 33.594 (35.234)	Acc@5 66.406 (70.158)
Epoch: [3][130/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.3029 (2.3986)	Acc@1 42.969 (35.311)	Acc@5 69.531 (70.157)
Epoch: [3][140/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.3850 (2.4022)	Acc@1 30.469 (35.173)	Acc@5 68.750 (70.058)
Epoch: [3][150/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.6012 (2.4066)	Acc@1 34.375 (35.208)	Acc@5 63.281 (69.842)
Epoch: [3][160/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3075 (2.4081)	Acc@1 32.812 (35.132)	Acc@5 71.094 (69.764)
Epoch: [3][170/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.4202 (2.4090)	Acc@1 35.156 (35.015)	Acc@5 70.312 (69.709)
Epoch: [3][180/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2187 (2.4125)	Acc@1 36.719 (34.871)	Acc@5 77.344 (69.631)
Epoch: [3][190/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.4784 (2.4135)	Acc@1 36.719 (34.899)	Acc@5 69.531 (69.613)
Epoch: [3][200/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5610 (2.4167)	Acc@1 31.250 (34.775)	Acc@5 65.625 (69.442)
Epoch: [3][210/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4190 (2.4176)	Acc@1 42.188 (34.805)	Acc@5 73.438 (69.413)
Epoch: [3][220/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5137 (2.4193)	Acc@1 33.594 (34.827)	Acc@5 71.875 (69.418)
Epoch: [3][230/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4938 (2.4207)	Acc@1 34.375 (34.920)	Acc@5 67.969 (69.440)
Epoch: [3][240/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5914 (2.4161)	Acc@1 34.375 (35.033)	Acc@5 64.062 (69.577)
Epoch: [3][250/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4004 (2.4157)	Acc@1 32.812 (34.982)	Acc@5 68.750 (69.634)
Epoch: [3][260/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3360 (2.4131)	Acc@1 32.812 (34.995)	Acc@5 74.219 (69.711)
Epoch: [3][270/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.2968 (2.4118)	Acc@1 30.469 (34.972)	Acc@5 71.875 (69.733)
Epoch: [3][280/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4317 (2.4125)	Acc@1 32.031 (34.967)	Acc@5 67.969 (69.670)
Epoch: [3][290/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.5651 (2.4133)	Acc@1 28.906 (34.939)	Acc@5 67.188 (69.647)
Epoch: [3][300/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3914 (2.4133)	Acc@1 34.375 (34.928)	Acc@5 70.312 (69.671)
Epoch: [3][310/391]	Time 0.096 (0.089)	Data 0.001 (0.002)	Loss 2.2961 (2.4121)	Acc@1 39.844 (34.938)	Acc@5 74.219 (69.697)
Epoch: [3][320/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.5224 (2.4118)	Acc@1 35.156 (34.910)	Acc@5 69.531 (69.736)
Epoch: [3][330/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4688 (2.4123)	Acc@1 35.156 (34.868)	Acc@5 73.438 (69.760)
Epoch: [3][340/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3101 (2.4129)	Acc@1 37.500 (34.874)	Acc@5 70.312 (69.701)
Epoch: [3][350/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2709 (2.4122)	Acc@1 39.844 (34.869)	Acc@5 77.344 (69.723)
Epoch: [3][360/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.4723 (2.4110)	Acc@1 33.594 (34.864)	Acc@5 68.750 (69.761)
Epoch: [3][370/391]	Time 0.084 (0.089)	Data 0.001 (0.002)	Loss 2.2852 (2.4131)	Acc@1 40.625 (34.811)	Acc@5 68.750 (69.714)
Epoch: [3][380/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3935 (2.4110)	Acc@1 39.062 (34.884)	Acc@5 70.312 (69.794)
Epoch: [3][390/391]	Time 0.073 (0.089)	Data 0.001 (0.002)	Loss 2.3949 (2.4122)	Acc@1 36.250 (34.902)	Acc@5 66.250 (69.786)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [4][0/391]	Time 0.098 (0.098)	Data 0.164 (0.164)	Loss 2.2508 (2.2508)	Acc@1 36.719 (36.719)	Acc@5 71.094 (71.094)
Epoch: [4][10/391]	Time 0.085 (0.090)	Data 0.001 (0.016)	Loss 2.3295 (2.3837)	Acc@1 39.844 (35.653)	Acc@5 71.875 (69.815)
Epoch: [4][20/391]	Time 0.094 (0.090)	Data 0.001 (0.009)	Loss 2.3457 (2.4215)	Acc@1 41.406 (35.528)	Acc@5 69.531 (69.494)
Epoch: [4][30/391]	Time 0.089 (0.089)	Data 0.001 (0.006)	Loss 2.4372 (2.4299)	Acc@1 33.594 (35.030)	Acc@5 75.781 (69.355)
Epoch: [4][40/391]	Time 0.089 (0.089)	Data 0.001 (0.005)	Loss 2.3288 (2.4218)	Acc@1 38.281 (35.309)	Acc@5 71.875 (69.760)
Epoch: [4][50/391]	Time 0.089 (0.089)	Data 0.001 (0.004)	Loss 2.3971 (2.4115)	Acc@1 32.812 (35.080)	Acc@5 67.969 (69.975)
Epoch: [4][60/391]	Time 0.096 (0.089)	Data 0.001 (0.004)	Loss 2.6320 (2.4176)	Acc@1 29.688 (34.708)	Acc@5 62.500 (69.467)
Epoch: [4][70/391]	Time 0.086 (0.089)	Data 0.001 (0.003)	Loss 2.3628 (2.4225)	Acc@1 42.188 (34.727)	Acc@5 67.969 (69.355)
Epoch: [4][80/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.1683 (2.4185)	Acc@1 36.719 (34.722)	Acc@5 78.906 (69.512)
Epoch: [4][90/391]	Time 0.086 (0.089)	Data 0.001 (0.003)	Loss 2.4855 (2.4229)	Acc@1 36.719 (34.718)	Acc@5 68.750 (69.402)
Epoch: [4][100/391]	Time 0.088 (0.088)	Data 0.001 (0.003)	Loss 2.2280 (2.4199)	Acc@1 39.062 (34.762)	Acc@5 72.656 (69.516)
Epoch: [4][110/391]	Time 0.088 (0.088)	Data 0.001 (0.003)	Loss 2.3441 (2.4185)	Acc@1 39.844 (34.790)	Acc@5 70.312 (69.510)
Epoch: [4][120/391]	Time 0.090 (0.088)	Data 0.001 (0.003)	Loss 2.5092 (2.4124)	Acc@1 38.281 (34.898)	Acc@5 71.875 (69.686)
Epoch: [4][130/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4260 (2.4086)	Acc@1 35.156 (34.912)	Acc@5 71.094 (69.692)
Epoch: [4][140/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.4413 (2.4049)	Acc@1 36.719 (35.045)	Acc@5 69.531 (69.703)
Epoch: [4][150/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.4948 (2.4077)	Acc@1 30.469 (35.068)	Acc@5 65.625 (69.645)
Epoch: [4][160/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.6269 (2.4093)	Acc@1 29.688 (35.088)	Acc@5 64.062 (69.687)
Epoch: [4][170/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.2426 (2.4075)	Acc@1 37.500 (35.156)	Acc@5 75.781 (69.787)
Epoch: [4][180/391]	Time 0.093 (0.088)	Data 0.001 (0.002)	Loss 2.2707 (2.4058)	Acc@1 40.625 (35.117)	Acc@5 71.094 (69.833)
Epoch: [4][190/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.6544 (2.4042)	Acc@1 29.688 (35.119)	Acc@5 64.844 (69.908)
Epoch: [4][200/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.5214 (2.4052)	Acc@1 31.250 (35.113)	Acc@5 71.094 (69.803)
Epoch: [4][210/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.3361 (2.4057)	Acc@1 41.406 (35.119)	Acc@5 70.312 (69.820)
Epoch: [4][220/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.5266 (2.4087)	Acc@1 38.281 (35.043)	Acc@5 64.844 (69.743)
Epoch: [4][230/391]	Time 0.093 (0.088)	Data 0.001 (0.002)	Loss 2.4110 (2.4108)	Acc@1 32.812 (35.018)	Acc@5 67.969 (69.724)
Epoch: [4][240/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3386 (2.4105)	Acc@1 38.281 (34.971)	Acc@5 73.438 (69.817)
Epoch: [4][250/391]	Time 0.091 (0.088)	Data 0.001 (0.002)	Loss 2.2442 (2.4095)	Acc@1 40.625 (34.938)	Acc@5 75.000 (69.827)
Epoch: [4][260/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3386 (2.4134)	Acc@1 34.375 (34.899)	Acc@5 68.750 (69.711)
Epoch: [4][270/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4857 (2.4115)	Acc@1 34.375 (34.920)	Acc@5 69.531 (69.771)
Epoch: [4][280/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.2783 (2.4129)	Acc@1 36.719 (34.898)	Acc@5 72.656 (69.706)
Epoch: [4][290/391]	Time 0.093 (0.088)	Data 0.001 (0.002)	Loss 2.2899 (2.4093)	Acc@1 37.500 (34.976)	Acc@5 71.094 (69.765)
Epoch: [4][300/391]	Time 0.099 (0.088)	Data 0.001 (0.002)	Loss 2.2750 (2.4084)	Acc@1 39.844 (34.990)	Acc@5 71.094 (69.788)
Epoch: [4][310/391]	Time 0.091 (0.088)	Data 0.001 (0.002)	Loss 2.5120 (2.4072)	Acc@1 34.375 (35.048)	Acc@5 66.406 (69.805)
Epoch: [4][320/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4730 (2.4082)	Acc@1 39.062 (35.108)	Acc@5 64.062 (69.750)
Epoch: [4][330/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.0859 (2.4055)	Acc@1 40.625 (35.185)	Acc@5 76.562 (69.817)
Epoch: [4][340/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3027 (2.4039)	Acc@1 39.062 (35.195)	Acc@5 71.875 (69.859)
Epoch: [4][350/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.1998 (2.4033)	Acc@1 38.281 (35.136)	Acc@5 76.562 (69.863)
Epoch: [4][360/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.5353 (2.4025)	Acc@1 34.375 (35.141)	Acc@5 63.281 (69.910)
Epoch: [4][370/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.5975 (2.4038)	Acc@1 32.031 (35.139)	Acc@5 64.062 (69.856)
Epoch: [4][380/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4117 (2.4047)	Acc@1 35.156 (35.095)	Acc@5 68.750 (69.829)
Epoch: [4][390/391]	Time 0.076 (0.088)	Data 0.001 (0.002)	Loss 2.2866 (2.4036)	Acc@1 41.250 (35.162)	Acc@5 76.250 (69.862)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [5][0/391]	Time 0.096 (0.096)	Data 0.164 (0.164)	Loss 2.1649 (2.1649)	Acc@1 42.188 (42.188)	Acc@5 73.438 (73.438)
Epoch: [5][10/391]	Time 0.088 (0.091)	Data 0.001 (0.016)	Loss 2.4888 (2.3972)	Acc@1 32.812 (34.943)	Acc@5 64.062 (69.247)
Epoch: [5][20/391]	Time 0.087 (0.089)	Data 0.001 (0.009)	Loss 2.1448 (2.3726)	Acc@1 42.969 (35.231)	Acc@5 73.438 (70.573)
Epoch: [5][30/391]	Time 0.088 (0.089)	Data 0.002 (0.006)	Loss 2.2444 (2.3968)	Acc@1 38.281 (34.476)	Acc@5 71.875 (70.464)
Epoch: [5][40/391]	Time 0.091 (0.089)	Data 0.001 (0.005)	Loss 2.3153 (2.4036)	Acc@1 37.500 (34.394)	Acc@5 70.312 (70.427)
Epoch: [5][50/391]	Time 0.088 (0.089)	Data 0.001 (0.004)	Loss 2.2395 (2.3904)	Acc@1 41.406 (34.850)	Acc@5 73.438 (70.512)
Epoch: [5][60/391]	Time 0.089 (0.089)	Data 0.001 (0.004)	Loss 2.5906 (2.4020)	Acc@1 30.469 (35.041)	Acc@5 69.531 (70.223)
Epoch: [5][70/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.5124 (2.3970)	Acc@1 28.906 (35.145)	Acc@5 60.156 (70.037)
Epoch: [5][80/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.3331 (2.3901)	Acc@1 35.938 (35.147)	Acc@5 71.094 (70.303)
Epoch: [5][90/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.4502 (2.3915)	Acc@1 34.375 (35.148)	Acc@5 68.750 (70.330)
Epoch: [5][100/391]	Time 0.091 (0.088)	Data 0.001 (0.003)	Loss 2.4989 (2.3984)	Acc@1 32.031 (34.986)	Acc@5 69.531 (70.297)
Epoch: [5][110/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.2552 (2.3940)	Acc@1 37.500 (35.100)	Acc@5 71.094 (70.334)
Epoch: [5][120/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.1853 (2.3924)	Acc@1 36.719 (35.105)	Acc@5 73.438 (70.325)
Epoch: [5][130/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4959 (2.3920)	Acc@1 34.375 (35.061)	Acc@5 69.531 (70.235)
Epoch: [5][140/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.5371 (2.3926)	Acc@1 32.031 (35.095)	Acc@5 64.844 (70.229)
Epoch: [5][150/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.1720 (2.3922)	Acc@1 35.938 (35.048)	Acc@5 75.781 (70.302)
Epoch: [5][160/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4127 (2.3880)	Acc@1 36.719 (35.176)	Acc@5 67.188 (70.346)
Epoch: [5][170/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.5225 (2.3933)	Acc@1 34.375 (35.097)	Acc@5 62.500 (70.217)
Epoch: [5][180/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3393 (2.3921)	Acc@1 37.500 (35.152)	Acc@5 71.094 (70.218)
Epoch: [5][190/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3480 (2.3900)	Acc@1 29.688 (35.246)	Acc@5 69.531 (70.243)
Epoch: [5][200/391]	Time 0.091 (0.088)	Data 0.001 (0.002)	Loss 2.3844 (2.3887)	Acc@1 37.500 (35.261)	Acc@5 67.188 (70.235)
Epoch: [5][210/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.6304 (2.3932)	Acc@1 33.594 (35.260)	Acc@5 67.188 (70.161)
Epoch: [5][220/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.2358 (2.3935)	Acc@1 42.969 (35.255)	Acc@5 70.312 (70.100)
Epoch: [5][230/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.3487 (2.3900)	Acc@1 35.156 (35.305)	Acc@5 75.000 (70.235)
Epoch: [5][240/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.5930 (2.3889)	Acc@1 28.906 (35.325)	Acc@5 60.156 (70.270)
Epoch: [5][250/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.2635 (2.3897)	Acc@1 39.844 (35.303)	Acc@5 73.438 (70.266)
Epoch: [5][260/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3294 (2.3910)	Acc@1 33.594 (35.279)	Acc@5 73.438 (70.238)
Epoch: [5][270/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.5950 (2.3920)	Acc@1 32.031 (35.272)	Acc@5 64.062 (70.214)
Epoch: [5][280/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.2493 (2.3942)	Acc@1 34.375 (35.178)	Acc@5 75.781 (70.187)
Epoch: [5][290/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.3893 (2.3954)	Acc@1 35.938 (35.170)	Acc@5 67.188 (70.135)
Epoch: [5][300/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.4995 (2.3937)	Acc@1 28.125 (35.206)	Acc@5 69.531 (70.157)
Epoch: [5][310/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3716 (2.3932)	Acc@1 32.812 (35.239)	Acc@5 75.781 (70.167)
Epoch: [5][320/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.4156 (2.3960)	Acc@1 35.156 (35.164)	Acc@5 70.312 (70.098)
Epoch: [5][330/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.3425 (2.3958)	Acc@1 37.500 (35.152)	Acc@5 75.781 (70.135)
Epoch: [5][340/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3423 (2.3950)	Acc@1 35.938 (35.145)	Acc@5 68.750 (70.141)
Epoch: [5][350/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.2704 (2.3932)	Acc@1 40.625 (35.138)	Acc@5 73.438 (70.172)
Epoch: [5][360/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4060 (2.3928)	Acc@1 32.812 (35.189)	Acc@5 70.312 (70.157)
Epoch: [5][370/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3728 (2.3916)	Acc@1 33.594 (35.205)	Acc@5 74.219 (70.192)
Epoch: [5][380/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3262 (2.3911)	Acc@1 38.281 (35.257)	Acc@5 66.406 (70.175)
Epoch: [5][390/391]	Time 0.072 (0.088)	Data 0.001 (0.002)	Loss 2.2113 (2.3915)	Acc@1 30.000 (35.264)	Acc@5 76.250 (70.138)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [6][0/391]	Time 0.106 (0.106)	Data 0.189 (0.189)	Loss 2.2394 (2.2394)	Acc@1 42.969 (42.969)	Acc@5 74.219 (74.219)
Epoch: [6][10/391]	Time 0.091 (0.093)	Data 0.001 (0.018)	Loss 2.4880 (2.3715)	Acc@1 35.156 (36.293)	Acc@5 65.625 (69.531)
Epoch: [6][20/391]	Time 0.090 (0.093)	Data 0.001 (0.010)	Loss 2.5141 (2.3922)	Acc@1 32.031 (35.900)	Acc@5 67.969 (70.201)
Epoch: [6][30/391]	Time 0.091 (0.092)	Data 0.001 (0.007)	Loss 2.3493 (2.3944)	Acc@1 32.812 (35.459)	Acc@5 73.438 (69.960)
Epoch: [6][40/391]	Time 0.097 (0.092)	Data 0.001 (0.006)	Loss 2.2078 (2.3923)	Acc@1 40.625 (35.671)	Acc@5 73.438 (70.160)
Epoch: [6][50/391]	Time 0.098 (0.092)	Data 0.001 (0.005)	Loss 2.3212 (2.4024)	Acc@1 38.281 (35.110)	Acc@5 71.094 (70.021)
Epoch: [6][60/391]	Time 0.092 (0.092)	Data 0.001 (0.004)	Loss 2.3031 (2.4037)	Acc@1 36.719 (35.207)	Acc@5 69.531 (69.826)
Epoch: [6][70/391]	Time 0.092 (0.092)	Data 0.001 (0.004)	Loss 2.3324 (2.3937)	Acc@1 31.250 (35.299)	Acc@5 74.219 (70.048)
Epoch: [6][80/391]	Time 0.096 (0.092)	Data 0.001 (0.004)	Loss 2.2844 (2.3902)	Acc@1 35.156 (35.282)	Acc@5 73.438 (69.956)
Epoch: [6][90/391]	Time 0.092 (0.092)	Data 0.001 (0.003)	Loss 2.2158 (2.3872)	Acc@1 42.969 (35.362)	Acc@5 68.750 (69.935)
Epoch: [6][100/391]	Time 0.091 (0.092)	Data 0.001 (0.003)	Loss 2.3038 (2.3814)	Acc@1 43.750 (35.520)	Acc@5 74.219 (70.227)
Epoch: [6][110/391]	Time 0.097 (0.092)	Data 0.001 (0.003)	Loss 2.4895 (2.3813)	Acc@1 38.281 (35.536)	Acc@5 67.188 (70.249)
Epoch: [6][120/391]	Time 0.092 (0.092)	Data 0.001 (0.003)	Loss 2.2725 (2.3843)	Acc@1 37.500 (35.660)	Acc@5 71.094 (70.119)
Epoch: [6][130/391]	Time 0.095 (0.092)	Data 0.001 (0.003)	Loss 2.4537 (2.3891)	Acc@1 32.031 (35.615)	Acc@5 71.875 (70.056)
Epoch: [6][140/391]	Time 0.088 (0.092)	Data 0.001 (0.003)	Loss 2.5526 (2.3915)	Acc@1 24.219 (35.455)	Acc@5 67.969 (69.908)
Epoch: [6][150/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.3718 (2.3886)	Acc@1 40.625 (35.534)	Acc@5 71.094 (69.966)
Epoch: [6][160/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.2058 (2.3843)	Acc@1 37.500 (35.520)	Acc@5 73.438 (70.118)
Epoch: [6][170/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.3137 (2.3879)	Acc@1 41.406 (35.485)	Acc@5 72.656 (69.952)
Epoch: [6][180/391]	Time 0.099 (0.092)	Data 0.002 (0.002)	Loss 2.5417 (2.3909)	Acc@1 30.469 (35.407)	Acc@5 67.188 (69.915)
Epoch: [6][190/391]	Time 0.094 (0.092)	Data 0.001 (0.002)	Loss 2.3625 (2.3924)	Acc@1 36.719 (35.365)	Acc@5 71.875 (69.891)
Epoch: [6][200/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.2256 (2.3927)	Acc@1 39.062 (35.436)	Acc@5 72.656 (69.916)
Epoch: [6][210/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.3915 (2.3906)	Acc@1 40.625 (35.545)	Acc@5 74.219 (69.983)
Epoch: [6][220/391]	Time 0.095 (0.092)	Data 0.001 (0.002)	Loss 2.2910 (2.3905)	Acc@1 39.844 (35.570)	Acc@5 72.656 (70.033)
Epoch: [6][230/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.4801 (2.3908)	Acc@1 33.594 (35.501)	Acc@5 64.062 (70.035)
Epoch: [6][240/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.5269 (2.3900)	Acc@1 28.906 (35.490)	Acc@5 64.062 (70.008)
Epoch: [6][250/391]	Time 0.088 (0.092)	Data 0.001 (0.002)	Loss 2.3033 (2.3887)	Acc@1 38.281 (35.511)	Acc@5 72.656 (70.020)
Epoch: [6][260/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.5470 (2.3852)	Acc@1 36.719 (35.572)	Acc@5 71.094 (70.160)
Epoch: [6][270/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.4465 (2.3831)	Acc@1 33.594 (35.606)	Acc@5 66.406 (70.263)
Epoch: [6][280/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.3636 (2.3830)	Acc@1 36.719 (35.673)	Acc@5 67.188 (70.260)
Epoch: [6][290/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.3626 (2.3823)	Acc@1 32.031 (35.631)	Acc@5 71.094 (70.280)
Epoch: [6][300/391]	Time 0.089 (0.092)	Data 0.001 (0.002)	Loss 2.4648 (2.3824)	Acc@1 32.031 (35.616)	Acc@5 67.969 (70.232)
Epoch: [6][310/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.2517 (2.3811)	Acc@1 42.188 (35.724)	Acc@5 70.312 (70.240)
Epoch: [6][320/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.3760 (2.3822)	Acc@1 35.156 (35.675)	Acc@5 72.656 (70.222)
Epoch: [6][330/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.3605 (2.3836)	Acc@1 39.062 (35.647)	Acc@5 67.969 (70.249)
Epoch: [6][340/391]	Time 0.096 (0.092)	Data 0.001 (0.002)	Loss 2.5547 (2.3848)	Acc@1 26.562 (35.640)	Acc@5 67.969 (70.248)
Epoch: [6][350/391]	Time 0.094 (0.092)	Data 0.001 (0.002)	Loss 2.4976 (2.3845)	Acc@1 34.375 (35.677)	Acc@5 70.312 (70.268)
Epoch: [6][360/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.4473 (2.3843)	Acc@1 35.156 (35.684)	Acc@5 72.656 (70.332)
Epoch: [6][370/391]	Time 0.095 (0.092)	Data 0.001 (0.002)	Loss 2.2920 (2.3836)	Acc@1 35.938 (35.723)	Acc@5 75.781 (70.369)
Epoch: [6][380/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.3845 (2.3837)	Acc@1 41.406 (35.743)	Acc@5 78.125 (70.403)
Epoch: [6][390/391]	Time 0.077 (0.092)	Data 0.001 (0.002)	Loss 2.1412 (2.3824)	Acc@1 40.000 (35.754)	Acc@5 78.750 (70.446)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [7][0/391]	Time 0.100 (0.100)	Data 0.164 (0.164)	Loss 2.6805 (2.6805)	Acc@1 32.031 (32.031)	Acc@5 65.625 (65.625)
Epoch: [7][10/391]	Time 0.090 (0.091)	Data 0.001 (0.016)	Loss 2.1039 (2.3627)	Acc@1 43.750 (35.795)	Acc@5 78.125 (70.455)
Epoch: [7][20/391]	Time 0.089 (0.090)	Data 0.001 (0.009)	Loss 2.5043 (2.3355)	Acc@1 33.594 (36.124)	Acc@5 66.406 (71.057)
Epoch: [7][30/391]	Time 0.088 (0.089)	Data 0.001 (0.006)	Loss 2.3824 (2.3560)	Acc@1 39.062 (35.786)	Acc@5 69.531 (70.287)
Epoch: [7][40/391]	Time 0.089 (0.089)	Data 0.002 (0.005)	Loss 2.4422 (2.3606)	Acc@1 38.281 (35.918)	Acc@5 70.312 (70.522)
Epoch: [7][50/391]	Time 0.089 (0.089)	Data 0.001 (0.004)	Loss 2.2002 (2.3452)	Acc@1 35.938 (36.198)	Acc@5 76.562 (71.032)
Epoch: [7][60/391]	Time 0.088 (0.089)	Data 0.001 (0.004)	Loss 2.1876 (2.3509)	Acc@1 39.062 (35.989)	Acc@5 76.562 (70.863)
Epoch: [7][70/391]	Time 0.088 (0.089)	Data 0.001 (0.004)	Loss 2.4364 (2.3518)	Acc@1 36.719 (36.015)	Acc@5 66.406 (70.819)
Epoch: [7][80/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.5047 (2.3563)	Acc@1 36.719 (35.860)	Acc@5 68.750 (70.882)
Epoch: [7][90/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.4682 (2.3651)	Acc@1 35.156 (35.714)	Acc@5 65.625 (70.630)
Epoch: [7][100/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.2026 (2.3686)	Acc@1 45.312 (35.605)	Acc@5 78.906 (70.537)
Epoch: [7][110/391]	Time 0.091 (0.089)	Data 0.001 (0.003)	Loss 2.2820 (2.3736)	Acc@1 40.625 (35.374)	Acc@5 75.781 (70.425)
Epoch: [7][120/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.4542 (2.3685)	Acc@1 32.812 (35.602)	Acc@5 65.625 (70.538)
Epoch: [7][130/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.0983 (2.3696)	Acc@1 42.969 (35.693)	Acc@5 75.781 (70.533)
Epoch: [7][140/391]	Time 0.094 (0.089)	Data 0.002 (0.002)	Loss 2.3509 (2.3657)	Acc@1 32.031 (35.793)	Acc@5 72.656 (70.601)
Epoch: [7][150/391]	Time 0.094 (0.089)	Data 0.001 (0.002)	Loss 2.4155 (2.3680)	Acc@1 31.250 (35.694)	Acc@5 71.094 (70.633)
Epoch: [7][160/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.5291 (2.3724)	Acc@1 33.594 (35.641)	Acc@5 67.188 (70.613)
Epoch: [7][170/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2395 (2.3696)	Acc@1 38.281 (35.645)	Acc@5 71.875 (70.660)
Epoch: [7][180/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4588 (2.3685)	Acc@1 29.688 (35.648)	Acc@5 67.188 (70.628)
Epoch: [7][190/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2408 (2.3668)	Acc@1 39.062 (35.733)	Acc@5 76.562 (70.644)
Epoch: [7][200/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.1536 (2.3654)	Acc@1 37.500 (35.755)	Acc@5 78.125 (70.693)
Epoch: [7][210/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5008 (2.3669)	Acc@1 34.375 (35.730)	Acc@5 71.875 (70.661)
Epoch: [7][220/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.2424 (2.3686)	Acc@1 41.406 (35.655)	Acc@5 78.125 (70.627)
Epoch: [7][230/391]	Time 0.097 (0.089)	Data 0.001 (0.002)	Loss 2.4154 (2.3716)	Acc@1 33.594 (35.667)	Acc@5 71.094 (70.526)
Epoch: [7][240/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3149 (2.3720)	Acc@1 35.938 (35.753)	Acc@5 70.312 (70.513)
Epoch: [7][250/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4977 (2.3702)	Acc@1 28.906 (35.732)	Acc@5 71.875 (70.533)
Epoch: [7][260/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4505 (2.3729)	Acc@1 34.375 (35.674)	Acc@5 70.312 (70.552)
Epoch: [7][270/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3121 (2.3741)	Acc@1 35.938 (35.609)	Acc@5 72.656 (70.520)
Epoch: [7][280/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3880 (2.3747)	Acc@1 37.500 (35.629)	Acc@5 71.094 (70.463)
Epoch: [7][290/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3852 (2.3761)	Acc@1 32.812 (35.602)	Acc@5 70.312 (70.447)
Epoch: [7][300/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4224 (2.3759)	Acc@1 35.156 (35.592)	Acc@5 66.406 (70.445)
Epoch: [7][310/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4967 (2.3757)	Acc@1 36.719 (35.568)	Acc@5 65.625 (70.478)
Epoch: [7][320/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4129 (2.3762)	Acc@1 39.062 (35.575)	Acc@5 69.531 (70.424)
Epoch: [7][330/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.3922 (2.3754)	Acc@1 32.812 (35.583)	Acc@5 71.094 (70.421)
Epoch: [7][340/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2415 (2.3781)	Acc@1 38.281 (35.594)	Acc@5 73.438 (70.335)
Epoch: [7][350/391]	Time 0.088 (0.089)	Data 0.002 (0.002)	Loss 2.3292 (2.3810)	Acc@1 32.031 (35.488)	Acc@5 71.094 (70.337)
Epoch: [7][360/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3767 (2.3809)	Acc@1 36.719 (35.457)	Acc@5 68.750 (70.319)
Epoch: [7][370/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4419 (2.3819)	Acc@1 39.844 (35.422)	Acc@5 66.406 (70.272)
Epoch: [7][380/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3876 (2.3819)	Acc@1 41.406 (35.447)	Acc@5 71.094 (70.269)
Epoch: [7][390/391]	Time 0.074 (0.089)	Data 0.001 (0.002)	Loss 2.3011 (2.3839)	Acc@1 33.750 (35.408)	Acc@5 70.000 (70.208)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [8][0/391]	Time 0.104 (0.104)	Data 0.182 (0.182)	Loss 2.7557 (2.7557)	Acc@1 23.438 (23.438)	Acc@5 65.625 (65.625)
Epoch: [8][10/391]	Time 0.090 (0.094)	Data 0.001 (0.018)	Loss 2.4499 (2.4656)	Acc@1 33.594 (32.812)	Acc@5 70.312 (69.105)
Epoch: [8][20/391]	Time 0.092 (0.093)	Data 0.001 (0.010)	Loss 2.3162 (2.3806)	Acc@1 40.625 (34.821)	Acc@5 71.094 (70.833)
Epoch: [8][30/391]	Time 0.091 (0.093)	Data 0.001 (0.007)	Loss 2.6296 (2.3578)	Acc@1 33.594 (36.164)	Acc@5 64.062 (70.943)
Epoch: [8][40/391]	Time 0.089 (0.093)	Data 0.001 (0.006)	Loss 2.4497 (2.3505)	Acc@1 29.688 (35.938)	Acc@5 69.531 (71.284)
Epoch: [8][50/391]	Time 0.091 (0.092)	Data 0.001 (0.005)	Loss 2.3903 (2.3446)	Acc@1 41.406 (36.213)	Acc@5 68.750 (71.293)
Epoch: [8][60/391]	Time 0.091 (0.092)	Data 0.001 (0.004)	Loss 2.2735 (2.3550)	Acc@1 33.594 (35.848)	Acc@5 73.438 (70.927)
Epoch: [8][70/391]	Time 0.090 (0.092)	Data 0.001 (0.004)	Loss 2.3584 (2.3633)	Acc@1 36.719 (35.706)	Acc@5 70.312 (70.709)
Epoch: [8][80/391]	Time 0.091 (0.092)	Data 0.001 (0.003)	Loss 2.3790 (2.3618)	Acc@1 32.031 (35.658)	Acc@5 70.312 (70.640)
Epoch: [8][90/391]	Time 0.089 (0.092)	Data 0.001 (0.003)	Loss 2.2376 (2.3658)	Acc@1 37.500 (35.577)	Acc@5 75.781 (70.690)
Epoch: [8][100/391]	Time 0.092 (0.092)	Data 0.001 (0.003)	Loss 2.2318 (2.3645)	Acc@1 44.531 (35.628)	Acc@5 69.531 (70.637)
Epoch: [8][110/391]	Time 0.091 (0.092)	Data 0.001 (0.003)	Loss 2.4229 (2.3703)	Acc@1 35.938 (35.649)	Acc@5 71.094 (70.432)
Epoch: [8][120/391]	Time 0.093 (0.092)	Data 0.001 (0.003)	Loss 2.3966 (2.3737)	Acc@1 30.469 (35.550)	Acc@5 72.656 (70.345)
Epoch: [8][130/391]	Time 0.091 (0.092)	Data 0.001 (0.003)	Loss 2.4467 (2.3719)	Acc@1 35.938 (35.633)	Acc@5 71.875 (70.402)
Epoch: [8][140/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.2451 (2.3766)	Acc@1 36.719 (35.522)	Acc@5 75.000 (70.312)
Epoch: [8][150/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.4321 (2.3738)	Acc@1 35.938 (35.710)	Acc@5 69.531 (70.369)
Epoch: [8][160/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.5074 (2.3770)	Acc@1 37.500 (35.700)	Acc@5 71.875 (70.351)
Epoch: [8][170/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.1148 (2.3768)	Acc@1 46.094 (35.810)	Acc@5 78.906 (70.349)
Epoch: [8][180/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.3511 (2.3745)	Acc@1 39.844 (35.860)	Acc@5 70.312 (70.364)
Epoch: [8][190/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.6935 (2.3775)	Acc@1 28.906 (35.704)	Acc@5 63.281 (70.317)
Epoch: [8][200/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.3885 (2.3775)	Acc@1 35.156 (35.766)	Acc@5 69.531 (70.375)
Epoch: [8][210/391]	Time 0.099 (0.092)	Data 0.001 (0.002)	Loss 2.0521 (2.3737)	Acc@1 48.438 (35.897)	Acc@5 77.344 (70.472)
Epoch: [8][220/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.1703 (2.3729)	Acc@1 43.750 (35.976)	Acc@5 71.875 (70.496)
Epoch: [8][230/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.2862 (2.3688)	Acc@1 36.719 (36.025)	Acc@5 72.656 (70.641)
Epoch: [8][240/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.0686 (2.3674)	Acc@1 42.969 (36.035)	Acc@5 73.438 (70.659)
Epoch: [8][250/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.3014 (2.3641)	Acc@1 35.938 (36.065)	Acc@5 70.312 (70.745)
Epoch: [8][260/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.3724 (2.3657)	Acc@1 37.500 (36.054)	Acc@5 76.562 (70.702)
Epoch: [8][270/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.6757 (2.3631)	Acc@1 32.031 (36.099)	Acc@5 68.750 (70.788)
Epoch: [8][280/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.4209 (2.3624)	Acc@1 31.250 (36.063)	Acc@5 72.656 (70.821)
Epoch: [8][290/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.3029 (2.3646)	Acc@1 38.281 (36.040)	Acc@5 67.188 (70.745)
Epoch: [8][300/391]	Time 0.089 (0.092)	Data 0.001 (0.002)	Loss 2.2080 (2.3640)	Acc@1 38.281 (36.039)	Acc@5 68.750 (70.723)
Epoch: [8][310/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.1508 (2.3649)	Acc@1 39.062 (36.013)	Acc@5 82.812 (70.684)
Epoch: [8][320/391]	Time 0.088 (0.092)	Data 0.001 (0.002)	Loss 2.2519 (2.3670)	Acc@1 36.719 (35.962)	Acc@5 74.219 (70.643)
Epoch: [8][330/391]	Time 0.094 (0.092)	Data 0.001 (0.002)	Loss 2.3978 (2.3689)	Acc@1 35.938 (35.926)	Acc@5 67.969 (70.624)
Epoch: [8][340/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.3071 (2.3709)	Acc@1 37.500 (35.894)	Acc@5 72.656 (70.617)
Epoch: [8][350/391]	Time 0.099 (0.092)	Data 0.002 (0.002)	Loss 2.6842 (2.3708)	Acc@1 31.250 (35.897)	Acc@5 60.938 (70.609)
Epoch: [8][360/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.4307 (2.3726)	Acc@1 32.031 (35.808)	Acc@5 67.188 (70.568)
Epoch: [8][370/391]	Time 0.100 (0.092)	Data 0.002 (0.002)	Loss 2.4289 (2.3720)	Acc@1 36.719 (35.809)	Acc@5 69.531 (70.616)
Epoch: [8][380/391]	Time 0.095 (0.092)	Data 0.001 (0.002)	Loss 2.3173 (2.3706)	Acc@1 35.938 (35.804)	Acc@5 68.750 (70.659)
Epoch: [8][390/391]	Time 0.076 (0.092)	Data 0.001 (0.002)	Loss 2.4169 (2.3713)	Acc@1 42.500 (35.810)	Acc@5 70.000 (70.634)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [9][0/391]	Time 0.097 (0.097)	Data 0.167 (0.167)	Loss 2.1248 (2.1248)	Acc@1 40.625 (40.625)	Acc@5 78.906 (78.906)
Epoch: [9][10/391]	Time 0.094 (0.090)	Data 0.001 (0.016)	Loss 2.2646 (2.2852)	Acc@1 34.375 (37.074)	Acc@5 76.562 (72.372)
Epoch: [9][20/391]	Time 0.090 (0.090)	Data 0.001 (0.009)	Loss 2.4265 (2.3351)	Acc@1 35.938 (36.086)	Acc@5 73.438 (71.243)
Epoch: [9][30/391]	Time 0.095 (0.090)	Data 0.001 (0.007)	Loss 2.3478 (2.3413)	Acc@1 36.719 (36.164)	Acc@5 76.562 (71.069)
Epoch: [9][40/391]	Time 0.090 (0.089)	Data 0.001 (0.005)	Loss 2.1746 (2.3479)	Acc@1 42.969 (36.433)	Acc@5 73.438 (70.884)
Epoch: [9][50/391]	Time 0.094 (0.089)	Data 0.001 (0.004)	Loss 2.2111 (2.3572)	Acc@1 40.625 (36.275)	Acc@5 71.094 (70.818)
Epoch: [9][60/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.4016 (2.3704)	Acc@1 33.594 (35.797)	Acc@5 69.531 (70.543)
Epoch: [9][70/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.4457 (2.3720)	Acc@1 32.812 (35.717)	Acc@5 67.188 (70.544)
Epoch: [9][80/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.2201 (2.3695)	Acc@1 40.625 (35.831)	Acc@5 73.438 (70.727)
Epoch: [9][90/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.2068 (2.3736)	Acc@1 38.281 (35.731)	Acc@5 73.438 (70.630)
Epoch: [9][100/391]	Time 0.092 (0.089)	Data 0.001 (0.003)	Loss 2.5115 (2.3659)	Acc@1 35.938 (35.945)	Acc@5 64.844 (70.668)
Epoch: [9][110/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.3130 (2.3680)	Acc@1 34.375 (35.825)	Acc@5 70.312 (70.552)
Epoch: [9][120/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.2653 (2.3656)	Acc@1 41.406 (35.828)	Acc@5 71.875 (70.603)
Epoch: [9][130/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.0678 (2.3613)	Acc@1 42.969 (35.848)	Acc@5 78.125 (70.652)
Epoch: [9][140/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3743 (2.3626)	Acc@1 40.625 (35.910)	Acc@5 70.312 (70.689)
Epoch: [9][150/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.2406 (2.3663)	Acc@1 37.500 (35.834)	Acc@5 74.219 (70.509)
Epoch: [9][160/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.5825 (2.3631)	Acc@1 30.469 (35.908)	Acc@5 66.406 (70.589)
Epoch: [9][170/391]	Time 0.096 (0.089)	Data 0.001 (0.002)	Loss 2.5339 (2.3654)	Acc@1 31.250 (35.810)	Acc@5 67.969 (70.568)
Epoch: [9][180/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2346 (2.3694)	Acc@1 35.156 (35.709)	Acc@5 74.219 (70.515)
Epoch: [9][190/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.3767 (2.3706)	Acc@1 33.594 (35.663)	Acc@5 72.656 (70.501)
Epoch: [9][200/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2283 (2.3669)	Acc@1 42.188 (35.774)	Acc@5 77.344 (70.612)
Epoch: [9][210/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3807 (2.3664)	Acc@1 33.594 (35.775)	Acc@5 74.219 (70.661)
Epoch: [9][220/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4004 (2.3650)	Acc@1 31.250 (35.814)	Acc@5 71.094 (70.761)
Epoch: [9][230/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4099 (2.3641)	Acc@1 30.469 (35.802)	Acc@5 71.875 (70.783)
Epoch: [9][240/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1638 (2.3615)	Acc@1 37.500 (35.915)	Acc@5 76.562 (70.922)
Epoch: [9][250/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2751 (2.3641)	Acc@1 34.375 (35.863)	Acc@5 74.219 (70.904)
Epoch: [9][260/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.5349 (2.3683)	Acc@1 32.812 (35.800)	Acc@5 62.500 (70.759)
Epoch: [9][270/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2587 (2.3687)	Acc@1 33.594 (35.762)	Acc@5 75.781 (70.791)
Epoch: [9][280/391]	Time 0.091 (0.089)	Data 0.002 (0.002)	Loss 2.4013 (2.3700)	Acc@1 39.062 (35.787)	Acc@5 67.188 (70.763)
Epoch: [9][290/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.3899 (2.3707)	Acc@1 36.719 (35.806)	Acc@5 71.094 (70.737)
Epoch: [9][300/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.5332 (2.3716)	Acc@1 28.125 (35.740)	Acc@5 67.969 (70.743)
Epoch: [9][310/391]	Time 0.096 (0.089)	Data 0.001 (0.002)	Loss 2.2924 (2.3722)	Acc@1 37.500 (35.769)	Acc@5 65.625 (70.694)
Epoch: [9][320/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.3225 (2.3726)	Acc@1 36.719 (35.770)	Acc@5 72.656 (70.670)
Epoch: [9][330/391]	Time 0.091 (0.089)	Data 0.002 (0.002)	Loss 2.3115 (2.3706)	Acc@1 35.938 (35.758)	Acc@5 71.875 (70.700)
Epoch: [9][340/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.2915 (2.3685)	Acc@1 39.062 (35.798)	Acc@5 67.969 (70.713)
Epoch: [9][350/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4160 (2.3705)	Acc@1 35.156 (35.773)	Acc@5 69.531 (70.684)
Epoch: [9][360/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2751 (2.3700)	Acc@1 35.938 (35.780)	Acc@5 67.969 (70.665)
Epoch: [9][370/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2875 (2.3704)	Acc@1 37.500 (35.786)	Acc@5 68.750 (70.643)
Epoch: [9][380/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4322 (2.3679)	Acc@1 30.469 (35.808)	Acc@5 69.531 (70.677)
Epoch: [9][390/391]	Time 0.075 (0.089)	Data 0.001 (0.002)	Loss 2.3483 (2.3691)	Acc@1 37.500 (35.796)	Acc@5 68.750 (70.648)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [10][0/391]	Time 0.099 (0.099)	Data 0.158 (0.158)	Loss 2.2829 (2.2829)	Acc@1 36.719 (36.719)	Acc@5 75.000 (75.000)
Epoch: [10][10/391]	Time 0.090 (0.091)	Data 0.001 (0.015)	Loss 2.2064 (2.3046)	Acc@1 37.500 (37.145)	Acc@5 75.000 (73.793)
Epoch: [10][20/391]	Time 0.092 (0.090)	Data 0.001 (0.009)	Loss 2.4243 (2.3417)	Acc@1 37.500 (36.830)	Acc@5 66.406 (71.949)
Epoch: [10][30/391]	Time 0.091 (0.090)	Data 0.001 (0.006)	Loss 2.4108 (2.3632)	Acc@1 36.719 (36.265)	Acc@5 73.438 (71.673)
Epoch: [10][40/391]	Time 0.088 (0.090)	Data 0.001 (0.005)	Loss 2.4488 (2.3664)	Acc@1 37.500 (36.300)	Acc@5 68.750 (71.818)
Epoch: [10][50/391]	Time 0.092 (0.089)	Data 0.001 (0.004)	Loss 2.3235 (2.3549)	Acc@1 35.156 (36.183)	Acc@5 69.531 (71.982)
Epoch: [10][60/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.4087 (2.3500)	Acc@1 38.281 (36.386)	Acc@5 65.625 (71.862)
Epoch: [10][70/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.2831 (2.3491)	Acc@1 35.938 (36.488)	Acc@5 72.656 (71.853)
Epoch: [10][80/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.4500 (2.3567)	Acc@1 32.031 (36.227)	Acc@5 69.531 (71.730)
Epoch: [10][90/391]	Time 0.091 (0.089)	Data 0.001 (0.003)	Loss 2.4821 (2.3595)	Acc@1 31.250 (36.264)	Acc@5 67.188 (71.566)
Epoch: [10][100/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.3759 (2.3599)	Acc@1 33.594 (36.170)	Acc@5 71.875 (71.535)
Epoch: [10][110/391]	Time 0.094 (0.089)	Data 0.001 (0.003)	Loss 2.3002 (2.3592)	Acc@1 35.156 (36.163)	Acc@5 69.531 (71.418)
Epoch: [10][120/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.2475 (2.3593)	Acc@1 39.062 (36.118)	Acc@5 73.438 (71.326)
Epoch: [10][130/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.5074 (2.3581)	Acc@1 34.375 (36.134)	Acc@5 70.312 (71.368)
Epoch: [10][140/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3149 (2.3570)	Acc@1 29.688 (36.043)	Acc@5 72.656 (71.354)
Epoch: [10][150/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4663 (2.3523)	Acc@1 35.938 (36.175)	Acc@5 68.750 (71.394)
Epoch: [10][160/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3978 (2.3545)	Acc@1 38.281 (36.151)	Acc@5 73.438 (71.293)
Epoch: [10][170/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.2703 (2.3548)	Acc@1 40.625 (36.084)	Acc@5 72.656 (71.258)
Epoch: [10][180/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.5048 (2.3573)	Acc@1 30.469 (35.959)	Acc@5 65.625 (71.163)
Epoch: [10][190/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.2623 (2.3538)	Acc@1 42.969 (36.056)	Acc@5 73.438 (71.212)
Epoch: [10][200/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.5453 (2.3498)	Acc@1 31.250 (36.128)	Acc@5 67.188 (71.241)
Epoch: [10][210/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.3352 (2.3520)	Acc@1 36.719 (36.093)	Acc@5 73.438 (71.197)
Epoch: [10][220/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.3821 (2.3519)	Acc@1 35.938 (36.128)	Acc@5 71.875 (71.217)
Epoch: [10][230/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4601 (2.3538)	Acc@1 28.125 (35.975)	Acc@5 71.094 (71.192)
Epoch: [10][240/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.5668 (2.3545)	Acc@1 27.344 (35.999)	Acc@5 66.406 (71.227)
Epoch: [10][250/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.2256 (2.3544)	Acc@1 33.594 (36.025)	Acc@5 75.000 (71.190)
Epoch: [10][260/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4420 (2.3521)	Acc@1 36.719 (36.123)	Acc@5 70.312 (71.243)
Epoch: [10][270/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4200 (2.3528)	Acc@1 37.500 (36.157)	Acc@5 71.094 (71.183)
Epoch: [10][280/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5933 (2.3556)	Acc@1 35.156 (36.063)	Acc@5 64.062 (71.155)
Epoch: [10][290/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4351 (2.3550)	Acc@1 36.719 (36.080)	Acc@5 64.844 (71.145)
Epoch: [10][300/391]	Time 0.096 (0.089)	Data 0.001 (0.002)	Loss 2.3703 (2.3574)	Acc@1 39.844 (36.041)	Acc@5 70.312 (71.089)
Epoch: [10][310/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4136 (2.3596)	Acc@1 32.812 (36.043)	Acc@5 69.531 (71.026)
Epoch: [10][320/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4151 (2.3611)	Acc@1 34.375 (35.974)	Acc@5 71.094 (70.960)
Epoch: [10][330/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4559 (2.3624)	Acc@1 31.250 (35.940)	Acc@5 70.312 (70.929)
Epoch: [10][340/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2726 (2.3624)	Acc@1 37.500 (35.876)	Acc@5 71.094 (70.917)
Epoch: [10][350/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.5041 (2.3621)	Acc@1 34.375 (35.862)	Acc@5 67.969 (70.958)
Epoch: [10][360/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3326 (2.3633)	Acc@1 35.156 (35.866)	Acc@5 69.531 (70.927)
Epoch: [10][370/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2474 (2.3628)	Acc@1 34.375 (35.887)	Acc@5 72.656 (70.955)
Epoch: [10][380/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3350 (2.3606)	Acc@1 36.719 (35.935)	Acc@5 70.312 (71.001)
Epoch: [10][390/391]	Time 0.073 (0.088)	Data 0.001 (0.002)	Loss 2.6040 (2.3607)	Acc@1 38.750 (35.966)	Acc@5 63.750 (70.986)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [11][0/391]	Time 0.099 (0.099)	Data 0.165 (0.165)	Loss 2.2447 (2.2447)	Acc@1 39.844 (39.844)	Acc@5 71.094 (71.094)
Epoch: [11][10/391]	Time 0.091 (0.090)	Data 0.001 (0.016)	Loss 2.3126 (2.3127)	Acc@1 36.719 (37.571)	Acc@5 73.438 (72.656)
Epoch: [11][20/391]	Time 0.087 (0.089)	Data 0.001 (0.009)	Loss 2.2036 (2.3361)	Acc@1 39.062 (36.719)	Acc@5 75.781 (72.470)
Epoch: [11][30/391]	Time 0.086 (0.089)	Data 0.001 (0.006)	Loss 2.4493 (2.3382)	Acc@1 29.688 (36.190)	Acc@5 67.188 (71.925)
Epoch: [11][40/391]	Time 0.089 (0.089)	Data 0.001 (0.005)	Loss 2.3310 (2.3526)	Acc@1 35.156 (35.938)	Acc@5 75.000 (71.837)
Epoch: [11][50/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.3705 (2.3519)	Acc@1 35.156 (36.137)	Acc@5 64.844 (71.722)
Epoch: [11][60/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.5814 (2.3531)	Acc@1 32.812 (35.822)	Acc@5 66.406 (71.657)
Epoch: [11][70/391]	Time 0.086 (0.089)	Data 0.001 (0.003)	Loss 2.1701 (2.3526)	Acc@1 35.938 (35.982)	Acc@5 72.656 (71.600)
Epoch: [11][80/391]	Time 0.085 (0.089)	Data 0.001 (0.003)	Loss 2.3315 (2.3591)	Acc@1 35.938 (35.793)	Acc@5 64.844 (71.373)
Epoch: [11][90/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.1325 (2.3620)	Acc@1 42.969 (35.723)	Acc@5 74.219 (71.308)
Epoch: [11][100/391]	Time 0.089 (0.089)	Data 0.002 (0.003)	Loss 2.4345 (2.3660)	Acc@1 40.625 (35.883)	Acc@5 66.406 (71.024)
Epoch: [11][110/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.5566 (2.3601)	Acc@1 30.469 (36.184)	Acc@5 62.500 (71.115)
Epoch: [11][120/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.3438 (2.3599)	Acc@1 35.938 (36.034)	Acc@5 69.531 (71.249)
Epoch: [11][130/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.2355 (2.3591)	Acc@1 34.375 (36.015)	Acc@5 77.344 (71.165)
Epoch: [11][140/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.1868 (2.3542)	Acc@1 45.312 (36.131)	Acc@5 73.438 (71.227)
Epoch: [11][150/391]	Time 0.084 (0.089)	Data 0.001 (0.002)	Loss 2.2710 (2.3515)	Acc@1 39.062 (36.186)	Acc@5 71.094 (71.264)
Epoch: [11][160/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5367 (2.3546)	Acc@1 32.031 (36.127)	Acc@5 64.844 (71.147)
Epoch: [11][170/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2060 (2.3524)	Acc@1 40.625 (36.198)	Acc@5 79.688 (71.190)
Epoch: [11][180/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.3111 (2.3553)	Acc@1 35.938 (36.313)	Acc@5 71.875 (71.133)
Epoch: [11][190/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.7731 (2.3540)	Acc@1 29.688 (36.326)	Acc@5 63.281 (71.147)
Epoch: [11][200/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.2160 (2.3538)	Acc@1 39.062 (36.311)	Acc@5 74.219 (71.195)
Epoch: [11][210/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.4774 (2.3541)	Acc@1 35.938 (36.311)	Acc@5 71.875 (71.105)
Epoch: [11][220/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.5433 (2.3550)	Acc@1 32.812 (36.298)	Acc@5 65.625 (71.104)
Epoch: [11][230/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1882 (2.3533)	Acc@1 39.062 (36.387)	Acc@5 68.750 (71.155)
Epoch: [11][240/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2445 (2.3486)	Acc@1 38.281 (36.469)	Acc@5 73.438 (71.175)
Epoch: [11][250/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4889 (2.3485)	Acc@1 35.938 (36.420)	Acc@5 68.750 (71.165)
Epoch: [11][260/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4160 (2.3460)	Acc@1 36.719 (36.458)	Acc@5 71.875 (71.246)
Epoch: [11][270/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.4778 (2.3447)	Acc@1 36.719 (36.485)	Acc@5 69.531 (71.278)
Epoch: [11][280/391]	Time 0.094 (0.089)	Data 0.001 (0.002)	Loss 2.1685 (2.3452)	Acc@1 39.844 (36.469)	Acc@5 75.000 (71.255)
Epoch: [11][290/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1940 (2.3454)	Acc@1 40.625 (36.491)	Acc@5 77.344 (71.260)
Epoch: [11][300/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3198 (2.3454)	Acc@1 39.062 (36.498)	Acc@5 75.000 (71.252)
Epoch: [11][310/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.6586 (2.3459)	Acc@1 28.125 (36.457)	Acc@5 64.844 (71.272)
Epoch: [11][320/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1809 (2.3469)	Acc@1 39.062 (36.388)	Acc@5 68.750 (71.230)
Epoch: [11][330/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2087 (2.3458)	Acc@1 39.062 (36.431)	Acc@5 75.781 (71.238)
Epoch: [11][340/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3289 (2.3459)	Acc@1 37.500 (36.428)	Acc@5 73.438 (71.240)
Epoch: [11][350/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5945 (2.3467)	Acc@1 39.844 (36.458)	Acc@5 67.188 (71.225)
Epoch: [11][360/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3444 (2.3446)	Acc@1 33.594 (36.476)	Acc@5 71.875 (71.314)
Epoch: [11][370/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.7265 (2.3495)	Acc@1 32.812 (36.371)	Acc@5 64.844 (71.186)
Epoch: [11][380/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4568 (2.3512)	Acc@1 39.062 (36.356)	Acc@5 68.750 (71.166)
Epoch: [11][390/391]	Time 0.078 (0.089)	Data 0.001 (0.002)	Loss 2.5956 (2.3525)	Acc@1 36.250 (36.316)	Acc@5 63.750 (71.114)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [12][0/391]	Time 0.103 (0.103)	Data 0.175 (0.175)	Loss 2.3868 (2.3868)	Acc@1 36.719 (36.719)	Acc@5 67.188 (67.188)
Epoch: [12][10/391]	Time 0.091 (0.091)	Data 0.001 (0.017)	Loss 2.1850 (2.2929)	Acc@1 37.500 (37.145)	Acc@5 72.656 (72.230)
Epoch: [12][20/391]	Time 0.084 (0.089)	Data 0.001 (0.009)	Loss 2.4092 (2.3574)	Acc@1 34.375 (36.049)	Acc@5 72.656 (70.982)
Epoch: [12][30/391]	Time 0.087 (0.089)	Data 0.001 (0.007)	Loss 2.4750 (2.3440)	Acc@1 31.250 (36.038)	Acc@5 68.750 (71.094)
Epoch: [12][40/391]	Time 0.088 (0.088)	Data 0.001 (0.005)	Loss 2.1315 (2.3184)	Acc@1 37.500 (36.643)	Acc@5 78.906 (71.818)
Epoch: [12][50/391]	Time 0.086 (0.089)	Data 0.001 (0.005)	Loss 2.2153 (2.3152)	Acc@1 40.625 (37.056)	Acc@5 76.562 (71.967)
Epoch: [12][60/391]	Time 0.088 (0.089)	Data 0.001 (0.004)	Loss 2.4802 (2.3246)	Acc@1 35.156 (36.936)	Acc@5 68.750 (71.696)
Epoch: [12][70/391]	Time 0.093 (0.089)	Data 0.001 (0.004)	Loss 2.3538 (2.3203)	Acc@1 34.375 (37.115)	Acc@5 71.094 (71.622)
Epoch: [12][80/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.3623 (2.3294)	Acc@1 38.281 (36.892)	Acc@5 67.969 (71.451)
Epoch: [12][90/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.5384 (2.3327)	Acc@1 28.125 (36.805)	Acc@5 67.188 (71.463)
Epoch: [12][100/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.3697 (2.3333)	Acc@1 33.594 (36.843)	Acc@5 69.531 (71.434)
Epoch: [12][110/391]	Time 0.087 (0.088)	Data 0.001 (0.003)	Loss 2.0933 (2.3355)	Acc@1 36.719 (36.719)	Acc@5 75.000 (71.326)
Epoch: [12][120/391]	Time 0.085 (0.089)	Data 0.001 (0.003)	Loss 2.1432 (2.3457)	Acc@1 40.625 (36.357)	Acc@5 76.562 (71.197)
Epoch: [12][130/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.4682 (2.3463)	Acc@1 34.375 (36.260)	Acc@5 67.969 (71.243)
Epoch: [12][140/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.2915 (2.3471)	Acc@1 34.375 (36.143)	Acc@5 67.969 (71.310)
Epoch: [12][150/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4156 (2.3431)	Acc@1 32.812 (36.232)	Acc@5 67.969 (71.425)
Epoch: [12][160/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2773 (2.3403)	Acc@1 36.719 (36.316)	Acc@5 74.219 (71.487)
Epoch: [12][170/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2328 (2.3419)	Acc@1 38.281 (36.294)	Acc@5 73.438 (71.446)
Epoch: [12][180/391]	Time 0.084 (0.088)	Data 0.001 (0.002)	Loss 2.3017 (2.3417)	Acc@1 32.812 (36.218)	Acc@5 72.656 (71.435)
Epoch: [12][190/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.3472 (2.3421)	Acc@1 39.062 (36.179)	Acc@5 73.438 (71.446)
Epoch: [12][200/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.5774 (2.3469)	Acc@1 35.156 (36.155)	Acc@5 65.625 (71.350)
Epoch: [12][210/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.2935 (2.3446)	Acc@1 32.812 (36.245)	Acc@5 79.688 (71.490)
Epoch: [12][220/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.2606 (2.3453)	Acc@1 33.594 (36.249)	Acc@5 72.656 (71.412)
Epoch: [12][230/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.2309 (2.3427)	Acc@1 35.938 (36.330)	Acc@5 76.562 (71.493)
Epoch: [12][240/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3119 (2.3431)	Acc@1 38.281 (36.327)	Acc@5 74.219 (71.457)
Epoch: [12][250/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.3549 (2.3453)	Acc@1 32.031 (36.258)	Acc@5 70.312 (71.365)
Epoch: [12][260/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.2852 (2.3461)	Acc@1 35.156 (36.219)	Acc@5 73.438 (71.321)
Epoch: [12][270/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.2733 (2.3464)	Acc@1 36.719 (36.257)	Acc@5 71.094 (71.350)
Epoch: [12][280/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3220 (2.3484)	Acc@1 37.500 (36.218)	Acc@5 67.188 (71.263)
Epoch: [12][290/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.4784 (2.3511)	Acc@1 33.594 (36.112)	Acc@5 64.062 (71.217)
Epoch: [12][300/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4463 (2.3535)	Acc@1 34.375 (36.078)	Acc@5 71.875 (71.195)
Epoch: [12][310/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.2468 (2.3532)	Acc@1 39.062 (36.091)	Acc@5 72.656 (71.217)
Epoch: [12][320/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3533 (2.3525)	Acc@1 38.281 (36.101)	Acc@5 74.219 (71.218)
Epoch: [12][330/391]	Time 0.092 (0.088)	Data 0.001 (0.002)	Loss 2.4322 (2.3526)	Acc@1 29.688 (36.053)	Acc@5 70.312 (71.224)
Epoch: [12][340/391]	Time 0.084 (0.088)	Data 0.001 (0.002)	Loss 2.4444 (2.3528)	Acc@1 35.938 (36.029)	Acc@5 67.188 (71.243)
Epoch: [12][350/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.2135 (2.3543)	Acc@1 36.719 (36.011)	Acc@5 71.094 (71.172)
Epoch: [12][360/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3354 (2.3564)	Acc@1 41.406 (36.022)	Acc@5 71.094 (71.144)
Epoch: [12][370/391]	Time 0.092 (0.088)	Data 0.001 (0.002)	Loss 2.2918 (2.3571)	Acc@1 39.844 (36.030)	Acc@5 75.000 (71.102)
Epoch: [12][380/391]	Time 0.093 (0.088)	Data 0.001 (0.002)	Loss 2.3508 (2.3590)	Acc@1 35.938 (36.003)	Acc@5 75.781 (71.077)
Epoch: [12][390/391]	Time 0.073 (0.088)	Data 0.001 (0.002)	Loss 2.1175 (2.3577)	Acc@1 37.500 (35.968)	Acc@5 75.000 (71.132)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [13][0/391]	Time 0.100 (0.100)	Data 0.163 (0.163)	Loss 2.1366 (2.1366)	Acc@1 47.656 (47.656)	Acc@5 81.250 (81.250)
Epoch: [13][10/391]	Time 0.093 (0.092)	Data 0.001 (0.016)	Loss 2.3424 (2.3227)	Acc@1 43.750 (35.653)	Acc@5 74.219 (72.514)
Epoch: [13][20/391]	Time 0.096 (0.092)	Data 0.001 (0.009)	Loss 2.3267 (2.3061)	Acc@1 34.375 (36.458)	Acc@5 73.438 (72.842)
Epoch: [13][30/391]	Time 0.091 (0.092)	Data 0.001 (0.006)	Loss 2.1806 (2.3191)	Acc@1 40.625 (36.341)	Acc@5 75.000 (71.850)
Epoch: [13][40/391]	Time 0.096 (0.092)	Data 0.001 (0.005)	Loss 2.4835 (2.3409)	Acc@1 33.594 (35.785)	Acc@5 68.750 (71.361)
Epoch: [13][50/391]	Time 0.091 (0.092)	Data 0.001 (0.004)	Loss 2.2212 (2.3328)	Acc@1 38.281 (35.907)	Acc@5 70.312 (71.354)
Epoch: [13][60/391]	Time 0.089 (0.092)	Data 0.001 (0.004)	Loss 2.2630 (2.3360)	Acc@1 41.406 (36.142)	Acc@5 75.781 (71.324)
Epoch: [13][70/391]	Time 0.092 (0.092)	Data 0.001 (0.003)	Loss 2.4676 (2.3328)	Acc@1 32.812 (36.213)	Acc@5 66.406 (71.347)
Epoch: [13][80/391]	Time 0.092 (0.092)	Data 0.001 (0.003)	Loss 2.1627 (2.3262)	Acc@1 39.844 (36.352)	Acc@5 78.125 (71.460)
Epoch: [13][90/391]	Time 0.090 (0.092)	Data 0.001 (0.003)	Loss 2.5711 (2.3320)	Acc@1 32.031 (36.367)	Acc@5 60.938 (71.463)
Epoch: [13][100/391]	Time 0.090 (0.092)	Data 0.001 (0.003)	Loss 2.4583 (2.3318)	Acc@1 33.594 (36.409)	Acc@5 70.312 (71.550)
Epoch: [13][110/391]	Time 0.090 (0.092)	Data 0.001 (0.003)	Loss 2.4022 (2.3323)	Acc@1 38.281 (36.388)	Acc@5 68.750 (71.488)
Epoch: [13][120/391]	Time 0.091 (0.092)	Data 0.001 (0.003)	Loss 2.4626 (2.3322)	Acc@1 35.938 (36.383)	Acc@5 63.281 (71.378)
Epoch: [13][130/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.4367 (2.3285)	Acc@1 35.156 (36.444)	Acc@5 67.188 (71.481)
Epoch: [13][140/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.1247 (2.3334)	Acc@1 39.844 (36.359)	Acc@5 78.125 (71.459)
Epoch: [13][150/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.4457 (2.3383)	Acc@1 32.031 (36.362)	Acc@5 64.844 (71.223)
Epoch: [13][160/391]	Time 0.094 (0.092)	Data 0.001 (0.002)	Loss 2.4954 (2.3427)	Acc@1 34.375 (36.248)	Acc@5 71.094 (71.215)
Epoch: [13][170/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.4347 (2.3414)	Acc@1 35.938 (36.326)	Acc@5 74.219 (71.286)
Epoch: [13][180/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.2403 (2.3427)	Acc@1 38.281 (36.330)	Acc@5 70.312 (71.258)
Epoch: [13][190/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.2663 (2.3446)	Acc@1 35.938 (36.314)	Acc@5 74.219 (71.192)
Epoch: [13][200/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.6220 (2.3488)	Acc@1 34.375 (36.299)	Acc@5 64.844 (71.074)
Epoch: [13][210/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.3076 (2.3509)	Acc@1 39.844 (36.237)	Acc@5 68.750 (70.990)
Epoch: [13][220/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.0404 (2.3501)	Acc@1 39.844 (36.196)	Acc@5 77.344 (71.065)
Epoch: [13][230/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.6339 (2.3531)	Acc@1 28.906 (36.205)	Acc@5 65.625 (70.982)
Epoch: [13][240/391]	Time 0.088 (0.092)	Data 0.001 (0.002)	Loss 2.6024 (2.3546)	Acc@1 35.156 (36.161)	Acc@5 61.719 (70.941)
Epoch: [13][250/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.2767 (2.3546)	Acc@1 30.469 (36.124)	Acc@5 75.781 (70.947)
Epoch: [13][260/391]	Time 0.093 (0.092)	Data 0.001 (0.002)	Loss 2.5406 (2.3543)	Acc@1 35.938 (36.123)	Acc@5 67.188 (70.983)
Epoch: [13][270/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.4650 (2.3567)	Acc@1 35.938 (36.125)	Acc@5 70.312 (70.927)
Epoch: [13][280/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.4756 (2.3579)	Acc@1 33.594 (36.124)	Acc@5 65.625 (70.896)
Epoch: [13][290/391]	Time 0.092 (0.092)	Data 0.001 (0.002)	Loss 2.3461 (2.3563)	Acc@1 30.469 (36.190)	Acc@5 72.656 (70.943)
Epoch: [13][300/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.3600 (2.3559)	Acc@1 37.500 (36.236)	Acc@5 71.875 (70.954)
Epoch: [13][310/391]	Time 0.091 (0.092)	Data 0.001 (0.002)	Loss 2.4433 (2.3563)	Acc@1 27.344 (36.194)	Acc@5 64.844 (70.880)
Epoch: [13][320/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.0909 (2.3530)	Acc@1 39.844 (36.268)	Acc@5 78.906 (70.994)
Epoch: [13][330/391]	Time 0.096 (0.092)	Data 0.001 (0.002)	Loss 2.4389 (2.3505)	Acc@1 36.719 (36.343)	Acc@5 70.312 (71.044)
Epoch: [13][340/391]	Time 0.089 (0.092)	Data 0.001 (0.002)	Loss 2.4817 (2.3486)	Acc@1 35.156 (36.382)	Acc@5 71.875 (71.085)
Epoch: [13][350/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.2194 (2.3489)	Acc@1 42.969 (36.407)	Acc@5 75.000 (71.109)
Epoch: [13][360/391]	Time 0.089 (0.092)	Data 0.001 (0.002)	Loss 2.6590 (2.3489)	Acc@1 28.906 (36.394)	Acc@5 65.625 (71.135)
Epoch: [13][370/391]	Time 0.090 (0.092)	Data 0.001 (0.002)	Loss 2.5164 (2.3491)	Acc@1 33.594 (36.333)	Acc@5 66.406 (71.094)
Epoch: [13][380/391]	Time 0.089 (0.092)	Data 0.001 (0.002)	Loss 2.4075 (2.3489)	Acc@1 39.062 (36.358)	Acc@5 67.188 (71.063)
Epoch: [13][390/391]	Time 0.077 (0.092)	Data 0.001 (0.002)	Loss 2.6522 (2.3480)	Acc@1 32.500 (36.382)	Acc@5 68.750 (71.088)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [14][0/391]	Time 0.103 (0.103)	Data 0.167 (0.167)	Loss 2.4463 (2.4463)	Acc@1 35.938 (35.938)	Acc@5 64.062 (64.062)
Epoch: [14][10/391]	Time 0.090 (0.093)	Data 0.001 (0.016)	Loss 2.2820 (2.3413)	Acc@1 37.500 (36.506)	Acc@5 70.312 (70.170)
Epoch: [14][20/391]	Time 0.090 (0.091)	Data 0.001 (0.009)	Loss 2.2243 (2.3029)	Acc@1 39.844 (37.909)	Acc@5 71.094 (71.391)
Epoch: [14][30/391]	Time 0.093 (0.090)	Data 0.001 (0.006)	Loss 2.2494 (2.2952)	Acc@1 42.969 (37.727)	Acc@5 76.562 (71.673)
Epoch: [14][40/391]	Time 0.088 (0.090)	Data 0.001 (0.005)	Loss 2.2736 (2.2808)	Acc@1 39.062 (38.014)	Acc@5 71.875 (72.180)
Epoch: [14][50/391]	Time 0.088 (0.090)	Data 0.001 (0.004)	Loss 1.9385 (2.2880)	Acc@1 50.781 (38.159)	Acc@5 75.781 (72.074)
Epoch: [14][60/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.1002 (2.2890)	Acc@1 40.625 (38.051)	Acc@5 75.781 (72.003)
Epoch: [14][70/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.4216 (2.2968)	Acc@1 35.156 (37.687)	Acc@5 72.656 (71.996)
Epoch: [14][80/391]	Time 0.092 (0.089)	Data 0.001 (0.003)	Loss 2.3730 (2.2999)	Acc@1 35.156 (37.693)	Acc@5 66.406 (71.971)
Epoch: [14][90/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.1095 (2.2960)	Acc@1 45.312 (37.783)	Acc@5 78.125 (72.047)
Epoch: [14][100/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.3013 (2.3027)	Acc@1 34.375 (37.701)	Acc@5 70.312 (71.767)
Epoch: [14][110/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.5629 (2.3169)	Acc@1 35.156 (37.317)	Acc@5 60.938 (71.425)
Epoch: [14][120/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.2230 (2.3157)	Acc@1 30.469 (37.209)	Acc@5 74.219 (71.346)
Epoch: [14][130/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3510 (2.3114)	Acc@1 34.375 (37.178)	Acc@5 77.344 (71.535)
Epoch: [14][140/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4251 (2.3121)	Acc@1 34.375 (37.234)	Acc@5 69.531 (71.498)
Epoch: [14][150/391]	Time 0.084 (0.089)	Data 0.001 (0.002)	Loss 2.3115 (2.3131)	Acc@1 36.719 (37.148)	Acc@5 71.094 (71.389)
Epoch: [14][160/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1856 (2.3132)	Acc@1 39.062 (37.044)	Acc@5 70.312 (71.433)
Epoch: [14][170/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.0975 (2.3137)	Acc@1 37.500 (36.993)	Acc@5 78.906 (71.441)
Epoch: [14][180/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3035 (2.3139)	Acc@1 40.625 (37.051)	Acc@5 71.094 (71.409)
Epoch: [14][190/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1602 (2.3119)	Acc@1 40.625 (37.099)	Acc@5 75.000 (71.486)
Epoch: [14][200/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4127 (2.3126)	Acc@1 37.500 (37.111)	Acc@5 71.094 (71.541)
Epoch: [14][210/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.5275 (2.3153)	Acc@1 36.719 (37.108)	Acc@5 64.062 (71.531)
Epoch: [14][220/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3439 (2.3182)	Acc@1 31.250 (37.019)	Acc@5 68.750 (71.454)
Epoch: [14][230/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5353 (2.3237)	Acc@1 30.469 (36.864)	Acc@5 64.844 (71.364)
Epoch: [14][240/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.3931 (2.3261)	Acc@1 32.812 (36.745)	Acc@5 68.750 (71.314)
Epoch: [14][250/391]	Time 0.092 (0.089)	Data 0.002 (0.002)	Loss 2.1133 (2.3245)	Acc@1 35.938 (36.781)	Acc@5 75.781 (71.365)
Epoch: [14][260/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.3121 (2.3241)	Acc@1 39.062 (36.776)	Acc@5 69.531 (71.405)
Epoch: [14][270/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1834 (2.3231)	Acc@1 42.188 (36.791)	Acc@5 71.094 (71.396)
Epoch: [14][280/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.2228 (2.3252)	Acc@1 38.281 (36.677)	Acc@5 75.781 (71.377)
Epoch: [14][290/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.4094 (2.3263)	Acc@1 28.125 (36.598)	Acc@5 73.438 (71.362)
Epoch: [14][300/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.1191 (2.3265)	Acc@1 44.531 (36.646)	Acc@5 76.562 (71.351)
Epoch: [14][310/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3462 (2.3259)	Acc@1 35.156 (36.689)	Acc@5 71.094 (71.340)
Epoch: [14][320/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1007 (2.3262)	Acc@1 45.312 (36.660)	Acc@5 75.781 (71.354)
Epoch: [14][330/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3555 (2.3255)	Acc@1 33.594 (36.674)	Acc@5 72.656 (71.445)
Epoch: [14][340/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.2752 (2.3261)	Acc@1 35.938 (36.664)	Acc@5 75.781 (71.460)
Epoch: [14][350/391]	Time 0.091 (0.089)	Data 0.002 (0.002)	Loss 2.2433 (2.3275)	Acc@1 43.750 (36.674)	Acc@5 70.312 (71.408)
Epoch: [14][360/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3922 (2.3284)	Acc@1 33.594 (36.688)	Acc@5 74.219 (71.423)
Epoch: [14][370/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4547 (2.3287)	Acc@1 35.938 (36.685)	Acc@5 67.969 (71.439)
Epoch: [14][380/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2946 (2.3269)	Acc@1 35.156 (36.737)	Acc@5 72.656 (71.469)
Epoch: [14][390/391]	Time 0.073 (0.089)	Data 0.001 (0.002)	Loss 2.6265 (2.3288)	Acc@1 35.000 (36.726)	Acc@5 67.500 (71.420)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [15][0/391]	Time 0.099 (0.099)	Data 0.165 (0.165)	Loss 2.2511 (2.2511)	Acc@1 40.625 (40.625)	Acc@5 75.000 (75.000)
Epoch: [15][10/391]	Time 0.088 (0.091)	Data 0.001 (0.016)	Loss 2.1922 (2.3356)	Acc@1 39.844 (35.582)	Acc@5 75.000 (72.372)
Epoch: [15][20/391]	Time 0.087 (0.090)	Data 0.001 (0.009)	Loss 2.3259 (2.3046)	Acc@1 37.500 (36.756)	Acc@5 71.094 (72.359)
Epoch: [15][30/391]	Time 0.087 (0.090)	Data 0.001 (0.006)	Loss 2.3267 (2.3219)	Acc@1 30.469 (36.416)	Acc@5 68.750 (71.648)
Epoch: [15][40/391]	Time 0.093 (0.089)	Data 0.001 (0.005)	Loss 2.1503 (2.2986)	Acc@1 38.281 (36.947)	Acc@5 71.094 (71.951)
Epoch: [15][50/391]	Time 0.088 (0.090)	Data 0.001 (0.004)	Loss 2.2386 (2.2937)	Acc@1 42.188 (37.025)	Acc@5 71.094 (72.304)
Epoch: [15][60/391]	Time 0.087 (0.090)	Data 0.001 (0.004)	Loss 2.6582 (2.3163)	Acc@1 32.812 (36.655)	Acc@5 65.625 (71.824)
Epoch: [15][70/391]	Time 0.088 (0.090)	Data 0.001 (0.003)	Loss 2.2833 (2.3233)	Acc@1 37.500 (36.774)	Acc@5 69.531 (71.556)
Epoch: [15][80/391]	Time 0.084 (0.090)	Data 0.001 (0.003)	Loss 2.4089 (2.3266)	Acc@1 38.281 (36.622)	Acc@5 72.656 (71.518)
Epoch: [15][90/391]	Time 0.088 (0.090)	Data 0.001 (0.003)	Loss 2.2998 (2.3235)	Acc@1 38.281 (36.676)	Acc@5 70.312 (71.652)
Epoch: [15][100/391]	Time 0.088 (0.090)	Data 0.001 (0.003)	Loss 2.5123 (2.3236)	Acc@1 32.031 (36.479)	Acc@5 63.281 (71.635)
Epoch: [15][110/391]	Time 0.088 (0.090)	Data 0.002 (0.003)	Loss 2.3251 (2.3265)	Acc@1 38.281 (36.543)	Acc@5 71.094 (71.692)
Epoch: [15][120/391]	Time 0.085 (0.090)	Data 0.001 (0.002)	Loss 2.5392 (2.3291)	Acc@1 32.812 (36.435)	Acc@5 64.844 (71.668)
Epoch: [15][130/391]	Time 0.088 (0.090)	Data 0.001 (0.002)	Loss 2.2045 (2.3252)	Acc@1 42.188 (36.683)	Acc@5 71.094 (71.756)
Epoch: [15][140/391]	Time 0.089 (0.090)	Data 0.001 (0.002)	Loss 2.0456 (2.3217)	Acc@1 42.188 (36.686)	Acc@5 75.781 (71.847)
Epoch: [15][150/391]	Time 0.088 (0.090)	Data 0.001 (0.002)	Loss 1.9778 (2.3156)	Acc@1 49.219 (36.827)	Acc@5 78.906 (72.046)
Epoch: [15][160/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3197 (2.3167)	Acc@1 35.156 (36.753)	Acc@5 73.438 (72.011)
Epoch: [15][170/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.0378 (2.3108)	Acc@1 41.406 (36.929)	Acc@5 78.906 (72.117)
Epoch: [15][180/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4411 (2.3120)	Acc@1 37.500 (36.891)	Acc@5 71.094 (72.056)
Epoch: [15][190/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.1815 (2.3119)	Acc@1 40.625 (36.948)	Acc@5 75.781 (72.035)
Epoch: [15][200/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1836 (2.3086)	Acc@1 46.094 (37.053)	Acc@5 75.781 (72.135)
Epoch: [15][210/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.2163 (2.3099)	Acc@1 36.719 (37.015)	Acc@5 75.000 (72.142)
Epoch: [15][220/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.3488 (2.3123)	Acc@1 39.062 (37.030)	Acc@5 71.875 (72.091)
Epoch: [15][230/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.6849 (2.3163)	Acc@1 26.562 (36.989)	Acc@5 63.281 (72.004)
Epoch: [15][240/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2474 (2.3175)	Acc@1 38.281 (36.978)	Acc@5 75.000 (72.011)
Epoch: [15][250/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.2776 (2.3201)	Acc@1 37.500 (36.937)	Acc@5 74.219 (72.015)
Epoch: [15][260/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.0743 (2.3223)	Acc@1 38.281 (36.898)	Acc@5 76.562 (71.929)
Epoch: [15][270/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4761 (2.3240)	Acc@1 35.938 (36.903)	Acc@5 65.625 (71.866)
Epoch: [15][280/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5346 (2.3253)	Acc@1 33.594 (36.905)	Acc@5 63.281 (71.817)
Epoch: [15][290/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3316 (2.3247)	Acc@1 35.156 (36.874)	Acc@5 68.750 (71.794)
Epoch: [15][300/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3139 (2.3255)	Acc@1 40.625 (36.874)	Acc@5 73.438 (71.766)
Epoch: [15][310/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3494 (2.3255)	Acc@1 38.281 (36.867)	Acc@5 71.875 (71.790)
Epoch: [15][320/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3213 (2.3287)	Acc@1 37.500 (36.833)	Acc@5 75.781 (71.692)
Epoch: [15][330/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3282 (2.3306)	Acc@1 36.719 (36.797)	Acc@5 70.312 (71.658)
Epoch: [15][340/391]	Time 0.083 (0.089)	Data 0.001 (0.002)	Loss 2.4442 (2.3315)	Acc@1 32.812 (36.758)	Acc@5 67.188 (71.673)
Epoch: [15][350/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4787 (2.3321)	Acc@1 38.281 (36.712)	Acc@5 68.750 (71.635)
Epoch: [15][360/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2790 (2.3325)	Acc@1 39.062 (36.723)	Acc@5 71.094 (71.620)
Epoch: [15][370/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1659 (2.3305)	Acc@1 39.844 (36.744)	Acc@5 72.656 (71.656)
Epoch: [15][380/391]	Time 0.083 (0.089)	Data 0.001 (0.002)	Loss 2.4220 (2.3299)	Acc@1 32.812 (36.725)	Acc@5 69.531 (71.668)
Epoch: [15][390/391]	Time 0.072 (0.089)	Data 0.001 (0.002)	Loss 1.9048 (2.3292)	Acc@1 40.000 (36.718)	Acc@5 78.750 (71.682)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [16][0/391]	Time 0.098 (0.098)	Data 0.163 (0.163)	Loss 2.3281 (2.3281)	Acc@1 34.375 (34.375)	Acc@5 69.531 (69.531)
Epoch: [16][10/391]	Time 0.094 (0.093)	Data 0.001 (0.016)	Loss 2.0867 (2.2135)	Acc@1 40.625 (38.352)	Acc@5 75.000 (74.219)
Epoch: [16][20/391]	Time 0.090 (0.092)	Data 0.001 (0.009)	Loss 2.2287 (2.2503)	Acc@1 41.406 (37.798)	Acc@5 75.000 (73.438)
Epoch: [16][30/391]	Time 0.086 (0.092)	Data 0.001 (0.006)	Loss 2.2172 (2.2600)	Acc@1 40.625 (37.954)	Acc@5 71.094 (73.085)
Epoch: [16][40/391]	Time 0.087 (0.091)	Data 0.001 (0.005)	Loss 2.5097 (2.2680)	Acc@1 29.688 (37.995)	Acc@5 71.094 (72.980)
Epoch: [16][50/391]	Time 0.089 (0.091)	Data 0.001 (0.004)	Loss 2.1671 (2.2671)	Acc@1 42.969 (37.929)	Acc@5 78.125 (72.932)
Epoch: [16][60/391]	Time 0.087 (0.091)	Data 0.001 (0.004)	Loss 2.2429 (2.2766)	Acc@1 39.844 (37.923)	Acc@5 73.438 (72.656)
Epoch: [16][70/391]	Time 0.088 (0.090)	Data 0.001 (0.003)	Loss 2.4629 (2.2835)	Acc@1 33.594 (37.676)	Acc@5 70.312 (72.513)
Epoch: [16][80/391]	Time 0.089 (0.090)	Data 0.001 (0.003)	Loss 2.1665 (2.2895)	Acc@1 38.281 (37.741)	Acc@5 75.000 (72.386)
Epoch: [16][90/391]	Time 0.088 (0.090)	Data 0.001 (0.003)	Loss 2.5179 (2.2968)	Acc@1 31.250 (37.612)	Acc@5 66.406 (72.193)
Epoch: [16][100/391]	Time 0.088 (0.090)	Data 0.001 (0.003)	Loss 2.2636 (2.3026)	Acc@1 32.031 (37.438)	Acc@5 71.094 (72.115)
Epoch: [16][110/391]	Time 0.086 (0.090)	Data 0.001 (0.003)	Loss 2.4774 (2.3041)	Acc@1 34.375 (37.549)	Acc@5 71.875 (72.030)
Epoch: [16][120/391]	Time 0.088 (0.090)	Data 0.001 (0.002)	Loss 2.4657 (2.3138)	Acc@1 37.500 (37.345)	Acc@5 72.656 (71.817)
Epoch: [16][130/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2494 (2.3127)	Acc@1 33.594 (37.184)	Acc@5 75.000 (71.911)
Epoch: [16][140/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5576 (2.3169)	Acc@1 33.594 (37.151)	Acc@5 72.656 (71.864)
Epoch: [16][150/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2219 (2.3226)	Acc@1 36.719 (37.060)	Acc@5 76.562 (71.751)
Epoch: [16][160/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3541 (2.3215)	Acc@1 42.188 (37.155)	Acc@5 67.969 (71.783)
Epoch: [16][170/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5755 (2.3206)	Acc@1 24.219 (37.121)	Acc@5 65.625 (71.774)
Epoch: [16][180/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.0967 (2.3189)	Acc@1 42.188 (37.133)	Acc@5 75.781 (71.897)
Epoch: [16][190/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1399 (2.3134)	Acc@1 36.719 (37.210)	Acc@5 72.656 (71.994)
Epoch: [16][200/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.3863 (2.3131)	Acc@1 39.062 (37.240)	Acc@5 71.094 (71.918)
Epoch: [16][210/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.5213 (2.3113)	Acc@1 25.781 (37.267)	Acc@5 69.531 (71.964)
Epoch: [16][220/391]	Time 0.094 (0.089)	Data 0.001 (0.002)	Loss 2.3058 (2.3127)	Acc@1 33.594 (37.143)	Acc@5 72.656 (71.978)
Epoch: [16][230/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3351 (2.3147)	Acc@1 43.750 (37.196)	Acc@5 70.312 (71.902)
Epoch: [16][240/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4015 (2.3170)	Acc@1 39.844 (37.202)	Acc@5 71.094 (71.823)
Epoch: [16][250/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3283 (2.3188)	Acc@1 37.500 (37.148)	Acc@5 70.312 (71.782)
Epoch: [16][260/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.0553 (2.3204)	Acc@1 42.969 (37.159)	Acc@5 78.125 (71.719)
Epoch: [16][270/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.2472 (2.3214)	Acc@1 39.844 (37.131)	Acc@5 72.656 (71.682)
Epoch: [16][280/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.3914 (2.3230)	Acc@1 34.375 (37.108)	Acc@5 72.656 (71.641)
Epoch: [16][290/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2554 (2.3230)	Acc@1 38.281 (37.052)	Acc@5 73.438 (71.641)
Epoch: [16][300/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2994 (2.3232)	Acc@1 33.594 (36.999)	Acc@5 66.406 (71.618)
Epoch: [16][310/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.0635 (2.3235)	Acc@1 45.312 (37.010)	Acc@5 79.688 (71.654)
Epoch: [16][320/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.2247 (2.3248)	Acc@1 38.281 (37.004)	Acc@5 73.438 (71.583)
Epoch: [16][330/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3005 (2.3252)	Acc@1 38.281 (37.054)	Acc@5 71.094 (71.587)
Epoch: [16][340/391]	Time 0.095 (0.089)	Data 0.001 (0.002)	Loss 2.3978 (2.3257)	Acc@1 37.500 (37.014)	Acc@5 66.406 (71.524)
Epoch: [16][350/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5353 (2.3278)	Acc@1 32.031 (36.928)	Acc@5 68.750 (71.510)
Epoch: [16][360/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4478 (2.3285)	Acc@1 36.719 (36.885)	Acc@5 64.844 (71.488)
Epoch: [16][370/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5911 (2.3283)	Acc@1 27.344 (36.864)	Acc@5 68.750 (71.460)
Epoch: [16][380/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1468 (2.3285)	Acc@1 45.312 (36.885)	Acc@5 72.656 (71.455)
Epoch: [16][390/391]	Time 0.073 (0.089)	Data 0.001 (0.002)	Loss 1.9490 (2.3275)	Acc@1 45.000 (36.894)	Acc@5 78.750 (71.484)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [17][0/391]	Time 0.098 (0.098)	Data 0.174 (0.174)	Loss 2.4724 (2.4724)	Acc@1 38.281 (38.281)	Acc@5 70.312 (70.312)
Epoch: [17][10/391]	Time 0.088 (0.091)	Data 0.001 (0.017)	Loss 2.3252 (2.2902)	Acc@1 28.906 (36.932)	Acc@5 67.969 (71.875)
Epoch: [17][20/391]	Time 0.089 (0.090)	Data 0.001 (0.009)	Loss 2.3845 (2.3014)	Acc@1 32.031 (36.644)	Acc@5 70.312 (71.838)
Epoch: [17][30/391]	Time 0.089 (0.089)	Data 0.001 (0.007)	Loss 2.2406 (2.2987)	Acc@1 41.406 (37.072)	Acc@5 74.219 (71.976)
Epoch: [17][40/391]	Time 0.088 (0.089)	Data 0.001 (0.005)	Loss 2.2154 (2.3118)	Acc@1 35.938 (36.795)	Acc@5 74.219 (71.742)
Epoch: [17][50/391]	Time 0.088 (0.089)	Data 0.001 (0.005)	Loss 2.0588 (2.3177)	Acc@1 40.625 (36.841)	Acc@5 78.125 (71.752)
Epoch: [17][60/391]	Time 0.092 (0.089)	Data 0.001 (0.004)	Loss 2.3655 (2.3153)	Acc@1 32.031 (36.552)	Acc@5 72.656 (71.888)
Epoch: [17][70/391]	Time 0.087 (0.089)	Data 0.001 (0.004)	Loss 2.2846 (2.3132)	Acc@1 39.844 (36.642)	Acc@5 73.438 (71.996)
Epoch: [17][80/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.4419 (2.3176)	Acc@1 32.031 (36.815)	Acc@5 65.625 (71.701)
Epoch: [17][90/391]	Time 0.095 (0.089)	Data 0.001 (0.003)	Loss 2.0785 (2.3150)	Acc@1 40.625 (36.770)	Acc@5 73.438 (71.557)
Epoch: [17][100/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.1232 (2.3115)	Acc@1 42.969 (36.928)	Acc@5 77.344 (71.658)
Epoch: [17][110/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.4151 (2.3089)	Acc@1 35.938 (37.113)	Acc@5 67.969 (71.734)
Epoch: [17][120/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.1298 (2.3056)	Acc@1 38.281 (37.119)	Acc@5 77.344 (71.836)
Epoch: [17][130/391]	Time 0.089 (0.088)	Data 0.001 (0.003)	Loss 2.5390 (2.3037)	Acc@1 35.938 (37.214)	Acc@5 61.719 (71.887)
Epoch: [17][140/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.2350 (2.3011)	Acc@1 39.844 (37.256)	Acc@5 70.312 (71.947)
Epoch: [17][150/391]	Time 0.084 (0.088)	Data 0.001 (0.002)	Loss 2.5692 (2.3048)	Acc@1 32.031 (37.278)	Acc@5 61.719 (71.849)
Epoch: [17][160/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.5012 (2.3080)	Acc@1 34.375 (37.214)	Acc@5 63.281 (71.768)
Epoch: [17][170/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4744 (2.3090)	Acc@1 38.281 (37.148)	Acc@5 72.656 (71.825)
Epoch: [17][180/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4258 (2.3125)	Acc@1 35.938 (37.142)	Acc@5 70.312 (71.737)
Epoch: [17][190/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.3706 (2.3169)	Acc@1 35.938 (36.997)	Acc@5 75.000 (71.654)
Epoch: [17][200/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.5211 (2.3179)	Acc@1 36.719 (36.933)	Acc@5 70.312 (71.755)
Epoch: [17][210/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.2522 (2.3189)	Acc@1 36.719 (36.904)	Acc@5 71.875 (71.731)
Epoch: [17][220/391]	Time 0.084 (0.088)	Data 0.001 (0.002)	Loss 2.4090 (2.3228)	Acc@1 36.719 (36.818)	Acc@5 71.094 (71.719)
Epoch: [17][230/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.2232 (2.3217)	Acc@1 42.188 (36.881)	Acc@5 80.469 (71.767)
Epoch: [17][240/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4436 (2.3261)	Acc@1 32.812 (36.771)	Acc@5 70.312 (71.661)
Epoch: [17][250/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4323 (2.3268)	Acc@1 34.375 (36.741)	Acc@5 69.531 (71.651)
Epoch: [17][260/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3062 (2.3286)	Acc@1 32.812 (36.725)	Acc@5 75.000 (71.627)
Epoch: [17][270/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.3622 (2.3290)	Acc@1 37.500 (36.716)	Acc@5 71.875 (71.656)
Epoch: [17][280/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.3047 (2.3295)	Acc@1 34.375 (36.671)	Acc@5 71.875 (71.644)
Epoch: [17][290/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.0599 (2.3284)	Acc@1 42.188 (36.724)	Acc@5 81.250 (71.663)
Epoch: [17][300/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3590 (2.3271)	Acc@1 35.156 (36.732)	Acc@5 71.094 (71.704)
Epoch: [17][310/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.2055 (2.3268)	Acc@1 42.969 (36.756)	Acc@5 73.438 (71.764)
Epoch: [17][320/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4716 (2.3270)	Acc@1 33.594 (36.758)	Acc@5 66.406 (71.727)
Epoch: [17][330/391]	Time 0.092 (0.088)	Data 0.001 (0.002)	Loss 2.5655 (2.3262)	Acc@1 31.250 (36.808)	Acc@5 57.812 (71.696)
Epoch: [17][340/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3987 (2.3253)	Acc@1 37.500 (36.838)	Acc@5 74.219 (71.715)
Epoch: [17][350/391]	Time 0.084 (0.088)	Data 0.001 (0.002)	Loss 2.2189 (2.3252)	Acc@1 39.844 (36.859)	Acc@5 71.094 (71.686)
Epoch: [17][360/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.2693 (2.3261)	Acc@1 34.375 (36.807)	Acc@5 71.094 (71.674)
Epoch: [17][370/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.2445 (2.3251)	Acc@1 39.844 (36.860)	Acc@5 71.875 (71.685)
Epoch: [17][380/391]	Time 0.094 (0.088)	Data 0.001 (0.002)	Loss 2.4506 (2.3253)	Acc@1 31.250 (36.852)	Acc@5 72.656 (71.678)
Epoch: [17][390/391]	Time 0.075 (0.088)	Data 0.001 (0.002)	Loss 2.3331 (2.3255)	Acc@1 40.000 (36.888)	Acc@5 67.500 (71.682)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [18][0/391]	Time 0.097 (0.097)	Data 0.168 (0.168)	Loss 2.4055 (2.4055)	Acc@1 33.594 (33.594)	Acc@5 71.094 (71.094)
Epoch: [18][10/391]	Time 0.095 (0.091)	Data 0.001 (0.016)	Loss 2.3933 (2.2640)	Acc@1 35.938 (38.636)	Acc@5 70.312 (72.585)
Epoch: [18][20/391]	Time 0.086 (0.090)	Data 0.001 (0.009)	Loss 2.1960 (2.2733)	Acc@1 37.500 (37.872)	Acc@5 75.781 (72.247)
Epoch: [18][30/391]	Time 0.087 (0.089)	Data 0.001 (0.006)	Loss 1.9774 (2.2557)	Acc@1 42.188 (38.332)	Acc@5 78.125 (72.858)
Epoch: [18][40/391]	Time 0.090 (0.089)	Data 0.001 (0.005)	Loss 2.6041 (2.2940)	Acc@1 35.156 (37.386)	Acc@5 64.062 (72.237)
Epoch: [18][50/391]	Time 0.090 (0.089)	Data 0.001 (0.004)	Loss 2.1637 (2.2928)	Acc@1 40.625 (37.194)	Acc@5 75.000 (72.396)
Epoch: [18][60/391]	Time 0.088 (0.089)	Data 0.001 (0.004)	Loss 2.4696 (2.3103)	Acc@1 36.719 (36.962)	Acc@5 72.656 (72.208)
Epoch: [18][70/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.3315 (2.3101)	Acc@1 35.156 (37.104)	Acc@5 71.094 (72.249)
Epoch: [18][80/391]	Time 0.086 (0.089)	Data 0.001 (0.003)	Loss 2.0737 (2.2990)	Acc@1 46.875 (37.645)	Acc@5 75.781 (72.483)
Epoch: [18][90/391]	Time 0.095 (0.089)	Data 0.001 (0.003)	Loss 2.4627 (2.3007)	Acc@1 35.938 (37.397)	Acc@5 72.656 (72.570)
Epoch: [18][100/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.2835 (2.3005)	Acc@1 37.500 (37.570)	Acc@5 75.781 (72.502)
Epoch: [18][110/391]	Time 0.089 (0.089)	Data 0.001 (0.003)	Loss 2.1447 (2.2988)	Acc@1 37.500 (37.627)	Acc@5 75.000 (72.572)
Epoch: [18][120/391]	Time 0.087 (0.089)	Data 0.001 (0.003)	Loss 2.2962 (2.3005)	Acc@1 41.406 (37.565)	Acc@5 74.219 (72.495)
Epoch: [18][130/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.2173 (2.3060)	Acc@1 38.281 (37.393)	Acc@5 78.125 (72.412)
Epoch: [18][140/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2942 (2.3079)	Acc@1 34.375 (37.295)	Acc@5 70.312 (72.318)
Epoch: [18][150/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1867 (2.3085)	Acc@1 39.062 (37.278)	Acc@5 74.219 (72.232)
Epoch: [18][160/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.1665 (2.3076)	Acc@1 35.938 (37.379)	Acc@5 74.219 (72.122)
Epoch: [18][170/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2923 (2.3071)	Acc@1 34.375 (37.441)	Acc@5 74.219 (71.989)
Epoch: [18][180/391]	Time 0.094 (0.089)	Data 0.001 (0.002)	Loss 2.3562 (2.3073)	Acc@1 42.188 (37.504)	Acc@5 68.750 (71.905)
Epoch: [18][190/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3520 (2.3108)	Acc@1 28.125 (37.443)	Acc@5 72.656 (71.826)
Epoch: [18][200/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2814 (2.3104)	Acc@1 42.969 (37.496)	Acc@5 71.094 (71.871)
Epoch: [18][210/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2134 (2.3118)	Acc@1 39.062 (37.474)	Acc@5 75.000 (71.868)
Epoch: [18][220/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.2511 (2.3133)	Acc@1 33.594 (37.415)	Acc@5 75.000 (71.783)
Epoch: [18][230/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3815 (2.3159)	Acc@1 33.594 (37.304)	Acc@5 70.312 (71.709)
Epoch: [18][240/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4384 (2.3185)	Acc@1 34.375 (37.215)	Acc@5 67.188 (71.684)
Epoch: [18][250/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.2671 (2.3151)	Acc@1 38.281 (37.260)	Acc@5 68.750 (71.704)
Epoch: [18][260/391]	Time 0.093 (0.089)	Data 0.001 (0.002)	Loss 2.3420 (2.3155)	Acc@1 32.812 (37.225)	Acc@5 68.750 (71.662)
Epoch: [18][270/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.1831 (2.3149)	Acc@1 35.156 (37.194)	Acc@5 78.125 (71.688)
Epoch: [18][280/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3402 (2.3154)	Acc@1 42.188 (37.177)	Acc@5 70.312 (71.666)
Epoch: [18][290/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.4653 (2.3139)	Acc@1 35.938 (37.202)	Acc@5 67.969 (71.679)
Epoch: [18][300/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1439 (2.3145)	Acc@1 39.062 (37.168)	Acc@5 76.562 (71.686)
Epoch: [18][310/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.5646 (2.3133)	Acc@1 28.125 (37.181)	Acc@5 63.281 (71.714)
Epoch: [18][320/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2962 (2.3132)	Acc@1 39.062 (37.154)	Acc@5 72.656 (71.729)
Epoch: [18][330/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.4361 (2.3129)	Acc@1 35.156 (37.172)	Acc@5 67.969 (71.750)
Epoch: [18][340/391]	Time 0.083 (0.089)	Data 0.001 (0.002)	Loss 2.2533 (2.3150)	Acc@1 35.156 (37.092)	Acc@5 75.000 (71.719)
Epoch: [18][350/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4114 (2.3155)	Acc@1 32.031 (37.064)	Acc@5 69.531 (71.681)
Epoch: [18][360/391]	Time 0.088 (0.089)	Data 0.002 (0.002)	Loss 2.1235 (2.3160)	Acc@1 41.406 (37.115)	Acc@5 77.344 (71.689)
Epoch: [18][370/391]	Time 0.089 (0.089)	Data 0.002 (0.002)	Loss 2.1996 (2.3158)	Acc@1 37.500 (37.119)	Acc@5 72.656 (71.683)
Epoch: [18][380/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.2708 (2.3151)	Acc@1 39.844 (37.133)	Acc@5 71.094 (71.690)
Epoch: [18][390/391]	Time 0.077 (0.089)	Data 0.001 (0.002)	Loss 2.6188 (2.3170)	Acc@1 28.750 (37.090)	Acc@5 68.750 (71.660)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [19][0/391]	Time 0.098 (0.098)	Data 0.186 (0.186)	Loss 2.1740 (2.1740)	Acc@1 46.094 (46.094)	Acc@5 77.344 (77.344)
Epoch: [19][10/391]	Time 0.098 (0.093)	Data 0.001 (0.018)	Loss 2.1647 (2.3381)	Acc@1 44.531 (37.145)	Acc@5 74.219 (71.662)
Epoch: [19][20/391]	Time 0.088 (0.091)	Data 0.001 (0.010)	Loss 2.6348 (2.3454)	Acc@1 28.906 (36.496)	Acc@5 67.969 (71.503)
Epoch: [19][30/391]	Time 0.088 (0.090)	Data 0.001 (0.007)	Loss 2.4349 (2.3392)	Acc@1 35.156 (36.668)	Acc@5 71.094 (71.825)
Epoch: [19][40/391]	Time 0.088 (0.090)	Data 0.001 (0.006)	Loss 2.3747 (2.3338)	Acc@1 35.938 (36.700)	Acc@5 70.312 (72.046)
Epoch: [19][50/391]	Time 0.088 (0.089)	Data 0.001 (0.005)	Loss 2.2637 (2.3341)	Acc@1 36.719 (36.780)	Acc@5 74.219 (72.166)
Epoch: [19][60/391]	Time 0.089 (0.089)	Data 0.001 (0.004)	Loss 2.0959 (2.3168)	Acc@1 47.656 (37.295)	Acc@5 79.688 (72.439)
Epoch: [19][70/391]	Time 0.085 (0.089)	Data 0.001 (0.004)	Loss 2.2843 (2.3201)	Acc@1 40.625 (37.214)	Acc@5 71.875 (72.348)
Epoch: [19][80/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.3404 (2.3108)	Acc@1 39.062 (37.760)	Acc@5 71.094 (72.386)
Epoch: [19][90/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.2169 (2.3056)	Acc@1 32.812 (37.706)	Acc@5 72.656 (72.536)
Epoch: [19][100/391]	Time 0.090 (0.089)	Data 0.001 (0.003)	Loss 2.1372 (2.3110)	Acc@1 41.406 (37.631)	Acc@5 75.000 (72.424)
Epoch: [19][110/391]	Time 0.088 (0.089)	Data 0.001 (0.003)	Loss 2.0613 (2.3131)	Acc@1 46.875 (37.549)	Acc@5 77.344 (72.290)
Epoch: [19][120/391]	Time 0.093 (0.089)	Data 0.001 (0.003)	Loss 2.2494 (2.3130)	Acc@1 39.062 (37.403)	Acc@5 72.656 (72.269)
Epoch: [19][130/391]	Time 0.094 (0.089)	Data 0.001 (0.003)	Loss 2.4408 (2.3159)	Acc@1 41.406 (37.357)	Acc@5 66.406 (72.114)
Epoch: [19][140/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.4353 (2.3149)	Acc@1 39.844 (37.489)	Acc@5 71.875 (72.030)
Epoch: [19][150/391]	Time 0.085 (0.089)	Data 0.001 (0.002)	Loss 2.1654 (2.3125)	Acc@1 39.062 (37.438)	Acc@5 78.125 (72.113)
Epoch: [19][160/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2676 (2.3086)	Acc@1 40.625 (37.461)	Acc@5 71.094 (72.253)
Epoch: [19][170/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3974 (2.3085)	Acc@1 35.938 (37.523)	Acc@5 70.312 (72.250)
Epoch: [19][180/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.3159 (2.3093)	Acc@1 32.812 (37.465)	Acc@5 70.312 (72.186)
Epoch: [19][190/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.4350 (2.3128)	Acc@1 35.156 (37.398)	Acc@5 71.875 (72.129)
Epoch: [19][200/391]	Time 0.086 (0.089)	Data 0.001 (0.002)	Loss 2.3789 (2.3129)	Acc@1 34.375 (37.387)	Acc@5 70.312 (72.097)
Epoch: [19][210/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3190 (2.3149)	Acc@1 38.281 (37.333)	Acc@5 67.188 (72.079)
Epoch: [19][220/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2379 (2.3110)	Acc@1 37.500 (37.390)	Acc@5 75.781 (72.225)
Epoch: [19][230/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3465 (2.3128)	Acc@1 35.938 (37.267)	Acc@5 71.875 (72.217)
Epoch: [19][240/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3686 (2.3132)	Acc@1 35.938 (37.299)	Acc@5 71.094 (72.206)
Epoch: [19][250/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.3570 (2.3143)	Acc@1 32.812 (37.186)	Acc@5 73.438 (72.158)
Epoch: [19][260/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3854 (2.3099)	Acc@1 35.156 (37.299)	Acc@5 67.188 (72.231)
Epoch: [19][270/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.4714 (2.3103)	Acc@1 30.469 (37.290)	Acc@5 66.406 (72.224)
Epoch: [19][280/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.0553 (2.3108)	Acc@1 37.500 (37.266)	Acc@5 81.250 (72.209)
Epoch: [19][290/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.2905 (2.3129)	Acc@1 41.406 (37.226)	Acc@5 73.438 (72.192)
Epoch: [19][300/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.0027 (2.3110)	Acc@1 44.531 (37.243)	Acc@5 81.250 (72.241)
Epoch: [19][310/391]	Time 0.087 (0.089)	Data 0.001 (0.002)	Loss 2.1586 (2.3120)	Acc@1 44.531 (37.264)	Acc@5 75.781 (72.254)
Epoch: [19][320/391]	Time 0.090 (0.089)	Data 0.001 (0.002)	Loss 2.3539 (2.3121)	Acc@1 37.500 (37.281)	Acc@5 71.094 (72.311)
Epoch: [19][330/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.1137 (2.3127)	Acc@1 36.719 (37.257)	Acc@5 74.219 (72.264)
Epoch: [19][340/391]	Time 0.088 (0.089)	Data 0.001 (0.002)	Loss 2.3091 (2.3122)	Acc@1 33.594 (37.317)	Acc@5 72.656 (72.262)
Epoch: [19][350/391]	Time 0.089 (0.089)	Data 0.001 (0.002)	Loss 2.1823 (2.3110)	Acc@1 40.625 (37.293)	Acc@5 69.531 (72.258)
Epoch: [19][360/391]	Time 0.092 (0.089)	Data 0.001 (0.002)	Loss 2.2940 (2.3108)	Acc@1 37.500 (37.305)	Acc@5 74.219 (72.241)
Epoch: [19][370/391]	Time 0.084 (0.089)	Data 0.001 (0.002)	Loss 2.2594 (2.3116)	Acc@1 39.062 (37.268)	Acc@5 70.312 (72.199)
Epoch: [19][380/391]	Time 0.091 (0.089)	Data 0.001 (0.002)	Loss 2.5357 (2.3139)	Acc@1 26.562 (37.158)	Acc@5 65.625 (72.133)
Epoch: [19][390/391]	Time 0.074 (0.089)	Data 0.001 (0.002)	Loss 2.5563 (2.3145)	Acc@1 35.000 (37.154)	Acc@5 72.500 (72.114)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [20][0/391]	Time 0.098 (0.098)	Data 0.157 (0.157)	Loss 2.0797 (2.0797)	Acc@1 41.406 (41.406)	Acc@5 77.344 (77.344)
Epoch: [20][10/391]	Time 0.091 (0.088)	Data 0.001 (0.015)	Loss 2.2832 (2.2546)	Acc@1 37.500 (38.920)	Acc@5 70.312 (73.153)
Epoch: [20][20/391]	Time 0.087 (0.088)	Data 0.001 (0.009)	Loss 2.2378 (2.2160)	Acc@1 39.844 (39.881)	Acc@5 75.781 (73.847)
Epoch: [20][30/391]	Time 0.088 (0.088)	Data 0.001 (0.006)	Loss 2.3967 (2.2342)	Acc@1 33.594 (38.785)	Acc@5 68.750 (73.034)
Epoch: [20][40/391]	Time 0.087 (0.088)	Data 0.001 (0.005)	Loss 2.5818 (2.2639)	Acc@1 32.812 (38.205)	Acc@5 62.500 (72.828)
Epoch: [20][50/391]	Time 0.090 (0.088)	Data 0.001 (0.004)	Loss 2.1422 (2.2620)	Acc@1 47.656 (38.251)	Acc@5 72.656 (73.116)
Epoch: [20][60/391]	Time 0.086 (0.088)	Data 0.001 (0.004)	Loss 2.4302 (2.2609)	Acc@1 32.812 (38.473)	Acc@5 69.531 (73.284)
Epoch: [20][70/391]	Time 0.089 (0.088)	Data 0.001 (0.003)	Loss 2.4956 (2.2642)	Acc@1 37.500 (38.666)	Acc@5 71.875 (73.140)
Epoch: [20][80/391]	Time 0.087 (0.088)	Data 0.001 (0.003)	Loss 2.3161 (2.2671)	Acc@1 38.281 (38.551)	Acc@5 69.531 (72.946)
Epoch: [20][90/391]	Time 0.092 (0.088)	Data 0.001 (0.003)	Loss 2.1599 (2.2806)	Acc@1 42.969 (38.333)	Acc@5 73.438 (72.751)
Epoch: [20][100/391]	Time 0.090 (0.088)	Data 0.001 (0.003)	Loss 2.5160 (2.2875)	Acc@1 39.062 (38.235)	Acc@5 67.969 (72.432)
Epoch: [20][110/391]	Time 0.092 (0.088)	Data 0.001 (0.003)	Loss 2.6993 (2.2969)	Acc@1 25.781 (37.880)	Acc@5 61.719 (72.135)
Epoch: [20][120/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.6429 (2.2957)	Acc@1 25.781 (37.920)	Acc@5 63.281 (72.191)
Epoch: [20][130/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3362 (2.3022)	Acc@1 35.156 (37.542)	Acc@5 72.656 (72.096)
Epoch: [20][140/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4274 (2.3006)	Acc@1 41.406 (37.716)	Acc@5 65.625 (72.052)
Epoch: [20][150/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.2918 (2.3052)	Acc@1 34.375 (37.505)	Acc@5 74.219 (71.958)
Epoch: [20][160/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.4615 (2.3030)	Acc@1 32.812 (37.447)	Acc@5 73.438 (72.021)
Epoch: [20][170/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.0952 (2.2983)	Acc@1 42.969 (37.413)	Acc@5 74.219 (72.186)
Epoch: [20][180/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.3127 (2.2995)	Acc@1 39.062 (37.362)	Acc@5 69.531 (72.104)
Epoch: [20][190/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3416 (2.3024)	Acc@1 33.594 (37.275)	Acc@5 75.000 (72.129)
Epoch: [20][200/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.5055 (2.3087)	Acc@1 34.375 (37.111)	Acc@5 67.969 (72.046)
Epoch: [20][210/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.4912 (2.3125)	Acc@1 36.719 (37.008)	Acc@5 67.188 (71.953)
Epoch: [20][220/391]	Time 0.085 (0.088)	Data 0.001 (0.002)	Loss 2.3555 (2.3150)	Acc@1 36.719 (36.977)	Acc@5 73.438 (71.942)
Epoch: [20][230/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.2373 (2.3130)	Acc@1 42.969 (37.057)	Acc@5 72.656 (71.976)
Epoch: [20][240/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.3382 (2.3118)	Acc@1 29.688 (37.069)	Acc@5 74.219 (71.982)
Epoch: [20][250/391]	Time 0.089 (0.088)	Data 0.001 (0.002)	Loss 2.1871 (2.3131)	Acc@1 37.500 (37.021)	Acc@5 75.781 (71.953)
Epoch: [20][260/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.2325 (2.3150)	Acc@1 40.625 (36.958)	Acc@5 75.781 (71.896)
Epoch: [20][270/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.1063 (2.3103)	Acc@1 40.625 (37.036)	Acc@5 74.219 (72.005)
Epoch: [20][280/391]	Time 0.084 (0.088)	Data 0.001 (0.002)	Loss 2.3908 (2.3103)	Acc@1 34.375 (37.061)	Acc@5 75.000 (72.039)
Epoch: [20][290/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.5082 (2.3081)	Acc@1 35.156 (37.186)	Acc@5 67.188 (72.103)
Epoch: [20][300/391]	Time 0.087 (0.088)	Data 0.001 (0.002)	Loss 2.3004 (2.3093)	Acc@1 35.938 (37.222)	Acc@5 70.312 (72.031)
Epoch: [20][310/391]	Time 0.091 (0.088)	Data 0.001 (0.002)	Loss 2.3002 (2.3065)	Acc@1 41.406 (37.302)	Acc@5 71.094 (72.116)
Epoch: [20][320/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.3508 (2.3075)	Acc@1 30.469 (37.227)	Acc@5 69.531 (72.099)
Epoch: [20][330/391]	Time 0.094 (0.088)	Data 0.001 (0.002)	Loss 2.3254 (2.3086)	Acc@1 33.594 (37.153)	Acc@5 74.219 (72.097)
Epoch: [20][340/391]	Time 0.088 (0.088)	Data 0.001 (0.002)	Loss 2.4084 (2.3080)	Acc@1 35.938 (37.184)	Acc@5 71.094 (72.132)
Epoch: [20][350/391]	Time 0.092 (0.088)	Data 0.002 (0.002)	Loss 2.2907 (2.3074)	Acc@1 36.719 (37.162)	Acc@5 68.750 (72.155)
Epoch: [20][360/391]	Time 0.086 (0.088)	Data 0.001 (0.002)	Loss 2.3910 (2.3090)	Acc@1 33.594 (37.130)	Acc@5 67.969 (72.096)
Epoch: [20][370/391]	Time 0.090 (0.088)	Data 0.001 (0.002)	Loss 2.3027 (2.3095)	Acc@1 47.656 (37.178)	Acc@5 75.781 (72.107)
Epoch: [20][380/391]	Time 0.091 (0.088)	Data 0.001 (0.002)	Loss 2.1329 (2.3085)	Acc@1 41.406 (37.170)	Acc@5 73.438 (72.135)
Epoch: [20][390/391]	Time 0.072 (0.088)	Data 0.001 (0.002)	Loss 2.6725 (2.3070)	Acc@1 31.250 (37.228)	Acc@5 63.750 (72.194)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): AdaptiveAvgPool2d(output_size=(1, 1))
    (93): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Best acc:
30.51


now deeper
Epoch: [1][0/391]	Time 0.107 (0.107)	Data 0.165 (0.165)	Loss 2.4125 (2.4125)	Acc@1 32.031 (32.031)	Acc@5 67.188 (67.188)
Epoch: [1][10/391]	Time 0.095 (0.096)	Data 0.001 (0.016)	Loss 2.4271 (2.3281)	Acc@1 38.281 (38.281)	Acc@5 67.969 (71.591)
Epoch: [1][20/391]	Time 0.094 (0.096)	Data 0.001 (0.009)	Loss 2.1917 (2.3127)	Acc@1 39.844 (38.095)	Acc@5 76.562 (72.582)
Epoch: [1][30/391]	Time 0.095 (0.096)	Data 0.001 (0.006)	Loss 2.3359 (2.3234)	Acc@1 32.031 (36.895)	Acc@5 70.312 (72.228)
Epoch: [1][40/391]	Time 0.095 (0.096)	Data 0.001 (0.005)	Loss 2.3490 (2.3182)	Acc@1 33.594 (36.852)	Acc@5 69.531 (72.294)
Epoch: [1][50/391]	Time 0.097 (0.096)	Data 0.001 (0.004)	Loss 2.3629 (2.3230)	Acc@1 36.719 (36.458)	Acc@5 68.750 (72.028)
Epoch: [1][60/391]	Time 0.093 (0.096)	Data 0.001 (0.004)	Loss 2.2948 (2.3212)	Acc@1 35.938 (36.424)	Acc@5 72.656 (72.362)
Epoch: [1][70/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.4909 (2.3063)	Acc@1 39.844 (36.950)	Acc@5 66.406 (72.755)
Epoch: [1][80/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.1180 (2.3032)	Acc@1 43.750 (37.114)	Acc@5 76.562 (72.637)
Epoch: [1][90/391]	Time 0.093 (0.096)	Data 0.001 (0.003)	Loss 2.1790 (2.3040)	Acc@1 38.281 (37.165)	Acc@5 76.562 (72.553)
Epoch: [1][100/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.3315 (2.3028)	Acc@1 34.375 (37.299)	Acc@5 71.094 (72.386)
Epoch: [1][110/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.0309 (2.2965)	Acc@1 45.312 (37.444)	Acc@5 78.906 (72.558)
Epoch: [1][120/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.2244 (2.2939)	Acc@1 43.750 (37.584)	Acc@5 72.656 (72.553)
Epoch: [1][130/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.0610 (2.2954)	Acc@1 46.094 (37.583)	Acc@5 74.219 (72.525)
Epoch: [1][140/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3814 (2.2976)	Acc@1 35.156 (37.600)	Acc@5 72.656 (72.424)
Epoch: [1][150/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3776 (2.2985)	Acc@1 29.688 (37.505)	Acc@5 69.531 (72.418)
Epoch: [1][160/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.2714 (2.2993)	Acc@1 44.531 (37.447)	Acc@5 71.094 (72.385)
Epoch: [1][170/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.1107 (2.3021)	Acc@1 41.406 (37.404)	Acc@5 77.344 (72.286)
Epoch: [1][180/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.4476 (2.3046)	Acc@1 35.156 (37.418)	Acc@5 66.406 (72.255)
Epoch: [1][190/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3592 (2.3019)	Acc@1 36.719 (37.533)	Acc@5 69.531 (72.317)
Epoch: [1][200/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3531 (2.2999)	Acc@1 39.062 (37.523)	Acc@5 71.094 (72.279)
Epoch: [1][210/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3202 (2.2981)	Acc@1 28.125 (37.544)	Acc@5 70.312 (72.327)
Epoch: [1][220/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3561 (2.2980)	Acc@1 37.500 (37.606)	Acc@5 72.656 (72.342)
Epoch: [1][230/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.1187 (2.2992)	Acc@1 39.844 (37.520)	Acc@5 78.125 (72.355)
Epoch: [1][240/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.4517 (2.2992)	Acc@1 29.688 (37.494)	Acc@5 71.875 (72.355)
Epoch: [1][250/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3411 (2.3032)	Acc@1 38.281 (37.472)	Acc@5 68.750 (72.295)
Epoch: [1][260/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4523 (2.3045)	Acc@1 33.594 (37.434)	Acc@5 71.875 (72.234)
Epoch: [1][270/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2036 (2.3060)	Acc@1 44.531 (37.442)	Acc@5 71.094 (72.111)
Epoch: [1][280/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.3661 (2.3046)	Acc@1 37.500 (37.439)	Acc@5 72.656 (72.106)
Epoch: [1][290/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1659 (2.3030)	Acc@1 40.625 (37.492)	Acc@5 74.219 (72.170)
Epoch: [1][300/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4240 (2.3022)	Acc@1 34.375 (37.529)	Acc@5 66.406 (72.166)
Epoch: [1][310/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3395 (2.3002)	Acc@1 32.812 (37.538)	Acc@5 72.656 (72.204)
Epoch: [1][320/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1714 (2.3001)	Acc@1 39.844 (37.522)	Acc@5 75.781 (72.148)
Epoch: [1][330/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2222 (2.2995)	Acc@1 46.875 (37.542)	Acc@5 75.000 (72.213)
Epoch: [1][340/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.2357 (2.3010)	Acc@1 40.625 (37.500)	Acc@5 73.438 (72.175)
Epoch: [1][350/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0457 (2.3022)	Acc@1 40.625 (37.458)	Acc@5 78.125 (72.160)
Epoch: [1][360/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2751 (2.3012)	Acc@1 36.719 (37.496)	Acc@5 75.000 (72.178)
Epoch: [1][370/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.2494 (2.3012)	Acc@1 35.938 (37.479)	Acc@5 71.875 (72.174)
Epoch: [1][380/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.3606 (2.3000)	Acc@1 34.375 (37.502)	Acc@5 72.656 (72.215)
Epoch: [1][390/391]	Time 0.079 (0.096)	Data 0.001 (0.002)	Loss 2.4103 (2.2996)	Acc@1 31.250 (37.498)	Acc@5 73.750 (72.246)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [2][0/391]	Time 0.112 (0.112)	Data 0.183 (0.183)	Loss 2.2372 (2.2372)	Acc@1 36.719 (36.719)	Acc@5 78.906 (78.906)
Epoch: [2][10/391]	Time 0.095 (0.097)	Data 0.001 (0.017)	Loss 2.1181 (2.2563)	Acc@1 40.625 (36.932)	Acc@5 78.125 (75.213)
Epoch: [2][20/391]	Time 0.098 (0.096)	Data 0.001 (0.010)	Loss 2.1971 (2.2735)	Acc@1 41.406 (37.463)	Acc@5 73.438 (73.772)
Epoch: [2][30/391]	Time 0.091 (0.096)	Data 0.001 (0.007)	Loss 2.2526 (2.2908)	Acc@1 32.031 (37.172)	Acc@5 76.562 (73.034)
Epoch: [2][40/391]	Time 0.096 (0.095)	Data 0.001 (0.006)	Loss 2.0486 (2.2881)	Acc@1 45.312 (37.062)	Acc@5 80.469 (73.075)
Epoch: [2][50/391]	Time 0.092 (0.095)	Data 0.001 (0.005)	Loss 2.1868 (2.2878)	Acc@1 40.625 (37.362)	Acc@5 73.438 (72.947)
Epoch: [2][60/391]	Time 0.095 (0.095)	Data 0.001 (0.004)	Loss 2.4156 (2.2798)	Acc@1 32.812 (37.705)	Acc@5 69.531 (73.053)
Epoch: [2][70/391]	Time 0.094 (0.095)	Data 0.001 (0.004)	Loss 2.3315 (2.2822)	Acc@1 32.812 (37.698)	Acc@5 76.562 (72.920)
Epoch: [2][80/391]	Time 0.093 (0.095)	Data 0.001 (0.003)	Loss 2.3257 (2.2852)	Acc@1 39.844 (37.568)	Acc@5 68.750 (72.791)
Epoch: [2][90/391]	Time 0.095 (0.095)	Data 0.001 (0.003)	Loss 2.2779 (2.2895)	Acc@1 39.844 (37.345)	Acc@5 75.000 (72.802)
Epoch: [2][100/391]	Time 0.093 (0.095)	Data 0.001 (0.003)	Loss 2.4609 (2.2869)	Acc@1 32.812 (37.554)	Acc@5 67.969 (72.826)
Epoch: [2][110/391]	Time 0.095 (0.095)	Data 0.001 (0.003)	Loss 1.9248 (2.2907)	Acc@1 46.875 (37.613)	Acc@5 80.469 (72.755)
Epoch: [2][120/391]	Time 0.103 (0.095)	Data 0.001 (0.003)	Loss 2.1467 (2.2882)	Acc@1 41.406 (37.584)	Acc@5 75.000 (72.798)
Epoch: [2][130/391]	Time 0.099 (0.095)	Data 0.001 (0.003)	Loss 2.3586 (2.2826)	Acc@1 35.938 (37.685)	Acc@5 67.969 (72.931)
Epoch: [2][140/391]	Time 0.099 (0.095)	Data 0.001 (0.002)	Loss 2.2073 (2.2806)	Acc@1 35.938 (37.655)	Acc@5 69.531 (72.883)
Epoch: [2][150/391]	Time 0.096 (0.095)	Data 0.001 (0.002)	Loss 2.1218 (2.2814)	Acc@1 38.281 (37.697)	Acc@5 78.125 (72.899)
Epoch: [2][160/391]	Time 0.100 (0.095)	Data 0.001 (0.002)	Loss 2.3164 (2.2829)	Acc@1 38.281 (37.786)	Acc@5 73.438 (72.884)
Epoch: [2][170/391]	Time 0.094 (0.095)	Data 0.001 (0.002)	Loss 2.4505 (2.2849)	Acc@1 36.719 (37.802)	Acc@5 65.625 (72.738)
Epoch: [2][180/391]	Time 0.101 (0.095)	Data 0.001 (0.002)	Loss 2.3813 (2.2863)	Acc@1 39.062 (37.768)	Acc@5 68.750 (72.691)
Epoch: [2][190/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3536 (2.2854)	Acc@1 38.281 (37.750)	Acc@5 75.781 (72.685)
Epoch: [2][200/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2902 (2.2870)	Acc@1 34.375 (37.644)	Acc@5 71.094 (72.621)
Epoch: [2][210/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.3553 (2.2879)	Acc@1 40.625 (37.707)	Acc@5 71.094 (72.578)
Epoch: [2][220/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1198 (2.2881)	Acc@1 42.969 (37.677)	Acc@5 75.000 (72.571)
Epoch: [2][230/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 1.9909 (2.2881)	Acc@1 46.875 (37.591)	Acc@5 78.906 (72.626)
Epoch: [2][240/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.0225 (2.2837)	Acc@1 46.875 (37.737)	Acc@5 75.781 (72.698)
Epoch: [2][250/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.2072 (2.2830)	Acc@1 39.844 (37.786)	Acc@5 73.438 (72.666)
Epoch: [2][260/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.5248 (2.2854)	Acc@1 35.156 (37.710)	Acc@5 67.969 (72.554)
Epoch: [2][270/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.3780 (2.2880)	Acc@1 35.938 (37.638)	Acc@5 69.531 (72.452)
Epoch: [2][280/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.1759 (2.2911)	Acc@1 44.531 (37.628)	Acc@5 71.875 (72.375)
Epoch: [2][290/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.0470 (2.2905)	Acc@1 41.406 (37.618)	Acc@5 79.688 (72.415)
Epoch: [2][300/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2770 (2.2901)	Acc@1 39.844 (37.643)	Acc@5 68.750 (72.417)
Epoch: [2][310/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1688 (2.2895)	Acc@1 34.375 (37.606)	Acc@5 75.000 (72.448)
Epoch: [2][320/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3149 (2.2898)	Acc@1 36.719 (37.580)	Acc@5 74.219 (72.442)
Epoch: [2][330/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1015 (2.2931)	Acc@1 38.281 (37.472)	Acc@5 78.906 (72.380)
Epoch: [2][340/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.1594 (2.2926)	Acc@1 35.156 (37.493)	Acc@5 71.875 (72.386)
Epoch: [2][350/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.4045 (2.2949)	Acc@1 39.062 (37.493)	Acc@5 72.656 (72.320)
Epoch: [2][360/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1541 (2.2969)	Acc@1 39.062 (37.446)	Acc@5 76.562 (72.286)
Epoch: [2][370/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.3253 (2.2975)	Acc@1 39.844 (37.416)	Acc@5 67.188 (72.290)
Epoch: [2][380/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.5192 (2.3010)	Acc@1 30.469 (37.330)	Acc@5 60.938 (72.197)
Epoch: [2][390/391]	Time 0.081 (0.096)	Data 0.001 (0.002)	Loss 1.9313 (2.3018)	Acc@1 50.000 (37.306)	Acc@5 81.250 (72.180)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [3][0/391]	Time 0.109 (0.109)	Data 0.165 (0.165)	Loss 2.2893 (2.2893)	Acc@1 30.469 (30.469)	Acc@5 76.562 (76.562)
Epoch: [3][10/391]	Time 0.094 (0.098)	Data 0.001 (0.016)	Loss 2.3652 (2.3560)	Acc@1 39.062 (34.872)	Acc@5 74.219 (71.094)
Epoch: [3][20/391]	Time 0.101 (0.098)	Data 0.001 (0.009)	Loss 2.3355 (2.2998)	Acc@1 39.062 (36.086)	Acc@5 71.875 (72.954)
Epoch: [3][30/391]	Time 0.094 (0.098)	Data 0.001 (0.006)	Loss 2.2427 (2.3082)	Acc@1 36.719 (36.694)	Acc@5 72.656 (72.757)
Epoch: [3][40/391]	Time 0.100 (0.098)	Data 0.001 (0.005)	Loss 2.1947 (2.3107)	Acc@1 42.969 (36.947)	Acc@5 77.344 (72.199)
Epoch: [3][50/391]	Time 0.096 (0.098)	Data 0.001 (0.004)	Loss 2.2048 (2.3007)	Acc@1 32.031 (36.673)	Acc@5 75.781 (72.503)
Epoch: [3][60/391]	Time 0.101 (0.098)	Data 0.001 (0.004)	Loss 2.0866 (2.2986)	Acc@1 43.750 (36.885)	Acc@5 75.000 (72.515)
Epoch: [3][70/391]	Time 0.097 (0.098)	Data 0.001 (0.003)	Loss 2.0606 (2.2933)	Acc@1 41.406 (37.082)	Acc@5 80.469 (72.579)
Epoch: [3][80/391]	Time 0.096 (0.098)	Data 0.001 (0.003)	Loss 2.3420 (2.2890)	Acc@1 37.500 (37.413)	Acc@5 71.875 (72.512)
Epoch: [3][90/391]	Time 0.094 (0.097)	Data 0.001 (0.003)	Loss 2.0737 (2.2824)	Acc@1 41.406 (37.586)	Acc@5 82.031 (72.768)
Epoch: [3][100/391]	Time 0.100 (0.097)	Data 0.001 (0.003)	Loss 2.2581 (2.2867)	Acc@1 42.969 (37.539)	Acc@5 77.344 (72.726)
Epoch: [3][110/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 2.2708 (2.2894)	Acc@1 37.500 (37.521)	Acc@5 71.875 (72.586)
Epoch: [3][120/391]	Time 0.104 (0.097)	Data 0.001 (0.003)	Loss 2.2152 (2.2886)	Acc@1 39.844 (37.577)	Acc@5 71.094 (72.566)
Epoch: [3][130/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.2970 (2.2893)	Acc@1 36.719 (37.578)	Acc@5 73.438 (72.495)
Epoch: [3][140/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.1013 (2.2843)	Acc@1 37.500 (37.661)	Acc@5 77.344 (72.601)
Epoch: [3][150/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2940 (2.2846)	Acc@1 36.719 (37.635)	Acc@5 76.562 (72.584)
Epoch: [3][160/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.0839 (2.2840)	Acc@1 48.438 (37.694)	Acc@5 76.562 (72.559)
Epoch: [3][170/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 1.8984 (2.2808)	Acc@1 40.625 (37.770)	Acc@5 87.500 (72.656)
Epoch: [3][180/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1711 (2.2850)	Acc@1 39.062 (37.655)	Acc@5 78.906 (72.557)
Epoch: [3][190/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.0510 (2.2855)	Acc@1 39.844 (37.590)	Acc@5 75.000 (72.566)
Epoch: [3][200/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.1535 (2.2851)	Acc@1 42.969 (37.648)	Acc@5 74.219 (72.532)
Epoch: [3][210/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.2694 (2.2882)	Acc@1 44.531 (37.559)	Acc@5 71.094 (72.453)
Epoch: [3][220/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.2965 (2.2913)	Acc@1 35.938 (37.465)	Acc@5 73.438 (72.409)
Epoch: [3][230/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.4047 (2.2910)	Acc@1 35.156 (37.595)	Acc@5 70.312 (72.389)
Epoch: [3][240/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.6289 (2.2932)	Acc@1 35.156 (37.575)	Acc@5 67.188 (72.322)
Epoch: [3][250/391]	Time 0.106 (0.097)	Data 0.001 (0.002)	Loss 2.4570 (2.2966)	Acc@1 32.031 (37.432)	Acc@5 64.844 (72.242)
Epoch: [3][260/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.4166 (2.2983)	Acc@1 32.812 (37.392)	Acc@5 70.312 (72.210)
Epoch: [3][270/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.1676 (2.2990)	Acc@1 39.844 (37.370)	Acc@5 75.781 (72.175)
Epoch: [3][280/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2779 (2.2966)	Acc@1 39.062 (37.414)	Acc@5 71.875 (72.214)
Epoch: [3][290/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.5297 (2.2989)	Acc@1 34.375 (37.363)	Acc@5 70.312 (72.213)
Epoch: [3][300/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2529 (2.2997)	Acc@1 38.281 (37.274)	Acc@5 75.000 (72.233)
Epoch: [3][310/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.1595 (2.2969)	Acc@1 38.281 (37.297)	Acc@5 72.656 (72.277)
Epoch: [3][320/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.2870 (2.2954)	Acc@1 35.938 (37.335)	Acc@5 72.656 (72.281)
Epoch: [3][330/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.3089 (2.2958)	Acc@1 40.625 (37.328)	Acc@5 71.875 (72.272)
Epoch: [3][340/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.6450 (2.2962)	Acc@1 25.000 (37.296)	Acc@5 64.062 (72.260)
Epoch: [3][350/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.0785 (2.2953)	Acc@1 42.969 (37.380)	Acc@5 78.125 (72.273)
Epoch: [3][360/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.1695 (2.2950)	Acc@1 36.719 (37.366)	Acc@5 74.219 (72.295)
Epoch: [3][370/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2069 (2.2940)	Acc@1 36.719 (37.378)	Acc@5 76.562 (72.332)
Epoch: [3][380/391]	Time 0.103 (0.097)	Data 0.001 (0.002)	Loss 2.2595 (2.2961)	Acc@1 40.625 (37.301)	Acc@5 70.312 (72.289)
Epoch: [3][390/391]	Time 0.080 (0.097)	Data 0.001 (0.002)	Loss 2.2401 (2.2970)	Acc@1 40.000 (37.304)	Acc@5 72.500 (72.260)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [4][0/391]	Time 0.113 (0.113)	Data 0.162 (0.162)	Loss 2.2036 (2.2036)	Acc@1 35.156 (35.156)	Acc@5 75.000 (75.000)
Epoch: [4][10/391]	Time 0.099 (0.099)	Data 0.001 (0.016)	Loss 2.2474 (2.2630)	Acc@1 39.062 (37.571)	Acc@5 74.219 (72.159)
Epoch: [4][20/391]	Time 0.094 (0.097)	Data 0.001 (0.009)	Loss 2.4264 (2.2441)	Acc@1 36.719 (38.318)	Acc@5 66.406 (72.135)
Epoch: [4][30/391]	Time 0.099 (0.097)	Data 0.001 (0.006)	Loss 2.2720 (2.2660)	Acc@1 35.938 (38.029)	Acc@5 70.312 (72.203)
Epoch: [4][40/391]	Time 0.096 (0.097)	Data 0.001 (0.005)	Loss 2.1891 (2.2633)	Acc@1 39.062 (38.205)	Acc@5 76.562 (72.447)
Epoch: [4][50/391]	Time 0.095 (0.097)	Data 0.001 (0.004)	Loss 2.2341 (2.2680)	Acc@1 42.188 (38.021)	Acc@5 75.000 (72.488)
Epoch: [4][60/391]	Time 0.096 (0.097)	Data 0.001 (0.004)	Loss 2.2025 (2.2657)	Acc@1 37.500 (38.140)	Acc@5 73.438 (72.503)
Epoch: [4][70/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.3340 (2.2629)	Acc@1 43.750 (38.391)	Acc@5 71.875 (72.546)
Epoch: [4][80/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 2.3725 (2.2597)	Acc@1 37.500 (38.368)	Acc@5 71.094 (72.425)
Epoch: [4][90/391]	Time 0.098 (0.097)	Data 0.001 (0.003)	Loss 2.5015 (2.2616)	Acc@1 35.156 (38.427)	Acc@5 67.188 (72.364)
Epoch: [4][100/391]	Time 0.092 (0.097)	Data 0.001 (0.003)	Loss 2.3472 (2.2630)	Acc@1 35.156 (38.328)	Acc@5 71.875 (72.316)
Epoch: [4][110/391]	Time 0.094 (0.097)	Data 0.001 (0.003)	Loss 2.6704 (2.2687)	Acc@1 35.938 (38.302)	Acc@5 65.625 (72.361)
Epoch: [4][120/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.4445 (2.2748)	Acc@1 27.344 (37.991)	Acc@5 64.844 (72.185)
Epoch: [4][130/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.3576 (2.2795)	Acc@1 36.719 (37.947)	Acc@5 70.312 (72.078)
Epoch: [4][140/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.4173 (2.2880)	Acc@1 25.781 (37.683)	Acc@5 69.531 (71.969)
Epoch: [4][150/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.5377 (2.2917)	Acc@1 34.375 (37.619)	Acc@5 65.625 (71.896)
Epoch: [4][160/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3606 (2.2932)	Acc@1 34.375 (37.665)	Acc@5 74.219 (71.890)
Epoch: [4][170/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3489 (2.2924)	Acc@1 36.719 (37.811)	Acc@5 73.438 (71.966)
Epoch: [4][180/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2760 (2.2949)	Acc@1 36.719 (37.724)	Acc@5 70.312 (71.957)
Epoch: [4][190/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1966 (2.2934)	Acc@1 35.156 (37.733)	Acc@5 74.219 (71.936)
Epoch: [4][200/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2129 (2.2918)	Acc@1 39.844 (37.733)	Acc@5 73.438 (72.042)
Epoch: [4][210/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1779 (2.2957)	Acc@1 41.406 (37.659)	Acc@5 73.438 (71.956)
Epoch: [4][220/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1638 (2.2972)	Acc@1 38.281 (37.571)	Acc@5 68.750 (71.879)
Epoch: [4][230/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3748 (2.2962)	Acc@1 33.594 (37.629)	Acc@5 71.094 (71.909)
Epoch: [4][240/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.0075 (2.2931)	Acc@1 42.188 (37.682)	Acc@5 81.250 (72.027)
Epoch: [4][250/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3511 (2.2970)	Acc@1 40.625 (37.659)	Acc@5 71.094 (71.947)
Epoch: [4][260/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3902 (2.2975)	Acc@1 32.031 (37.641)	Acc@5 71.875 (71.959)
Epoch: [4][270/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0977 (2.2976)	Acc@1 41.406 (37.627)	Acc@5 78.125 (71.993)
Epoch: [4][280/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.4721 (2.2976)	Acc@1 34.375 (37.633)	Acc@5 67.188 (71.992)
Epoch: [4][290/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.1719 (2.2963)	Acc@1 37.500 (37.637)	Acc@5 74.219 (71.998)
Epoch: [4][300/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.2398 (2.2974)	Acc@1 36.719 (37.632)	Acc@5 73.438 (71.961)
Epoch: [4][310/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1135 (2.2982)	Acc@1 40.625 (37.528)	Acc@5 78.906 (71.963)
Epoch: [4][320/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2128 (2.2979)	Acc@1 35.938 (37.619)	Acc@5 71.094 (71.982)
Epoch: [4][330/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3096 (2.2978)	Acc@1 39.844 (37.675)	Acc@5 73.438 (72.038)
Epoch: [4][340/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1535 (2.2979)	Acc@1 46.094 (37.665)	Acc@5 76.562 (72.049)
Epoch: [4][350/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2869 (2.2994)	Acc@1 35.938 (37.620)	Acc@5 73.438 (72.035)
Epoch: [4][360/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.3316 (2.3009)	Acc@1 27.344 (37.593)	Acc@5 71.875 (71.977)
Epoch: [4][370/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.0691 (2.2986)	Acc@1 38.281 (37.641)	Acc@5 78.125 (72.062)
Epoch: [4][380/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.5986 (2.2999)	Acc@1 26.562 (37.617)	Acc@5 67.969 (72.074)
Epoch: [4][390/391]	Time 0.079 (0.096)	Data 0.001 (0.002)	Loss 1.9906 (2.2991)	Acc@1 37.500 (37.612)	Acc@5 81.250 (72.102)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [5][0/391]	Time 0.105 (0.105)	Data 0.166 (0.166)	Loss 2.2419 (2.2419)	Acc@1 37.500 (37.500)	Acc@5 69.531 (69.531)
Epoch: [5][10/391]	Time 0.097 (0.097)	Data 0.001 (0.016)	Loss 1.9949 (2.2420)	Acc@1 49.219 (38.778)	Acc@5 78.125 (73.153)
Epoch: [5][20/391]	Time 0.102 (0.097)	Data 0.001 (0.009)	Loss 2.2845 (2.2706)	Acc@1 37.500 (37.574)	Acc@5 72.656 (72.731)
Epoch: [5][30/391]	Time 0.094 (0.097)	Data 0.001 (0.006)	Loss 2.1716 (2.2769)	Acc@1 37.500 (37.727)	Acc@5 75.781 (72.404)
Epoch: [5][40/391]	Time 0.098 (0.097)	Data 0.001 (0.005)	Loss 2.1752 (2.2735)	Acc@1 46.094 (37.957)	Acc@5 74.219 (72.351)
Epoch: [5][50/391]	Time 0.096 (0.096)	Data 0.001 (0.004)	Loss 2.4281 (2.2775)	Acc@1 38.281 (38.082)	Acc@5 66.406 (72.243)
Epoch: [5][60/391]	Time 0.096 (0.096)	Data 0.001 (0.004)	Loss 2.3653 (2.2818)	Acc@1 36.719 (37.871)	Acc@5 73.438 (71.990)
Epoch: [5][70/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.2183 (2.2803)	Acc@1 40.625 (37.478)	Acc@5 73.438 (72.227)
Epoch: [5][80/391]	Time 0.098 (0.096)	Data 0.001 (0.003)	Loss 2.1451 (2.2794)	Acc@1 36.719 (37.471)	Acc@5 72.656 (72.087)
Epoch: [5][90/391]	Time 0.098 (0.096)	Data 0.001 (0.003)	Loss 2.1034 (2.2783)	Acc@1 38.281 (37.483)	Acc@5 76.562 (72.150)
Epoch: [5][100/391]	Time 0.094 (0.096)	Data 0.001 (0.003)	Loss 2.3492 (2.2802)	Acc@1 32.812 (37.415)	Acc@5 71.094 (72.146)
Epoch: [5][110/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.2237 (2.2751)	Acc@1 41.406 (37.591)	Acc@5 72.656 (72.213)
Epoch: [5][120/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.3714 (2.2754)	Acc@1 38.281 (37.603)	Acc@5 75.000 (72.411)
Epoch: [5][130/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3226 (2.2837)	Acc@1 40.625 (37.464)	Acc@5 71.875 (72.275)
Epoch: [5][140/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2424 (2.2921)	Acc@1 39.844 (37.173)	Acc@5 75.000 (72.180)
Epoch: [5][150/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3323 (2.2943)	Acc@1 33.594 (37.034)	Acc@5 73.438 (72.154)
Epoch: [5][160/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1553 (2.2949)	Acc@1 39.062 (37.034)	Acc@5 73.438 (72.200)
Epoch: [5][170/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.0554 (2.2926)	Acc@1 42.188 (37.103)	Acc@5 77.344 (72.167)
Epoch: [5][180/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3949 (2.2938)	Acc@1 34.375 (37.107)	Acc@5 67.969 (72.177)
Epoch: [5][190/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.5099 (2.2924)	Acc@1 30.469 (37.107)	Acc@5 69.531 (72.247)
Epoch: [5][200/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3957 (2.2920)	Acc@1 37.500 (37.208)	Acc@5 69.531 (72.295)
Epoch: [5][210/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.3935 (2.2939)	Acc@1 38.281 (37.148)	Acc@5 67.969 (72.242)
Epoch: [5][220/391]	Time 0.091 (0.096)	Data 0.001 (0.002)	Loss 2.1634 (2.2941)	Acc@1 42.188 (37.143)	Acc@5 74.219 (72.317)
Epoch: [5][230/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.4215 (2.2951)	Acc@1 39.062 (37.074)	Acc@5 66.406 (72.264)
Epoch: [5][240/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2770 (2.2939)	Acc@1 45.312 (37.153)	Acc@5 73.438 (72.277)
Epoch: [5][250/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4589 (2.2945)	Acc@1 38.281 (37.164)	Acc@5 68.750 (72.255)
Epoch: [5][260/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3976 (2.2978)	Acc@1 30.469 (37.075)	Acc@5 67.969 (72.159)
Epoch: [5][270/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2950 (2.2993)	Acc@1 32.812 (37.082)	Acc@5 75.000 (72.183)
Epoch: [5][280/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.1908 (2.2993)	Acc@1 31.250 (37.011)	Acc@5 78.906 (72.192)
Epoch: [5][290/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.5262 (2.3013)	Acc@1 30.469 (36.968)	Acc@5 66.406 (72.173)
Epoch: [5][300/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4212 (2.3032)	Acc@1 33.594 (36.908)	Acc@5 69.531 (72.194)
Epoch: [5][310/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.4523 (2.3045)	Acc@1 28.906 (36.864)	Acc@5 68.750 (72.151)
Epoch: [5][320/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.2790 (2.3022)	Acc@1 38.281 (36.952)	Acc@5 76.562 (72.213)
Epoch: [5][330/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2916 (2.3009)	Acc@1 39.844 (37.009)	Acc@5 68.750 (72.215)
Epoch: [5][340/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.2011 (2.2983)	Acc@1 47.656 (37.138)	Acc@5 77.344 (72.269)
Epoch: [5][350/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.2587 (2.2984)	Acc@1 36.719 (37.082)	Acc@5 73.438 (72.282)
Epoch: [5][360/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2718 (2.2991)	Acc@1 37.500 (37.054)	Acc@5 75.000 (72.299)
Epoch: [5][370/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.0990 (2.2981)	Acc@1 42.969 (37.087)	Acc@5 83.594 (72.355)
Epoch: [5][380/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4956 (2.2968)	Acc@1 34.375 (37.098)	Acc@5 67.188 (72.355)
Epoch: [5][390/391]	Time 0.079 (0.096)	Data 0.001 (0.002)	Loss 2.5220 (2.2960)	Acc@1 30.000 (37.120)	Acc@5 71.250 (72.402)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [6][0/391]	Time 0.104 (0.104)	Data 0.168 (0.168)	Loss 2.3397 (2.3397)	Acc@1 37.500 (37.500)	Acc@5 65.625 (65.625)
Epoch: [6][10/391]	Time 0.094 (0.098)	Data 0.001 (0.016)	Loss 2.4632 (2.2985)	Acc@1 36.719 (37.287)	Acc@5 66.406 (70.810)
Epoch: [6][20/391]	Time 0.096 (0.097)	Data 0.001 (0.009)	Loss 2.3134 (2.2845)	Acc@1 33.594 (36.942)	Acc@5 73.438 (71.949)
Epoch: [6][30/391]	Time 0.095 (0.097)	Data 0.001 (0.007)	Loss 2.3913 (2.2608)	Acc@1 34.375 (37.979)	Acc@5 67.969 (72.833)
Epoch: [6][40/391]	Time 0.098 (0.097)	Data 0.001 (0.005)	Loss 2.5879 (2.2776)	Acc@1 35.156 (37.576)	Acc@5 69.531 (72.504)
Epoch: [6][50/391]	Time 0.097 (0.097)	Data 0.001 (0.004)	Loss 2.3651 (2.2839)	Acc@1 37.500 (37.500)	Acc@5 68.750 (72.518)
Epoch: [6][60/391]	Time 0.099 (0.097)	Data 0.001 (0.004)	Loss 2.3729 (2.2827)	Acc@1 33.594 (37.718)	Acc@5 70.312 (72.477)
Epoch: [6][70/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.3891 (2.2737)	Acc@1 36.719 (37.874)	Acc@5 71.094 (72.755)
Epoch: [6][80/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 2.2081 (2.2658)	Acc@1 37.500 (37.915)	Acc@5 75.000 (73.003)
Epoch: [6][90/391]	Time 0.093 (0.097)	Data 0.001 (0.003)	Loss 2.4935 (2.2688)	Acc@1 35.938 (37.843)	Acc@5 67.188 (72.948)
Epoch: [6][100/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 2.0409 (2.2659)	Acc@1 47.656 (38.011)	Acc@5 77.344 (72.950)
Epoch: [6][110/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.6054 (2.2679)	Acc@1 26.562 (37.852)	Acc@5 64.062 (72.846)
Epoch: [6][120/391]	Time 0.094 (0.096)	Data 0.001 (0.003)	Loss 2.4058 (2.2747)	Acc@1 33.594 (37.765)	Acc@5 71.094 (72.701)
Epoch: [6][130/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.5299 (2.2810)	Acc@1 36.719 (37.554)	Acc@5 66.406 (72.650)
Epoch: [6][140/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2342 (2.2802)	Acc@1 39.844 (37.544)	Acc@5 72.656 (72.678)
Epoch: [6][150/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3262 (2.2754)	Acc@1 32.812 (37.676)	Acc@5 74.219 (72.801)
Epoch: [6][160/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.4660 (2.2757)	Acc@1 27.344 (37.612)	Acc@5 65.625 (72.778)
Epoch: [6][170/391]	Time 0.097 (0.096)	Data 0.002 (0.002)	Loss 2.1721 (2.2742)	Acc@1 40.625 (37.628)	Acc@5 78.125 (72.798)
Epoch: [6][180/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3360 (2.2754)	Acc@1 31.250 (37.621)	Acc@5 68.750 (72.794)
Epoch: [6][190/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2037 (2.2762)	Acc@1 39.062 (37.565)	Acc@5 72.656 (72.771)
Epoch: [6][200/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.3788 (2.2771)	Acc@1 35.938 (37.519)	Acc@5 77.344 (72.827)
Epoch: [6][210/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.5716 (2.2788)	Acc@1 32.812 (37.589)	Acc@5 64.062 (72.812)
Epoch: [6][220/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1642 (2.2804)	Acc@1 42.188 (37.613)	Acc@5 75.000 (72.759)
Epoch: [6][230/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.4865 (2.2821)	Acc@1 30.469 (37.598)	Acc@5 70.312 (72.697)
Epoch: [6][240/391]	Time 0.102 (0.096)	Data 0.001 (0.002)	Loss 2.2801 (2.2786)	Acc@1 35.156 (37.714)	Acc@5 77.344 (72.789)
Epoch: [6][250/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.2662 (2.2800)	Acc@1 35.156 (37.665)	Acc@5 75.000 (72.787)
Epoch: [6][260/391]	Time 0.101 (0.096)	Data 0.001 (0.002)	Loss 2.2090 (2.2828)	Acc@1 32.812 (37.539)	Acc@5 78.906 (72.785)
Epoch: [6][270/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.6915 (2.2846)	Acc@1 28.906 (37.494)	Acc@5 59.375 (72.699)
Epoch: [6][280/391]	Time 0.101 (0.096)	Data 0.001 (0.002)	Loss 2.3184 (2.2852)	Acc@1 32.031 (37.417)	Acc@5 67.188 (72.687)
Epoch: [6][290/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2507 (2.2843)	Acc@1 40.625 (37.521)	Acc@5 72.656 (72.739)
Epoch: [6][300/391]	Time 0.103 (0.096)	Data 0.001 (0.002)	Loss 1.9888 (2.2833)	Acc@1 44.531 (37.526)	Acc@5 78.125 (72.711)
Epoch: [6][310/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2290 (2.2832)	Acc@1 32.031 (37.505)	Acc@5 78.125 (72.659)
Epoch: [6][320/391]	Time 0.102 (0.096)	Data 0.001 (0.002)	Loss 2.2953 (2.2840)	Acc@1 39.844 (37.502)	Acc@5 71.094 (72.673)
Epoch: [6][330/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1679 (2.2846)	Acc@1 39.062 (37.462)	Acc@5 75.781 (72.666)
Epoch: [6][340/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4175 (2.2840)	Acc@1 40.625 (37.461)	Acc@5 68.750 (72.652)
Epoch: [6][350/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.2552 (2.2836)	Acc@1 39.844 (37.482)	Acc@5 71.094 (72.692)
Epoch: [6][360/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1267 (2.2854)	Acc@1 46.875 (37.496)	Acc@5 75.781 (72.656)
Epoch: [6][370/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3886 (2.2859)	Acc@1 39.844 (37.523)	Acc@5 69.531 (72.654)
Epoch: [6][380/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.6062 (2.2871)	Acc@1 39.062 (37.533)	Acc@5 65.625 (72.652)
Epoch: [6][390/391]	Time 0.081 (0.096)	Data 0.001 (0.002)	Loss 2.3718 (2.2873)	Acc@1 38.750 (37.562)	Acc@5 73.750 (72.654)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [7][0/391]	Time 0.108 (0.108)	Data 0.173 (0.173)	Loss 2.3982 (2.3982)	Acc@1 32.812 (32.812)	Acc@5 67.969 (67.969)
Epoch: [7][10/391]	Time 0.097 (0.100)	Data 0.001 (0.017)	Loss 2.0481 (2.1992)	Acc@1 37.500 (39.915)	Acc@5 79.688 (73.651)
Epoch: [7][20/391]	Time 0.097 (0.099)	Data 0.001 (0.009)	Loss 2.2419 (2.2343)	Acc@1 41.406 (39.509)	Acc@5 74.219 (73.363)
Epoch: [7][30/391]	Time 0.092 (0.098)	Data 0.001 (0.007)	Loss 2.2465 (2.2290)	Acc@1 37.500 (38.936)	Acc@5 75.781 (73.639)
Epoch: [7][40/391]	Time 0.101 (0.098)	Data 0.001 (0.005)	Loss 2.2520 (2.2376)	Acc@1 39.844 (38.758)	Acc@5 71.094 (73.552)
Epoch: [7][50/391]	Time 0.095 (0.098)	Data 0.001 (0.005)	Loss 2.3596 (2.2450)	Acc@1 42.188 (38.680)	Acc@5 71.094 (73.483)
Epoch: [7][60/391]	Time 0.104 (0.098)	Data 0.001 (0.004)	Loss 2.4121 (2.2533)	Acc@1 32.812 (38.486)	Acc@5 73.438 (73.322)
Epoch: [7][70/391]	Time 0.094 (0.098)	Data 0.001 (0.004)	Loss 2.2840 (2.2506)	Acc@1 39.844 (38.380)	Acc@5 75.000 (73.460)
Epoch: [7][80/391]	Time 0.101 (0.098)	Data 0.001 (0.003)	Loss 2.1971 (2.2466)	Acc@1 39.062 (38.493)	Acc@5 72.656 (73.418)
Epoch: [7][90/391]	Time 0.100 (0.097)	Data 0.001 (0.003)	Loss 2.3652 (2.2554)	Acc@1 35.938 (38.264)	Acc@5 72.656 (73.326)
Epoch: [7][100/391]	Time 0.098 (0.097)	Data 0.001 (0.003)	Loss 2.2816 (2.2578)	Acc@1 32.812 (38.250)	Acc@5 71.875 (73.314)
Epoch: [7][110/391]	Time 0.099 (0.097)	Data 0.001 (0.003)	Loss 2.2173 (2.2645)	Acc@1 36.719 (38.126)	Acc@5 75.000 (73.255)
Epoch: [7][120/391]	Time 0.092 (0.097)	Data 0.001 (0.003)	Loss 2.1733 (2.2595)	Acc@1 42.188 (38.281)	Acc@5 72.656 (73.334)
Epoch: [7][130/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.4171 (2.2644)	Acc@1 31.250 (38.001)	Acc@5 67.969 (73.163)
Epoch: [7][140/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.3749 (2.2650)	Acc@1 42.969 (38.026)	Acc@5 70.312 (73.055)
Epoch: [7][150/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4041 (2.2712)	Acc@1 33.594 (37.924)	Acc@5 67.969 (72.853)
Epoch: [7][160/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3519 (2.2747)	Acc@1 35.156 (37.840)	Acc@5 71.094 (72.787)
Epoch: [7][170/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.3004 (2.2735)	Acc@1 42.969 (37.806)	Acc@5 71.094 (72.821)
Epoch: [7][180/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.3545 (2.2751)	Acc@1 35.938 (37.781)	Acc@5 65.625 (72.773)
Epoch: [7][190/391]	Time 0.104 (0.097)	Data 0.001 (0.002)	Loss 2.4373 (2.2787)	Acc@1 34.375 (37.635)	Acc@5 67.969 (72.705)
Epoch: [7][200/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.0809 (2.2748)	Acc@1 42.969 (37.706)	Acc@5 75.000 (72.792)
Epoch: [7][210/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2713 (2.2775)	Acc@1 38.281 (37.656)	Acc@5 70.312 (72.682)
Epoch: [7][220/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1611 (2.2782)	Acc@1 42.969 (37.574)	Acc@5 69.531 (72.677)
Epoch: [7][230/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.3250 (2.2800)	Acc@1 37.500 (37.588)	Acc@5 71.094 (72.568)
Epoch: [7][240/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3874 (2.2830)	Acc@1 35.938 (37.539)	Acc@5 71.094 (72.471)
Epoch: [7][250/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2299 (2.2834)	Acc@1 42.969 (37.528)	Acc@5 70.312 (72.498)
Epoch: [7][260/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.5507 (2.2865)	Acc@1 28.125 (37.425)	Acc@5 63.281 (72.456)
Epoch: [7][270/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.0640 (2.2883)	Acc@1 44.531 (37.445)	Acc@5 75.781 (72.403)
Epoch: [7][280/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1782 (2.2887)	Acc@1 41.406 (37.447)	Acc@5 74.219 (72.392)
Epoch: [7][290/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3551 (2.2900)	Acc@1 37.500 (37.401)	Acc@5 69.531 (72.353)
Epoch: [7][300/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4286 (2.2923)	Acc@1 29.688 (37.386)	Acc@5 68.750 (72.311)
Epoch: [7][310/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2925 (2.2945)	Acc@1 35.156 (37.379)	Acc@5 72.656 (72.249)
Epoch: [7][320/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2621 (2.2930)	Acc@1 33.594 (37.369)	Acc@5 75.000 (72.296)
Epoch: [7][330/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1321 (2.2930)	Acc@1 46.094 (37.382)	Acc@5 75.781 (72.309)
Epoch: [7][340/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1298 (2.2917)	Acc@1 46.094 (37.420)	Acc@5 76.562 (72.349)
Epoch: [7][350/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.5022 (2.2919)	Acc@1 35.938 (37.407)	Acc@5 69.531 (72.322)
Epoch: [7][360/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 1.8873 (2.2914)	Acc@1 50.000 (37.459)	Acc@5 80.469 (72.312)
Epoch: [7][370/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2926 (2.2913)	Acc@1 34.375 (37.492)	Acc@5 70.312 (72.321)
Epoch: [7][380/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.4723 (2.2911)	Acc@1 37.500 (37.475)	Acc@5 66.406 (72.297)
Epoch: [7][390/391]	Time 0.079 (0.097)	Data 0.001 (0.002)	Loss 2.2067 (2.2904)	Acc@1 46.250 (37.478)	Acc@5 72.500 (72.370)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [8][0/391]	Time 0.110 (0.110)	Data 0.177 (0.177)	Loss 2.2839 (2.2839)	Acc@1 41.406 (41.406)	Acc@5 70.312 (70.312)
Epoch: [8][10/391]	Time 0.095 (0.098)	Data 0.001 (0.017)	Loss 2.6165 (2.2104)	Acc@1 29.688 (39.702)	Acc@5 70.312 (75.639)
Epoch: [8][20/391]	Time 0.096 (0.097)	Data 0.001 (0.009)	Loss 2.3560 (2.2403)	Acc@1 39.062 (38.653)	Acc@5 74.219 (74.777)
Epoch: [8][30/391]	Time 0.094 (0.096)	Data 0.001 (0.007)	Loss 2.0727 (2.2467)	Acc@1 42.969 (39.088)	Acc@5 78.906 (74.168)
Epoch: [8][40/391]	Time 0.096 (0.096)	Data 0.001 (0.005)	Loss 2.4691 (2.2427)	Acc@1 34.375 (38.929)	Acc@5 69.531 (74.352)
Epoch: [8][50/391]	Time 0.095 (0.095)	Data 0.001 (0.005)	Loss 2.1998 (2.2383)	Acc@1 31.250 (38.542)	Acc@5 77.344 (74.234)
Epoch: [8][60/391]	Time 0.094 (0.095)	Data 0.001 (0.004)	Loss 2.3997 (2.2376)	Acc@1 37.500 (38.832)	Acc@5 70.312 (74.142)
Epoch: [8][70/391]	Time 0.095 (0.095)	Data 0.001 (0.004)	Loss 2.3456 (2.2359)	Acc@1 33.594 (38.743)	Acc@5 70.312 (74.098)
Epoch: [8][80/391]	Time 0.095 (0.095)	Data 0.001 (0.003)	Loss 2.0610 (2.2339)	Acc@1 37.500 (38.783)	Acc@5 75.781 (74.267)
Epoch: [8][90/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.4042 (2.2308)	Acc@1 30.469 (38.814)	Acc@5 71.875 (74.270)
Epoch: [8][100/391]	Time 0.097 (0.096)	Data 0.001 (0.003)	Loss 2.1551 (2.2307)	Acc@1 40.625 (38.745)	Acc@5 78.906 (74.095)
Epoch: [8][110/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.1276 (2.2333)	Acc@1 43.750 (38.844)	Acc@5 74.219 (73.923)
Epoch: [8][120/391]	Time 0.092 (0.096)	Data 0.001 (0.003)	Loss 2.2691 (2.2313)	Acc@1 35.938 (38.843)	Acc@5 72.656 (73.986)
Epoch: [8][130/391]	Time 0.094 (0.096)	Data 0.001 (0.003)	Loss 2.6153 (2.2352)	Acc@1 29.688 (38.597)	Acc@5 65.625 (73.980)
Epoch: [8][140/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0502 (2.2401)	Acc@1 39.062 (38.486)	Acc@5 75.000 (73.803)
Epoch: [8][150/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3894 (2.2457)	Acc@1 29.688 (38.359)	Acc@5 73.438 (73.758)
Epoch: [8][160/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2981 (2.2494)	Acc@1 40.625 (38.286)	Acc@5 71.094 (73.685)
Epoch: [8][170/391]	Time 0.101 (0.096)	Data 0.001 (0.002)	Loss 2.3602 (2.2513)	Acc@1 37.500 (38.295)	Acc@5 71.875 (73.611)
Epoch: [8][180/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.4371 (2.2509)	Acc@1 33.594 (38.255)	Acc@5 75.000 (73.692)
Epoch: [8][190/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.2890 (2.2558)	Acc@1 37.500 (38.167)	Acc@5 72.656 (73.568)
Epoch: [8][200/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.3461 (2.2564)	Acc@1 36.719 (38.184)	Acc@5 73.438 (73.527)
Epoch: [8][210/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.2808 (2.2617)	Acc@1 40.625 (38.152)	Acc@5 77.344 (73.486)
Epoch: [8][220/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.5314 (2.2647)	Acc@1 32.812 (38.059)	Acc@5 63.281 (73.392)
Epoch: [8][230/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2830 (2.2651)	Acc@1 38.281 (38.102)	Acc@5 72.656 (73.346)
Epoch: [8][240/391]	Time 0.091 (0.096)	Data 0.001 (0.002)	Loss 2.2581 (2.2662)	Acc@1 39.844 (38.171)	Acc@5 77.344 (73.288)
Epoch: [8][250/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.2118 (2.2701)	Acc@1 40.625 (38.091)	Acc@5 72.656 (73.226)
Epoch: [8][260/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 1.9511 (2.2697)	Acc@1 46.094 (38.036)	Acc@5 80.469 (73.222)
Epoch: [8][270/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1826 (2.2678)	Acc@1 36.719 (38.071)	Acc@5 75.000 (73.230)
Epoch: [8][280/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.1867 (2.2733)	Acc@1 48.438 (38.064)	Acc@5 76.562 (73.093)
Epoch: [8][290/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.5189 (2.2774)	Acc@1 35.156 (37.924)	Acc@5 71.094 (72.978)
Epoch: [8][300/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 1.9899 (2.2781)	Acc@1 39.844 (37.835)	Acc@5 78.906 (72.994)
Epoch: [8][310/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.3485 (2.2795)	Acc@1 36.719 (37.796)	Acc@5 71.094 (72.953)
Epoch: [8][320/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3848 (2.2810)	Acc@1 32.031 (37.743)	Acc@5 67.969 (72.907)
Epoch: [8][330/391]	Time 0.102 (0.096)	Data 0.001 (0.002)	Loss 2.2322 (2.2799)	Acc@1 39.062 (37.764)	Acc@5 72.656 (72.892)
Epoch: [8][340/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.4303 (2.2799)	Acc@1 36.719 (37.775)	Acc@5 71.875 (72.878)
Epoch: [8][350/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.3423 (2.2795)	Acc@1 33.594 (37.720)	Acc@5 74.219 (72.886)
Epoch: [8][360/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.1188 (2.2794)	Acc@1 40.625 (37.725)	Acc@5 75.000 (72.881)
Epoch: [8][370/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.2342 (2.2804)	Acc@1 38.281 (37.727)	Acc@5 71.094 (72.848)
Epoch: [8][380/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1768 (2.2803)	Acc@1 43.750 (37.719)	Acc@5 74.219 (72.863)
Epoch: [8][390/391]	Time 0.084 (0.096)	Data 0.001 (0.002)	Loss 2.2311 (2.2806)	Acc@1 38.750 (37.720)	Acc@5 76.250 (72.846)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [9][0/391]	Time 0.103 (0.103)	Data 0.162 (0.162)	Loss 2.2737 (2.2737)	Acc@1 38.281 (38.281)	Acc@5 74.219 (74.219)
Epoch: [9][10/391]	Time 0.093 (0.096)	Data 0.001 (0.016)	Loss 2.0736 (2.3008)	Acc@1 39.844 (35.653)	Acc@5 80.469 (71.733)
Epoch: [9][20/391]	Time 0.097 (0.096)	Data 0.001 (0.009)	Loss 2.1551 (2.2786)	Acc@1 43.750 (37.798)	Acc@5 76.562 (72.024)
Epoch: [9][30/391]	Time 0.097 (0.096)	Data 0.001 (0.006)	Loss 2.0633 (2.2599)	Acc@1 39.062 (38.180)	Acc@5 78.906 (73.009)
Epoch: [9][40/391]	Time 0.095 (0.095)	Data 0.001 (0.005)	Loss 1.9668 (2.2474)	Acc@1 43.750 (38.548)	Acc@5 82.031 (73.380)
Epoch: [9][50/391]	Time 0.093 (0.096)	Data 0.001 (0.004)	Loss 2.2284 (2.2409)	Acc@1 42.969 (38.680)	Acc@5 74.219 (73.591)
Epoch: [9][60/391]	Time 0.096 (0.096)	Data 0.001 (0.004)	Loss 2.1635 (2.2496)	Acc@1 39.844 (38.499)	Acc@5 75.000 (73.425)
Epoch: [9][70/391]	Time 0.098 (0.096)	Data 0.001 (0.003)	Loss 2.0245 (2.2487)	Acc@1 42.969 (38.457)	Acc@5 79.688 (73.471)
Epoch: [9][80/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.1476 (2.2450)	Acc@1 38.281 (38.619)	Acc@5 78.906 (73.621)
Epoch: [9][90/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.2457 (2.2493)	Acc@1 36.719 (38.547)	Acc@5 73.438 (73.532)
Epoch: [9][100/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.1355 (2.2467)	Acc@1 38.281 (38.567)	Acc@5 79.688 (73.584)
Epoch: [9][110/391]	Time 0.098 (0.096)	Data 0.001 (0.003)	Loss 2.2307 (2.2517)	Acc@1 39.844 (38.514)	Acc@5 70.312 (73.346)
Epoch: [9][120/391]	Time 0.094 (0.096)	Data 0.001 (0.003)	Loss 2.4247 (2.2619)	Acc@1 39.844 (38.275)	Acc@5 64.844 (73.192)
Epoch: [9][130/391]	Time 0.101 (0.096)	Data 0.001 (0.002)	Loss 2.2773 (2.2646)	Acc@1 35.938 (38.269)	Acc@5 74.219 (73.259)
Epoch: [9][140/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.2128 (2.2627)	Acc@1 38.281 (38.215)	Acc@5 76.562 (73.316)
Epoch: [9][150/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2916 (2.2617)	Acc@1 42.969 (38.338)	Acc@5 71.875 (73.313)
Epoch: [9][160/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3951 (2.2654)	Acc@1 37.500 (38.257)	Acc@5 68.750 (73.248)
Epoch: [9][170/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.2449 (2.2676)	Acc@1 39.062 (38.222)	Acc@5 75.000 (73.150)
Epoch: [9][180/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1281 (2.2662)	Acc@1 41.406 (38.255)	Acc@5 78.906 (73.174)
Epoch: [9][190/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.4924 (2.2692)	Acc@1 34.375 (38.150)	Acc@5 68.750 (73.061)
Epoch: [9][200/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2234 (2.2731)	Acc@1 42.969 (38.130)	Acc@5 74.219 (72.994)
Epoch: [9][210/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3197 (2.2749)	Acc@1 41.406 (38.059)	Acc@5 72.656 (72.927)
Epoch: [9][220/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 1.9735 (2.2741)	Acc@1 45.312 (38.059)	Acc@5 78.906 (72.865)
Epoch: [9][230/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3066 (2.2761)	Acc@1 38.281 (38.038)	Acc@5 71.094 (72.815)
Epoch: [9][240/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.4673 (2.2751)	Acc@1 32.031 (38.051)	Acc@5 70.312 (72.896)
Epoch: [9][250/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2288 (2.2791)	Acc@1 39.062 (37.967)	Acc@5 71.094 (72.803)
Epoch: [9][260/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2595 (2.2780)	Acc@1 32.812 (37.955)	Acc@5 71.875 (72.821)
Epoch: [9][270/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 1.9495 (2.2793)	Acc@1 43.750 (37.938)	Acc@5 81.250 (72.769)
Epoch: [9][280/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3895 (2.2803)	Acc@1 35.156 (37.925)	Acc@5 70.312 (72.734)
Epoch: [9][290/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3193 (2.2824)	Acc@1 42.188 (37.916)	Acc@5 72.656 (72.688)
Epoch: [9][300/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2379 (2.2817)	Acc@1 42.188 (37.897)	Acc@5 71.094 (72.716)
Epoch: [9][310/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.2715 (2.2792)	Acc@1 42.188 (37.877)	Acc@5 77.344 (72.719)
Epoch: [9][320/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4981 (2.2805)	Acc@1 29.688 (37.831)	Acc@5 68.750 (72.693)
Epoch: [9][330/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1723 (2.2794)	Acc@1 40.625 (37.871)	Acc@5 75.000 (72.692)
Epoch: [9][340/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.1654 (2.2788)	Acc@1 39.844 (37.901)	Acc@5 71.094 (72.654)
Epoch: [9][350/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.2193 (2.2788)	Acc@1 39.062 (37.887)	Acc@5 75.781 (72.679)
Epoch: [9][360/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.2822 (2.2780)	Acc@1 45.312 (37.928)	Acc@5 67.969 (72.671)
Epoch: [9][370/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1603 (2.2787)	Acc@1 41.406 (37.896)	Acc@5 72.656 (72.644)
Epoch: [9][380/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.3061 (2.2806)	Acc@1 35.938 (37.812)	Acc@5 68.750 (72.568)
Epoch: [9][390/391]	Time 0.079 (0.096)	Data 0.001 (0.002)	Loss 2.4145 (2.2792)	Acc@1 41.250 (37.846)	Acc@5 66.250 (72.644)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [10][0/391]	Time 0.115 (0.115)	Data 0.176 (0.176)	Loss 2.2337 (2.2337)	Acc@1 35.938 (35.938)	Acc@5 73.438 (73.438)
Epoch: [10][10/391]	Time 0.095 (0.098)	Data 0.001 (0.017)	Loss 2.1833 (2.2854)	Acc@1 35.938 (37.855)	Acc@5 75.000 (72.656)
Epoch: [10][20/391]	Time 0.101 (0.097)	Data 0.002 (0.009)	Loss 2.3299 (2.2732)	Acc@1 35.938 (38.095)	Acc@5 68.750 (72.396)
Epoch: [10][30/391]	Time 0.099 (0.097)	Data 0.001 (0.007)	Loss 2.0896 (2.2735)	Acc@1 42.969 (37.979)	Acc@5 75.781 (72.429)
Epoch: [10][40/391]	Time 0.100 (0.097)	Data 0.001 (0.005)	Loss 2.4143 (2.2779)	Acc@1 44.531 (38.072)	Acc@5 71.875 (72.771)
Epoch: [10][50/391]	Time 0.099 (0.097)	Data 0.001 (0.005)	Loss 2.1551 (2.2707)	Acc@1 42.188 (38.343)	Acc@5 76.562 (73.039)
Epoch: [10][60/391]	Time 0.095 (0.097)	Data 0.001 (0.004)	Loss 2.2765 (2.2766)	Acc@1 37.500 (37.820)	Acc@5 73.438 (72.759)
Epoch: [10][70/391]	Time 0.095 (0.097)	Data 0.001 (0.004)	Loss 1.9987 (2.2829)	Acc@1 43.750 (37.687)	Acc@5 75.000 (72.447)
Epoch: [10][80/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.2411 (2.2867)	Acc@1 42.188 (37.625)	Acc@5 74.219 (72.550)
Epoch: [10][90/391]	Time 0.093 (0.096)	Data 0.001 (0.003)	Loss 2.4786 (2.2914)	Acc@1 35.938 (37.388)	Acc@5 67.969 (72.442)
Epoch: [10][100/391]	Time 0.092 (0.096)	Data 0.001 (0.003)	Loss 2.2865 (2.2930)	Acc@1 42.969 (37.508)	Acc@5 74.219 (72.386)
Epoch: [10][110/391]	Time 0.094 (0.096)	Data 0.001 (0.003)	Loss 2.1894 (2.2948)	Acc@1 35.938 (37.437)	Acc@5 77.344 (72.347)
Epoch: [10][120/391]	Time 0.093 (0.096)	Data 0.001 (0.003)	Loss 2.1613 (2.2911)	Acc@1 45.312 (37.429)	Acc@5 74.219 (72.340)
Epoch: [10][130/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.2911 (2.2909)	Acc@1 33.594 (37.303)	Acc@5 75.000 (72.424)
Epoch: [10][140/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.0361 (2.2855)	Acc@1 42.188 (37.483)	Acc@5 76.562 (72.545)
Epoch: [10][150/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1305 (2.2792)	Acc@1 43.750 (37.671)	Acc@5 75.000 (72.692)
Epoch: [10][160/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2700 (2.2789)	Acc@1 37.500 (37.680)	Acc@5 76.562 (72.807)
Epoch: [10][170/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2844 (2.2802)	Acc@1 37.500 (37.651)	Acc@5 69.531 (72.748)
Epoch: [10][180/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.3053 (2.2800)	Acc@1 39.062 (37.772)	Acc@5 74.219 (72.738)
Epoch: [10][190/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.4643 (2.2771)	Acc@1 30.469 (37.733)	Acc@5 72.656 (72.881)
Epoch: [10][200/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2524 (2.2710)	Acc@1 38.281 (37.904)	Acc@5 74.219 (73.088)
Epoch: [10][210/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.3803 (2.2734)	Acc@1 38.281 (37.867)	Acc@5 70.312 (73.027)
Epoch: [10][220/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3121 (2.2712)	Acc@1 38.281 (37.938)	Acc@5 69.531 (73.084)
Epoch: [10][230/391]	Time 0.091 (0.096)	Data 0.001 (0.002)	Loss 2.3259 (2.2731)	Acc@1 41.406 (37.909)	Acc@5 71.094 (73.062)
Epoch: [10][240/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1921 (2.2738)	Acc@1 40.625 (37.908)	Acc@5 75.781 (73.045)
Epoch: [10][250/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0228 (2.2719)	Acc@1 43.750 (37.898)	Acc@5 79.688 (73.126)
Epoch: [10][260/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.5028 (2.2755)	Acc@1 27.344 (37.811)	Acc@5 67.188 (73.000)
Epoch: [10][270/391]	Time 0.091 (0.095)	Data 0.001 (0.002)	Loss 2.3537 (2.2792)	Acc@1 42.188 (37.739)	Acc@5 74.219 (72.921)
Epoch: [10][280/391]	Time 0.097 (0.095)	Data 0.001 (0.002)	Loss 2.2428 (2.2793)	Acc@1 32.031 (37.734)	Acc@5 75.781 (72.954)
Epoch: [10][290/391]	Time 0.097 (0.095)	Data 0.001 (0.002)	Loss 2.3252 (2.2798)	Acc@1 40.625 (37.760)	Acc@5 71.094 (72.954)
Epoch: [10][300/391]	Time 0.095 (0.095)	Data 0.001 (0.002)	Loss 2.4574 (2.2806)	Acc@1 31.250 (37.739)	Acc@5 66.406 (72.944)
Epoch: [10][310/391]	Time 0.093 (0.095)	Data 0.001 (0.002)	Loss 2.1524 (2.2812)	Acc@1 39.062 (37.721)	Acc@5 75.000 (72.948)
Epoch: [10][320/391]	Time 0.094 (0.095)	Data 0.001 (0.002)	Loss 2.4507 (2.2826)	Acc@1 34.375 (37.665)	Acc@5 71.094 (72.929)
Epoch: [10][330/391]	Time 0.095 (0.095)	Data 0.001 (0.002)	Loss 2.5251 (2.2838)	Acc@1 35.938 (37.649)	Acc@5 64.844 (72.866)
Epoch: [10][340/391]	Time 0.100 (0.095)	Data 0.001 (0.002)	Loss 2.3053 (2.2830)	Acc@1 32.031 (37.605)	Acc@5 77.344 (72.901)
Epoch: [10][350/391]	Time 0.098 (0.095)	Data 0.001 (0.002)	Loss 2.3549 (2.2814)	Acc@1 42.969 (37.703)	Acc@5 68.750 (72.899)
Epoch: [10][360/391]	Time 0.095 (0.095)	Data 0.001 (0.002)	Loss 2.3388 (2.2812)	Acc@1 39.844 (37.723)	Acc@5 75.000 (72.925)
Epoch: [10][370/391]	Time 0.096 (0.095)	Data 0.001 (0.002)	Loss 2.4059 (2.2820)	Acc@1 38.281 (37.736)	Acc@5 71.875 (72.905)
Epoch: [10][380/391]	Time 0.091 (0.095)	Data 0.001 (0.002)	Loss 2.3064 (2.2835)	Acc@1 36.719 (37.652)	Acc@5 73.438 (72.878)
Epoch: [10][390/391]	Time 0.079 (0.095)	Data 0.001 (0.002)	Loss 2.1174 (2.2847)	Acc@1 40.000 (37.624)	Acc@5 76.250 (72.842)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [11][0/391]	Time 0.115 (0.115)	Data 0.185 (0.185)	Loss 2.5174 (2.5174)	Acc@1 32.031 (32.031)	Acc@5 68.750 (68.750)
Epoch: [11][10/391]	Time 0.100 (0.101)	Data 0.001 (0.017)	Loss 2.5656 (2.2698)	Acc@1 32.812 (37.642)	Acc@5 65.625 (73.935)
Epoch: [11][20/391]	Time 0.099 (0.100)	Data 0.001 (0.010)	Loss 2.3696 (2.2567)	Acc@1 36.719 (37.463)	Acc@5 71.875 (73.996)
Epoch: [11][30/391]	Time 0.106 (0.100)	Data 0.001 (0.007)	Loss 1.9495 (2.2354)	Acc@1 48.438 (38.256)	Acc@5 75.000 (74.168)
Epoch: [11][40/391]	Time 0.098 (0.100)	Data 0.001 (0.005)	Loss 2.2715 (2.2502)	Acc@1 33.594 (37.957)	Acc@5 74.219 (73.647)
Epoch: [11][50/391]	Time 0.094 (0.100)	Data 0.001 (0.005)	Loss 2.4415 (2.2509)	Acc@1 39.844 (37.960)	Acc@5 67.188 (73.545)
Epoch: [11][60/391]	Time 0.098 (0.099)	Data 0.001 (0.004)	Loss 2.1846 (2.2463)	Acc@1 35.156 (38.473)	Acc@5 75.000 (73.642)
Epoch: [11][70/391]	Time 0.095 (0.099)	Data 0.001 (0.004)	Loss 2.0534 (2.2477)	Acc@1 42.188 (38.292)	Acc@5 75.781 (73.438)
Epoch: [11][80/391]	Time 0.097 (0.099)	Data 0.001 (0.003)	Loss 2.1810 (2.2469)	Acc@1 37.500 (38.320)	Acc@5 71.094 (73.312)
Epoch: [11][90/391]	Time 0.097 (0.099)	Data 0.001 (0.003)	Loss 2.2344 (2.2447)	Acc@1 36.719 (38.221)	Acc@5 70.312 (73.386)
Epoch: [11][100/391]	Time 0.093 (0.099)	Data 0.001 (0.003)	Loss 2.3189 (2.2490)	Acc@1 38.281 (38.196)	Acc@5 69.531 (73.283)
Epoch: [11][110/391]	Time 0.095 (0.099)	Data 0.001 (0.003)	Loss 2.3784 (2.2514)	Acc@1 34.375 (38.148)	Acc@5 71.094 (73.416)
Epoch: [11][120/391]	Time 0.096 (0.099)	Data 0.001 (0.003)	Loss 2.3401 (2.2560)	Acc@1 37.500 (38.023)	Acc@5 72.656 (73.308)
Epoch: [11][130/391]	Time 0.091 (0.099)	Data 0.001 (0.002)	Loss 2.3318 (2.2576)	Acc@1 38.281 (38.090)	Acc@5 71.875 (73.241)
Epoch: [11][140/391]	Time 0.096 (0.099)	Data 0.001 (0.002)	Loss 2.2319 (2.2607)	Acc@1 39.062 (38.032)	Acc@5 73.438 (73.249)
Epoch: [11][150/391]	Time 0.093 (0.099)	Data 0.001 (0.002)	Loss 1.9282 (2.2571)	Acc@1 44.531 (38.224)	Acc@5 78.125 (73.267)
Epoch: [11][160/391]	Time 0.098 (0.099)	Data 0.001 (0.002)	Loss 2.2671 (2.2581)	Acc@1 35.938 (38.233)	Acc@5 67.188 (73.190)
Epoch: [11][170/391]	Time 0.097 (0.098)	Data 0.001 (0.002)	Loss 2.0357 (2.2563)	Acc@1 41.406 (38.304)	Acc@5 76.562 (73.200)
Epoch: [11][180/391]	Time 0.099 (0.098)	Data 0.001 (0.002)	Loss 2.5022 (2.2556)	Acc@1 35.938 (38.350)	Acc@5 67.969 (73.196)
Epoch: [11][190/391]	Time 0.096 (0.098)	Data 0.001 (0.002)	Loss 2.2636 (2.2558)	Acc@1 40.625 (38.351)	Acc@5 69.531 (73.229)
Epoch: [11][200/391]	Time 0.094 (0.098)	Data 0.001 (0.002)	Loss 2.3794 (2.2577)	Acc@1 36.719 (38.320)	Acc@5 71.094 (73.169)
Epoch: [11][210/391]	Time 0.097 (0.098)	Data 0.001 (0.002)	Loss 2.1912 (2.2617)	Acc@1 35.938 (38.155)	Acc@5 73.438 (72.967)
Epoch: [11][220/391]	Time 0.098 (0.098)	Data 0.001 (0.002)	Loss 2.1966 (2.2612)	Acc@1 39.062 (38.158)	Acc@5 74.219 (73.031)
Epoch: [11][230/391]	Time 0.095 (0.098)	Data 0.001 (0.002)	Loss 2.3305 (2.2647)	Acc@1 38.281 (38.126)	Acc@5 66.406 (72.954)
Epoch: [11][240/391]	Time 0.097 (0.098)	Data 0.001 (0.002)	Loss 2.1679 (2.2643)	Acc@1 44.531 (38.249)	Acc@5 73.438 (72.919)
Epoch: [11][250/391]	Time 0.093 (0.098)	Data 0.001 (0.002)	Loss 2.1637 (2.2663)	Acc@1 36.719 (38.179)	Acc@5 77.344 (72.915)
Epoch: [11][260/391]	Time 0.095 (0.098)	Data 0.001 (0.002)	Loss 2.0969 (2.2657)	Acc@1 41.406 (38.182)	Acc@5 78.125 (72.947)
Epoch: [11][270/391]	Time 0.095 (0.098)	Data 0.001 (0.002)	Loss 2.2208 (2.2639)	Acc@1 39.844 (38.212)	Acc@5 71.094 (72.970)
Epoch: [11][280/391]	Time 0.095 (0.098)	Data 0.001 (0.002)	Loss 2.1846 (2.2621)	Acc@1 42.969 (38.273)	Acc@5 77.344 (73.015)
Epoch: [11][290/391]	Time 0.094 (0.098)	Data 0.001 (0.002)	Loss 2.0470 (2.2619)	Acc@1 42.969 (38.297)	Acc@5 75.000 (72.997)
Epoch: [11][300/391]	Time 0.095 (0.098)	Data 0.001 (0.002)	Loss 2.1360 (2.2634)	Acc@1 37.500 (38.276)	Acc@5 70.312 (72.942)
Epoch: [11][310/391]	Time 0.097 (0.098)	Data 0.001 (0.002)	Loss 2.1245 (2.2644)	Acc@1 39.844 (38.234)	Acc@5 78.906 (72.930)
Epoch: [11][320/391]	Time 0.091 (0.097)	Data 0.001 (0.002)	Loss 2.1845 (2.2656)	Acc@1 39.844 (38.218)	Acc@5 75.000 (72.912)
Epoch: [11][330/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3492 (2.2654)	Acc@1 39.844 (38.241)	Acc@5 66.406 (72.930)
Epoch: [11][340/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.5588 (2.2672)	Acc@1 33.594 (38.256)	Acc@5 64.844 (72.908)
Epoch: [11][350/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3841 (2.2711)	Acc@1 35.938 (38.192)	Acc@5 70.312 (72.830)
Epoch: [11][360/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.2144 (2.2707)	Acc@1 39.844 (38.208)	Acc@5 75.000 (72.853)
Epoch: [11][370/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1567 (2.2707)	Acc@1 36.719 (38.170)	Acc@5 75.781 (72.877)
Epoch: [11][380/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4531 (2.2730)	Acc@1 38.281 (38.134)	Acc@5 71.875 (72.806)
Epoch: [11][390/391]	Time 0.079 (0.097)	Data 0.001 (0.002)	Loss 2.1108 (2.2733)	Acc@1 45.000 (38.148)	Acc@5 78.750 (72.812)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [12][0/391]	Time 0.106 (0.106)	Data 0.168 (0.168)	Loss 2.1080 (2.1080)	Acc@1 41.406 (41.406)	Acc@5 75.000 (75.000)
Epoch: [12][10/391]	Time 0.095 (0.098)	Data 0.001 (0.016)	Loss 2.1743 (2.2426)	Acc@1 37.500 (39.205)	Acc@5 76.562 (73.864)
Epoch: [12][20/391]	Time 0.095 (0.097)	Data 0.001 (0.009)	Loss 2.2517 (2.2545)	Acc@1 36.719 (38.988)	Acc@5 71.875 (73.289)
Epoch: [12][30/391]	Time 0.096 (0.097)	Data 0.001 (0.007)	Loss 2.5509 (2.2852)	Acc@1 34.375 (38.080)	Acc@5 67.188 (72.077)
Epoch: [12][40/391]	Time 0.095 (0.097)	Data 0.001 (0.005)	Loss 2.2830 (2.2896)	Acc@1 33.594 (38.224)	Acc@5 70.312 (72.104)
Epoch: [12][50/391]	Time 0.096 (0.096)	Data 0.001 (0.004)	Loss 2.4869 (2.2789)	Acc@1 30.469 (38.159)	Acc@5 70.312 (72.151)
Epoch: [12][60/391]	Time 0.099 (0.096)	Data 0.001 (0.004)	Loss 2.1515 (2.2677)	Acc@1 43.750 (38.332)	Acc@5 75.000 (72.426)
Epoch: [12][70/391]	Time 0.094 (0.096)	Data 0.001 (0.004)	Loss 1.9992 (2.2734)	Acc@1 42.969 (38.116)	Acc@5 80.469 (72.502)
Epoch: [12][80/391]	Time 0.097 (0.096)	Data 0.001 (0.003)	Loss 2.2355 (2.2792)	Acc@1 42.188 (38.117)	Acc@5 73.438 (72.434)
Epoch: [12][90/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.3365 (2.2773)	Acc@1 33.594 (37.981)	Acc@5 72.656 (72.630)
Epoch: [12][100/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.3316 (2.2796)	Acc@1 29.688 (37.887)	Acc@5 74.219 (72.579)
Epoch: [12][110/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.0608 (2.2757)	Acc@1 42.188 (37.852)	Acc@5 78.125 (72.748)
Epoch: [12][120/391]	Time 0.098 (0.096)	Data 0.001 (0.003)	Loss 2.3071 (2.2725)	Acc@1 35.938 (37.933)	Acc@5 75.000 (72.843)
Epoch: [12][130/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.1849 (2.2785)	Acc@1 38.281 (37.822)	Acc@5 75.781 (72.734)
Epoch: [12][140/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2555 (2.2745)	Acc@1 39.062 (37.893)	Acc@5 73.438 (72.773)
Epoch: [12][150/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2147 (2.2742)	Acc@1 38.281 (37.862)	Acc@5 75.000 (72.760)
Epoch: [12][160/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.4556 (2.2762)	Acc@1 39.844 (37.898)	Acc@5 71.875 (72.821)
Epoch: [12][170/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 1.9691 (2.2747)	Acc@1 45.312 (37.870)	Acc@5 81.250 (72.898)
Epoch: [12][180/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.5728 (2.2788)	Acc@1 28.125 (37.746)	Acc@5 65.625 (72.838)
Epoch: [12][190/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.1891 (2.2791)	Acc@1 35.156 (37.737)	Acc@5 71.094 (72.820)
Epoch: [12][200/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3282 (2.2820)	Acc@1 37.500 (37.620)	Acc@5 75.781 (72.812)
Epoch: [12][210/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2213 (2.2819)	Acc@1 38.281 (37.593)	Acc@5 75.000 (72.841)
Epoch: [12][220/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.4531 (2.2843)	Acc@1 28.906 (37.482)	Acc@5 65.625 (72.769)
Epoch: [12][230/391]	Time 0.103 (0.096)	Data 0.001 (0.002)	Loss 2.1270 (2.2797)	Acc@1 39.062 (37.547)	Acc@5 78.125 (72.890)
Epoch: [12][240/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.5505 (2.2792)	Acc@1 29.688 (37.536)	Acc@5 64.062 (72.854)
Epoch: [12][250/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.1296 (2.2760)	Acc@1 42.188 (37.640)	Acc@5 79.688 (72.930)
Epoch: [12][260/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1592 (2.2748)	Acc@1 43.750 (37.692)	Acc@5 78.125 (72.932)
Epoch: [12][270/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1870 (2.2747)	Acc@1 45.312 (37.725)	Acc@5 71.875 (72.939)
Epoch: [12][280/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.4463 (2.2735)	Acc@1 38.281 (37.806)	Acc@5 71.875 (72.943)
Epoch: [12][290/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.1369 (2.2706)	Acc@1 44.531 (37.911)	Acc@5 71.875 (73.013)
Epoch: [12][300/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.1502 (2.2688)	Acc@1 46.094 (37.993)	Acc@5 73.438 (73.004)
Epoch: [12][310/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3185 (2.2674)	Acc@1 35.156 (38.030)	Acc@5 72.656 (73.018)
Epoch: [12][320/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.2661 (2.2673)	Acc@1 39.844 (38.067)	Acc@5 75.781 (73.055)
Epoch: [12][330/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2116 (2.2683)	Acc@1 39.062 (38.088)	Acc@5 75.781 (73.010)
Epoch: [12][340/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3577 (2.2692)	Acc@1 35.938 (38.038)	Acc@5 71.875 (72.998)
Epoch: [12][350/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.5125 (2.2678)	Acc@1 34.375 (38.085)	Acc@5 73.438 (73.072)
Epoch: [12][360/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2892 (2.2695)	Acc@1 39.844 (38.052)	Acc@5 74.219 (73.037)
Epoch: [12][370/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0351 (2.2684)	Acc@1 53.906 (38.088)	Acc@5 80.469 (73.090)
Epoch: [12][380/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.4967 (2.2704)	Acc@1 27.344 (38.004)	Acc@5 67.969 (73.075)
Epoch: [12][390/391]	Time 0.079 (0.096)	Data 0.001 (0.002)	Loss 2.3863 (2.2714)	Acc@1 36.250 (37.960)	Acc@5 66.250 (73.036)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [13][0/391]	Time 0.104 (0.104)	Data 0.180 (0.180)	Loss 2.2242 (2.2242)	Acc@1 35.938 (35.938)	Acc@5 70.312 (70.312)
Epoch: [13][10/391]	Time 0.094 (0.098)	Data 0.001 (0.017)	Loss 2.1154 (2.2691)	Acc@1 39.062 (37.358)	Acc@5 79.688 (73.935)
Epoch: [13][20/391]	Time 0.098 (0.098)	Data 0.001 (0.010)	Loss 2.4136 (2.2887)	Acc@1 30.469 (36.682)	Acc@5 66.406 (73.326)
Epoch: [13][30/391]	Time 0.095 (0.097)	Data 0.001 (0.007)	Loss 2.2391 (2.2614)	Acc@1 41.406 (37.550)	Acc@5 73.438 (73.362)
Epoch: [13][40/391]	Time 0.096 (0.096)	Data 0.001 (0.006)	Loss 2.3322 (2.2684)	Acc@1 33.594 (37.424)	Acc@5 73.438 (73.228)
Epoch: [13][50/391]	Time 0.094 (0.096)	Data 0.001 (0.005)	Loss 2.2214 (2.2622)	Acc@1 37.500 (37.699)	Acc@5 77.344 (73.284)
Epoch: [13][60/391]	Time 0.099 (0.096)	Data 0.001 (0.004)	Loss 2.2108 (2.2606)	Acc@1 42.188 (37.961)	Acc@5 71.875 (73.053)
Epoch: [13][70/391]	Time 0.097 (0.097)	Data 0.001 (0.004)	Loss 2.3929 (2.2644)	Acc@1 35.156 (38.215)	Acc@5 74.219 (73.041)
Epoch: [13][80/391]	Time 0.099 (0.097)	Data 0.001 (0.003)	Loss 2.1879 (2.2596)	Acc@1 39.844 (38.387)	Acc@5 74.219 (72.984)
Epoch: [13][90/391]	Time 0.098 (0.097)	Data 0.001 (0.003)	Loss 2.1496 (2.2634)	Acc@1 34.375 (38.333)	Acc@5 76.562 (72.991)
Epoch: [13][100/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.2459 (2.2603)	Acc@1 39.062 (38.428)	Acc@5 68.750 (73.082)
Epoch: [13][110/391]	Time 0.097 (0.097)	Data 0.001 (0.003)	Loss 2.3811 (2.2596)	Acc@1 38.281 (38.506)	Acc@5 62.500 (73.057)
Epoch: [13][120/391]	Time 0.098 (0.097)	Data 0.001 (0.003)	Loss 1.9805 (2.2560)	Acc@1 48.438 (38.533)	Acc@5 82.812 (73.121)
Epoch: [13][130/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.4561 (2.2586)	Acc@1 31.250 (38.347)	Acc@5 69.531 (73.056)
Epoch: [13][140/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.0500 (2.2550)	Acc@1 43.750 (38.276)	Acc@5 76.562 (73.116)
Epoch: [13][150/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.0367 (2.2529)	Acc@1 46.875 (38.281)	Acc@5 74.219 (73.044)
Epoch: [13][160/391]	Time 0.101 (0.097)	Data 0.001 (0.002)	Loss 2.2326 (2.2509)	Acc@1 42.969 (38.403)	Acc@5 68.750 (73.074)
Epoch: [13][170/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.2466 (2.2524)	Acc@1 41.406 (38.405)	Acc@5 73.438 (73.035)
Epoch: [13][180/391]	Time 0.103 (0.097)	Data 0.001 (0.002)	Loss 2.2135 (2.2566)	Acc@1 40.625 (38.368)	Acc@5 76.562 (73.040)
Epoch: [13][190/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2938 (2.2572)	Acc@1 35.938 (38.400)	Acc@5 67.969 (72.988)
Epoch: [13][200/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.1912 (2.2534)	Acc@1 43.750 (38.476)	Acc@5 72.656 (73.045)
Epoch: [13][210/391]	Time 0.091 (0.097)	Data 0.001 (0.002)	Loss 1.9708 (2.2515)	Acc@1 50.781 (38.518)	Acc@5 78.906 (73.108)
Epoch: [13][220/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4423 (2.2534)	Acc@1 30.469 (38.497)	Acc@5 68.750 (73.056)
Epoch: [13][230/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 1.9821 (2.2524)	Acc@1 46.094 (38.572)	Acc@5 78.906 (73.109)
Epoch: [13][240/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4661 (2.2547)	Acc@1 27.344 (38.450)	Acc@5 70.312 (73.058)
Epoch: [13][250/391]	Time 0.091 (0.097)	Data 0.001 (0.002)	Loss 2.1491 (2.2527)	Acc@1 39.062 (38.440)	Acc@5 78.125 (73.123)
Epoch: [13][260/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.2306 (2.2564)	Acc@1 35.938 (38.347)	Acc@5 71.094 (72.968)
Epoch: [13][270/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2700 (2.2572)	Acc@1 38.281 (38.304)	Acc@5 67.969 (72.896)
Epoch: [13][280/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3220 (2.2583)	Acc@1 39.844 (38.281)	Acc@5 68.750 (72.818)
Epoch: [13][290/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 1.9326 (2.2607)	Acc@1 45.312 (38.228)	Acc@5 79.688 (72.782)
Epoch: [13][300/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.2821 (2.2617)	Acc@1 39.844 (38.203)	Acc@5 75.781 (72.757)
Epoch: [13][310/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.5636 (2.2615)	Acc@1 28.906 (38.231)	Acc@5 61.719 (72.719)
Epoch: [13][320/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.3107 (2.2605)	Acc@1 39.062 (38.272)	Acc@5 71.094 (72.758)
Epoch: [13][330/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.3771 (2.2600)	Acc@1 31.250 (38.293)	Acc@5 71.875 (72.767)
Epoch: [13][340/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1339 (2.2594)	Acc@1 37.500 (38.274)	Acc@5 75.781 (72.805)
Epoch: [13][350/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.4089 (2.2629)	Acc@1 32.031 (38.170)	Acc@5 75.781 (72.745)
Epoch: [13][360/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.3010 (2.2638)	Acc@1 39.062 (38.177)	Acc@5 72.656 (72.745)
Epoch: [13][370/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.5554 (2.2650)	Acc@1 37.500 (38.210)	Acc@5 68.750 (72.705)
Epoch: [13][380/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.3289 (2.2666)	Acc@1 34.375 (38.127)	Acc@5 71.875 (72.697)
Epoch: [13][390/391]	Time 0.080 (0.097)	Data 0.001 (0.002)	Loss 2.5018 (2.2678)	Acc@1 38.750 (38.140)	Acc@5 66.250 (72.666)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [14][0/391]	Time 0.106 (0.106)	Data 0.165 (0.165)	Loss 2.0412 (2.0412)	Acc@1 42.969 (42.969)	Acc@5 81.250 (81.250)
Epoch: [14][10/391]	Time 0.096 (0.100)	Data 0.001 (0.016)	Loss 2.4273 (2.2068)	Acc@1 35.156 (39.418)	Acc@5 67.188 (75.639)
Epoch: [14][20/391]	Time 0.098 (0.099)	Data 0.001 (0.009)	Loss 2.2139 (2.2144)	Acc@1 38.281 (39.509)	Acc@5 72.656 (74.702)
Epoch: [14][30/391]	Time 0.095 (0.099)	Data 0.001 (0.007)	Loss 2.0234 (2.2163)	Acc@1 40.625 (39.264)	Acc@5 77.344 (74.395)
Epoch: [14][40/391]	Time 0.094 (0.099)	Data 0.001 (0.005)	Loss 2.3723 (2.2319)	Acc@1 34.375 (38.739)	Acc@5 70.312 (74.428)
Epoch: [14][50/391]	Time 0.101 (0.098)	Data 0.001 (0.004)	Loss 2.2248 (2.2220)	Acc@1 38.281 (38.634)	Acc@5 69.531 (74.494)
Epoch: [14][60/391]	Time 0.095 (0.098)	Data 0.001 (0.004)	Loss 2.1333 (2.2105)	Acc@1 39.062 (38.922)	Acc@5 76.562 (74.616)
Epoch: [14][70/391]	Time 0.097 (0.098)	Data 0.001 (0.003)	Loss 2.2740 (2.2198)	Acc@1 39.844 (38.776)	Acc@5 72.656 (74.307)
Epoch: [14][80/391]	Time 0.096 (0.098)	Data 0.001 (0.003)	Loss 2.0435 (2.2278)	Acc@1 41.406 (38.522)	Acc@5 78.906 (74.171)
Epoch: [14][90/391]	Time 0.093 (0.098)	Data 0.001 (0.003)	Loss 2.2493 (2.2321)	Acc@1 41.406 (38.496)	Acc@5 76.562 (74.124)
Epoch: [14][100/391]	Time 0.096 (0.098)	Data 0.001 (0.003)	Loss 2.4368 (2.2333)	Acc@1 35.156 (38.583)	Acc@5 68.750 (74.056)
Epoch: [14][110/391]	Time 0.093 (0.098)	Data 0.001 (0.003)	Loss 2.3193 (2.2345)	Acc@1 35.938 (38.408)	Acc@5 67.188 (74.008)
Epoch: [14][120/391]	Time 0.094 (0.097)	Data 0.001 (0.003)	Loss 2.2525 (2.2374)	Acc@1 41.406 (38.443)	Acc@5 71.875 (73.889)
Epoch: [14][130/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1470 (2.2383)	Acc@1 39.062 (38.424)	Acc@5 75.781 (73.819)
Epoch: [14][140/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.1938 (2.2423)	Acc@1 41.406 (38.486)	Acc@5 76.562 (73.659)
Epoch: [14][150/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.2295 (2.2470)	Acc@1 34.375 (38.405)	Acc@5 76.562 (73.484)
Epoch: [14][160/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1578 (2.2516)	Acc@1 46.094 (38.257)	Acc@5 78.125 (73.374)
Epoch: [14][170/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3197 (2.2524)	Acc@1 36.719 (38.099)	Acc@5 74.219 (73.442)
Epoch: [14][180/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1991 (2.2500)	Acc@1 33.594 (38.052)	Acc@5 78.125 (73.532)
Epoch: [14][190/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.1891 (2.2535)	Acc@1 44.531 (38.003)	Acc@5 70.312 (73.466)
Epoch: [14][200/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.3582 (2.2543)	Acc@1 36.719 (37.986)	Acc@5 71.094 (73.422)
Epoch: [14][210/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.0292 (2.2581)	Acc@1 43.750 (37.985)	Acc@5 74.219 (73.363)
Epoch: [14][220/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.5091 (2.2635)	Acc@1 29.688 (37.903)	Acc@5 64.062 (73.215)
Epoch: [14][230/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2117 (2.2626)	Acc@1 42.188 (37.940)	Acc@5 72.656 (73.275)
Epoch: [14][240/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.3146 (2.2644)	Acc@1 37.500 (37.850)	Acc@5 69.531 (73.214)
Epoch: [14][250/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.3674 (2.2675)	Acc@1 35.156 (37.789)	Acc@5 70.312 (73.132)
Epoch: [14][260/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.4523 (2.2669)	Acc@1 35.156 (37.844)	Acc@5 65.625 (73.120)
Epoch: [14][270/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.0829 (2.2661)	Acc@1 39.062 (37.794)	Acc@5 73.438 (73.094)
Epoch: [14][280/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1731 (2.2659)	Acc@1 42.188 (37.806)	Acc@5 75.781 (73.129)
Epoch: [14][290/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1643 (2.2652)	Acc@1 42.188 (37.828)	Acc@5 75.781 (73.164)
Epoch: [14][300/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4222 (2.2675)	Acc@1 38.281 (37.788)	Acc@5 70.312 (73.061)
Epoch: [14][310/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.6217 (2.2694)	Acc@1 34.375 (37.744)	Acc@5 69.531 (73.010)
Epoch: [14][320/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2383 (2.2666)	Acc@1 33.594 (37.790)	Acc@5 78.906 (73.082)
Epoch: [14][330/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.3377 (2.2668)	Acc@1 39.062 (37.781)	Acc@5 69.531 (73.069)
Epoch: [14][340/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2527 (2.2651)	Acc@1 38.281 (37.839)	Acc@5 74.219 (73.142)
Epoch: [14][350/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1694 (2.2623)	Acc@1 40.625 (37.874)	Acc@5 78.906 (73.195)
Epoch: [14][360/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.2174 (2.2629)	Acc@1 38.281 (37.918)	Acc@5 75.781 (73.113)
Epoch: [14][370/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.3521 (2.2631)	Acc@1 39.062 (37.982)	Acc@5 69.531 (73.082)
Epoch: [14][380/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2140 (2.2635)	Acc@1 41.406 (37.953)	Acc@5 75.781 (73.077)
Epoch: [14][390/391]	Time 0.079 (0.096)	Data 0.001 (0.002)	Loss 2.6173 (2.2651)	Acc@1 35.000 (37.906)	Acc@5 67.500 (73.068)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [15][0/391]	Time 0.104 (0.104)	Data 0.166 (0.166)	Loss 2.2014 (2.2014)	Acc@1 40.625 (40.625)	Acc@5 71.875 (71.875)
Epoch: [15][10/391]	Time 0.095 (0.096)	Data 0.001 (0.016)	Loss 2.3376 (2.2993)	Acc@1 36.719 (37.003)	Acc@5 68.750 (71.307)
Epoch: [15][20/391]	Time 0.097 (0.097)	Data 0.001 (0.009)	Loss 2.2521 (2.2761)	Acc@1 38.281 (37.426)	Acc@5 75.781 (71.949)
Epoch: [15][30/391]	Time 0.093 (0.096)	Data 0.001 (0.006)	Loss 2.3184 (2.2637)	Acc@1 32.812 (37.702)	Acc@5 68.750 (72.681)
Epoch: [15][40/391]	Time 0.095 (0.096)	Data 0.001 (0.005)	Loss 2.0042 (2.2693)	Acc@1 41.406 (37.843)	Acc@5 81.250 (72.561)
Epoch: [15][50/391]	Time 0.098 (0.096)	Data 0.001 (0.004)	Loss 2.1711 (2.2640)	Acc@1 32.031 (37.423)	Acc@5 74.219 (72.794)
Epoch: [15][60/391]	Time 0.101 (0.096)	Data 0.001 (0.004)	Loss 2.4005 (2.2598)	Acc@1 30.469 (37.513)	Acc@5 71.875 (73.028)
Epoch: [15][70/391]	Time 0.097 (0.095)	Data 0.001 (0.003)	Loss 2.4293 (2.2563)	Acc@1 39.062 (37.742)	Acc@5 64.844 (73.195)
Epoch: [15][80/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.1863 (2.2582)	Acc@1 35.156 (37.731)	Acc@5 79.688 (73.225)
Epoch: [15][90/391]	Time 0.096 (0.095)	Data 0.001 (0.003)	Loss 2.5795 (2.2501)	Acc@1 32.812 (37.826)	Acc@5 69.531 (73.403)
Epoch: [15][100/391]	Time 0.092 (0.096)	Data 0.001 (0.003)	Loss 2.0938 (2.2518)	Acc@1 42.188 (37.809)	Acc@5 75.000 (73.314)
Epoch: [15][110/391]	Time 0.096 (0.095)	Data 0.001 (0.003)	Loss 2.2405 (2.2453)	Acc@1 44.531 (37.908)	Acc@5 74.219 (73.430)
Epoch: [15][120/391]	Time 0.098 (0.095)	Data 0.001 (0.002)	Loss 2.2612 (2.2497)	Acc@1 39.062 (37.913)	Acc@5 65.625 (73.321)
Epoch: [15][130/391]	Time 0.096 (0.095)	Data 0.001 (0.002)	Loss 2.2123 (2.2511)	Acc@1 45.312 (37.911)	Acc@5 72.656 (73.342)
Epoch: [15][140/391]	Time 0.095 (0.095)	Data 0.001 (0.002)	Loss 2.6485 (2.2536)	Acc@1 33.594 (37.893)	Acc@5 64.844 (73.216)
Epoch: [15][150/391]	Time 0.096 (0.095)	Data 0.001 (0.002)	Loss 2.0264 (2.2539)	Acc@1 42.969 (37.971)	Acc@5 81.250 (73.215)
Epoch: [15][160/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0985 (2.2527)	Acc@1 41.406 (37.922)	Acc@5 75.000 (73.292)
Epoch: [15][170/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.5300 (2.2528)	Acc@1 28.906 (37.902)	Acc@5 68.750 (73.246)
Epoch: [15][180/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.4269 (2.2595)	Acc@1 29.688 (37.729)	Acc@5 71.875 (73.084)
Epoch: [15][190/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.4813 (2.2617)	Acc@1 36.719 (37.688)	Acc@5 70.312 (73.049)
Epoch: [15][200/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.2862 (2.2664)	Acc@1 36.719 (37.613)	Acc@5 73.438 (72.936)
Epoch: [15][210/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.4420 (2.2681)	Acc@1 35.938 (37.559)	Acc@5 75.781 (72.912)
Epoch: [15][220/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2851 (2.2682)	Acc@1 32.812 (37.539)	Acc@5 74.219 (72.907)
Epoch: [15][230/391]	Time 0.098 (0.096)	Data 0.002 (0.002)	Loss 2.4152 (2.2700)	Acc@1 36.719 (37.459)	Acc@5 72.656 (72.866)
Epoch: [15][240/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1841 (2.2689)	Acc@1 42.188 (37.519)	Acc@5 73.438 (72.935)
Epoch: [15][250/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.0777 (2.2687)	Acc@1 40.625 (37.488)	Acc@5 77.344 (72.958)
Epoch: [15][260/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.2990 (2.2730)	Acc@1 37.500 (37.389)	Acc@5 70.312 (72.833)
Epoch: [15][270/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.1364 (2.2741)	Acc@1 43.750 (37.367)	Acc@5 71.094 (72.841)
Epoch: [15][280/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2415 (2.2764)	Acc@1 35.156 (37.325)	Acc@5 73.438 (72.779)
Epoch: [15][290/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.0494 (2.2739)	Acc@1 43.750 (37.395)	Acc@5 76.562 (72.831)
Epoch: [15][300/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3986 (2.2724)	Acc@1 36.719 (37.448)	Acc@5 70.312 (72.830)
Epoch: [15][310/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.2328 (2.2708)	Acc@1 40.625 (37.472)	Acc@5 72.656 (72.857)
Epoch: [15][320/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2001 (2.2702)	Acc@1 43.750 (37.510)	Acc@5 77.344 (72.873)
Epoch: [15][330/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.2935 (2.2693)	Acc@1 37.500 (37.552)	Acc@5 73.438 (72.890)
Epoch: [15][340/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2313 (2.2690)	Acc@1 33.594 (37.573)	Acc@5 71.094 (72.872)
Epoch: [15][350/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.0523 (2.2709)	Acc@1 47.656 (37.547)	Acc@5 77.344 (72.810)
Epoch: [15][360/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.1478 (2.2707)	Acc@1 43.750 (37.567)	Acc@5 75.781 (72.827)
Epoch: [15][370/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.3133 (2.2715)	Acc@1 37.500 (37.603)	Acc@5 76.562 (72.837)
Epoch: [15][380/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 1.8682 (2.2704)	Acc@1 47.656 (37.639)	Acc@5 82.031 (72.890)
Epoch: [15][390/391]	Time 0.080 (0.096)	Data 0.001 (0.002)	Loss 2.1565 (2.2704)	Acc@1 43.750 (37.660)	Acc@5 76.250 (72.910)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [16][0/391]	Time 0.108 (0.108)	Data 0.173 (0.173)	Loss 2.1385 (2.1385)	Acc@1 42.969 (42.969)	Acc@5 74.219 (74.219)
Epoch: [16][10/391]	Time 0.097 (0.097)	Data 0.001 (0.017)	Loss 2.0627 (2.2066)	Acc@1 42.969 (39.418)	Acc@5 77.344 (75.710)
Epoch: [16][20/391]	Time 0.094 (0.096)	Data 0.001 (0.009)	Loss 2.4845 (2.2445)	Acc@1 34.375 (38.467)	Acc@5 70.312 (73.586)
Epoch: [16][30/391]	Time 0.095 (0.096)	Data 0.001 (0.007)	Loss 1.9897 (2.2465)	Acc@1 47.656 (38.508)	Acc@5 74.219 (73.261)
Epoch: [16][40/391]	Time 0.093 (0.096)	Data 0.001 (0.005)	Loss 2.3328 (2.2315)	Acc@1 41.406 (38.700)	Acc@5 70.312 (73.533)
Epoch: [16][50/391]	Time 0.095 (0.096)	Data 0.001 (0.005)	Loss 2.3625 (2.2448)	Acc@1 36.719 (38.404)	Acc@5 71.094 (73.438)
Epoch: [16][60/391]	Time 0.095 (0.096)	Data 0.001 (0.004)	Loss 2.6725 (2.2530)	Acc@1 39.062 (38.384)	Acc@5 65.625 (73.399)
Epoch: [16][70/391]	Time 0.095 (0.095)	Data 0.001 (0.004)	Loss 2.3200 (2.2581)	Acc@1 38.281 (38.446)	Acc@5 75.781 (73.283)
Epoch: [16][80/391]	Time 0.101 (0.096)	Data 0.001 (0.003)	Loss 2.4175 (2.2611)	Acc@1 31.250 (38.320)	Acc@5 71.875 (73.090)
Epoch: [16][90/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.3383 (2.2557)	Acc@1 34.375 (38.187)	Acc@5 67.188 (73.309)
Epoch: [16][100/391]	Time 0.095 (0.096)	Data 0.001 (0.003)	Loss 2.3266 (2.2495)	Acc@1 35.938 (38.250)	Acc@5 69.531 (73.461)
Epoch: [16][110/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.5049 (2.2607)	Acc@1 28.125 (38.119)	Acc@5 67.188 (73.128)
Epoch: [16][120/391]	Time 0.109 (0.096)	Data 0.002 (0.003)	Loss 2.1522 (2.2657)	Acc@1 37.500 (38.010)	Acc@5 78.906 (73.037)
Epoch: [16][130/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.2195 (2.2613)	Acc@1 34.375 (38.061)	Acc@5 75.781 (73.235)
Epoch: [16][140/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.3569 (2.2565)	Acc@1 37.500 (38.098)	Acc@5 71.875 (73.426)
Epoch: [16][150/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.3960 (2.2597)	Acc@1 39.844 (38.178)	Acc@5 65.625 (73.386)
Epoch: [16][160/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.5181 (2.2595)	Acc@1 35.156 (38.238)	Acc@5 65.625 (73.408)
Epoch: [16][170/391]	Time 0.098 (0.096)	Data 0.002 (0.002)	Loss 2.2056 (2.2560)	Acc@1 42.188 (38.418)	Acc@5 72.656 (73.442)
Epoch: [16][180/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.0313 (2.2537)	Acc@1 39.844 (38.411)	Acc@5 80.469 (73.472)
Epoch: [16][190/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.4349 (2.2528)	Acc@1 32.812 (38.437)	Acc@5 67.969 (73.446)
Epoch: [16][200/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.4039 (2.2585)	Acc@1 42.969 (38.347)	Acc@5 70.312 (73.274)
Epoch: [16][210/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.0862 (2.2558)	Acc@1 41.406 (38.403)	Acc@5 75.000 (73.319)
Epoch: [16][220/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.0262 (2.2532)	Acc@1 44.531 (38.465)	Acc@5 80.469 (73.381)
Epoch: [16][230/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.2529 (2.2551)	Acc@1 39.062 (38.471)	Acc@5 75.781 (73.289)
Epoch: [16][240/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2656 (2.2585)	Acc@1 44.531 (38.476)	Acc@5 72.656 (73.237)
Epoch: [16][250/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.4907 (2.2595)	Acc@1 37.500 (38.499)	Acc@5 65.625 (73.185)
Epoch: [16][260/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3983 (2.2601)	Acc@1 34.375 (38.491)	Acc@5 70.312 (73.213)
Epoch: [16][270/391]	Time 0.091 (0.097)	Data 0.001 (0.002)	Loss 2.4191 (2.2605)	Acc@1 35.156 (38.521)	Acc@5 67.188 (73.175)
Epoch: [16][280/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.2870 (2.2598)	Acc@1 39.844 (38.529)	Acc@5 72.656 (73.196)
Epoch: [16][290/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2538 (2.2611)	Acc@1 36.719 (38.480)	Acc@5 67.969 (73.137)
Epoch: [16][300/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4111 (2.2606)	Acc@1 35.156 (38.536)	Acc@5 67.188 (73.116)
Epoch: [16][310/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.4996 (2.2628)	Acc@1 31.250 (38.515)	Acc@5 64.062 (73.031)
Epoch: [16][320/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.3518 (2.2619)	Acc@1 35.156 (38.498)	Acc@5 73.438 (73.048)
Epoch: [16][330/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2400 (2.2610)	Acc@1 41.406 (38.508)	Acc@5 70.312 (73.057)
Epoch: [16][340/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 1.9770 (2.2603)	Acc@1 45.312 (38.490)	Acc@5 82.031 (73.078)
Epoch: [16][350/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1088 (2.2617)	Acc@1 34.375 (38.428)	Acc@5 76.562 (73.032)
Epoch: [16][360/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1915 (2.2616)	Acc@1 41.406 (38.398)	Acc@5 71.875 (73.009)
Epoch: [16][370/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3412 (2.2615)	Acc@1 32.031 (38.393)	Acc@5 71.875 (73.048)
Epoch: [16][380/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.0495 (2.2612)	Acc@1 44.531 (38.349)	Acc@5 78.125 (73.062)
Epoch: [16][390/391]	Time 0.082 (0.097)	Data 0.001 (0.002)	Loss 2.3144 (2.2618)	Acc@1 41.250 (38.326)	Acc@5 70.000 (73.054)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [17][0/391]	Time 0.112 (0.112)	Data 0.166 (0.166)	Loss 2.3307 (2.3307)	Acc@1 39.062 (39.062)	Acc@5 72.656 (72.656)
Epoch: [17][10/391]	Time 0.095 (0.097)	Data 0.001 (0.016)	Loss 2.2250 (2.2499)	Acc@1 33.594 (38.352)	Acc@5 73.438 (73.651)
Epoch: [17][20/391]	Time 0.100 (0.098)	Data 0.001 (0.009)	Loss 2.1710 (2.2498)	Acc@1 39.844 (38.170)	Acc@5 69.531 (72.582)
Epoch: [17][30/391]	Time 0.097 (0.097)	Data 0.001 (0.006)	Loss 2.2405 (2.2605)	Acc@1 35.156 (38.004)	Acc@5 75.000 (72.656)
Epoch: [17][40/391]	Time 0.094 (0.097)	Data 0.001 (0.005)	Loss 2.3133 (2.2511)	Acc@1 36.719 (37.938)	Acc@5 75.781 (72.771)
Epoch: [17][50/391]	Time 0.093 (0.096)	Data 0.001 (0.004)	Loss 1.9831 (2.2410)	Acc@1 42.969 (37.745)	Acc@5 75.781 (73.300)
Epoch: [17][60/391]	Time 0.099 (0.096)	Data 0.001 (0.004)	Loss 2.2737 (2.2271)	Acc@1 39.844 (38.192)	Acc@5 69.531 (73.758)
Epoch: [17][70/391]	Time 0.100 (0.097)	Data 0.001 (0.003)	Loss 2.4691 (2.2357)	Acc@1 33.594 (38.083)	Acc@5 67.969 (73.493)
Epoch: [17][80/391]	Time 0.092 (0.097)	Data 0.001 (0.003)	Loss 2.2881 (2.2385)	Acc@1 44.531 (38.088)	Acc@5 68.750 (73.360)
Epoch: [17][90/391]	Time 0.097 (0.097)	Data 0.001 (0.003)	Loss 2.2695 (2.2314)	Acc@1 42.969 (38.504)	Acc@5 70.312 (73.489)
Epoch: [17][100/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 2.5504 (2.2421)	Acc@1 37.500 (38.320)	Acc@5 66.406 (73.283)
Epoch: [17][110/391]	Time 0.098 (0.097)	Data 0.001 (0.003)	Loss 2.2594 (2.2467)	Acc@1 38.281 (38.176)	Acc@5 71.094 (73.226)
Epoch: [17][120/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.1656 (2.2488)	Acc@1 39.062 (38.126)	Acc@5 75.000 (73.179)
Epoch: [17][130/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.2779 (2.2509)	Acc@1 33.594 (37.900)	Acc@5 73.438 (73.145)
Epoch: [17][140/391]	Time 0.091 (0.097)	Data 0.001 (0.002)	Loss 2.1773 (2.2503)	Acc@1 42.188 (38.021)	Acc@5 73.438 (73.160)
Epoch: [17][150/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.4153 (2.2517)	Acc@1 34.375 (38.002)	Acc@5 71.875 (73.112)
Epoch: [17][160/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2216 (2.2487)	Acc@1 38.281 (38.073)	Acc@5 71.875 (73.209)
Epoch: [17][170/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.3625 (2.2487)	Acc@1 39.062 (38.117)	Acc@5 71.875 (73.209)
Epoch: [17][180/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.3009 (2.2510)	Acc@1 39.062 (38.191)	Acc@5 74.219 (73.191)
Epoch: [17][190/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.0147 (2.2504)	Acc@1 46.875 (38.195)	Acc@5 79.688 (73.110)
Epoch: [17][200/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.3705 (2.2525)	Acc@1 38.281 (38.106)	Acc@5 68.750 (73.080)
Epoch: [17][210/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.2479 (2.2522)	Acc@1 40.625 (38.163)	Acc@5 77.344 (73.067)
Epoch: [17][220/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.2345 (2.2503)	Acc@1 41.406 (38.228)	Acc@5 74.219 (73.070)
Epoch: [17][230/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.6195 (2.2503)	Acc@1 32.812 (38.231)	Acc@5 64.062 (73.072)
Epoch: [17][240/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.4024 (2.2498)	Acc@1 35.938 (38.262)	Acc@5 70.312 (73.126)
Epoch: [17][250/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.3622 (2.2509)	Acc@1 34.375 (38.297)	Acc@5 71.875 (73.151)
Epoch: [17][260/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.1687 (2.2534)	Acc@1 37.500 (38.227)	Acc@5 75.000 (73.114)
Epoch: [17][270/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.3875 (2.2568)	Acc@1 32.812 (38.149)	Acc@5 75.781 (73.100)
Epoch: [17][280/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.3290 (2.2556)	Acc@1 31.250 (38.126)	Acc@5 71.094 (73.190)
Epoch: [17][290/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.2719 (2.2550)	Acc@1 40.625 (38.144)	Acc@5 75.000 (73.174)
Epoch: [17][300/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2044 (2.2537)	Acc@1 36.719 (38.180)	Acc@5 78.125 (73.206)
Epoch: [17][310/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.2549 (2.2539)	Acc@1 41.406 (38.141)	Acc@5 74.219 (73.209)
Epoch: [17][320/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2346 (2.2553)	Acc@1 27.344 (38.067)	Acc@5 76.562 (73.165)
Epoch: [17][330/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.3516 (2.2541)	Acc@1 40.625 (38.097)	Acc@5 69.531 (73.176)
Epoch: [17][340/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.2974 (2.2560)	Acc@1 43.750 (38.070)	Acc@5 75.000 (73.121)
Epoch: [17][350/391]	Time 0.095 (0.097)	Data 0.001 (0.002)	Loss 2.2401 (2.2577)	Acc@1 38.281 (37.979)	Acc@5 75.781 (73.101)
Epoch: [17][360/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2965 (2.2583)	Acc@1 38.281 (37.996)	Acc@5 75.781 (73.137)
Epoch: [17][370/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.3104 (2.2596)	Acc@1 38.281 (37.972)	Acc@5 68.750 (73.105)
Epoch: [17][380/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2661 (2.2604)	Acc@1 30.469 (37.943)	Acc@5 71.094 (73.054)
Epoch: [17][390/391]	Time 0.080 (0.097)	Data 0.001 (0.002)	Loss 1.9115 (2.2591)	Acc@1 48.750 (38.004)	Acc@5 80.000 (73.048)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [18][0/391]	Time 0.108 (0.108)	Data 0.157 (0.157)	Loss 2.2428 (2.2428)	Acc@1 39.062 (39.062)	Acc@5 75.000 (75.000)
Epoch: [18][10/391]	Time 0.100 (0.097)	Data 0.001 (0.015)	Loss 2.1267 (2.2690)	Acc@1 39.844 (36.790)	Acc@5 76.562 (74.432)
Epoch: [18][20/391]	Time 0.097 (0.097)	Data 0.001 (0.009)	Loss 2.2069 (2.3055)	Acc@1 36.719 (36.272)	Acc@5 69.531 (72.954)
Epoch: [18][30/391]	Time 0.096 (0.097)	Data 0.001 (0.006)	Loss 2.3342 (2.2989)	Acc@1 35.938 (37.072)	Acc@5 70.312 (72.505)
Epoch: [18][40/391]	Time 0.095 (0.096)	Data 0.001 (0.005)	Loss 2.0808 (2.2799)	Acc@1 39.844 (37.633)	Acc@5 76.562 (73.056)
Epoch: [18][50/391]	Time 0.095 (0.096)	Data 0.001 (0.004)	Loss 2.1649 (2.2748)	Acc@1 34.375 (37.868)	Acc@5 77.344 (73.039)
Epoch: [18][60/391]	Time 0.094 (0.096)	Data 0.001 (0.004)	Loss 2.2549 (2.2720)	Acc@1 36.719 (37.833)	Acc@5 69.531 (72.976)
Epoch: [18][70/391]	Time 0.092 (0.095)	Data 0.001 (0.003)	Loss 2.4286 (2.2644)	Acc@1 33.594 (38.083)	Acc@5 70.312 (73.129)
Epoch: [18][80/391]	Time 0.100 (0.096)	Data 0.001 (0.003)	Loss 2.3894 (2.2750)	Acc@1 34.375 (37.789)	Acc@5 73.438 (72.888)
Epoch: [18][90/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.4117 (2.2879)	Acc@1 35.938 (37.448)	Acc@5 69.531 (72.588)
Epoch: [18][100/391]	Time 0.096 (0.096)	Data 0.001 (0.003)	Loss 2.4462 (2.2923)	Acc@1 32.812 (37.423)	Acc@5 74.219 (72.571)
Epoch: [18][110/391]	Time 0.092 (0.096)	Data 0.001 (0.003)	Loss 2.0246 (2.2913)	Acc@1 37.500 (37.556)	Acc@5 79.688 (72.565)
Epoch: [18][120/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0687 (2.2845)	Acc@1 39.844 (37.603)	Acc@5 80.469 (72.695)
Epoch: [18][130/391]	Time 0.099 (0.096)	Data 0.001 (0.002)	Loss 2.1475 (2.2770)	Acc@1 45.312 (37.870)	Acc@5 72.656 (72.823)
Epoch: [18][140/391]	Time 0.092 (0.096)	Data 0.001 (0.002)	Loss 2.1861 (2.2723)	Acc@1 39.844 (37.893)	Acc@5 75.000 (72.878)
Epoch: [18][150/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 1.9806 (2.2687)	Acc@1 50.781 (38.064)	Acc@5 75.000 (72.910)
Epoch: [18][160/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.5083 (2.2696)	Acc@1 37.500 (38.155)	Acc@5 64.844 (72.884)
Epoch: [18][170/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3098 (2.2670)	Acc@1 34.375 (38.181)	Acc@5 75.781 (72.962)
Epoch: [18][180/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2876 (2.2698)	Acc@1 40.625 (38.100)	Acc@5 73.438 (72.920)
Epoch: [18][190/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2678 (2.2708)	Acc@1 38.281 (38.093)	Acc@5 71.875 (72.836)
Epoch: [18][200/391]	Time 0.093 (0.096)	Data 0.001 (0.002)	Loss 2.3875 (2.2687)	Acc@1 33.594 (38.145)	Acc@5 72.656 (72.897)
Epoch: [18][210/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2411 (2.2690)	Acc@1 42.969 (38.159)	Acc@5 69.531 (72.838)
Epoch: [18][220/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.1402 (2.2728)	Acc@1 38.281 (38.023)	Acc@5 73.438 (72.798)
Epoch: [18][230/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2098 (2.2735)	Acc@1 40.625 (38.045)	Acc@5 78.125 (72.822)
Epoch: [18][240/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.4502 (2.2707)	Acc@1 38.281 (38.132)	Acc@5 68.750 (72.870)
Epoch: [18][250/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.2399 (2.2704)	Acc@1 38.281 (38.060)	Acc@5 75.781 (72.921)
Epoch: [18][260/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.3901 (2.2706)	Acc@1 36.719 (38.069)	Acc@5 71.094 (72.908)
Epoch: [18][270/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.4511 (2.2708)	Acc@1 30.469 (38.051)	Acc@5 68.750 (72.916)
Epoch: [18][280/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3706 (2.2684)	Acc@1 38.281 (38.123)	Acc@5 70.312 (72.954)
Epoch: [18][290/391]	Time 0.091 (0.096)	Data 0.001 (0.002)	Loss 2.2221 (2.2705)	Acc@1 46.094 (38.072)	Acc@5 75.000 (72.941)
Epoch: [18][300/391]	Time 0.100 (0.096)	Data 0.001 (0.002)	Loss 2.3028 (2.2707)	Acc@1 33.594 (38.074)	Acc@5 72.656 (72.934)
Epoch: [18][310/391]	Time 0.094 (0.096)	Data 0.001 (0.002)	Loss 2.0987 (2.2694)	Acc@1 42.188 (38.136)	Acc@5 76.562 (73.026)
Epoch: [18][320/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.2195 (2.2669)	Acc@1 39.844 (38.225)	Acc@5 71.875 (73.082)
Epoch: [18][330/391]	Time 0.098 (0.096)	Data 0.001 (0.002)	Loss 2.3460 (2.2650)	Acc@1 35.938 (38.298)	Acc@5 68.750 (73.065)
Epoch: [18][340/391]	Time 0.097 (0.096)	Data 0.001 (0.002)	Loss 2.3548 (2.2643)	Acc@1 34.375 (38.251)	Acc@5 68.750 (73.073)
Epoch: [18][350/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.3493 (2.2671)	Acc@1 35.938 (38.212)	Acc@5 67.969 (72.995)
Epoch: [18][360/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.2503 (2.2663)	Acc@1 39.062 (38.253)	Acc@5 77.344 (73.022)
Epoch: [18][370/391]	Time 0.096 (0.096)	Data 0.001 (0.002)	Loss 2.4640 (2.2652)	Acc@1 33.594 (38.302)	Acc@5 69.531 (73.029)
Epoch: [18][380/391]	Time 0.095 (0.096)	Data 0.001 (0.002)	Loss 2.0113 (2.2631)	Acc@1 44.531 (38.353)	Acc@5 75.781 (73.109)
Epoch: [18][390/391]	Time 0.086 (0.096)	Data 0.001 (0.002)	Loss 2.2516 (2.2612)	Acc@1 42.500 (38.414)	Acc@5 75.000 (73.162)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [19][0/391]	Time 0.110 (0.110)	Data 0.193 (0.193)	Loss 2.0591 (2.0591)	Acc@1 46.875 (46.875)	Acc@5 79.688 (79.688)
Epoch: [19][10/391]	Time 0.108 (0.104)	Data 0.001 (0.018)	Loss 2.2402 (2.2884)	Acc@1 33.594 (39.489)	Acc@5 74.219 (72.514)
Epoch: [19][20/391]	Time 0.103 (0.102)	Data 0.001 (0.010)	Loss 2.3339 (2.2726)	Acc@1 34.375 (38.765)	Acc@5 71.875 (72.991)
Epoch: [19][30/391]	Time 0.104 (0.101)	Data 0.001 (0.007)	Loss 2.1328 (2.2822)	Acc@1 38.281 (38.458)	Acc@5 75.781 (72.429)
Epoch: [19][40/391]	Time 0.099 (0.101)	Data 0.001 (0.006)	Loss 2.0396 (2.2618)	Acc@1 42.188 (38.510)	Acc@5 78.906 (73.018)
Epoch: [19][50/391]	Time 0.100 (0.101)	Data 0.002 (0.005)	Loss 2.1785 (2.2555)	Acc@1 39.844 (38.572)	Acc@5 76.562 (73.407)
Epoch: [19][60/391]	Time 0.101 (0.101)	Data 0.001 (0.004)	Loss 2.2478 (2.2539)	Acc@1 35.156 (38.422)	Acc@5 71.094 (73.322)
Epoch: [19][70/391]	Time 0.101 (0.101)	Data 0.001 (0.004)	Loss 2.3393 (2.2512)	Acc@1 37.500 (38.776)	Acc@5 71.875 (73.526)
Epoch: [19][80/391]	Time 0.099 (0.101)	Data 0.001 (0.004)	Loss 2.2034 (2.2482)	Acc@1 39.844 (38.706)	Acc@5 78.906 (73.601)
Epoch: [19][90/391]	Time 0.100 (0.101)	Data 0.001 (0.003)	Loss 2.4786 (2.2510)	Acc@1 38.281 (38.968)	Acc@5 71.094 (73.480)
Epoch: [19][100/391]	Time 0.099 (0.101)	Data 0.001 (0.003)	Loss 2.2231 (2.2523)	Acc@1 34.375 (38.769)	Acc@5 79.688 (73.507)
Epoch: [19][110/391]	Time 0.095 (0.101)	Data 0.001 (0.003)	Loss 2.4683 (2.2559)	Acc@1 33.594 (38.556)	Acc@5 67.969 (73.423)
Epoch: [19][120/391]	Time 0.104 (0.101)	Data 0.001 (0.003)	Loss 2.2142 (2.2528)	Acc@1 41.406 (38.630)	Acc@5 71.875 (73.476)
Epoch: [19][130/391]	Time 0.099 (0.100)	Data 0.001 (0.003)	Loss 2.3402 (2.2584)	Acc@1 32.812 (38.544)	Acc@5 72.656 (73.402)
Epoch: [19][140/391]	Time 0.107 (0.100)	Data 0.001 (0.003)	Loss 1.9856 (2.2531)	Acc@1 47.656 (38.702)	Acc@5 75.000 (73.449)
Epoch: [19][150/391]	Time 0.100 (0.100)	Data 0.001 (0.002)	Loss 2.3218 (2.2524)	Acc@1 35.156 (38.612)	Acc@5 70.312 (73.422)
Epoch: [19][160/391]	Time 0.100 (0.100)	Data 0.001 (0.002)	Loss 2.1700 (2.2473)	Acc@1 41.406 (38.723)	Acc@5 77.344 (73.544)
Epoch: [19][170/391]	Time 0.099 (0.100)	Data 0.001 (0.002)	Loss 2.3562 (2.2492)	Acc@1 36.719 (38.729)	Acc@5 69.531 (73.492)
Epoch: [19][180/391]	Time 0.099 (0.100)	Data 0.001 (0.002)	Loss 2.1774 (2.2481)	Acc@1 43.750 (38.769)	Acc@5 72.656 (73.472)
Epoch: [19][190/391]	Time 0.102 (0.100)	Data 0.001 (0.002)	Loss 2.4986 (2.2517)	Acc@1 32.812 (38.678)	Acc@5 72.656 (73.454)
Epoch: [19][200/391]	Time 0.102 (0.101)	Data 0.001 (0.002)	Loss 2.2868 (2.2519)	Acc@1 35.156 (38.588)	Acc@5 73.438 (73.511)
Epoch: [19][210/391]	Time 0.099 (0.101)	Data 0.001 (0.002)	Loss 2.0614 (2.2498)	Acc@1 39.844 (38.585)	Acc@5 78.125 (73.541)
Epoch: [19][220/391]	Time 0.099 (0.100)	Data 0.001 (0.002)	Loss 2.2547 (2.2474)	Acc@1 35.938 (38.681)	Acc@5 77.344 (73.561)
Epoch: [19][230/391]	Time 0.099 (0.101)	Data 0.001 (0.002)	Loss 2.4123 (2.2481)	Acc@1 31.250 (38.616)	Acc@5 68.750 (73.600)
Epoch: [19][240/391]	Time 0.097 (0.100)	Data 0.001 (0.002)	Loss 2.3687 (2.2471)	Acc@1 35.938 (38.638)	Acc@5 69.531 (73.606)
Epoch: [19][250/391]	Time 0.101 (0.101)	Data 0.001 (0.002)	Loss 2.2627 (2.2454)	Acc@1 35.938 (38.670)	Acc@5 77.344 (73.677)
Epoch: [19][260/391]	Time 0.097 (0.100)	Data 0.001 (0.002)	Loss 2.3428 (2.2450)	Acc@1 42.188 (38.673)	Acc@5 69.531 (73.677)
Epoch: [19][270/391]	Time 0.100 (0.100)	Data 0.001 (0.002)	Loss 2.4186 (2.2454)	Acc@1 32.031 (38.613)	Acc@5 67.969 (73.674)
Epoch: [19][280/391]	Time 0.098 (0.100)	Data 0.001 (0.002)	Loss 2.2540 (2.2456)	Acc@1 39.844 (38.607)	Acc@5 71.875 (73.618)
Epoch: [19][290/391]	Time 0.104 (0.100)	Data 0.001 (0.002)	Loss 2.0995 (2.2441)	Acc@1 44.531 (38.646)	Acc@5 75.781 (73.633)
Epoch: [19][300/391]	Time 0.098 (0.100)	Data 0.001 (0.002)	Loss 2.1266 (2.2453)	Acc@1 41.406 (38.613)	Acc@5 71.875 (73.627)
Epoch: [19][310/391]	Time 0.097 (0.100)	Data 0.001 (0.002)	Loss 2.3280 (2.2457)	Acc@1 35.156 (38.540)	Acc@5 73.438 (73.646)
Epoch: [19][320/391]	Time 0.095 (0.100)	Data 0.001 (0.002)	Loss 1.9755 (2.2434)	Acc@1 39.844 (38.564)	Acc@5 84.375 (73.681)
Epoch: [19][330/391]	Time 0.098 (0.100)	Data 0.001 (0.002)	Loss 1.9609 (2.2436)	Acc@1 40.625 (38.513)	Acc@5 81.250 (73.709)
Epoch: [19][340/391]	Time 0.098 (0.100)	Data 0.001 (0.002)	Loss 1.8277 (2.2419)	Acc@1 53.125 (38.591)	Acc@5 77.344 (73.706)
Epoch: [19][350/391]	Time 0.100 (0.100)	Data 0.001 (0.002)	Loss 2.1543 (2.2429)	Acc@1 40.625 (38.573)	Acc@5 76.562 (73.662)
Epoch: [19][360/391]	Time 0.101 (0.100)	Data 0.001 (0.002)	Loss 2.2433 (2.2449)	Acc@1 32.812 (38.508)	Acc@5 72.656 (73.602)
Epoch: [19][370/391]	Time 0.099 (0.100)	Data 0.001 (0.002)	Loss 2.2231 (2.2466)	Acc@1 40.625 (38.490)	Acc@5 76.562 (73.585)
Epoch: [19][380/391]	Time 0.097 (0.100)	Data 0.001 (0.002)	Loss 2.2796 (2.2461)	Acc@1 41.406 (38.515)	Acc@5 71.875 (73.581)
Epoch: [19][390/391]	Time 0.081 (0.100)	Data 0.001 (0.002)	Loss 2.1047 (2.2477)	Acc@1 35.000 (38.466)	Acc@5 78.750 (73.536)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [20][0/391]	Time 0.111 (0.111)	Data 0.177 (0.177)	Loss 2.1296 (2.1296)	Acc@1 41.406 (41.406)	Acc@5 78.125 (78.125)
Epoch: [20][10/391]	Time 0.098 (0.098)	Data 0.001 (0.017)	Loss 2.3563 (2.2067)	Acc@1 34.375 (38.778)	Acc@5 70.312 (73.935)
Epoch: [20][20/391]	Time 0.100 (0.099)	Data 0.001 (0.009)	Loss 2.3501 (2.1985)	Acc@1 40.625 (39.844)	Acc@5 69.531 (74.182)
Epoch: [20][30/391]	Time 0.098 (0.098)	Data 0.001 (0.007)	Loss 2.3609 (2.1896)	Acc@1 39.062 (40.323)	Acc@5 69.531 (73.992)
Epoch: [20][40/391]	Time 0.102 (0.098)	Data 0.001 (0.005)	Loss 2.2266 (2.2137)	Acc@1 35.156 (39.729)	Acc@5 74.219 (73.590)
Epoch: [20][50/391]	Time 0.095 (0.098)	Data 0.001 (0.005)	Loss 2.4073 (2.2226)	Acc@1 35.156 (39.568)	Acc@5 67.188 (73.376)
Epoch: [20][60/391]	Time 0.097 (0.098)	Data 0.001 (0.004)	Loss 2.3454 (2.2286)	Acc@1 33.594 (39.242)	Acc@5 70.312 (73.399)
Epoch: [20][70/391]	Time 0.097 (0.098)	Data 0.001 (0.004)	Loss 2.3383 (2.2322)	Acc@1 32.812 (38.897)	Acc@5 68.750 (73.526)
Epoch: [20][80/391]	Time 0.095 (0.097)	Data 0.001 (0.003)	Loss 2.4812 (2.2298)	Acc@1 26.562 (38.735)	Acc@5 70.312 (73.630)
Epoch: [20][90/391]	Time 0.094 (0.097)	Data 0.001 (0.003)	Loss 2.3961 (2.2318)	Acc@1 39.844 (38.917)	Acc@5 67.969 (73.532)
Epoch: [20][100/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 1.9405 (2.2335)	Acc@1 45.312 (39.024)	Acc@5 79.688 (73.461)
Epoch: [20][110/391]	Time 0.107 (0.097)	Data 0.001 (0.003)	Loss 2.2264 (2.2355)	Acc@1 38.281 (38.915)	Acc@5 69.531 (73.402)
Epoch: [20][120/391]	Time 0.096 (0.097)	Data 0.001 (0.003)	Loss 2.0151 (2.2339)	Acc@1 39.062 (38.920)	Acc@5 78.125 (73.470)
Epoch: [20][130/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.1138 (2.2392)	Acc@1 38.281 (38.752)	Acc@5 71.875 (73.241)
Epoch: [20][140/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.3935 (2.2388)	Acc@1 36.719 (38.885)	Acc@5 67.188 (73.277)
Epoch: [20][150/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.1358 (2.2404)	Acc@1 39.062 (38.778)	Acc@5 78.906 (73.293)
Epoch: [20][160/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.0862 (2.2369)	Acc@1 39.844 (38.844)	Acc@5 76.562 (73.399)
Epoch: [20][170/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.3183 (2.2363)	Acc@1 34.375 (38.811)	Acc@5 69.531 (73.332)
Epoch: [20][180/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.1032 (2.2413)	Acc@1 42.969 (38.765)	Acc@5 78.125 (73.248)
Epoch: [20][190/391]	Time 0.100 (0.097)	Data 0.001 (0.002)	Loss 2.2316 (2.2397)	Acc@1 38.281 (38.866)	Acc@5 77.344 (73.258)
Epoch: [20][200/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.0300 (2.2372)	Acc@1 40.625 (38.860)	Acc@5 81.250 (73.340)
Epoch: [20][210/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 1.9857 (2.2387)	Acc@1 43.750 (38.814)	Acc@5 76.562 (73.338)
Epoch: [20][220/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.2895 (2.2400)	Acc@1 33.594 (38.751)	Acc@5 74.219 (73.342)
Epoch: [20][230/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.3694 (2.2411)	Acc@1 39.844 (38.799)	Acc@5 72.656 (73.319)
Epoch: [20][240/391]	Time 0.104 (0.097)	Data 0.001 (0.002)	Loss 2.1773 (2.2398)	Acc@1 36.719 (38.797)	Acc@5 71.875 (73.360)
Epoch: [20][250/391]	Time 0.099 (0.097)	Data 0.001 (0.002)	Loss 2.4922 (2.2432)	Acc@1 33.594 (38.733)	Acc@5 65.625 (73.260)
Epoch: [20][260/391]	Time 0.101 (0.097)	Data 0.001 (0.002)	Loss 2.2167 (2.2451)	Acc@1 40.625 (38.763)	Acc@5 74.219 (73.192)
Epoch: [20][270/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.4816 (2.2479)	Acc@1 33.594 (38.630)	Acc@5 71.875 (73.164)
Epoch: [20][280/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.2314 (2.2499)	Acc@1 39.844 (38.565)	Acc@5 69.531 (73.159)
Epoch: [20][290/391]	Time 0.098 (0.097)	Data 0.001 (0.002)	Loss 2.5059 (2.2522)	Acc@1 33.594 (38.493)	Acc@5 67.188 (73.148)
Epoch: [20][300/391]	Time 0.099 (0.098)	Data 0.001 (0.002)	Loss 2.5856 (2.2547)	Acc@1 32.812 (38.429)	Acc@5 66.406 (73.110)
Epoch: [20][310/391]	Time 0.096 (0.098)	Data 0.001 (0.002)	Loss 2.4647 (2.2544)	Acc@1 30.469 (38.427)	Acc@5 67.969 (73.146)
Epoch: [20][320/391]	Time 0.099 (0.098)	Data 0.001 (0.002)	Loss 2.3627 (2.2558)	Acc@1 35.938 (38.386)	Acc@5 70.312 (73.128)
Epoch: [20][330/391]	Time 0.095 (0.098)	Data 0.001 (0.002)	Loss 2.2769 (2.2557)	Acc@1 32.031 (38.343)	Acc@5 75.000 (73.128)
Epoch: [20][340/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.2384 (2.2565)	Acc@1 39.062 (38.348)	Acc@5 74.219 (73.128)
Epoch: [20][350/391]	Time 0.097 (0.097)	Data 0.001 (0.002)	Loss 2.3182 (2.2560)	Acc@1 44.531 (38.364)	Acc@5 71.875 (73.119)
Epoch: [20][360/391]	Time 0.093 (0.097)	Data 0.001 (0.002)	Loss 2.1359 (2.2583)	Acc@1 42.188 (38.299)	Acc@5 78.125 (73.078)
Epoch: [20][370/391]	Time 0.096 (0.097)	Data 0.001 (0.002)	Loss 2.2913 (2.2587)	Acc@1 32.812 (38.304)	Acc@5 75.000 (73.082)
Epoch: [20][380/391]	Time 0.094 (0.097)	Data 0.001 (0.002)	Loss 2.1316 (2.2586)	Acc@1 39.062 (38.281)	Acc@5 79.688 (73.105)
Epoch: [20][390/391]	Time 0.088 (0.097)	Data 0.001 (0.002)	Loss 2.1890 (2.2578)	Acc@1 28.750 (38.260)	Acc@5 81.250 (73.142)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): AdaptiveAvgPool2d(output_size=(1, 1))
    (101): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Best acc:
29.27


now deeper
Epoch: [1][0/391]	Time 0.109 (0.109)	Data 0.162 (0.162)	Loss 2.4653 (2.4653)	Acc@1 35.156 (35.156)	Acc@5 71.875 (71.875)
Epoch: [1][10/391]	Time 0.105 (0.107)	Data 0.001 (0.016)	Loss 2.2789 (2.2463)	Acc@1 39.062 (37.216)	Acc@5 70.312 (74.432)
Epoch: [1][20/391]	Time 0.107 (0.106)	Data 0.001 (0.009)	Loss 2.2334 (2.2516)	Acc@1 39.062 (38.579)	Acc@5 75.781 (73.661)
Epoch: [1][30/391]	Time 0.101 (0.105)	Data 0.001 (0.006)	Loss 2.4015 (2.2415)	Acc@1 32.812 (38.710)	Acc@5 69.531 (73.816)
Epoch: [1][40/391]	Time 0.102 (0.105)	Data 0.001 (0.005)	Loss 2.3200 (2.2296)	Acc@1 35.938 (38.929)	Acc@5 72.656 (74.390)
Epoch: [1][50/391]	Time 0.106 (0.106)	Data 0.001 (0.004)	Loss 2.1691 (2.2284)	Acc@1 35.156 (38.863)	Acc@5 75.000 (74.372)
Epoch: [1][60/391]	Time 0.102 (0.105)	Data 0.001 (0.004)	Loss 2.2123 (2.2330)	Acc@1 40.625 (38.986)	Acc@5 77.344 (74.385)
Epoch: [1][70/391]	Time 0.110 (0.106)	Data 0.001 (0.003)	Loss 2.2917 (2.2262)	Acc@1 39.844 (38.952)	Acc@5 73.438 (74.472)
Epoch: [1][80/391]	Time 0.100 (0.106)	Data 0.001 (0.003)	Loss 2.1993 (2.2275)	Acc@1 36.719 (38.792)	Acc@5 72.656 (74.556)
Epoch: [1][90/391]	Time 0.108 (0.106)	Data 0.001 (0.003)	Loss 2.2446 (2.2251)	Acc@1 39.062 (38.788)	Acc@5 70.312 (74.519)
Epoch: [1][100/391]	Time 0.101 (0.106)	Data 0.001 (0.003)	Loss 2.0519 (2.2257)	Acc@1 46.094 (38.931)	Acc@5 76.562 (74.482)
Epoch: [1][110/391]	Time 0.108 (0.106)	Data 0.001 (0.003)	Loss 2.2916 (2.2245)	Acc@1 35.156 (39.147)	Acc@5 71.875 (74.430)
Epoch: [1][120/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.1057 (2.2296)	Acc@1 46.094 (39.134)	Acc@5 77.344 (74.245)
Epoch: [1][130/391]	Time 0.114 (0.105)	Data 0.001 (0.002)	Loss 2.1584 (2.2247)	Acc@1 41.406 (39.206)	Acc@5 73.438 (74.302)
Epoch: [1][140/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.1858 (2.2227)	Acc@1 39.062 (39.262)	Acc@5 75.000 (74.191)
Epoch: [1][150/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.0311 (2.2170)	Acc@1 39.844 (39.285)	Acc@5 75.781 (74.276)
Epoch: [1][160/391]	Time 0.104 (0.105)	Data 0.001 (0.002)	Loss 2.1262 (2.2167)	Acc@1 43.750 (39.281)	Acc@5 75.000 (74.258)
Epoch: [1][170/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.1732 (2.2189)	Acc@1 37.500 (39.327)	Acc@5 75.000 (74.278)
Epoch: [1][180/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.0763 (2.2223)	Acc@1 42.969 (39.296)	Acc@5 78.906 (74.150)
Epoch: [1][190/391]	Time 0.106 (0.105)	Data 0.001 (0.002)	Loss 2.1966 (2.2249)	Acc@1 35.938 (39.275)	Acc@5 76.562 (74.145)
Epoch: [1][200/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.1172 (2.2274)	Acc@1 45.312 (39.276)	Acc@5 75.781 (74.106)
Epoch: [1][210/391]	Time 0.101 (0.105)	Data 0.001 (0.002)	Loss 2.5142 (2.2321)	Acc@1 37.500 (39.129)	Acc@5 65.625 (73.971)
Epoch: [1][220/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.2026 (2.2328)	Acc@1 39.062 (39.077)	Acc@5 74.219 (73.932)
Epoch: [1][230/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.6198 (2.2365)	Acc@1 26.562 (39.015)	Acc@5 64.062 (73.810)
Epoch: [1][240/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2790 (2.2363)	Acc@1 37.500 (38.994)	Acc@5 74.219 (73.849)
Epoch: [1][250/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3255 (2.2372)	Acc@1 31.250 (38.919)	Acc@5 69.531 (73.805)
Epoch: [1][260/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0969 (2.2360)	Acc@1 39.844 (38.910)	Acc@5 78.125 (73.830)
Epoch: [1][270/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2348 (2.2345)	Acc@1 42.188 (38.927)	Acc@5 76.562 (73.873)
Epoch: [1][280/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1845 (2.2356)	Acc@1 42.969 (38.926)	Acc@5 71.875 (73.830)
Epoch: [1][290/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.4936 (2.2361)	Acc@1 41.406 (38.899)	Acc@5 69.531 (73.819)
Epoch: [1][300/391]	Time 0.098 (0.104)	Data 0.001 (0.002)	Loss 2.2236 (2.2358)	Acc@1 39.062 (38.948)	Acc@5 67.969 (73.744)
Epoch: [1][310/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2731 (2.2372)	Acc@1 44.531 (38.924)	Acc@5 79.688 (73.754)
Epoch: [1][320/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.4169 (2.2394)	Acc@1 36.719 (38.887)	Acc@5 62.500 (73.695)
Epoch: [1][330/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3126 (2.2390)	Acc@1 37.500 (38.893)	Acc@5 71.094 (73.688)
Epoch: [1][340/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.3153 (2.2404)	Acc@1 34.375 (38.891)	Acc@5 75.781 (73.699)
Epoch: [1][350/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0710 (2.2399)	Acc@1 48.438 (38.918)	Acc@5 76.562 (73.669)
Epoch: [1][360/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2462 (2.2402)	Acc@1 38.281 (38.868)	Acc@5 75.781 (73.671)
Epoch: [1][370/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2489 (2.2404)	Acc@1 34.375 (38.865)	Acc@5 78.906 (73.661)
Epoch: [1][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2505 (2.2404)	Acc@1 40.625 (38.847)	Acc@5 75.781 (73.653)
Epoch: [1][390/391]	Time 0.085 (0.104)	Data 0.001 (0.002)	Loss 2.3927 (2.2434)	Acc@1 42.500 (38.842)	Acc@5 63.750 (73.594)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [2][0/391]	Time 0.127 (0.127)	Data 0.181 (0.181)	Loss 2.1169 (2.1169)	Acc@1 40.625 (40.625)	Acc@5 73.438 (73.438)
Epoch: [2][10/391]	Time 0.112 (0.107)	Data 0.001 (0.017)	Loss 2.1024 (2.1656)	Acc@1 46.875 (39.489)	Acc@5 76.562 (75.710)
Epoch: [2][20/391]	Time 0.101 (0.106)	Data 0.001 (0.010)	Loss 2.0392 (2.2116)	Acc@1 44.531 (39.174)	Acc@5 75.781 (74.702)
Epoch: [2][30/391]	Time 0.110 (0.105)	Data 0.001 (0.007)	Loss 2.4851 (2.2404)	Acc@1 32.812 (38.483)	Acc@5 71.094 (73.816)
Epoch: [2][40/391]	Time 0.101 (0.105)	Data 0.001 (0.005)	Loss 2.1628 (2.2321)	Acc@1 40.625 (38.338)	Acc@5 75.781 (73.971)
Epoch: [2][50/391]	Time 0.102 (0.104)	Data 0.001 (0.005)	Loss 2.0855 (2.2417)	Acc@1 35.938 (37.852)	Acc@5 77.344 (73.468)
Epoch: [2][60/391]	Time 0.106 (0.104)	Data 0.001 (0.004)	Loss 2.2144 (2.2371)	Acc@1 39.844 (38.140)	Acc@5 78.125 (73.719)
Epoch: [2][70/391]	Time 0.101 (0.104)	Data 0.001 (0.004)	Loss 2.1177 (2.2260)	Acc@1 42.969 (38.391)	Acc@5 76.562 (73.889)
Epoch: [2][80/391]	Time 0.102 (0.105)	Data 0.001 (0.003)	Loss 2.2162 (2.2196)	Acc@1 36.719 (38.773)	Acc@5 75.000 (74.142)
Epoch: [2][90/391]	Time 0.108 (0.105)	Data 0.001 (0.003)	Loss 2.3425 (2.2228)	Acc@1 31.250 (38.711)	Acc@5 71.875 (74.133)
Epoch: [2][100/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.2246 (2.2286)	Acc@1 40.625 (38.537)	Acc@5 73.438 (74.087)
Epoch: [2][110/391]	Time 0.109 (0.104)	Data 0.001 (0.003)	Loss 2.1368 (2.2325)	Acc@1 42.188 (38.499)	Acc@5 77.344 (73.909)
Epoch: [2][120/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.0878 (2.2305)	Acc@1 43.750 (38.565)	Acc@5 77.344 (73.889)
Epoch: [2][130/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 2.1738 (2.2309)	Acc@1 38.281 (38.663)	Acc@5 75.781 (73.885)
Epoch: [2][140/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.0885 (2.2245)	Acc@1 42.188 (38.813)	Acc@5 76.562 (74.053)
Epoch: [2][150/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4406 (2.2234)	Acc@1 30.469 (38.892)	Acc@5 68.750 (74.079)
Epoch: [2][160/391]	Time 0.098 (0.104)	Data 0.001 (0.002)	Loss 2.3510 (2.2311)	Acc@1 35.156 (38.728)	Acc@5 69.531 (73.845)
Epoch: [2][170/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1844 (2.2324)	Acc@1 39.062 (38.702)	Acc@5 73.438 (73.821)
Epoch: [2][180/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0798 (2.2331)	Acc@1 48.438 (38.726)	Acc@5 76.562 (73.753)
Epoch: [2][190/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2773 (2.2324)	Acc@1 41.406 (38.797)	Acc@5 74.219 (73.777)
Epoch: [2][200/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1776 (2.2298)	Acc@1 39.062 (38.775)	Acc@5 75.781 (73.865)
Epoch: [2][210/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 1.8979 (2.2283)	Acc@1 40.625 (38.848)	Acc@5 83.594 (73.882)
Epoch: [2][220/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1813 (2.2304)	Acc@1 39.062 (38.808)	Acc@5 75.781 (73.826)
Epoch: [2][230/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2559 (2.2307)	Acc@1 39.062 (38.734)	Acc@5 70.312 (73.810)
Epoch: [2][240/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.5315 (2.2284)	Acc@1 33.594 (38.758)	Acc@5 70.312 (73.911)
Epoch: [2][250/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0344 (2.2279)	Acc@1 45.312 (38.757)	Acc@5 74.219 (73.886)
Epoch: [2][260/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.2238 (2.2274)	Acc@1 39.062 (38.766)	Acc@5 73.438 (73.907)
Epoch: [2][270/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.3213 (2.2246)	Acc@1 39.844 (38.855)	Acc@5 71.094 (73.991)
Epoch: [2][280/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.3889 (2.2270)	Acc@1 38.281 (38.837)	Acc@5 64.844 (73.957)
Epoch: [2][290/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.3973 (2.2294)	Acc@1 37.500 (38.826)	Acc@5 72.656 (73.907)
Epoch: [2][300/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1777 (2.2286)	Acc@1 49.219 (38.886)	Acc@5 74.219 (73.920)
Epoch: [2][310/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.2197 (2.2322)	Acc@1 38.281 (38.811)	Acc@5 74.219 (73.844)
Epoch: [2][320/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.4718 (2.2336)	Acc@1 37.500 (38.802)	Acc@5 71.094 (73.837)
Epoch: [2][330/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2446 (2.2371)	Acc@1 36.719 (38.694)	Acc@5 75.000 (73.787)
Epoch: [2][340/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.0404 (2.2352)	Acc@1 43.750 (38.790)	Acc@5 77.344 (73.841)
Epoch: [2][350/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.4159 (2.2381)	Acc@1 38.281 (38.729)	Acc@5 70.312 (73.791)
Epoch: [2][360/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4335 (2.2388)	Acc@1 35.156 (38.710)	Acc@5 70.312 (73.790)
Epoch: [2][370/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1697 (2.2379)	Acc@1 42.969 (38.776)	Acc@5 71.094 (73.774)
Epoch: [2][380/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2525 (2.2389)	Acc@1 41.406 (38.753)	Acc@5 71.094 (73.753)
Epoch: [2][390/391]	Time 0.085 (0.104)	Data 0.001 (0.002)	Loss 2.0555 (2.2376)	Acc@1 41.250 (38.810)	Acc@5 78.750 (73.774)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [3][0/391]	Time 0.118 (0.118)	Data 0.171 (0.171)	Loss 2.1861 (2.1861)	Acc@1 37.500 (37.500)	Acc@5 75.781 (75.781)
Epoch: [3][10/391]	Time 0.109 (0.105)	Data 0.001 (0.017)	Loss 2.2897 (2.2513)	Acc@1 38.281 (39.347)	Acc@5 71.875 (73.509)
Epoch: [3][20/391]	Time 0.108 (0.104)	Data 0.001 (0.009)	Loss 2.1438 (2.2700)	Acc@1 40.625 (38.616)	Acc@5 75.781 (72.879)
Epoch: [3][30/391]	Time 0.105 (0.104)	Data 0.001 (0.007)	Loss 2.2243 (2.2500)	Acc@1 36.719 (39.088)	Acc@5 77.344 (73.639)
Epoch: [3][40/391]	Time 0.103 (0.103)	Data 0.001 (0.005)	Loss 2.0946 (2.2284)	Acc@1 44.531 (38.986)	Acc@5 73.438 (73.952)
Epoch: [3][50/391]	Time 0.102 (0.103)	Data 0.001 (0.005)	Loss 2.2989 (2.2263)	Acc@1 43.750 (38.940)	Acc@5 73.438 (74.066)
Epoch: [3][60/391]	Time 0.103 (0.104)	Data 0.001 (0.004)	Loss 2.3016 (2.2242)	Acc@1 35.938 (38.832)	Acc@5 72.656 (74.155)
Epoch: [3][70/391]	Time 0.103 (0.103)	Data 0.001 (0.004)	Loss 2.2735 (2.2254)	Acc@1 34.375 (38.941)	Acc@5 73.438 (74.142)
Epoch: [3][80/391]	Time 0.104 (0.103)	Data 0.001 (0.003)	Loss 2.3852 (2.2223)	Acc@1 39.062 (38.976)	Acc@5 71.875 (74.113)
Epoch: [3][90/391]	Time 0.103 (0.104)	Data 0.001 (0.003)	Loss 2.1959 (2.2307)	Acc@1 40.625 (38.925)	Acc@5 74.219 (73.918)
Epoch: [3][100/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.1859 (2.2365)	Acc@1 40.625 (38.861)	Acc@5 75.781 (73.755)
Epoch: [3][110/391]	Time 0.103 (0.104)	Data 0.001 (0.003)	Loss 2.4343 (2.2361)	Acc@1 30.469 (38.711)	Acc@5 67.969 (73.613)
Epoch: [3][120/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 2.0652 (2.2360)	Acc@1 45.312 (38.707)	Acc@5 78.906 (73.696)
Epoch: [3][130/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.0796 (2.2338)	Acc@1 42.969 (38.824)	Acc@5 76.562 (73.736)
Epoch: [3][140/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.3510 (2.2354)	Acc@1 38.281 (38.791)	Acc@5 71.094 (73.753)
Epoch: [3][150/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.0422 (2.2306)	Acc@1 45.312 (39.052)	Acc@5 80.469 (73.882)
Epoch: [3][160/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.1351 (2.2290)	Acc@1 42.969 (39.096)	Acc@5 72.656 (73.898)
Epoch: [3][170/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.3895 (2.2324)	Acc@1 33.594 (39.012)	Acc@5 71.875 (73.881)
Epoch: [3][180/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.2239 (2.2317)	Acc@1 36.719 (38.937)	Acc@5 75.781 (73.899)
Epoch: [3][190/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.4283 (2.2312)	Acc@1 35.938 (38.997)	Acc@5 68.750 (73.859)
Epoch: [3][200/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.1376 (2.2276)	Acc@1 40.625 (39.156)	Acc@5 76.562 (73.892)
Epoch: [3][210/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.3256 (2.2251)	Acc@1 37.500 (39.196)	Acc@5 70.312 (73.863)
Epoch: [3][220/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.2727 (2.2272)	Acc@1 45.312 (39.232)	Acc@5 72.656 (73.840)
Epoch: [3][230/391]	Time 0.109 (0.103)	Data 0.001 (0.002)	Loss 2.2203 (2.2269)	Acc@1 41.406 (39.259)	Acc@5 77.344 (73.843)
Epoch: [3][240/391]	Time 0.100 (0.103)	Data 0.001 (0.002)	Loss 2.1303 (2.2280)	Acc@1 42.969 (39.251)	Acc@5 75.781 (73.775)
Epoch: [3][250/391]	Time 0.109 (0.103)	Data 0.001 (0.002)	Loss 2.2116 (2.2284)	Acc@1 37.500 (39.168)	Acc@5 68.750 (73.752)
Epoch: [3][260/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.0650 (2.2321)	Acc@1 42.188 (39.068)	Acc@5 73.438 (73.680)
Epoch: [3][270/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.4050 (2.2323)	Acc@1 34.375 (38.985)	Acc@5 67.969 (73.694)
Epoch: [3][280/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.0604 (2.2331)	Acc@1 40.625 (38.954)	Acc@5 75.781 (73.691)
Epoch: [3][290/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.1254 (2.2350)	Acc@1 35.938 (38.888)	Acc@5 75.781 (73.674)
Epoch: [3][300/391]	Time 0.099 (0.103)	Data 0.001 (0.002)	Loss 2.2534 (2.2337)	Acc@1 35.938 (38.935)	Acc@5 72.656 (73.669)
Epoch: [3][310/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.5172 (2.2365)	Acc@1 35.156 (38.967)	Acc@5 65.625 (73.623)
Epoch: [3][320/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.0600 (2.2361)	Acc@1 43.750 (38.955)	Acc@5 78.906 (73.642)
Epoch: [3][330/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.3263 (2.2382)	Acc@1 34.375 (38.871)	Acc@5 67.188 (73.551)
Epoch: [3][340/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.3032 (2.2370)	Acc@1 41.406 (38.868)	Acc@5 68.750 (73.554)
Epoch: [3][350/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.3098 (2.2372)	Acc@1 32.031 (38.835)	Acc@5 78.125 (73.596)
Epoch: [3][360/391]	Time 0.099 (0.103)	Data 0.001 (0.002)	Loss 2.1868 (2.2377)	Acc@1 41.406 (38.807)	Acc@5 75.000 (73.593)
Epoch: [3][370/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.3966 (2.2381)	Acc@1 36.719 (38.810)	Acc@5 67.188 (73.581)
Epoch: [3][380/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.0656 (2.2360)	Acc@1 42.188 (38.802)	Acc@5 78.906 (73.647)
Epoch: [3][390/391]	Time 0.085 (0.103)	Data 0.001 (0.002)	Loss 2.5555 (2.2374)	Acc@1 31.250 (38.764)	Acc@5 66.250 (73.614)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [4][0/391]	Time 0.117 (0.117)	Data 0.187 (0.187)	Loss 2.1685 (2.1685)	Acc@1 38.281 (38.281)	Acc@5 76.562 (76.562)
Epoch: [4][10/391]	Time 0.103 (0.105)	Data 0.001 (0.018)	Loss 2.3625 (2.2128)	Acc@1 42.969 (39.702)	Acc@5 78.906 (75.142)
Epoch: [4][20/391]	Time 0.102 (0.105)	Data 0.001 (0.010)	Loss 2.1569 (2.2247)	Acc@1 42.969 (39.844)	Acc@5 76.562 (74.033)
Epoch: [4][30/391]	Time 0.103 (0.104)	Data 0.001 (0.007)	Loss 2.1721 (2.2232)	Acc@1 42.188 (39.743)	Acc@5 76.562 (74.118)
Epoch: [4][40/391]	Time 0.108 (0.104)	Data 0.001 (0.006)	Loss 2.3531 (2.2480)	Acc@1 33.594 (39.329)	Acc@5 75.781 (73.495)
Epoch: [4][50/391]	Time 0.103 (0.104)	Data 0.001 (0.005)	Loss 2.1563 (2.2339)	Acc@1 38.281 (39.599)	Acc@5 77.344 (73.805)
Epoch: [4][60/391]	Time 0.109 (0.104)	Data 0.001 (0.004)	Loss 2.0313 (2.2203)	Acc@1 43.750 (39.728)	Acc@5 78.906 (74.142)
Epoch: [4][70/391]	Time 0.102 (0.104)	Data 0.001 (0.004)	Loss 2.3598 (2.2185)	Acc@1 32.812 (39.657)	Acc@5 67.188 (74.142)
Epoch: [4][80/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.1655 (2.2123)	Acc@1 39.844 (39.747)	Acc@5 78.125 (74.209)
Epoch: [4][90/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.1067 (2.2122)	Acc@1 39.844 (39.758)	Acc@5 78.906 (74.133)
Epoch: [4][100/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.2627 (2.2171)	Acc@1 34.375 (39.612)	Acc@5 74.219 (74.010)
Epoch: [4][110/391]	Time 0.101 (0.104)	Data 0.001 (0.003)	Loss 2.1319 (2.2180)	Acc@1 46.875 (39.506)	Acc@5 74.219 (74.050)
Epoch: [4][120/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 2.4788 (2.2141)	Acc@1 33.594 (39.624)	Acc@5 67.188 (74.180)
Epoch: [4][130/391]	Time 0.105 (0.104)	Data 0.001 (0.003)	Loss 2.4556 (2.2208)	Acc@1 32.812 (39.450)	Acc@5 69.531 (73.986)
Epoch: [4][140/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.1628 (2.2257)	Acc@1 42.969 (39.412)	Acc@5 74.219 (73.792)
Epoch: [4][150/391]	Time 0.101 (0.104)	Data 0.002 (0.002)	Loss 2.4853 (2.2294)	Acc@1 42.969 (39.244)	Acc@5 65.625 (73.717)
Epoch: [4][160/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2801 (2.2318)	Acc@1 46.094 (39.164)	Acc@5 72.656 (73.690)
Epoch: [4][170/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0391 (2.2373)	Acc@1 44.531 (39.031)	Acc@5 78.906 (73.575)
Epoch: [4][180/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.3914 (2.2392)	Acc@1 33.594 (38.985)	Acc@5 71.875 (73.515)
Epoch: [4][190/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2414 (2.2434)	Acc@1 35.938 (38.891)	Acc@5 71.094 (73.327)
Epoch: [4][200/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2529 (2.2428)	Acc@1 39.062 (38.860)	Acc@5 72.656 (73.321)
Epoch: [4][210/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1374 (2.2447)	Acc@1 40.625 (38.744)	Acc@5 75.781 (73.323)
Epoch: [4][220/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1942 (2.2390)	Acc@1 44.531 (38.840)	Acc@5 78.125 (73.459)
Epoch: [4][230/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1445 (2.2408)	Acc@1 39.062 (38.738)	Acc@5 76.562 (73.417)
Epoch: [4][240/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.1704 (2.2396)	Acc@1 46.094 (38.832)	Acc@5 71.875 (73.467)
Epoch: [4][250/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2507 (2.2403)	Acc@1 33.594 (38.776)	Acc@5 71.094 (73.450)
Epoch: [4][260/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 1.9879 (2.2388)	Acc@1 47.656 (38.829)	Acc@5 79.688 (73.473)
Epoch: [4][270/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.4729 (2.2410)	Acc@1 32.812 (38.806)	Acc@5 73.438 (73.423)
Epoch: [4][280/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1789 (2.2437)	Acc@1 37.500 (38.715)	Acc@5 75.000 (73.362)
Epoch: [4][290/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.2300 (2.2429)	Acc@1 35.938 (38.668)	Acc@5 75.000 (73.443)
Epoch: [4][300/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.2412 (2.2457)	Acc@1 34.375 (38.538)	Acc@5 72.656 (73.349)
Epoch: [4][310/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0235 (2.2437)	Acc@1 46.094 (38.565)	Acc@5 79.688 (73.415)
Epoch: [4][320/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 1.9999 (2.2437)	Acc@1 47.656 (38.590)	Acc@5 78.125 (73.420)
Epoch: [4][330/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.6324 (2.2445)	Acc@1 30.469 (38.567)	Acc@5 67.188 (73.430)
Epoch: [4][340/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.0916 (2.2453)	Acc@1 37.500 (38.526)	Acc@5 77.344 (73.399)
Epoch: [4][350/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.3558 (2.2455)	Acc@1 34.375 (38.531)	Acc@5 71.094 (73.391)
Epoch: [4][360/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.0902 (2.2454)	Acc@1 39.062 (38.498)	Acc@5 77.344 (73.420)
Epoch: [4][370/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2348 (2.2439)	Acc@1 39.844 (38.563)	Acc@5 77.344 (73.456)
Epoch: [4][380/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.3667 (2.2445)	Acc@1 38.281 (38.540)	Acc@5 72.656 (73.450)
Epoch: [4][390/391]	Time 0.085 (0.104)	Data 0.001 (0.002)	Loss 2.4262 (2.2459)	Acc@1 36.250 (38.466)	Acc@5 71.250 (73.440)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [5][0/391]	Time 0.115 (0.115)	Data 0.167 (0.167)	Loss 2.2356 (2.2356)	Acc@1 40.625 (40.625)	Acc@5 72.656 (72.656)
Epoch: [5][10/391]	Time 0.109 (0.107)	Data 0.001 (0.016)	Loss 2.4668 (2.1886)	Acc@1 33.594 (39.489)	Acc@5 66.406 (74.574)
Epoch: [5][20/391]	Time 0.101 (0.105)	Data 0.001 (0.009)	Loss 1.9984 (2.1753)	Acc@1 42.188 (39.844)	Acc@5 82.812 (74.963)
Epoch: [5][30/391]	Time 0.102 (0.105)	Data 0.001 (0.006)	Loss 2.3120 (2.1654)	Acc@1 36.719 (40.297)	Acc@5 72.656 (75.000)
Epoch: [5][40/391]	Time 0.105 (0.105)	Data 0.001 (0.005)	Loss 2.1082 (2.1879)	Acc@1 42.969 (40.015)	Acc@5 71.875 (74.104)
Epoch: [5][50/391]	Time 0.102 (0.105)	Data 0.001 (0.004)	Loss 2.2135 (2.1948)	Acc@1 38.281 (39.737)	Acc@5 72.656 (73.943)
Epoch: [5][60/391]	Time 0.103 (0.105)	Data 0.001 (0.004)	Loss 2.1930 (2.1817)	Acc@1 36.719 (39.972)	Acc@5 74.219 (74.283)
Epoch: [5][70/391]	Time 0.107 (0.105)	Data 0.001 (0.003)	Loss 2.2899 (2.1867)	Acc@1 37.500 (39.910)	Acc@5 73.438 (74.351)
Epoch: [5][80/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.4133 (2.1968)	Acc@1 36.719 (39.660)	Acc@5 66.406 (74.161)
Epoch: [5][90/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.3729 (2.1942)	Acc@1 36.719 (39.861)	Acc@5 72.656 (74.227)
Epoch: [5][100/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.1354 (2.1847)	Acc@1 38.281 (40.076)	Acc@5 75.781 (74.621)
Epoch: [5][110/391]	Time 0.114 (0.104)	Data 0.002 (0.003)	Loss 2.1787 (2.1824)	Acc@1 36.719 (39.985)	Acc@5 71.875 (74.697)
Epoch: [5][120/391]	Time 0.107 (0.104)	Data 0.001 (0.003)	Loss 2.0656 (2.1870)	Acc@1 39.844 (39.682)	Acc@5 72.656 (74.561)
Epoch: [5][130/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1296 (2.1947)	Acc@1 42.969 (39.575)	Acc@5 75.781 (74.284)
Epoch: [5][140/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3086 (2.1924)	Acc@1 39.844 (39.633)	Acc@5 72.656 (74.263)
Epoch: [5][150/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.3358 (2.1962)	Acc@1 36.719 (39.487)	Acc@5 75.781 (74.255)
Epoch: [5][160/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.0290 (2.2014)	Acc@1 42.969 (39.349)	Acc@5 76.562 (74.093)
Epoch: [5][170/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2411 (2.2032)	Acc@1 42.188 (39.355)	Acc@5 69.531 (74.059)
Epoch: [5][180/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2915 (2.2080)	Acc@1 39.844 (39.313)	Acc@5 73.438 (73.930)
Epoch: [5][190/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.2145 (2.2085)	Acc@1 34.375 (39.267)	Acc@5 76.562 (73.908)
Epoch: [5][200/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4176 (2.2126)	Acc@1 31.250 (39.261)	Acc@5 67.188 (73.818)
Epoch: [5][210/391]	Time 0.099 (0.103)	Data 0.001 (0.002)	Loss 2.1835 (2.2149)	Acc@1 38.281 (39.211)	Acc@5 75.781 (73.819)
Epoch: [5][220/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.3083 (2.2178)	Acc@1 34.375 (39.204)	Acc@5 71.875 (73.802)
Epoch: [5][230/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.3927 (2.2223)	Acc@1 39.844 (39.120)	Acc@5 71.094 (73.749)
Epoch: [5][240/391]	Time 0.108 (0.103)	Data 0.001 (0.002)	Loss 2.0459 (2.2252)	Acc@1 37.500 (38.991)	Acc@5 78.906 (73.703)
Epoch: [5][250/391]	Time 0.108 (0.103)	Data 0.001 (0.002)	Loss 2.2128 (2.2269)	Acc@1 42.188 (38.994)	Acc@5 75.781 (73.721)
Epoch: [5][260/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.3206 (2.2302)	Acc@1 38.281 (38.955)	Acc@5 68.750 (73.653)
Epoch: [5][270/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.1639 (2.2321)	Acc@1 42.969 (38.976)	Acc@5 74.219 (73.645)
Epoch: [5][280/391]	Time 0.105 (0.103)	Data 0.001 (0.002)	Loss 2.2422 (2.2311)	Acc@1 41.406 (39.040)	Acc@5 73.438 (73.671)
Epoch: [5][290/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.1817 (2.2320)	Acc@1 39.062 (39.041)	Acc@5 78.906 (73.642)
Epoch: [5][300/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.1279 (2.2312)	Acc@1 36.719 (39.055)	Acc@5 77.344 (73.681)
Epoch: [5][310/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.1357 (2.2315)	Acc@1 39.844 (39.040)	Acc@5 77.344 (73.649)
Epoch: [5][320/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.2671 (2.2289)	Acc@1 39.844 (39.082)	Acc@5 69.531 (73.715)
Epoch: [5][330/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.1901 (2.2291)	Acc@1 37.500 (39.048)	Acc@5 73.438 (73.737)
Epoch: [5][340/391]	Time 0.100 (0.103)	Data 0.001 (0.002)	Loss 2.4296 (2.2303)	Acc@1 34.375 (39.088)	Acc@5 68.750 (73.690)
Epoch: [5][350/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.4005 (2.2308)	Acc@1 28.906 (39.094)	Acc@5 68.750 (73.682)
Epoch: [5][360/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.2147 (2.2286)	Acc@1 36.719 (39.095)	Acc@5 73.438 (73.740)
Epoch: [5][370/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.1968 (2.2282)	Acc@1 39.844 (39.117)	Acc@5 76.562 (73.745)
Epoch: [5][380/391]	Time 0.105 (0.103)	Data 0.001 (0.002)	Loss 2.5343 (2.2267)	Acc@1 35.938 (39.167)	Acc@5 62.500 (73.747)
Epoch: [5][390/391]	Time 0.087 (0.103)	Data 0.001 (0.002)	Loss 2.2046 (2.2266)	Acc@1 38.750 (39.210)	Acc@5 75.000 (73.738)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [6][0/391]	Time 0.117 (0.117)	Data 0.160 (0.160)	Loss 2.4162 (2.4162)	Acc@1 32.031 (32.031)	Acc@5 69.531 (69.531)
Epoch: [6][10/391]	Time 0.104 (0.105)	Data 0.001 (0.016)	Loss 2.2337 (2.2558)	Acc@1 37.500 (37.216)	Acc@5 74.219 (73.438)
Epoch: [6][20/391]	Time 0.101 (0.104)	Data 0.001 (0.009)	Loss 2.3304 (2.2661)	Acc@1 32.812 (38.132)	Acc@5 67.188 (73.326)
Epoch: [6][30/391]	Time 0.103 (0.104)	Data 0.001 (0.006)	Loss 2.1045 (2.2272)	Acc@1 42.188 (38.962)	Acc@5 79.688 (73.992)
Epoch: [6][40/391]	Time 0.102 (0.104)	Data 0.001 (0.005)	Loss 2.0779 (2.2309)	Acc@1 44.531 (38.720)	Acc@5 77.344 (73.761)
Epoch: [6][50/391]	Time 0.103 (0.103)	Data 0.001 (0.004)	Loss 2.3690 (2.2317)	Acc@1 29.688 (38.940)	Acc@5 78.906 (73.729)
Epoch: [6][60/391]	Time 0.101 (0.103)	Data 0.001 (0.004)	Loss 1.9596 (2.2225)	Acc@1 46.094 (39.319)	Acc@5 78.906 (73.873)
Epoch: [6][70/391]	Time 0.107 (0.103)	Data 0.001 (0.003)	Loss 2.2183 (2.2167)	Acc@1 38.281 (39.305)	Acc@5 77.344 (74.186)
Epoch: [6][80/391]	Time 0.102 (0.103)	Data 0.001 (0.003)	Loss 2.4837 (2.2259)	Acc@1 31.250 (38.956)	Acc@5 68.750 (73.949)
Epoch: [6][90/391]	Time 0.103 (0.103)	Data 0.001 (0.003)	Loss 2.3536 (2.2321)	Acc@1 36.719 (38.573)	Acc@5 73.438 (74.030)
Epoch: [6][100/391]	Time 0.103 (0.103)	Data 0.001 (0.003)	Loss 2.0638 (2.2354)	Acc@1 41.406 (38.583)	Acc@5 76.562 (73.832)
Epoch: [6][110/391]	Time 0.101 (0.103)	Data 0.001 (0.003)	Loss 2.4180 (2.2309)	Acc@1 35.938 (38.697)	Acc@5 70.312 (73.874)
Epoch: [6][120/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.2015 (2.2315)	Acc@1 46.875 (38.630)	Acc@5 70.312 (73.838)
Epoch: [6][130/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.1226 (2.2249)	Acc@1 43.750 (38.770)	Acc@5 75.781 (73.998)
Epoch: [6][140/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.2442 (2.2290)	Acc@1 44.531 (38.802)	Acc@5 69.531 (73.814)
Epoch: [6][150/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.3702 (2.2302)	Acc@1 32.031 (38.731)	Acc@5 66.406 (73.794)
Epoch: [6][160/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 1.9122 (2.2281)	Acc@1 45.312 (38.810)	Acc@5 82.812 (73.816)
Epoch: [6][170/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.2836 (2.2292)	Acc@1 35.938 (38.770)	Acc@5 76.562 (73.872)
Epoch: [6][180/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.3216 (2.2308)	Acc@1 40.625 (38.726)	Acc@5 70.312 (73.882)
Epoch: [6][190/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.1468 (2.2306)	Acc@1 40.625 (38.760)	Acc@5 75.781 (73.904)
Epoch: [6][200/391]	Time 0.109 (0.103)	Data 0.001 (0.002)	Loss 2.4069 (2.2336)	Acc@1 36.719 (38.693)	Acc@5 71.094 (73.803)
Epoch: [6][210/391]	Time 0.105 (0.103)	Data 0.001 (0.002)	Loss 2.1643 (2.2333)	Acc@1 39.844 (38.714)	Acc@5 70.312 (73.800)
Epoch: [6][220/391]	Time 0.101 (0.103)	Data 0.001 (0.002)	Loss 2.1611 (2.2360)	Acc@1 40.625 (38.649)	Acc@5 73.438 (73.795)
Epoch: [6][230/391]	Time 0.108 (0.103)	Data 0.001 (0.002)	Loss 1.9666 (2.2377)	Acc@1 46.875 (38.663)	Acc@5 81.250 (73.772)
Epoch: [6][240/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.2429 (2.2366)	Acc@1 29.688 (38.657)	Acc@5 75.781 (73.833)
Epoch: [6][250/391]	Time 0.108 (0.103)	Data 0.001 (0.002)	Loss 2.0840 (2.2349)	Acc@1 39.062 (38.708)	Acc@5 76.562 (73.827)
Epoch: [6][260/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.2665 (2.2351)	Acc@1 42.188 (38.706)	Acc@5 71.875 (73.866)
Epoch: [6][270/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.4533 (2.2369)	Acc@1 32.812 (38.644)	Acc@5 69.531 (73.832)
Epoch: [6][280/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.2818 (2.2362)	Acc@1 38.281 (38.676)	Acc@5 72.656 (73.807)
Epoch: [6][290/391]	Time 0.108 (0.103)	Data 0.001 (0.002)	Loss 2.0865 (2.2358)	Acc@1 39.844 (38.660)	Acc@5 82.031 (73.778)
Epoch: [6][300/391]	Time 0.105 (0.103)	Data 0.001 (0.002)	Loss 2.1181 (2.2367)	Acc@1 43.750 (38.684)	Acc@5 72.656 (73.749)
Epoch: [6][310/391]	Time 0.105 (0.103)	Data 0.001 (0.002)	Loss 2.3352 (2.2368)	Acc@1 38.281 (38.711)	Acc@5 69.531 (73.701)
Epoch: [6][320/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.1968 (2.2364)	Acc@1 35.156 (38.688)	Acc@5 74.219 (73.698)
Epoch: [6][330/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.2034 (2.2355)	Acc@1 34.375 (38.668)	Acc@5 71.875 (73.688)
Epoch: [6][340/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.3776 (2.2352)	Acc@1 36.719 (38.726)	Acc@5 71.094 (73.678)
Epoch: [6][350/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.2361 (2.2371)	Acc@1 35.938 (38.653)	Acc@5 73.438 (73.685)
Epoch: [6][360/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.5819 (2.2387)	Acc@1 30.469 (38.647)	Acc@5 62.500 (73.641)
Epoch: [6][370/391]	Time 0.109 (0.103)	Data 0.001 (0.002)	Loss 2.3222 (2.2397)	Acc@1 39.844 (38.633)	Acc@5 69.531 (73.604)
Epoch: [6][380/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.2646 (2.2409)	Acc@1 39.844 (38.644)	Acc@5 71.094 (73.538)
Epoch: [6][390/391]	Time 0.086 (0.103)	Data 0.001 (0.002)	Loss 2.2232 (2.2402)	Acc@1 33.750 (38.626)	Acc@5 76.250 (73.568)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [7][0/391]	Time 0.114 (0.114)	Data 0.165 (0.165)	Loss 2.4716 (2.4716)	Acc@1 35.938 (35.938)	Acc@5 66.406 (66.406)
Epoch: [7][10/391]	Time 0.106 (0.105)	Data 0.001 (0.016)	Loss 2.0853 (2.2108)	Acc@1 42.969 (39.418)	Acc@5 78.125 (74.290)
Epoch: [7][20/391]	Time 0.102 (0.105)	Data 0.001 (0.009)	Loss 2.1887 (2.2184)	Acc@1 37.500 (38.504)	Acc@5 71.094 (74.070)
Epoch: [7][30/391]	Time 0.104 (0.104)	Data 0.001 (0.006)	Loss 2.3116 (2.2351)	Acc@1 32.812 (38.105)	Acc@5 77.344 (74.219)
Epoch: [7][40/391]	Time 0.101 (0.104)	Data 0.001 (0.005)	Loss 2.1898 (2.2283)	Acc@1 37.500 (38.281)	Acc@5 69.531 (74.047)
Epoch: [7][50/391]	Time 0.108 (0.104)	Data 0.001 (0.004)	Loss 1.9629 (2.2330)	Acc@1 46.875 (38.143)	Acc@5 75.000 (73.820)
Epoch: [7][60/391]	Time 0.102 (0.104)	Data 0.001 (0.004)	Loss 2.1779 (2.2273)	Acc@1 40.625 (38.153)	Acc@5 76.562 (73.770)
Epoch: [7][70/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.4633 (2.2260)	Acc@1 32.031 (38.094)	Acc@5 67.969 (73.922)
Epoch: [7][80/391]	Time 0.108 (0.104)	Data 0.001 (0.003)	Loss 1.9635 (2.2234)	Acc@1 53.125 (38.320)	Acc@5 75.781 (74.132)
Epoch: [7][90/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.2598 (2.2303)	Acc@1 38.281 (38.470)	Acc@5 75.781 (74.021)
Epoch: [7][100/391]	Time 0.108 (0.104)	Data 0.001 (0.003)	Loss 2.1299 (2.2317)	Acc@1 42.188 (38.382)	Acc@5 78.125 (73.979)
Epoch: [7][110/391]	Time 0.105 (0.104)	Data 0.001 (0.003)	Loss 2.0994 (2.2277)	Acc@1 50.000 (38.640)	Acc@5 78.125 (73.951)
Epoch: [7][120/391]	Time 0.107 (0.104)	Data 0.002 (0.003)	Loss 2.0967 (2.2266)	Acc@1 35.938 (38.688)	Acc@5 75.781 (74.012)
Epoch: [7][130/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2449 (2.2236)	Acc@1 43.750 (38.746)	Acc@5 75.781 (74.076)
Epoch: [7][140/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 1.9690 (2.2239)	Acc@1 47.656 (38.907)	Acc@5 79.688 (73.980)
Epoch: [7][150/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0134 (2.2223)	Acc@1 39.062 (38.949)	Acc@5 79.688 (74.038)
Epoch: [7][160/391]	Time 0.111 (0.104)	Data 0.001 (0.002)	Loss 2.1447 (2.2221)	Acc@1 36.719 (38.965)	Acc@5 76.562 (74.054)
Epoch: [7][170/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.1514 (2.2193)	Acc@1 42.188 (39.017)	Acc@5 77.344 (74.118)
Epoch: [7][180/391]	Time 0.114 (0.104)	Data 0.001 (0.002)	Loss 2.1987 (2.2226)	Acc@1 43.750 (38.972)	Acc@5 75.000 (74.050)
Epoch: [7][190/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4211 (2.2234)	Acc@1 35.156 (38.903)	Acc@5 71.094 (74.010)
Epoch: [7][200/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 1.9080 (2.2203)	Acc@1 46.094 (38.934)	Acc@5 80.469 (74.094)
Epoch: [7][210/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2322 (2.2220)	Acc@1 37.500 (38.937)	Acc@5 75.781 (74.067)
Epoch: [7][220/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2291 (2.2260)	Acc@1 36.719 (38.836)	Acc@5 75.000 (74.042)
Epoch: [7][230/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.0775 (2.2253)	Acc@1 40.625 (38.836)	Acc@5 75.781 (74.060)
Epoch: [7][240/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.2345 (2.2280)	Acc@1 37.500 (38.748)	Acc@5 69.531 (74.002)
Epoch: [7][250/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 1.9973 (2.2266)	Acc@1 42.969 (38.764)	Acc@5 76.562 (74.023)
Epoch: [7][260/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.5305 (2.2294)	Acc@1 29.688 (38.733)	Acc@5 64.844 (73.943)
Epoch: [7][270/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 1.9618 (2.2316)	Acc@1 43.750 (38.673)	Acc@5 78.906 (73.841)
Epoch: [7][280/391]	Time 0.111 (0.104)	Data 0.001 (0.002)	Loss 2.0399 (2.2324)	Acc@1 41.406 (38.651)	Acc@5 80.469 (73.838)
Epoch: [7][290/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.5291 (2.2348)	Acc@1 31.250 (38.630)	Acc@5 64.062 (73.797)
Epoch: [7][300/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.2027 (2.2331)	Acc@1 43.750 (38.673)	Acc@5 74.219 (73.842)
Epoch: [7][310/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2456 (2.2345)	Acc@1 39.062 (38.696)	Acc@5 71.875 (73.752)
Epoch: [7][320/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3110 (2.2368)	Acc@1 38.281 (38.661)	Acc@5 72.656 (73.676)
Epoch: [7][330/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.1662 (2.2376)	Acc@1 35.156 (38.642)	Acc@5 75.000 (73.671)
Epoch: [7][340/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2608 (2.2367)	Acc@1 43.750 (38.662)	Acc@5 76.562 (73.680)
Epoch: [7][350/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1516 (2.2371)	Acc@1 39.062 (38.677)	Acc@5 77.344 (73.676)
Epoch: [7][360/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.5504 (2.2368)	Acc@1 32.031 (38.703)	Acc@5 62.500 (73.686)
Epoch: [7][370/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2017 (2.2352)	Acc@1 37.500 (38.763)	Acc@5 74.219 (73.694)
Epoch: [7][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2577 (2.2352)	Acc@1 42.969 (38.747)	Acc@5 73.438 (73.720)
Epoch: [7][390/391]	Time 0.085 (0.104)	Data 0.001 (0.002)	Loss 2.2279 (2.2354)	Acc@1 46.250 (38.750)	Acc@5 76.250 (73.720)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [8][0/391]	Time 0.115 (0.115)	Data 0.166 (0.166)	Loss 2.2544 (2.2544)	Acc@1 36.719 (36.719)	Acc@5 72.656 (72.656)
Epoch: [8][10/391]	Time 0.104 (0.105)	Data 0.001 (0.016)	Loss 2.3473 (2.2144)	Acc@1 33.594 (38.352)	Acc@5 73.438 (73.224)
Epoch: [8][20/391]	Time 0.100 (0.104)	Data 0.001 (0.009)	Loss 2.1665 (2.2092)	Acc@1 45.312 (39.993)	Acc@5 73.438 (74.256)
Epoch: [8][30/391]	Time 0.102 (0.104)	Data 0.001 (0.006)	Loss 2.2065 (2.2070)	Acc@1 35.938 (40.297)	Acc@5 71.094 (74.420)
Epoch: [8][40/391]	Time 0.105 (0.103)	Data 0.001 (0.005)	Loss 2.3239 (2.2096)	Acc@1 40.625 (40.168)	Acc@5 69.531 (74.162)
Epoch: [8][50/391]	Time 0.110 (0.103)	Data 0.001 (0.004)	Loss 2.3819 (2.2097)	Acc@1 42.188 (40.242)	Acc@5 72.656 (74.249)
Epoch: [8][60/391]	Time 0.100 (0.103)	Data 0.001 (0.004)	Loss 2.0749 (2.2107)	Acc@1 44.531 (39.818)	Acc@5 78.906 (74.206)
Epoch: [8][70/391]	Time 0.108 (0.103)	Data 0.001 (0.003)	Loss 2.1128 (2.2053)	Acc@1 39.844 (39.723)	Acc@5 76.562 (74.450)
Epoch: [8][80/391]	Time 0.103 (0.103)	Data 0.001 (0.003)	Loss 2.3657 (2.2012)	Acc@1 39.062 (39.950)	Acc@5 69.531 (74.576)
Epoch: [8][90/391]	Time 0.100 (0.103)	Data 0.001 (0.003)	Loss 2.0115 (2.1969)	Acc@1 40.625 (39.852)	Acc@5 78.125 (74.622)
Epoch: [8][100/391]	Time 0.102 (0.103)	Data 0.001 (0.003)	Loss 2.2384 (2.2013)	Acc@1 39.844 (39.952)	Acc@5 74.219 (74.420)
Epoch: [8][110/391]	Time 0.102 (0.103)	Data 0.001 (0.003)	Loss 2.2295 (2.2079)	Acc@1 34.375 (39.724)	Acc@5 72.656 (74.282)
Epoch: [8][120/391]	Time 0.099 (0.103)	Data 0.001 (0.003)	Loss 2.1692 (2.2042)	Acc@1 39.844 (39.766)	Acc@5 78.125 (74.277)
Epoch: [8][130/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.1394 (2.2030)	Acc@1 39.844 (39.719)	Acc@5 72.656 (74.350)
Epoch: [8][140/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.5425 (2.2080)	Acc@1 33.594 (39.572)	Acc@5 67.969 (74.180)
Epoch: [8][150/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.2488 (2.2130)	Acc@1 44.531 (39.466)	Acc@5 72.656 (74.074)
Epoch: [8][160/391]	Time 0.099 (0.103)	Data 0.001 (0.002)	Loss 2.1644 (2.2111)	Acc@1 38.281 (39.485)	Acc@5 76.562 (74.136)
Epoch: [8][170/391]	Time 0.105 (0.103)	Data 0.001 (0.002)	Loss 2.3860 (2.2191)	Acc@1 41.406 (39.369)	Acc@5 69.531 (73.954)
Epoch: [8][180/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.2983 (2.2186)	Acc@1 32.031 (39.416)	Acc@5 77.344 (74.007)
Epoch: [8][190/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.2462 (2.2201)	Acc@1 35.156 (39.308)	Acc@5 76.562 (73.998)
Epoch: [8][200/391]	Time 0.099 (0.103)	Data 0.001 (0.002)	Loss 2.1163 (2.2233)	Acc@1 43.750 (39.125)	Acc@5 75.000 (73.935)
Epoch: [8][210/391]	Time 0.109 (0.103)	Data 0.001 (0.002)	Loss 2.3559 (2.2193)	Acc@1 35.156 (39.214)	Acc@5 67.969 (74.067)
Epoch: [8][220/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.2665 (2.2189)	Acc@1 42.188 (39.218)	Acc@5 76.562 (74.063)
Epoch: [8][230/391]	Time 0.111 (0.103)	Data 0.001 (0.002)	Loss 2.1870 (2.2192)	Acc@1 42.188 (39.245)	Acc@5 71.094 (74.036)
Epoch: [8][240/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.1627 (2.2198)	Acc@1 39.062 (39.247)	Acc@5 75.000 (73.995)
Epoch: [8][250/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.5348 (2.2193)	Acc@1 26.562 (39.290)	Acc@5 72.656 (74.032)
Epoch: [8][260/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.2440 (2.2174)	Acc@1 39.062 (39.365)	Acc@5 73.438 (74.129)
Epoch: [8][270/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.1152 (2.2206)	Acc@1 36.719 (39.308)	Acc@5 71.094 (74.072)
Epoch: [8][280/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.1641 (2.2227)	Acc@1 39.062 (39.227)	Acc@5 75.781 (74.002)
Epoch: [8][290/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.1751 (2.2240)	Acc@1 39.062 (39.253)	Acc@5 71.875 (73.956)
Epoch: [8][300/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.2036 (2.2256)	Acc@1 40.625 (39.226)	Acc@5 74.219 (73.928)
Epoch: [8][310/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1301 (2.2275)	Acc@1 38.281 (39.191)	Acc@5 76.562 (73.870)
Epoch: [8][320/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.6359 (2.2294)	Acc@1 27.344 (39.150)	Acc@5 63.281 (73.844)
Epoch: [8][330/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2103 (2.2278)	Acc@1 44.531 (39.197)	Acc@5 72.656 (73.853)
Epoch: [8][340/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3126 (2.2280)	Acc@1 39.844 (39.198)	Acc@5 70.312 (73.836)
Epoch: [8][350/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1909 (2.2303)	Acc@1 40.625 (39.174)	Acc@5 75.781 (73.805)
Epoch: [8][360/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.1126 (2.2300)	Acc@1 35.938 (39.175)	Acc@5 82.812 (73.834)
Epoch: [8][370/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2998 (2.2313)	Acc@1 34.375 (39.134)	Acc@5 77.344 (73.854)
Epoch: [8][380/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0612 (2.2304)	Acc@1 42.188 (39.120)	Acc@5 76.562 (73.893)
Epoch: [8][390/391]	Time 0.085 (0.104)	Data 0.001 (0.002)	Loss 2.1012 (2.2325)	Acc@1 42.500 (39.062)	Acc@5 77.500 (73.824)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [9][0/391]	Time 0.113 (0.113)	Data 0.167 (0.167)	Loss 2.1457 (2.1457)	Acc@1 44.531 (44.531)	Acc@5 73.438 (73.438)
Epoch: [9][10/391]	Time 0.114 (0.106)	Data 0.001 (0.016)	Loss 2.2793 (2.2453)	Acc@1 35.938 (38.565)	Acc@5 73.438 (73.366)
Epoch: [9][20/391]	Time 0.101 (0.104)	Data 0.001 (0.009)	Loss 2.6271 (2.2476)	Acc@1 27.344 (39.211)	Acc@5 66.406 (72.805)
Epoch: [9][30/391]	Time 0.109 (0.104)	Data 0.001 (0.006)	Loss 2.1548 (2.2513)	Acc@1 44.531 (38.684)	Acc@5 71.875 (73.034)
Epoch: [9][40/391]	Time 0.101 (0.104)	Data 0.001 (0.005)	Loss 1.9102 (2.2227)	Acc@1 46.875 (38.720)	Acc@5 76.562 (73.552)
Epoch: [9][50/391]	Time 0.107 (0.104)	Data 0.001 (0.004)	Loss 2.1685 (2.2216)	Acc@1 42.188 (38.879)	Acc@5 74.219 (73.759)
Epoch: [9][60/391]	Time 0.103 (0.104)	Data 0.001 (0.004)	Loss 2.2079 (2.2299)	Acc@1 37.500 (38.730)	Acc@5 78.906 (73.719)
Epoch: [9][70/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.2646 (2.2377)	Acc@1 46.094 (38.490)	Acc@5 71.875 (73.658)
Epoch: [9][80/391]	Time 0.103 (0.104)	Data 0.001 (0.003)	Loss 2.1598 (2.2335)	Acc@1 37.500 (38.792)	Acc@5 75.000 (73.679)
Epoch: [9][90/391]	Time 0.110 (0.104)	Data 0.001 (0.003)	Loss 2.2811 (2.2316)	Acc@1 39.844 (38.711)	Acc@5 70.312 (73.644)
Epoch: [9][100/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.1491 (2.2175)	Acc@1 38.281 (38.946)	Acc@5 77.344 (74.049)
Epoch: [9][110/391]	Time 0.108 (0.104)	Data 0.001 (0.003)	Loss 2.0911 (2.2138)	Acc@1 42.188 (38.908)	Acc@5 82.812 (74.177)
Epoch: [9][120/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1696 (2.2113)	Acc@1 40.625 (39.037)	Acc@5 74.219 (74.257)
Epoch: [9][130/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4105 (2.2156)	Acc@1 40.625 (39.104)	Acc@5 71.094 (74.213)
Epoch: [9][140/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2979 (2.2191)	Acc@1 42.188 (39.062)	Acc@5 73.438 (74.053)
Epoch: [9][150/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.4737 (2.2260)	Acc@1 32.812 (38.876)	Acc@5 68.750 (73.903)
Epoch: [9][160/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2993 (2.2311)	Acc@1 35.938 (38.830)	Acc@5 74.219 (73.831)
Epoch: [9][170/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1493 (2.2336)	Acc@1 41.406 (38.848)	Acc@5 78.125 (73.830)
Epoch: [9][180/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4010 (2.2349)	Acc@1 35.156 (38.821)	Acc@5 71.094 (73.860)
Epoch: [9][190/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.1549 (2.2330)	Acc@1 40.625 (38.858)	Acc@5 74.219 (73.867)
Epoch: [9][200/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2138 (2.2336)	Acc@1 39.844 (38.837)	Acc@5 73.438 (73.861)
Epoch: [9][210/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1681 (2.2321)	Acc@1 42.188 (38.918)	Acc@5 72.656 (73.930)
Epoch: [9][220/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1091 (2.2300)	Acc@1 42.188 (38.960)	Acc@5 78.906 (73.947)
Epoch: [9][230/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0503 (2.2296)	Acc@1 47.656 (39.032)	Acc@5 76.562 (73.948)
Epoch: [9][240/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2752 (2.2290)	Acc@1 41.406 (39.072)	Acc@5 67.969 (73.976)
Epoch: [9][250/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2451 (2.2322)	Acc@1 42.969 (39.122)	Acc@5 71.094 (73.864)
Epoch: [9][260/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2025 (2.2332)	Acc@1 42.188 (39.074)	Acc@5 71.875 (73.824)
Epoch: [9][270/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2521 (2.2327)	Acc@1 41.406 (39.100)	Acc@5 72.656 (73.830)
Epoch: [9][280/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.4290 (2.2347)	Acc@1 28.906 (39.018)	Acc@5 65.625 (73.793)
Epoch: [9][290/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2221 (2.2366)	Acc@1 42.188 (38.963)	Acc@5 77.344 (73.736)
Epoch: [9][300/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3782 (2.2379)	Acc@1 35.938 (38.920)	Acc@5 65.625 (73.650)
Epoch: [9][310/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2498 (2.2391)	Acc@1 38.281 (38.841)	Acc@5 76.562 (73.649)
Epoch: [9][320/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1495 (2.2413)	Acc@1 43.750 (38.746)	Acc@5 72.656 (73.584)
Epoch: [9][330/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1288 (2.2393)	Acc@1 39.062 (38.772)	Acc@5 76.562 (73.622)
Epoch: [9][340/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.2988 (2.2402)	Acc@1 39.844 (38.774)	Acc@5 71.875 (73.651)
Epoch: [9][350/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.4730 (2.2405)	Acc@1 35.938 (38.766)	Acc@5 67.188 (73.667)
Epoch: [9][360/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3569 (2.2390)	Acc@1 33.594 (38.788)	Acc@5 73.438 (73.673)
Epoch: [9][370/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.1735 (2.2392)	Acc@1 39.062 (38.763)	Acc@5 75.000 (73.669)
Epoch: [9][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1545 (2.2410)	Acc@1 38.281 (38.689)	Acc@5 72.656 (73.593)
Epoch: [9][390/391]	Time 0.089 (0.104)	Data 0.001 (0.002)	Loss 2.3309 (2.2411)	Acc@1 33.750 (38.698)	Acc@5 70.000 (73.562)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [10][0/391]	Time 0.112 (0.112)	Data 0.168 (0.168)	Loss 2.1007 (2.1007)	Acc@1 46.094 (46.094)	Acc@5 74.219 (74.219)
Epoch: [10][10/391]	Time 0.111 (0.106)	Data 0.001 (0.016)	Loss 2.0983 (2.1946)	Acc@1 39.062 (39.702)	Acc@5 78.125 (74.503)
Epoch: [10][20/391]	Time 0.102 (0.106)	Data 0.001 (0.009)	Loss 2.3996 (2.1994)	Acc@1 35.938 (39.918)	Acc@5 67.188 (73.549)
Epoch: [10][30/391]	Time 0.109 (0.105)	Data 0.001 (0.006)	Loss 2.3175 (2.1789)	Acc@1 36.719 (39.844)	Acc@5 75.000 (74.471)
Epoch: [10][40/391]	Time 0.104 (0.105)	Data 0.001 (0.005)	Loss 2.3024 (2.1888)	Acc@1 36.719 (39.520)	Acc@5 73.438 (74.295)
Epoch: [10][50/391]	Time 0.110 (0.105)	Data 0.001 (0.004)	Loss 2.4682 (2.2036)	Acc@1 29.688 (38.925)	Acc@5 67.188 (74.066)
Epoch: [10][60/391]	Time 0.103 (0.105)	Data 0.001 (0.004)	Loss 2.1922 (2.2035)	Acc@1 38.281 (38.883)	Acc@5 75.781 (74.270)
Epoch: [10][70/391]	Time 0.107 (0.105)	Data 0.001 (0.003)	Loss 2.0233 (2.2083)	Acc@1 42.969 (38.831)	Acc@5 75.781 (74.120)
Epoch: [10][80/391]	Time 0.109 (0.105)	Data 0.001 (0.003)	Loss 2.3470 (2.2113)	Acc@1 41.406 (38.908)	Acc@5 71.875 (74.103)
Epoch: [10][90/391]	Time 0.105 (0.105)	Data 0.001 (0.003)	Loss 2.4795 (2.2204)	Acc@1 33.594 (38.745)	Acc@5 67.188 (73.944)
Epoch: [10][100/391]	Time 0.111 (0.105)	Data 0.001 (0.003)	Loss 2.4572 (2.2222)	Acc@1 35.938 (38.838)	Acc@5 66.406 (73.840)
Epoch: [10][110/391]	Time 0.100 (0.105)	Data 0.001 (0.003)	Loss 2.3272 (2.2282)	Acc@1 32.812 (38.682)	Acc@5 71.094 (73.599)
Epoch: [10][120/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.2010 (2.2284)	Acc@1 38.281 (38.598)	Acc@5 75.781 (73.631)
Epoch: [10][130/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.3126 (2.2291)	Acc@1 37.500 (38.603)	Acc@5 71.094 (73.676)
Epoch: [10][140/391]	Time 0.105 (0.105)	Data 0.001 (0.002)	Loss 2.1066 (2.2267)	Acc@1 50.781 (38.669)	Acc@5 73.438 (73.770)
Epoch: [10][150/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2504 (2.2268)	Acc@1 46.094 (38.747)	Acc@5 73.438 (73.763)
Epoch: [10][160/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2210 (2.2236)	Acc@1 40.625 (38.771)	Acc@5 73.438 (73.826)
Epoch: [10][170/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1787 (2.2208)	Acc@1 39.844 (38.779)	Acc@5 75.000 (73.894)
Epoch: [10][180/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.1658 (2.2194)	Acc@1 42.969 (38.782)	Acc@5 73.438 (73.964)
Epoch: [10][190/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.1416 (2.2165)	Acc@1 40.625 (39.038)	Acc@5 80.469 (74.022)
Epoch: [10][200/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.0694 (2.2143)	Acc@1 47.656 (39.082)	Acc@5 82.031 (74.056)
Epoch: [10][210/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.1626 (2.2154)	Acc@1 37.500 (39.092)	Acc@5 75.000 (74.030)
Epoch: [10][220/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2445 (2.2166)	Acc@1 37.500 (39.070)	Acc@5 73.438 (73.950)
Epoch: [10][230/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 1.9153 (2.2156)	Acc@1 46.875 (39.130)	Acc@5 80.469 (73.952)
Epoch: [10][240/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.1008 (2.2157)	Acc@1 35.156 (39.030)	Acc@5 76.562 (73.963)
Epoch: [10][250/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2275 (2.2173)	Acc@1 36.719 (39.010)	Acc@5 75.000 (73.967)
Epoch: [10][260/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.4158 (2.2204)	Acc@1 39.844 (38.937)	Acc@5 71.875 (73.910)
Epoch: [10][270/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.3614 (2.2190)	Acc@1 34.375 (38.956)	Acc@5 72.656 (73.954)
Epoch: [10][280/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.1861 (2.2225)	Acc@1 41.406 (38.832)	Acc@5 77.344 (73.905)
Epoch: [10][290/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2198 (2.2212)	Acc@1 37.500 (38.853)	Acc@5 73.438 (73.918)
Epoch: [10][300/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.3106 (2.2216)	Acc@1 36.719 (38.870)	Acc@5 71.094 (73.918)
Epoch: [10][310/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1714 (2.2224)	Acc@1 41.406 (38.902)	Acc@5 74.219 (73.890)
Epoch: [10][320/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.3479 (2.2214)	Acc@1 29.688 (38.902)	Acc@5 68.750 (73.917)
Epoch: [10][330/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3331 (2.2214)	Acc@1 39.062 (38.897)	Acc@5 67.969 (73.898)
Epoch: [10][340/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.0454 (2.2201)	Acc@1 42.188 (38.941)	Acc@5 75.000 (73.967)
Epoch: [10][350/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2108 (2.2204)	Acc@1 42.188 (38.982)	Acc@5 75.781 (73.972)
Epoch: [10][360/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1303 (2.2209)	Acc@1 41.406 (39.019)	Acc@5 74.219 (73.933)
Epoch: [10][370/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0424 (2.2201)	Acc@1 46.875 (39.062)	Acc@5 75.000 (73.977)
Epoch: [10][380/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2170 (2.2226)	Acc@1 38.281 (39.067)	Acc@5 71.094 (73.923)
Epoch: [10][390/391]	Time 0.084 (0.104)	Data 0.001 (0.002)	Loss 2.1584 (2.2244)	Acc@1 37.500 (39.038)	Acc@5 75.000 (73.884)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [11][0/391]	Time 0.116 (0.116)	Data 0.159 (0.159)	Loss 1.9845 (1.9845)	Acc@1 43.750 (43.750)	Acc@5 74.219 (74.219)
Epoch: [11][10/391]	Time 0.100 (0.107)	Data 0.001 (0.015)	Loss 2.3681 (2.3154)	Acc@1 37.500 (35.866)	Acc@5 71.875 (70.597)
Epoch: [11][20/391]	Time 0.104 (0.105)	Data 0.001 (0.009)	Loss 2.1587 (2.2534)	Acc@1 42.188 (38.579)	Acc@5 73.438 (73.103)
Epoch: [11][30/391]	Time 0.103 (0.105)	Data 0.001 (0.006)	Loss 2.1155 (2.2494)	Acc@1 39.062 (38.785)	Acc@5 80.469 (73.841)
Epoch: [11][40/391]	Time 0.103 (0.105)	Data 0.001 (0.005)	Loss 2.2042 (2.2455)	Acc@1 41.406 (38.853)	Acc@5 71.094 (73.742)
Epoch: [11][50/391]	Time 0.101 (0.105)	Data 0.001 (0.004)	Loss 2.0553 (2.2278)	Acc@1 39.062 (39.108)	Acc@5 76.562 (74.341)
Epoch: [11][60/391]	Time 0.111 (0.104)	Data 0.001 (0.004)	Loss 2.1438 (2.2287)	Acc@1 39.062 (39.255)	Acc@5 75.781 (74.219)
Epoch: [11][70/391]	Time 0.108 (0.105)	Data 0.001 (0.003)	Loss 2.4631 (2.2185)	Acc@1 35.156 (39.514)	Acc@5 70.312 (74.373)
Epoch: [11][80/391]	Time 0.108 (0.105)	Data 0.001 (0.003)	Loss 2.1863 (2.2134)	Acc@1 32.031 (39.583)	Acc@5 75.781 (74.624)
Epoch: [11][90/391]	Time 0.102 (0.105)	Data 0.001 (0.003)	Loss 2.0777 (2.2056)	Acc@1 38.281 (39.663)	Acc@5 77.344 (74.708)
Epoch: [11][100/391]	Time 0.106 (0.105)	Data 0.001 (0.003)	Loss 2.2172 (2.2020)	Acc@1 37.500 (39.534)	Acc@5 70.312 (74.497)
Epoch: [11][110/391]	Time 0.106 (0.105)	Data 0.001 (0.003)	Loss 2.0962 (2.1988)	Acc@1 35.938 (39.541)	Acc@5 81.250 (74.550)
Epoch: [11][120/391]	Time 0.107 (0.105)	Data 0.001 (0.002)	Loss 2.1313 (2.1950)	Acc@1 39.062 (39.669)	Acc@5 75.781 (74.658)
Epoch: [11][130/391]	Time 0.111 (0.105)	Data 0.001 (0.002)	Loss 2.0391 (2.1988)	Acc@1 43.750 (39.671)	Acc@5 76.562 (74.547)
Epoch: [11][140/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.1729 (2.1965)	Acc@1 42.188 (39.838)	Acc@5 75.000 (74.518)
Epoch: [11][150/391]	Time 0.105 (0.105)	Data 0.001 (0.002)	Loss 2.3635 (2.1968)	Acc@1 35.156 (39.849)	Acc@5 70.312 (74.555)
Epoch: [11][160/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.3221 (2.2015)	Acc@1 35.938 (39.790)	Acc@5 75.000 (74.466)
Epoch: [11][170/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.3332 (2.2007)	Acc@1 36.719 (39.821)	Acc@5 68.750 (74.443)
Epoch: [11][180/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.2867 (2.2067)	Acc@1 37.500 (39.714)	Acc@5 68.750 (74.249)
Epoch: [11][190/391]	Time 0.104 (0.105)	Data 0.001 (0.002)	Loss 2.7708 (2.2119)	Acc@1 32.031 (39.562)	Acc@5 66.406 (74.133)
Epoch: [11][200/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.1131 (2.2110)	Acc@1 40.625 (39.603)	Acc@5 78.125 (74.125)
Epoch: [11][210/391]	Time 0.104 (0.105)	Data 0.001 (0.002)	Loss 2.4051 (2.2161)	Acc@1 38.281 (39.436)	Acc@5 70.312 (74.015)
Epoch: [11][220/391]	Time 0.100 (0.105)	Data 0.001 (0.002)	Loss 2.0078 (2.2130)	Acc@1 42.969 (39.501)	Acc@5 78.125 (74.109)
Epoch: [11][230/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.0902 (2.2112)	Acc@1 45.312 (39.482)	Acc@5 75.781 (74.219)
Epoch: [11][240/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.1617 (2.2129)	Acc@1 40.625 (39.416)	Acc@5 83.594 (74.206)
Epoch: [11][250/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2448 (2.2153)	Acc@1 37.500 (39.380)	Acc@5 72.656 (74.110)
Epoch: [11][260/391]	Time 0.101 (0.104)	Data 0.002 (0.002)	Loss 1.9852 (2.2146)	Acc@1 52.344 (39.404)	Acc@5 79.688 (74.126)
Epoch: [11][270/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2745 (2.2157)	Acc@1 38.281 (39.325)	Acc@5 71.094 (74.083)
Epoch: [11][280/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.5066 (2.2176)	Acc@1 34.375 (39.252)	Acc@5 68.750 (74.052)
Epoch: [11][290/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.3050 (2.2195)	Acc@1 40.625 (39.159)	Acc@5 68.750 (73.996)
Epoch: [11][300/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0866 (2.2200)	Acc@1 40.625 (39.117)	Acc@5 76.562 (73.980)
Epoch: [11][310/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 1.9223 (2.2208)	Acc@1 49.219 (39.083)	Acc@5 80.469 (73.975)
Epoch: [11][320/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1437 (2.2199)	Acc@1 42.969 (39.077)	Acc@5 75.781 (74.007)
Epoch: [11][330/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1672 (2.2213)	Acc@1 35.156 (39.037)	Acc@5 77.344 (74.004)
Epoch: [11][340/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2714 (2.2206)	Acc@1 36.719 (39.044)	Acc@5 71.875 (74.047)
Epoch: [11][350/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.5030 (2.2225)	Acc@1 31.250 (39.034)	Acc@5 66.406 (73.992)
Epoch: [11][360/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2794 (2.2212)	Acc@1 42.188 (39.067)	Acc@5 69.531 (73.981)
Epoch: [11][370/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0247 (2.2217)	Acc@1 42.188 (39.037)	Acc@5 79.688 (73.962)
Epoch: [11][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2766 (2.2223)	Acc@1 38.281 (39.056)	Acc@5 71.094 (73.913)
Epoch: [11][390/391]	Time 0.093 (0.104)	Data 0.001 (0.002)	Loss 2.1729 (2.2238)	Acc@1 38.750 (39.078)	Acc@5 76.250 (73.880)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [12][0/391]	Time 0.114 (0.114)	Data 0.179 (0.179)	Loss 2.2249 (2.2249)	Acc@1 43.750 (43.750)	Acc@5 77.344 (77.344)
Epoch: [12][10/391]	Time 0.104 (0.107)	Data 0.001 (0.017)	Loss 2.2331 (2.2547)	Acc@1 36.719 (38.281)	Acc@5 74.219 (71.165)
Epoch: [12][20/391]	Time 0.110 (0.107)	Data 0.001 (0.010)	Loss 2.0954 (2.2015)	Acc@1 49.219 (39.881)	Acc@5 74.219 (72.842)
Epoch: [12][30/391]	Time 0.109 (0.106)	Data 0.001 (0.007)	Loss 2.3234 (2.2090)	Acc@1 34.375 (38.785)	Acc@5 75.781 (73.286)
Epoch: [12][40/391]	Time 0.108 (0.106)	Data 0.001 (0.005)	Loss 2.2902 (2.2022)	Acc@1 35.156 (38.796)	Acc@5 75.000 (73.761)
Epoch: [12][50/391]	Time 0.101 (0.106)	Data 0.001 (0.005)	Loss 2.1781 (2.2127)	Acc@1 43.750 (38.802)	Acc@5 74.219 (73.790)
Epoch: [12][60/391]	Time 0.102 (0.106)	Data 0.001 (0.004)	Loss 2.0804 (2.2190)	Acc@1 42.969 (39.114)	Acc@5 75.781 (73.668)
Epoch: [12][70/391]	Time 0.102 (0.106)	Data 0.001 (0.004)	Loss 2.1810 (2.2176)	Acc@1 37.500 (39.096)	Acc@5 75.781 (73.812)
Epoch: [12][80/391]	Time 0.106 (0.106)	Data 0.001 (0.003)	Loss 2.2461 (2.2132)	Acc@1 39.062 (39.062)	Acc@5 72.656 (73.939)
Epoch: [12][90/391]	Time 0.107 (0.105)	Data 0.001 (0.003)	Loss 2.2742 (2.2125)	Acc@1 35.156 (39.054)	Acc@5 73.438 (74.004)
Epoch: [12][100/391]	Time 0.111 (0.106)	Data 0.001 (0.003)	Loss 2.3371 (2.2152)	Acc@1 41.406 (39.078)	Acc@5 75.000 (73.987)
Epoch: [12][110/391]	Time 0.105 (0.105)	Data 0.001 (0.003)	Loss 2.2688 (2.2092)	Acc@1 39.062 (39.062)	Acc@5 72.656 (74.184)
Epoch: [12][120/391]	Time 0.107 (0.105)	Data 0.001 (0.003)	Loss 2.1433 (2.2054)	Acc@1 34.375 (39.088)	Acc@5 75.781 (74.251)
Epoch: [12][130/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.1330 (2.2023)	Acc@1 45.312 (39.229)	Acc@5 78.125 (74.404)
Epoch: [12][140/391]	Time 0.106 (0.105)	Data 0.001 (0.002)	Loss 2.3456 (2.2043)	Acc@1 36.719 (39.123)	Acc@5 67.969 (74.302)
Epoch: [12][150/391]	Time 0.100 (0.105)	Data 0.001 (0.002)	Loss 2.1432 (2.2093)	Acc@1 34.375 (39.052)	Acc@5 79.688 (74.245)
Epoch: [12][160/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.0515 (2.2077)	Acc@1 41.406 (39.101)	Acc@5 78.906 (74.253)
Epoch: [12][170/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.2834 (2.2079)	Acc@1 37.500 (39.062)	Acc@5 71.094 (74.251)
Epoch: [12][180/391]	Time 0.102 (0.105)	Data 0.002 (0.002)	Loss 2.1656 (2.2111)	Acc@1 42.969 (38.985)	Acc@5 73.438 (74.210)
Epoch: [12][190/391]	Time 0.104 (0.105)	Data 0.001 (0.002)	Loss 2.2054 (2.2124)	Acc@1 44.531 (39.034)	Acc@5 75.000 (74.116)
Epoch: [12][200/391]	Time 0.104 (0.105)	Data 0.001 (0.002)	Loss 2.2941 (2.2134)	Acc@1 32.812 (38.961)	Acc@5 75.781 (74.223)
Epoch: [12][210/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1359 (2.2138)	Acc@1 39.844 (38.966)	Acc@5 71.875 (74.189)
Epoch: [12][220/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3717 (2.2160)	Acc@1 33.594 (38.956)	Acc@5 69.531 (74.145)
Epoch: [12][230/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2241 (2.2171)	Acc@1 39.062 (38.860)	Acc@5 74.219 (74.134)
Epoch: [12][240/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.3957 (2.2197)	Acc@1 35.156 (38.813)	Acc@5 73.438 (74.109)
Epoch: [12][250/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3777 (2.2218)	Acc@1 30.469 (38.726)	Acc@5 72.656 (74.076)
Epoch: [12][260/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.2112 (2.2235)	Acc@1 40.625 (38.694)	Acc@5 74.219 (74.006)
Epoch: [12][270/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3946 (2.2215)	Acc@1 37.500 (38.771)	Acc@5 70.312 (74.017)
Epoch: [12][280/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.0823 (2.2208)	Acc@1 39.844 (38.765)	Acc@5 78.125 (74.030)
Epoch: [12][290/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0870 (2.2218)	Acc@1 40.625 (38.805)	Acc@5 78.125 (73.993)
Epoch: [12][300/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1699 (2.2243)	Acc@1 43.750 (38.795)	Acc@5 76.562 (73.923)
Epoch: [12][310/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.3470 (2.2221)	Acc@1 38.281 (38.824)	Acc@5 64.844 (73.927)
Epoch: [12][320/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.0460 (2.2227)	Acc@1 46.094 (38.783)	Acc@5 76.562 (73.932)
Epoch: [12][330/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.5086 (2.2251)	Acc@1 30.469 (38.708)	Acc@5 64.062 (73.865)
Epoch: [12][340/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2125 (2.2233)	Acc@1 42.188 (38.758)	Acc@5 72.656 (73.912)
Epoch: [12][350/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.1309 (2.2237)	Acc@1 41.406 (38.758)	Acc@5 73.438 (73.874)
Epoch: [12][360/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0773 (2.2222)	Acc@1 35.156 (38.731)	Acc@5 81.250 (73.942)
Epoch: [12][370/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.0854 (2.2227)	Acc@1 40.625 (38.753)	Acc@5 77.344 (73.968)
Epoch: [12][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2811 (2.2224)	Acc@1 34.375 (38.759)	Acc@5 72.656 (73.997)
Epoch: [12][390/391]	Time 0.086 (0.104)	Data 0.001 (0.002)	Loss 2.1799 (2.2213)	Acc@1 32.500 (38.820)	Acc@5 78.750 (74.004)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [13][0/391]	Time 0.119 (0.119)	Data 0.166 (0.166)	Loss 2.0190 (2.0190)	Acc@1 46.094 (46.094)	Acc@5 78.125 (78.125)
Epoch: [13][10/391]	Time 0.112 (0.108)	Data 0.001 (0.016)	Loss 2.2531 (2.1862)	Acc@1 36.719 (38.991)	Acc@5 72.656 (74.432)
Epoch: [13][20/391]	Time 0.107 (0.107)	Data 0.001 (0.009)	Loss 2.1570 (2.2007)	Acc@1 42.188 (39.807)	Acc@5 67.188 (73.921)
Epoch: [13][30/391]	Time 0.109 (0.106)	Data 0.001 (0.006)	Loss 2.1472 (2.1656)	Acc@1 38.281 (40.272)	Acc@5 82.031 (74.975)
Epoch: [13][40/391]	Time 0.103 (0.105)	Data 0.001 (0.005)	Loss 1.9120 (2.1734)	Acc@1 42.969 (40.091)	Acc@5 82.812 (74.924)
Epoch: [13][50/391]	Time 0.110 (0.105)	Data 0.001 (0.004)	Loss 2.1131 (2.1640)	Acc@1 41.406 (40.150)	Acc@5 75.781 (74.801)
Epoch: [13][60/391]	Time 0.103 (0.105)	Data 0.001 (0.004)	Loss 2.3081 (2.1856)	Acc@1 42.969 (39.677)	Acc@5 71.094 (74.257)
Epoch: [13][70/391]	Time 0.104 (0.105)	Data 0.001 (0.003)	Loss 2.3659 (2.1934)	Acc@1 34.375 (39.470)	Acc@5 67.969 (74.120)
Epoch: [13][80/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.3541 (2.1956)	Acc@1 34.375 (39.390)	Acc@5 71.875 (74.103)
Epoch: [13][90/391]	Time 0.109 (0.104)	Data 0.001 (0.003)	Loss 2.2702 (2.2025)	Acc@1 38.281 (39.414)	Acc@5 74.219 (73.935)
Epoch: [13][100/391]	Time 0.103 (0.104)	Data 0.001 (0.003)	Loss 2.0973 (2.2033)	Acc@1 40.625 (39.449)	Acc@5 72.656 (73.809)
Epoch: [13][110/391]	Time 0.103 (0.104)	Data 0.001 (0.003)	Loss 2.2557 (2.2044)	Acc@1 38.281 (39.457)	Acc@5 72.656 (73.775)
Epoch: [13][120/391]	Time 0.107 (0.104)	Data 0.001 (0.003)	Loss 2.0790 (2.2024)	Acc@1 39.844 (39.450)	Acc@5 80.469 (73.831)
Epoch: [13][130/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2374 (2.2045)	Acc@1 35.938 (39.522)	Acc@5 78.906 (73.927)
Epoch: [13][140/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1116 (2.2036)	Acc@1 39.062 (39.622)	Acc@5 76.562 (73.953)
Epoch: [13][150/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.3618 (2.2039)	Acc@1 39.844 (39.621)	Acc@5 72.656 (73.965)
Epoch: [13][160/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 1.9819 (2.2022)	Acc@1 46.875 (39.557)	Acc@5 80.469 (74.005)
Epoch: [13][170/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0802 (2.1992)	Acc@1 44.531 (39.542)	Acc@5 76.562 (74.095)
Epoch: [13][180/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.5321 (2.2046)	Acc@1 33.594 (39.451)	Acc@5 68.750 (73.981)
Epoch: [13][190/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1586 (2.2016)	Acc@1 43.750 (39.594)	Acc@5 75.781 (74.084)
Epoch: [13][200/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.1573 (2.2055)	Acc@1 35.156 (39.490)	Acc@5 75.000 (74.056)
Epoch: [13][210/391]	Time 0.103 (0.103)	Data 0.001 (0.002)	Loss 2.1102 (2.2058)	Acc@1 38.281 (39.511)	Acc@5 79.688 (74.067)
Epoch: [13][220/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1402 (2.2104)	Acc@1 46.875 (39.434)	Acc@5 76.562 (74.003)
Epoch: [13][230/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.0858 (2.2116)	Acc@1 46.094 (39.465)	Acc@5 75.000 (73.985)
Epoch: [13][240/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 2.1173 (2.2139)	Acc@1 42.188 (39.419)	Acc@5 75.781 (73.933)
Epoch: [13][250/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.2406 (2.2166)	Acc@1 41.406 (39.315)	Acc@5 74.219 (73.883)
Epoch: [13][260/391]	Time 0.107 (0.103)	Data 0.001 (0.002)	Loss 2.2976 (2.2173)	Acc@1 41.406 (39.332)	Acc@5 72.656 (73.889)
Epoch: [13][270/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.3375 (2.2169)	Acc@1 35.156 (39.331)	Acc@5 68.750 (73.853)
Epoch: [13][280/391]	Time 0.102 (0.103)	Data 0.001 (0.002)	Loss 2.3153 (2.2158)	Acc@1 39.062 (39.366)	Acc@5 66.406 (73.888)
Epoch: [13][290/391]	Time 0.106 (0.103)	Data 0.001 (0.002)	Loss 1.9518 (2.2130)	Acc@1 46.094 (39.468)	Acc@5 79.688 (73.926)
Epoch: [13][300/391]	Time 0.104 (0.103)	Data 0.001 (0.002)	Loss 2.3747 (2.2141)	Acc@1 40.625 (39.465)	Acc@5 67.969 (73.910)
Epoch: [13][310/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0011 (2.2144)	Acc@1 38.281 (39.437)	Acc@5 81.250 (73.882)
Epoch: [13][320/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3447 (2.2176)	Acc@1 38.281 (39.320)	Acc@5 70.312 (73.827)
Epoch: [13][330/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2013 (2.2187)	Acc@1 39.062 (39.301)	Acc@5 74.219 (73.810)
Epoch: [13][340/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.1659 (2.2192)	Acc@1 39.844 (39.296)	Acc@5 77.344 (73.795)
Epoch: [13][350/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.0383 (2.2215)	Acc@1 39.844 (39.229)	Acc@5 77.344 (73.789)
Epoch: [13][360/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4641 (2.2230)	Acc@1 30.469 (39.188)	Acc@5 70.312 (73.756)
Epoch: [13][370/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.3250 (2.2238)	Acc@1 37.500 (39.155)	Acc@5 67.969 (73.690)
Epoch: [13][380/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3433 (2.2247)	Acc@1 39.844 (39.151)	Acc@5 71.094 (73.700)
Epoch: [13][390/391]	Time 0.086 (0.104)	Data 0.001 (0.002)	Loss 2.4404 (2.2257)	Acc@1 37.500 (39.110)	Acc@5 66.250 (73.684)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [14][0/391]	Time 0.121 (0.121)	Data 0.172 (0.172)	Loss 2.4748 (2.4748)	Acc@1 34.375 (34.375)	Acc@5 68.750 (68.750)
Epoch: [14][10/391]	Time 0.103 (0.106)	Data 0.001 (0.017)	Loss 2.2675 (2.2047)	Acc@1 32.812 (40.057)	Acc@5 77.344 (74.645)
Epoch: [14][20/391]	Time 0.102 (0.105)	Data 0.001 (0.009)	Loss 2.1877 (2.2067)	Acc@1 38.281 (39.695)	Acc@5 79.688 (74.591)
Epoch: [14][30/391]	Time 0.108 (0.105)	Data 0.001 (0.007)	Loss 2.3712 (2.2150)	Acc@1 42.969 (39.441)	Acc@5 70.312 (74.345)
Epoch: [14][40/391]	Time 0.107 (0.105)	Data 0.001 (0.005)	Loss 2.2336 (2.2233)	Acc@1 43.750 (39.444)	Acc@5 73.438 (73.990)
Epoch: [14][50/391]	Time 0.105 (0.105)	Data 0.001 (0.005)	Loss 2.3382 (2.2156)	Acc@1 35.938 (39.737)	Acc@5 71.875 (74.295)
Epoch: [14][60/391]	Time 0.105 (0.105)	Data 0.001 (0.004)	Loss 2.1670 (2.2081)	Acc@1 43.750 (39.908)	Acc@5 75.781 (74.372)
Epoch: [14][70/391]	Time 0.103 (0.105)	Data 0.001 (0.004)	Loss 2.6240 (2.2141)	Acc@1 33.594 (39.855)	Acc@5 66.406 (74.142)
Epoch: [14][80/391]	Time 0.105 (0.104)	Data 0.001 (0.003)	Loss 2.4335 (2.2189)	Acc@1 33.594 (39.468)	Acc@5 71.875 (74.045)
Epoch: [14][90/391]	Time 0.100 (0.104)	Data 0.001 (0.003)	Loss 2.0153 (2.2161)	Acc@1 42.969 (39.414)	Acc@5 80.469 (74.176)
Epoch: [14][100/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.1039 (2.2100)	Acc@1 39.844 (39.565)	Acc@5 77.344 (74.203)
Epoch: [14][110/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 1.9626 (2.2035)	Acc@1 47.656 (39.745)	Acc@5 80.469 (74.338)
Epoch: [14][120/391]	Time 0.111 (0.104)	Data 0.001 (0.003)	Loss 2.1361 (2.2033)	Acc@1 42.969 (39.928)	Acc@5 74.219 (74.251)
Epoch: [14][130/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 1.9779 (2.2062)	Acc@1 44.531 (39.975)	Acc@5 75.781 (74.195)
Epoch: [14][140/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1974 (2.2065)	Acc@1 34.375 (39.905)	Acc@5 76.562 (74.280)
Epoch: [14][150/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.3685 (2.2081)	Acc@1 35.938 (39.916)	Acc@5 70.312 (74.208)
Epoch: [14][160/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0722 (2.2157)	Acc@1 43.750 (39.747)	Acc@5 76.562 (74.088)
Epoch: [14][170/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.0950 (2.2162)	Acc@1 45.312 (39.775)	Acc@5 71.875 (74.063)
Epoch: [14][180/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2058 (2.2157)	Acc@1 39.062 (39.744)	Acc@5 72.656 (74.055)
Epoch: [14][190/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.0928 (2.2126)	Acc@1 46.094 (39.705)	Acc@5 76.562 (74.170)
Epoch: [14][200/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1722 (2.2108)	Acc@1 34.375 (39.735)	Acc@5 75.781 (74.180)
Epoch: [14][210/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2140 (2.2115)	Acc@1 36.719 (39.736)	Acc@5 76.562 (74.130)
Epoch: [14][220/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0722 (2.2125)	Acc@1 45.312 (39.635)	Acc@5 76.562 (74.127)
Epoch: [14][230/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.1239 (2.2126)	Acc@1 35.938 (39.624)	Acc@5 75.781 (74.121)
Epoch: [14][240/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.2770 (2.2144)	Acc@1 34.375 (39.539)	Acc@5 76.562 (74.073)
Epoch: [14][250/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.1231 (2.2122)	Acc@1 39.844 (39.595)	Acc@5 78.125 (74.085)
Epoch: [14][260/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1578 (2.2117)	Acc@1 41.406 (39.685)	Acc@5 75.781 (74.087)
Epoch: [14][270/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.3918 (2.2128)	Acc@1 33.594 (39.717)	Acc@5 73.438 (74.060)
Epoch: [14][280/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.0269 (2.2131)	Acc@1 38.281 (39.638)	Acc@5 80.469 (74.096)
Epoch: [14][290/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0815 (2.2124)	Acc@1 42.188 (39.696)	Acc@5 75.781 (74.079)
Epoch: [14][300/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0922 (2.2117)	Acc@1 39.844 (39.717)	Acc@5 76.562 (74.105)
Epoch: [14][310/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2381 (2.2127)	Acc@1 40.625 (39.680)	Acc@5 70.312 (74.068)
Epoch: [14][320/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.1501 (2.2141)	Acc@1 39.844 (39.659)	Acc@5 75.000 (74.019)
Epoch: [14][330/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2304 (2.2148)	Acc@1 36.719 (39.643)	Acc@5 75.781 (73.983)
Epoch: [14][340/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3612 (2.2158)	Acc@1 41.406 (39.619)	Acc@5 75.000 (73.985)
Epoch: [14][350/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0731 (2.2176)	Acc@1 44.531 (39.588)	Acc@5 74.219 (73.987)
Epoch: [14][360/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2198 (2.2178)	Acc@1 38.281 (39.621)	Acc@5 73.438 (74.000)
Epoch: [14][370/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.1723 (2.2165)	Acc@1 35.938 (39.583)	Acc@5 75.000 (74.029)
Epoch: [14][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.4397 (2.2177)	Acc@1 32.031 (39.538)	Acc@5 71.094 (74.003)
Epoch: [14][390/391]	Time 0.086 (0.104)	Data 0.001 (0.002)	Loss 2.2274 (2.2193)	Acc@1 36.250 (39.494)	Acc@5 75.000 (73.976)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [15][0/391]	Time 0.112 (0.112)	Data 0.165 (0.165)	Loss 2.1295 (2.1295)	Acc@1 39.844 (39.844)	Acc@5 77.344 (77.344)
Epoch: [15][10/391]	Time 0.103 (0.106)	Data 0.001 (0.016)	Loss 2.1751 (2.2564)	Acc@1 47.656 (37.713)	Acc@5 74.219 (73.509)
Epoch: [15][20/391]	Time 0.110 (0.105)	Data 0.001 (0.009)	Loss 2.3937 (2.2303)	Acc@1 38.281 (38.728)	Acc@5 75.000 (74.293)
Epoch: [15][30/391]	Time 0.102 (0.104)	Data 0.001 (0.006)	Loss 2.1479 (2.2117)	Acc@1 40.625 (40.096)	Acc@5 75.781 (74.219)
Epoch: [15][40/391]	Time 0.108 (0.104)	Data 0.001 (0.005)	Loss 2.4467 (2.2112)	Acc@1 28.906 (40.111)	Acc@5 66.406 (73.742)
Epoch: [15][50/391]	Time 0.102 (0.104)	Data 0.001 (0.004)	Loss 1.9791 (2.2051)	Acc@1 46.875 (39.982)	Acc@5 78.125 (73.744)
Epoch: [15][60/391]	Time 0.111 (0.104)	Data 0.001 (0.004)	Loss 2.0607 (2.2179)	Acc@1 45.312 (39.588)	Acc@5 72.656 (73.540)
Epoch: [15][70/391]	Time 0.108 (0.104)	Data 0.001 (0.003)	Loss 2.2103 (2.2163)	Acc@1 41.406 (39.624)	Acc@5 72.656 (73.812)
Epoch: [15][80/391]	Time 0.110 (0.104)	Data 0.001 (0.003)	Loss 2.2748 (2.2089)	Acc@1 35.938 (39.641)	Acc@5 74.219 (74.113)
Epoch: [15][90/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.4402 (2.2110)	Acc@1 41.406 (39.646)	Acc@5 70.312 (74.107)
Epoch: [15][100/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.1998 (2.2195)	Acc@1 39.844 (39.511)	Acc@5 74.219 (73.987)
Epoch: [15][110/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.6045 (2.2303)	Acc@1 32.812 (39.217)	Acc@5 64.062 (73.796)
Epoch: [15][120/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.3333 (2.2318)	Acc@1 35.156 (39.121)	Acc@5 67.969 (73.709)
Epoch: [15][130/391]	Time 0.105 (0.105)	Data 0.001 (0.002)	Loss 2.3068 (2.2248)	Acc@1 39.844 (39.289)	Acc@5 71.094 (73.831)
Epoch: [15][140/391]	Time 0.105 (0.105)	Data 0.001 (0.002)	Loss 2.2202 (2.2291)	Acc@1 36.719 (39.112)	Acc@5 71.094 (73.665)
Epoch: [15][150/391]	Time 0.103 (0.105)	Data 0.001 (0.002)	Loss 2.1742 (2.2349)	Acc@1 41.406 (39.000)	Acc@5 79.688 (73.577)
Epoch: [15][160/391]	Time 0.100 (0.105)	Data 0.001 (0.002)	Loss 2.3985 (2.2310)	Acc@1 31.250 (39.058)	Acc@5 67.969 (73.622)
Epoch: [15][170/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.4301 (2.2286)	Acc@1 33.594 (39.072)	Acc@5 66.406 (73.634)
Epoch: [15][180/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1526 (2.2231)	Acc@1 44.531 (39.188)	Acc@5 74.219 (73.735)
Epoch: [15][190/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.0088 (2.2276)	Acc@1 44.531 (39.038)	Acc@5 76.562 (73.662)
Epoch: [15][200/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1208 (2.2265)	Acc@1 40.625 (39.121)	Acc@5 77.344 (73.690)
Epoch: [15][210/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2097 (2.2230)	Acc@1 41.406 (39.240)	Acc@5 68.750 (73.752)
Epoch: [15][220/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2203 (2.2228)	Acc@1 39.062 (39.260)	Acc@5 70.312 (73.727)
Epoch: [15][230/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3615 (2.2236)	Acc@1 34.375 (39.255)	Acc@5 69.531 (73.759)
Epoch: [15][240/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2801 (2.2232)	Acc@1 39.844 (39.267)	Acc@5 74.219 (73.765)
Epoch: [15][250/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0904 (2.2224)	Acc@1 39.844 (39.299)	Acc@5 75.000 (73.817)
Epoch: [15][260/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.3088 (2.2219)	Acc@1 29.688 (39.245)	Acc@5 78.125 (73.863)
Epoch: [15][270/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3764 (2.2253)	Acc@1 36.719 (39.204)	Acc@5 69.531 (73.798)
Epoch: [15][280/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.1620 (2.2277)	Acc@1 44.531 (39.168)	Acc@5 75.781 (73.760)
Epoch: [15][290/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3673 (2.2302)	Acc@1 32.031 (39.114)	Acc@5 70.312 (73.655)
Epoch: [15][300/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1293 (2.2309)	Acc@1 45.312 (39.133)	Acc@5 75.781 (73.645)
Epoch: [15][310/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3262 (2.2317)	Acc@1 37.500 (39.135)	Acc@5 68.750 (73.654)
Epoch: [15][320/391]	Time 0.112 (0.104)	Data 0.001 (0.002)	Loss 2.3558 (2.2310)	Acc@1 32.812 (39.092)	Acc@5 68.750 (73.669)
Epoch: [15][330/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 1.9598 (2.2285)	Acc@1 38.281 (39.114)	Acc@5 83.594 (73.730)
Epoch: [15][340/391]	Time 0.113 (0.104)	Data 0.001 (0.002)	Loss 2.2480 (2.2286)	Acc@1 41.406 (39.122)	Acc@5 75.000 (73.719)
Epoch: [15][350/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.0137 (2.2274)	Acc@1 42.969 (39.096)	Acc@5 79.688 (73.762)
Epoch: [15][360/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3447 (2.2290)	Acc@1 32.812 (39.080)	Acc@5 68.750 (73.706)
Epoch: [15][370/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3368 (2.2290)	Acc@1 29.688 (39.033)	Acc@5 68.750 (73.673)
Epoch: [15][380/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 1.9455 (2.2279)	Acc@1 46.094 (39.060)	Acc@5 82.031 (73.716)
Epoch: [15][390/391]	Time 0.086 (0.104)	Data 0.001 (0.002)	Loss 1.9440 (2.2272)	Acc@1 43.750 (39.038)	Acc@5 82.500 (73.714)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [16][0/391]	Time 0.115 (0.115)	Data 0.165 (0.165)	Loss 2.1860 (2.1860)	Acc@1 40.625 (40.625)	Acc@5 72.656 (72.656)
Epoch: [16][10/391]	Time 0.102 (0.107)	Data 0.001 (0.016)	Loss 1.9859 (2.1601)	Acc@1 41.406 (39.347)	Acc@5 76.562 (75.852)
Epoch: [16][20/391]	Time 0.102 (0.105)	Data 0.001 (0.009)	Loss 2.6239 (2.1933)	Acc@1 28.906 (38.616)	Acc@5 65.625 (74.702)
Epoch: [16][30/391]	Time 0.102 (0.105)	Data 0.001 (0.006)	Loss 2.2496 (2.2096)	Acc@1 42.969 (38.911)	Acc@5 70.312 (74.168)
Epoch: [16][40/391]	Time 0.105 (0.105)	Data 0.001 (0.005)	Loss 2.1642 (2.2083)	Acc@1 39.062 (38.796)	Acc@5 76.562 (74.524)
Epoch: [16][50/391]	Time 0.100 (0.104)	Data 0.001 (0.004)	Loss 2.5188 (2.2085)	Acc@1 34.375 (38.986)	Acc@5 69.531 (74.602)
Epoch: [16][60/391]	Time 0.106 (0.104)	Data 0.001 (0.004)	Loss 2.1177 (2.1935)	Acc@1 40.625 (39.588)	Acc@5 73.438 (74.731)
Epoch: [16][70/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 1.9700 (2.1859)	Acc@1 45.312 (39.987)	Acc@5 79.688 (74.967)
Epoch: [16][80/391]	Time 0.099 (0.104)	Data 0.001 (0.003)	Loss 2.1233 (2.1686)	Acc@1 43.750 (40.374)	Acc@5 77.344 (75.241)
Epoch: [16][90/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 2.3230 (2.1698)	Acc@1 37.500 (40.513)	Acc@5 67.188 (75.052)
Epoch: [16][100/391]	Time 0.106 (0.104)	Data 0.001 (0.003)	Loss 2.1790 (2.1717)	Acc@1 35.156 (40.424)	Acc@5 75.000 (75.054)
Epoch: [16][110/391]	Time 0.101 (0.104)	Data 0.001 (0.003)	Loss 2.1615 (2.1766)	Acc@1 42.188 (40.484)	Acc@5 73.438 (74.916)
Epoch: [16][120/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2749 (2.1764)	Acc@1 39.062 (40.360)	Acc@5 71.875 (74.839)
Epoch: [16][130/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1675 (2.1734)	Acc@1 42.188 (40.386)	Acc@5 78.125 (75.018)
Epoch: [16][140/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1292 (2.1772)	Acc@1 40.625 (40.254)	Acc@5 78.906 (75.006)
Epoch: [16][150/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.6066 (2.1832)	Acc@1 32.812 (40.154)	Acc@5 64.062 (74.876)
Epoch: [16][160/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1772 (2.1886)	Acc@1 40.625 (40.140)	Acc@5 72.656 (74.791)
Epoch: [16][170/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.5130 (2.1930)	Acc@1 28.906 (39.940)	Acc@5 67.188 (74.744)
Epoch: [16][180/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1885 (2.1943)	Acc@1 38.281 (39.887)	Acc@5 75.000 (74.637)
Epoch: [16][190/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2507 (2.1946)	Acc@1 37.500 (39.848)	Acc@5 75.000 (74.640)
Epoch: [16][200/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1180 (2.1923)	Acc@1 39.062 (39.894)	Acc@5 81.250 (74.658)
Epoch: [16][210/391]	Time 0.103 (0.104)	Data 0.002 (0.002)	Loss 2.3123 (2.1911)	Acc@1 42.969 (39.884)	Acc@5 67.969 (74.696)
Epoch: [16][220/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0438 (2.1941)	Acc@1 45.312 (39.854)	Acc@5 75.000 (74.608)
Epoch: [16][230/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2918 (2.1937)	Acc@1 42.969 (39.840)	Acc@5 72.656 (74.594)
Epoch: [16][240/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1610 (2.1942)	Acc@1 39.844 (39.828)	Acc@5 74.219 (74.540)
Epoch: [16][250/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2153 (2.1970)	Acc@1 35.938 (39.707)	Acc@5 76.562 (74.521)
Epoch: [16][260/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.0154 (2.1968)	Acc@1 46.875 (39.748)	Acc@5 78.906 (74.500)
Epoch: [16][270/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.6350 (2.2000)	Acc@1 33.594 (39.656)	Acc@5 69.531 (74.498)
Epoch: [16][280/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2249 (2.2003)	Acc@1 39.062 (39.671)	Acc@5 71.875 (74.500)
Epoch: [16][290/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 1.9801 (2.1996)	Acc@1 46.875 (39.707)	Acc@5 78.125 (74.479)
Epoch: [16][300/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2490 (2.2008)	Acc@1 38.281 (39.680)	Acc@5 74.219 (74.442)
Epoch: [16][310/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2398 (2.2028)	Acc@1 40.625 (39.650)	Acc@5 73.438 (74.390)
Epoch: [16][320/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2776 (2.2037)	Acc@1 42.188 (39.613)	Acc@5 73.438 (74.426)
Epoch: [16][330/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.0429 (2.2042)	Acc@1 45.312 (39.603)	Acc@5 76.562 (74.448)
Epoch: [16][340/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1305 (2.2050)	Acc@1 39.062 (39.530)	Acc@5 76.562 (74.448)
Epoch: [16][350/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0259 (2.2066)	Acc@1 47.656 (39.530)	Acc@5 77.344 (74.408)
Epoch: [16][360/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1271 (2.2049)	Acc@1 38.281 (39.588)	Acc@5 75.781 (74.422)
Epoch: [16][370/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1743 (2.2068)	Acc@1 35.938 (39.524)	Acc@5 71.875 (74.351)
Epoch: [16][380/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1606 (2.2078)	Acc@1 41.406 (39.516)	Acc@5 77.344 (74.313)
Epoch: [16][390/391]	Time 0.085 (0.104)	Data 0.001 (0.002)	Loss 2.1157 (2.2085)	Acc@1 42.500 (39.490)	Acc@5 80.000 (74.322)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [17][0/391]	Time 0.116 (0.116)	Data 0.167 (0.167)	Loss 2.1767 (2.1767)	Acc@1 42.969 (42.969)	Acc@5 75.781 (75.781)
Epoch: [17][10/391]	Time 0.104 (0.105)	Data 0.001 (0.016)	Loss 2.0503 (2.2571)	Acc@1 41.406 (39.560)	Acc@5 80.469 (72.798)
Epoch: [17][20/391]	Time 0.108 (0.105)	Data 0.001 (0.009)	Loss 2.3307 (2.2589)	Acc@1 37.500 (38.876)	Acc@5 69.531 (72.396)
Epoch: [17][30/391]	Time 0.106 (0.104)	Data 0.001 (0.007)	Loss 2.1014 (2.2446)	Acc@1 45.312 (39.743)	Acc@5 78.125 (72.883)
Epoch: [17][40/391]	Time 0.108 (0.104)	Data 0.001 (0.005)	Loss 1.9491 (2.2057)	Acc@1 52.344 (40.758)	Acc@5 82.031 (74.028)
Epoch: [17][50/391]	Time 0.106 (0.104)	Data 0.001 (0.004)	Loss 2.1320 (2.2124)	Acc@1 42.188 (40.610)	Acc@5 76.562 (74.066)
Epoch: [17][60/391]	Time 0.105 (0.104)	Data 0.001 (0.004)	Loss 2.2827 (2.2177)	Acc@1 37.500 (40.100)	Acc@5 71.094 (73.937)
Epoch: [17][70/391]	Time 0.099 (0.104)	Data 0.001 (0.004)	Loss 2.2507 (2.2111)	Acc@1 28.125 (40.196)	Acc@5 74.219 (74.197)
Epoch: [17][80/391]	Time 0.108 (0.104)	Data 0.001 (0.003)	Loss 2.0728 (2.2023)	Acc@1 40.625 (40.355)	Acc@5 73.438 (74.402)
Epoch: [17][90/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 2.0252 (2.1967)	Acc@1 38.281 (40.393)	Acc@5 79.688 (74.622)
Epoch: [17][100/391]	Time 0.108 (0.104)	Data 0.001 (0.003)	Loss 1.9052 (2.2077)	Acc@1 48.438 (40.200)	Acc@5 79.688 (74.350)
Epoch: [17][110/391]	Time 0.105 (0.104)	Data 0.001 (0.003)	Loss 2.3323 (2.2097)	Acc@1 34.375 (40.210)	Acc@5 75.000 (74.381)
Epoch: [17][120/391]	Time 0.107 (0.104)	Data 0.001 (0.003)	Loss 2.0721 (2.2154)	Acc@1 38.281 (39.986)	Acc@5 75.781 (74.367)
Epoch: [17][130/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2567 (2.2164)	Acc@1 40.625 (39.981)	Acc@5 74.219 (74.320)
Epoch: [17][140/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1510 (2.2131)	Acc@1 37.500 (39.999)	Acc@5 74.219 (74.346)
Epoch: [17][150/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.0451 (2.2130)	Acc@1 48.438 (39.942)	Acc@5 78.906 (74.333)
Epoch: [17][160/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.0324 (2.2125)	Acc@1 41.406 (39.941)	Acc@5 78.125 (74.364)
Epoch: [17][170/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 1.9678 (2.2070)	Acc@1 42.969 (39.963)	Acc@5 80.469 (74.465)
Epoch: [17][180/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1128 (2.2094)	Acc@1 35.938 (39.857)	Acc@5 76.562 (74.417)
Epoch: [17][190/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2699 (2.2102)	Acc@1 39.844 (39.782)	Acc@5 68.750 (74.374)
Epoch: [17][200/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.4222 (2.2102)	Acc@1 35.938 (39.735)	Acc@5 67.969 (74.413)
Epoch: [17][210/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2956 (2.2123)	Acc@1 42.188 (39.666)	Acc@5 71.094 (74.411)
Epoch: [17][220/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0911 (2.2129)	Acc@1 39.844 (39.653)	Acc@5 78.125 (74.392)
Epoch: [17][230/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2828 (2.2130)	Acc@1 42.969 (39.661)	Acc@5 67.188 (74.297)
Epoch: [17][240/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 1.9744 (2.2081)	Acc@1 43.750 (39.756)	Acc@5 79.688 (74.381)
Epoch: [17][250/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2885 (2.2074)	Acc@1 38.281 (39.732)	Acc@5 74.219 (74.471)
Epoch: [17][260/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.3806 (2.2092)	Acc@1 32.812 (39.685)	Acc@5 68.750 (74.410)
Epoch: [17][270/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2484 (2.2121)	Acc@1 41.406 (39.610)	Acc@5 75.781 (74.354)
Epoch: [17][280/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0243 (2.2118)	Acc@1 39.062 (39.585)	Acc@5 74.219 (74.361)
Epoch: [17][290/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.5385 (2.2080)	Acc@1 30.469 (39.607)	Acc@5 64.062 (74.391)
Epoch: [17][300/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3736 (2.2094)	Acc@1 31.250 (39.631)	Acc@5 65.625 (74.307)
Epoch: [17][310/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0928 (2.2100)	Acc@1 44.531 (39.618)	Acc@5 78.906 (74.292)
Epoch: [17][320/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1637 (2.2106)	Acc@1 41.406 (39.605)	Acc@5 75.000 (74.280)
Epoch: [17][330/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.0927 (2.2108)	Acc@1 39.062 (39.589)	Acc@5 73.438 (74.306)
Epoch: [17][340/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1559 (2.2129)	Acc@1 39.844 (39.496)	Acc@5 76.562 (74.267)
Epoch: [17][350/391]	Time 0.098 (0.104)	Data 0.001 (0.002)	Loss 2.0073 (2.2134)	Acc@1 43.750 (39.508)	Acc@5 78.906 (74.248)
Epoch: [17][360/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.1536 (2.2142)	Acc@1 37.500 (39.513)	Acc@5 79.688 (74.225)
Epoch: [17][370/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2147 (2.2135)	Acc@1 37.500 (39.503)	Acc@5 78.906 (74.242)
Epoch: [17][380/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2093 (2.2117)	Acc@1 38.281 (39.507)	Acc@5 78.906 (74.286)
Epoch: [17][390/391]	Time 0.087 (0.104)	Data 0.001 (0.002)	Loss 2.2598 (2.2119)	Acc@1 31.250 (39.488)	Acc@5 72.500 (74.298)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [18][0/391]	Time 0.118 (0.118)	Data 0.166 (0.166)	Loss 2.1441 (2.1441)	Acc@1 46.094 (46.094)	Acc@5 75.000 (75.000)
Epoch: [18][10/391]	Time 0.102 (0.107)	Data 0.001 (0.016)	Loss 2.2488 (2.1571)	Acc@1 38.281 (39.560)	Acc@5 75.781 (75.355)
Epoch: [18][20/391]	Time 0.102 (0.106)	Data 0.001 (0.009)	Loss 2.2700 (2.1968)	Acc@1 32.812 (38.728)	Acc@5 71.094 (74.033)
Epoch: [18][30/391]	Time 0.099 (0.105)	Data 0.001 (0.006)	Loss 2.2954 (2.1972)	Acc@1 36.719 (39.088)	Acc@5 72.656 (73.816)
Epoch: [18][40/391]	Time 0.100 (0.105)	Data 0.001 (0.005)	Loss 2.1117 (2.2052)	Acc@1 41.406 (39.024)	Acc@5 78.906 (73.742)
Epoch: [18][50/391]	Time 0.106 (0.105)	Data 0.001 (0.004)	Loss 2.2178 (2.1949)	Acc@1 39.062 (39.262)	Acc@5 71.094 (73.958)
Epoch: [18][60/391]	Time 0.100 (0.104)	Data 0.001 (0.004)	Loss 2.1874 (2.1940)	Acc@1 42.969 (39.088)	Acc@5 77.344 (74.308)
Epoch: [18][70/391]	Time 0.101 (0.104)	Data 0.001 (0.003)	Loss 2.2346 (2.1819)	Acc@1 41.406 (39.305)	Acc@5 71.094 (74.527)
Epoch: [18][80/391]	Time 0.101 (0.104)	Data 0.001 (0.003)	Loss 2.0490 (2.1833)	Acc@1 42.188 (39.313)	Acc@5 79.688 (74.547)
Epoch: [18][90/391]	Time 0.100 (0.104)	Data 0.001 (0.003)	Loss 2.0804 (2.1905)	Acc@1 44.531 (39.243)	Acc@5 78.906 (74.528)
Epoch: [18][100/391]	Time 0.101 (0.104)	Data 0.001 (0.003)	Loss 2.4477 (2.1921)	Acc@1 37.500 (39.380)	Acc@5 72.656 (74.598)
Epoch: [18][110/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 1.9360 (2.1949)	Acc@1 48.438 (39.323)	Acc@5 78.906 (74.479)
Epoch: [18][120/391]	Time 0.105 (0.104)	Data 0.001 (0.003)	Loss 2.3303 (2.1961)	Acc@1 30.469 (39.431)	Acc@5 73.438 (74.380)
Epoch: [18][130/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 1.9923 (2.1947)	Acc@1 48.438 (39.450)	Acc@5 79.688 (74.416)
Epoch: [18][140/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2011 (2.1991)	Acc@1 36.719 (39.240)	Acc@5 67.969 (74.280)
Epoch: [18][150/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3692 (2.1982)	Acc@1 41.406 (39.357)	Acc@5 70.312 (74.214)
Epoch: [18][160/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 1.8909 (2.1970)	Acc@1 42.188 (39.344)	Acc@5 81.250 (74.209)
Epoch: [18][170/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0689 (2.1989)	Acc@1 49.219 (39.286)	Acc@5 73.438 (74.114)
Epoch: [18][180/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2124 (2.2006)	Acc@1 39.062 (39.235)	Acc@5 74.219 (74.055)
Epoch: [18][190/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.4728 (2.2023)	Acc@1 34.375 (39.128)	Acc@5 73.438 (74.116)
Epoch: [18][200/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2931 (2.2041)	Acc@1 41.406 (39.090)	Acc@5 71.094 (74.036)
Epoch: [18][210/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0584 (2.2082)	Acc@1 49.219 (39.085)	Acc@5 75.000 (73.945)
Epoch: [18][220/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3097 (2.2092)	Acc@1 40.625 (39.073)	Acc@5 72.656 (73.908)
Epoch: [18][230/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1128 (2.2092)	Acc@1 38.281 (39.079)	Acc@5 78.906 (73.918)
Epoch: [18][240/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.1392 (2.2119)	Acc@1 36.719 (39.040)	Acc@5 75.000 (73.846)
Epoch: [18][250/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.2270 (2.2126)	Acc@1 38.281 (38.982)	Acc@5 73.438 (73.842)
Epoch: [18][260/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1725 (2.2151)	Acc@1 44.531 (38.904)	Acc@5 72.656 (73.785)
Epoch: [18][270/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 1.8941 (2.2127)	Acc@1 50.000 (38.970)	Acc@5 79.688 (73.902)
Epoch: [18][280/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1512 (2.2126)	Acc@1 39.062 (38.962)	Acc@5 77.344 (73.941)
Epoch: [18][290/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.6038 (2.2158)	Acc@1 32.031 (38.896)	Acc@5 62.500 (73.867)
Epoch: [18][300/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3977 (2.2140)	Acc@1 33.594 (38.946)	Acc@5 74.219 (73.918)
Epoch: [18][310/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2401 (2.2153)	Acc@1 38.281 (38.965)	Acc@5 77.344 (73.965)
Epoch: [18][320/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.2297 (2.2153)	Acc@1 33.594 (38.997)	Acc@5 75.000 (73.990)
Epoch: [18][330/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1107 (2.2161)	Acc@1 42.188 (38.994)	Acc@5 73.438 (73.976)
Epoch: [18][340/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.1721 (2.2171)	Acc@1 38.281 (38.987)	Acc@5 78.906 (74.006)
Epoch: [18][350/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.1813 (2.2168)	Acc@1 39.844 (38.982)	Acc@5 78.906 (74.016)
Epoch: [18][360/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.2378 (2.2159)	Acc@1 41.406 (39.015)	Acc@5 72.656 (74.048)
Epoch: [18][370/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.2163 (2.2170)	Acc@1 41.406 (39.029)	Acc@5 75.781 (74.042)
Epoch: [18][380/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2751 (2.2196)	Acc@1 30.469 (38.995)	Acc@5 70.312 (73.995)
Epoch: [18][390/391]	Time 0.086 (0.104)	Data 0.001 (0.002)	Loss 2.0922 (2.2193)	Acc@1 36.250 (38.970)	Acc@5 77.500 (74.006)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [19][0/391]	Time 0.115 (0.115)	Data 0.162 (0.162)	Loss 2.1540 (2.1540)	Acc@1 46.094 (46.094)	Acc@5 75.000 (75.000)
Epoch: [19][10/391]	Time 0.104 (0.105)	Data 0.001 (0.016)	Loss 2.3166 (2.2240)	Acc@1 32.812 (38.423)	Acc@5 77.344 (73.651)
Epoch: [19][20/391]	Time 0.110 (0.106)	Data 0.001 (0.009)	Loss 2.0734 (2.1902)	Acc@1 41.406 (39.062)	Acc@5 74.219 (74.516)
Epoch: [19][30/391]	Time 0.105 (0.105)	Data 0.001 (0.006)	Loss 2.2372 (2.1771)	Acc@1 37.500 (39.617)	Acc@5 73.438 (74.647)
Epoch: [19][40/391]	Time 0.103 (0.105)	Data 0.001 (0.005)	Loss 2.3962 (2.1738)	Acc@1 38.281 (39.787)	Acc@5 69.531 (74.790)
Epoch: [19][50/391]	Time 0.098 (0.105)	Data 0.001 (0.004)	Loss 2.1923 (2.1687)	Acc@1 35.938 (39.982)	Acc@5 79.688 (74.724)
Epoch: [19][60/391]	Time 0.100 (0.105)	Data 0.001 (0.004)	Loss 2.0698 (2.1732)	Acc@1 42.188 (39.857)	Acc@5 77.344 (74.744)
Epoch: [19][70/391]	Time 0.104 (0.105)	Data 0.001 (0.003)	Loss 1.9869 (2.1752)	Acc@1 43.750 (39.712)	Acc@5 76.562 (74.868)
Epoch: [19][80/391]	Time 0.100 (0.105)	Data 0.001 (0.003)	Loss 2.2823 (2.1689)	Acc@1 39.062 (39.902)	Acc@5 71.875 (75.019)
Epoch: [19][90/391]	Time 0.104 (0.104)	Data 0.001 (0.003)	Loss 2.2170 (2.1710)	Acc@1 39.062 (39.801)	Acc@5 76.562 (74.957)
Epoch: [19][100/391]	Time 0.102 (0.104)	Data 0.001 (0.003)	Loss 1.9707 (2.1687)	Acc@1 43.750 (39.813)	Acc@5 77.344 (75.023)
Epoch: [19][110/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.2238 (2.1810)	Acc@1 40.625 (39.682)	Acc@5 71.094 (74.704)
Epoch: [19][120/391]	Time 0.102 (0.105)	Data 0.001 (0.002)	Loss 2.3305 (2.1860)	Acc@1 31.250 (39.618)	Acc@5 70.312 (74.613)
Epoch: [19][130/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.2019 (2.1887)	Acc@1 37.500 (39.629)	Acc@5 76.562 (74.577)
Epoch: [19][140/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3184 (2.1847)	Acc@1 35.156 (39.672)	Acc@5 67.969 (74.668)
Epoch: [19][150/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1117 (2.1898)	Acc@1 38.281 (39.554)	Acc@5 81.250 (74.524)
Epoch: [19][160/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1501 (2.1887)	Acc@1 45.312 (39.688)	Acc@5 75.000 (74.515)
Epoch: [19][170/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1444 (2.1888)	Acc@1 39.062 (39.748)	Acc@5 75.781 (74.497)
Epoch: [19][180/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2108 (2.1898)	Acc@1 35.938 (39.727)	Acc@5 75.000 (74.512)
Epoch: [19][190/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.1285 (2.1917)	Acc@1 40.625 (39.631)	Acc@5 76.562 (74.476)
Epoch: [19][200/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 1.9225 (2.1930)	Acc@1 42.969 (39.634)	Acc@5 80.469 (74.479)
Epoch: [19][210/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.3930 (2.1932)	Acc@1 35.938 (39.618)	Acc@5 65.625 (74.493)
Epoch: [19][220/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1872 (2.1940)	Acc@1 39.844 (39.600)	Acc@5 78.906 (74.540)
Epoch: [19][230/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.3071 (2.1938)	Acc@1 32.812 (39.546)	Acc@5 76.562 (74.591)
Epoch: [19][240/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2511 (2.1927)	Acc@1 36.719 (39.558)	Acc@5 74.219 (74.637)
Epoch: [19][250/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3746 (2.1922)	Acc@1 35.938 (39.573)	Acc@5 71.875 (74.651)
Epoch: [19][260/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1950 (2.1912)	Acc@1 34.375 (39.610)	Acc@5 73.438 (74.692)
Epoch: [19][270/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.0558 (2.1914)	Acc@1 45.312 (39.633)	Acc@5 75.781 (74.663)
Epoch: [19][280/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.4050 (2.1931)	Acc@1 35.938 (39.599)	Acc@5 67.969 (74.633)
Epoch: [19][290/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0168 (2.1908)	Acc@1 46.094 (39.653)	Acc@5 77.344 (74.662)
Epoch: [19][300/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1312 (2.1916)	Acc@1 42.188 (39.634)	Acc@5 74.219 (74.663)
Epoch: [19][310/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3859 (2.1928)	Acc@1 42.188 (39.675)	Acc@5 71.094 (74.591)
Epoch: [19][320/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.4691 (2.1966)	Acc@1 32.031 (39.625)	Acc@5 67.188 (74.516)
Epoch: [19][330/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.3775 (2.1980)	Acc@1 35.938 (39.579)	Acc@5 67.188 (74.476)
Epoch: [19][340/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.3962 (2.2010)	Acc@1 39.062 (39.555)	Acc@5 69.531 (74.402)
Epoch: [19][350/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.1261 (2.2026)	Acc@1 45.312 (39.574)	Acc@5 75.781 (74.348)
Epoch: [19][360/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1450 (2.2019)	Acc@1 45.312 (39.584)	Acc@5 76.562 (74.357)
Epoch: [19][370/391]	Time 0.105 (0.104)	Data 0.001 (0.002)	Loss 2.2289 (2.2033)	Acc@1 41.406 (39.570)	Acc@5 75.000 (74.328)
Epoch: [19][380/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.1946 (2.2047)	Acc@1 35.156 (39.542)	Acc@5 72.656 (74.311)
Epoch: [19][390/391]	Time 0.090 (0.104)	Data 0.001 (0.002)	Loss 2.1579 (2.2061)	Acc@1 47.500 (39.560)	Acc@5 75.000 (74.286)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [20][0/391]	Time 0.116 (0.116)	Data 0.173 (0.173)	Loss 2.2018 (2.2018)	Acc@1 37.500 (37.500)	Acc@5 71.094 (71.094)
Epoch: [20][10/391]	Time 0.106 (0.106)	Data 0.001 (0.017)	Loss 2.0533 (2.1396)	Acc@1 47.656 (41.761)	Acc@5 78.125 (75.639)
Epoch: [20][20/391]	Time 0.100 (0.106)	Data 0.001 (0.009)	Loss 2.0533 (2.1779)	Acc@1 39.844 (40.253)	Acc@5 75.000 (74.963)
Epoch: [20][30/391]	Time 0.102 (0.105)	Data 0.001 (0.007)	Loss 2.1833 (2.1650)	Acc@1 40.625 (40.953)	Acc@5 76.562 (75.529)
Epoch: [20][40/391]	Time 0.102 (0.105)	Data 0.001 (0.005)	Loss 2.0295 (2.1819)	Acc@1 41.406 (40.377)	Acc@5 78.125 (75.286)
Epoch: [20][50/391]	Time 0.103 (0.105)	Data 0.001 (0.005)	Loss 2.0094 (2.1809)	Acc@1 50.781 (40.610)	Acc@5 79.688 (75.123)
Epoch: [20][60/391]	Time 0.098 (0.105)	Data 0.001 (0.004)	Loss 2.1679 (2.1858)	Acc@1 39.844 (40.510)	Acc@5 72.656 (75.102)
Epoch: [20][70/391]	Time 0.104 (0.105)	Data 0.001 (0.004)	Loss 2.4536 (2.1995)	Acc@1 37.500 (40.042)	Acc@5 68.750 (74.659)
Epoch: [20][80/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.1119 (2.2020)	Acc@1 37.500 (39.853)	Acc@5 78.125 (74.470)
Epoch: [20][90/391]	Time 0.108 (0.105)	Data 0.001 (0.003)	Loss 2.2953 (2.2054)	Acc@1 35.156 (39.706)	Acc@5 77.344 (74.476)
Epoch: [20][100/391]	Time 0.100 (0.104)	Data 0.001 (0.003)	Loss 2.1317 (2.2041)	Acc@1 40.625 (39.588)	Acc@5 74.219 (74.489)
Epoch: [20][110/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.1572 (2.2106)	Acc@1 43.750 (39.323)	Acc@5 76.562 (74.360)
Epoch: [20][120/391]	Time 0.103 (0.105)	Data 0.001 (0.003)	Loss 2.3219 (2.2192)	Acc@1 34.375 (39.121)	Acc@5 68.750 (74.083)
Epoch: [20][130/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.2799 (2.2162)	Acc@1 32.031 (39.051)	Acc@5 72.656 (74.105)
Epoch: [20][140/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.0560 (2.2111)	Acc@1 44.531 (39.268)	Acc@5 78.906 (74.158)
Epoch: [20][150/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.0499 (2.2092)	Acc@1 41.406 (39.332)	Acc@5 74.219 (74.260)
Epoch: [20][160/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.1478 (2.2063)	Acc@1 43.750 (39.490)	Acc@5 73.438 (74.287)
Epoch: [20][170/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 1.9404 (2.2029)	Acc@1 45.312 (39.519)	Acc@5 81.250 (74.347)
Epoch: [20][180/391]	Time 0.104 (0.104)	Data 0.002 (0.002)	Loss 2.4658 (2.2032)	Acc@1 28.906 (39.503)	Acc@5 72.656 (74.409)
Epoch: [20][190/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2054 (2.2028)	Acc@1 39.062 (39.582)	Acc@5 74.219 (74.325)
Epoch: [20][200/391]	Time 0.108 (0.104)	Data 0.001 (0.002)	Loss 2.3838 (2.2042)	Acc@1 34.375 (39.576)	Acc@5 73.438 (74.254)
Epoch: [20][210/391]	Time 0.099 (0.104)	Data 0.001 (0.002)	Loss 2.4798 (2.2074)	Acc@1 32.812 (39.473)	Acc@5 68.750 (74.134)
Epoch: [20][220/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.2957 (2.2074)	Acc@1 36.719 (39.430)	Acc@5 69.531 (74.127)
Epoch: [20][230/391]	Time 0.103 (0.104)	Data 0.001 (0.002)	Loss 2.3826 (2.2037)	Acc@1 38.281 (39.556)	Acc@5 68.750 (74.205)
Epoch: [20][240/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 1.9235 (2.1982)	Acc@1 43.750 (39.646)	Acc@5 81.250 (74.306)
Epoch: [20][250/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.1134 (2.1979)	Acc@1 45.312 (39.676)	Acc@5 77.344 (74.343)
Epoch: [20][260/391]	Time 0.110 (0.104)	Data 0.001 (0.002)	Loss 2.0727 (2.1982)	Acc@1 45.312 (39.637)	Acc@5 74.219 (74.335)
Epoch: [20][270/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2582 (2.1981)	Acc@1 35.156 (39.633)	Acc@5 73.438 (74.374)
Epoch: [20][280/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.2619 (2.1988)	Acc@1 35.938 (39.660)	Acc@5 67.969 (74.386)
Epoch: [20][290/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.1665 (2.1976)	Acc@1 40.625 (39.763)	Acc@5 75.781 (74.374)
Epoch: [20][300/391]	Time 0.106 (0.104)	Data 0.001 (0.002)	Loss 2.3358 (2.1979)	Acc@1 38.281 (39.745)	Acc@5 70.312 (74.367)
Epoch: [20][310/391]	Time 0.109 (0.104)	Data 0.001 (0.002)	Loss 2.0073 (2.1973)	Acc@1 39.844 (39.728)	Acc@5 80.469 (74.374)
Epoch: [20][320/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.1485 (2.1971)	Acc@1 42.969 (39.785)	Acc@5 73.438 (74.362)
Epoch: [20][330/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.3238 (2.1964)	Acc@1 38.281 (39.808)	Acc@5 74.219 (74.379)
Epoch: [20][340/391]	Time 0.102 (0.104)	Data 0.001 (0.002)	Loss 2.3972 (2.1956)	Acc@1 31.250 (39.780)	Acc@5 73.438 (74.418)
Epoch: [20][350/391]	Time 0.104 (0.104)	Data 0.001 (0.002)	Loss 2.2283 (2.1954)	Acc@1 39.844 (39.821)	Acc@5 75.781 (74.406)
Epoch: [20][360/391]	Time 0.101 (0.104)	Data 0.001 (0.002)	Loss 2.4158 (2.1956)	Acc@1 32.812 (39.781)	Acc@5 68.750 (74.383)
Epoch: [20][370/391]	Time 0.107 (0.104)	Data 0.001 (0.002)	Loss 2.2444 (2.1988)	Acc@1 39.844 (39.701)	Acc@5 75.781 (74.356)
Epoch: [20][380/391]	Time 0.100 (0.104)	Data 0.001 (0.002)	Loss 2.2700 (2.1975)	Acc@1 42.188 (39.747)	Acc@5 71.094 (74.373)
Epoch: [20][390/391]	Time 0.088 (0.104)	Data 0.001 (0.002)	Loss 2.0664 (2.2000)	Acc@1 40.000 (39.684)	Acc@5 77.500 (74.304)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): AdaptiveAvgPool2d(output_size=(1, 1))
    (109): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Best acc:
33.0


now deeper
Epoch: [1][0/391]	Time 0.124 (0.124)	Data 0.163 (0.163)	Loss 2.1023 (2.1023)	Acc@1 40.625 (40.625)	Acc@5 73.438 (73.438)
Epoch: [1][10/391]	Time 0.117 (0.113)	Data 0.001 (0.016)	Loss 2.1169 (2.0554)	Acc@1 42.188 (42.827)	Acc@5 78.125 (75.852)
Epoch: [1][20/391]	Time 0.108 (0.111)	Data 0.001 (0.009)	Loss 2.0540 (2.1044)	Acc@1 44.531 (41.518)	Acc@5 75.781 (75.744)
Epoch: [1][30/391]	Time 0.111 (0.111)	Data 0.001 (0.006)	Loss 2.2860 (2.1343)	Acc@1 41.406 (40.827)	Acc@5 70.312 (75.504)
Epoch: [1][40/391]	Time 0.110 (0.111)	Data 0.001 (0.005)	Loss 2.6530 (2.1692)	Acc@1 35.156 (40.091)	Acc@5 63.281 (74.524)
Epoch: [1][50/391]	Time 0.111 (0.111)	Data 0.001 (0.004)	Loss 2.1860 (2.1792)	Acc@1 34.375 (39.675)	Acc@5 76.562 (74.387)
Epoch: [1][60/391]	Time 0.110 (0.111)	Data 0.001 (0.004)	Loss 2.0548 (2.1702)	Acc@1 43.750 (40.061)	Acc@5 78.125 (74.680)
Epoch: [1][70/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.3269 (2.1735)	Acc@1 37.500 (39.778)	Acc@5 73.438 (74.615)
Epoch: [1][80/391]	Time 0.116 (0.111)	Data 0.001 (0.003)	Loss 2.2483 (2.1797)	Acc@1 35.156 (39.767)	Acc@5 75.000 (74.508)
Epoch: [1][90/391]	Time 0.113 (0.111)	Data 0.001 (0.003)	Loss 2.3038 (2.1803)	Acc@1 35.156 (39.732)	Acc@5 74.219 (74.493)
Epoch: [1][100/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.2124 (2.1826)	Acc@1 47.656 (39.828)	Acc@5 75.781 (74.466)
Epoch: [1][110/391]	Time 0.116 (0.111)	Data 0.001 (0.003)	Loss 2.0336 (2.1850)	Acc@1 50.000 (39.823)	Acc@5 75.781 (74.388)
Epoch: [1][120/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2926 (2.1857)	Acc@1 29.688 (39.811)	Acc@5 75.000 (74.419)
Epoch: [1][130/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2126 (2.1907)	Acc@1 35.156 (39.659)	Acc@5 70.312 (74.368)
Epoch: [1][140/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9954 (2.1899)	Acc@1 45.312 (39.644)	Acc@5 76.562 (74.346)
Epoch: [1][150/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.5245 (2.1955)	Acc@1 33.594 (39.575)	Acc@5 71.875 (74.317)
Epoch: [1][160/391]	Time 0.106 (0.111)	Data 0.001 (0.002)	Loss 2.1415 (2.1976)	Acc@1 33.594 (39.451)	Acc@5 75.781 (74.306)
Epoch: [1][170/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2019 (2.1975)	Acc@1 35.156 (39.382)	Acc@5 74.219 (74.310)
Epoch: [1][180/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.2633 (2.1979)	Acc@1 39.062 (39.503)	Acc@5 72.656 (74.279)
Epoch: [1][190/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1058 (2.1997)	Acc@1 40.625 (39.570)	Acc@5 78.125 (74.296)
Epoch: [1][200/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.1262 (2.1999)	Acc@1 43.750 (39.544)	Acc@5 75.781 (74.320)
Epoch: [1][210/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1094 (2.1972)	Acc@1 40.625 (39.507)	Acc@5 77.344 (74.396)
Epoch: [1][220/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.2888 (2.2042)	Acc@1 39.062 (39.313)	Acc@5 71.094 (74.254)
Epoch: [1][230/391]	Time 0.105 (0.111)	Data 0.001 (0.002)	Loss 2.2681 (2.2067)	Acc@1 41.406 (39.306)	Acc@5 74.219 (74.219)
Epoch: [1][240/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1417 (2.2073)	Acc@1 44.531 (39.413)	Acc@5 78.906 (74.219)
Epoch: [1][250/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1440 (2.2080)	Acc@1 42.188 (39.405)	Acc@5 77.344 (74.169)
Epoch: [1][260/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.4070 (2.2095)	Acc@1 37.500 (39.416)	Acc@5 69.531 (74.159)
Epoch: [1][270/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0559 (2.2082)	Acc@1 39.062 (39.455)	Acc@5 81.250 (74.236)
Epoch: [1][280/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.0517 (2.2077)	Acc@1 40.625 (39.413)	Acc@5 77.344 (74.224)
Epoch: [1][290/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2220 (2.2094)	Acc@1 40.625 (39.374)	Acc@5 74.219 (74.152)
Epoch: [1][300/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9608 (2.2081)	Acc@1 46.094 (39.351)	Acc@5 76.562 (74.141)
Epoch: [1][310/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.4797 (2.2063)	Acc@1 27.344 (39.387)	Acc@5 66.406 (74.214)
Epoch: [1][320/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 1.7681 (2.2042)	Acc@1 47.656 (39.449)	Acc@5 86.719 (74.265)
Epoch: [1][330/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0531 (2.2036)	Acc@1 47.656 (39.490)	Acc@5 78.906 (74.299)
Epoch: [1][340/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2101 (2.2050)	Acc@1 37.500 (39.489)	Acc@5 78.125 (74.290)
Epoch: [1][350/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0310 (2.2023)	Acc@1 42.969 (39.537)	Acc@5 74.219 (74.343)
Epoch: [1][360/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3146 (2.2033)	Acc@1 39.844 (39.517)	Acc@5 75.781 (74.340)
Epoch: [1][370/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4377 (2.2058)	Acc@1 32.031 (39.471)	Acc@5 72.656 (74.269)
Epoch: [1][380/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.1502 (2.2073)	Acc@1 38.281 (39.432)	Acc@5 79.688 (74.264)
Epoch: [1][390/391]	Time 0.097 (0.111)	Data 0.001 (0.002)	Loss 2.0564 (2.2077)	Acc@1 50.000 (39.482)	Acc@5 77.500 (74.260)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [2][0/391]	Time 0.123 (0.123)	Data 0.166 (0.166)	Loss 2.0987 (2.0987)	Acc@1 39.844 (39.844)	Acc@5 71.875 (71.875)
Epoch: [2][10/391]	Time 0.111 (0.113)	Data 0.001 (0.016)	Loss 1.9298 (2.1689)	Acc@1 44.531 (40.199)	Acc@5 80.469 (75.284)
Epoch: [2][20/391]	Time 0.112 (0.112)	Data 0.001 (0.009)	Loss 2.2667 (2.1823)	Acc@1 40.625 (40.662)	Acc@5 73.438 (74.888)
Epoch: [2][30/391]	Time 0.113 (0.112)	Data 0.001 (0.007)	Loss 2.1492 (2.1636)	Acc@1 43.750 (40.801)	Acc@5 74.219 (75.252)
Epoch: [2][40/391]	Time 0.111 (0.112)	Data 0.001 (0.005)	Loss 2.1019 (2.1632)	Acc@1 42.188 (40.758)	Acc@5 74.219 (75.324)
Epoch: [2][50/391]	Time 0.110 (0.111)	Data 0.001 (0.004)	Loss 2.1544 (2.1627)	Acc@1 42.188 (40.732)	Acc@5 75.000 (75.245)
Epoch: [2][60/391]	Time 0.112 (0.112)	Data 0.001 (0.004)	Loss 1.9248 (2.1664)	Acc@1 40.625 (40.382)	Acc@5 79.688 (75.192)
Epoch: [2][70/391]	Time 0.111 (0.112)	Data 0.001 (0.004)	Loss 2.1270 (2.1696)	Acc@1 43.750 (40.449)	Acc@5 81.250 (75.231)
Epoch: [2][80/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.3311 (2.1809)	Acc@1 36.719 (40.114)	Acc@5 68.750 (74.981)
Epoch: [2][90/391]	Time 0.116 (0.112)	Data 0.001 (0.003)	Loss 2.1964 (2.1777)	Acc@1 39.844 (40.058)	Acc@5 72.656 (75.129)
Epoch: [2][100/391]	Time 0.116 (0.112)	Data 0.001 (0.003)	Loss 2.0214 (2.1764)	Acc@1 42.969 (40.068)	Acc@5 77.344 (75.155)
Epoch: [2][110/391]	Time 0.115 (0.112)	Data 0.001 (0.003)	Loss 2.0838 (2.1771)	Acc@1 38.281 (40.034)	Acc@5 76.562 (75.000)
Epoch: [2][120/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.1548 (2.1738)	Acc@1 38.281 (40.244)	Acc@5 74.219 (75.013)
Epoch: [2][130/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.0712 (2.1705)	Acc@1 42.969 (40.291)	Acc@5 81.250 (75.131)
Epoch: [2][140/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3958 (2.1762)	Acc@1 36.719 (40.104)	Acc@5 70.312 (74.956)
Epoch: [2][150/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.3398 (2.1827)	Acc@1 36.719 (39.880)	Acc@5 66.406 (74.814)
Epoch: [2][160/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2655 (2.1827)	Acc@1 36.719 (39.897)	Acc@5 71.875 (74.869)
Epoch: [2][170/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3377 (2.1844)	Acc@1 37.500 (39.784)	Acc@5 75.000 (74.836)
Epoch: [2][180/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2806 (2.1868)	Acc@1 41.406 (39.757)	Acc@5 71.875 (74.793)
Epoch: [2][190/391]	Time 0.105 (0.111)	Data 0.001 (0.002)	Loss 2.3405 (2.1881)	Acc@1 35.938 (39.778)	Acc@5 72.656 (74.738)
Epoch: [2][200/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9692 (2.1884)	Acc@1 46.875 (39.754)	Acc@5 75.781 (74.728)
Epoch: [2][210/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.1554 (2.1883)	Acc@1 39.844 (39.762)	Acc@5 70.312 (74.682)
Epoch: [2][220/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0222 (2.1891)	Acc@1 46.094 (39.777)	Acc@5 81.250 (74.661)
Epoch: [2][230/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.0988 (2.1914)	Acc@1 44.531 (39.739)	Acc@5 78.125 (74.638)
Epoch: [2][240/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.0725 (2.1913)	Acc@1 46.875 (39.759)	Acc@5 78.906 (74.637)
Epoch: [2][250/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.0511 (2.1887)	Acc@1 36.719 (39.806)	Acc@5 76.562 (74.739)
Epoch: [2][260/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.3482 (2.1895)	Acc@1 34.375 (39.799)	Acc@5 77.344 (74.752)
Epoch: [2][270/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.4211 (2.1923)	Acc@1 27.344 (39.708)	Acc@5 71.875 (74.683)
Epoch: [2][280/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4721 (2.1963)	Acc@1 35.938 (39.635)	Acc@5 71.094 (74.577)
Epoch: [2][290/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2534 (2.2000)	Acc@1 41.406 (39.594)	Acc@5 76.562 (74.503)
Epoch: [2][300/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2486 (2.1991)	Acc@1 38.281 (39.584)	Acc@5 72.656 (74.515)
Epoch: [2][310/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 1.9956 (2.1980)	Acc@1 39.844 (39.557)	Acc@5 79.688 (74.596)
Epoch: [2][320/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.2885 (2.2009)	Acc@1 42.188 (39.484)	Acc@5 71.875 (74.547)
Epoch: [2][330/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2494 (2.1998)	Acc@1 45.312 (39.527)	Acc@5 73.438 (74.603)
Epoch: [2][340/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1549 (2.2005)	Acc@1 42.969 (39.539)	Acc@5 74.219 (74.558)
Epoch: [2][350/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4182 (2.2015)	Acc@1 35.156 (39.554)	Acc@5 67.969 (74.504)
Epoch: [2][360/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.4685 (2.2021)	Acc@1 26.562 (39.526)	Acc@5 71.094 (74.498)
Epoch: [2][370/391]	Time 0.118 (0.111)	Data 0.001 (0.002)	Loss 2.4818 (2.2021)	Acc@1 28.906 (39.528)	Acc@5 67.969 (74.499)
Epoch: [2][380/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.2328 (2.2023)	Acc@1 35.938 (39.510)	Acc@5 78.125 (74.502)
Epoch: [2][390/391]	Time 0.093 (0.111)	Data 0.001 (0.002)	Loss 2.2673 (2.2046)	Acc@1 41.250 (39.466)	Acc@5 72.500 (74.446)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [3][0/391]	Time 0.128 (0.128)	Data 0.157 (0.157)	Loss 2.3063 (2.3063)	Acc@1 35.156 (35.156)	Acc@5 73.438 (73.438)
Epoch: [3][10/391]	Time 0.111 (0.113)	Data 0.001 (0.015)	Loss 2.3122 (2.2451)	Acc@1 40.625 (38.778)	Acc@5 69.531 (73.295)
Epoch: [3][20/391]	Time 0.117 (0.113)	Data 0.001 (0.009)	Loss 2.1235 (2.1969)	Acc@1 35.938 (39.993)	Acc@5 81.250 (74.777)
Epoch: [3][30/391]	Time 0.111 (0.113)	Data 0.001 (0.006)	Loss 2.1884 (2.1581)	Acc@1 38.281 (40.499)	Acc@5 68.750 (75.605)
Epoch: [3][40/391]	Time 0.110 (0.112)	Data 0.001 (0.005)	Loss 2.2049 (2.1468)	Acc@1 35.938 (41.101)	Acc@5 75.000 (75.648)
Epoch: [3][50/391]	Time 0.112 (0.112)	Data 0.001 (0.004)	Loss 1.8665 (2.1435)	Acc@1 46.875 (40.947)	Acc@5 80.469 (75.659)
Epoch: [3][60/391]	Time 0.115 (0.112)	Data 0.001 (0.004)	Loss 2.3243 (2.1540)	Acc@1 39.844 (40.894)	Acc@5 74.219 (75.371)
Epoch: [3][70/391]	Time 0.111 (0.112)	Data 0.001 (0.003)	Loss 2.2555 (2.1730)	Acc@1 39.062 (40.394)	Acc@5 72.656 (74.923)
Epoch: [3][80/391]	Time 0.113 (0.112)	Data 0.001 (0.003)	Loss 2.0928 (2.1715)	Acc@1 40.625 (40.355)	Acc@5 78.125 (74.904)
Epoch: [3][90/391]	Time 0.120 (0.112)	Data 0.001 (0.003)	Loss 2.2783 (2.1826)	Acc@1 35.938 (40.144)	Acc@5 76.562 (74.845)
Epoch: [3][100/391]	Time 0.116 (0.112)	Data 0.001 (0.003)	Loss 2.1311 (2.1860)	Acc@1 39.844 (40.114)	Acc@5 78.125 (74.660)
Epoch: [3][110/391]	Time 0.107 (0.112)	Data 0.001 (0.003)	Loss 2.3765 (2.1889)	Acc@1 32.031 (40.090)	Acc@5 72.656 (74.550)
Epoch: [3][120/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.1968 (2.1900)	Acc@1 35.156 (39.992)	Acc@5 71.094 (74.483)
Epoch: [3][130/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1723 (2.1928)	Acc@1 40.625 (39.850)	Acc@5 73.438 (74.380)
Epoch: [3][140/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.4820 (2.1950)	Acc@1 37.500 (39.894)	Acc@5 66.406 (74.379)
Epoch: [3][150/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2872 (2.1965)	Acc@1 32.812 (39.813)	Acc@5 71.875 (74.333)
Epoch: [3][160/391]	Time 0.117 (0.112)	Data 0.001 (0.002)	Loss 2.3399 (2.1950)	Acc@1 38.281 (39.980)	Acc@5 71.875 (74.437)
Epoch: [3][170/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1401 (2.1945)	Acc@1 35.938 (40.026)	Acc@5 75.000 (74.461)
Epoch: [3][180/391]	Time 0.118 (0.112)	Data 0.001 (0.002)	Loss 2.1967 (2.1976)	Acc@1 39.062 (40.038)	Acc@5 76.562 (74.387)
Epoch: [3][190/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.3645 (2.2001)	Acc@1 40.625 (39.979)	Acc@5 67.188 (74.301)
Epoch: [3][200/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 2.2522 (2.2022)	Acc@1 39.062 (39.902)	Acc@5 72.656 (74.211)
Epoch: [3][210/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.2852 (2.2065)	Acc@1 40.625 (39.836)	Acc@5 72.656 (74.115)
Epoch: [3][220/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.2461 (2.2078)	Acc@1 40.625 (39.773)	Acc@5 74.219 (74.106)
Epoch: [3][230/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.3590 (2.2095)	Acc@1 40.625 (39.736)	Acc@5 69.531 (74.165)
Epoch: [3][240/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2655 (2.2111)	Acc@1 34.375 (39.682)	Acc@5 74.219 (74.099)
Epoch: [3][250/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2937 (2.2118)	Acc@1 36.719 (39.589)	Acc@5 78.125 (74.132)
Epoch: [3][260/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.2728 (2.2105)	Acc@1 36.719 (39.568)	Acc@5 75.000 (74.150)
Epoch: [3][270/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3771 (2.2110)	Acc@1 31.250 (39.527)	Acc@5 74.219 (74.118)
Epoch: [3][280/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.1651 (2.2109)	Acc@1 39.844 (39.516)	Acc@5 75.781 (74.069)
Epoch: [3][290/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3611 (2.2119)	Acc@1 34.375 (39.489)	Acc@5 72.656 (74.068)
Epoch: [3][300/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.3575 (2.2106)	Acc@1 32.031 (39.486)	Acc@5 71.875 (74.094)
Epoch: [3][310/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.1794 (2.2102)	Acc@1 37.500 (39.482)	Acc@5 72.656 (74.103)
Epoch: [3][320/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.1144 (2.2108)	Acc@1 36.719 (39.464)	Acc@5 78.906 (74.102)
Epoch: [3][330/391]	Time 0.105 (0.112)	Data 0.001 (0.002)	Loss 1.9679 (2.2100)	Acc@1 43.750 (39.490)	Acc@5 79.688 (74.098)
Epoch: [3][340/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 1.8804 (2.2081)	Acc@1 50.000 (39.544)	Acc@5 84.375 (74.139)
Epoch: [3][350/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2281 (2.2071)	Acc@1 41.406 (39.561)	Acc@5 71.094 (74.152)
Epoch: [3][360/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1461 (2.2074)	Acc@1 36.719 (39.560)	Acc@5 75.781 (74.156)
Epoch: [3][370/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0852 (2.2068)	Acc@1 43.750 (39.534)	Acc@5 83.594 (74.219)
Epoch: [3][380/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1383 (2.2078)	Acc@1 39.062 (39.505)	Acc@5 78.125 (74.215)
Epoch: [3][390/391]	Time 0.091 (0.112)	Data 0.001 (0.002)	Loss 2.8396 (2.2088)	Acc@1 30.000 (39.498)	Acc@5 60.000 (74.162)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [4][0/391]	Time 0.125 (0.125)	Data 0.157 (0.157)	Loss 2.1069 (2.1069)	Acc@1 42.188 (42.188)	Acc@5 76.562 (76.562)
Epoch: [4][10/391]	Time 0.108 (0.113)	Data 0.001 (0.015)	Loss 2.4077 (2.2573)	Acc@1 34.375 (37.855)	Acc@5 71.094 (75.071)
Epoch: [4][20/391]	Time 0.107 (0.112)	Data 0.001 (0.009)	Loss 2.1694 (2.2172)	Acc@1 35.156 (37.612)	Acc@5 74.219 (74.926)
Epoch: [4][30/391]	Time 0.114 (0.112)	Data 0.001 (0.006)	Loss 2.0226 (2.2081)	Acc@1 42.188 (38.836)	Acc@5 75.781 (75.151)
Epoch: [4][40/391]	Time 0.111 (0.112)	Data 0.001 (0.005)	Loss 2.1728 (2.1983)	Acc@1 41.406 (39.005)	Acc@5 74.219 (75.076)
Epoch: [4][50/391]	Time 0.108 (0.112)	Data 0.001 (0.004)	Loss 2.2482 (2.2009)	Acc@1 35.938 (39.001)	Acc@5 75.781 (74.969)
Epoch: [4][60/391]	Time 0.116 (0.112)	Data 0.002 (0.004)	Loss 2.3045 (2.1924)	Acc@1 33.594 (39.088)	Acc@5 76.562 (75.295)
Epoch: [4][70/391]	Time 0.107 (0.112)	Data 0.001 (0.003)	Loss 2.0891 (2.1809)	Acc@1 45.312 (39.393)	Acc@5 73.438 (75.638)
Epoch: [4][80/391]	Time 0.113 (0.112)	Data 0.001 (0.003)	Loss 2.2394 (2.1840)	Acc@1 40.625 (39.284)	Acc@5 74.219 (75.453)
Epoch: [4][90/391]	Time 0.109 (0.112)	Data 0.001 (0.003)	Loss 2.3658 (2.1873)	Acc@1 35.156 (39.140)	Acc@5 64.844 (75.283)
Epoch: [4][100/391]	Time 0.111 (0.112)	Data 0.001 (0.003)	Loss 2.1947 (2.1900)	Acc@1 41.406 (39.117)	Acc@5 75.000 (75.186)
Epoch: [4][110/391]	Time 0.113 (0.112)	Data 0.001 (0.003)	Loss 2.0820 (2.1939)	Acc@1 40.625 (38.985)	Acc@5 81.250 (75.141)
Epoch: [4][120/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.3362 (2.1957)	Acc@1 40.625 (39.172)	Acc@5 72.656 (75.039)
Epoch: [4][130/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2278 (2.1921)	Acc@1 40.625 (39.325)	Acc@5 71.875 (75.048)
Epoch: [4][140/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1657 (2.1918)	Acc@1 40.625 (39.439)	Acc@5 71.094 (74.939)
Epoch: [4][150/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.0332 (2.1940)	Acc@1 42.188 (39.590)	Acc@5 78.125 (74.865)
Epoch: [4][160/391]	Time 0.117 (0.112)	Data 0.001 (0.002)	Loss 2.2077 (2.1904)	Acc@1 36.719 (39.776)	Acc@5 75.000 (74.825)
Epoch: [4][170/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2725 (2.1893)	Acc@1 37.500 (39.775)	Acc@5 72.656 (74.845)
Epoch: [4][180/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.0504 (2.1885)	Acc@1 43.750 (39.805)	Acc@5 77.344 (74.832)
Epoch: [4][190/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.0889 (2.1871)	Acc@1 46.875 (39.819)	Acc@5 75.000 (74.890)
Epoch: [4][200/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 1.9065 (2.1910)	Acc@1 48.438 (39.723)	Acc@5 79.688 (74.716)
Epoch: [4][210/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2210 (2.1935)	Acc@1 35.156 (39.725)	Acc@5 75.000 (74.715)
Epoch: [4][220/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.4129 (2.1934)	Acc@1 38.281 (39.752)	Acc@5 68.750 (74.692)
Epoch: [4][230/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.3200 (2.1918)	Acc@1 33.594 (39.786)	Acc@5 68.750 (74.675)
Epoch: [4][240/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.1457 (2.1925)	Acc@1 38.281 (39.769)	Acc@5 73.438 (74.695)
Epoch: [4][250/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.2386 (2.1948)	Acc@1 39.844 (39.738)	Acc@5 74.219 (74.633)
Epoch: [4][260/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.1668 (2.1969)	Acc@1 39.844 (39.730)	Acc@5 72.656 (74.557)
Epoch: [4][270/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2566 (2.2004)	Acc@1 33.594 (39.648)	Acc@5 75.781 (74.452)
Epoch: [4][280/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.3123 (2.1997)	Acc@1 35.938 (39.660)	Acc@5 68.750 (74.436)
Epoch: [4][290/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0750 (2.1988)	Acc@1 39.062 (39.696)	Acc@5 78.906 (74.425)
Epoch: [4][300/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.8145 (2.1992)	Acc@1 50.781 (39.727)	Acc@5 81.250 (74.413)
Epoch: [4][310/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.0691 (2.1986)	Acc@1 45.312 (39.758)	Acc@5 77.344 (74.425)
Epoch: [4][320/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.4741 (2.1986)	Acc@1 30.469 (39.761)	Acc@5 65.625 (74.404)
Epoch: [4][330/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2630 (2.1996)	Acc@1 36.719 (39.674)	Acc@5 75.781 (74.429)
Epoch: [4][340/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2558 (2.2013)	Acc@1 35.938 (39.640)	Acc@5 70.312 (74.361)
Epoch: [4][350/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.4088 (2.2039)	Acc@1 36.719 (39.623)	Acc@5 68.750 (74.294)
Epoch: [4][360/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.4814 (2.2054)	Acc@1 32.812 (39.627)	Acc@5 63.281 (74.236)
Epoch: [4][370/391]	Time 0.117 (0.112)	Data 0.001 (0.002)	Loss 1.9915 (2.2068)	Acc@1 39.844 (39.574)	Acc@5 74.219 (74.187)
Epoch: [4][380/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 2.2361 (2.2070)	Acc@1 39.062 (39.575)	Acc@5 71.094 (74.165)
Epoch: [4][390/391]	Time 0.091 (0.112)	Data 0.001 (0.002)	Loss 2.3130 (2.2074)	Acc@1 36.250 (39.572)	Acc@5 71.250 (74.120)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [5][0/391]	Time 0.119 (0.119)	Data 0.172 (0.172)	Loss 2.3978 (2.3978)	Acc@1 36.719 (36.719)	Acc@5 72.656 (72.656)
Epoch: [5][10/391]	Time 0.108 (0.113)	Data 0.001 (0.017)	Loss 2.2065 (2.2547)	Acc@1 35.938 (37.003)	Acc@5 74.219 (72.159)
Epoch: [5][20/391]	Time 0.111 (0.112)	Data 0.001 (0.009)	Loss 1.9118 (2.1799)	Acc@1 49.219 (39.993)	Acc@5 75.781 (73.735)
Epoch: [5][30/391]	Time 0.107 (0.112)	Data 0.001 (0.007)	Loss 1.9938 (2.1633)	Acc@1 48.438 (40.625)	Acc@5 78.906 (74.244)
Epoch: [5][40/391]	Time 0.111 (0.111)	Data 0.001 (0.005)	Loss 2.0569 (2.1543)	Acc@1 38.281 (41.006)	Acc@5 81.250 (74.771)
Epoch: [5][50/391]	Time 0.111 (0.111)	Data 0.001 (0.005)	Loss 2.1209 (2.1599)	Acc@1 40.625 (40.656)	Acc@5 75.781 (74.893)
Epoch: [5][60/391]	Time 0.109 (0.111)	Data 0.001 (0.004)	Loss 2.1312 (2.1623)	Acc@1 42.969 (40.446)	Acc@5 81.250 (74.962)
Epoch: [5][70/391]	Time 0.110 (0.111)	Data 0.001 (0.004)	Loss 2.3641 (2.1752)	Acc@1 36.719 (39.987)	Acc@5 69.531 (74.560)
Epoch: [5][80/391]	Time 0.111 (0.111)	Data 0.001 (0.003)	Loss 2.1985 (2.1971)	Acc@1 36.719 (39.429)	Acc@5 74.219 (74.228)
Epoch: [5][90/391]	Time 0.119 (0.112)	Data 0.001 (0.003)	Loss 2.2358 (2.2045)	Acc@1 35.938 (39.251)	Acc@5 77.344 (74.176)
Epoch: [5][100/391]	Time 0.108 (0.112)	Data 0.001 (0.003)	Loss 2.3144 (2.1989)	Acc@1 37.500 (39.449)	Acc@5 72.656 (74.397)
Epoch: [5][110/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.4695 (2.2000)	Acc@1 33.594 (39.485)	Acc@5 69.531 (74.282)
Epoch: [5][120/391]	Time 0.112 (0.111)	Data 0.001 (0.003)	Loss 2.2247 (2.2016)	Acc@1 39.062 (39.534)	Acc@5 69.531 (74.174)
Epoch: [5][130/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2010 (2.1995)	Acc@1 33.594 (39.528)	Acc@5 71.875 (74.278)
Epoch: [5][140/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1630 (2.1973)	Acc@1 39.844 (39.511)	Acc@5 76.562 (74.402)
Epoch: [5][150/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2436 (2.1952)	Acc@1 40.625 (39.632)	Acc@5 73.438 (74.389)
Epoch: [5][160/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4236 (2.1983)	Acc@1 30.469 (39.465)	Acc@5 74.219 (74.384)
Epoch: [5][170/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1791 (2.1971)	Acc@1 36.719 (39.391)	Acc@5 77.344 (74.465)
Epoch: [5][180/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2189 (2.1965)	Acc@1 41.406 (39.429)	Acc@5 74.219 (74.508)
Epoch: [5][190/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.0039 (2.1946)	Acc@1 48.438 (39.492)	Acc@5 81.250 (74.558)
Epoch: [5][200/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4114 (2.1940)	Acc@1 42.188 (39.529)	Acc@5 71.094 (74.518)
Epoch: [5][210/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1995 (2.1943)	Acc@1 42.188 (39.525)	Acc@5 68.750 (74.474)
Epoch: [5][220/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.1569 (2.1936)	Acc@1 33.594 (39.526)	Acc@5 73.438 (74.420)
Epoch: [5][230/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1115 (2.1910)	Acc@1 40.625 (39.516)	Acc@5 71.875 (74.483)
Epoch: [5][240/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.9541 (2.1901)	Acc@1 40.625 (39.500)	Acc@5 79.688 (74.494)
Epoch: [5][250/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.3709 (2.1912)	Acc@1 37.500 (39.399)	Acc@5 67.188 (74.490)
Epoch: [5][260/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1580 (2.1923)	Acc@1 43.750 (39.347)	Acc@5 73.438 (74.476)
Epoch: [5][270/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4044 (2.1934)	Acc@1 32.031 (39.336)	Acc@5 64.062 (74.421)
Epoch: [5][280/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1558 (2.1942)	Acc@1 42.969 (39.418)	Acc@5 71.875 (74.413)
Epoch: [5][290/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1182 (2.1938)	Acc@1 46.094 (39.489)	Acc@5 77.344 (74.442)
Epoch: [5][300/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.0681 (2.1958)	Acc@1 42.969 (39.460)	Acc@5 70.312 (74.338)
Epoch: [5][310/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.3812 (2.1999)	Acc@1 34.375 (39.369)	Acc@5 69.531 (74.219)
Epoch: [5][320/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.3683 (2.2008)	Acc@1 38.281 (39.376)	Acc@5 70.312 (74.146)
Epoch: [5][330/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0840 (2.2019)	Acc@1 39.062 (39.329)	Acc@5 75.781 (74.115)
Epoch: [5][340/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.1542 (2.2018)	Acc@1 45.312 (39.301)	Acc@5 71.094 (74.116)
Epoch: [5][350/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.4999 (2.2058)	Acc@1 28.906 (39.194)	Acc@5 67.969 (74.054)
Epoch: [5][360/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.3227 (2.2062)	Acc@1 36.719 (39.188)	Acc@5 72.656 (74.087)
Epoch: [5][370/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.2791 (2.2089)	Acc@1 35.156 (39.075)	Acc@5 72.656 (74.040)
Epoch: [5][380/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.4423 (2.2127)	Acc@1 35.938 (39.003)	Acc@5 71.875 (73.991)
Epoch: [5][390/391]	Time 0.096 (0.111)	Data 0.001 (0.002)	Loss 2.2239 (2.2125)	Acc@1 36.250 (39.014)	Acc@5 73.750 (73.998)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [6][0/391]	Time 0.120 (0.120)	Data 0.162 (0.162)	Loss 2.1768 (2.1768)	Acc@1 41.406 (41.406)	Acc@5 74.219 (74.219)
Epoch: [6][10/391]	Time 0.111 (0.114)	Data 0.001 (0.016)	Loss 2.3940 (2.1902)	Acc@1 35.156 (38.991)	Acc@5 72.656 (75.071)
Epoch: [6][20/391]	Time 0.113 (0.113)	Data 0.001 (0.009)	Loss 2.2822 (2.1870)	Acc@1 33.594 (39.062)	Acc@5 75.781 (74.851)
Epoch: [6][30/391]	Time 0.112 (0.113)	Data 0.001 (0.006)	Loss 2.1418 (2.1652)	Acc@1 42.188 (40.071)	Acc@5 75.781 (75.050)
Epoch: [6][40/391]	Time 0.115 (0.113)	Data 0.001 (0.005)	Loss 1.9496 (2.1564)	Acc@1 42.188 (40.187)	Acc@5 82.031 (75.114)
Epoch: [6][50/391]	Time 0.110 (0.113)	Data 0.001 (0.004)	Loss 2.0297 (2.1449)	Acc@1 42.188 (40.487)	Acc@5 75.000 (75.260)
Epoch: [6][60/391]	Time 0.111 (0.112)	Data 0.001 (0.004)	Loss 1.9455 (2.1437)	Acc@1 49.219 (40.676)	Acc@5 82.031 (75.359)
Epoch: [6][70/391]	Time 0.113 (0.112)	Data 0.001 (0.003)	Loss 2.1122 (2.1506)	Acc@1 42.969 (40.526)	Acc@5 75.781 (75.429)
Epoch: [6][80/391]	Time 0.111 (0.112)	Data 0.001 (0.003)	Loss 1.9346 (2.1508)	Acc@1 43.750 (40.635)	Acc@5 75.781 (75.318)
Epoch: [6][90/391]	Time 0.114 (0.113)	Data 0.001 (0.003)	Loss 2.1118 (2.1659)	Acc@1 38.281 (40.385)	Acc@5 78.125 (74.931)
Epoch: [6][100/391]	Time 0.117 (0.113)	Data 0.001 (0.003)	Loss 2.3428 (2.1698)	Acc@1 34.375 (40.354)	Acc@5 67.188 (74.791)
Epoch: [6][110/391]	Time 0.111 (0.112)	Data 0.001 (0.003)	Loss 2.1556 (2.1676)	Acc@1 39.062 (40.329)	Acc@5 75.000 (74.887)
Epoch: [6][120/391]	Time 0.112 (0.112)	Data 0.001 (0.003)	Loss 2.1190 (2.1619)	Acc@1 38.281 (40.341)	Acc@5 75.000 (75.110)
Epoch: [6][130/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1868 (2.1673)	Acc@1 39.062 (40.267)	Acc@5 72.656 (74.964)
Epoch: [6][140/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.2202 (2.1720)	Acc@1 41.406 (40.248)	Acc@5 72.656 (74.878)
Epoch: [6][150/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.8928 (2.1744)	Acc@1 50.781 (40.242)	Acc@5 80.469 (74.834)
Epoch: [6][160/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.3477 (2.1782)	Acc@1 37.500 (40.140)	Acc@5 69.531 (74.738)
Epoch: [6][170/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.4742 (2.1840)	Acc@1 32.812 (40.017)	Acc@5 71.875 (74.612)
Epoch: [6][180/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.2816 (2.1814)	Acc@1 36.719 (40.081)	Acc@5 74.219 (74.676)
Epoch: [6][190/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.2924 (2.1824)	Acc@1 37.500 (40.073)	Acc@5 71.094 (74.554)
Epoch: [6][200/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.6447 (2.1831)	Acc@1 33.594 (40.131)	Acc@5 64.844 (74.514)
Epoch: [6][210/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.3336 (2.1893)	Acc@1 33.594 (39.981)	Acc@5 70.312 (74.341)
Epoch: [6][220/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1183 (2.1898)	Acc@1 46.094 (39.925)	Acc@5 73.438 (74.371)
Epoch: [6][230/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2985 (2.1917)	Acc@1 35.156 (39.888)	Acc@5 74.219 (74.280)
Epoch: [6][240/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.4366 (2.1970)	Acc@1 32.812 (39.782)	Acc@5 70.312 (74.170)
Epoch: [6][250/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.5803 (2.1982)	Acc@1 28.906 (39.710)	Acc@5 68.750 (74.172)
Epoch: [6][260/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.1630 (2.1967)	Acc@1 38.281 (39.694)	Acc@5 71.875 (74.150)
Epoch: [6][270/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3076 (2.2006)	Acc@1 35.156 (39.593)	Acc@5 71.094 (74.092)
Epoch: [6][280/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.0506 (2.1991)	Acc@1 48.438 (39.610)	Acc@5 75.000 (74.124)
Epoch: [6][290/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 1.9375 (2.1972)	Acc@1 52.344 (39.739)	Acc@5 78.906 (74.181)
Epoch: [6][300/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.0118 (2.1994)	Acc@1 45.312 (39.740)	Acc@5 75.781 (74.133)
Epoch: [6][310/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3423 (2.2015)	Acc@1 34.375 (39.708)	Acc@5 71.875 (74.128)
Epoch: [6][320/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0736 (2.2012)	Acc@1 43.750 (39.739)	Acc@5 78.125 (74.175)
Epoch: [6][330/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.1651 (2.2037)	Acc@1 45.312 (39.667)	Acc@5 75.781 (74.113)
Epoch: [6][340/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2575 (2.2025)	Acc@1 36.719 (39.672)	Acc@5 69.531 (74.132)
Epoch: [6][350/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.2299 (2.2022)	Acc@1 34.375 (39.628)	Acc@5 73.438 (74.148)
Epoch: [6][360/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2672 (2.2029)	Acc@1 38.281 (39.619)	Acc@5 71.875 (74.106)
Epoch: [6][370/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.9988 (2.2015)	Acc@1 43.750 (39.656)	Acc@5 78.125 (74.141)
Epoch: [6][380/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.1707 (2.2004)	Acc@1 33.594 (39.657)	Acc@5 75.000 (74.186)
Epoch: [6][390/391]	Time 0.091 (0.111)	Data 0.001 (0.002)	Loss 2.5661 (2.2015)	Acc@1 33.750 (39.660)	Acc@5 62.500 (74.174)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [7][0/391]	Time 0.124 (0.124)	Data 0.167 (0.167)	Loss 2.3230 (2.3230)	Acc@1 32.812 (32.812)	Acc@5 70.312 (70.312)
Epoch: [7][10/391]	Time 0.112 (0.113)	Data 0.001 (0.016)	Loss 2.2998 (2.2670)	Acc@1 38.281 (37.500)	Acc@5 67.969 (72.656)
Epoch: [7][20/391]	Time 0.111 (0.112)	Data 0.001 (0.009)	Loss 2.1115 (2.2250)	Acc@1 41.406 (38.653)	Acc@5 76.562 (73.958)
Epoch: [7][30/391]	Time 0.113 (0.111)	Data 0.001 (0.007)	Loss 2.1397 (2.2468)	Acc@1 42.969 (38.584)	Acc@5 75.000 (73.488)
Epoch: [7][40/391]	Time 0.111 (0.111)	Data 0.001 (0.005)	Loss 2.0874 (2.2143)	Acc@1 45.312 (39.463)	Acc@5 77.344 (74.314)
Epoch: [7][50/391]	Time 0.115 (0.111)	Data 0.001 (0.004)	Loss 2.1370 (2.1985)	Acc@1 39.062 (39.813)	Acc@5 74.219 (74.556)
Epoch: [7][60/391]	Time 0.115 (0.111)	Data 0.001 (0.004)	Loss 2.3416 (2.1871)	Acc@1 38.281 (40.023)	Acc@5 71.094 (74.782)
Epoch: [7][70/391]	Time 0.108 (0.111)	Data 0.001 (0.004)	Loss 2.2168 (2.1804)	Acc@1 31.250 (40.130)	Acc@5 74.219 (74.890)
Epoch: [7][80/391]	Time 0.113 (0.111)	Data 0.001 (0.003)	Loss 2.0496 (2.1731)	Acc@1 42.969 (40.249)	Acc@5 78.125 (75.077)
Epoch: [7][90/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.1787 (2.1631)	Acc@1 37.500 (40.436)	Acc@5 73.438 (75.189)
Epoch: [7][100/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.2441 (2.1760)	Acc@1 38.281 (40.277)	Acc@5 72.656 (74.876)
Epoch: [7][110/391]	Time 0.112 (0.111)	Data 0.001 (0.003)	Loss 2.0249 (2.1794)	Acc@1 46.094 (40.118)	Acc@5 79.688 (74.704)
Epoch: [7][120/391]	Time 0.113 (0.111)	Data 0.001 (0.003)	Loss 2.0645 (2.1776)	Acc@1 46.875 (40.070)	Acc@5 76.562 (74.780)
Epoch: [7][130/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.2606 (2.1817)	Acc@1 39.844 (39.987)	Acc@5 72.656 (74.767)
Epoch: [7][140/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.3406 (2.1791)	Acc@1 39.844 (39.910)	Acc@5 73.438 (74.900)
Epoch: [7][150/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.0717 (2.1790)	Acc@1 44.531 (39.802)	Acc@5 75.781 (74.912)
Epoch: [7][160/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.3021 (2.1794)	Acc@1 35.156 (39.849)	Acc@5 74.219 (74.913)
Epoch: [7][170/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1189 (2.1802)	Acc@1 44.531 (39.816)	Acc@5 71.094 (74.863)
Epoch: [7][180/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.2131 (2.1788)	Acc@1 35.156 (39.870)	Acc@5 78.906 (74.935)
Epoch: [7][190/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.9814 (2.1783)	Acc@1 46.875 (39.913)	Acc@5 76.562 (74.943)
Epoch: [7][200/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.2272 (2.1785)	Acc@1 40.625 (39.929)	Acc@5 64.844 (74.930)
Epoch: [7][210/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.1232 (2.1788)	Acc@1 38.281 (39.899)	Acc@5 75.781 (74.915)
Epoch: [7][220/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 2.2338 (2.1774)	Acc@1 41.406 (39.925)	Acc@5 75.000 (74.943)
Epoch: [7][230/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.4297 (2.1774)	Acc@1 26.562 (39.911)	Acc@5 71.875 (74.909)
Epoch: [7][240/391]	Time 0.120 (0.112)	Data 0.001 (0.002)	Loss 2.3001 (2.1812)	Acc@1 39.062 (39.896)	Acc@5 74.219 (74.831)
Epoch: [7][250/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2924 (2.1850)	Acc@1 39.844 (39.822)	Acc@5 74.219 (74.714)
Epoch: [7][260/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 2.0543 (2.1851)	Acc@1 42.969 (39.787)	Acc@5 73.438 (74.701)
Epoch: [7][270/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.1716 (2.1825)	Acc@1 41.406 (39.832)	Acc@5 75.781 (74.758)
Epoch: [7][280/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2250 (2.1840)	Acc@1 41.406 (39.824)	Acc@5 74.219 (74.736)
Epoch: [7][290/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2995 (2.1840)	Acc@1 37.500 (39.820)	Acc@5 71.875 (74.753)
Epoch: [7][300/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 2.3076 (2.1871)	Acc@1 35.938 (39.797)	Acc@5 73.438 (74.670)
Epoch: [7][310/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1386 (2.1909)	Acc@1 40.625 (39.675)	Acc@5 76.562 (74.586)
Epoch: [7][320/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.1635 (2.1954)	Acc@1 42.188 (39.540)	Acc@5 78.125 (74.506)
Epoch: [7][330/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2578 (2.1954)	Acc@1 38.281 (39.577)	Acc@5 69.531 (74.481)
Epoch: [7][340/391]	Time 0.119 (0.112)	Data 0.001 (0.002)	Loss 2.3748 (2.1967)	Acc@1 38.281 (39.578)	Acc@5 72.656 (74.448)
Epoch: [7][350/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.3415 (2.1973)	Acc@1 37.500 (39.572)	Acc@5 71.875 (74.401)
Epoch: [7][360/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2306 (2.1971)	Acc@1 40.625 (39.591)	Acc@5 73.438 (74.398)
Epoch: [7][370/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.4851 (2.1999)	Acc@1 28.125 (39.505)	Acc@5 67.969 (74.366)
Epoch: [7][380/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1089 (2.2006)	Acc@1 41.406 (39.524)	Acc@5 75.781 (74.350)
Epoch: [7][390/391]	Time 0.095 (0.112)	Data 0.001 (0.002)	Loss 2.5568 (2.2013)	Acc@1 31.250 (39.514)	Acc@5 65.000 (74.334)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [8][0/391]	Time 0.128 (0.128)	Data 0.170 (0.170)	Loss 2.1778 (2.1778)	Acc@1 37.500 (37.500)	Acc@5 76.562 (76.562)
Epoch: [8][10/391]	Time 0.111 (0.114)	Data 0.001 (0.016)	Loss 2.1148 (2.1333)	Acc@1 41.406 (39.062)	Acc@5 76.562 (75.994)
Epoch: [8][20/391]	Time 0.114 (0.114)	Data 0.001 (0.009)	Loss 2.3510 (2.1714)	Acc@1 38.281 (39.435)	Acc@5 69.531 (74.293)
Epoch: [8][30/391]	Time 0.114 (0.113)	Data 0.001 (0.007)	Loss 1.8069 (2.1631)	Acc@1 45.312 (39.793)	Acc@5 82.031 (74.370)
Epoch: [8][40/391]	Time 0.110 (0.113)	Data 0.001 (0.005)	Loss 2.0974 (2.1529)	Acc@1 40.625 (40.225)	Acc@5 75.781 (74.619)
Epoch: [8][50/391]	Time 0.109 (0.113)	Data 0.001 (0.004)	Loss 2.1862 (2.1604)	Acc@1 44.531 (40.702)	Acc@5 76.562 (74.847)
Epoch: [8][60/391]	Time 0.111 (0.113)	Data 0.001 (0.004)	Loss 2.1982 (2.1639)	Acc@1 37.500 (40.561)	Acc@5 75.781 (74.693)
Epoch: [8][70/391]	Time 0.114 (0.112)	Data 0.001 (0.004)	Loss 2.1347 (2.1566)	Acc@1 41.406 (40.735)	Acc@5 73.438 (74.824)
Epoch: [8][80/391]	Time 0.112 (0.112)	Data 0.001 (0.003)	Loss 2.0181 (2.1658)	Acc@1 43.750 (40.770)	Acc@5 76.562 (74.691)
Epoch: [8][90/391]	Time 0.113 (0.112)	Data 0.001 (0.003)	Loss 2.1908 (2.1680)	Acc@1 38.281 (40.711)	Acc@5 76.562 (74.742)
Epoch: [8][100/391]	Time 0.114 (0.112)	Data 0.001 (0.003)	Loss 2.1202 (2.1696)	Acc@1 36.719 (40.617)	Acc@5 77.344 (74.845)
Epoch: [8][110/391]	Time 0.114 (0.112)	Data 0.001 (0.003)	Loss 2.1024 (2.1694)	Acc@1 46.875 (40.534)	Acc@5 78.125 (74.824)
Epoch: [8][120/391]	Time 0.112 (0.112)	Data 0.001 (0.003)	Loss 1.9530 (2.1673)	Acc@1 46.094 (40.567)	Acc@5 82.812 (75.006)
Epoch: [8][130/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.3799 (2.1728)	Acc@1 35.156 (40.434)	Acc@5 71.094 (74.928)
Epoch: [8][140/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.2443 (2.1743)	Acc@1 35.156 (40.398)	Acc@5 75.000 (74.900)
Epoch: [8][150/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0928 (2.1752)	Acc@1 42.188 (40.397)	Acc@5 77.344 (74.834)
Epoch: [8][160/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.0326 (2.1775)	Acc@1 42.969 (40.373)	Acc@5 78.125 (74.704)
Epoch: [8][170/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0602 (2.1769)	Acc@1 38.281 (40.346)	Acc@5 78.125 (74.708)
Epoch: [8][180/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.2268 (2.1789)	Acc@1 36.719 (40.323)	Acc@5 71.875 (74.633)
Epoch: [8][190/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2252 (2.1792)	Acc@1 39.062 (40.286)	Acc@5 72.656 (74.616)
Epoch: [8][200/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.9438 (2.1748)	Acc@1 45.312 (40.403)	Acc@5 80.469 (74.681)
Epoch: [8][210/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3047 (2.1765)	Acc@1 37.500 (40.399)	Acc@5 69.531 (74.656)
Epoch: [8][220/391]	Time 0.118 (0.112)	Data 0.001 (0.002)	Loss 2.2928 (2.1762)	Acc@1 38.281 (40.392)	Acc@5 72.656 (74.710)
Epoch: [8][230/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.1218 (2.1770)	Acc@1 41.406 (40.361)	Acc@5 71.094 (74.645)
Epoch: [8][240/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.3013 (2.1782)	Acc@1 41.406 (40.314)	Acc@5 72.656 (74.666)
Epoch: [8][250/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.2092 (2.1776)	Acc@1 40.625 (40.360)	Acc@5 72.656 (74.707)
Epoch: [8][260/391]	Time 0.120 (0.112)	Data 0.001 (0.002)	Loss 2.2444 (2.1784)	Acc@1 41.406 (40.332)	Acc@5 73.438 (74.704)
Epoch: [8][270/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.3709 (2.1817)	Acc@1 34.375 (40.239)	Acc@5 70.312 (74.605)
Epoch: [8][280/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1901 (2.1806)	Acc@1 37.500 (40.241)	Acc@5 76.562 (74.594)
Epoch: [8][290/391]	Time 0.118 (0.112)	Data 0.001 (0.002)	Loss 2.2027 (2.1795)	Acc@1 38.281 (40.249)	Acc@5 75.000 (74.579)
Epoch: [8][300/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1143 (2.1808)	Acc@1 42.969 (40.267)	Acc@5 78.906 (74.543)
Epoch: [8][310/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2202 (2.1830)	Acc@1 44.531 (40.183)	Acc@5 73.438 (74.495)
Epoch: [8][320/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2929 (2.1863)	Acc@1 35.938 (40.051)	Acc@5 74.219 (74.430)
Epoch: [8][330/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.2847 (2.1899)	Acc@1 34.375 (39.933)	Acc@5 71.094 (74.353)
Epoch: [8][340/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.3027 (2.1899)	Acc@1 37.500 (39.942)	Acc@5 67.969 (74.340)
Epoch: [8][350/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3149 (2.1927)	Acc@1 42.969 (39.873)	Acc@5 71.094 (74.306)
Epoch: [8][360/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3883 (2.1960)	Acc@1 33.594 (39.792)	Acc@5 73.438 (74.251)
Epoch: [8][370/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.2863 (2.1957)	Acc@1 37.500 (39.829)	Acc@5 70.312 (74.271)
Epoch: [8][380/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.1303 (2.1957)	Acc@1 37.500 (39.786)	Acc@5 79.688 (74.313)
Epoch: [8][390/391]	Time 0.093 (0.112)	Data 0.001 (0.002)	Loss 2.3911 (2.1954)	Acc@1 27.500 (39.816)	Acc@5 70.000 (74.276)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [9][0/391]	Time 0.118 (0.118)	Data 0.171 (0.171)	Loss 2.2188 (2.2188)	Acc@1 39.844 (39.844)	Acc@5 74.219 (74.219)
Epoch: [9][10/391]	Time 0.110 (0.112)	Data 0.001 (0.016)	Loss 2.2123 (2.1673)	Acc@1 38.281 (40.199)	Acc@5 75.781 (75.213)
Epoch: [9][20/391]	Time 0.109 (0.111)	Data 0.001 (0.009)	Loss 2.3886 (2.2052)	Acc@1 35.938 (39.621)	Acc@5 65.625 (75.000)
Epoch: [9][30/391]	Time 0.109 (0.111)	Data 0.001 (0.007)	Loss 2.2184 (2.2200)	Acc@1 38.281 (39.491)	Acc@5 71.094 (74.320)
Epoch: [9][40/391]	Time 0.108 (0.111)	Data 0.001 (0.005)	Loss 2.2290 (2.2197)	Acc@1 37.500 (39.024)	Acc@5 73.438 (74.066)
Epoch: [9][50/391]	Time 0.109 (0.110)	Data 0.001 (0.005)	Loss 2.0311 (2.2176)	Acc@1 39.844 (38.848)	Acc@5 82.812 (74.142)
Epoch: [9][60/391]	Time 0.110 (0.110)	Data 0.001 (0.004)	Loss 2.3930 (2.2140)	Acc@1 39.844 (38.896)	Acc@5 71.094 (74.244)
Epoch: [9][70/391]	Time 0.108 (0.110)	Data 0.001 (0.004)	Loss 2.1431 (2.2106)	Acc@1 43.750 (38.985)	Acc@5 71.875 (74.252)
Epoch: [9][80/391]	Time 0.109 (0.110)	Data 0.001 (0.003)	Loss 2.1208 (2.2080)	Acc@1 38.281 (38.918)	Acc@5 77.344 (74.450)
Epoch: [9][90/391]	Time 0.109 (0.110)	Data 0.001 (0.003)	Loss 2.2345 (2.2052)	Acc@1 36.719 (38.951)	Acc@5 76.562 (74.596)
Epoch: [9][100/391]	Time 0.108 (0.110)	Data 0.001 (0.003)	Loss 1.8454 (2.2066)	Acc@1 50.781 (39.093)	Acc@5 80.469 (74.582)
Epoch: [9][110/391]	Time 0.107 (0.110)	Data 0.001 (0.003)	Loss 2.2260 (2.1996)	Acc@1 39.062 (39.330)	Acc@5 71.875 (74.747)
Epoch: [9][120/391]	Time 0.108 (0.110)	Data 0.001 (0.003)	Loss 2.1831 (2.1920)	Acc@1 38.281 (39.560)	Acc@5 71.094 (74.884)
Epoch: [9][130/391]	Time 0.108 (0.110)	Data 0.001 (0.002)	Loss 2.1457 (2.1964)	Acc@1 42.969 (39.516)	Acc@5 72.656 (74.773)
Epoch: [9][140/391]	Time 0.110 (0.110)	Data 0.001 (0.002)	Loss 2.1546 (2.1993)	Acc@1 39.844 (39.561)	Acc@5 75.781 (74.673)
Epoch: [9][150/391]	Time 0.113 (0.110)	Data 0.001 (0.002)	Loss 2.2695 (2.2016)	Acc@1 38.281 (39.513)	Acc@5 73.438 (74.550)
Epoch: [9][160/391]	Time 0.107 (0.110)	Data 0.001 (0.002)	Loss 2.2460 (2.2028)	Acc@1 35.156 (39.441)	Acc@5 70.312 (74.515)
Epoch: [9][170/391]	Time 0.112 (0.110)	Data 0.001 (0.002)	Loss 2.0291 (2.2003)	Acc@1 42.188 (39.574)	Acc@5 75.000 (74.511)
Epoch: [9][180/391]	Time 0.110 (0.110)	Data 0.001 (0.002)	Loss 2.1005 (2.1991)	Acc@1 42.969 (39.585)	Acc@5 77.344 (74.486)
Epoch: [9][190/391]	Time 0.112 (0.110)	Data 0.001 (0.002)	Loss 2.0159 (2.2000)	Acc@1 42.188 (39.611)	Acc@5 80.469 (74.370)
Epoch: [9][200/391]	Time 0.107 (0.110)	Data 0.001 (0.002)	Loss 2.3135 (2.1985)	Acc@1 34.375 (39.688)	Acc@5 73.438 (74.433)
Epoch: [9][210/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2298 (2.1986)	Acc@1 36.719 (39.633)	Acc@5 74.219 (74.459)
Epoch: [9][220/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.0633 (2.1986)	Acc@1 47.656 (39.596)	Acc@5 76.562 (74.473)
Epoch: [9][230/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.3095 (2.2018)	Acc@1 40.625 (39.583)	Acc@5 70.312 (74.442)
Epoch: [9][240/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0251 (2.1994)	Acc@1 43.750 (39.685)	Acc@5 78.906 (74.472)
Epoch: [9][250/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1811 (2.1978)	Acc@1 35.938 (39.657)	Acc@5 76.562 (74.468)
Epoch: [9][260/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0577 (2.1984)	Acc@1 41.406 (39.679)	Acc@5 75.000 (74.431)
Epoch: [9][270/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1965 (2.1945)	Acc@1 48.438 (39.775)	Acc@5 72.656 (74.542)
Epoch: [9][280/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0163 (2.1950)	Acc@1 43.750 (39.735)	Acc@5 79.688 (74.527)
Epoch: [9][290/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9484 (2.1954)	Acc@1 45.312 (39.712)	Acc@5 82.031 (74.501)
Epoch: [9][300/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1338 (2.1966)	Acc@1 46.094 (39.709)	Acc@5 77.344 (74.476)
Epoch: [9][310/391]	Time 0.111 (0.110)	Data 0.001 (0.002)	Loss 2.2860 (2.1963)	Acc@1 36.719 (39.663)	Acc@5 72.656 (74.472)
Epoch: [9][320/391]	Time 0.105 (0.111)	Data 0.001 (0.002)	Loss 2.2564 (2.1974)	Acc@1 39.062 (39.642)	Acc@5 75.781 (74.469)
Epoch: [9][330/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2100 (2.1971)	Acc@1 36.719 (39.674)	Acc@5 77.344 (74.476)
Epoch: [9][340/391]	Time 0.110 (0.110)	Data 0.001 (0.002)	Loss 2.3642 (2.1981)	Acc@1 37.500 (39.672)	Acc@5 67.969 (74.471)
Epoch: [9][350/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 1.9830 (2.1968)	Acc@1 44.531 (39.690)	Acc@5 79.688 (74.475)
Epoch: [9][360/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3516 (2.1969)	Acc@1 38.281 (39.677)	Acc@5 67.188 (74.461)
Epoch: [9][370/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 2.2510 (2.1970)	Acc@1 39.062 (39.639)	Acc@5 72.656 (74.467)
Epoch: [9][380/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2118 (2.1963)	Acc@1 41.406 (39.710)	Acc@5 76.562 (74.508)
Epoch: [9][390/391]	Time 0.092 (0.111)	Data 0.001 (0.002)	Loss 1.9377 (2.1980)	Acc@1 46.250 (39.692)	Acc@5 80.000 (74.498)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [10][0/391]	Time 0.125 (0.125)	Data 0.170 (0.170)	Loss 2.0938 (2.0938)	Acc@1 46.094 (46.094)	Acc@5 78.125 (78.125)
Epoch: [10][10/391]	Time 0.110 (0.113)	Data 0.001 (0.016)	Loss 2.4268 (2.2158)	Acc@1 32.031 (38.281)	Acc@5 68.750 (75.000)
Epoch: [10][20/391]	Time 0.110 (0.113)	Data 0.001 (0.009)	Loss 2.0237 (2.1803)	Acc@1 42.188 (39.472)	Acc@5 78.906 (75.260)
Epoch: [10][30/391]	Time 0.113 (0.112)	Data 0.001 (0.007)	Loss 2.3916 (2.1834)	Acc@1 33.594 (39.264)	Acc@5 69.531 (74.899)
Epoch: [10][40/391]	Time 0.113 (0.112)	Data 0.001 (0.005)	Loss 2.4534 (2.1945)	Acc@1 35.156 (39.882)	Acc@5 68.750 (74.562)
Epoch: [10][50/391]	Time 0.112 (0.112)	Data 0.001 (0.004)	Loss 2.2538 (2.1835)	Acc@1 31.250 (39.936)	Acc@5 74.219 (74.556)
Epoch: [10][60/391]	Time 0.119 (0.112)	Data 0.001 (0.004)	Loss 2.2347 (2.1961)	Acc@1 32.812 (39.344)	Acc@5 76.562 (74.513)
Epoch: [10][70/391]	Time 0.114 (0.112)	Data 0.001 (0.004)	Loss 2.0448 (2.2018)	Acc@1 46.875 (39.250)	Acc@5 75.781 (74.285)
Epoch: [10][80/391]	Time 0.118 (0.112)	Data 0.002 (0.003)	Loss 2.3502 (2.2098)	Acc@1 32.812 (39.149)	Acc@5 72.656 (73.929)
Epoch: [10][90/391]	Time 0.111 (0.113)	Data 0.001 (0.003)	Loss 2.1173 (2.2094)	Acc@1 43.750 (39.088)	Acc@5 76.562 (73.910)
Epoch: [10][100/391]	Time 0.109 (0.113)	Data 0.001 (0.003)	Loss 2.2293 (2.2169)	Acc@1 39.844 (38.908)	Acc@5 71.094 (73.700)
Epoch: [10][110/391]	Time 0.112 (0.113)	Data 0.001 (0.003)	Loss 2.1836 (2.2212)	Acc@1 46.094 (38.971)	Acc@5 71.094 (73.628)
Epoch: [10][120/391]	Time 0.112 (0.113)	Data 0.001 (0.003)	Loss 2.1655 (2.2219)	Acc@1 39.844 (38.927)	Acc@5 73.438 (73.657)
Epoch: [10][130/391]	Time 0.112 (0.113)	Data 0.001 (0.002)	Loss 2.2525 (2.2210)	Acc@1 39.062 (38.848)	Acc@5 72.656 (73.783)
Epoch: [10][140/391]	Time 0.109 (0.113)	Data 0.001 (0.002)	Loss 2.2774 (2.2221)	Acc@1 34.375 (38.863)	Acc@5 69.531 (73.670)
Epoch: [10][150/391]	Time 0.113 (0.113)	Data 0.001 (0.002)	Loss 2.1148 (2.2233)	Acc@1 42.969 (38.737)	Acc@5 74.219 (73.608)
Epoch: [10][160/391]	Time 0.114 (0.113)	Data 0.001 (0.002)	Loss 2.0870 (2.2205)	Acc@1 45.312 (38.902)	Acc@5 73.438 (73.627)
Epoch: [10][170/391]	Time 0.109 (0.113)	Data 0.001 (0.002)	Loss 2.0870 (2.2208)	Acc@1 43.750 (38.921)	Acc@5 80.469 (73.607)
Epoch: [10][180/391]	Time 0.112 (0.113)	Data 0.001 (0.002)	Loss 2.1414 (2.2160)	Acc@1 38.281 (38.950)	Acc@5 80.469 (73.701)
Epoch: [10][190/391]	Time 0.108 (0.113)	Data 0.001 (0.002)	Loss 2.2073 (2.2134)	Acc@1 35.156 (38.944)	Acc@5 68.750 (73.761)
Epoch: [10][200/391]	Time 0.109 (0.113)	Data 0.001 (0.002)	Loss 1.9606 (2.2060)	Acc@1 46.094 (39.144)	Acc@5 76.562 (73.943)
Epoch: [10][210/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.1730 (2.2043)	Acc@1 35.938 (39.140)	Acc@5 78.125 (74.063)
Epoch: [10][220/391]	Time 0.113 (0.113)	Data 0.001 (0.002)	Loss 2.2902 (2.2022)	Acc@1 35.156 (39.154)	Acc@5 75.781 (74.194)
Epoch: [10][230/391]	Time 0.119 (0.113)	Data 0.001 (0.002)	Loss 2.0603 (2.2011)	Acc@1 42.969 (39.164)	Acc@5 76.562 (74.198)
Epoch: [10][240/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.0987 (2.2004)	Acc@1 45.312 (39.195)	Acc@5 70.312 (74.141)
Epoch: [10][250/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.2865 (2.2023)	Acc@1 36.719 (39.156)	Acc@5 74.219 (74.100)
Epoch: [10][260/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.0946 (2.1992)	Acc@1 39.062 (39.242)	Acc@5 78.906 (74.180)
Epoch: [10][270/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.3621 (2.1999)	Acc@1 37.500 (39.259)	Acc@5 72.656 (74.196)
Epoch: [10][280/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.0746 (2.1997)	Acc@1 40.625 (39.285)	Acc@5 76.562 (74.185)
Epoch: [10][290/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.3574 (2.2009)	Acc@1 37.500 (39.275)	Acc@5 66.406 (74.192)
Epoch: [10][300/391]	Time 0.106 (0.112)	Data 0.001 (0.002)	Loss 2.3265 (2.2005)	Acc@1 32.812 (39.249)	Acc@5 73.438 (74.203)
Epoch: [10][310/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.1940 (2.2004)	Acc@1 40.625 (39.261)	Acc@5 79.688 (74.224)
Epoch: [10][320/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.1779 (2.1993)	Acc@1 41.406 (39.274)	Acc@5 74.219 (74.265)
Epoch: [10][330/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.0987 (2.1973)	Acc@1 42.969 (39.275)	Acc@5 73.438 (74.294)
Epoch: [10][340/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.2815 (2.1998)	Acc@1 43.750 (39.250)	Acc@5 77.344 (74.255)
Epoch: [10][350/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.1528 (2.1995)	Acc@1 38.281 (39.261)	Acc@5 75.781 (74.272)
Epoch: [10][360/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.1864 (2.1982)	Acc@1 39.062 (39.322)	Acc@5 74.219 (74.320)
Epoch: [10][370/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 1.9801 (2.1991)	Acc@1 42.188 (39.317)	Acc@5 77.344 (74.292)
Epoch: [10][380/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.2446 (2.1991)	Acc@1 38.281 (39.321)	Acc@5 75.000 (74.329)
Epoch: [10][390/391]	Time 0.092 (0.112)	Data 0.001 (0.002)	Loss 2.3167 (2.1988)	Acc@1 30.000 (39.338)	Acc@5 68.750 (74.282)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [11][0/391]	Time 0.125 (0.125)	Data 0.167 (0.167)	Loss 2.1435 (2.1435)	Acc@1 39.062 (39.062)	Acc@5 78.906 (78.906)
Epoch: [11][10/391]	Time 0.111 (0.114)	Data 0.001 (0.016)	Loss 2.3171 (2.1974)	Acc@1 36.719 (37.926)	Acc@5 68.750 (74.148)
Epoch: [11][20/391]	Time 0.110 (0.113)	Data 0.001 (0.009)	Loss 1.9538 (2.1878)	Acc@1 42.188 (39.025)	Acc@5 81.250 (74.628)
Epoch: [11][30/391]	Time 0.110 (0.113)	Data 0.001 (0.006)	Loss 2.0674 (2.1673)	Acc@1 46.094 (39.415)	Acc@5 78.906 (75.353)
Epoch: [11][40/391]	Time 0.108 (0.112)	Data 0.001 (0.005)	Loss 2.2598 (2.1649)	Acc@1 32.812 (39.463)	Acc@5 75.000 (75.400)
Epoch: [11][50/391]	Time 0.115 (0.113)	Data 0.001 (0.004)	Loss 2.0515 (2.1562)	Acc@1 42.188 (39.752)	Acc@5 80.469 (75.705)
Epoch: [11][60/391]	Time 0.114 (0.113)	Data 0.001 (0.004)	Loss 2.3156 (2.1727)	Acc@1 40.625 (39.408)	Acc@5 67.969 (74.872)
Epoch: [11][70/391]	Time 0.113 (0.113)	Data 0.001 (0.003)	Loss 2.2929 (2.1640)	Acc@1 35.938 (39.855)	Acc@5 71.875 (74.879)
Epoch: [11][80/391]	Time 0.115 (0.113)	Data 0.001 (0.003)	Loss 2.4107 (2.1705)	Acc@1 28.125 (39.747)	Acc@5 72.656 (74.855)
Epoch: [11][90/391]	Time 0.113 (0.113)	Data 0.001 (0.003)	Loss 1.9784 (2.1820)	Acc@1 46.875 (39.655)	Acc@5 75.781 (74.742)
Epoch: [11][100/391]	Time 0.117 (0.113)	Data 0.001 (0.003)	Loss 2.1139 (2.1828)	Acc@1 42.969 (39.534)	Acc@5 80.469 (74.853)
Epoch: [11][110/391]	Time 0.111 (0.113)	Data 0.001 (0.003)	Loss 2.0551 (2.1827)	Acc@1 37.500 (39.548)	Acc@5 77.344 (74.894)
Epoch: [11][120/391]	Time 0.109 (0.113)	Data 0.001 (0.002)	Loss 1.9097 (2.1794)	Acc@1 50.781 (39.605)	Acc@5 78.906 (74.935)
Epoch: [11][130/391]	Time 0.114 (0.113)	Data 0.001 (0.002)	Loss 2.2747 (2.1772)	Acc@1 42.188 (39.665)	Acc@5 71.094 (74.970)
Epoch: [11][140/391]	Time 0.109 (0.113)	Data 0.001 (0.002)	Loss 1.9746 (2.1770)	Acc@1 36.719 (39.694)	Acc@5 81.250 (74.911)
Epoch: [11][150/391]	Time 0.113 (0.113)	Data 0.001 (0.002)	Loss 2.2075 (2.1842)	Acc@1 35.156 (39.507)	Acc@5 75.781 (74.731)
Epoch: [11][160/391]	Time 0.110 (0.113)	Data 0.001 (0.002)	Loss 2.0699 (2.1816)	Acc@1 39.062 (39.621)	Acc@5 76.562 (74.757)
Epoch: [11][170/391]	Time 0.111 (0.113)	Data 0.001 (0.002)	Loss 2.0994 (2.1821)	Acc@1 39.844 (39.624)	Acc@5 75.781 (74.730)
Epoch: [11][180/391]	Time 0.108 (0.113)	Data 0.001 (0.002)	Loss 2.1027 (2.1826)	Acc@1 41.406 (39.611)	Acc@5 77.344 (74.711)
Epoch: [11][190/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 1.8930 (2.1845)	Acc@1 48.438 (39.656)	Acc@5 85.156 (74.652)
Epoch: [11][200/391]	Time 0.106 (0.112)	Data 0.001 (0.002)	Loss 2.1533 (2.1871)	Acc@1 41.406 (39.544)	Acc@5 72.656 (74.654)
Epoch: [11][210/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.0401 (2.1903)	Acc@1 31.250 (39.455)	Acc@5 78.906 (74.541)
Epoch: [11][220/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.1224 (2.1937)	Acc@1 37.500 (39.391)	Acc@5 76.562 (74.456)
Epoch: [11][230/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.0329 (2.1960)	Acc@1 43.750 (39.350)	Acc@5 77.344 (74.398)
Epoch: [11][240/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.3576 (2.1938)	Acc@1 36.719 (39.474)	Acc@5 75.781 (74.465)
Epoch: [11][250/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.3376 (2.1940)	Acc@1 35.938 (39.470)	Acc@5 71.094 (74.449)
Epoch: [11][260/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1922 (2.1936)	Acc@1 37.500 (39.529)	Acc@5 75.000 (74.473)
Epoch: [11][270/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0624 (2.1941)	Acc@1 42.188 (39.567)	Acc@5 73.438 (74.429)
Epoch: [11][280/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2471 (2.1930)	Acc@1 42.188 (39.591)	Acc@5 74.219 (74.438)
Epoch: [11][290/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2523 (2.1961)	Acc@1 35.938 (39.543)	Acc@5 72.656 (74.356)
Epoch: [11][300/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.3681 (2.1955)	Acc@1 35.938 (39.532)	Acc@5 65.625 (74.351)
Epoch: [11][310/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.0874 (2.1966)	Acc@1 35.938 (39.487)	Acc@5 78.906 (74.327)
Epoch: [11][320/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 1.9928 (2.1940)	Acc@1 43.750 (39.515)	Acc@5 80.469 (74.379)
Epoch: [11][330/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.0152 (2.1935)	Acc@1 45.312 (39.544)	Acc@5 74.219 (74.391)
Epoch: [11][340/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.2102 (2.1949)	Acc@1 39.062 (39.516)	Acc@5 73.438 (74.340)
Epoch: [11][350/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0647 (2.1959)	Acc@1 43.750 (39.519)	Acc@5 81.250 (74.319)
Epoch: [11][360/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.2609 (2.1957)	Acc@1 35.938 (39.495)	Acc@5 71.875 (74.329)
Epoch: [11][370/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.0893 (2.1959)	Acc@1 44.531 (39.513)	Acc@5 75.000 (74.307)
Epoch: [11][380/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.4094 (2.1973)	Acc@1 33.594 (39.473)	Acc@5 69.531 (74.256)
Epoch: [11][390/391]	Time 0.095 (0.112)	Data 0.001 (0.002)	Loss 2.5212 (2.1983)	Acc@1 28.750 (39.472)	Acc@5 66.250 (74.242)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [12][0/391]	Time 0.124 (0.124)	Data 0.165 (0.165)	Loss 1.9210 (1.9210)	Acc@1 46.094 (46.094)	Acc@5 80.469 (80.469)
Epoch: [12][10/391]	Time 0.110 (0.113)	Data 0.001 (0.016)	Loss 2.2553 (2.1921)	Acc@1 42.969 (39.773)	Acc@5 70.312 (75.426)
Epoch: [12][20/391]	Time 0.108 (0.111)	Data 0.001 (0.009)	Loss 2.3888 (2.1687)	Acc@1 35.938 (40.699)	Acc@5 73.438 (76.116)
Epoch: [12][30/391]	Time 0.111 (0.111)	Data 0.001 (0.006)	Loss 1.9892 (2.1439)	Acc@1 40.625 (40.852)	Acc@5 78.125 (76.260)
Epoch: [12][40/391]	Time 0.109 (0.111)	Data 0.001 (0.005)	Loss 2.1231 (2.1468)	Acc@1 37.500 (40.892)	Acc@5 75.781 (75.953)
Epoch: [12][50/391]	Time 0.110 (0.111)	Data 0.001 (0.004)	Loss 2.1922 (2.1557)	Acc@1 38.281 (40.748)	Acc@5 73.438 (75.659)
Epoch: [12][60/391]	Time 0.112 (0.111)	Data 0.001 (0.004)	Loss 2.3622 (2.1586)	Acc@1 39.062 (40.843)	Acc@5 71.875 (75.653)
Epoch: [12][70/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.1400 (2.1682)	Acc@1 42.969 (40.867)	Acc@5 74.219 (75.308)
Epoch: [12][80/391]	Time 0.112 (0.111)	Data 0.001 (0.003)	Loss 2.3979 (2.1770)	Acc@1 38.281 (40.741)	Acc@5 69.531 (74.990)
Epoch: [12][90/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.0830 (2.1852)	Acc@1 37.500 (40.436)	Acc@5 83.594 (74.742)
Epoch: [12][100/391]	Time 0.123 (0.111)	Data 0.001 (0.003)	Loss 2.3308 (2.1838)	Acc@1 40.625 (40.555)	Acc@5 68.750 (74.822)
Epoch: [12][110/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.0100 (2.1826)	Acc@1 35.938 (40.435)	Acc@5 77.344 (74.838)
Epoch: [12][120/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.2427 (2.1831)	Acc@1 42.969 (40.464)	Acc@5 74.219 (74.839)
Epoch: [12][130/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2988 (2.1846)	Acc@1 35.156 (40.380)	Acc@5 74.219 (74.922)
Epoch: [12][140/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0217 (2.1834)	Acc@1 42.969 (40.492)	Acc@5 80.469 (74.889)
Epoch: [12][150/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3100 (2.1894)	Acc@1 39.062 (40.247)	Acc@5 71.094 (74.715)
Epoch: [12][160/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2067 (2.1885)	Acc@1 37.500 (40.125)	Acc@5 75.000 (74.714)
Epoch: [12][170/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2021 (2.1850)	Acc@1 35.938 (40.191)	Acc@5 75.781 (74.730)
Epoch: [12][180/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3340 (2.1897)	Acc@1 37.500 (40.155)	Acc@5 74.219 (74.659)
Epoch: [12][190/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.4177 (2.1919)	Acc@1 35.938 (40.118)	Acc@5 67.969 (74.607)
Epoch: [12][200/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.2082 (2.1941)	Acc@1 36.719 (40.065)	Acc@5 78.125 (74.530)
Epoch: [12][210/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2008 (2.1926)	Acc@1 38.281 (40.099)	Acc@5 72.656 (74.563)
Epoch: [12][220/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.0703 (2.1919)	Acc@1 46.094 (40.130)	Acc@5 78.906 (74.629)
Epoch: [12][230/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1016 (2.1970)	Acc@1 40.625 (40.009)	Acc@5 75.781 (74.543)
Epoch: [12][240/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.7430 (2.2002)	Acc@1 27.344 (39.899)	Acc@5 64.844 (74.485)
Epoch: [12][250/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0053 (2.1984)	Acc@1 43.750 (39.900)	Acc@5 79.688 (74.592)
Epoch: [12][260/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1175 (2.1965)	Acc@1 41.406 (39.889)	Acc@5 74.219 (74.602)
Epoch: [12][270/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 2.0554 (2.1943)	Acc@1 42.188 (39.994)	Acc@5 78.125 (74.637)
Epoch: [12][280/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1228 (2.1909)	Acc@1 43.750 (40.097)	Acc@5 77.344 (74.650)
Epoch: [12][290/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1084 (2.1896)	Acc@1 44.531 (40.059)	Acc@5 76.562 (74.699)
Epoch: [12][300/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2848 (2.1904)	Acc@1 42.969 (40.057)	Acc@5 71.094 (74.642)
Epoch: [12][310/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.4503 (2.1933)	Acc@1 35.938 (40.020)	Acc@5 69.531 (74.568)
Epoch: [12][320/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 1.9992 (2.1924)	Acc@1 46.094 (40.004)	Acc@5 82.031 (74.584)
Epoch: [12][330/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2136 (2.1922)	Acc@1 40.625 (39.992)	Acc@5 70.312 (74.585)
Epoch: [12][340/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9664 (2.1904)	Acc@1 45.312 (40.006)	Acc@5 77.344 (74.629)
Epoch: [12][350/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2815 (2.1904)	Acc@1 33.594 (40.002)	Acc@5 69.531 (74.608)
Epoch: [12][360/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2179 (2.1896)	Acc@1 41.406 (40.058)	Acc@5 77.344 (74.632)
Epoch: [12][370/391]	Time 0.118 (0.111)	Data 0.001 (0.002)	Loss 2.1570 (2.1901)	Acc@1 44.531 (40.088)	Acc@5 76.562 (74.646)
Epoch: [12][380/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.3270 (2.1886)	Acc@1 34.375 (40.164)	Acc@5 74.219 (74.660)
Epoch: [12][390/391]	Time 0.093 (0.111)	Data 0.001 (0.002)	Loss 2.1334 (2.1872)	Acc@1 40.000 (40.180)	Acc@5 73.750 (74.666)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [13][0/391]	Time 0.132 (0.132)	Data 0.178 (0.178)	Loss 2.3131 (2.3131)	Acc@1 34.375 (34.375)	Acc@5 71.094 (71.094)
Epoch: [13][10/391]	Time 0.109 (0.112)	Data 0.001 (0.017)	Loss 2.0724 (2.1832)	Acc@1 42.188 (40.341)	Acc@5 75.781 (73.793)
Epoch: [13][20/391]	Time 0.110 (0.112)	Data 0.001 (0.009)	Loss 2.3696 (2.1758)	Acc@1 35.156 (40.699)	Acc@5 67.188 (74.107)
Epoch: [13][30/391]	Time 0.110 (0.112)	Data 0.001 (0.007)	Loss 2.2007 (2.1626)	Acc@1 43.750 (40.978)	Acc@5 73.438 (74.496)
Epoch: [13][40/391]	Time 0.114 (0.112)	Data 0.001 (0.005)	Loss 2.0975 (2.1730)	Acc@1 42.188 (40.111)	Acc@5 73.438 (74.428)
Epoch: [13][50/391]	Time 0.111 (0.112)	Data 0.002 (0.005)	Loss 1.9351 (2.1664)	Acc@1 52.344 (40.702)	Acc@5 85.156 (74.801)
Epoch: [13][60/391]	Time 0.112 (0.112)	Data 0.001 (0.004)	Loss 2.0914 (2.1783)	Acc@1 39.844 (40.164)	Acc@5 80.469 (74.974)
Epoch: [13][70/391]	Time 0.116 (0.112)	Data 0.001 (0.004)	Loss 2.1994 (2.1799)	Acc@1 41.406 (40.097)	Acc@5 73.438 (75.033)
Epoch: [13][80/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.2828 (2.1726)	Acc@1 37.500 (40.461)	Acc@5 72.656 (75.125)
Epoch: [13][90/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.1661 (2.1725)	Acc@1 38.281 (40.479)	Acc@5 71.875 (74.888)
Epoch: [13][100/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.3216 (2.1732)	Acc@1 41.406 (40.393)	Acc@5 71.094 (74.822)
Epoch: [13][110/391]	Time 0.111 (0.112)	Data 0.002 (0.003)	Loss 2.3588 (2.1827)	Acc@1 34.375 (40.168)	Acc@5 72.656 (74.669)
Epoch: [13][120/391]	Time 0.111 (0.112)	Data 0.001 (0.003)	Loss 2.2537 (2.1865)	Acc@1 40.625 (40.018)	Acc@5 65.625 (74.574)
Epoch: [13][130/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.1044 (2.1912)	Acc@1 40.625 (39.921)	Acc@5 75.000 (74.481)
Epoch: [13][140/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.0092 (2.1874)	Acc@1 50.000 (39.993)	Acc@5 82.031 (74.540)
Epoch: [13][150/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.3064 (2.1901)	Acc@1 35.938 (39.901)	Acc@5 75.000 (74.436)
Epoch: [13][160/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.1060 (2.1857)	Acc@1 43.750 (39.999)	Acc@5 75.000 (74.524)
Epoch: [13][170/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.2406 (2.1845)	Acc@1 39.844 (40.068)	Acc@5 74.219 (74.552)
Epoch: [13][180/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.3087 (2.1879)	Acc@1 34.375 (40.012)	Acc@5 71.094 (74.456)
Epoch: [13][190/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 1.9669 (2.1861)	Acc@1 46.875 (39.983)	Acc@5 79.688 (74.562)
Epoch: [13][200/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.0809 (2.1881)	Acc@1 38.281 (39.871)	Acc@5 77.344 (74.588)
Epoch: [13][210/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.0510 (2.1868)	Acc@1 40.625 (39.936)	Acc@5 75.000 (74.582)
Epoch: [13][220/391]	Time 0.116 (0.112)	Data 0.001 (0.002)	Loss 2.0624 (2.1861)	Acc@1 46.094 (40.010)	Acc@5 75.781 (74.583)
Epoch: [13][230/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.0631 (2.1833)	Acc@1 42.188 (40.037)	Acc@5 73.438 (74.594)
Epoch: [13][240/391]	Time 0.117 (0.112)	Data 0.001 (0.002)	Loss 2.2046 (2.1818)	Acc@1 38.281 (40.067)	Acc@5 73.438 (74.656)
Epoch: [13][250/391]	Time 0.117 (0.112)	Data 0.001 (0.002)	Loss 2.1491 (2.1829)	Acc@1 42.969 (40.090)	Acc@5 73.438 (74.639)
Epoch: [13][260/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.1782 (2.1831)	Acc@1 39.844 (40.056)	Acc@5 77.344 (74.617)
Epoch: [13][270/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.2962 (2.1833)	Acc@1 37.500 (40.017)	Acc@5 75.781 (74.622)
Epoch: [13][280/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.2016 (2.1825)	Acc@1 40.625 (40.055)	Acc@5 80.469 (74.694)
Epoch: [13][290/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.4528 (2.1841)	Acc@1 37.500 (39.997)	Acc@5 69.531 (74.675)
Epoch: [13][300/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2763 (2.1869)	Acc@1 37.500 (39.875)	Acc@5 74.219 (74.657)
Epoch: [13][310/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2766 (2.1891)	Acc@1 34.375 (39.804)	Acc@5 67.188 (74.596)
Epoch: [13][320/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.3322 (2.1892)	Acc@1 41.406 (39.827)	Acc@5 66.406 (74.613)
Epoch: [13][330/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4930 (2.1916)	Acc@1 34.375 (39.818)	Acc@5 63.281 (74.526)
Epoch: [13][340/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1338 (2.1909)	Acc@1 39.062 (39.839)	Acc@5 76.562 (74.523)
Epoch: [13][350/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1862 (2.1937)	Acc@1 40.625 (39.781)	Acc@5 74.219 (74.419)
Epoch: [13][360/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1458 (2.1938)	Acc@1 38.281 (39.785)	Acc@5 76.562 (74.392)
Epoch: [13][370/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1944 (2.1953)	Acc@1 37.500 (39.713)	Acc@5 73.438 (74.343)
Epoch: [13][380/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2378 (2.1935)	Acc@1 38.281 (39.715)	Acc@5 74.219 (74.373)
Epoch: [13][390/391]	Time 0.092 (0.111)	Data 0.001 (0.002)	Loss 2.5029 (2.1928)	Acc@1 31.250 (39.678)	Acc@5 70.000 (74.404)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [14][0/391]	Time 0.124 (0.124)	Data 0.186 (0.186)	Loss 2.0093 (2.0093)	Acc@1 40.625 (40.625)	Acc@5 78.125 (78.125)
Epoch: [14][10/391]	Time 0.108 (0.112)	Data 0.001 (0.018)	Loss 2.1789 (2.1768)	Acc@1 41.406 (40.696)	Acc@5 78.125 (75.497)
Epoch: [14][20/391]	Time 0.115 (0.112)	Data 0.001 (0.010)	Loss 2.1668 (2.1779)	Acc@1 44.531 (41.257)	Acc@5 76.562 (75.186)
Epoch: [14][30/391]	Time 0.109 (0.112)	Data 0.001 (0.007)	Loss 2.1118 (2.1961)	Acc@1 42.188 (40.449)	Acc@5 72.656 (74.395)
Epoch: [14][40/391]	Time 0.113 (0.111)	Data 0.001 (0.006)	Loss 2.1774 (2.1643)	Acc@1 42.969 (41.178)	Acc@5 74.219 (75.305)
Epoch: [14][50/391]	Time 0.108 (0.111)	Data 0.001 (0.005)	Loss 2.0070 (2.1540)	Acc@1 43.750 (41.131)	Acc@5 80.469 (75.582)
Epoch: [14][60/391]	Time 0.114 (0.111)	Data 0.001 (0.004)	Loss 2.3871 (2.1643)	Acc@1 34.375 (40.612)	Acc@5 68.750 (75.141)
Epoch: [14][70/391]	Time 0.108 (0.111)	Data 0.001 (0.004)	Loss 2.1715 (2.1590)	Acc@1 39.062 (40.559)	Acc@5 76.562 (75.275)
Epoch: [14][80/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.1887 (2.1603)	Acc@1 41.406 (40.606)	Acc@5 71.875 (75.106)
Epoch: [14][90/391]	Time 0.112 (0.111)	Data 0.001 (0.003)	Loss 2.3816 (2.1596)	Acc@1 34.375 (40.694)	Acc@5 68.750 (75.026)
Epoch: [14][100/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 1.9728 (2.1531)	Acc@1 39.844 (40.780)	Acc@5 76.562 (75.155)
Epoch: [14][110/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.2215 (2.1552)	Acc@1 37.500 (40.667)	Acc@5 76.562 (75.134)
Epoch: [14][120/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.4347 (2.1633)	Acc@1 26.562 (40.431)	Acc@5 74.219 (75.019)
Epoch: [14][130/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.2467 (2.1750)	Acc@1 39.062 (40.208)	Acc@5 71.094 (74.809)
Epoch: [14][140/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0962 (2.1773)	Acc@1 37.500 (40.038)	Acc@5 78.125 (74.729)
Epoch: [14][150/391]	Time 0.118 (0.111)	Data 0.001 (0.002)	Loss 2.2283 (2.1835)	Acc@1 39.062 (40.082)	Acc@5 66.406 (74.524)
Epoch: [14][160/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.5396 (2.1877)	Acc@1 30.469 (39.955)	Acc@5 67.188 (74.524)
Epoch: [14][170/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.4575 (2.1905)	Acc@1 34.375 (39.807)	Acc@5 69.531 (74.493)
Epoch: [14][180/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2449 (2.1933)	Acc@1 44.531 (39.766)	Acc@5 72.656 (74.448)
Epoch: [14][190/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 1.9571 (2.1915)	Acc@1 44.531 (39.754)	Acc@5 79.688 (74.399)
Epoch: [14][200/391]	Time 0.119 (0.112)	Data 0.001 (0.002)	Loss 1.9880 (2.1937)	Acc@1 44.531 (39.692)	Acc@5 79.688 (74.324)
Epoch: [14][210/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.0789 (2.1953)	Acc@1 43.750 (39.714)	Acc@5 75.000 (74.278)
Epoch: [14][220/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.2341 (2.1968)	Acc@1 39.062 (39.603)	Acc@5 75.000 (74.275)
Epoch: [14][230/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.3160 (2.1968)	Acc@1 34.375 (39.573)	Acc@5 70.312 (74.198)
Epoch: [14][240/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2921 (2.1968)	Acc@1 40.625 (39.571)	Acc@5 71.875 (74.232)
Epoch: [14][250/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.2046 (2.1977)	Acc@1 35.938 (39.579)	Acc@5 76.562 (74.253)
Epoch: [14][260/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.4356 (2.1975)	Acc@1 32.812 (39.676)	Acc@5 64.844 (74.228)
Epoch: [14][270/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1234 (2.1945)	Acc@1 50.781 (39.708)	Acc@5 72.656 (74.288)
Epoch: [14][280/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.0007 (2.1934)	Acc@1 41.406 (39.721)	Acc@5 77.344 (74.313)
Epoch: [14][290/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.2496 (2.1928)	Acc@1 28.906 (39.726)	Acc@5 74.219 (74.321)
Epoch: [14][300/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.2715 (2.1916)	Acc@1 37.500 (39.758)	Acc@5 74.219 (74.377)
Epoch: [14][310/391]	Time 0.109 (0.112)	Data 0.001 (0.002)	Loss 2.1015 (2.1917)	Acc@1 40.625 (39.726)	Acc@5 75.000 (74.380)
Epoch: [14][320/391]	Time 0.112 (0.112)	Data 0.001 (0.002)	Loss 2.5018 (2.1917)	Acc@1 35.938 (39.766)	Acc@5 68.750 (74.350)
Epoch: [14][330/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.0937 (2.1897)	Acc@1 37.500 (39.773)	Acc@5 75.000 (74.384)
Epoch: [14][340/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.2371 (2.1914)	Acc@1 44.531 (39.731)	Acc@5 68.750 (74.342)
Epoch: [14][350/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.1511 (2.1912)	Acc@1 39.062 (39.721)	Acc@5 72.656 (74.366)
Epoch: [14][360/391]	Time 0.114 (0.112)	Data 0.001 (0.002)	Loss 2.1090 (2.1908)	Acc@1 45.312 (39.746)	Acc@5 77.344 (74.388)
Epoch: [14][370/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2541 (2.1915)	Acc@1 36.719 (39.743)	Acc@5 72.656 (74.362)
Epoch: [14][380/391]	Time 0.111 (0.112)	Data 0.001 (0.002)	Loss 2.3276 (2.1929)	Acc@1 32.812 (39.694)	Acc@5 72.656 (74.356)
Epoch: [14][390/391]	Time 0.091 (0.111)	Data 0.001 (0.002)	Loss 2.4644 (2.1949)	Acc@1 35.000 (39.646)	Acc@5 68.750 (74.264)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [15][0/391]	Time 0.128 (0.128)	Data 0.200 (0.200)	Loss 1.9388 (1.9388)	Acc@1 47.656 (47.656)	Acc@5 80.469 (80.469)
Epoch: [15][10/391]	Time 0.111 (0.114)	Data 0.001 (0.019)	Loss 2.0534 (2.1556)	Acc@1 41.406 (40.838)	Acc@5 75.000 (75.639)
Epoch: [15][20/391]	Time 0.107 (0.113)	Data 0.001 (0.010)	Loss 2.1083 (2.1388)	Acc@1 41.406 (39.993)	Acc@5 74.219 (75.744)
Epoch: [15][30/391]	Time 0.114 (0.112)	Data 0.001 (0.007)	Loss 2.0240 (2.1298)	Acc@1 44.531 (40.020)	Acc@5 76.562 (75.857)
Epoch: [15][40/391]	Time 0.112 (0.112)	Data 0.001 (0.006)	Loss 2.0370 (2.1374)	Acc@1 43.750 (40.282)	Acc@5 74.219 (75.724)
Epoch: [15][50/391]	Time 0.112 (0.112)	Data 0.001 (0.005)	Loss 2.0093 (2.1449)	Acc@1 41.406 (39.997)	Acc@5 78.906 (75.368)
Epoch: [15][60/391]	Time 0.107 (0.112)	Data 0.001 (0.004)	Loss 2.2330 (2.1489)	Acc@1 39.844 (40.036)	Acc@5 74.219 (75.423)
Epoch: [15][70/391]	Time 0.110 (0.112)	Data 0.001 (0.004)	Loss 2.4163 (2.1666)	Acc@1 29.688 (39.690)	Acc@5 67.969 (74.934)
Epoch: [15][80/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.2160 (2.1652)	Acc@1 42.969 (39.786)	Acc@5 70.312 (74.817)
Epoch: [15][90/391]	Time 0.113 (0.112)	Data 0.001 (0.003)	Loss 1.8412 (2.1585)	Acc@1 47.656 (39.921)	Acc@5 82.031 (74.940)
Epoch: [15][100/391]	Time 0.109 (0.112)	Data 0.001 (0.003)	Loss 2.2641 (2.1640)	Acc@1 39.844 (39.836)	Acc@5 71.875 (74.807)
Epoch: [15][110/391]	Time 0.113 (0.111)	Data 0.001 (0.003)	Loss 2.1303 (2.1631)	Acc@1 39.844 (39.766)	Acc@5 79.688 (74.866)
Epoch: [15][120/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.2202 (2.1577)	Acc@1 42.969 (39.947)	Acc@5 71.094 (74.981)
Epoch: [15][130/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.1574 (2.1560)	Acc@1 39.062 (39.939)	Acc@5 75.781 (75.042)
Epoch: [15][140/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3897 (2.1590)	Acc@1 39.062 (39.888)	Acc@5 64.062 (74.989)
Epoch: [15][150/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2620 (2.1648)	Acc@1 32.812 (39.751)	Acc@5 71.875 (74.840)
Epoch: [15][160/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2394 (2.1663)	Acc@1 36.719 (39.771)	Acc@5 75.781 (74.820)
Epoch: [15][170/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.2634 (2.1696)	Acc@1 32.031 (39.675)	Acc@5 71.094 (74.822)
Epoch: [15][180/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.0381 (2.1713)	Acc@1 42.188 (39.667)	Acc@5 78.125 (74.780)
Epoch: [15][190/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.3854 (2.1742)	Acc@1 37.500 (39.656)	Acc@5 72.656 (74.726)
Epoch: [15][200/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2861 (2.1729)	Acc@1 35.938 (39.657)	Acc@5 71.094 (74.763)
Epoch: [15][210/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.1299 (2.1730)	Acc@1 35.938 (39.629)	Acc@5 75.781 (74.748)
Epoch: [15][220/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.1825 (2.1758)	Acc@1 40.625 (39.589)	Acc@5 72.656 (74.646)
Epoch: [15][230/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2514 (2.1787)	Acc@1 39.062 (39.610)	Acc@5 74.219 (74.601)
Epoch: [15][240/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3554 (2.1806)	Acc@1 39.844 (39.630)	Acc@5 72.656 (74.569)
Epoch: [15][250/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9758 (2.1804)	Acc@1 44.531 (39.607)	Acc@5 76.562 (74.577)
Epoch: [15][260/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1572 (2.1804)	Acc@1 44.531 (39.655)	Acc@5 71.094 (74.551)
Epoch: [15][270/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2770 (2.1798)	Acc@1 45.312 (39.720)	Acc@5 70.312 (74.556)
Epoch: [15][280/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.0055 (2.1807)	Acc@1 45.312 (39.769)	Acc@5 76.562 (74.552)
Epoch: [15][290/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9936 (2.1787)	Acc@1 43.750 (39.820)	Acc@5 77.344 (74.595)
Epoch: [15][300/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.1204 (2.1790)	Acc@1 36.719 (39.776)	Acc@5 74.219 (74.569)
Epoch: [15][310/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2003 (2.1816)	Acc@1 45.312 (39.713)	Acc@5 70.312 (74.500)
Epoch: [15][320/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2955 (2.1837)	Acc@1 34.375 (39.615)	Acc@5 69.531 (74.438)
Epoch: [15][330/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1174 (2.1851)	Acc@1 39.844 (39.546)	Acc@5 79.688 (74.476)
Epoch: [15][340/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3971 (2.1863)	Acc@1 31.250 (39.544)	Acc@5 75.000 (74.482)
Epoch: [15][350/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3625 (2.1872)	Acc@1 34.375 (39.519)	Acc@5 66.406 (74.479)
Epoch: [15][360/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2294 (2.1868)	Acc@1 36.719 (39.554)	Acc@5 73.438 (74.520)
Epoch: [15][370/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1072 (2.1833)	Acc@1 36.719 (39.639)	Acc@5 76.562 (74.591)
Epoch: [15][380/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1734 (2.1821)	Acc@1 35.156 (39.667)	Acc@5 76.562 (74.641)
Epoch: [15][390/391]	Time 0.092 (0.111)	Data 0.001 (0.002)	Loss 2.2836 (2.1838)	Acc@1 37.500 (39.678)	Acc@5 76.250 (74.586)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [16][0/391]	Time 0.127 (0.127)	Data 0.163 (0.163)	Loss 2.0879 (2.0879)	Acc@1 43.750 (43.750)	Acc@5 76.562 (76.562)
Epoch: [16][10/391]	Time 0.112 (0.112)	Data 0.001 (0.016)	Loss 2.5483 (2.1584)	Acc@1 35.938 (41.619)	Acc@5 67.969 (74.077)
Epoch: [16][20/391]	Time 0.115 (0.112)	Data 0.001 (0.009)	Loss 2.3229 (2.2106)	Acc@1 36.719 (40.923)	Acc@5 68.750 (73.251)
Epoch: [16][30/391]	Time 0.110 (0.112)	Data 0.001 (0.006)	Loss 2.1253 (2.2110)	Acc@1 39.062 (40.398)	Acc@5 78.906 (73.236)
Epoch: [16][40/391]	Time 0.110 (0.111)	Data 0.001 (0.005)	Loss 2.2080 (2.2053)	Acc@1 42.969 (39.901)	Acc@5 69.531 (73.628)
Epoch: [16][50/391]	Time 0.112 (0.111)	Data 0.001 (0.004)	Loss 2.2903 (2.1913)	Acc@1 38.281 (40.165)	Acc@5 73.438 (74.050)
Epoch: [16][60/391]	Time 0.108 (0.111)	Data 0.001 (0.004)	Loss 2.0873 (2.1877)	Acc@1 37.500 (39.933)	Acc@5 76.562 (74.193)
Epoch: [16][70/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.2854 (2.1795)	Acc@1 37.500 (40.053)	Acc@5 71.094 (74.384)
Epoch: [16][80/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 1.9769 (2.1773)	Acc@1 41.406 (40.210)	Acc@5 78.125 (74.489)
Epoch: [16][90/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.3080 (2.1722)	Acc@1 39.844 (40.350)	Acc@5 72.656 (74.502)
Epoch: [16][100/391]	Time 0.118 (0.111)	Data 0.001 (0.003)	Loss 2.2414 (2.1720)	Acc@1 36.719 (40.254)	Acc@5 75.000 (74.551)
Epoch: [16][110/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.0911 (2.1730)	Acc@1 38.281 (40.182)	Acc@5 75.781 (74.599)
Epoch: [16][120/391]	Time 0.117 (0.111)	Data 0.001 (0.003)	Loss 2.0342 (2.1749)	Acc@1 37.500 (40.089)	Acc@5 78.906 (74.554)
Epoch: [16][130/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2292 (2.1784)	Acc@1 40.625 (39.838)	Acc@5 75.000 (74.505)
Epoch: [16][140/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1511 (2.1819)	Acc@1 40.625 (39.866)	Acc@5 74.219 (74.490)
Epoch: [16][150/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 1.9245 (2.1863)	Acc@1 46.094 (39.797)	Acc@5 82.812 (74.333)
Epoch: [16][160/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.4204 (2.1837)	Acc@1 35.156 (39.984)	Acc@5 71.875 (74.393)
Epoch: [16][170/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9883 (2.1824)	Acc@1 47.656 (40.045)	Acc@5 76.562 (74.406)
Epoch: [16][180/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3467 (2.1810)	Acc@1 32.812 (39.934)	Acc@5 77.344 (74.525)
Epoch: [16][190/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9910 (2.1798)	Acc@1 44.531 (39.954)	Acc@5 77.344 (74.628)
Epoch: [16][200/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.5575 (2.1822)	Acc@1 35.156 (39.945)	Acc@5 68.750 (74.545)
Epoch: [16][210/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3996 (2.1819)	Acc@1 34.375 (39.981)	Acc@5 76.562 (74.626)
Epoch: [16][220/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.3420 (2.1856)	Acc@1 41.406 (39.964)	Acc@5 69.531 (74.533)
Epoch: [16][230/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.5505 (2.1850)	Acc@1 30.469 (39.925)	Acc@5 67.188 (74.570)
Epoch: [16][240/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.5626 (2.1885)	Acc@1 29.688 (39.941)	Acc@5 64.062 (74.459)
Epoch: [16][250/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0377 (2.1910)	Acc@1 45.312 (39.918)	Acc@5 78.125 (74.374)
Epoch: [16][260/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2051 (2.1910)	Acc@1 39.062 (39.874)	Acc@5 70.312 (74.338)
Epoch: [16][270/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2313 (2.1930)	Acc@1 35.156 (39.803)	Acc@5 73.438 (74.294)
Epoch: [16][280/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.4378 (2.1928)	Acc@1 34.375 (39.799)	Acc@5 71.094 (74.327)
Epoch: [16][290/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1988 (2.1948)	Acc@1 36.719 (39.787)	Acc@5 79.688 (74.305)
Epoch: [16][300/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2889 (2.1940)	Acc@1 36.719 (39.815)	Acc@5 75.000 (74.341)
Epoch: [16][310/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2227 (2.1914)	Acc@1 38.281 (39.846)	Acc@5 78.906 (74.462)
Epoch: [16][320/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9548 (2.1908)	Acc@1 49.219 (39.912)	Acc@5 79.688 (74.513)
Epoch: [16][330/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1504 (2.1916)	Acc@1 38.281 (39.948)	Acc@5 73.438 (74.476)
Epoch: [16][340/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.3040 (2.1908)	Acc@1 35.156 (39.938)	Acc@5 67.969 (74.512)
Epoch: [16][350/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1607 (2.1896)	Acc@1 44.531 (40.033)	Acc@5 75.000 (74.486)
Epoch: [16][360/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 2.2103 (2.1885)	Acc@1 36.719 (40.021)	Acc@5 71.094 (74.504)
Epoch: [16][370/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9767 (2.1895)	Acc@1 39.062 (39.995)	Acc@5 78.125 (74.499)
Epoch: [16][380/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.4449 (2.1911)	Acc@1 28.125 (39.985)	Acc@5 69.531 (74.455)
Epoch: [16][390/391]	Time 0.091 (0.111)	Data 0.001 (0.002)	Loss 2.3430 (2.1956)	Acc@1 36.250 (39.906)	Acc@5 71.250 (74.374)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [17][0/391]	Time 0.127 (0.127)	Data 0.176 (0.176)	Loss 2.4393 (2.4393)	Acc@1 34.375 (34.375)	Acc@5 71.094 (71.094)
Epoch: [17][10/391]	Time 0.114 (0.112)	Data 0.001 (0.017)	Loss 2.0416 (2.2439)	Acc@1 42.188 (37.713)	Acc@5 84.375 (74.077)
Epoch: [17][20/391]	Time 0.114 (0.112)	Data 0.001 (0.009)	Loss 1.9049 (2.1932)	Acc@1 46.094 (38.988)	Acc@5 82.031 (75.372)
Epoch: [17][30/391]	Time 0.110 (0.112)	Data 0.001 (0.007)	Loss 2.3541 (2.2007)	Acc@1 34.375 (38.962)	Acc@5 72.656 (74.748)
Epoch: [17][40/391]	Time 0.108 (0.111)	Data 0.001 (0.005)	Loss 2.0374 (2.2066)	Acc@1 46.094 (39.329)	Acc@5 75.000 (74.104)
Epoch: [17][50/391]	Time 0.112 (0.111)	Data 0.001 (0.005)	Loss 2.2257 (2.1874)	Acc@1 42.188 (39.537)	Acc@5 71.875 (74.449)
Epoch: [17][60/391]	Time 0.112 (0.111)	Data 0.001 (0.004)	Loss 2.2169 (2.1828)	Acc@1 39.844 (39.780)	Acc@5 70.312 (74.590)
Epoch: [17][70/391]	Time 0.113 (0.112)	Data 0.001 (0.004)	Loss 2.1909 (2.1843)	Acc@1 40.625 (39.844)	Acc@5 75.000 (74.615)
Epoch: [17][80/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.2231 (2.1814)	Acc@1 42.188 (40.066)	Acc@5 74.219 (74.730)
Epoch: [17][90/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.0394 (2.1815)	Acc@1 43.750 (39.930)	Acc@5 78.906 (74.742)
Epoch: [17][100/391]	Time 0.106 (0.111)	Data 0.001 (0.003)	Loss 2.0411 (2.1860)	Acc@1 41.406 (39.790)	Acc@5 78.125 (74.752)
Epoch: [17][110/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.3181 (2.1922)	Acc@1 32.812 (39.633)	Acc@5 71.094 (74.620)
Epoch: [17][120/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.1660 (2.1955)	Acc@1 38.281 (39.624)	Acc@5 74.219 (74.567)
Epoch: [17][130/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.0622 (2.1915)	Acc@1 42.188 (39.701)	Acc@5 75.781 (74.696)
Epoch: [17][140/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2989 (2.1902)	Acc@1 35.938 (39.689)	Acc@5 75.000 (74.795)
Epoch: [17][150/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 1.9774 (2.1871)	Acc@1 46.875 (39.689)	Acc@5 81.250 (74.902)
Epoch: [17][160/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.0637 (2.1876)	Acc@1 41.406 (39.635)	Acc@5 76.562 (74.888)
Epoch: [17][170/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.1664 (2.1865)	Acc@1 37.500 (39.679)	Acc@5 75.781 (74.858)
Epoch: [17][180/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.0537 (2.1862)	Acc@1 43.750 (39.680)	Acc@5 79.688 (74.892)
Epoch: [17][190/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1640 (2.1905)	Acc@1 40.625 (39.623)	Acc@5 77.344 (74.771)
Epoch: [17][200/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.2121 (2.1897)	Acc@1 41.406 (39.579)	Acc@5 75.781 (74.685)
Epoch: [17][210/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.8394 (2.1865)	Acc@1 46.875 (39.685)	Acc@5 85.156 (74.804)
Epoch: [17][220/391]	Time 0.117 (0.111)	Data 0.001 (0.002)	Loss 2.3278 (2.1849)	Acc@1 40.625 (39.685)	Acc@5 68.750 (74.816)
Epoch: [17][230/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.1434 (2.1815)	Acc@1 41.406 (39.668)	Acc@5 76.562 (74.919)
Epoch: [17][240/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1109 (2.1823)	Acc@1 40.625 (39.610)	Acc@5 76.562 (74.867)
Epoch: [17][250/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.3278 (2.1814)	Acc@1 38.281 (39.657)	Acc@5 71.875 (74.900)
Epoch: [17][260/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3877 (2.1827)	Acc@1 40.625 (39.682)	Acc@5 71.875 (74.841)
Epoch: [17][270/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1820 (2.1833)	Acc@1 37.500 (39.674)	Acc@5 72.656 (74.792)
Epoch: [17][280/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 2.3328 (2.1863)	Acc@1 40.625 (39.644)	Acc@5 75.000 (74.703)
Epoch: [17][290/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.0512 (2.1852)	Acc@1 41.406 (39.704)	Acc@5 78.906 (74.758)
Epoch: [17][300/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.0942 (2.1835)	Acc@1 38.281 (39.743)	Acc@5 80.469 (74.792)
Epoch: [17][310/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.1530 (2.1837)	Acc@1 43.750 (39.786)	Acc@5 78.125 (74.797)
Epoch: [17][320/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.0755 (2.1858)	Acc@1 39.844 (39.771)	Acc@5 78.906 (74.744)
Epoch: [17][330/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0621 (2.1841)	Acc@1 44.531 (39.801)	Acc@5 75.000 (74.762)
Epoch: [17][340/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2949 (2.1864)	Acc@1 31.250 (39.677)	Acc@5 73.438 (74.757)
Epoch: [17][350/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2170 (2.1889)	Acc@1 42.188 (39.628)	Acc@5 73.438 (74.679)
Epoch: [17][360/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1559 (2.1893)	Acc@1 40.625 (39.586)	Acc@5 75.781 (74.712)
Epoch: [17][370/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.0982 (2.1891)	Acc@1 42.188 (39.658)	Acc@5 81.250 (74.707)
Epoch: [17][380/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3631 (2.1893)	Acc@1 33.594 (39.682)	Acc@5 71.094 (74.717)
Epoch: [17][390/391]	Time 0.093 (0.111)	Data 0.001 (0.002)	Loss 2.0029 (2.1897)	Acc@1 51.250 (39.670)	Acc@5 80.000 (74.706)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [18][0/391]	Time 0.127 (0.127)	Data 0.164 (0.164)	Loss 2.1423 (2.1423)	Acc@1 39.844 (39.844)	Acc@5 78.906 (78.906)
Epoch: [18][10/391]	Time 0.107 (0.114)	Data 0.001 (0.016)	Loss 2.2399 (2.2371)	Acc@1 38.281 (37.784)	Acc@5 69.531 (73.153)
Epoch: [18][20/391]	Time 0.115 (0.114)	Data 0.001 (0.009)	Loss 2.0332 (2.2333)	Acc@1 36.719 (37.872)	Acc@5 78.906 (73.996)
Epoch: [18][30/391]	Time 0.110 (0.113)	Data 0.001 (0.006)	Loss 2.1615 (2.2176)	Acc@1 41.406 (38.105)	Acc@5 75.781 (73.967)
Epoch: [18][40/391]	Time 0.110 (0.114)	Data 0.001 (0.005)	Loss 2.0652 (2.2006)	Acc@1 40.625 (38.796)	Acc@5 79.688 (74.352)
Epoch: [18][50/391]	Time 0.112 (0.113)	Data 0.001 (0.004)	Loss 2.1274 (2.2058)	Acc@1 41.406 (38.971)	Acc@5 74.219 (74.265)
Epoch: [18][60/391]	Time 0.112 (0.113)	Data 0.001 (0.004)	Loss 2.2962 (2.2103)	Acc@1 33.594 (38.986)	Acc@5 68.750 (74.129)
Epoch: [18][70/391]	Time 0.119 (0.113)	Data 0.001 (0.003)	Loss 1.9893 (2.1971)	Acc@1 47.656 (39.261)	Acc@5 74.219 (74.263)
Epoch: [18][80/391]	Time 0.111 (0.113)	Data 0.001 (0.003)	Loss 2.3010 (2.2010)	Acc@1 34.375 (39.130)	Acc@5 71.094 (74.267)
Epoch: [18][90/391]	Time 0.111 (0.113)	Data 0.001 (0.003)	Loss 2.3312 (2.1936)	Acc@1 32.812 (39.337)	Acc@5 70.312 (74.476)
Epoch: [18][100/391]	Time 0.109 (0.112)	Data 0.001 (0.003)	Loss 1.9126 (2.1818)	Acc@1 50.781 (39.658)	Acc@5 77.344 (74.675)
Epoch: [18][110/391]	Time 0.110 (0.112)	Data 0.001 (0.003)	Loss 2.0510 (2.1793)	Acc@1 43.750 (40.027)	Acc@5 80.469 (74.740)
Epoch: [18][120/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.0494 (2.1824)	Acc@1 42.969 (39.889)	Acc@5 78.125 (74.780)
Epoch: [18][130/391]	Time 0.115 (0.112)	Data 0.001 (0.002)	Loss 2.0916 (2.1815)	Acc@1 39.844 (39.951)	Acc@5 74.219 (74.881)
Epoch: [18][140/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.3475 (2.1787)	Acc@1 37.500 (40.137)	Acc@5 71.875 (74.939)
Epoch: [18][150/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1010 (2.1803)	Acc@1 44.531 (40.056)	Acc@5 73.438 (74.788)
Epoch: [18][160/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.0468 (2.1816)	Acc@1 42.969 (39.931)	Acc@5 79.688 (74.782)
Epoch: [18][170/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3109 (2.1867)	Acc@1 29.688 (39.825)	Acc@5 73.438 (74.694)
Epoch: [18][180/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.3307 (2.1870)	Acc@1 39.062 (39.788)	Acc@5 73.438 (74.732)
Epoch: [18][190/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1655 (2.1907)	Acc@1 37.500 (39.684)	Acc@5 79.688 (74.656)
Epoch: [18][200/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9548 (2.1893)	Acc@1 46.094 (39.797)	Acc@5 79.688 (74.674)
Epoch: [18][210/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1263 (2.1861)	Acc@1 42.969 (39.877)	Acc@5 78.906 (74.830)
Epoch: [18][220/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3323 (2.1852)	Acc@1 38.281 (39.868)	Acc@5 70.312 (74.855)
Epoch: [18][230/391]	Time 0.106 (0.111)	Data 0.001 (0.002)	Loss 1.9518 (2.1849)	Acc@1 46.875 (39.844)	Acc@5 78.125 (74.858)
Epoch: [18][240/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2375 (2.1851)	Acc@1 44.531 (39.782)	Acc@5 70.312 (74.854)
Epoch: [18][250/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.2676 (2.1859)	Acc@1 42.188 (39.794)	Acc@5 75.000 (74.841)
Epoch: [18][260/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.3614 (2.1857)	Acc@1 38.281 (39.808)	Acc@5 71.875 (74.859)
Epoch: [18][270/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3710 (2.1860)	Acc@1 33.594 (39.824)	Acc@5 71.094 (74.865)
Epoch: [18][280/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.0200 (2.1882)	Acc@1 42.969 (39.749)	Acc@5 78.906 (74.828)
Epoch: [18][290/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2555 (2.1873)	Acc@1 35.156 (39.798)	Acc@5 73.438 (74.871)
Epoch: [18][300/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3440 (2.1882)	Acc@1 36.719 (39.748)	Acc@5 68.750 (74.808)
Epoch: [18][310/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.3021 (2.1894)	Acc@1 35.938 (39.736)	Acc@5 72.656 (74.781)
Epoch: [18][320/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.1973 (2.1888)	Acc@1 41.406 (39.766)	Acc@5 72.656 (74.757)
Epoch: [18][330/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.0210 (2.1897)	Acc@1 43.750 (39.702)	Acc@5 75.781 (74.714)
Epoch: [18][340/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.4049 (2.1888)	Acc@1 35.938 (39.750)	Acc@5 69.531 (74.737)
Epoch: [18][350/391]	Time 0.107 (0.111)	Data 0.001 (0.002)	Loss 2.0178 (2.1862)	Acc@1 44.531 (39.784)	Acc@5 75.000 (74.804)
Epoch: [18][360/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 1.9447 (2.1852)	Acc@1 45.312 (39.826)	Acc@5 84.375 (74.823)
Epoch: [18][370/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.2581 (2.1860)	Acc@1 33.594 (39.774)	Acc@5 76.562 (74.827)
Epoch: [18][380/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.2521 (2.1880)	Acc@1 39.844 (39.745)	Acc@5 71.875 (74.770)
Epoch: [18][390/391]	Time 0.092 (0.111)	Data 0.001 (0.002)	Loss 2.3974 (2.1891)	Acc@1 37.500 (39.706)	Acc@5 71.250 (74.730)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [19][0/391]	Time 0.124 (0.124)	Data 0.163 (0.163)	Loss 2.1598 (2.1598)	Acc@1 39.062 (39.062)	Acc@5 75.000 (75.000)
Epoch: [19][10/391]	Time 0.108 (0.112)	Data 0.001 (0.016)	Loss 2.1130 (2.1499)	Acc@1 42.188 (40.909)	Acc@5 78.125 (74.929)
Epoch: [19][20/391]	Time 0.117 (0.112)	Data 0.001 (0.009)	Loss 2.1799 (2.1660)	Acc@1 41.406 (41.146)	Acc@5 74.219 (74.740)
Epoch: [19][30/391]	Time 0.112 (0.112)	Data 0.001 (0.006)	Loss 2.4303 (2.1883)	Acc@1 34.375 (40.499)	Acc@5 69.531 (74.042)
Epoch: [19][40/391]	Time 0.118 (0.111)	Data 0.001 (0.005)	Loss 1.9075 (2.1812)	Acc@1 46.875 (40.377)	Acc@5 78.906 (74.581)
Epoch: [19][50/391]	Time 0.110 (0.111)	Data 0.001 (0.004)	Loss 2.3095 (2.1630)	Acc@1 43.750 (40.702)	Acc@5 69.531 (75.337)
Epoch: [19][60/391]	Time 0.111 (0.111)	Data 0.001 (0.004)	Loss 2.1222 (2.1608)	Acc@1 40.625 (40.881)	Acc@5 75.781 (75.435)
Epoch: [19][70/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.1105 (2.1649)	Acc@1 42.969 (40.746)	Acc@5 78.125 (75.220)
Epoch: [19][80/391]	Time 0.114 (0.111)	Data 0.001 (0.003)	Loss 2.2782 (2.1762)	Acc@1 39.844 (40.268)	Acc@5 70.312 (75.116)
Epoch: [19][90/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.1386 (2.1760)	Acc@1 43.750 (40.213)	Acc@5 75.000 (75.266)
Epoch: [19][100/391]	Time 0.110 (0.111)	Data 0.001 (0.003)	Loss 2.1994 (2.1722)	Acc@1 42.188 (40.238)	Acc@5 73.438 (75.302)
Epoch: [19][110/391]	Time 0.111 (0.111)	Data 0.001 (0.003)	Loss 2.1562 (2.1749)	Acc@1 39.062 (40.125)	Acc@5 72.656 (75.169)
Epoch: [19][120/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.3162 (2.1785)	Acc@1 32.031 (39.928)	Acc@5 71.875 (75.174)
Epoch: [19][130/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.7932 (2.1730)	Acc@1 53.125 (40.202)	Acc@5 80.469 (75.119)
Epoch: [19][140/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.0619 (2.1710)	Acc@1 45.312 (40.182)	Acc@5 78.125 (75.078)
Epoch: [19][150/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9208 (2.1664)	Acc@1 45.312 (40.232)	Acc@5 79.688 (75.191)
Epoch: [19][160/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3436 (2.1736)	Acc@1 35.156 (40.159)	Acc@5 66.406 (74.985)
Epoch: [19][170/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.2653 (2.1687)	Acc@1 37.500 (40.223)	Acc@5 73.438 (75.105)
Epoch: [19][180/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.2694 (2.1668)	Acc@1 39.062 (40.357)	Acc@5 74.219 (75.112)
Epoch: [19][190/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.0680 (2.1709)	Acc@1 46.875 (40.269)	Acc@5 81.250 (75.000)
Epoch: [19][200/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.1826 (2.1755)	Acc@1 35.156 (40.108)	Acc@5 75.000 (74.891)
Epoch: [19][210/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.3444 (2.1810)	Acc@1 38.281 (40.033)	Acc@5 75.000 (74.833)
Epoch: [19][220/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3661 (2.1826)	Acc@1 37.500 (39.982)	Acc@5 69.531 (74.791)
Epoch: [19][230/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.2253 (2.1836)	Acc@1 40.625 (40.003)	Acc@5 73.438 (74.777)
Epoch: [19][240/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.4150 (2.1834)	Acc@1 34.375 (39.993)	Acc@5 70.312 (74.773)
Epoch: [19][250/391]	Time 0.118 (0.111)	Data 0.001 (0.002)	Loss 2.0352 (2.1818)	Acc@1 45.312 (40.012)	Acc@5 76.562 (74.819)
Epoch: [19][260/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1491 (2.1826)	Acc@1 43.750 (39.975)	Acc@5 72.656 (74.790)
Epoch: [19][270/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1340 (2.1798)	Acc@1 40.625 (40.048)	Acc@5 74.219 (74.888)
Epoch: [19][280/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.2415 (2.1804)	Acc@1 38.281 (40.027)	Acc@5 74.219 (74.880)
Epoch: [19][290/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3749 (2.1812)	Acc@1 31.250 (40.002)	Acc@5 70.312 (74.866)
Epoch: [19][300/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 2.1513 (2.1803)	Acc@1 39.062 (40.005)	Acc@5 76.562 (74.909)
Epoch: [19][310/391]	Time 0.110 (0.112)	Data 0.001 (0.002)	Loss 2.2492 (2.1813)	Acc@1 43.750 (40.070)	Acc@5 74.219 (74.862)
Epoch: [19][320/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 1.9131 (2.1829)	Acc@1 50.781 (40.060)	Acc@5 76.562 (74.830)
Epoch: [19][330/391]	Time 0.108 (0.112)	Data 0.001 (0.002)	Loss 2.3017 (2.1832)	Acc@1 38.281 (40.030)	Acc@5 75.000 (74.851)
Epoch: [19][340/391]	Time 0.113 (0.112)	Data 0.001 (0.002)	Loss 2.1495 (2.1833)	Acc@1 40.625 (40.048)	Acc@5 74.219 (74.844)
Epoch: [19][350/391]	Time 0.107 (0.112)	Data 0.001 (0.002)	Loss 2.3060 (2.1861)	Acc@1 34.375 (39.939)	Acc@5 70.312 (74.797)
Epoch: [19][360/391]	Time 0.106 (0.112)	Data 0.001 (0.002)	Loss 2.3606 (2.1882)	Acc@1 39.844 (39.943)	Acc@5 68.750 (74.729)
Epoch: [19][370/391]	Time 0.106 (0.112)	Data 0.001 (0.002)	Loss 2.1181 (2.1882)	Acc@1 42.969 (39.949)	Acc@5 77.344 (74.724)
Epoch: [19][380/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.1932 (2.1903)	Acc@1 35.938 (39.897)	Acc@5 73.438 (74.653)
Epoch: [19][390/391]	Time 0.090 (0.111)	Data 0.001 (0.002)	Loss 2.5624 (2.1906)	Acc@1 40.000 (39.862)	Acc@5 68.750 (74.662)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [20][0/391]	Time 0.120 (0.120)	Data 0.158 (0.158)	Loss 2.2675 (2.2675)	Acc@1 29.688 (29.688)	Acc@5 72.656 (72.656)
Epoch: [20][10/391]	Time 0.108 (0.112)	Data 0.001 (0.016)	Loss 2.0347 (2.2028)	Acc@1 40.625 (39.418)	Acc@5 75.000 (75.781)
Epoch: [20][20/391]	Time 0.110 (0.111)	Data 0.001 (0.009)	Loss 2.3394 (2.1895)	Acc@1 34.375 (39.509)	Acc@5 67.188 (75.037)
Epoch: [20][30/391]	Time 0.105 (0.111)	Data 0.001 (0.006)	Loss 2.0616 (2.1741)	Acc@1 46.094 (39.516)	Acc@5 76.562 (75.479)
Epoch: [20][40/391]	Time 0.109 (0.110)	Data 0.001 (0.005)	Loss 2.0054 (2.1531)	Acc@1 42.969 (40.168)	Acc@5 77.344 (75.877)
Epoch: [20][50/391]	Time 0.108 (0.111)	Data 0.001 (0.004)	Loss 2.2150 (2.1592)	Acc@1 44.531 (40.273)	Acc@5 72.656 (75.444)
Epoch: [20][60/391]	Time 0.112 (0.111)	Data 0.001 (0.004)	Loss 2.1473 (2.1602)	Acc@1 34.375 (39.946)	Acc@5 78.906 (75.295)
Epoch: [20][70/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.2219 (2.1674)	Acc@1 40.625 (39.976)	Acc@5 71.875 (75.022)
Epoch: [20][80/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.0980 (2.1685)	Acc@1 39.062 (39.998)	Acc@5 82.031 (75.231)
Epoch: [20][90/391]	Time 0.109 (0.111)	Data 0.001 (0.003)	Loss 2.3036 (2.1763)	Acc@1 38.281 (39.861)	Acc@5 73.438 (75.172)
Epoch: [20][100/391]	Time 0.112 (0.111)	Data 0.001 (0.003)	Loss 2.0326 (2.1797)	Acc@1 44.531 (39.790)	Acc@5 76.562 (75.085)
Epoch: [20][110/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.3234 (2.1771)	Acc@1 35.156 (39.851)	Acc@5 68.750 (75.007)
Epoch: [20][120/391]	Time 0.108 (0.111)	Data 0.001 (0.003)	Loss 2.4360 (2.1788)	Acc@1 39.844 (39.844)	Acc@5 70.312 (74.923)
Epoch: [20][130/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 2.3210 (2.1815)	Acc@1 40.625 (39.844)	Acc@5 74.219 (74.887)
Epoch: [20][140/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1282 (2.1822)	Acc@1 40.625 (39.827)	Acc@5 78.125 (74.900)
Epoch: [20][150/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3705 (2.1915)	Acc@1 34.375 (39.632)	Acc@5 68.750 (74.659)
Epoch: [20][160/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.1939 (2.1920)	Acc@1 36.719 (39.548)	Acc@5 71.875 (74.631)
Epoch: [20][170/391]	Time 0.106 (0.110)	Data 0.001 (0.002)	Loss 2.2342 (2.1934)	Acc@1 39.062 (39.565)	Acc@5 70.312 (74.621)
Epoch: [20][180/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.0437 (2.1906)	Acc@1 36.719 (39.693)	Acc@5 81.250 (74.603)
Epoch: [20][190/391]	Time 0.115 (0.111)	Data 0.001 (0.002)	Loss 2.4442 (2.1911)	Acc@1 35.156 (39.615)	Acc@5 68.750 (74.603)
Epoch: [20][200/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1657 (2.1930)	Acc@1 36.719 (39.603)	Acc@5 74.219 (74.534)
Epoch: [20][210/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.2138 (2.1914)	Acc@1 39.062 (39.610)	Acc@5 75.781 (74.667)
Epoch: [20][220/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.0461 (2.1901)	Acc@1 35.938 (39.554)	Acc@5 78.906 (74.745)
Epoch: [20][230/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 1.9296 (2.1873)	Acc@1 48.438 (39.631)	Acc@5 78.906 (74.807)
Epoch: [20][240/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.0821 (2.1873)	Acc@1 39.844 (39.620)	Acc@5 77.344 (74.789)
Epoch: [20][250/391]	Time 0.113 (0.111)	Data 0.001 (0.002)	Loss 2.0881 (2.1873)	Acc@1 42.188 (39.626)	Acc@5 75.781 (74.798)
Epoch: [20][260/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1086 (2.1904)	Acc@1 36.719 (39.565)	Acc@5 78.125 (74.713)
Epoch: [20][270/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.1489 (2.1907)	Acc@1 40.625 (39.619)	Acc@5 73.438 (74.686)
Epoch: [20][280/391]	Time 0.109 (0.111)	Data 0.001 (0.002)	Loss 1.9731 (2.1910)	Acc@1 42.188 (39.641)	Acc@5 78.906 (74.652)
Epoch: [20][290/391]	Time 0.116 (0.111)	Data 0.001 (0.002)	Loss 2.3669 (2.1907)	Acc@1 39.844 (39.750)	Acc@5 71.875 (74.678)
Epoch: [20][300/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 2.1757 (2.1914)	Acc@1 39.844 (39.730)	Acc@5 74.219 (74.681)
Epoch: [20][310/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.3598 (2.1932)	Acc@1 35.938 (39.685)	Acc@5 69.531 (74.671)
Epoch: [20][320/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.3036 (2.1944)	Acc@1 42.188 (39.727)	Acc@5 71.094 (74.628)
Epoch: [20][330/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.3158 (2.1927)	Acc@1 44.531 (39.808)	Acc@5 69.531 (74.655)
Epoch: [20][340/391]	Time 0.110 (0.111)	Data 0.001 (0.002)	Loss 2.2800 (2.1925)	Acc@1 39.844 (39.823)	Acc@5 71.094 (74.672)
Epoch: [20][350/391]	Time 0.108 (0.111)	Data 0.001 (0.002)	Loss 2.1619 (2.1933)	Acc@1 39.844 (39.788)	Acc@5 75.781 (74.637)
Epoch: [20][360/391]	Time 0.114 (0.111)	Data 0.001 (0.002)	Loss 2.1799 (2.1934)	Acc@1 39.062 (39.772)	Acc@5 71.875 (74.597)
Epoch: [20][370/391]	Time 0.112 (0.111)	Data 0.001 (0.002)	Loss 2.2605 (2.1927)	Acc@1 38.281 (39.833)	Acc@5 72.656 (74.596)
Epoch: [20][380/391]	Time 0.111 (0.111)	Data 0.001 (0.002)	Loss 1.9067 (2.1909)	Acc@1 49.219 (39.872)	Acc@5 79.688 (74.627)
Epoch: [20][390/391]	Time 0.093 (0.111)	Data 0.001 (0.002)	Loss 2.6371 (2.1917)	Acc@1 27.500 (39.912)	Acc@5 66.250 (74.630)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): AdaptiveAvgPool2d(output_size=(1, 1))
    (117): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Best acc:
31.26


now deeper
Epoch: [1][0/391]	Time 0.125 (0.125)	Data 0.171 (0.171)	Loss 1.9709 (1.9709)	Acc@1 39.062 (39.062)	Acc@5 83.594 (83.594)
Epoch: [1][10/391]	Time 0.122 (0.122)	Data 0.001 (0.016)	Loss 2.1591 (2.1017)	Acc@1 39.062 (42.614)	Acc@5 77.344 (77.344)
Epoch: [1][20/391]	Time 0.120 (0.121)	Data 0.001 (0.009)	Loss 2.0582 (2.0718)	Acc@1 46.094 (43.490)	Acc@5 78.906 (77.121)
Epoch: [1][30/391]	Time 0.118 (0.121)	Data 0.001 (0.007)	Loss 2.1722 (2.0781)	Acc@1 35.156 (42.843)	Acc@5 72.656 (76.739)
Epoch: [1][40/391]	Time 0.117 (0.121)	Data 0.001 (0.005)	Loss 2.1690 (2.1036)	Acc@1 38.281 (42.111)	Acc@5 75.781 (76.372)
Epoch: [1][50/391]	Time 0.120 (0.120)	Data 0.001 (0.004)	Loss 2.0855 (2.1178)	Acc@1 44.531 (42.034)	Acc@5 80.469 (76.210)
Epoch: [1][60/391]	Time 0.121 (0.121)	Data 0.001 (0.004)	Loss 2.2173 (2.1140)	Acc@1 38.281 (41.880)	Acc@5 73.438 (76.332)
Epoch: [1][70/391]	Time 0.119 (0.121)	Data 0.001 (0.003)	Loss 2.1303 (2.1154)	Acc@1 44.531 (41.879)	Acc@5 79.688 (76.298)
Epoch: [1][80/391]	Time 0.118 (0.120)	Data 0.001 (0.003)	Loss 2.0894 (2.1142)	Acc@1 39.844 (41.879)	Acc@5 79.688 (76.370)
Epoch: [1][90/391]	Time 0.123 (0.121)	Data 0.001 (0.003)	Loss 2.3261 (2.1204)	Acc@1 37.500 (41.947)	Acc@5 68.750 (76.279)
Epoch: [1][100/391]	Time 0.116 (0.120)	Data 0.001 (0.003)	Loss 2.1644 (2.1226)	Acc@1 46.094 (41.994)	Acc@5 73.438 (76.207)
Epoch: [1][110/391]	Time 0.118 (0.120)	Data 0.001 (0.003)	Loss 1.9517 (2.1302)	Acc@1 41.406 (41.786)	Acc@5 82.031 (76.063)
Epoch: [1][120/391]	Time 0.116 (0.120)	Data 0.001 (0.002)	Loss 2.2764 (2.1346)	Acc@1 33.594 (41.684)	Acc@5 71.875 (75.917)
Epoch: [1][130/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.3185 (2.1442)	Acc@1 36.719 (41.442)	Acc@5 67.188 (75.698)
Epoch: [1][140/391]	Time 0.122 (0.120)	Data 0.001 (0.002)	Loss 1.9167 (2.1452)	Acc@1 52.344 (41.362)	Acc@5 75.781 (75.626)
Epoch: [1][150/391]	Time 0.119 (0.120)	Data 0.001 (0.002)	Loss 2.0819 (2.1483)	Acc@1 31.250 (41.246)	Acc@5 79.688 (75.569)
Epoch: [1][160/391]	Time 0.120 (0.120)	Data 0.001 (0.002)	Loss 2.0465 (2.1465)	Acc@1 36.719 (41.227)	Acc@5 81.250 (75.631)
Epoch: [1][170/391]	Time 0.127 (0.120)	Data 0.001 (0.002)	Loss 2.4154 (2.1481)	Acc@1 35.938 (41.233)	Acc@5 68.750 (75.603)
Epoch: [1][180/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.2069 (2.1468)	Acc@1 39.062 (41.251)	Acc@5 76.562 (75.626)
Epoch: [1][190/391]	Time 0.121 (0.120)	Data 0.001 (0.002)	Loss 2.3338 (2.1461)	Acc@1 39.062 (41.263)	Acc@5 66.406 (75.630)
Epoch: [1][200/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.1497 (2.1470)	Acc@1 44.531 (41.247)	Acc@5 75.781 (75.521)
Epoch: [1][210/391]	Time 0.121 (0.120)	Data 0.001 (0.002)	Loss 2.0252 (2.1467)	Acc@1 45.312 (41.243)	Acc@5 78.125 (75.515)
Epoch: [1][220/391]	Time 0.117 (0.120)	Data 0.001 (0.002)	Loss 1.9937 (2.1473)	Acc@1 44.531 (41.233)	Acc@5 78.125 (75.587)
Epoch: [1][230/391]	Time 0.117 (0.120)	Data 0.001 (0.002)	Loss 2.3339 (2.1499)	Acc@1 37.500 (41.210)	Acc@5 73.438 (75.578)
Epoch: [1][240/391]	Time 0.117 (0.120)	Data 0.001 (0.002)	Loss 1.9848 (2.1495)	Acc@1 46.875 (41.205)	Acc@5 79.688 (75.635)
Epoch: [1][250/391]	Time 0.117 (0.120)	Data 0.001 (0.002)	Loss 2.1834 (2.1499)	Acc@1 39.844 (41.229)	Acc@5 75.000 (75.626)
Epoch: [1][260/391]	Time 0.122 (0.120)	Data 0.001 (0.002)	Loss 2.2170 (2.1525)	Acc@1 34.375 (41.110)	Acc@5 74.219 (75.566)
Epoch: [1][270/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 1.9965 (2.1541)	Acc@1 42.969 (41.121)	Acc@5 74.219 (75.525)
Epoch: [1][280/391]	Time 0.120 (0.120)	Data 0.001 (0.002)	Loss 2.1901 (2.1550)	Acc@1 42.188 (41.042)	Acc@5 72.656 (75.473)
Epoch: [1][290/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.1113 (2.1579)	Acc@1 40.625 (40.982)	Acc@5 75.781 (75.376)
Epoch: [1][300/391]	Time 0.121 (0.120)	Data 0.001 (0.002)	Loss 2.3722 (2.1606)	Acc@1 37.500 (40.939)	Acc@5 67.188 (75.280)
Epoch: [1][310/391]	Time 0.121 (0.120)	Data 0.001 (0.002)	Loss 2.1586 (2.1625)	Acc@1 42.969 (40.906)	Acc@5 73.438 (75.284)
Epoch: [1][320/391]	Time 0.120 (0.120)	Data 0.001 (0.002)	Loss 2.2297 (2.1670)	Acc@1 28.906 (40.783)	Acc@5 75.781 (75.173)
Epoch: [1][330/391]	Time 0.122 (0.120)	Data 0.001 (0.002)	Loss 2.1610 (2.1675)	Acc@1 37.500 (40.793)	Acc@5 75.781 (75.137)
Epoch: [1][340/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.3419 (2.1708)	Acc@1 37.500 (40.641)	Acc@5 72.656 (75.066)
Epoch: [1][350/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.1058 (2.1726)	Acc@1 39.062 (40.578)	Acc@5 76.562 (75.049)
Epoch: [1][360/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.1560 (2.1735)	Acc@1 33.594 (40.573)	Acc@5 75.000 (75.043)
Epoch: [1][370/391]	Time 0.118 (0.120)	Data 0.001 (0.002)	Loss 2.1324 (2.1756)	Acc@1 42.969 (40.484)	Acc@5 75.000 (74.981)
Epoch: [1][380/391]	Time 0.117 (0.120)	Data 0.001 (0.002)	Loss 2.2897 (2.1754)	Acc@1 36.719 (40.479)	Acc@5 74.219 (74.971)
Epoch: [1][390/391]	Time 0.096 (0.120)	Data 0.001 (0.002)	Loss 2.2015 (2.1750)	Acc@1 42.500 (40.478)	Acc@5 72.500 (74.966)
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (23): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (27): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (45): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (67): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (68): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (69): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (70): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (71): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (72): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (73): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (74): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (75): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (76): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (77): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (78): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (79): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (80): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (81): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (82): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (83): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (84): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (85): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (86): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (87): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (88): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (89): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (90): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (91): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (92): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (93): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (94): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (95): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (96): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (97): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (98): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (99): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (100): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (101): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (102): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (103): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (104): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (105): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (106): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (107): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (108): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (109): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (110): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (111): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (112): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (113): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (114): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (115): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (116): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (117): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (118): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (119): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (120): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (121): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (122): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (123): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (124): AdaptiveAvgPool2d(output_size=(1, 1))
    (125): Linear(in_features=16, out_features=100, bias=True)
  )
  (relu): ReLU(inplace=True)
)
Epoch: [2][0/391]	Time 0.134 (0.134)	Data 0.162 (0.162)	Loss 1.9925 (1.9925)	Acc@1 43.750 (43.750)	Acc@5 77.344 (77.344)
Epoch: [2][10/391]	Time 0.114 (0.121)	Data 0.001 (0.016)	Loss 2.2699 (2.1244)	Acc@1 39.062 (40.128)	Acc@5 74.219 (76.776)
Epoch: [2][20/391]	Time 0.117 (0.119)	Data 0.001 (0.009)	Loss 2.0449 (2.1296)	Acc@1 36.719 (40.290)	Acc@5 77.344 (76.376)
Epoch: [2][30/391]	Time 0.116 (0.119)	Data 0.001 (0.006)	Loss 2.0806 (2.1249)	Acc@1 43.750 (40.801)	Acc@5 75.781 (76.084)
Epoch: [2][40/391]	Time 0.123 (0.119)	Data 0.001 (0.005)	Loss 2.2271 (2.1437)	Acc@1 34.375 (40.111)	Acc@5 73.438 (75.648)
Epoch: [2][50/391]	Time 0.125 (0.119)	Data 0.001 (0.004)	Loss 2.0315 (2.1306)	Acc@1 48.438 (40.564)	Acc@5 78.906 (76.072)
Epoch: [2][60/391]	Time 0.113 (0.119)	Data 0.001 (0.004)	Loss 2.0380 (2.1311)	Acc@1 44.531 (40.817)	Acc@5 74.219 (76.050)
Epoch: [2][70/391]	Time 0.114 (0.119)	Data 0.001 (0.003)	Loss 2.1786 (2.1378)	Acc@1 40.625 (40.680)	Acc@5 75.000 (75.858)
Epoch: [2][80/391]	Time 0.121 (0.119)	Data 0.001 (0.003)	Loss 2.1305 (2.1441)	Acc@1 39.062 (40.509)	Acc@5 75.781 (75.704)
Epoch: [2][90/391]	Time 0.116 (0.119)	Data 0.001 (0.003)	Loss 2.1640 (2.1474)	Acc@1 31.250 (40.531)	Acc@5 77.344 (75.610)
Epoch: [2][100/391]	Time 0.116 (0.119)	Data 0.001 (0.003)	Loss 2.2547 (2.1485)	Acc@1 36.719 (40.385)	Acc@5 70.312 (75.518)
Epoch: [2][110/391]	Time 0.121 (0.119)	Data 0.001 (0.003)	Loss 2.2523 (2.1500)	Acc@1 42.969 (40.393)	Acc@5 73.438 (75.528)
Epoch: [2][120/391]	Time 0.118 (0.119)	Data 0.001 (0.003)	Loss 2.0237 (2.1481)	Acc@1 42.969 (40.373)	Acc@5 75.781 (75.555)
Epoch: [2][130/391]	Time 0.125 (0.119)	Data 0.001 (0.002)	Loss 2.3729 (2.1540)	Acc@1 36.719 (40.237)	Acc@5 67.969 (75.465)
Epoch: [2][140/391]	Time 0.115 (0.119)	Data 0.001 (0.002)	Loss 2.3429 (2.1564)	Acc@1 37.500 (40.182)	Acc@5 69.531 (75.404)
Epoch: [2][150/391]	Time 0.123 (0.119)	Data 0.001 (0.002)	Loss 1.7780 (2.1561)	Acc@1 48.438 (40.108)	Acc@5 81.250 (75.414)
Epoch: [2][160/391]	Time 0.117 (0.119)	Data 0.001 (0.002)	Loss 2.1300 (2.1633)	Acc@1 38.281 (39.965)	Acc@5 78.125 (75.345)
Epoch: [2][170/391]	Time 0.117 (0.119)	Data 0.001 (0.002)	Loss 2.2959 (2.1630)	Acc@1 37.500 (40.045)	Acc@5 65.625 (75.329)
Epoch: [2][180/391]	Time 0.115 (0.119)	Data 0.001 (0.002)	Loss 2.2415 (2.1645)	Acc@1 39.062 (40.029)	Acc@5 73.438 (75.363)
Epoch: [2][190/391]	Time 0.115 (0.119)	Data 0.001 (0.002)	Loss 2.0673 (2.1591)	Acc@1 40.625 (40.216)	Acc@5 79.688 (75.515)
Epoch: [2][200/391]	Time 0.126 (0.120)	Data 0.001 (0.002)	Loss 2.3667 (2.1595)	Acc@1 39.844 (40.217)	Acc@5 63.281 (75.455)
Epoch: [2][210/391]	Time 0.119 (0.120)	Data 0.001 (0.002)	Loss 1.9830 (2.1599)	Acc@1 46.875 (40.240)	Acc@5 76.562 (75.422)
