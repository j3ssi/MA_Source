digraph {
	graph [size="21.599999999999998,21.599999999999998"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140712356614384 [label=AddmmBackward fillcolor=darkolivegreen1]
	140712356647656 -> 140712356614384
	140712356647656 [label="module_list.21.bias
 (10)" fillcolor=lightblue]
	140712356647040 -> 140712356614384
	140712356647040 [label=ViewBackward]
	140712356648272 -> 140712356647040
	140712356648272 [label=ViewBackward]
	140712356649784 -> 140712356648272
	140712356649784 [label=MeanBackward1]
	140712356649616 -> 140712356649784
	140712356649616 [label=ViewBackward]
	140712356648496 -> 140712356649616
	140712356648496 [label=ReluBackward1]
	140712356647264 -> 140712356648496
	140712356647264 [label=CudnnBatchNormBackward]
	140711011258440 -> 140712356647264
	140711011258440 [label=CudnnConvolutionBackward]
	140711011258664 -> 140711011258440
	140711011258664 [label=ReluBackward1]
	140711011258832 -> 140711011258664
	140711011258832 [label=AddBackward0]
	140711011259000 -> 140711011258832
	140711011259000 [label=ReluBackward1]
	140711011259168 -> 140711011259000
	140711011259168 [label=CudnnBatchNormBackward]
	140711011259336 -> 140711011259168
	140711011259336 [label=CudnnConvolutionBackward]
	140711011259560 -> 140711011259336
	140711011259560 [label=ReluBackward1]
	140711011259728 -> 140711011259560
	140711011259728 [label=CudnnBatchNormBackward]
	140711011259896 -> 140711011259728
	140711011259896 [label=CudnnConvolutionBackward]
	140711011260120 -> 140711011259896
	140711011260120 [label=ReluBackward1]
	140711011260288 -> 140711011260120
	140711011260288 [label=AddBackward0]
	140711011260456 -> 140711011260288
	140711011260456 [label=ReluBackward1]
	140711011260624 -> 140711011260456
	140711011260624 [label=AddBackward0]
	140711011260792 -> 140711011260624
	140711011260792 [label=ReluBackward1]
	140711011260960 -> 140711011260792
	140711011260960 [label=CudnnBatchNormBackward]
	140711011261128 -> 140711011260960
	140711011261128 [label=CudnnConvolutionBackward]
	140711011261352 -> 140711011261128
	140711011261352 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140711011261184 -> 140711011260960
	140711011261184 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140711011261240 -> 140711011260960
	140711011261240 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140711011260848 -> 140711011260624
	140711011260848 [label=CudnnBatchNormBackward]
	140711011261016 -> 140711011260848
	140711011261016 [label=CudnnConvolutionBackward]
	140711011261464 -> 140711011261016
	140711011261464 [label=ReluBackward1]
	140711011261688 -> 140711011261464
	140711011261688 [label=CudnnBatchNormBackward]
	140711011261800 -> 140711011261688
	140711011261800 [label=CudnnConvolutionBackward]
	140711011260792 -> 140711011261800
	140711011262024 -> 140711011261800
	140711011262024 [label="module_list.2.weight
 (15, 16, 3, 3)" fillcolor=lightblue]
	140711011261856 -> 140711011261688
	140711011261856 [label="module_list.3.weight
 (15)" fillcolor=lightblue]
	140711011261912 -> 140711011261688
	140711011261912 [label="module_list.3.bias
 (15)" fillcolor=lightblue]
	140711011261576 -> 140711011261016
	140711011261576 [label="module_list.4.weight
 (16, 15, 3, 3)" fillcolor=lightblue]
	140711011261296 -> 140711011260848
	140711011261296 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140711011261408 -> 140711011260848
	140711011261408 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140711011260512 -> 140711011260288
	140711011260512 [label=CudnnBatchNormBackward]
	140711011260680 -> 140711011260512
	140711011260680 [label=CudnnConvolutionBackward]
	140711011261968 -> 140711011260680
	140711011261968 [label=ReluBackward1]
	140711011262192 -> 140711011261968
	140711011262192 [label=CudnnBatchNormBackward]
	140711011262136 -> 140711011262192
	140711011262136 [label=CudnnConvolutionBackward]
	140711011260456 -> 140711011262136
	140711011278920 -> 140711011262136
	140711011278920 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140711011262304 -> 140711011262192
	140711011262304 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140711011262360 -> 140711011262192
	140711011262360 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140711011262080 -> 140711011260680
	140711011262080 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140711011260904 -> 140711011260512
	140711011260904 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140711011261520 -> 140711011260512
	140711011261520 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140711011260176 -> 140711011259896
	140711011260176 [label="module_list.10.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140711011259952 -> 140711011259728
	140711011259952 [label="module_list.11.weight
 (32)" fillcolor=lightblue]
	140711011260008 -> 140711011259728
	140711011260008 [label="module_list.11.bias
 (32)" fillcolor=lightblue]
	140711011259616 -> 140711011259336
	140711011259616 [label="module_list.12.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140711011259392 -> 140711011259168
	140711011259392 [label="module_list.13.weight
 (32)" fillcolor=lightblue]
	140711011259448 -> 140711011259168
	140711011259448 [label="module_list.13.bias
 (32)" fillcolor=lightblue]
	140711011259056 -> 140711011258832
	140711011259056 [label=CudnnBatchNormBackward]
	140711011259224 -> 140711011259056
	140711011259224 [label=CudnnConvolutionBackward]
	140711011260232 -> 140711011259224
	140711011260232 [label=ReluBackward1]
	140711011261632 -> 140711011260232
	140711011261632 [label=CudnnBatchNormBackward]
	140711011261744 -> 140711011261632
	140711011261744 [label=CudnnConvolutionBackward]
	140711011259000 -> 140711011261744
	140711011279088 -> 140711011261744
	140711011279088 [label="module_list.14.weight
 (31, 32, 3, 3)" fillcolor=lightblue]
	140711011262416 -> 140711011261632
	140711011262416 [label="module_list.15.weight
 (31)" fillcolor=lightblue]
	140711011262248 -> 140711011261632
	140711011262248 [label="module_list.15.bias
 (31)" fillcolor=lightblue]
	140711011259784 -> 140711011259224
	140711011259784 [label="module_list.16.weight
 (32, 31, 3, 3)" fillcolor=lightblue]
	140711011259504 -> 140711011259056
	140711011259504 [label="module_list.17.weight
 (32)" fillcolor=lightblue]
	140711011259672 -> 140711011259056
	140711011259672 [label="module_list.17.bias
 (32)" fillcolor=lightblue]
	140711011258720 -> 140711011258440
	140711011258720 [label="module_list.18.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140711011258496 -> 140712356647264
	140711011258496 [label="module_list.19.weight
 (32)" fillcolor=lightblue]
	140711011258552 -> 140712356647264
	140711011258552 [label="module_list.19.bias
 (32)" fillcolor=lightblue]
	140712356648440 -> 140712356614384
	140712356648440 [label=TBackward]
	140712356649168 -> 140712356648440
	140712356649168 [label="module_list.21.weight
 (10, 32)" fillcolor=lightblue]
}
