Thres 0.1
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
numoFStages: 3
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
1
lr: 0.1

Epoch: [1 | 5] LR: 0.100000
Epoch: [1][0/196]	Time 0.718 (0.718)	Data 0.260 (0.260)	Loss 2.9851 (2.9851)	Acc@1 14.844 (14.844)	Acc@5 44.531 (44.531)
Epoch: [1][64/196]	Time 0.634 (0.588)	Data 0.000 (0.004)	Loss 2.2604 (2.5797)	Acc@1 32.031 (24.423)	Acc@5 89.453 (79.171)
Epoch: [1][128/196]	Time 0.391 (0.585)	Data 0.000 (0.002)	Loss 2.0338 (2.4124)	Acc@1 39.062 (30.169)	Acc@5 91.797 (83.703)
Epoch: [1][192/196]	Time 0.113 (0.482)	Data 0.000 (0.001)	Loss 2.0250 (2.3157)	Acc@1 44.531 (33.737)	Acc@5 93.359 (86.004)
Max memory in training epoch: 81.9808768
count0: 487386
1
lr: 0.1

Epoch: [2 | 5] LR: 0.100000
Epoch: [2][0/196]	Time 0.148 (0.148)	Data 0.274 (0.274)	Loss 2.0528 (2.0528)	Acc@1 43.750 (43.750)	Acc@5 88.672 (88.672)
Epoch: [2][64/196]	Time 0.120 (0.121)	Data 0.000 (0.004)	Loss 1.7937 (1.9355)	Acc@1 52.344 (48.065)	Acc@5 95.312 (92.903)
Epoch: [2][128/196]	Time 0.122 (0.122)	Data 0.000 (0.002)	Loss 1.7029 (1.8592)	Acc@1 55.078 (50.618)	Acc@5 96.484 (93.653)
Epoch: [2][192/196]	Time 0.114 (0.122)	Data 0.000 (0.002)	Loss 1.7127 (1.7950)	Acc@1 55.078 (52.951)	Acc@5 96.094 (94.254)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [3 | 5] LR: 0.100000
Epoch: [3][0/196]	Time 0.158 (0.158)	Data 0.278 (0.278)	Loss 1.5496 (1.5496)	Acc@1 58.984 (58.984)	Acc@5 97.266 (97.266)
Epoch: [3][64/196]	Time 0.122 (0.120)	Data 0.000 (0.004)	Loss 1.5953 (1.5335)	Acc@1 57.422 (61.611)	Acc@5 96.875 (96.304)
Epoch: [3][128/196]	Time 0.120 (0.120)	Data 0.000 (0.002)	Loss 1.5315 (1.4854)	Acc@1 59.375 (63.181)	Acc@5 97.656 (96.578)
Epoch: [3][192/196]	Time 0.124 (0.121)	Data 0.000 (0.002)	Loss 1.3552 (1.4429)	Acc@1 68.359 (64.427)	Acc@5 98.438 (96.899)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [4 | 5] LR: 0.100000
Epoch: [4][0/196]	Time 0.162 (0.162)	Data 0.275 (0.275)	Loss 1.2721 (1.2721)	Acc@1 69.141 (69.141)	Acc@5 98.828 (98.828)
Epoch: [4][64/196]	Time 0.122 (0.124)	Data 0.000 (0.004)	Loss 1.1289 (1.2795)	Acc@1 74.219 (69.477)	Acc@5 98.047 (97.873)
Epoch: [4][128/196]	Time 0.125 (0.123)	Data 0.000 (0.002)	Loss 1.1925 (1.2483)	Acc@1 73.828 (70.455)	Acc@5 97.656 (97.977)
Epoch: [4][192/196]	Time 0.121 (0.123)	Data 0.000 (0.002)	Loss 1.0835 (1.2269)	Acc@1 76.562 (71.156)	Acc@5 98.828 (97.964)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [5 | 5] LR: 0.100000
Epoch: [5][0/196]	Time 0.141 (0.141)	Data 0.273 (0.273)	Loss 1.1210 (1.1210)	Acc@1 73.828 (73.828)	Acc@5 98.047 (98.047)
Epoch: [5][64/196]	Time 0.120 (0.124)	Data 0.000 (0.004)	Loss 1.0520 (1.1250)	Acc@1 78.125 (74.050)	Acc@5 99.609 (98.245)
Epoch: [5][128/196]	Time 0.125 (0.124)	Data 0.000 (0.002)	Loss 1.0603 (1.0996)	Acc@1 75.391 (74.936)	Acc@5 97.266 (98.310)
Epoch: [5][192/196]	Time 0.119 (0.124)	Data 0.000 (0.002)	Loss 1.1420 (1.0902)	Acc@1 72.656 (75.055)	Acc@5 98.828 (98.389)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
Count: 372560 ; 487386 ; 0.7644043940531735
[INFO] Storing checkpoint...

  256
  71.07
Max memory: 102.6363904
 24.645s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.1568256
1
lr: 0.1

Epoch: [6 | 10] LR: 0.100000
Epoch: [6][0/196]	Time 0.334 (0.334)	Data 0.254 (0.254)	Loss 1.0493 (1.0493)	Acc@1 75.000 (75.000)	Acc@5 97.656 (97.656)
Epoch: [6][64/196]	Time 0.123 (0.120)	Data 0.000 (0.004)	Loss 0.9081 (0.9739)	Acc@1 77.734 (76.935)	Acc@5 98.828 (98.552)
Epoch: [6][128/196]	Time 0.119 (0.120)	Data 0.000 (0.002)	Loss 1.0339 (0.9840)	Acc@1 76.953 (76.472)	Acc@5 98.047 (98.528)
Epoch: [6][192/196]	Time 0.121 (0.121)	Data 0.000 (0.001)	Loss 0.8915 (0.9761)	Acc@1 83.594 (76.767)	Acc@5 98.047 (98.500)
Max memory in training epoch: 75.8281728
count0: 372560
1
lr: 0.1

Epoch: [7 | 10] LR: 0.100000
Epoch: [7][0/196]	Time 0.163 (0.163)	Data 0.310 (0.310)	Loss 0.8642 (0.8642)	Acc@1 79.688 (79.688)	Acc@5 99.609 (99.609)
Epoch: [7][64/196]	Time 0.124 (0.124)	Data 0.000 (0.005)	Loss 0.8302 (0.9311)	Acc@1 82.031 (78.179)	Acc@5 99.609 (98.720)
Epoch: [7][128/196]	Time 0.121 (0.124)	Data 0.000 (0.003)	Loss 0.8449 (0.9212)	Acc@1 80.469 (78.597)	Acc@5 100.000 (98.746)
Epoch: [7][192/196]	Time 0.122 (0.124)	Data 0.000 (0.002)	Loss 0.8263 (0.9111)	Acc@1 83.594 (78.874)	Acc@5 99.219 (98.802)
Max memory in training epoch: 65.4678528
count0: 372560
1
lr: 0.1

Epoch: [8 | 10] LR: 0.100000
Epoch: [8][0/196]	Time 0.163 (0.163)	Data 0.319 (0.319)	Loss 0.8563 (0.8563)	Acc@1 80.469 (80.469)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.609 (0.273)	Data 0.000 (0.005)	Loss 0.9091 (0.8739)	Acc@1 78.906 (79.748)	Acc@5 98.828 (98.864)
Epoch: [8][128/196]	Time 1.241 (0.656)	Data 0.000 (0.003)	Loss 0.8973 (0.8876)	Acc@1 80.078 (79.721)	Acc@5 98.438 (98.934)
Epoch: [8][192/196]	Time 1.240 (0.850)	Data 0.000 (0.002)	Loss 0.9642 (0.8891)	Acc@1 79.297 (79.815)	Acc@5 97.266 (98.915)
Max memory in training epoch: 65.4678528
count0: 372560
1
lr: 0.1

Epoch: [9 | 10] LR: 0.100000
Epoch: [9][0/196]	Time 1.259 (1.259)	Data 0.437 (0.437)	Loss 0.9535 (0.9535)	Acc@1 77.344 (77.344)	Acc@5 98.828 (98.828)
Epoch: [9][64/196]	Time 1.313 (1.246)	Data 0.000 (0.007)	Loss 0.8554 (0.8774)	Acc@1 83.984 (80.781)	Acc@5 99.219 (98.960)
Epoch: [9][128/196]	Time 1.037 (1.167)	Data 0.000 (0.004)	Loss 0.7848 (0.8780)	Acc@1 84.375 (80.605)	Acc@5 99.219 (98.964)
Epoch: [9][192/196]	Time 1.035 (1.124)	Data 0.000 (0.002)	Loss 0.9007 (0.8769)	Acc@1 81.250 (80.487)	Acc@5 99.219 (98.931)
Max memory in training epoch: 65.4678528
count0: 372560
1
lr: 0.1

Epoch: [10 | 10] LR: 0.100000
Epoch: [10][0/196]	Time 1.061 (1.061)	Data 0.330 (0.330)	Loss 0.8285 (0.8285)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [10][64/196]	Time 1.036 (1.043)	Data 0.000 (0.005)	Loss 0.7838 (0.8669)	Acc@1 81.641 (80.619)	Acc@5 99.609 (98.954)
Epoch: [10][128/196]	Time 1.036 (1.042)	Data 0.000 (0.003)	Loss 0.8300 (0.8465)	Acc@1 81.641 (81.262)	Acc@5 98.828 (98.977)
Epoch: [10][192/196]	Time 1.034 (1.041)	Data 0.000 (0.002)	Loss 0.9565 (0.8453)	Acc@1 79.688 (81.278)	Acc@5 97.266 (98.996)
Max memory in training epoch: 65.4678528
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 372560
Count: 254364 ; 372560 ; 0.6827464032639038
[INFO] Storing checkpoint...

  256
  73.18
Max memory: 101.0417152
 204.397s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.109824
1
lr: 0.1

Epoch: [11 | 15] LR: 0.100000
Epoch: [11][0/196]	Time 2.142 (2.142)	Data 0.286 (0.286)	Loss 1.0349 (1.0349)	Acc@1 76.562 (76.562)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 1.011 (1.029)	Data 0.000 (0.005)	Loss 0.8492 (0.8502)	Acc@1 80.859 (79.910)	Acc@5 98.438 (98.840)
Epoch: [11][128/196]	Time 1.010 (1.020)	Data 0.000 (0.002)	Loss 0.8149 (0.8518)	Acc@1 80.078 (79.842)	Acc@5 98.438 (98.807)
Epoch: [11][192/196]	Time 0.914 (1.018)	Data 0.000 (0.002)	Loss 0.8055 (0.8433)	Acc@1 82.031 (80.009)	Acc@5 97.656 (98.848)
Max memory in training epoch: 70.2340608
count0: 254364
1
lr: 0.1

Epoch: [12 | 15] LR: 0.100000
Epoch: [12][0/196]	Time 1.042 (1.042)	Data 0.472 (0.472)	Loss 0.8097 (0.8097)	Acc@1 82.422 (82.422)	Acc@5 98.438 (98.438)
Epoch: [12][64/196]	Time 1.010 (1.013)	Data 0.000 (0.007)	Loss 0.7274 (0.8158)	Acc@1 85.938 (81.136)	Acc@5 99.219 (99.002)
Epoch: [12][128/196]	Time 1.010 (1.012)	Data 0.000 (0.004)	Loss 0.8040 (0.8065)	Acc@1 81.641 (81.383)	Acc@5 98.828 (98.983)
Epoch: [12][192/196]	Time 0.888 (1.000)	Data 0.000 (0.003)	Loss 0.9296 (0.8119)	Acc@1 75.781 (81.145)	Acc@5 98.438 (98.994)
Max memory in training epoch: 61.1772928
count0: 254364
1
lr: 0.1

Epoch: [13 | 15] LR: 0.100000
Epoch: [13][0/196]	Time 0.750 (0.750)	Data 0.343 (0.343)	Loss 0.8344 (0.8344)	Acc@1 81.250 (81.250)	Acc@5 99.609 (99.609)
Epoch: [13][64/196]	Time 0.998 (0.824)	Data 0.000 (0.005)	Loss 0.8041 (0.8204)	Acc@1 80.859 (80.685)	Acc@5 100.000 (99.026)
Epoch: [13][128/196]	Time 1.197 (0.993)	Data 0.000 (0.003)	Loss 0.7901 (0.8049)	Acc@1 82.422 (81.435)	Acc@5 98.828 (99.079)
Epoch: [13][192/196]	Time 1.196 (1.061)	Data 0.000 (0.002)	Loss 0.8964 (0.8028)	Acc@1 78.516 (81.539)	Acc@5 98.828 (99.091)
Max memory in training epoch: 61.1772928
count0: 254364
1
lr: 0.1

Epoch: [14 | 15] LR: 0.100000
Epoch: [14][0/196]	Time 1.220 (1.220)	Data 0.269 (0.269)	Loss 0.9628 (0.9628)	Acc@1 76.562 (76.562)	Acc@5 96.484 (96.484)
Epoch: [14][64/196]	Time 0.997 (1.178)	Data 0.000 (0.004)	Loss 0.7494 (0.7963)	Acc@1 83.984 (81.851)	Acc@5 99.609 (99.032)
Epoch: [14][128/196]	Time 1.001 (1.093)	Data 0.000 (0.002)	Loss 0.8160 (0.7855)	Acc@1 80.469 (82.295)	Acc@5 100.000 (99.095)
Epoch: [14][192/196]	Time 0.997 (1.066)	Data 0.000 (0.002)	Loss 0.8797 (0.7828)	Acc@1 75.391 (82.333)	Acc@5 99.219 (99.136)
Max memory in training epoch: 61.1772928
count0: 254364
1
lr: 0.1

Epoch: [15 | 15] LR: 0.100000
Epoch: [15][0/196]	Time 1.017 (1.017)	Data 0.304 (0.304)	Loss 0.7805 (0.7805)	Acc@1 80.469 (80.469)	Acc@5 99.219 (99.219)
Epoch: [15][64/196]	Time 1.005 (1.011)	Data 0.000 (0.005)	Loss 0.7450 (0.7752)	Acc@1 82.812 (82.578)	Acc@5 98.828 (99.225)
Epoch: [15][128/196]	Time 0.997 (1.009)	Data 0.000 (0.002)	Loss 0.8031 (0.7722)	Acc@1 81.250 (82.634)	Acc@5 97.656 (99.140)
Epoch: [15][192/196]	Time 1.041 (1.010)	Data 0.000 (0.002)	Loss 0.8511 (0.7863)	Acc@1 80.469 (82.240)	Acc@5 98.438 (99.089)
Max memory in training epoch: 61.1772928
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 254364
Count: 248438 ; 254364 ; 0.9767026780519256
[INFO] Storing checkpoint...

  256
  72.26
Max memory: 94.9621248
 198.256s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Epoch: [16][0/196]	Time 2.516 (2.516)	Data 0.285 (0.285)	Loss 0.8471 (0.8471)	Acc@1 80.078 (80.078)	Acc@5 98.828 (98.828)
Epoch: [16][64/196]	Time 1.196 (1.216)	Data 0.000 (0.005)	Loss 0.8269 (0.7605)	Acc@1 80.469 (83.371)	Acc@5 98.438 (99.147)
Epoch: [16][128/196]	Time 1.196 (1.206)	Data 0.000 (0.002)	Loss 0.9103 (0.7625)	Acc@1 77.734 (82.976)	Acc@5 98.438 (99.125)
Epoch: [16][192/196]	Time 1.194 (1.203)	Data 0.000 (0.002)	Loss 0.8234 (0.7645)	Acc@1 78.516 (82.806)	Acc@5 98.828 (99.099)
Max memory in training epoch: 69.397248
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 423, in main
    test_loss, test_acc, test_epoch_time = test(testloader, model, criterion, epoch, use_cuda)
  File "main.py", line 705, in test
    outputs = model(inputs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.76 GiB total capacity; 584.35 MiB already allocated; 19.94 MiB free; 600.00 MiB reserved in total by PyTorch)
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 596, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1610, in linear
    ret = torch.addmm(bias, input, weight.t())
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.1075712
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Epoch: [16][0/196]	Time 1.913 (1.913)	Data 0.438 (0.438)	Loss 0.7781 (0.7781)	Acc@1 82.812 (82.812)	Acc@5 98.438 (98.438)
Epoch: [16][64/196]	Time 1.179 (1.198)	Data 0.000 (0.007)	Loss 0.7446 (0.7507)	Acc@1 85.547 (83.395)	Acc@5 99.219 (99.201)
Epoch: [16][128/196]	Time 1.280 (1.206)	Data 0.000 (0.004)	Loss 0.7543 (0.7602)	Acc@1 85.156 (83.040)	Acc@5 100.000 (99.188)
Epoch: [16][192/196]	Time 1.200 (1.210)	Data 0.000 (0.003)	Loss 0.7542 (0.7688)	Acc@1 79.297 (82.679)	Acc@5 99.609 (99.154)
Max memory in training epoch: 69.397248
count0: 248438
1
lr: 0.1

Epoch: [17 | 20] LR: 0.100000
Epoch: [17][0/196]	Time 0.986 (0.986)	Data 0.527 (0.527)	Loss 0.7257 (0.7257)	Acc@1 83.984 (83.984)	Acc@5 98.438 (98.438)
Epoch: [17][64/196]	Time 1.192 (1.057)	Data 0.000 (0.008)	Loss 0.8741 (0.7576)	Acc@1 79.688 (83.119)	Acc@5 100.000 (99.141)
Epoch: [17][128/196]	Time 1.255 (1.133)	Data 0.000 (0.004)	Loss 0.8184 (0.7630)	Acc@1 80.859 (83.046)	Acc@5 99.609 (99.104)
Epoch: [17][192/196]	Time 1.209 (1.156)	Data 0.000 (0.003)	Loss 0.8402 (0.7670)	Acc@1 82.422 (82.871)	Acc@5 98.438 (99.114)
Max memory in training epoch: 60.5915648
count0: 248438
1
lr: 0.1

Epoch: [18 | 20] LR: 0.100000
Epoch: [18][0/196]	Time 1.230 (1.230)	Data 0.474 (0.474)	Loss 0.7430 (0.7430)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [18][64/196]	Time 1.058 (1.153)	Data 0.000 (0.007)	Loss 0.7664 (0.7642)	Acc@1 83.203 (83.059)	Acc@5 99.609 (99.123)
Epoch: [18][128/196]	Time 1.203 (1.166)	Data 0.000 (0.004)	Loss 0.6469 (0.7583)	Acc@1 89.062 (83.227)	Acc@5 99.219 (99.137)
Epoch: [18][192/196]	Time 1.008 (1.160)	Data 0.000 (0.003)	Loss 0.7288 (0.7621)	Acc@1 82.031 (83.088)	Acc@5 99.219 (99.130)
Max memory in training epoch: 60.5915648
count0: 248438
1
lr: 0.1

Epoch: [19 | 20] LR: 0.100000
Epoch: [19][0/196]	Time 1.247 (1.247)	Data 0.462 (0.462)	Loss 0.7873 (0.7873)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 1.332 (1.209)	Data 0.000 (0.007)	Loss 0.7465 (0.7579)	Acc@1 85.156 (83.299)	Acc@5 99.609 (99.225)
Epoch: [19][128/196]	Time 1.191 (1.202)	Data 0.000 (0.004)	Loss 0.7613 (0.7552)	Acc@1 84.375 (83.448)	Acc@5 98.438 (99.210)
Epoch: [19][192/196]	Time 1.189 (1.204)	Data 0.000 (0.003)	Loss 0.8337 (0.7542)	Acc@1 77.734 (83.406)	Acc@5 98.047 (99.188)
Max memory in training epoch: 60.5915648
count0: 248438
1
lr: 0.1

Epoch: [20 | 20] LR: 0.100000
Epoch: [20][0/196]	Time 0.921 (0.921)	Data 0.558 (0.558)	Loss 0.7500 (0.7500)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [20][64/196]	Time 1.002 (1.032)	Data 0.000 (0.009)	Loss 0.8601 (0.7503)	Acc@1 82.031 (83.462)	Acc@5 98.438 (99.183)
Epoch: [20][128/196]	Time 0.994 (1.031)	Data 0.000 (0.005)	Loss 0.6532 (0.7490)	Acc@1 87.109 (83.406)	Acc@5 99.219 (99.170)
Epoch: [20][192/196]	Time 0.961 (1.026)	Data 0.000 (0.003)	Loss 0.8785 (0.7484)	Acc@1 79.688 (83.440)	Acc@5 99.609 (99.231)
Max memory in training epoch: 60.5915648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 248438
Count: 240198 ; 248438 ; 0.9668327711541712
[INFO] Storing checkpoint...

  256
  70.71
Max memory: 93.8813952
 201.518s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1042432
1
lr: 0.1

Epoch: [21 | 25] LR: 0.100000
Epoch: [21][0/196]	Time 2.614 (2.614)	Data 0.503 (0.503)	Loss 0.8087 (0.8087)	Acc@1 78.516 (78.516)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 1.195 (1.251)	Data 0.000 (0.008)	Loss 0.7457 (0.7282)	Acc@1 83.594 (83.840)	Acc@5 98.438 (99.261)
Epoch: [21][128/196]	Time 1.284 (1.238)	Data 0.000 (0.004)	Loss 0.7880 (0.7418)	Acc@1 83.203 (83.454)	Acc@5 98.438 (99.173)
Epoch: [21][192/196]	Time 0.997 (1.216)	Data 0.000 (0.003)	Loss 0.8394 (0.7386)	Acc@1 82.031 (83.594)	Acc@5 98.828 (99.215)
Max memory in training epoch: 68.0929792
count0: 240198
1
lr: 0.1

Epoch: [22 | 25] LR: 0.100000
Epoch: [22][0/196]	Time 1.056 (1.056)	Data 0.745 (0.745)	Loss 0.7471 (0.7471)	Acc@1 83.984 (83.984)	Acc@5 98.828 (98.828)
Epoch: [22][64/196]	Time 0.927 (1.021)	Data 0.000 (0.012)	Loss 0.6727 (0.7221)	Acc@1 83.203 (84.525)	Acc@5 99.609 (99.243)
Epoch: [22][128/196]	Time 0.994 (1.020)	Data 0.000 (0.006)	Loss 0.7625 (0.7418)	Acc@1 82.422 (83.809)	Acc@5 97.266 (99.222)
Epoch: [22][192/196]	Time 0.991 (1.014)	Data 0.000 (0.004)	Loss 0.7402 (0.7365)	Acc@1 85.156 (83.950)	Acc@5 99.219 (99.201)
Max memory in training epoch: 59.2710656
count0: 240198
1
lr: 0.1

Epoch: [23 | 25] LR: 0.100000
Epoch: [23][0/196]	Time 0.993 (0.993)	Data 0.484 (0.484)	Loss 0.7366 (0.7366)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [23][64/196]	Time 1.048 (1.143)	Data 0.000 (0.008)	Loss 0.8114 (0.7378)	Acc@1 82.422 (83.744)	Acc@5 99.219 (99.309)
Epoch: [23][128/196]	Time 1.202 (1.172)	Data 0.000 (0.004)	Loss 0.7965 (0.7368)	Acc@1 80.078 (83.742)	Acc@5 98.438 (99.288)
Epoch: [23][192/196]	Time 1.178 (1.183)	Data 0.000 (0.003)	Loss 0.8088 (0.7391)	Acc@1 81.250 (83.695)	Acc@5 97.656 (99.265)
Max memory in training epoch: 59.2710656
count0: 240198
1
lr: 0.1

Epoch: [24 | 25] LR: 0.100000
Epoch: [24][0/196]	Time 1.219 (1.219)	Data 0.512 (0.512)	Loss 0.7073 (0.7073)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [24][64/196]	Time 1.216 (1.197)	Data 0.000 (0.008)	Loss 0.7143 (0.7247)	Acc@1 85.156 (84.351)	Acc@5 100.000 (99.279)
Epoch: [24][128/196]	Time 1.114 (1.159)	Data 0.000 (0.004)	Loss 0.8244 (0.7269)	Acc@1 79.297 (84.221)	Acc@5 99.609 (99.249)
Epoch: [24][192/196]	Time 1.024 (1.173)	Data 0.000 (0.003)	Loss 0.7686 (0.7351)	Acc@1 81.641 (84.049)	Acc@5 99.609 (99.192)
Max memory in training epoch: 59.2710656
count0: 240198
1
lr: 0.1

Epoch: [25 | 25] LR: 0.100000
Epoch: [25][0/196]	Time 1.153 (1.153)	Data 0.419 (0.419)	Loss 0.6355 (0.6355)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [25][64/196]	Time 1.222 (1.207)	Data 0.000 (0.007)	Loss 0.7042 (0.7231)	Acc@1 86.328 (84.471)	Acc@5 99.609 (99.327)
Epoch: [25][128/196]	Time 1.003 (1.155)	Data 0.000 (0.003)	Loss 0.7472 (0.7264)	Acc@1 84.766 (84.269)	Acc@5 98.828 (99.261)
Epoch: [25][192/196]	Time 0.809 (1.107)	Data 0.000 (0.002)	Loss 0.8385 (0.7284)	Acc@1 80.078 (84.156)	Acc@5 98.828 (99.239)
Max memory in training epoch: 59.2710656
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 240198
Count: 230374 ; 240198 ; 0.9591004088293824
[INFO] Storing checkpoint...

  256
  76.3
Max memory: 91.986432
 216.884s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Epoch: [26][0/196]	Time 3.378 (3.378)	Data 0.464 (0.464)	Loss 0.7197 (0.7197)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 1.398 (1.436)	Data 0.000 (0.007)	Loss 0.6742 (0.7009)	Acc@1 87.500 (85.186)	Acc@5 99.219 (99.363)
Epoch: [26][128/196]	Time 1.257 (1.359)	Data 0.000 (0.004)	Loss 0.6563 (0.7160)	Acc@1 87.109 (84.551)	Acc@5 98.828 (99.325)
Epoch: [26][192/196]	Time 1.244 (1.310)	Data 0.000 (0.003)	Loss 0.6462 (0.7161)	Acc@1 86.719 (84.513)	Acc@5 99.219 (99.306)
Max memory in training epoch: 60.854528
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 423, in main
    test_loss, test_acc, test_epoch_time = test(testloader, model, criterion, epoch, use_cuda)
  File "main.py", line 705, in test
    outputs = model(inputs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 537, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 10.76 GiB total capacity; 627.46 MiB already allocated; 11.94 MiB free; 644.00 MiB reserved in total by PyTorch)
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 525.11 MiB already allocated; 89.94 MiB free; 590.00 MiB reserved in total by PyTorch)
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 525.11 MiB already allocated; 89.94 MiB free; 590.00 MiB reserved in total by PyTorch)
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 525.11 MiB already allocated; 89.94 MiB free; 590.00 MiB reserved in total by PyTorch)
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 525.11 MiB already allocated; 89.94 MiB free; 590.00 MiB reserved in total by PyTorch)
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 525.11 MiB already allocated; 89.94 MiB free; 590.00 MiB reserved in total by PyTorch)
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 10.76 GiB total capacity; 525.11 MiB already allocated; 89.94 MiB free; 590.00 MiB reserved in total by PyTorch)
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1004544
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Epoch: [26][0/196]	Time 2.344 (2.344)	Data 0.518 (0.518)	Loss 0.6958 (0.6958)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [26][64/196]	Time 1.199 (1.154)	Data 0.000 (0.008)	Loss 0.6682 (0.7083)	Acc@1 85.156 (84.579)	Acc@5 99.609 (99.345)
Epoch: [26][128/196]	Time 1.208 (1.181)	Data 0.000 (0.004)	Loss 0.6566 (0.7160)	Acc@1 87.109 (84.439)	Acc@5 99.609 (99.237)
Epoch: [26][192/196]	Time 1.197 (1.187)	Data 0.000 (0.003)	Loss 0.6585 (0.7210)	Acc@1 86.328 (84.209)	Acc@5 99.609 (99.257)
Max memory in training epoch: 66.7034112
count0: 230374
1
lr: 0.1

Epoch: [27 | 30] LR: 0.100000
Epoch: [27][0/196]	Time 1.194 (1.194)	Data 0.528 (0.528)	Loss 0.7046 (0.7046)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [27][64/196]	Time 1.002 (1.064)	Data 0.000 (0.008)	Loss 0.8320 (0.7205)	Acc@1 80.078 (84.423)	Acc@5 98.438 (99.303)
Epoch: [27][128/196]	Time 1.101 (1.038)	Data 0.000 (0.004)	Loss 0.7421 (0.7202)	Acc@1 82.812 (84.369)	Acc@5 99.219 (99.285)
Epoch: [27][192/196]	Time 0.993 (1.026)	Data 0.000 (0.003)	Loss 0.6520 (0.7146)	Acc@1 85.938 (84.573)	Acc@5 100.000 (99.308)
Max memory in training epoch: 57.902336
count0: 230374
1
lr: 0.1

Epoch: [28 | 30] LR: 0.100000
Epoch: [28][0/196]	Time 1.052 (1.052)	Data 0.483 (0.483)	Loss 0.7005 (0.7005)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [28][64/196]	Time 0.988 (1.006)	Data 0.000 (0.008)	Loss 0.6454 (0.7024)	Acc@1 86.719 (84.838)	Acc@5 100.000 (99.375)
Epoch: [28][128/196]	Time 1.239 (1.046)	Data 0.000 (0.004)	Loss 0.7768 (0.7139)	Acc@1 82.812 (84.648)	Acc@5 99.219 (99.331)
Epoch: [28][192/196]	Time 1.081 (1.080)	Data 0.000 (0.003)	Loss 0.7735 (0.7116)	Acc@1 82.031 (84.620)	Acc@5 99.609 (99.342)
Max memory in training epoch: 57.902336
count0: 230374
1
lr: 0.1

Epoch: [29 | 30] LR: 0.100000
Epoch: [29][0/196]	Time 0.999 (0.999)	Data 0.467 (0.467)	Loss 0.6709 (0.6709)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [29][64/196]	Time 1.393 (0.964)	Data 0.000 (0.007)	Loss 0.6478 (0.7057)	Acc@1 85.938 (84.862)	Acc@5 99.219 (99.273)
Epoch: [29][128/196]	Time 1.210 (1.148)	Data 0.000 (0.004)	Loss 0.7171 (0.7114)	Acc@1 82.031 (84.433)	Acc@5 99.219 (99.316)
Epoch: [29][192/196]	Time 1.209 (1.168)	Data 0.000 (0.003)	Loss 0.6926 (0.7204)	Acc@1 86.719 (84.189)	Acc@5 99.609 (99.257)
Max memory in training epoch: 57.902336
count0: 230374
1
lr: 0.1

Epoch: [30 | 30] LR: 0.100000
Epoch: [30][0/196]	Time 1.245 (1.245)	Data 0.497 (0.497)	Loss 0.6361 (0.6361)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [30][64/196]	Time 1.007 (1.172)	Data 0.000 (0.008)	Loss 0.6884 (0.7045)	Acc@1 84.766 (84.880)	Acc@5 99.219 (99.321)
Epoch: [30][128/196]	Time 1.206 (1.174)	Data 0.000 (0.004)	Loss 0.7036 (0.7106)	Acc@1 83.594 (84.705)	Acc@5 98.828 (99.310)
Epoch: [30][192/196]	Time 1.205 (1.185)	Data 0.000 (0.003)	Loss 0.7475 (0.7117)	Acc@1 83.203 (84.628)	Acc@5 99.609 (99.306)
Max memory in training epoch: 57.902336
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
count0: 230374
Count: 226554 ; 230374 ; 0.9834182676864577
[INFO] Storing checkpoint...

  256
  68.16
Max memory: 89.6428032
 233.103s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Epoch: [31][0/196]	Time 2.626 (2.626)	Data 0.403 (0.403)	Loss 0.7056 (0.7056)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 1.093 (1.153)	Data 0.000 (0.006)	Loss 0.6563 (0.6821)	Acc@1 87.891 (85.499)	Acc@5 99.219 (99.393)
Epoch: [31][128/196]	Time 1.124 (1.142)	Data 0.000 (0.003)	Loss 0.7383 (0.6949)	Acc@1 82.422 (85.129)	Acc@5 100.000 (99.334)
Epoch: [31][192/196]	Time 0.909 (1.139)	Data 0.000 (0.002)	Loss 0.7061 (0.7008)	Acc@1 85.547 (84.994)	Acc@5 99.609 (99.336)
Max memory in training epoch: 64.8375808
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 423, in main
    test_loss, test_acc, test_epoch_time = test(testloader, model, criterion, epoch, use_cuda)
  File "main.py", line 705, in test
    outputs = model(inputs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 633.65 MiB already allocated; 19.94 MiB free; 670.00 MiB reserved in total by PyTorch)
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 135.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7fbebf4a7536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7fbebf6f0f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7fbebf6eb95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7fbe5c57e906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7fbe5c58224d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7fbe5c5755da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7fbe5c5762f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7fbe5c57a32b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7fbe5c57a882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7fbe5c5e13a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7fbe5c625c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7fbe5c57bf1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7fbe5c5e16cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7fbe5c625c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7fbe9a76b9b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7fbe9a7bb444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7fbe9a383918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7fbe9a874c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7fbe9a871f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7fbe9a872ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7fbe9a86b359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7fbec00264d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7fbea6ddb6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7fbeca4236db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7fbeca75c88f in /lib/x86_64-linux-gnu/libc.so.6)

j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f449f789536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f449f9d2f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f449f9cd95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f443a860906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f443a86424d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f443a8575da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f443a8582f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f443a85c32b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f443a85c882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f443a8c33a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f443a907c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f443a85df1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f443a8c36cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f443a907c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f4478a4d9b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f4478a9d444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f4478665918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f4478b56c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f4478b53f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f4478b54ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f4478b4d359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f44a03084d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f44850bd6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f44a87056db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f44a8a3e88f in /lib/x86_64-linux-gnu/libc.so.6)

j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f7ac8a41536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f7ac8c8af1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f7ac8c8595b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f7a62c32906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f7a62c3624d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f7a62c295da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f7a62c2a2f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f7a62c2e32b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f7a62c2e882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f7a62c953a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f7a62cd9c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f7a62c2ff1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f7a62c956cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f7a62cd9c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f7aa0e1f9b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f7aa0e6f444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f7aa0a37918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f7aa0f28c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f7aa0f25f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f7aa0f26ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f7aa0f1f359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f7ac5ed94d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f7aad48f6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f7ad0ad76db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f7ad0e1088f in /lib/x86_64-linux-gnu/libc.so.6)

j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f15df49c536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f15df6e5f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f15df6e095b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f1578458906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f157845c24d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f157844f5da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f15784502f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f157845432b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f1578454882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f15784bb3a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f15784ffc38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f1578455f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f15784bb6cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f15784ffc94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f15b66459b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f15b6695444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f15b625d918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f15b674ec05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f15b674bf03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f15b674cce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f15b6745359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f15e001b4d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f15c2cb56df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f15e62fd6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f15e663688f in /lib/x86_64-linux-gnu/libc.so.6)

j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f10e773a536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f10e7983f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f10e797e95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f10806f6906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f10806fa24d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f10806ed5da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f10806ee2f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f10806f232b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f10806f2882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f10807593a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f108079dc38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f10806f3f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f10807596cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f108079dc94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f10be8e39b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f10be933444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f10be4fb918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f10be9ecc05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f10be9e9f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f10be9eace2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f10be9e3359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f10e82b94d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f10caf536df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f10ee59b6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f10ee8d488f in /lib/x86_64-linux-gnu/libc.so.6)

j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f979c1d8536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f979c421f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f979c41c95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f97363c9906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f97363cd24d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f97363c05da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f97363c12f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f97363c532b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f97363c5882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f973642c3a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f9736470c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f97363c6f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f973642c6cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f9736470c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f97745b69b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f9774606444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f97741ce918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f97746bfc05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f97746bcf03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f97746bdce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f97746b6359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f97996704d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f9780c266df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f97a426e6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f97a45a788f in /lib/x86_64-linux-gnu/libc.so.6)

j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f35c1e23536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f35c206cf1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f35c206795b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f355addf906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f355ade324d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f355add65da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f355add72f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f355addb32b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f355addb882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f355ae423a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f355ae86c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f355addcf1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f355ae426cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f355ae86c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f3598fcc9b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f359901c444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f3598be4918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f35990d5c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f35990d2f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f35990d3ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f35990cc359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f35c29a24d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f35a563c6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f35c8c846db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f35c8fbd88f in /lib/x86_64-linux-gnu/libc.so.6)

j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f141e843536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f141ea8cf1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f141ea8795b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f13b991a906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f13b991e24d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f13b99115da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f13b99122f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f13b991632b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f13b9916882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f13b997d3a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f13b99c1c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f13b9917f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f13b997d6cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f13b99c1c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f13f7b079b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f13f7b57444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f13f771f918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f13f7c10c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f13f7c0df03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f13f7c0ece2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f13f7c07359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f141f3c24d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f14041776df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f14277bf6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f1427af888f in /lib/x86_64-linux-gnu/libc.so.6)

j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f48cc669536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f48cc8b2f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f48cc8ad95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f4865625906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f486562924d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f486561c5da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f486561d2f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f486562132b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f4865621882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f48656883a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f48656ccc38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f4865622f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f48656886cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f48656ccc94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f48a38129b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f48a3862444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f48a342a918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f48a391bc05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f48a3918f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f48a3919ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f48a3912359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f48cd1e84d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f48afe826df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f48d34ca6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f48d380388f in /lib/x86_64-linux-gnu/libc.so.6)

j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f16a3f5e536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f16a41a7f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f16a41a295b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f163f035906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f163f03924d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f163f02c5da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f163f02d2f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f163f03132b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f163f031882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f163f0983a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f163f0dcc38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f163f032f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f163f0986cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f163f0dcc94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f167d2229b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f167d272444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f167ce3a918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f167d32bc05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f167d328f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f167d329ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f167d322359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f16a4add4d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f16898926df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f16aceda6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f16ad21388f in /lib/x86_64-linux-gnu/libc.so.6)

j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f46ee973536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f46eebbcf1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f46eebb795b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f4686a49906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f4686a4d24d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f4686a405da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f4686a412f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f4686a4532b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f4686a45882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f4686aac3a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f4686af0c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f4686a46f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f4686aac6cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f4686af0c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f46c4c369b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f46c4c86444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f46c484e918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f46c4d3fc05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f46c4d3cf03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f46c4d3dce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f46c4d36359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f46ebcf04d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f46d12a66df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f46f48ee6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f46f4c2788f in /lib/x86_64-linux-gnu/libc.so.6)

j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7febbe3ba536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7febbe603f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7febbe5fe95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7feb585ab906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7feb585af24d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7feb585a25da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7feb585a32f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7feb585a732b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7feb585a7882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7feb5860e3a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7feb58652c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7feb585a8f1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7feb5860e6cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7feb58652c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7feb967989b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7feb967e8444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7feb963b0918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7feb968a1c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7feb9689ef03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7feb9689fce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7feb96898359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7febbb8524d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7feba2e086df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7febc64506db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7febc678988f in /lib/x86_64-linux-gnu/libc.so.6)

j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Warning: Error detected in CudnnConvolutionBackward. Traceback of forward call that caused the error:
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 548, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
 (print_stack at /pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:60)
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 653, in train
    loss.backward()
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/tensor.py", line 198, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/autograd/__init__.py", line 100, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 134.00 MiB (GPU 0; 10.76 GiB total capacity; 476.78 MiB already allocated; 133.94 MiB free; 554.00 MiB reserved in total by PyTorch) (malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x46 (0x7f2accc1b536 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1cf1e (0x7f2acce64f1e in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: c10::cuda::CUDACachingAllocator::raw_alloc(unsigned long) + 0x5b (0x7f2acce5f95b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0xf1c906 (0x7f2a67cf2906 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xf2024d (0x7f2a67cf624d in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf135da (0x7f2a67ce95da in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf142f1 (0x7f2a67cea2f1 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0xf1832b (0x7f2a67cee32b in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #8: at::native::cudnn_convolution_backward_input(c10::ArrayRef<long>, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool) + 0xb2 (0x7f2a67cee882 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #9: <unknown function> + 0xf7f3a0 (0x7f2a67d553a0 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0xfc3c38 (0x7f2a67d99c38 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #11: at::native::cudnn_convolution_backward(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long, bool, bool, std::array<bool, 2ul>) + 0x4fa (0x7f2a67ceff1a in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #12: <unknown function> + 0xf7f6cb (0x7f2a67d556cb in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #13: <unknown function> + 0xfc3c94 (0x7f2a67d99c94 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0x2c809b6 (0x7f2aa5edf9b6 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x2cd0444 (0x7f2aa5f2f444 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #16: torch::autograd::generated::CudnnConvolutionBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x378 (0x7f2aa5af7918 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2d89c05 (0x7f2aa5fe8c05 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x16f3 (0x7f2aa5fe5f03 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f2aa5fe6ce2 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f2aa5fdf359 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f2acd79a4d8 in /home/jessica.buehler/venv/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #22: <unknown function> + 0xbd6df (0x7f2ab254f6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #23: <unknown function> + 0x76db (0x7f2ad5b976db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #24: clone + 0x3f (0x7f2ad5ed088f in /lib/x86_64-linux-gnu/libc.so.6)

j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.0984064
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Epoch: [31][0/196]	Time 2.010 (2.010)	Data 0.519 (0.519)	Loss 0.6967 (0.6967)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.745 (0.777)	Data 0.000 (0.008)	Loss 0.7683 (0.7022)	Acc@1 85.156 (84.784)	Acc@5 98.828 (99.435)
Epoch: [31][128/196]	Time 1.135 (0.901)	Data 0.000 (0.004)	Loss 0.6420 (0.6970)	Acc@1 86.719 (84.990)	Acc@5 99.219 (99.382)
Epoch: [31][192/196]	Time 1.141 (0.977)	Data 0.000 (0.003)	Loss 0.6996 (0.7022)	Acc@1 85.938 (84.919)	Acc@5 99.219 (99.324)
Max memory in training epoch: 64.8375808
count0: 226554
1
lr: 0.1

Epoch: [32 | 35] LR: 0.100000
Epoch: [32][0/196]	Time 1.184 (1.184)	Data 0.609 (0.609)	Loss 0.6296 (0.6296)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 1.102 (1.117)	Data 0.000 (0.010)	Loss 0.6390 (0.6889)	Acc@1 88.672 (85.361)	Acc@5 99.609 (99.381)
Epoch: [32][128/196]	Time 1.166 (1.080)	Data 0.000 (0.005)	Loss 0.6570 (0.6995)	Acc@1 87.109 (84.853)	Acc@5 99.609 (99.367)
Epoch: [32][192/196]	Time 1.144 (1.099)	Data 0.000 (0.003)	Loss 0.7380 (0.7072)	Acc@1 83.984 (84.594)	Acc@5 98.438 (99.318)
Max memory in training epoch: 55.889664
count0: 226554
1
lr: 0.1

Epoch: [33 | 35] LR: 0.100000
Epoch: [33][0/196]	Time 1.230 (1.230)	Data 0.489 (0.489)	Loss 0.6516 (0.6516)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 1.143 (1.138)	Data 0.000 (0.008)	Loss 0.6556 (0.7114)	Acc@1 85.938 (84.730)	Acc@5 99.219 (99.339)
Epoch: [33][128/196]	Time 0.944 (1.108)	Data 0.000 (0.004)	Loss 0.6735 (0.7047)	Acc@1 85.938 (84.781)	Acc@5 98.828 (99.328)
Epoch: [33][192/196]	Time 1.137 (1.103)	Data 0.000 (0.003)	Loss 0.8337 (0.7077)	Acc@1 83.594 (84.646)	Acc@5 98.828 (99.340)
Max memory in training epoch: 55.889664
count0: 226554
1
lr: 0.1

Epoch: [34 | 35] LR: 0.100000
Epoch: [34][0/196]	Time 1.185 (1.185)	Data 0.645 (0.645)	Loss 0.7473 (0.7473)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 1.126 (1.129)	Data 0.000 (0.010)	Loss 0.6663 (0.6919)	Acc@1 85.938 (85.120)	Acc@5 98.828 (99.393)
Epoch: [34][128/196]	Time 1.135 (1.127)	Data 0.000 (0.005)	Loss 0.7355 (0.6965)	Acc@1 85.156 (84.975)	Acc@5 99.609 (99.337)
Epoch: [34][192/196]	Time 1.128 (1.101)	Data 0.000 (0.004)	Loss 0.6737 (0.6984)	Acc@1 86.328 (84.919)	Acc@5 100.000 (99.326)
Max memory in training epoch: 55.889664
count0: 226554
1
lr: 0.1

Epoch: [35 | 35] LR: 0.100000
Epoch: [35][0/196]	Time 1.197 (1.197)	Data 0.551 (0.551)	Loss 0.7547 (0.7547)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [35][64/196]	Time 1.191 (1.137)	Data 0.000 (0.009)	Loss 0.7507 (0.7019)	Acc@1 85.156 (85.000)	Acc@5 99.219 (99.321)
Epoch: [35][128/196]	Time 1.114 (1.135)	Data 0.000 (0.004)	Loss 0.6479 (0.6998)	Acc@1 87.500 (84.987)	Acc@5 99.609 (99.364)
Epoch: [35][192/196]	Time 1.021 (1.135)	Data 0.000 (0.003)	Loss 0.7452 (0.7025)	Acc@1 83.984 (84.879)	Acc@5 98.828 (99.332)
Max memory in training epoch: 55.889664
count0: 226554
[INFO] Storing checkpoint...

  256
  69.02
Max memory: 86.267904
 222.707s  Thres 0.01
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
numoFStages: 3
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
1
lr: 0.1

Epoch: [1 | 5] LR: 0.100000
Epoch: [1][0/196]	Time 1.487 (1.487)	Data 0.448 (0.448)	Loss 3.1955 (3.1955)	Acc@1 10.547 (10.547)	Acc@5 50.000 (50.000)
Epoch: [1][64/196]	Time 1.190 (1.209)	Data 0.000 (0.007)	Loss 2.4468 (2.6009)	Acc@1 29.297 (26.310)	Acc@5 87.500 (79.069)
Epoch: [1][128/196]	Time 0.926 (1.091)	Data 0.000 (0.004)	Loss 2.1399 (2.4026)	Acc@1 42.578 (33.218)	Acc@5 88.281 (84.381)
Epoch: [1][192/196]	Time 1.210 (1.043)	Data 0.000 (0.003)	Loss 1.8830 (2.2689)	Acc@1 49.609 (38.014)	Acc@5 93.750 (87.115)
Max memory in training epoch: 81.9808768
count0: 487386
1
lr: 0.1

Epoch: [2 | 5] LR: 0.100000
Epoch: [2][0/196]	Time 1.222 (1.222)	Data 0.457 (0.457)	Loss 1.9631 (1.9631)	Acc@1 47.266 (47.266)	Acc@5 94.531 (94.531)
Epoch: [2][64/196]	Time 1.191 (1.207)	Data 0.000 (0.007)	Loss 1.8125 (1.8235)	Acc@1 55.859 (53.720)	Acc@5 94.141 (94.531)
Epoch: [2][128/196]	Time 1.227 (1.204)	Data 0.000 (0.004)	Loss 1.6477 (1.7508)	Acc@1 62.109 (56.053)	Acc@5 94.531 (95.004)
Epoch: [2][192/196]	Time 0.986 (1.197)	Data 0.000 (0.003)	Loss 1.5769 (1.6989)	Acc@1 60.938 (57.776)	Acc@5 96.094 (95.377)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [3 | 5] LR: 0.100000
Epoch: [3][0/196]	Time 1.019 (1.019)	Data 0.458 (0.458)	Loss 1.4512 (1.4512)	Acc@1 64.844 (64.844)	Acc@5 97.266 (97.266)
Epoch: [3][64/196]	Time 1.207 (1.168)	Data 0.000 (0.007)	Loss 1.5354 (1.4832)	Acc@1 60.938 (64.802)	Acc@5 96.094 (96.809)
Epoch: [3][128/196]	Time 1.203 (1.184)	Data 0.000 (0.004)	Loss 1.3669 (1.4481)	Acc@1 70.703 (65.813)	Acc@5 97.656 (97.020)
Epoch: [3][192/196]	Time 1.203 (1.187)	Data 0.000 (0.003)	Loss 1.3015 (1.4124)	Acc@1 72.266 (66.999)	Acc@5 97.266 (97.146)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [4 | 5] LR: 0.100000
Epoch: [4][0/196]	Time 1.303 (1.303)	Data 0.366 (0.366)	Loss 1.1829 (1.1829)	Acc@1 75.000 (75.000)	Acc@5 99.219 (99.219)
Epoch: [4][64/196]	Time 1.202 (1.118)	Data 0.000 (0.006)	Loss 1.2851 (1.2889)	Acc@1 72.656 (70.583)	Acc@5 98.047 (97.524)
Epoch: [4][128/196]	Time 1.215 (1.160)	Data 0.000 (0.003)	Loss 1.2613 (1.2653)	Acc@1 71.484 (71.115)	Acc@5 98.047 (97.768)
Epoch: [4][192/196]	Time 1.193 (1.174)	Data 0.000 (0.002)	Loss 1.2899 (1.2443)	Acc@1 71.094 (71.652)	Acc@5 97.656 (97.885)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [5 | 5] LR: 0.100000
Epoch: [5][0/196]	Time 1.290 (1.290)	Data 0.473 (0.473)	Loss 1.1921 (1.1921)	Acc@1 70.703 (70.703)	Acc@5 98.438 (98.438)
Epoch: [5][64/196]	Time 1.213 (1.118)	Data 0.000 (0.007)	Loss 1.1820 (1.1419)	Acc@1 72.656 (74.255)	Acc@5 98.438 (98.305)
Epoch: [5][128/196]	Time 1.207 (1.164)	Data 0.000 (0.004)	Loss 1.0712 (1.1188)	Acc@1 75.391 (74.952)	Acc@5 98.828 (98.368)
Epoch: [5][192/196]	Time 1.209 (1.178)	Data 0.000 (0.003)	Loss 1.0171 (1.1049)	Acc@1 78.125 (75.144)	Acc@5 97.656 (98.444)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
[INFO] Storing checkpoint...

  256
  71.82
Max memory: 102.6363904
 231.550s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
1
lr: 0.1

Epoch: [6 | 10] LR: 0.100000
Epoch: [6][0/196]	Time 1.420 (1.420)	Data 0.487 (0.487)	Loss 0.9969 (0.9969)	Acc@1 78.516 (78.516)	Acc@5 99.219 (99.219)
Epoch: [6][64/196]	Time 1.105 (1.196)	Data 0.000 (0.008)	Loss 1.0845 (1.0108)	Acc@1 77.344 (77.861)	Acc@5 98.047 (98.738)
Epoch: [6][128/196]	Time 1.160 (1.093)	Data 0.000 (0.004)	Loss 0.9497 (1.0133)	Acc@1 80.078 (77.565)	Acc@5 99.219 (98.686)
Epoch: [6][192/196]	Time 1.190 (1.095)	Data 0.000 (0.003)	Loss 1.0081 (1.0079)	Acc@1 77.344 (77.579)	Acc@5 98.438 (98.695)
Max memory in training epoch: 81.9807744
count0: 487386
1
lr: 0.1

Epoch: [7 | 10] LR: 0.100000
Epoch: [7][0/196]	Time 1.259 (1.259)	Data 0.519 (0.519)	Loss 1.1051 (1.1051)	Acc@1 72.656 (72.656)	Acc@5 97.656 (97.656)
Epoch: [7][64/196]	Time 1.256 (1.210)	Data 0.000 (0.008)	Loss 0.9148 (0.9772)	Acc@1 81.641 (78.438)	Acc@5 99.219 (98.786)
Epoch: [7][128/196]	Time 1.263 (1.209)	Data 0.000 (0.004)	Loss 1.0687 (0.9643)	Acc@1 75.391 (78.791)	Acc@5 100.000 (98.834)
Epoch: [7][192/196]	Time 1.004 (1.199)	Data 0.000 (0.003)	Loss 0.9886 (0.9614)	Acc@1 77.734 (78.710)	Acc@5 100.000 (98.812)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [8 | 10] LR: 0.100000
Epoch: [8][0/196]	Time 1.054 (1.054)	Data 0.389 (0.389)	Loss 0.9790 (0.9790)	Acc@1 79.688 (79.688)	Acc@5 97.266 (97.266)
Epoch: [8][64/196]	Time 1.071 (1.021)	Data 0.000 (0.006)	Loss 0.8998 (0.9063)	Acc@1 80.859 (80.337)	Acc@5 98.828 (98.798)
Epoch: [8][128/196]	Time 1.184 (1.110)	Data 0.000 (0.003)	Loss 0.9615 (0.9040)	Acc@1 76.172 (80.202)	Acc@5 97.266 (98.810)
Epoch: [8][192/196]	Time 1.203 (1.140)	Data 0.000 (0.002)	Loss 0.9591 (0.8990)	Acc@1 77.734 (80.127)	Acc@5 98.438 (98.889)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [9 | 10] LR: 0.100000
Epoch: [9][0/196]	Time 1.279 (1.279)	Data 0.551 (0.551)	Loss 0.8478 (0.8478)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 1.122 (1.206)	Data 0.000 (0.009)	Loss 0.8775 (0.8875)	Acc@1 81.641 (80.090)	Acc@5 98.828 (98.882)
Epoch: [9][128/196]	Time 1.003 (1.105)	Data 0.000 (0.004)	Loss 0.9248 (0.8792)	Acc@1 78.125 (80.284)	Acc@5 98.047 (98.925)
Epoch: [9][192/196]	Time 0.959 (1.069)	Data 0.000 (0.003)	Loss 0.9224 (0.8738)	Acc@1 78.125 (80.459)	Acc@5 98.828 (98.899)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [10 | 10] LR: 0.100000
Epoch: [10][0/196]	Time 1.070 (1.070)	Data 0.486 (0.486)	Loss 0.7706 (0.7706)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [10][64/196]	Time 0.855 (0.881)	Data 0.000 (0.008)	Loss 0.8414 (0.8466)	Acc@1 83.984 (81.214)	Acc@5 98.047 (99.038)
Epoch: [10][128/196]	Time 0.997 (0.934)	Data 0.000 (0.004)	Loss 0.8033 (0.8414)	Acc@1 83.594 (81.305)	Acc@5 99.219 (99.028)
Epoch: [10][192/196]	Time 0.936 (0.951)	Data 0.000 (0.003)	Loss 0.9575 (0.8395)	Acc@1 76.562 (81.224)	Acc@5 98.047 (99.035)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
[INFO] Storing checkpoint...

  256
  66.47
Max memory: 102.636288
 187.057s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
1
lr: 0.1

Epoch: [11 | 15] LR: 0.100000
Epoch: [11][0/196]	Time 1.211 (1.211)	Data 0.510 (0.510)	Loss 0.9256 (0.9256)	Acc@1 75.781 (75.781)	Acc@5 97.656 (97.656)
Epoch: [11][64/196]	Time 0.603 (0.820)	Data 0.000 (0.008)	Loss 0.9924 (0.8168)	Acc@1 76.562 (81.767)	Acc@5 99.219 (99.062)
Epoch: [11][128/196]	Time 0.805 (0.764)	Data 0.000 (0.004)	Loss 0.7454 (0.8201)	Acc@1 82.422 (81.822)	Acc@5 100.000 (99.016)
Epoch: [11][192/196]	Time 0.789 (0.775)	Data 0.000 (0.003)	Loss 0.7662 (0.8160)	Acc@1 84.375 (81.999)	Acc@5 99.609 (99.079)
Max memory in training epoch: 81.9807744
count0: 487386
1
lr: 0.1

Epoch: [12 | 15] LR: 0.100000
Epoch: [12][0/196]	Time 0.842 (0.842)	Data 0.380 (0.380)	Loss 0.8007 (0.8007)	Acc@1 79.688 (79.688)	Acc@5 100.000 (100.000)
Epoch: [12][64/196]	Time 0.812 (0.804)	Data 0.000 (0.006)	Loss 0.7930 (0.8031)	Acc@1 82.422 (82.121)	Acc@5 98.828 (99.044)
Epoch: [12][128/196]	Time 0.805 (0.799)	Data 0.000 (0.003)	Loss 0.8369 (0.8017)	Acc@1 81.250 (82.322)	Acc@5 98.047 (99.089)
Epoch: [12][192/196]	Time 0.791 (0.799)	Data 0.000 (0.002)	Loss 0.7333 (0.8071)	Acc@1 84.375 (82.072)	Acc@5 100.000 (99.093)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [13 | 15] LR: 0.100000
Epoch: [13][0/196]	Time 0.851 (0.851)	Data 0.369 (0.369)	Loss 0.6729 (0.6729)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [13][64/196]	Time 0.805 (0.798)	Data 0.000 (0.006)	Loss 0.7945 (0.8030)	Acc@1 81.250 (82.121)	Acc@5 99.219 (99.056)
Epoch: [13][128/196]	Time 0.805 (0.797)	Data 0.000 (0.003)	Loss 0.7515 (0.8000)	Acc@1 83.203 (82.292)	Acc@5 99.219 (99.089)
Epoch: [13][192/196]	Time 1.011 (0.862)	Data 0.000 (0.002)	Loss 0.8064 (0.7999)	Acc@1 83.203 (82.355)	Acc@5 98.438 (99.081)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [14 | 15] LR: 0.100000
Epoch: [14][0/196]	Time 1.141 (1.141)	Data 0.482 (0.482)	Loss 0.8316 (0.8316)	Acc@1 80.078 (80.078)	Acc@5 99.609 (99.609)
Epoch: [14][64/196]	Time 1.000 (1.010)	Data 0.000 (0.008)	Loss 0.8175 (0.7782)	Acc@1 81.641 (82.939)	Acc@5 99.609 (99.231)
Epoch: [14][128/196]	Time 1.000 (1.007)	Data 0.000 (0.004)	Loss 0.8511 (0.7786)	Acc@1 82.812 (82.958)	Acc@5 98.828 (99.225)
Epoch: [14][192/196]	Time 0.975 (1.003)	Data 0.000 (0.003)	Loss 0.8085 (0.7787)	Acc@1 80.469 (83.037)	Acc@5 99.609 (99.229)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [15 | 15] LR: 0.100000
Epoch: [15][0/196]	Time 1.106 (1.106)	Data 0.372 (0.372)	Loss 0.7596 (0.7596)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.997 (0.889)	Data 0.000 (0.006)	Loss 0.7681 (0.7719)	Acc@1 85.547 (82.915)	Acc@5 99.219 (99.303)
Epoch: [15][128/196]	Time 0.810 (0.921)	Data 0.000 (0.003)	Loss 0.6757 (0.7832)	Acc@1 87.109 (82.667)	Acc@5 99.219 (99.273)
Epoch: [15][192/196]	Time 0.968 (0.923)	Data 0.000 (0.002)	Loss 0.7351 (0.7878)	Acc@1 86.328 (82.628)	Acc@5 99.609 (99.184)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
Count: 485078 ; 487386 ; 0.9952645336550496
[INFO] Storing checkpoint...

  256
  77.06
Max memory: 102.636288
 181.789s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.2015744
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Epoch: [16][0/196]	Time 1.350 (1.350)	Data 0.513 (0.513)	Loss 0.6981 (0.6981)	Acc@1 89.453 (89.453)	Acc@5 98.438 (98.438)
Epoch: [16][64/196]	Time 1.018 (1.011)	Data 0.000 (0.008)	Loss 0.8178 (0.7515)	Acc@1 82.031 (84.153)	Acc@5 98.438 (99.141)
Epoch: [16][128/196]	Time 1.049 (1.011)	Data 0.000 (0.004)	Loss 0.7792 (0.7720)	Acc@1 82.812 (83.412)	Acc@5 98.828 (99.098)
Epoch: [16][192/196]	Time 1.026 (1.007)	Data 0.000 (0.003)	Loss 0.8185 (0.7741)	Acc@1 80.469 (83.181)	Acc@5 99.219 (99.144)
Max memory in training epoch: 81.584896
count0: 485078
1
lr: 0.1

Epoch: [17 | 20] LR: 0.100000
Epoch: [17][0/196]	Time 1.077 (1.077)	Data 0.549 (0.549)	Loss 0.7150 (0.7150)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [17][64/196]	Time 0.995 (1.004)	Data 0.000 (0.009)	Loss 0.8792 (0.7682)	Acc@1 83.594 (83.690)	Acc@5 99.609 (99.159)
Epoch: [17][128/196]	Time 1.022 (1.007)	Data 0.000 (0.004)	Loss 0.8501 (0.7646)	Acc@1 81.250 (83.827)	Acc@5 97.656 (99.152)
Epoch: [17][192/196]	Time 0.915 (1.004)	Data 0.000 (0.003)	Loss 0.8473 (0.7667)	Acc@1 82.422 (83.739)	Acc@5 98.047 (99.168)
Max memory in training epoch: 66.5119232
count0: 485078
1
lr: 0.1

Epoch: [18 | 20] LR: 0.100000
Epoch: [18][0/196]	Time 1.060 (1.060)	Data 0.473 (0.473)	Loss 0.8399 (0.8399)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [18][64/196]	Time 0.967 (0.996)	Data 0.000 (0.007)	Loss 0.7487 (0.7379)	Acc@1 83.203 (84.123)	Acc@5 98.828 (99.285)
Epoch: [18][128/196]	Time 0.835 (0.941)	Data 0.000 (0.004)	Loss 0.8399 (0.7634)	Acc@1 82.812 (83.433)	Acc@5 98.047 (99.176)
Epoch: [18][192/196]	Time 1.001 (0.960)	Data 0.000 (0.003)	Loss 0.6815 (0.7625)	Acc@1 87.109 (83.484)	Acc@5 99.219 (99.215)
Max memory in training epoch: 66.5119232
count0: 485078
1
lr: 0.1

Epoch: [19 | 20] LR: 0.100000
Epoch: [19][0/196]	Time 1.077 (1.077)	Data 0.465 (0.465)	Loss 0.7386 (0.7386)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [19][64/196]	Time 1.011 (1.003)	Data 0.000 (0.008)	Loss 0.8503 (0.7748)	Acc@1 80.078 (83.113)	Acc@5 97.656 (99.243)
Epoch: [19][128/196]	Time 1.069 (1.004)	Data 0.000 (0.004)	Loss 0.7629 (0.7643)	Acc@1 85.547 (83.551)	Acc@5 99.219 (99.225)
Epoch: [19][192/196]	Time 0.960 (1.001)	Data 0.000 (0.003)	Loss 0.8438 (0.7623)	Acc@1 81.250 (83.480)	Acc@5 97.656 (99.233)
Max memory in training epoch: 66.5119232
count0: 485078
1
lr: 0.1

Epoch: [20 | 20] LR: 0.100000
Epoch: [20][0/196]	Time 1.098 (1.098)	Data 0.568 (0.568)	Loss 0.6650 (0.6650)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [20][64/196]	Time 0.415 (0.694)	Data 0.000 (0.009)	Loss 0.7615 (0.7470)	Acc@1 82.812 (84.014)	Acc@5 98.828 (99.357)
Epoch: [20][128/196]	Time 1.042 (0.784)	Data 0.000 (0.005)	Loss 0.8439 (0.7586)	Acc@1 82.422 (83.860)	Acc@5 98.438 (99.252)
Epoch: [20][192/196]	Time 1.028 (0.857)	Data 0.000 (0.003)	Loss 0.7016 (0.7573)	Acc@1 86.328 (83.974)	Acc@5 99.219 (99.269)
Max memory in training epoch: 66.5119232
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 485078
Count: 470076 ; 485078 ; 0.9690730150614952
[INFO] Storing checkpoint...

  256
  73.43
Max memory: 102.6363904
 169.179s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.1956352
1
lr: 0.1

Epoch: [21 | 25] LR: 0.100000
Epoch: [21][0/196]	Time 1.332 (1.332)	Data 0.479 (0.479)	Loss 0.6375 (0.6375)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [21][64/196]	Time 1.007 (1.007)	Data 0.000 (0.008)	Loss 0.7397 (0.7306)	Acc@1 86.328 (84.369)	Acc@5 98.438 (99.399)
Epoch: [21][128/196]	Time 0.990 (1.006)	Data 0.000 (0.004)	Loss 0.6995 (0.7408)	Acc@1 83.984 (84.145)	Acc@5 99.609 (99.364)
Epoch: [21][192/196]	Time 0.965 (1.003)	Data 0.000 (0.003)	Loss 0.7697 (0.7456)	Acc@1 84.375 (83.994)	Acc@5 98.438 (99.340)
Max memory in training epoch: 80.2893312
count0: 470076
1
lr: 0.1

Epoch: [22 | 25] LR: 0.100000
Epoch: [22][0/196]	Time 1.123 (1.123)	Data 0.487 (0.487)	Loss 0.7622 (0.7622)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 1.016 (1.002)	Data 0.000 (0.008)	Loss 0.7210 (0.7464)	Acc@1 85.547 (84.381)	Acc@5 99.609 (99.327)
Epoch: [22][128/196]	Time 1.039 (1.006)	Data 0.000 (0.004)	Loss 0.7252 (0.7494)	Acc@1 85.156 (84.151)	Acc@5 99.609 (99.310)
Epoch: [22][192/196]	Time 1.005 (1.003)	Data 0.000 (0.003)	Loss 0.7041 (0.7491)	Acc@1 82.422 (84.175)	Acc@5 99.609 (99.286)
Max memory in training epoch: 66.3177728
count0: 470076
1
lr: 0.1

Epoch: [23 | 25] LR: 0.100000
Epoch: [23][0/196]	Time 1.090 (1.090)	Data 0.487 (0.487)	Loss 0.7635 (0.7635)	Acc@1 83.594 (83.594)	Acc@5 99.219 (99.219)
Epoch: [23][64/196]	Time 0.971 (0.995)	Data 0.000 (0.008)	Loss 0.7505 (0.7451)	Acc@1 85.156 (84.207)	Acc@5 98.047 (99.357)
Epoch: [23][128/196]	Time 0.869 (0.942)	Data 0.000 (0.004)	Loss 0.8488 (0.7343)	Acc@1 80.469 (84.587)	Acc@5 98.438 (99.370)
Epoch: [23][192/196]	Time 0.998 (0.957)	Data 0.000 (0.003)	Loss 0.6926 (0.7363)	Acc@1 83.203 (84.454)	Acc@5 99.609 (99.375)
Max memory in training epoch: 66.3177728
count0: 470076
1
lr: 0.1

Epoch: [24 | 25] LR: 0.100000
Epoch: [24][0/196]	Time 1.050 (1.050)	Data 0.395 (0.395)	Loss 0.6748 (0.6748)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [24][64/196]	Time 1.005 (1.006)	Data 0.000 (0.006)	Loss 0.6755 (0.7278)	Acc@1 86.719 (85.024)	Acc@5 100.000 (99.333)
Epoch: [24][128/196]	Time 0.867 (0.953)	Data 0.000 (0.003)	Loss 0.6877 (0.7348)	Acc@1 86.719 (84.708)	Acc@5 98.828 (99.319)
Epoch: [24][192/196]	Time 0.965 (0.932)	Data 0.000 (0.002)	Loss 0.7364 (0.7346)	Acc@1 83.203 (84.719)	Acc@5 100.000 (99.296)
Max memory in training epoch: 66.3177728
count0: 470076
1
lr: 0.1

Epoch: [25 | 25] LR: 0.100000
Epoch: [25][0/196]	Time 1.028 (1.028)	Data 0.553 (0.553)	Loss 0.7575 (0.7575)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 1.018 (0.897)	Data 0.000 (0.009)	Loss 0.7310 (0.7297)	Acc@1 83.984 (84.718)	Acc@5 98.828 (99.321)
Epoch: [25][128/196]	Time 0.943 (0.952)	Data 0.000 (0.004)	Loss 0.6362 (0.7336)	Acc@1 88.672 (84.517)	Acc@5 100.000 (99.279)
Epoch: [25][192/196]	Time 1.013 (0.972)	Data 0.000 (0.003)	Loss 0.7528 (0.7349)	Acc@1 83.203 (84.377)	Acc@5 99.609 (99.334)
Max memory in training epoch: 66.3177728
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 470076
Count: 452184 ; 470076 ; 0.9619380695887474
[INFO] Storing checkpoint...

  256
  77.05
Max memory: 102.4059904
 191.233s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1884672
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Epoch: [26][0/196]	Time 1.515 (1.515)	Data 0.427 (0.427)	Loss 0.6127 (0.6127)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [26][64/196]	Time 1.001 (1.021)	Data 0.000 (0.007)	Loss 0.6806 (0.6935)	Acc@1 87.500 (85.697)	Acc@5 100.000 (99.501)
Epoch: [26][128/196]	Time 1.008 (1.018)	Data 0.000 (0.004)	Loss 0.6932 (0.7068)	Acc@1 83.203 (85.277)	Acc@5 100.000 (99.422)
Epoch: [26][192/196]	Time 1.022 (1.017)	Data 0.000 (0.002)	Loss 0.7953 (0.7202)	Acc@1 82.422 (84.851)	Acc@5 99.609 (99.383)
Max memory in training epoch: 80.1439232
count0: 452184
1
lr: 0.1

Epoch: [27 | 30] LR: 0.100000
Epoch: [27][0/196]	Time 1.098 (1.098)	Data 0.529 (0.529)	Loss 0.6994 (0.6994)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [27][64/196]	Time 1.054 (1.010)	Data 0.000 (0.008)	Loss 0.6950 (0.7192)	Acc@1 86.719 (85.108)	Acc@5 99.219 (99.279)
Epoch: [27][128/196]	Time 1.027 (1.008)	Data 0.000 (0.004)	Loss 0.6217 (0.7246)	Acc@1 88.672 (84.941)	Acc@5 99.609 (99.273)
Epoch: [27][192/196]	Time 0.994 (1.009)	Data 0.000 (0.003)	Loss 0.6684 (0.7258)	Acc@1 88.672 (84.830)	Acc@5 100.000 (99.328)
Max memory in training epoch: 66.040064
count0: 452184
1
lr: 0.1

Epoch: [28 | 30] LR: 0.100000
Epoch: [28][0/196]	Time 1.101 (1.101)	Data 0.476 (0.476)	Loss 0.7142 (0.7142)	Acc@1 83.594 (83.594)	Acc@5 98.828 (98.828)
Epoch: [28][64/196]	Time 0.958 (1.001)	Data 0.000 (0.008)	Loss 0.7683 (0.7272)	Acc@1 83.594 (84.555)	Acc@5 99.219 (99.309)
Epoch: [28][128/196]	Time 0.797 (0.950)	Data 0.000 (0.004)	Loss 0.6539 (0.7195)	Acc@1 85.547 (84.859)	Acc@5 100.000 (99.337)
Epoch: [28][192/196]	Time 0.996 (0.966)	Data 0.000 (0.003)	Loss 0.7729 (0.7262)	Acc@1 81.641 (84.725)	Acc@5 98.438 (99.300)
Max memory in training epoch: 66.040064
count0: 452184
1
lr: 0.1

Epoch: [29 | 30] LR: 0.100000
Epoch: [29][0/196]	Time 1.058 (1.058)	Data 0.587 (0.587)	Loss 0.6785 (0.6785)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.930 (0.982)	Data 0.000 (0.009)	Loss 0.6743 (0.7120)	Acc@1 85.938 (85.523)	Acc@5 100.000 (99.309)
Epoch: [29][128/196]	Time 1.038 (0.872)	Data 0.000 (0.005)	Loss 0.9011 (0.7211)	Acc@1 79.688 (85.071)	Acc@5 97.656 (99.310)
Epoch: [29][192/196]	Time 0.973 (0.915)	Data 0.000 (0.003)	Loss 0.6445 (0.7260)	Acc@1 86.719 (84.883)	Acc@5 99.609 (99.316)
Max memory in training epoch: 66.040064
count0: 452184
1
lr: 0.1

Epoch: [30 | 30] LR: 0.100000
Epoch: [30][0/196]	Time 1.036 (1.036)	Data 0.491 (0.491)	Loss 0.6871 (0.6871)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 1.021 (0.896)	Data 0.000 (0.008)	Loss 0.6300 (0.7157)	Acc@1 89.844 (84.976)	Acc@5 99.609 (99.339)
Epoch: [30][128/196]	Time 0.941 (0.949)	Data 0.000 (0.004)	Loss 0.6447 (0.7165)	Acc@1 85.938 (85.056)	Acc@5 99.609 (99.352)
Epoch: [30][192/196]	Time 1.061 (0.970)	Data 0.000 (0.003)	Loss 0.7215 (0.7207)	Acc@1 84.375 (85.019)	Acc@5 100.000 (99.366)
Max memory in training epoch: 66.040064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 452184
Count: 430530 ; 452184 ; 0.9521124144153708
[INFO] Storing checkpoint...

  256
  76.62
Max memory: 102.0969472
 190.840s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.179968
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Epoch: [31][0/196]	Time 1.824 (1.824)	Data 0.597 (0.597)	Loss 0.6926 (0.6926)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [31][64/196]	Time 0.963 (1.015)	Data 0.000 (0.009)	Loss 0.5765 (0.6774)	Acc@1 88.672 (86.322)	Acc@5 100.000 (99.381)
Epoch: [31][128/196]	Time 1.026 (1.009)	Data 0.000 (0.005)	Loss 0.6650 (0.6983)	Acc@1 87.109 (85.550)	Acc@5 98.828 (99.410)
Epoch: [31][192/196]	Time 0.983 (1.006)	Data 0.000 (0.003)	Loss 0.6783 (0.7100)	Acc@1 85.547 (85.247)	Acc@5 99.609 (99.371)
Max memory in training epoch: 79.2028672
count0: 430530
1
lr: 0.1

Epoch: [32 | 35] LR: 0.100000
Epoch: [32][0/196]	Time 1.006 (1.006)	Data 0.509 (0.509)	Loss 0.7423 (0.7423)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [32][64/196]	Time 1.001 (0.992)	Data 0.000 (0.008)	Loss 0.6352 (0.7065)	Acc@1 87.891 (85.216)	Acc@5 99.219 (99.417)
Epoch: [32][128/196]	Time 1.018 (0.999)	Data 0.000 (0.004)	Loss 0.6179 (0.7078)	Acc@1 88.672 (85.311)	Acc@5 100.000 (99.385)
Epoch: [32][192/196]	Time 0.996 (0.998)	Data 0.000 (0.003)	Loss 0.7180 (0.7076)	Acc@1 85.938 (85.363)	Acc@5 99.609 (99.393)
Max memory in training epoch: 64.9837056
count0: 430530
1
lr: 0.1

Epoch: [33 | 35] LR: 0.100000
Epoch: [33][0/196]	Time 1.124 (1.124)	Data 0.483 (0.483)	Loss 0.7939 (0.7939)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [33][64/196]	Time 0.955 (1.003)	Data 0.000 (0.008)	Loss 0.7948 (0.6988)	Acc@1 80.469 (85.625)	Acc@5 99.609 (99.417)
Epoch: [33][128/196]	Time 0.805 (0.950)	Data 0.000 (0.004)	Loss 0.7618 (0.7119)	Acc@1 81.641 (85.180)	Acc@5 99.609 (99.391)
Epoch: [33][192/196]	Time 0.811 (0.954)	Data 0.000 (0.003)	Loss 0.6658 (0.7127)	Acc@1 87.109 (85.144)	Acc@5 99.609 (99.383)
Max memory in training epoch: 64.9837056
count0: 430530
1
lr: 0.1

Epoch: [34 | 35] LR: 0.100000
Epoch: [34][0/196]	Time 0.855 (0.855)	Data 0.426 (0.426)	Loss 0.7290 (0.7290)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [34][64/196]	Time 0.964 (0.928)	Data 0.000 (0.007)	Loss 0.7578 (0.7008)	Acc@1 83.984 (85.799)	Acc@5 99.609 (99.333)
Epoch: [34][128/196]	Time 1.026 (0.905)	Data 0.000 (0.003)	Loss 0.7112 (0.7085)	Acc@1 85.547 (85.498)	Acc@5 99.219 (99.340)
Epoch: [34][192/196]	Time 0.963 (0.934)	Data 0.000 (0.002)	Loss 0.7012 (0.7104)	Acc@1 84.375 (85.322)	Acc@5 100.000 (99.360)
Max memory in training epoch: 64.9837056
count0: 430530
1
lr: 0.1

Epoch: [35 | 35] LR: 0.100000
Epoch: [35][0/196]	Time 1.047 (1.047)	Data 0.498 (0.498)	Loss 0.6870 (0.6870)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [35][64/196]	Time 1.021 (0.890)	Data 0.000 (0.008)	Loss 0.6981 (0.7128)	Acc@1 87.891 (85.445)	Acc@5 98.828 (99.321)
Epoch: [35][128/196]	Time 0.928 (0.947)	Data 0.000 (0.004)	Loss 0.6976 (0.7057)	Acc@1 85.547 (85.420)	Acc@5 98.047 (99.340)
Epoch: [35][192/196]	Time 1.011 (0.966)	Data 0.000 (0.003)	Loss 0.7330 (0.7066)	Acc@1 87.500 (85.454)	Acc@5 98.828 (99.364)
Max memory in training epoch: 64.9837056
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 430530
Count: 404548 ; 430530 ; 0.9396511276798365
[INFO] Storing checkpoint...

  256
  72.61
Max memory: 100.329216
 190.052s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1696256
1
lr: 0.1

Epoch: [36 | 40] LR: 0.100000
Epoch: [36][0/196]	Time 1.856 (1.856)	Data 0.375 (0.375)	Loss 0.7932 (0.7932)	Acc@1 78.906 (78.906)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 1.001 (1.015)	Data 0.000 (0.006)	Loss 0.7663 (0.6739)	Acc@1 82.422 (86.641)	Acc@5 99.609 (99.411)
Epoch: [36][128/196]	Time 1.004 (1.007)	Data 0.000 (0.003)	Loss 0.7232 (0.6898)	Acc@1 86.719 (85.959)	Acc@5 100.000 (99.422)
Epoch: [36][192/196]	Time 1.010 (1.006)	Data 0.000 (0.002)	Loss 0.5634 (0.6963)	Acc@1 91.406 (85.674)	Acc@5 99.609 (99.379)
Max memory in training epoch: 78.1327872
count0: 404548
1
lr: 0.1

Epoch: [37 | 40] LR: 0.100000
Epoch: [37][0/196]	Time 1.077 (1.077)	Data 0.449 (0.449)	Loss 0.6410 (0.6410)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [37][64/196]	Time 1.003 (1.003)	Data 0.000 (0.007)	Loss 0.6393 (0.6922)	Acc@1 88.281 (86.082)	Acc@5 100.000 (99.441)
Epoch: [37][128/196]	Time 1.004 (1.005)	Data 0.000 (0.004)	Loss 0.6683 (0.6967)	Acc@1 88.281 (85.774)	Acc@5 100.000 (99.440)
Epoch: [37][192/196]	Time 1.007 (1.004)	Data 0.000 (0.003)	Loss 0.7133 (0.7033)	Acc@1 86.719 (85.660)	Acc@5 99.609 (99.419)
Max memory in training epoch: 64.0379392
count0: 404548
1
lr: 0.1

Epoch: [38 | 40] LR: 0.100000
Epoch: [38][0/196]	Time 1.076 (1.076)	Data 0.436 (0.436)	Loss 0.6725 (0.6725)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [38][64/196]	Time 0.964 (0.997)	Data 0.000 (0.007)	Loss 0.6557 (0.6972)	Acc@1 87.109 (85.655)	Acc@5 100.000 (99.453)
Epoch: [38][128/196]	Time 0.553 (0.932)	Data 0.000 (0.004)	Loss 0.7784 (0.6979)	Acc@1 82.031 (85.680)	Acc@5 100.000 (99.437)
Epoch: [38][192/196]	Time 1.003 (0.899)	Data 0.000 (0.002)	Loss 0.6652 (0.7037)	Acc@1 87.109 (85.502)	Acc@5 100.000 (99.397)
Max memory in training epoch: 64.0379392
count0: 404548
1
lr: 0.1

Epoch: [39 | 40] LR: 0.100000
Epoch: [39][0/196]	Time 1.080 (1.080)	Data 0.504 (0.504)	Loss 0.6744 (0.6744)	Acc@1 87.891 (87.891)	Acc@5 98.828 (98.828)
Epoch: [39][64/196]	Time 0.964 (0.996)	Data 0.000 (0.008)	Loss 0.6628 (0.6963)	Acc@1 85.938 (85.745)	Acc@5 99.609 (99.495)
Epoch: [39][128/196]	Time 0.801 (0.946)	Data 0.000 (0.004)	Loss 0.6826 (0.6963)	Acc@1 87.500 (85.786)	Acc@5 99.219 (99.431)
Epoch: [39][192/196]	Time 0.967 (0.956)	Data 0.000 (0.003)	Loss 0.6619 (0.6954)	Acc@1 86.328 (85.798)	Acc@5 99.609 (99.445)
Max memory in training epoch: 64.0379392
count0: 404548
1
lr: 0.1

Epoch: [40 | 40] LR: 0.100000
Epoch: [40][0/196]	Time 0.974 (0.974)	Data 0.344 (0.344)	Loss 0.7001 (0.7001)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [40][64/196]	Time 1.001 (0.894)	Data 0.000 (0.005)	Loss 0.7410 (0.6991)	Acc@1 84.375 (85.535)	Acc@5 99.219 (99.405)
Epoch: [40][128/196]	Time 1.011 (0.949)	Data 0.000 (0.003)	Loss 0.7540 (0.6929)	Acc@1 83.203 (85.913)	Acc@5 98.828 (99.403)
Epoch: [40][192/196]	Time 1.001 (0.966)	Data 0.000 (0.002)	Loss 0.6598 (0.6965)	Acc@1 85.938 (85.761)	Acc@5 99.609 (99.369)
Max memory in training epoch: 64.0379392
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 404548
Count: 396464 ; 404548 ; 0.9800172043861297
[INFO] Storing checkpoint...

  256
  78.57
Max memory: 98.7275776
 189.918s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1664512
1
lr: 0.1

Epoch: [41 | 45] LR: 0.100000
Epoch: [41][0/196]	Time 1.889 (1.889)	Data 0.392 (0.392)	Loss 0.7178 (0.7178)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [41][64/196]	Time 1.002 (1.013)	Data 0.000 (0.006)	Loss 0.7405 (0.6651)	Acc@1 84.766 (86.520)	Acc@5 100.000 (99.525)
Epoch: [41][128/196]	Time 1.003 (1.009)	Data 0.000 (0.003)	Loss 0.6969 (0.6784)	Acc@1 84.375 (86.304)	Acc@5 98.828 (99.455)
Epoch: [41][192/196]	Time 1.004 (1.008)	Data 0.000 (0.002)	Loss 0.6009 (0.6864)	Acc@1 88.281 (86.025)	Acc@5 99.609 (99.427)
Max memory in training epoch: 77.7143808
count0: 396464
1
lr: 0.1

Epoch: [42 | 45] LR: 0.100000
Epoch: [42][0/196]	Time 1.050 (1.050)	Data 0.428 (0.428)	Loss 0.6893 (0.6893)	Acc@1 86.328 (86.328)	Acc@5 100.000 (100.000)
Epoch: [42][64/196]	Time 1.008 (1.006)	Data 0.000 (0.007)	Loss 0.6951 (0.6867)	Acc@1 87.109 (86.268)	Acc@5 98.828 (99.399)
Epoch: [42][128/196]	Time 1.003 (1.004)	Data 0.000 (0.004)	Loss 0.6171 (0.6893)	Acc@1 87.500 (86.137)	Acc@5 100.000 (99.331)
Epoch: [42][192/196]	Time 1.001 (1.004)	Data 0.000 (0.002)	Loss 0.6947 (0.6908)	Acc@1 85.547 (85.986)	Acc@5 98.828 (99.356)
Max memory in training epoch: 63.6123648
count0: 396464
1
lr: 0.1

Epoch: [43 | 45] LR: 0.100000
Epoch: [43][0/196]	Time 1.060 (1.060)	Data 0.424 (0.424)	Loss 0.6872 (0.6872)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [43][64/196]	Time 0.811 (0.933)	Data 0.000 (0.007)	Loss 0.7221 (0.6882)	Acc@1 85.938 (86.046)	Acc@5 99.609 (99.399)
Epoch: [43][128/196]	Time 0.957 (0.929)	Data 0.000 (0.003)	Loss 0.8089 (0.7058)	Acc@1 80.078 (85.417)	Acc@5 99.609 (99.394)
Epoch: [43][192/196]	Time 1.002 (0.920)	Data 0.000 (0.002)	Loss 0.5825 (0.7058)	Acc@1 91.016 (85.338)	Acc@5 100.000 (99.405)
Max memory in training epoch: 63.6123648
count0: 396464
1
lr: 0.1

Epoch: [44 | 45] LR: 0.100000
Epoch: [44][0/196]	Time 1.074 (1.074)	Data 0.533 (0.533)	Loss 0.7626 (0.7626)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [44][64/196]	Time 0.964 (1.005)	Data 0.000 (0.008)	Loss 0.6426 (0.6623)	Acc@1 89.062 (86.917)	Acc@5 100.000 (99.489)
Epoch: [44][128/196]	Time 0.801 (0.957)	Data 0.000 (0.004)	Loss 0.6507 (0.6753)	Acc@1 86.328 (86.271)	Acc@5 100.000 (99.549)
Epoch: [44][192/196]	Time 0.966 (0.958)	Data 0.000 (0.003)	Loss 0.7177 (0.6787)	Acc@1 87.891 (86.197)	Acc@5 99.609 (99.490)
Max memory in training epoch: 63.6123648
count0: 396464
1
lr: 0.1

Epoch: [45 | 45] LR: 0.100000
Epoch: [45][0/196]	Time 1.016 (1.016)	Data 0.507 (0.507)	Loss 0.6883 (0.6883)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [45][64/196]	Time 1.002 (0.892)	Data 0.000 (0.008)	Loss 0.7233 (0.6821)	Acc@1 85.156 (86.130)	Acc@5 98.438 (99.453)
Epoch: [45][128/196]	Time 1.031 (0.947)	Data 0.000 (0.004)	Loss 0.6842 (0.6836)	Acc@1 86.328 (86.292)	Acc@5 100.000 (99.437)
Epoch: [45][192/196]	Time 1.002 (0.965)	Data 0.000 (0.003)	Loss 0.9005 (0.6945)	Acc@1 78.906 (85.857)	Acc@5 98.438 (99.405)
Max memory in training epoch: 63.6123648
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 396464
Count: 392422 ; 396464 ; 0.9898048750958472
[INFO] Storing checkpoint...

  256
  74.22
Max memory: 97.981184
 189.847s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1648128
1
lr: 0.1

Epoch: [46 | 50] LR: 0.100000
Epoch: [46][0/196]	Time 1.929 (1.929)	Data 0.548 (0.548)	Loss 0.7317 (0.7317)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [46][64/196]	Time 1.032 (1.021)	Data 0.000 (0.009)	Loss 0.6904 (0.6683)	Acc@1 83.594 (86.562)	Acc@5 100.000 (99.555)
Epoch: [46][128/196]	Time 1.004 (1.012)	Data 0.000 (0.004)	Loss 0.7163 (0.6715)	Acc@1 84.375 (86.595)	Acc@5 98.828 (99.470)
Epoch: [46][192/196]	Time 1.004 (1.008)	Data 0.000 (0.003)	Loss 0.7589 (0.6799)	Acc@1 82.422 (86.223)	Acc@5 99.219 (99.427)
Max memory in training epoch: 77.28512
count0: 392422
1
lr: 0.1

Epoch: [47 | 50] LR: 0.100000
Epoch: [47][0/196]	Time 1.080 (1.080)	Data 0.393 (0.393)	Loss 0.7753 (0.7753)	Acc@1 82.422 (82.422)	Acc@5 100.000 (100.000)
Epoch: [47][64/196]	Time 1.004 (1.001)	Data 0.000 (0.006)	Loss 0.7278 (0.6757)	Acc@1 83.984 (86.322)	Acc@5 99.609 (99.501)
Epoch: [47][128/196]	Time 1.002 (1.001)	Data 0.000 (0.003)	Loss 0.7068 (0.6794)	Acc@1 86.719 (86.358)	Acc@5 99.609 (99.452)
Epoch: [47][192/196]	Time 0.791 (0.975)	Data 0.000 (0.002)	Loss 0.5941 (0.6826)	Acc@1 91.016 (86.199)	Acc@5 99.219 (99.462)
Max memory in training epoch: 63.2125952
count0: 392422
1
lr: 0.1

Epoch: [48 | 50] LR: 0.100000
Epoch: [48][0/196]	Time 0.921 (0.921)	Data 0.523 (0.523)	Loss 0.6948 (0.6948)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [48][64/196]	Time 1.010 (0.991)	Data 0.000 (0.008)	Loss 0.6723 (0.6787)	Acc@1 85.547 (86.346)	Acc@5 98.828 (99.489)
Epoch: [48][128/196]	Time 0.959 (0.984)	Data 0.000 (0.004)	Loss 0.6765 (0.6791)	Acc@1 87.500 (86.495)	Acc@5 99.609 (99.488)
Epoch: [48][192/196]	Time 0.953 (0.952)	Data 0.000 (0.003)	Loss 0.7179 (0.6838)	Acc@1 86.719 (86.375)	Acc@5 99.219 (99.433)
Max memory in training epoch: 63.2125952
count0: 392422
1
lr: 0.1

Epoch: [49 | 50] LR: 0.100000
Epoch: [49][0/196]	Time 1.048 (1.048)	Data 0.389 (0.389)	Loss 0.6849 (0.6849)	Acc@1 85.547 (85.547)	Acc@5 99.219 (99.219)
Epoch: [49][64/196]	Time 0.963 (1.001)	Data 0.000 (0.006)	Loss 0.7464 (0.6633)	Acc@1 85.938 (86.851)	Acc@5 99.609 (99.483)
Epoch: [49][128/196]	Time 0.782 (0.963)	Data 0.000 (0.003)	Loss 0.6393 (0.6761)	Acc@1 88.281 (86.352)	Acc@5 99.609 (99.467)
Epoch: [49][192/196]	Time 0.963 (0.951)	Data 0.000 (0.002)	Loss 0.6962 (0.6816)	Acc@1 84.766 (86.251)	Acc@5 100.000 (99.443)
Max memory in training epoch: 63.2125952
count0: 392422
1
lr: 0.1

Epoch: [50 | 50] LR: 0.100000
Epoch: [50][0/196]	Time 1.012 (1.012)	Data 0.505 (0.505)	Loss 0.7414 (0.7414)	Acc@1 84.766 (84.766)	Acc@5 98.438 (98.438)
Epoch: [50][64/196]	Time 1.008 (0.889)	Data 0.000 (0.008)	Loss 0.7480 (0.6597)	Acc@1 84.375 (86.995)	Acc@5 99.609 (99.375)
Epoch: [50][128/196]	Time 1.006 (0.945)	Data 0.000 (0.004)	Loss 0.6880 (0.6679)	Acc@1 85.547 (86.782)	Acc@5 100.000 (99.425)
Epoch: [50][192/196]	Time 1.000 (0.961)	Data 0.000 (0.003)	Loss 0.6283 (0.6734)	Acc@1 87.500 (86.496)	Acc@5 99.609 (99.443)
Max memory in training epoch: 63.2125952
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 392422
Count: 388088 ; 392422 ; 0.9889557670059272
[INFO] Storing checkpoint...

  256
  67.5
Max memory: 97.8079232
 189.114s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1631744
1
lr: 0.1

Epoch: [51 | 55] LR: 0.100000
Epoch: [51][0/196]	Time 1.940 (1.940)	Data 0.529 (0.529)	Loss 0.7331 (0.7331)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [51][64/196]	Time 1.004 (1.017)	Data 0.000 (0.008)	Loss 0.6836 (0.6476)	Acc@1 86.328 (86.995)	Acc@5 98.828 (99.555)
Epoch: [51][128/196]	Time 1.005 (1.006)	Data 0.000 (0.004)	Loss 0.6901 (0.6700)	Acc@1 86.719 (86.510)	Acc@5 100.000 (99.509)
Epoch: [51][192/196]	Time 0.999 (1.004)	Data 0.000 (0.003)	Loss 0.5944 (0.6763)	Acc@1 89.062 (86.237)	Acc@5 100.000 (99.508)
Max memory in training epoch: 76.633856
count0: 388088
1
lr: 0.1

Epoch: [52 | 55] LR: 0.100000
Epoch: [52][0/196]	Time 1.084 (1.084)	Data 0.478 (0.478)	Loss 0.6101 (0.6101)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [52][64/196]	Time 1.002 (1.005)	Data 0.000 (0.008)	Loss 0.6776 (0.6657)	Acc@1 87.500 (86.785)	Acc@5 99.609 (99.471)
Epoch: [52][128/196]	Time 0.861 (0.950)	Data 0.000 (0.004)	Loss 0.7353 (0.6730)	Acc@1 83.203 (86.434)	Acc@5 99.219 (99.443)
Epoch: [52][192/196]	Time 1.002 (0.965)	Data 0.000 (0.003)	Loss 0.7797 (0.6760)	Acc@1 84.375 (86.407)	Acc@5 98.438 (99.429)
Max memory in training epoch: 62.8259328
count0: 388088
1
lr: 0.1

Epoch: [53 | 55] LR: 0.100000
Epoch: [53][0/196]	Time 1.122 (1.122)	Data 0.434 (0.434)	Loss 0.6915 (0.6915)	Acc@1 83.203 (83.203)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 1.002 (1.004)	Data 0.000 (0.007)	Loss 0.6626 (0.6592)	Acc@1 87.891 (86.893)	Acc@5 99.219 (99.537)
Epoch: [53][128/196]	Time 0.962 (0.992)	Data 0.000 (0.004)	Loss 0.6837 (0.6697)	Acc@1 84.375 (86.386)	Acc@5 100.000 (99.500)
Epoch: [53][192/196]	Time 0.997 (0.956)	Data 0.000 (0.002)	Loss 0.6842 (0.6771)	Acc@1 83.984 (86.207)	Acc@5 99.219 (99.449)
Max memory in training epoch: 62.8259328
count0: 388088
1
lr: 0.1

Epoch: [54 | 55] LR: 0.100000
Epoch: [54][0/196]	Time 1.104 (1.104)	Data 0.484 (0.484)	Loss 0.6347 (0.6347)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [54][64/196]	Time 1.009 (1.003)	Data 0.000 (0.008)	Loss 0.6228 (0.6781)	Acc@1 87.891 (86.094)	Acc@5 100.000 (99.555)
Epoch: [54][128/196]	Time 0.800 (0.978)	Data 0.000 (0.004)	Loss 0.7395 (0.6825)	Acc@1 85.156 (86.095)	Acc@5 99.219 (99.461)
Epoch: [54][192/196]	Time 0.960 (0.956)	Data 0.000 (0.003)	Loss 0.6653 (0.6803)	Acc@1 87.500 (86.099)	Acc@5 99.219 (99.452)
Max memory in training epoch: 62.8259328
count0: 388088
1
lr: 0.1

Epoch: [55 | 55] LR: 0.100000
Epoch: [55][0/196]	Time 1.010 (1.010)	Data 0.477 (0.477)	Loss 0.6188 (0.6188)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 1.000 (0.893)	Data 0.000 (0.008)	Loss 0.6502 (0.6645)	Acc@1 88.672 (86.791)	Acc@5 99.609 (99.537)
Epoch: [55][128/196]	Time 0.999 (0.947)	Data 0.000 (0.004)	Loss 0.6801 (0.6725)	Acc@1 85.547 (86.555)	Acc@5 100.000 (99.506)
Epoch: [55][192/196]	Time 0.998 (0.963)	Data 0.000 (0.003)	Loss 0.6845 (0.6771)	Acc@1 84.766 (86.344)	Acc@5 98.828 (99.464)
Max memory in training epoch: 62.8259328
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 388088
Count: 380002 ; 388088 ; 0.9791645193873555
[INFO] Storing checkpoint...

  256
  78.38
Max memory: 97.0219008
 189.551s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1598976
1
lr: 0.1

Epoch: [56 | 60] LR: 0.100000
Epoch: [56][0/196]	Time 1.933 (1.933)	Data 0.440 (0.440)	Loss 0.6200 (0.6200)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.959 (1.010)	Data 0.000 (0.007)	Loss 0.7922 (0.6424)	Acc@1 81.250 (87.512)	Acc@5 98.438 (99.525)
Epoch: [56][128/196]	Time 1.001 (1.005)	Data 0.000 (0.004)	Loss 0.7280 (0.6555)	Acc@1 85.547 (86.967)	Acc@5 99.219 (99.497)
Epoch: [56][192/196]	Time 0.992 (1.004)	Data 0.000 (0.002)	Loss 0.6042 (0.6665)	Acc@1 90.234 (86.640)	Acc@5 99.609 (99.458)
Max memory in training epoch: 76.1882112
count0: 380002
1
lr: 0.1

Epoch: [57 | 60] LR: 0.100000
Epoch: [57][0/196]	Time 0.999 (0.999)	Data 0.508 (0.508)	Loss 0.5828 (0.5828)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [57][64/196]	Time 0.999 (0.891)	Data 0.000 (0.008)	Loss 0.5969 (0.6557)	Acc@1 89.062 (87.067)	Acc@5 100.000 (99.621)
Epoch: [57][128/196]	Time 1.001 (0.943)	Data 0.000 (0.004)	Loss 0.6505 (0.6558)	Acc@1 89.844 (86.979)	Acc@5 98.438 (99.525)
Epoch: [57][192/196]	Time 0.993 (0.961)	Data 0.000 (0.003)	Loss 0.6848 (0.6644)	Acc@1 85.156 (86.727)	Acc@5 98.828 (99.484)
Max memory in training epoch: 62.4523776
count0: 380002
1
lr: 0.1

Epoch: [58 | 60] LR: 0.100000
Epoch: [58][0/196]	Time 1.078 (1.078)	Data 0.467 (0.467)	Loss 0.7428 (0.7428)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [58][64/196]	Time 1.016 (1.004)	Data 0.000 (0.007)	Loss 0.7277 (0.6626)	Acc@1 83.203 (86.923)	Acc@5 98.828 (99.471)
Epoch: [58][128/196]	Time 0.962 (0.993)	Data 0.000 (0.004)	Loss 0.7072 (0.6629)	Acc@1 85.547 (86.888)	Acc@5 99.219 (99.473)
Epoch: [58][192/196]	Time 0.996 (0.955)	Data 0.000 (0.003)	Loss 0.7060 (0.6595)	Acc@1 87.891 (86.816)	Acc@5 98.828 (99.500)
Max memory in training epoch: 62.4523776
count0: 380002
1
lr: 0.1

Epoch: [59 | 60] LR: 0.100000
Epoch: [59][0/196]	Time 1.056 (1.056)	Data 0.402 (0.402)	Loss 0.6852 (0.6852)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.997 (0.999)	Data 0.000 (0.006)	Loss 0.6688 (0.6581)	Acc@1 87.500 (86.953)	Acc@5 99.609 (99.489)
Epoch: [59][128/196]	Time 0.808 (0.982)	Data 0.000 (0.003)	Loss 0.6597 (0.6651)	Acc@1 87.109 (86.707)	Acc@5 98.828 (99.467)
Epoch: [59][192/196]	Time 0.964 (0.956)	Data 0.000 (0.002)	Loss 0.6266 (0.6690)	Acc@1 87.109 (86.541)	Acc@5 98.828 (99.460)
Max memory in training epoch: 62.4523776
count0: 380002
1
lr: 0.1

Epoch: [60 | 60] LR: 0.100000
Epoch: [60][0/196]	Time 1.047 (1.047)	Data 0.462 (0.462)	Loss 0.6592 (0.6592)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [60][64/196]	Time 1.000 (0.888)	Data 0.000 (0.007)	Loss 0.6638 (0.6519)	Acc@1 86.328 (87.230)	Acc@5 99.609 (99.495)
Epoch: [60][128/196]	Time 1.003 (0.945)	Data 0.000 (0.004)	Loss 0.6808 (0.6568)	Acc@1 85.938 (87.182)	Acc@5 98.828 (99.491)
Epoch: [60][192/196]	Time 0.996 (0.962)	Data 0.000 (0.003)	Loss 0.7332 (0.6576)	Acc@1 83.203 (87.063)	Acc@5 99.609 (99.520)
Max memory in training epoch: 62.4523776
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
count0: 380002
Count: 376760 ; 380002 ; 0.9914684659554424
[INFO] Storing checkpoint...

  256
  78.54
Max memory: 96.5996032
 189.382s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.157952
1
lr: 0.1

Epoch: [61 | 65] LR: 0.100000
Epoch: [61][0/196]	Time 1.932 (1.932)	Data 0.462 (0.462)	Loss 0.5969 (0.5969)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.944 (0.964)	Data 0.000 (0.007)	Loss 0.6067 (0.6470)	Acc@1 87.891 (87.031)	Acc@5 99.609 (99.543)
Epoch: [61][128/196]	Time 0.914 (0.955)	Data 0.000 (0.004)	Loss 0.6427 (0.6632)	Acc@1 87.500 (86.576)	Acc@5 99.219 (99.509)
Epoch: [61][192/196]	Time 0.968 (0.917)	Data 0.000 (0.003)	Loss 0.6931 (0.6639)	Acc@1 85.547 (86.599)	Acc@5 99.609 (99.504)
Max memory in training epoch: 74.0014592
count0: 376760
1
lr: 0.1

Epoch: [62 | 65] LR: 0.100000
Epoch: [62][0/196]	Time 0.976 (0.976)	Data 0.436 (0.436)	Loss 0.5759 (0.5759)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.949 (0.947)	Data 0.000 (0.007)	Loss 0.6591 (0.6670)	Acc@1 87.109 (86.466)	Acc@5 100.000 (99.561)
Epoch: [62][128/196]	Time 0.951 (0.947)	Data 0.003 (0.004)	Loss 0.6907 (0.6654)	Acc@1 85.156 (86.546)	Acc@5 99.609 (99.500)
Epoch: [62][192/196]	Time 0.941 (0.948)	Data 0.000 (0.002)	Loss 0.7735 (0.6694)	Acc@1 80.859 (86.452)	Acc@5 98.438 (99.474)
Max memory in training epoch: 60.3352576
count0: 376760
1
lr: 0.1

Epoch: [63 | 65] LR: 0.100000
Epoch: [63][0/196]	Time 1.070 (1.070)	Data 0.410 (0.410)	Loss 0.6596 (0.6596)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [63][64/196]	Time 0.947 (0.949)	Data 0.000 (0.007)	Loss 0.6281 (0.6577)	Acc@1 87.500 (86.707)	Acc@5 98.828 (99.501)
Epoch: [63][128/196]	Time 0.951 (0.947)	Data 0.000 (0.003)	Loss 0.6597 (0.6656)	Acc@1 86.719 (86.513)	Acc@5 99.609 (99.494)
Epoch: [63][192/196]	Time 0.760 (0.932)	Data 0.000 (0.002)	Loss 0.6262 (0.6679)	Acc@1 86.719 (86.464)	Acc@5 99.219 (99.486)
Max memory in training epoch: 60.3352576
count0: 376760
1
lr: 0.1

Epoch: [64 | 65] LR: 0.100000
Epoch: [64][0/196]	Time 0.823 (0.823)	Data 0.505 (0.505)	Loss 0.7394 (0.7394)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [64][64/196]	Time 0.933 (0.873)	Data 0.000 (0.008)	Loss 0.6258 (0.6518)	Acc@1 89.453 (87.085)	Acc@5 99.219 (99.477)
Epoch: [64][128/196]	Time 0.916 (0.909)	Data 0.000 (0.004)	Loss 0.6899 (0.6561)	Acc@1 88.672 (86.900)	Acc@5 98.828 (99.482)
Epoch: [64][192/196]	Time 0.756 (0.891)	Data 0.000 (0.003)	Loss 0.7308 (0.6616)	Acc@1 82.812 (86.694)	Acc@5 98.828 (99.456)
Max memory in training epoch: 60.3352576
count0: 376760
1
lr: 0.1

Epoch: [65 | 65] LR: 0.100000
Epoch: [65][0/196]	Time 0.803 (0.803)	Data 0.398 (0.398)	Loss 0.6029 (0.6029)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [65][64/196]	Time 0.912 (0.914)	Data 0.000 (0.006)	Loss 0.6080 (0.6634)	Acc@1 88.672 (86.430)	Acc@5 99.609 (99.495)
Epoch: [65][128/196]	Time 0.952 (0.881)	Data 0.000 (0.003)	Loss 0.6670 (0.6647)	Acc@1 85.547 (86.292)	Acc@5 98.438 (99.485)
Epoch: [65][192/196]	Time 0.945 (0.903)	Data 0.000 (0.002)	Loss 0.6068 (0.6687)	Acc@1 89.453 (86.352)	Acc@5 100.000 (99.468)
Max memory in training epoch: 60.3352576
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 376760
Count: 372714 ; 376760 ; 0.9892610680539335
[INFO] Storing checkpoint...

  256
  76.45
Max memory: 93.43104
 177.576s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1565184
1
lr: 0.1

Epoch: [66 | 70] LR: 0.100000
Epoch: [66][0/196]	Time 1.851 (1.851)	Data 0.396 (0.396)	Loss 0.5984 (0.5984)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [66][64/196]	Time 0.941 (0.959)	Data 0.000 (0.006)	Loss 0.6854 (0.6300)	Acc@1 85.156 (87.662)	Acc@5 99.219 (99.519)
Epoch: [66][128/196]	Time 0.907 (0.946)	Data 0.000 (0.003)	Loss 0.6212 (0.6490)	Acc@1 89.062 (87.121)	Acc@5 100.000 (99.503)
Epoch: [66][192/196]	Time 0.950 (0.909)	Data 0.000 (0.002)	Loss 0.5927 (0.6512)	Acc@1 88.281 (87.014)	Acc@5 100.000 (99.498)
Max memory in training epoch: 73.3956608
count0: 372714
1
lr: 0.1

Epoch: [67 | 70] LR: 0.100000
Epoch: [67][0/196]	Time 1.010 (1.010)	Data 0.425 (0.425)	Loss 0.6021 (0.6021)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [67][64/196]	Time 0.920 (0.945)	Data 0.000 (0.007)	Loss 0.6508 (0.6652)	Acc@1 86.719 (86.520)	Acc@5 99.609 (99.441)
Epoch: [67][128/196]	Time 0.952 (0.945)	Data 0.000 (0.004)	Loss 0.6704 (0.6639)	Acc@1 85.938 (86.701)	Acc@5 99.219 (99.512)
Epoch: [67][192/196]	Time 0.939 (0.943)	Data 0.000 (0.002)	Loss 0.6171 (0.6629)	Acc@1 87.891 (86.690)	Acc@5 99.609 (99.492)
Max memory in training epoch: 59.6872704
count0: 372714
1
lr: 0.1

Epoch: [68 | 70] LR: 0.100000
Epoch: [68][0/196]	Time 0.987 (0.987)	Data 0.391 (0.391)	Loss 0.6137 (0.6137)	Acc@1 91.016 (91.016)	Acc@5 99.609 (99.609)
Epoch: [68][64/196]	Time 0.993 (0.946)	Data 0.000 (0.006)	Loss 0.6628 (0.6616)	Acc@1 86.328 (86.803)	Acc@5 99.609 (99.561)
Epoch: [68][128/196]	Time 0.916 (0.944)	Data 0.000 (0.003)	Loss 0.5709 (0.6560)	Acc@1 91.016 (86.906)	Acc@5 99.609 (99.549)
Epoch: [68][192/196]	Time 0.908 (0.933)	Data 0.000 (0.002)	Loss 0.6105 (0.6601)	Acc@1 87.891 (86.858)	Acc@5 99.609 (99.496)
Max memory in training epoch: 59.6872704
count0: 372714
1
lr: 0.1

Epoch: [69 | 70] LR: 0.100000
Epoch: [69][0/196]	Time 0.814 (0.814)	Data 0.397 (0.397)	Loss 0.6811 (0.6811)	Acc@1 85.547 (85.547)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.939 (0.862)	Data 0.000 (0.006)	Loss 0.6385 (0.6570)	Acc@1 86.328 (86.797)	Acc@5 98.828 (99.465)
Epoch: [69][128/196]	Time 0.939 (0.902)	Data 0.000 (0.003)	Loss 0.7165 (0.6583)	Acc@1 85.156 (86.816)	Acc@5 99.219 (99.485)
Epoch: [69][192/196]	Time 0.902 (0.914)	Data 0.000 (0.002)	Loss 0.6515 (0.6617)	Acc@1 87.500 (86.723)	Acc@5 99.609 (99.480)
Max memory in training epoch: 59.6872704
count0: 372714
1
lr: 0.1

Epoch: [70 | 70] LR: 0.100000
Epoch: [70][0/196]	Time 1.023 (1.023)	Data 0.423 (0.423)	Loss 0.6519 (0.6519)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.814 (0.835)	Data 0.000 (0.007)	Loss 0.7685 (0.6467)	Acc@1 85.156 (87.386)	Acc@5 98.438 (99.501)
Epoch: [70][128/196]	Time 0.910 (0.876)	Data 0.000 (0.003)	Loss 0.6804 (0.6473)	Acc@1 87.109 (87.246)	Acc@5 99.219 (99.531)
Epoch: [70][192/196]	Time 0.945 (0.860)	Data 0.000 (0.002)	Loss 0.6553 (0.6573)	Acc@1 88.281 (86.860)	Acc@5 100.000 (99.543)
Max memory in training epoch: 59.6872704
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 372714
Count: 369248 ; 372714 ; 0.9907006444619735
[INFO] Storing checkpoint...

  256
  76.81
Max memory: 91.8219264
 169.325s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1551872
1
lr: 0.1

Epoch: [71 | 75] LR: 0.100000
Epoch: [71][0/196]	Time 2.017 (2.017)	Data 0.526 (0.526)	Loss 0.7153 (0.7153)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [71][64/196]	Time 0.946 (0.958)	Data 0.000 (0.008)	Loss 0.7033 (0.6404)	Acc@1 84.375 (87.506)	Acc@5 99.609 (99.543)
Epoch: [71][128/196]	Time 0.739 (0.924)	Data 0.000 (0.004)	Loss 0.6803 (0.6487)	Acc@1 87.109 (87.070)	Acc@5 99.219 (99.531)
Epoch: [71][192/196]	Time 0.933 (0.909)	Data 0.000 (0.003)	Loss 0.6661 (0.6576)	Acc@1 86.328 (86.715)	Acc@5 98.828 (99.514)
Max memory in training epoch: 72.8400384
count0: 369248
1
lr: 0.1

Epoch: [72 | 75] LR: 0.100000
Epoch: [72][0/196]	Time 1.003 (1.003)	Data 0.483 (0.483)	Loss 0.6155 (0.6155)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [72][64/196]	Time 0.943 (0.943)	Data 0.000 (0.008)	Loss 0.6557 (0.6737)	Acc@1 84.766 (86.130)	Acc@5 99.609 (99.501)
Epoch: [72][128/196]	Time 0.934 (0.941)	Data 0.000 (0.004)	Loss 0.6351 (0.6654)	Acc@1 87.891 (86.486)	Acc@5 100.000 (99.534)
Epoch: [72][192/196]	Time 0.934 (0.940)	Data 0.000 (0.003)	Loss 0.6327 (0.6653)	Acc@1 87.500 (86.559)	Acc@5 100.000 (99.530)
Max memory in training epoch: 59.4198016
count0: 369248
1
lr: 0.1

Epoch: [73 | 75] LR: 0.100000
Epoch: [73][0/196]	Time 0.954 (0.954)	Data 0.381 (0.381)	Loss 0.6490 (0.6490)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.940 (0.938)	Data 0.000 (0.006)	Loss 0.7324 (0.6490)	Acc@1 83.594 (86.845)	Acc@5 99.609 (99.549)
Epoch: [73][128/196]	Time 0.988 (0.940)	Data 0.000 (0.003)	Loss 0.7248 (0.6453)	Acc@1 84.375 (87.149)	Acc@5 99.219 (99.534)
Epoch: [73][192/196]	Time 0.909 (0.934)	Data 0.000 (0.002)	Loss 0.7388 (0.6522)	Acc@1 82.031 (86.901)	Acc@5 99.609 (99.512)
Max memory in training epoch: 59.4198016
count0: 369248
1
lr: 0.1

Epoch: [74 | 75] LR: 0.100000
Epoch: [74][0/196]	Time 0.856 (0.856)	Data 0.431 (0.431)	Loss 0.6528 (0.6528)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.931 (0.843)	Data 0.000 (0.007)	Loss 0.6770 (0.6602)	Acc@1 87.500 (86.755)	Acc@5 98.828 (99.429)
Epoch: [74][128/196]	Time 0.950 (0.893)	Data 0.000 (0.004)	Loss 0.7223 (0.6603)	Acc@1 84.766 (86.782)	Acc@5 98.828 (99.458)
Epoch: [74][192/196]	Time 0.941 (0.907)	Data 0.000 (0.002)	Loss 0.6475 (0.6603)	Acc@1 87.109 (86.792)	Acc@5 99.609 (99.478)
Max memory in training epoch: 59.4198016
count0: 369248
1
lr: 0.1

Epoch: [75 | 75] LR: 0.100000
Epoch: [75][0/196]	Time 1.009 (1.009)	Data 0.576 (0.576)	Loss 0.7086 (0.7086)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [75][64/196]	Time 0.905 (0.936)	Data 0.000 (0.009)	Loss 0.5805 (0.6443)	Acc@1 90.625 (87.578)	Acc@5 100.000 (99.573)
Epoch: [75][128/196]	Time 0.799 (0.884)	Data 0.000 (0.005)	Loss 0.6200 (0.6453)	Acc@1 88.672 (87.500)	Acc@5 99.609 (99.537)
Epoch: [75][192/196]	Time 0.903 (0.894)	Data 0.000 (0.003)	Loss 0.6633 (0.6507)	Acc@1 89.062 (87.287)	Acc@5 99.609 (99.530)
Max memory in training epoch: 59.4198016
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 369248
Count: 365786 ; 369248 ; 0.9906241875379149
[INFO] Storing checkpoint...

  256
  78.86
Max memory: 91.668224
 175.956s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.153856
1
lr: 0.1

Epoch: [76 | 80] LR: 0.100000
Epoch: [76][0/196]	Time 1.982 (1.982)	Data 0.523 (0.523)	Loss 0.5772 (0.5772)	Acc@1 88.672 (88.672)	Acc@5 99.609 (99.609)
Epoch: [76][64/196]	Time 1.009 (0.962)	Data 0.000 (0.008)	Loss 0.7167 (0.6276)	Acc@1 85.156 (87.482)	Acc@5 98.828 (99.657)
Epoch: [76][128/196]	Time 0.799 (0.903)	Data 0.000 (0.004)	Loss 0.5949 (0.6403)	Acc@1 87.500 (87.131)	Acc@5 99.219 (99.564)
Epoch: [76][192/196]	Time 0.936 (0.916)	Data 0.000 (0.003)	Loss 0.6729 (0.6476)	Acc@1 87.500 (86.970)	Acc@5 98.828 (99.528)
Max memory in training epoch: 72.837376
count0: 365786
1
lr: 0.1

Epoch: [77 | 80] LR: 0.100000
Epoch: [77][0/196]	Time 0.984 (0.984)	Data 0.515 (0.515)	Loss 0.5962 (0.5962)	Acc@1 89.844 (89.844)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.947 (0.947)	Data 0.000 (0.008)	Loss 0.6254 (0.6529)	Acc@1 89.844 (86.941)	Acc@5 99.219 (99.471)
Epoch: [77][128/196]	Time 0.936 (0.945)	Data 0.000 (0.004)	Loss 0.6069 (0.6497)	Acc@1 87.891 (87.097)	Acc@5 100.000 (99.488)
Epoch: [77][192/196]	Time 0.949 (0.944)	Data 0.000 (0.003)	Loss 0.6975 (0.6537)	Acc@1 86.328 (86.968)	Acc@5 99.219 (99.460)
Max memory in training epoch: 59.394816
count0: 365786
1
lr: 0.1

Epoch: [78 | 80] LR: 0.100000
Epoch: [78][0/196]	Time 1.010 (1.010)	Data 0.485 (0.485)	Loss 0.7408 (0.7408)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [78][64/196]	Time 0.935 (0.946)	Data 0.000 (0.008)	Loss 0.6630 (0.6559)	Acc@1 84.766 (87.067)	Acc@5 100.000 (99.453)
Epoch: [78][128/196]	Time 0.949 (0.943)	Data 0.000 (0.004)	Loss 0.6302 (0.6525)	Acc@1 86.328 (87.112)	Acc@5 99.219 (99.428)
Epoch: [78][192/196]	Time 0.968 (0.937)	Data 0.000 (0.003)	Loss 0.5820 (0.6562)	Acc@1 91.016 (86.903)	Acc@5 99.219 (99.460)
Max memory in training epoch: 59.394816
count0: 365786
1
lr: 0.1

Epoch: [79 | 80] LR: 0.100000
Epoch: [79][0/196]	Time 1.038 (1.038)	Data 0.566 (0.566)	Loss 0.6160 (0.6160)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [79][64/196]	Time 0.946 (0.848)	Data 0.000 (0.009)	Loss 0.7088 (0.6451)	Acc@1 83.984 (87.151)	Acc@5 98.828 (99.531)
Epoch: [79][128/196]	Time 0.952 (0.896)	Data 0.000 (0.005)	Loss 0.6443 (0.6606)	Acc@1 85.938 (86.676)	Acc@5 99.219 (99.503)
Epoch: [79][192/196]	Time 0.937 (0.912)	Data 0.000 (0.003)	Loss 0.6995 (0.6588)	Acc@1 85.156 (86.709)	Acc@5 99.609 (99.492)
Max memory in training epoch: 59.394816
count0: 365786
1
lr: 0.1

Epoch: [80 | 80] LR: 0.100000
Epoch: [80][0/196]	Time 1.007 (1.007)	Data 0.394 (0.394)	Loss 0.6328 (0.6328)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [80][64/196]	Time 0.944 (0.944)	Data 0.000 (0.006)	Loss 0.6926 (0.6641)	Acc@1 85.547 (86.460)	Acc@5 99.609 (99.381)
Epoch: [80][128/196]	Time 0.911 (0.940)	Data 0.000 (0.003)	Loss 0.6025 (0.6582)	Acc@1 89.453 (86.685)	Acc@5 99.609 (99.440)
Epoch: [80][192/196]	Time 0.813 (0.903)	Data 0.000 (0.002)	Loss 0.7280 (0.6567)	Acc@1 84.375 (86.796)	Acc@5 100.000 (99.478)
Max memory in training epoch: 59.394816
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 365786
Count: 364918 ; 365786 ; 0.9976270278250124
[INFO] Storing checkpoint...

  256
  82.85
Max memory: 91.5116544
 177.695s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1553408
1
lr: 0.1

Epoch: [91 | 95] LR: 0.100000
Epoch: [91][0/196]	Time 1.551 (1.551)	Data 0.554 (0.554)	Loss 0.6267 (0.6267)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [91][64/196]	Time 0.938 (0.790)	Data 0.000 (0.009)	Loss 0.8171 (0.6203)	Acc@1 80.469 (87.945)	Acc@5 98.828 (99.561)
Epoch: [91][128/196]	Time 0.935 (0.863)	Data 0.000 (0.005)	Loss 0.7156 (0.6358)	Acc@1 84.766 (87.464)	Acc@5 100.000 (99.543)
Epoch: [91][192/196]	Time 0.941 (0.890)	Data 0.000 (0.003)	Loss 0.6622 (0.6454)	Acc@1 86.719 (87.115)	Acc@5 98.828 (99.510)
Max memory in training epoch: 72.1112576
count0: 369818
1
lr: 0.1

Epoch: [92 | 95] LR: 0.100000
Epoch: [92][0/196]	Time 1.045 (1.045)	Data 0.553 (0.553)	Loss 0.6966 (0.6966)	Acc@1 83.984 (83.984)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.943 (0.941)	Data 0.000 (0.009)	Loss 0.6472 (0.6360)	Acc@1 85.547 (87.668)	Acc@5 99.219 (99.519)
Epoch: [92][128/196]	Time 1.030 (0.943)	Data 0.000 (0.004)	Loss 0.6326 (0.6455)	Acc@1 85.938 (87.215)	Acc@5 99.609 (99.549)
Epoch: [92][192/196]	Time 0.950 (0.941)	Data 0.000 (0.003)	Loss 0.7000 (0.6454)	Acc@1 87.109 (87.160)	Acc@5 99.219 (99.565)
Max memory in training epoch: 58.7781632
count0: 369818
1
lr: 0.010000000000000002

Epoch: [93 | 95] LR: 0.010000
Epoch: [93][0/196]	Time 0.959 (0.959)	Data 0.608 (0.608)	Loss 0.7167 (0.7167)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [93][64/196]	Time 0.947 (0.940)	Data 0.000 (0.010)	Loss 0.5354 (0.5658)	Acc@1 91.406 (90.060)	Acc@5 98.438 (99.615)
Epoch: [93][128/196]	Time 0.938 (0.942)	Data 0.000 (0.005)	Loss 0.5113 (0.5345)	Acc@1 91.406 (91.046)	Acc@5 100.000 (99.715)
Epoch: [93][192/196]	Time 0.906 (0.935)	Data 0.000 (0.003)	Loss 0.4760 (0.5180)	Acc@1 92.188 (91.611)	Acc@5 100.000 (99.767)
Max memory in training epoch: 58.7781632
count0: 369818
1
lr: 0.010000000000000002

Epoch: [94 | 95] LR: 0.010000
Epoch: [94][0/196]	Time 0.777 (0.777)	Data 0.488 (0.488)	Loss 0.4377 (0.4377)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [94][64/196]	Time 0.940 (0.832)	Data 0.000 (0.008)	Loss 0.4643 (0.4682)	Acc@1 92.969 (93.317)	Acc@5 100.000 (99.886)
Epoch: [94][128/196]	Time 0.958 (0.887)	Data 0.000 (0.004)	Loss 0.4691 (0.4639)	Acc@1 93.359 (93.344)	Acc@5 99.609 (99.876)
Epoch: [94][192/196]	Time 0.949 (0.906)	Data 0.000 (0.003)	Loss 0.4604 (0.4614)	Acc@1 92.578 (93.357)	Acc@5 100.000 (99.864)
Max memory in training epoch: 58.7781632
count0: 369818
1
lr: 0.010000000000000002

Epoch: [95 | 95] LR: 0.010000
Epoch: [95][0/196]	Time 0.960 (0.960)	Data 0.550 (0.550)	Loss 0.4318 (0.4318)	Acc@1 95.312 (95.312)	Acc@5 99.609 (99.609)
Epoch: [95][64/196]	Time 0.944 (0.942)	Data 0.000 (0.009)	Loss 0.4291 (0.4373)	Acc@1 93.750 (94.291)	Acc@5 100.000 (99.898)
Epoch: [95][128/196]	Time 0.939 (0.942)	Data 0.000 (0.004)	Loss 0.4969 (0.4350)	Acc@1 92.969 (94.147)	Acc@5 100.000 (99.909)
Epoch: [95][192/196]	Time 0.871 (0.937)	Data 0.000 (0.003)	Loss 0.4722 (0.4362)	Acc@1 92.969 (94.124)	Acc@5 99.609 (99.901)
Max memory in training epoch: 58.7781632
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 369818
Count: 368662 ; 369818 ; 0.9968741380895467
[INFO] Storing checkpoint...

  256
  91.08
Max memory: 90.4941568
 184.083s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1548288
1
lr: 0.010000000000000002

Epoch: [96 | 100] LR: 0.010000
Epoch: [96][0/196]	Time 1.663 (1.663)	Data 0.420 (0.420)	Loss 0.4107 (0.4107)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.947 (0.932)	Data 0.000 (0.007)	Loss 0.4289 (0.4192)	Acc@1 93.750 (94.621)	Acc@5 100.000 (99.832)
Epoch: [96][128/196]	Time 0.944 (0.938)	Data 0.000 (0.003)	Loss 0.3951 (0.4202)	Acc@1 94.531 (94.474)	Acc@5 100.000 (99.861)
Epoch: [96][192/196]	Time 0.940 (0.938)	Data 0.000 (0.002)	Loss 0.3789 (0.4217)	Acc@1 96.484 (94.396)	Acc@5 100.000 (99.875)
Max memory in training epoch: 71.9267328
count0: 368662
1
lr: 0.010000000000000002

Epoch: [97 | 100] LR: 0.010000
Epoch: [97][0/196]	Time 1.011 (1.011)	Data 0.396 (0.396)	Loss 0.3780 (0.3780)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [97][64/196]	Time 0.941 (0.939)	Data 0.000 (0.006)	Loss 0.3838 (0.4028)	Acc@1 97.266 (95.138)	Acc@5 100.000 (99.898)
Epoch: [97][128/196]	Time 0.813 (0.941)	Data 0.000 (0.003)	Loss 0.3960 (0.4057)	Acc@1 96.094 (94.895)	Acc@5 100.000 (99.909)
Epoch: [97][192/196]	Time 0.942 (0.936)	Data 0.000 (0.002)	Loss 0.3891 (0.4063)	Acc@1 95.312 (94.855)	Acc@5 100.000 (99.909)
Max memory in training epoch: 58.6188288
count0: 368662
1
lr: 0.010000000000000002

Epoch: [98 | 100] LR: 0.010000
Epoch: [98][0/196]	Time 0.964 (0.964)	Data 0.423 (0.423)	Loss 0.3951 (0.3951)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.939 (0.942)	Data 0.000 (0.007)	Loss 0.4116 (0.3976)	Acc@1 93.750 (95.030)	Acc@5 99.609 (99.928)
Epoch: [98][128/196]	Time 0.917 (0.941)	Data 0.000 (0.003)	Loss 0.3504 (0.3959)	Acc@1 96.094 (95.061)	Acc@5 100.000 (99.918)
Epoch: [98][192/196]	Time 0.750 (0.919)	Data 0.000 (0.002)	Loss 0.4136 (0.3964)	Acc@1 94.531 (94.995)	Acc@5 100.000 (99.921)
Max memory in training epoch: 58.6188288
count0: 368662
1
lr: 0.010000000000000002

Epoch: [99 | 100] LR: 0.010000
Epoch: [99][0/196]	Time 0.826 (0.826)	Data 0.485 (0.485)	Loss 0.3731 (0.3731)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.935 (0.884)	Data 0.000 (0.008)	Loss 0.3709 (0.3805)	Acc@1 96.094 (95.403)	Acc@5 100.000 (99.910)
Epoch: [99][128/196]	Time 0.943 (0.910)	Data 0.000 (0.004)	Loss 0.4520 (0.3831)	Acc@1 92.969 (95.325)	Acc@5 100.000 (99.909)
Epoch: [99][192/196]	Time 0.960 (0.920)	Data 0.000 (0.003)	Loss 0.3652 (0.3834)	Acc@1 97.656 (95.294)	Acc@5 99.219 (99.917)
Max memory in training epoch: 58.6188288
count0: 368662
1
lr: 0.010000000000000002

Epoch: [100 | 100] LR: 0.010000
Epoch: [100][0/196]	Time 1.033 (1.033)	Data 0.564 (0.564)	Loss 0.3765 (0.3765)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 0.940 (0.938)	Data 0.000 (0.009)	Loss 0.3963 (0.3681)	Acc@1 94.141 (95.637)	Acc@5 100.000 (99.964)
Epoch: [100][128/196]	Time 0.909 (0.936)	Data 0.000 (0.005)	Loss 0.3396 (0.3701)	Acc@1 96.484 (95.564)	Acc@5 100.000 (99.949)
Epoch: [100][192/196]	Time 0.934 (0.902)	Data 0.000 (0.003)	Loss 0.3895 (0.3723)	Acc@1 94.531 (95.468)	Acc@5 100.000 (99.935)
Max memory in training epoch: 58.6188288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368662
[INFO] Storing checkpoint...

  256
  91.25
Max memory: 90.4037376
 177.601s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1548288
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Epoch: [101][0/196]	Time 1.323 (1.323)	Data 0.371 (0.371)	Loss 0.3657 (0.3657)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [101][64/196]	Time 0.944 (0.834)	Data 0.000 (0.006)	Loss 0.4215 (0.3674)	Acc@1 92.188 (95.637)	Acc@5 100.000 (99.922)
Epoch: [101][128/196]	Time 0.912 (0.887)	Data 0.000 (0.003)	Loss 0.4218 (0.3684)	Acc@1 94.141 (95.543)	Acc@5 100.000 (99.942)
Epoch: [101][192/196]	Time 0.946 (0.906)	Data 0.000 (0.002)	Loss 0.3472 (0.3676)	Acc@1 95.703 (95.515)	Acc@5 100.000 (99.939)
Max memory in training epoch: 71.9267328
count0: 368662
1
lr: 0.010000000000000002

Epoch: [102 | 105] LR: 0.010000
Epoch: [102][0/196]	Time 0.954 (0.954)	Data 0.541 (0.541)	Loss 0.3372 (0.3372)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [102][64/196]	Time 0.946 (0.943)	Data 0.000 (0.009)	Loss 0.3465 (0.3555)	Acc@1 95.312 (95.835)	Acc@5 100.000 (99.922)
Epoch: [102][128/196]	Time 0.946 (0.942)	Data 0.000 (0.004)	Loss 0.4042 (0.3563)	Acc@1 95.312 (95.797)	Acc@5 100.000 (99.930)
Epoch: [102][192/196]	Time 0.950 (0.942)	Data 0.000 (0.003)	Loss 0.4358 (0.3566)	Acc@1 92.969 (95.756)	Acc@5 100.000 (99.933)
Max memory in training epoch: 58.6188288
count0: 368662
1
lr: 0.010000000000000002

Epoch: [103 | 105] LR: 0.010000
Epoch: [103][0/196]	Time 1.017 (1.017)	Data 0.567 (0.567)	Loss 0.3683 (0.3683)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [103][64/196]	Time 0.942 (0.939)	Data 0.000 (0.009)	Loss 0.3202 (0.3443)	Acc@1 97.266 (96.148)	Acc@5 100.000 (99.970)
Epoch: [103][128/196]	Time 0.905 (0.939)	Data 0.000 (0.005)	Loss 0.3213 (0.3462)	Acc@1 96.875 (96.015)	Acc@5 100.000 (99.949)
Epoch: [103][192/196]	Time 0.749 (0.909)	Data 0.000 (0.003)	Loss 0.3648 (0.3491)	Acc@1 95.703 (95.885)	Acc@5 100.000 (99.943)
Max memory in training epoch: 58.6188288
count0: 368662
1
lr: 0.010000000000000002

Epoch: [104 | 105] LR: 0.010000
Epoch: [104][0/196]	Time 0.836 (0.836)	Data 0.496 (0.496)	Loss 0.3230 (0.3230)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [104][64/196]	Time 1.003 (0.930)	Data 0.000 (0.008)	Loss 0.3724 (0.3425)	Acc@1 94.531 (96.112)	Acc@5 100.000 (99.964)
Epoch: [104][128/196]	Time 0.944 (0.936)	Data 0.000 (0.004)	Loss 0.3198 (0.3381)	Acc@1 95.703 (96.166)	Acc@5 100.000 (99.961)
Epoch: [104][192/196]	Time 0.945 (0.938)	Data 0.000 (0.003)	Loss 0.3405 (0.3403)	Acc@1 95.703 (96.041)	Acc@5 100.000 (99.953)
Max memory in training epoch: 58.6188288
count0: 368662
1
lr: 0.010000000000000002

Epoch: [105 | 105] LR: 0.010000
Epoch: [105][0/196]	Time 0.918 (0.918)	Data 0.559 (0.559)	Loss 0.3336 (0.3336)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [105][64/196]	Time 0.758 (0.860)	Data 0.000 (0.009)	Loss 0.3722 (0.3281)	Acc@1 94.922 (96.508)	Acc@5 100.000 (99.976)
Epoch: [105][128/196]	Time 0.941 (0.882)	Data 0.000 (0.005)	Loss 0.3168 (0.3312)	Acc@1 95.312 (96.312)	Acc@5 100.000 (99.973)
Epoch: [105][192/196]	Time 0.964 (0.901)	Data 0.000 (0.003)	Loss 0.3720 (0.3346)	Acc@1 95.312 (96.193)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.6188288
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368662
Count: 368372 ; 368662 ; 0.9992133715978322
[INFO] Storing checkpoint...

  256
  90.82
Max memory: 90.4037376
 177.454s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 106
Max memory: 0.1547264
1
lr: 0.010000000000000002

Epoch: [106 | 110] LR: 0.010000
Epoch: [106][0/196]	Time 1.533 (1.533)	Data 0.366 (0.366)	Loss 0.3460 (0.3460)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [106][64/196]	Time 0.751 (0.847)	Data 0.000 (0.006)	Loss 0.3056 (0.3184)	Acc@1 96.875 (96.623)	Acc@5 100.000 (99.982)
Epoch: [106][128/196]	Time 0.943 (0.870)	Data 0.000 (0.003)	Loss 0.3204 (0.3217)	Acc@1 95.312 (96.496)	Acc@5 100.000 (99.964)
Epoch: [106][192/196]	Time 0.936 (0.893)	Data 0.000 (0.002)	Loss 0.3186 (0.3264)	Acc@1 96.094 (96.300)	Acc@5 100.000 (99.964)
Max memory in training epoch: 71.6119552
count0: 368372
1
lr: 0.010000000000000002

Epoch: [107 | 110] LR: 0.010000
Epoch: [107][0/196]	Time 0.973 (0.973)	Data 0.572 (0.572)	Loss 0.3302 (0.3302)	Acc@1 96.484 (96.484)	Acc@5 99.609 (99.609)
Epoch: [107][64/196]	Time 0.949 (0.942)	Data 0.000 (0.009)	Loss 0.3462 (0.3193)	Acc@1 94.141 (96.490)	Acc@5 100.000 (99.958)
Epoch: [107][128/196]	Time 0.943 (0.941)	Data 0.000 (0.005)	Loss 0.3145 (0.3196)	Acc@1 96.484 (96.496)	Acc@5 100.000 (99.958)
Epoch: [107][192/196]	Time 0.941 (0.941)	Data 0.000 (0.003)	Loss 0.3519 (0.3225)	Acc@1 96.094 (96.371)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [108 | 110] LR: 0.010000
Epoch: [108][0/196]	Time 1.011 (1.011)	Data 0.557 (0.557)	Loss 0.3094 (0.3094)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [108][64/196]	Time 0.937 (0.943)	Data 0.000 (0.009)	Loss 0.3121 (0.3181)	Acc@1 96.484 (96.490)	Acc@5 100.000 (99.964)
Epoch: [108][128/196]	Time 0.902 (0.938)	Data 0.000 (0.005)	Loss 0.3880 (0.3181)	Acc@1 94.141 (96.448)	Acc@5 99.609 (99.958)
Epoch: [108][192/196]	Time 0.794 (0.902)	Data 0.000 (0.003)	Loss 0.3339 (0.3208)	Acc@1 95.312 (96.250)	Acc@5 100.000 (99.964)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [109 | 110] LR: 0.010000
Epoch: [109][0/196]	Time 0.995 (0.995)	Data 0.434 (0.434)	Loss 0.2696 (0.2696)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [109][64/196]	Time 0.949 (0.943)	Data 0.000 (0.007)	Loss 0.3128 (0.3093)	Acc@1 95.312 (96.599)	Acc@5 100.000 (99.976)
Epoch: [109][128/196]	Time 0.911 (0.943)	Data 0.000 (0.004)	Loss 0.2922 (0.3131)	Acc@1 97.266 (96.378)	Acc@5 100.000 (99.973)
Epoch: [109][192/196]	Time 0.942 (0.906)	Data 0.000 (0.002)	Loss 0.3837 (0.3150)	Acc@1 93.359 (96.308)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [110 | 110] LR: 0.010000
Epoch: [110][0/196]	Time 0.995 (0.995)	Data 0.628 (0.628)	Loss 0.2922 (0.2922)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [110][64/196]	Time 0.944 (0.941)	Data 0.000 (0.010)	Loss 0.2910 (0.3072)	Acc@1 97.656 (96.569)	Acc@5 100.000 (99.982)
Epoch: [110][128/196]	Time 0.949 (0.942)	Data 0.000 (0.005)	Loss 0.3265 (0.3045)	Acc@1 95.703 (96.636)	Acc@5 99.609 (99.976)
Epoch: [110][192/196]	Time 0.932 (0.939)	Data 0.000 (0.003)	Loss 0.3066 (0.3056)	Acc@1 95.703 (96.521)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.6184192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368372
[INFO] Storing checkpoint...

  256
  90.08
Max memory: 90.416128
 184.866s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 111
Max memory: 0.1547264
1
lr: 0.010000000000000002

Epoch: [111 | 115] LR: 0.010000
Epoch: [111][0/196]	Time 1.648 (1.648)	Data 0.504 (0.504)	Loss 0.3466 (0.3466)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [111][64/196]	Time 0.909 (0.930)	Data 0.000 (0.008)	Loss 0.2958 (0.2960)	Acc@1 97.266 (96.911)	Acc@5 100.000 (99.970)
Epoch: [111][128/196]	Time 0.795 (0.874)	Data 0.000 (0.004)	Loss 0.3323 (0.3005)	Acc@1 96.484 (96.639)	Acc@5 100.000 (99.958)
Epoch: [111][192/196]	Time 0.938 (0.897)	Data 0.000 (0.003)	Loss 0.3148 (0.3013)	Acc@1 94.922 (96.586)	Acc@5 100.000 (99.957)
Max memory in training epoch: 71.6119552
count0: 368372
1
lr: 0.010000000000000002

Epoch: [112 | 115] LR: 0.010000
Epoch: [112][0/196]	Time 1.000 (1.000)	Data 0.523 (0.523)	Loss 0.2722 (0.2722)	Acc@1 97.656 (97.656)	Acc@5 99.609 (99.609)
Epoch: [112][64/196]	Time 0.945 (0.938)	Data 0.000 (0.008)	Loss 0.3108 (0.2953)	Acc@1 96.094 (96.815)	Acc@5 100.000 (99.970)
Epoch: [112][128/196]	Time 0.941 (0.940)	Data 0.000 (0.004)	Loss 0.2807 (0.2981)	Acc@1 97.656 (96.651)	Acc@5 100.000 (99.958)
Epoch: [112][192/196]	Time 0.943 (0.940)	Data 0.000 (0.003)	Loss 0.3098 (0.2988)	Acc@1 96.094 (96.648)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [113 | 115] LR: 0.010000
Epoch: [113][0/196]	Time 0.962 (0.962)	Data 0.536 (0.536)	Loss 0.3206 (0.3206)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [113][64/196]	Time 0.940 (0.939)	Data 0.000 (0.008)	Loss 0.2827 (0.2982)	Acc@1 96.875 (96.520)	Acc@5 100.000 (99.970)
Epoch: [113][128/196]	Time 0.902 (0.934)	Data 0.000 (0.004)	Loss 0.2612 (0.2979)	Acc@1 98.047 (96.530)	Acc@5 100.000 (99.970)
Epoch: [113][192/196]	Time 0.944 (0.897)	Data 0.000 (0.003)	Loss 0.2684 (0.3024)	Acc@1 96.875 (96.345)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [114 | 115] LR: 0.010000
Epoch: [114][0/196]	Time 1.010 (1.010)	Data 0.506 (0.506)	Loss 0.3241 (0.3241)	Acc@1 95.703 (95.703)	Acc@5 99.609 (99.609)
Epoch: [114][64/196]	Time 0.756 (0.897)	Data 0.000 (0.008)	Loss 0.2477 (0.2986)	Acc@1 98.828 (96.611)	Acc@5 100.000 (99.958)
Epoch: [114][128/196]	Time 0.938 (0.888)	Data 0.000 (0.004)	Loss 0.2788 (0.2996)	Acc@1 96.094 (96.551)	Acc@5 100.000 (99.967)
Epoch: [114][192/196]	Time 0.946 (0.905)	Data 0.000 (0.003)	Loss 0.3398 (0.3009)	Acc@1 93.359 (96.407)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [115 | 115] LR: 0.010000
Epoch: [115][0/196]	Time 0.969 (0.969)	Data 0.472 (0.472)	Loss 0.2819 (0.2819)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [115][64/196]	Time 0.941 (0.936)	Data 0.000 (0.007)	Loss 0.2942 (0.2904)	Acc@1 96.484 (96.635)	Acc@5 100.000 (99.964)
Epoch: [115][128/196]	Time 0.933 (0.938)	Data 0.000 (0.004)	Loss 0.3225 (0.2935)	Acc@1 94.922 (96.512)	Acc@5 100.000 (99.970)
Epoch: [115][192/196]	Time 0.942 (0.938)	Data 0.000 (0.003)	Loss 0.3029 (0.2965)	Acc@1 96.484 (96.361)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.6184192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368372
[INFO] Storing checkpoint...

  256
  90.42
Max memory: 90.416128
 184.403s  j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 116
Max memory: 0.1547264
1
lr: 0.010000000000000002

Epoch: [116 | 120] LR: 0.010000
Epoch: [116][0/196]	Time 1.711 (1.711)	Data 0.442 (0.442)	Loss 0.3220 (0.3220)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [116][64/196]	Time 0.936 (0.947)	Data 0.000 (0.007)	Loss 0.3194 (0.2837)	Acc@1 94.922 (96.875)	Acc@5 100.000 (99.976)
Epoch: [116][128/196]	Time 0.906 (0.936)	Data 0.000 (0.004)	Loss 0.2821 (0.2876)	Acc@1 97.266 (96.715)	Acc@5 100.000 (99.970)
Epoch: [116][192/196]	Time 0.947 (0.903)	Data 0.000 (0.002)	Loss 0.2823 (0.2912)	Acc@1 97.656 (96.592)	Acc@5 100.000 (99.972)
Max memory in training epoch: 71.6119552
count0: 368372
1
lr: 0.010000000000000002

Epoch: [117 | 120] LR: 0.010000
Epoch: [117][0/196]	Time 0.833 (0.833)	Data 0.397 (0.397)	Loss 0.3082 (0.3082)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [117][64/196]	Time 0.944 (0.943)	Data 0.000 (0.006)	Loss 0.2626 (0.2854)	Acc@1 98.047 (96.641)	Acc@5 100.000 (100.000)
Epoch: [117][128/196]	Time 0.941 (0.942)	Data 0.000 (0.003)	Loss 0.3176 (0.2845)	Acc@1 96.094 (96.705)	Acc@5 100.000 (99.991)
Epoch: [117][192/196]	Time 0.943 (0.941)	Data 0.000 (0.002)	Loss 0.3212 (0.2874)	Acc@1 94.531 (96.584)	Acc@5 100.000 (99.986)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [118 | 120] LR: 0.010000
Epoch: [118][0/196]	Time 0.894 (0.894)	Data 0.494 (0.494)	Loss 0.2864 (0.2864)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [118][64/196]	Time 0.942 (0.942)	Data 0.000 (0.008)	Loss 0.2914 (0.2870)	Acc@1 96.484 (96.526)	Acc@5 100.000 (99.976)
Epoch: [118][128/196]	Time 0.905 (0.934)	Data 0.000 (0.004)	Loss 0.2684 (0.2860)	Acc@1 96.875 (96.530)	Acc@5 100.000 (99.973)
Epoch: [118][192/196]	Time 0.744 (0.862)	Data 0.000 (0.003)	Loss 0.3183 (0.2918)	Acc@1 94.141 (96.385)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [119 | 120] LR: 0.010000
Epoch: [119][0/196]	Time 0.951 (0.951)	Data 0.432 (0.432)	Loss 0.2360 (0.2360)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [119][64/196]	Time 0.940 (0.945)	Data 0.000 (0.007)	Loss 0.2499 (0.2839)	Acc@1 97.656 (96.749)	Acc@5 100.000 (99.982)
Epoch: [119][128/196]	Time 0.943 (0.944)	Data 0.000 (0.004)	Loss 0.3361 (0.2881)	Acc@1 95.703 (96.590)	Acc@5 100.000 (99.967)
Epoch: [119][192/196]	Time 0.941 (0.944)	Data 0.000 (0.002)	Loss 0.3183 (0.2914)	Acc@1 95.312 (96.420)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [120 | 120] LR: 0.010000
Epoch: [120][0/196]	Time 1.059 (1.059)	Data 0.407 (0.407)	Loss 0.3045 (0.3045)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [120][64/196]	Time 0.943 (0.945)	Data 0.000 (0.006)	Loss 0.2915 (0.2843)	Acc@1 96.875 (96.538)	Acc@5 99.609 (99.958)
Epoch: [120][128/196]	Time 0.948 (0.944)	Data 0.000 (0.003)	Loss 0.2609 (0.2832)	Acc@1 98.047 (96.621)	Acc@5 100.000 (99.964)
Epoch: [120][192/196]	Time 0.937 (0.943)	Data 0.000 (0.002)	Loss 0.3145 (0.2874)	Acc@1 96.484 (96.476)	Acc@5 100.000 (99.955)
Max memory in training epoch: 58.6184192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368372
[INFO] Storing checkpoint...

  256
  90.41
Max memory: 90.416128
 185.264s  j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 121
Max memory: 0.1547264
1
lr: 0.010000000000000002

Epoch: [121 | 125] LR: 0.010000
Epoch: [121][0/196]	Time 1.728 (1.728)	Data 0.270 (0.270)	Loss 0.3071 (0.3071)	Acc@1 94.141 (94.141)	Acc@5 100.000 (100.000)
Epoch: [121][64/196]	Time 0.942 (0.956)	Data 0.000 (0.004)	Loss 0.2686 (0.2737)	Acc@1 96.484 (96.863)	Acc@5 100.000 (99.964)
Epoch: [121][128/196]	Time 0.941 (0.948)	Data 0.000 (0.002)	Loss 0.2657 (0.2786)	Acc@1 98.047 (96.666)	Acc@5 100.000 (99.979)
Epoch: [121][192/196]	Time 0.753 (0.932)	Data 0.000 (0.002)	Loss 0.2954 (0.2826)	Acc@1 97.266 (96.549)	Acc@5 99.609 (99.978)
Max memory in training epoch: 71.6119552
count0: 368372
1
lr: 0.010000000000000002

Epoch: [122 | 125] LR: 0.010000
Epoch: [122][0/196]	Time 0.780 (0.780)	Data 0.298 (0.298)	Loss 0.3530 (0.3530)	Acc@1 92.969 (92.969)	Acc@5 99.609 (99.609)
Epoch: [122][64/196]	Time 0.941 (0.897)	Data 0.000 (0.005)	Loss 0.2352 (0.2866)	Acc@1 98.438 (96.412)	Acc@5 100.000 (99.982)
Epoch: [122][128/196]	Time 0.948 (0.919)	Data 0.000 (0.002)	Loss 0.2518 (0.2858)	Acc@1 97.266 (96.451)	Acc@5 100.000 (99.979)
Epoch: [122][192/196]	Time 0.944 (0.926)	Data 0.000 (0.002)	Loss 0.3073 (0.2893)	Acc@1 94.922 (96.308)	Acc@5 100.000 (99.972)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [123 | 125] LR: 0.010000
Epoch: [123][0/196]	Time 0.965 (0.965)	Data 0.323 (0.323)	Loss 0.2468 (0.2468)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [123][64/196]	Time 0.903 (0.935)	Data 0.000 (0.005)	Loss 0.2934 (0.2905)	Acc@1 95.312 (96.172)	Acc@5 100.000 (99.952)
Epoch: [123][128/196]	Time 0.905 (0.880)	Data 0.000 (0.003)	Loss 0.2598 (0.2887)	Acc@1 98.047 (96.269)	Acc@5 100.000 (99.958)
Epoch: [123][192/196]	Time 0.947 (0.869)	Data 0.000 (0.002)	Loss 0.2784 (0.2892)	Acc@1 97.656 (96.254)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [124 | 125] LR: 0.010000
Epoch: [124][0/196]	Time 0.878 (0.878)	Data 0.307 (0.307)	Loss 0.2559 (0.2559)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [124][64/196]	Time 0.945 (0.941)	Data 0.000 (0.005)	Loss 0.2668 (0.2820)	Acc@1 96.484 (96.544)	Acc@5 100.000 (99.976)
Epoch: [124][128/196]	Time 0.944 (0.941)	Data 0.000 (0.003)	Loss 0.2630 (0.2819)	Acc@1 97.266 (96.527)	Acc@5 100.000 (99.979)
Epoch: [124][192/196]	Time 0.941 (0.942)	Data 0.000 (0.002)	Loss 0.2775 (0.2871)	Acc@1 96.875 (96.244)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [125 | 125] LR: 0.010000
Epoch: [125][0/196]	Time 0.860 (0.860)	Data 0.332 (0.332)	Loss 0.2760 (0.2760)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [125][64/196]	Time 0.941 (0.940)	Data 0.000 (0.005)	Loss 0.3106 (0.2773)	Acc@1 94.922 (96.659)	Acc@5 100.000 (99.958)
Epoch: [125][128/196]	Time 0.945 (0.941)	Data 0.000 (0.003)	Loss 0.2828 (0.2778)	Acc@1 96.484 (96.618)	Acc@5 100.000 (99.967)
Epoch: [125][192/196]	Time 0.941 (0.941)	Data 0.000 (0.002)	Loss 0.3282 (0.2828)	Acc@1 93.359 (96.347)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.6184192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368372
[INFO] Storing checkpoint...

  256
  89.64
Max memory: 90.416128
 184.822s  j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 126
Max memory: 0.1547264
1
lr: 0.010000000000000002

Epoch: [126 | 130] LR: 0.010000
Epoch: [126][0/196]	Time 2.008 (2.008)	Data 0.331 (0.331)	Loss 0.2706 (0.2706)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [126][64/196]	Time 0.941 (0.957)	Data 0.000 (0.005)	Loss 0.2363 (0.2826)	Acc@1 98.828 (96.274)	Acc@5 100.000 (99.982)
Epoch: [126][128/196]	Time 0.937 (0.949)	Data 0.000 (0.003)	Loss 0.2748 (0.2805)	Acc@1 97.266 (96.330)	Acc@5 100.000 (99.985)
Epoch: [126][192/196]	Time 0.906 (0.946)	Data 0.000 (0.002)	Loss 0.2974 (0.2832)	Acc@1 94.922 (96.284)	Acc@5 100.000 (99.984)
Max memory in training epoch: 71.6119552
count0: 368372
1
lr: 0.010000000000000002

Epoch: [127 | 130] LR: 0.010000
Epoch: [127][0/196]	Time 0.831 (0.831)	Data 0.293 (0.293)	Loss 0.2666 (0.2666)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [127][64/196]	Time 0.965 (0.833)	Data 0.000 (0.005)	Loss 0.2759 (0.2765)	Acc@1 97.266 (96.544)	Acc@5 100.000 (99.988)
Epoch: [127][128/196]	Time 0.942 (0.886)	Data 0.000 (0.002)	Loss 0.3295 (0.2827)	Acc@1 94.141 (96.351)	Acc@5 100.000 (99.985)
Epoch: [127][192/196]	Time 0.756 (0.881)	Data 0.000 (0.002)	Loss 0.2902 (0.2825)	Acc@1 96.094 (96.349)	Acc@5 100.000 (99.980)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [128 | 130] LR: 0.010000
Epoch: [128][0/196]	Time 0.682 (0.682)	Data 0.302 (0.302)	Loss 0.3037 (0.3037)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [128][64/196]	Time 0.933 (0.929)	Data 0.000 (0.005)	Loss 0.2648 (0.2771)	Acc@1 96.094 (96.508)	Acc@5 100.000 (99.976)
Epoch: [128][128/196]	Time 0.744 (0.905)	Data 0.000 (0.002)	Loss 0.2846 (0.2781)	Acc@1 96.875 (96.409)	Acc@5 100.000 (99.976)
Epoch: [128][192/196]	Time 1.000 (0.898)	Data 0.000 (0.002)	Loss 0.4135 (0.2852)	Acc@1 92.578 (96.124)	Acc@5 99.219 (99.970)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [129 | 130] LR: 0.010000
Epoch: [129][0/196]	Time 0.850 (0.850)	Data 0.353 (0.353)	Loss 0.3015 (0.3015)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [129][64/196]	Time 0.943 (0.939)	Data 0.000 (0.006)	Loss 0.2782 (0.2805)	Acc@1 96.484 (96.280)	Acc@5 100.000 (99.970)
Epoch: [129][128/196]	Time 0.944 (0.939)	Data 0.000 (0.003)	Loss 0.2821 (0.2855)	Acc@1 96.094 (96.121)	Acc@5 99.609 (99.970)
Epoch: [129][192/196]	Time 0.937 (0.940)	Data 0.000 (0.002)	Loss 0.3131 (0.2855)	Acc@1 94.531 (96.126)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [130 | 130] LR: 0.010000
Epoch: [130][0/196]	Time 0.874 (0.874)	Data 0.306 (0.306)	Loss 0.3451 (0.3451)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [130][64/196]	Time 0.936 (0.940)	Data 0.000 (0.005)	Loss 0.2888 (0.2790)	Acc@1 96.094 (96.575)	Acc@5 100.000 (99.988)
Epoch: [130][128/196]	Time 0.941 (0.940)	Data 0.000 (0.002)	Loss 0.3091 (0.2845)	Acc@1 94.922 (96.248)	Acc@5 100.000 (99.979)
Epoch: [130][192/196]	Time 0.940 (0.940)	Data 0.000 (0.002)	Loss 0.2760 (0.2876)	Acc@1 96.484 (96.100)	Acc@5 100.000 (99.974)
Max memory in training epoch: 58.6184192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368372
[INFO] Storing checkpoint...

  256
  89.12
Max memory: 90.416128
 184.588s  j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 131
Max memory: 0.1547264
1
lr: 0.010000000000000002

Epoch: [131 | 135] LR: 0.010000
Epoch: [131][0/196]	Time 1.957 (1.957)	Data 0.287 (0.287)	Loss 0.2338 (0.2338)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [131][64/196]	Time 0.989 (0.956)	Data 0.000 (0.005)	Loss 0.2637 (0.2670)	Acc@1 97.656 (96.767)	Acc@5 100.000 (99.976)
Epoch: [131][128/196]	Time 0.941 (0.948)	Data 0.000 (0.002)	Loss 0.2618 (0.2787)	Acc@1 96.875 (96.360)	Acc@5 100.000 (99.982)
Epoch: [131][192/196]	Time 0.940 (0.946)	Data 0.000 (0.002)	Loss 0.3443 (0.2823)	Acc@1 93.359 (96.237)	Acc@5 100.000 (99.976)
Max memory in training epoch: 71.6119552
count0: 368372
1
lr: 0.010000000000000002

Epoch: [132 | 135] LR: 0.010000
Epoch: [132][0/196]	Time 0.866 (0.866)	Data 0.281 (0.281)	Loss 0.2944 (0.2944)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [132][64/196]	Time 0.718 (0.889)	Data 0.000 (0.004)	Loss 0.3124 (0.2839)	Acc@1 96.094 (96.190)	Acc@5 100.000 (99.970)
Epoch: [132][128/196]	Time 0.946 (0.824)	Data 0.000 (0.002)	Loss 0.2538 (0.2855)	Acc@1 97.656 (96.091)	Acc@5 100.000 (99.979)
Epoch: [132][192/196]	Time 0.945 (0.865)	Data 0.000 (0.002)	Loss 0.3322 (0.2922)	Acc@1 93.750 (95.857)	Acc@5 100.000 (99.960)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [133 | 135] LR: 0.010000
Epoch: [133][0/196]	Time 0.844 (0.844)	Data 0.292 (0.292)	Loss 0.2636 (0.2636)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [133][64/196]	Time 0.907 (0.945)	Data 0.000 (0.005)	Loss 0.3103 (0.2816)	Acc@1 95.703 (96.244)	Acc@5 100.000 (99.982)
Epoch: [133][128/196]	Time 0.753 (0.901)	Data 0.000 (0.002)	Loss 0.2677 (0.2819)	Acc@1 97.656 (96.209)	Acc@5 100.000 (99.982)
Epoch: [133][192/196]	Time 0.951 (0.909)	Data 0.000 (0.002)	Loss 0.2921 (0.2845)	Acc@1 95.312 (96.090)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [134 | 135] LR: 0.010000
Epoch: [134][0/196]	Time 0.856 (0.856)	Data 0.374 (0.374)	Loss 0.3047 (0.3047)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [134][64/196]	Time 0.949 (0.946)	Data 0.000 (0.006)	Loss 0.2529 (0.2764)	Acc@1 96.875 (96.472)	Acc@5 100.000 (100.000)
Epoch: [134][128/196]	Time 0.951 (0.947)	Data 0.000 (0.003)	Loss 0.2639 (0.2827)	Acc@1 96.484 (96.151)	Acc@5 100.000 (99.979)
Epoch: [134][192/196]	Time 0.940 (0.947)	Data 0.000 (0.002)	Loss 0.3376 (0.2880)	Acc@1 94.531 (95.946)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.6184192
count0: 368372
1
lr: 0.010000000000000002

Epoch: [135 | 135] LR: 0.010000
Epoch: [135][0/196]	Time 0.898 (0.898)	Data 0.289 (0.289)	Loss 0.3326 (0.3326)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [135][64/196]	Time 0.942 (0.947)	Data 0.000 (0.005)	Loss 0.2507 (0.2853)	Acc@1 97.656 (95.925)	Acc@5 100.000 (99.988)
Epoch: [135][128/196]	Time 0.880 (0.948)	Data 0.000 (0.002)	Loss 0.2809 (0.2850)	Acc@1 96.094 (96.048)	Acc@5 100.000 (99.985)
Epoch: [135][192/196]	Time 0.950 (0.947)	Data 0.000 (0.002)	Loss 0.2664 (0.2853)	Acc@1 96.094 (96.021)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.6184192
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368372
[INFO] Storing checkpoint...

  256
  89.39
Max memory: 90.416128
 186.072s  j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 136
Max memory: 0.154624
1
lr: 0.010000000000000002

Epoch: [136 | 140] LR: 0.010000
Epoch: [136][0/196]	Time 2.126 (2.126)	Data 0.267 (0.267)	Loss 0.2761 (0.2761)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [136][64/196]	Time 0.940 (0.959)	Data 0.000 (0.004)	Loss 0.2729 (0.2732)	Acc@1 95.703 (96.454)	Acc@5 100.000 (99.964)
Epoch: [136][128/196]	Time 0.930 (0.949)	Data 0.000 (0.002)	Loss 0.2328 (0.2815)	Acc@1 98.047 (96.227)	Acc@5 100.000 (99.964)
Epoch: [136][192/196]	Time 0.935 (0.946)	Data 0.000 (0.002)	Loss 0.2578 (0.2828)	Acc@1 97.266 (96.163)	Acc@5 100.000 (99.962)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.010000000000000002

Epoch: [137 | 140] LR: 0.010000
Epoch: [137][0/196]	Time 0.877 (0.877)	Data 0.296 (0.296)	Loss 0.2910 (0.2910)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [137][64/196]	Time 0.902 (0.939)	Data 0.000 (0.005)	Loss 0.2368 (0.2797)	Acc@1 98.828 (96.244)	Acc@5 100.000 (99.970)
Epoch: [137][128/196]	Time 0.560 (0.888)	Data 0.000 (0.002)	Loss 0.2572 (0.2796)	Acc@1 96.875 (96.236)	Acc@5 100.000 (99.973)
Epoch: [137][192/196]	Time 0.934 (0.836)	Data 0.000 (0.002)	Loss 0.2877 (0.2841)	Acc@1 95.312 (96.067)	Acc@5 100.000 (99.976)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [138 | 140] LR: 0.010000
Epoch: [138][0/196]	Time 0.909 (0.909)	Data 0.307 (0.307)	Loss 0.2542 (0.2542)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [138][64/196]	Time 0.901 (0.929)	Data 0.000 (0.005)	Loss 0.2791 (0.2703)	Acc@1 95.312 (96.490)	Acc@5 100.000 (99.994)
Epoch: [138][128/196]	Time 1.073 (0.879)	Data 0.000 (0.003)	Loss 0.3070 (0.2812)	Acc@1 94.922 (96.227)	Acc@5 100.000 (99.979)
Epoch: [138][192/196]	Time 0.933 (0.898)	Data 0.000 (0.002)	Loss 0.2989 (0.2832)	Acc@1 92.969 (96.112)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [139 | 140] LR: 0.010000
Epoch: [139][0/196]	Time 0.973 (0.973)	Data 0.305 (0.305)	Loss 0.2784 (0.2784)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [139][64/196]	Time 0.937 (0.937)	Data 0.000 (0.005)	Loss 0.2996 (0.2844)	Acc@1 95.312 (95.871)	Acc@5 100.000 (99.946)
Epoch: [139][128/196]	Time 0.894 (0.938)	Data 0.000 (0.002)	Loss 0.2935 (0.2871)	Acc@1 96.094 (95.794)	Acc@5 100.000 (99.936)
Epoch: [139][192/196]	Time 1.008 (0.938)	Data 0.000 (0.002)	Loss 0.3157 (0.2868)	Acc@1 94.531 (95.839)	Acc@5 99.609 (99.943)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [140 | 140] LR: 0.010000
Epoch: [140][0/196]	Time 1.028 (1.028)	Data 0.352 (0.352)	Loss 0.2387 (0.2387)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [140][64/196]	Time 0.941 (0.938)	Data 0.000 (0.006)	Loss 0.2741 (0.2847)	Acc@1 97.266 (96.208)	Acc@5 100.000 (99.958)
Epoch: [140][128/196]	Time 0.836 (0.938)	Data 0.000 (0.003)	Loss 0.2799 (0.2863)	Acc@1 96.094 (96.127)	Acc@5 100.000 (99.970)
Epoch: [140][192/196]	Time 0.939 (0.938)	Data 0.000 (0.002)	Loss 0.2666 (0.2884)	Acc@1 96.484 (96.025)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  89.04
Max memory: 89.8305024
 184.246s  j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 141
Max memory: 0.154624
1
lr: 0.010000000000000002

Epoch: [141 | 145] LR: 0.010000
Epoch: [141][0/196]	Time 1.928 (1.928)	Data 0.291 (0.291)	Loss 0.2612 (0.2612)	Acc@1 97.266 (97.266)	Acc@5 100.000 (100.000)
Epoch: [141][64/196]	Time 0.936 (0.956)	Data 0.000 (0.005)	Loss 0.2682 (0.2637)	Acc@1 96.484 (96.785)	Acc@5 100.000 (99.964)
Epoch: [141][128/196]	Time 0.948 (0.946)	Data 0.000 (0.002)	Loss 0.2991 (0.2750)	Acc@1 94.922 (96.412)	Acc@5 100.000 (99.970)
Epoch: [141][192/196]	Time 0.934 (0.943)	Data 0.000 (0.002)	Loss 0.3125 (0.2769)	Acc@1 93.750 (96.318)	Acc@5 100.000 (99.976)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.010000000000000002

Epoch: [142 | 145] LR: 0.010000
Epoch: [142][0/196]	Time 1.033 (1.033)	Data 0.333 (0.333)	Loss 0.2842 (0.2842)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [142][64/196]	Time 0.935 (0.938)	Data 0.000 (0.005)	Loss 0.2380 (0.2829)	Acc@1 97.656 (96.166)	Acc@5 100.000 (99.970)
Epoch: [142][128/196]	Time 0.937 (0.938)	Data 0.000 (0.003)	Loss 0.2476 (0.2805)	Acc@1 98.047 (96.251)	Acc@5 100.000 (99.958)
Epoch: [142][192/196]	Time 0.712 (0.907)	Data 0.000 (0.002)	Loss 0.3146 (0.2846)	Acc@1 94.922 (96.053)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [143 | 145] LR: 0.010000
Epoch: [143][0/196]	Time 0.428 (0.428)	Data 0.284 (0.284)	Loss 0.3141 (0.3141)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [143][64/196]	Time 0.906 (0.776)	Data 0.000 (0.005)	Loss 0.2603 (0.2847)	Acc@1 96.875 (96.094)	Acc@5 100.000 (99.982)
Epoch: [143][128/196]	Time 0.940 (0.808)	Data 0.000 (0.002)	Loss 0.3267 (0.2833)	Acc@1 96.094 (96.057)	Acc@5 99.609 (99.973)
Epoch: [143][192/196]	Time 0.943 (0.851)	Data 0.000 (0.002)	Loss 0.2938 (0.2863)	Acc@1 96.094 (95.901)	Acc@5 100.000 (99.966)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [144 | 145] LR: 0.010000
Epoch: [144][0/196]	Time 1.009 (1.009)	Data 0.332 (0.332)	Loss 0.2430 (0.2430)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [144][64/196]	Time 0.942 (0.941)	Data 0.000 (0.005)	Loss 0.2528 (0.2860)	Acc@1 97.266 (95.901)	Acc@5 100.000 (99.976)
Epoch: [144][128/196]	Time 0.940 (0.941)	Data 0.000 (0.003)	Loss 0.2621 (0.2856)	Acc@1 96.094 (95.903)	Acc@5 100.000 (99.967)
Epoch: [144][192/196]	Time 0.942 (0.941)	Data 0.000 (0.002)	Loss 0.2764 (0.2893)	Acc@1 96.484 (95.727)	Acc@5 100.000 (99.968)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [145 | 145] LR: 0.010000
Epoch: [145][0/196]	Time 1.031 (1.031)	Data 0.373 (0.373)	Loss 0.3209 (0.3209)	Acc@1 94.922 (94.922)	Acc@5 100.000 (100.000)
Epoch: [145][64/196]	Time 0.943 (0.941)	Data 0.000 (0.006)	Loss 0.2571 (0.2765)	Acc@1 96.875 (96.172)	Acc@5 100.000 (99.964)
Epoch: [145][128/196]	Time 0.941 (0.940)	Data 0.000 (0.003)	Loss 0.3369 (0.2810)	Acc@1 94.141 (96.051)	Acc@5 99.609 (99.967)
Epoch: [145][192/196]	Time 0.942 (0.940)	Data 0.000 (0.002)	Loss 0.3153 (0.2854)	Acc@1 93.750 (95.930)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  89.17
Max memory: 89.8305024
 184.667s  j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 146
Max memory: 0.154624
1
lr: 0.010000000000000002

Epoch: [146 | 150] LR: 0.010000
Epoch: [146][0/196]	Time 1.924 (1.924)	Data 0.308 (0.308)	Loss 0.2440 (0.2440)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [146][64/196]	Time 0.941 (0.955)	Data 0.000 (0.005)	Loss 0.2555 (0.2579)	Acc@1 97.266 (96.923)	Acc@5 100.000 (99.988)
Epoch: [146][128/196]	Time 0.929 (0.947)	Data 0.000 (0.003)	Loss 0.3267 (0.2678)	Acc@1 94.531 (96.487)	Acc@5 100.000 (99.982)
Epoch: [146][192/196]	Time 0.872 (0.945)	Data 0.000 (0.002)	Loss 0.3137 (0.2745)	Acc@1 95.312 (96.227)	Acc@5 100.000 (99.976)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.010000000000000002

Epoch: [147 | 150] LR: 0.010000
Epoch: [147][0/196]	Time 1.025 (1.025)	Data 0.343 (0.343)	Loss 0.2654 (0.2654)	Acc@1 96.484 (96.484)	Acc@5 100.000 (100.000)
Epoch: [147][64/196]	Time 0.944 (0.939)	Data 0.000 (0.005)	Loss 0.2596 (0.2759)	Acc@1 95.703 (96.244)	Acc@5 100.000 (99.982)
Epoch: [147][128/196]	Time 0.938 (0.939)	Data 0.000 (0.003)	Loss 0.3131 (0.2814)	Acc@1 94.531 (96.079)	Acc@5 99.609 (99.976)
Epoch: [147][192/196]	Time 0.909 (0.939)	Data 0.000 (0.002)	Loss 0.3037 (0.2845)	Acc@1 95.312 (95.993)	Acc@5 100.000 (99.978)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [148 | 150] LR: 0.010000
Epoch: [148][0/196]	Time 1.028 (1.028)	Data 0.392 (0.392)	Loss 0.2591 (0.2591)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [148][64/196]	Time 0.564 (0.756)	Data 0.000 (0.006)	Loss 0.2503 (0.2763)	Acc@1 96.875 (96.370)	Acc@5 100.000 (99.976)
Epoch: [148][128/196]	Time 0.936 (0.713)	Data 0.000 (0.003)	Loss 0.2744 (0.2803)	Acc@1 96.484 (96.251)	Acc@5 99.609 (99.973)
Epoch: [148][192/196]	Time 0.939 (0.787)	Data 0.000 (0.002)	Loss 0.2848 (0.2829)	Acc@1 95.312 (96.132)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.010000000000000002

Epoch: [149 | 150] LR: 0.010000
Epoch: [149][0/196]	Time 1.033 (1.033)	Data 0.330 (0.330)	Loss 0.2901 (0.2901)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [149][64/196]	Time 0.929 (0.936)	Data 0.000 (0.005)	Loss 0.2646 (0.2773)	Acc@1 96.094 (96.154)	Acc@5 100.000 (99.976)
Epoch: [149][128/196]	Time 0.934 (0.939)	Data 0.000 (0.003)	Loss 0.2698 (0.2796)	Acc@1 96.484 (96.169)	Acc@5 100.000 (99.964)
Epoch: [149][192/196]	Time 0.934 (0.938)	Data 0.000 (0.002)	Loss 0.3296 (0.2846)	Acc@1 95.312 (96.007)	Acc@5 100.000 (99.970)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [150 | 150] LR: 0.001000
Epoch: [150][0/196]	Time 1.040 (1.040)	Data 0.293 (0.293)	Loss 0.2884 (0.2884)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [150][64/196]	Time 0.940 (0.938)	Data 0.000 (0.005)	Loss 0.2328 (0.2537)	Acc@1 98.438 (97.206)	Acc@5 100.000 (99.982)
Epoch: [150][128/196]	Time 0.848 (0.937)	Data 0.000 (0.002)	Loss 0.2223 (0.2459)	Acc@1 98.828 (97.456)	Acc@5 100.000 (99.985)
Epoch: [150][192/196]	Time 0.934 (0.937)	Data 0.000 (0.002)	Loss 0.2228 (0.2402)	Acc@1 98.438 (97.662)	Acc@5 100.000 (99.988)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.12
Max memory: 89.8305024
 184.074s  j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 151
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [151 | 155] LR: 0.001000
Epoch: [151][0/196]	Time 1.888 (1.888)	Data 0.313 (0.313)	Loss 0.2187 (0.2187)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [151][64/196]	Time 0.937 (0.955)	Data 0.000 (0.005)	Loss 0.1972 (0.2266)	Acc@1 100.000 (98.161)	Acc@5 100.000 (99.988)
Epoch: [151][128/196]	Time 0.939 (0.947)	Data 0.000 (0.003)	Loss 0.2463 (0.2283)	Acc@1 97.656 (98.138)	Acc@5 100.000 (99.988)
Epoch: [151][192/196]	Time 0.942 (0.945)	Data 0.000 (0.002)	Loss 0.2076 (0.2257)	Acc@1 98.438 (98.247)	Acc@5 100.000 (99.990)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [152 | 155] LR: 0.001000
Epoch: [152][0/196]	Time 1.045 (1.045)	Data 0.338 (0.338)	Loss 0.2258 (0.2258)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [152][64/196]	Time 1.027 (0.941)	Data 0.000 (0.005)	Loss 0.2539 (0.2144)	Acc@1 97.656 (98.738)	Acc@5 100.000 (99.988)
Epoch: [152][128/196]	Time 0.938 (0.940)	Data 0.000 (0.003)	Loss 0.1953 (0.2140)	Acc@1 99.219 (98.680)	Acc@5 100.000 (99.991)
Epoch: [152][192/196]	Time 0.943 (0.940)	Data 0.000 (0.002)	Loss 0.2395 (0.2142)	Acc@1 97.266 (98.676)	Acc@5 100.000 (99.992)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [153 | 155] LR: 0.001000
Epoch: [153][0/196]	Time 1.040 (1.040)	Data 0.322 (0.322)	Loss 0.2122 (0.2122)	Acc@1 98.047 (98.047)	Acc@5 100.000 (100.000)
Epoch: [153][64/196]	Time 0.853 (0.907)	Data 0.000 (0.005)	Loss 0.2148 (0.2109)	Acc@1 98.438 (98.768)	Acc@5 100.000 (99.994)
Epoch: [153][128/196]	Time 0.897 (0.792)	Data 0.000 (0.003)	Loss 0.1887 (0.2105)	Acc@1 100.000 (98.740)	Acc@5 100.000 (99.991)
Epoch: [153][192/196]	Time 0.934 (0.808)	Data 0.000 (0.002)	Loss 0.2086 (0.2106)	Acc@1 98.438 (98.723)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [154 | 155] LR: 0.001000
Epoch: [154][0/196]	Time 1.023 (1.023)	Data 0.373 (0.373)	Loss 0.1945 (0.1945)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [154][64/196]	Time 0.943 (0.939)	Data 0.000 (0.006)	Loss 0.2027 (0.2057)	Acc@1 98.828 (98.948)	Acc@5 100.000 (99.982)
Epoch: [154][128/196]	Time 0.936 (0.940)	Data 0.000 (0.003)	Loss 0.2197 (0.2063)	Acc@1 98.438 (98.907)	Acc@5 100.000 (99.985)
Epoch: [154][192/196]	Time 0.937 (0.940)	Data 0.000 (0.002)	Loss 0.2139 (0.2072)	Acc@1 98.438 (98.867)	Acc@5 100.000 (99.990)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [155 | 155] LR: 0.001000
Epoch: [155][0/196]	Time 1.034 (1.034)	Data 0.332 (0.332)	Loss 0.2153 (0.2153)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [155][64/196]	Time 0.944 (0.940)	Data 0.000 (0.005)	Loss 0.2084 (0.2029)	Acc@1 99.219 (98.948)	Acc@5 100.000 (100.000)
Epoch: [155][128/196]	Time 0.939 (0.940)	Data 0.000 (0.003)	Loss 0.2037 (0.2032)	Acc@1 98.438 (98.973)	Acc@5 100.000 (99.997)
Epoch: [155][192/196]	Time 0.939 (0.940)	Data 0.000 (0.002)	Loss 0.1984 (0.2034)	Acc@1 99.219 (98.968)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.61
Max memory: 89.8305024
 184.601s  j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 156
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [156 | 160] LR: 0.001000
Epoch: [156][0/196]	Time 1.893 (1.893)	Data 0.309 (0.309)	Loss 0.2040 (0.2040)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [156][64/196]	Time 0.934 (0.954)	Data 0.000 (0.005)	Loss 0.1932 (0.2013)	Acc@1 99.219 (99.069)	Acc@5 100.000 (99.994)
Epoch: [156][128/196]	Time 0.935 (0.946)	Data 0.000 (0.003)	Loss 0.1934 (0.2016)	Acc@1 99.219 (99.076)	Acc@5 100.000 (99.994)
Epoch: [156][192/196]	Time 0.931 (0.944)	Data 0.000 (0.002)	Loss 0.2046 (0.2007)	Acc@1 99.219 (99.091)	Acc@5 100.000 (99.996)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [157 | 160] LR: 0.001000
Epoch: [157][0/196]	Time 0.989 (0.989)	Data 0.335 (0.335)	Loss 0.2036 (0.2036)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [157][64/196]	Time 0.942 (0.937)	Data 0.000 (0.005)	Loss 0.1895 (0.1981)	Acc@1 99.609 (99.201)	Acc@5 100.000 (100.000)
Epoch: [157][128/196]	Time 0.939 (0.937)	Data 0.000 (0.003)	Loss 0.2039 (0.1992)	Acc@1 98.828 (99.140)	Acc@5 100.000 (99.997)
Epoch: [157][192/196]	Time 0.940 (0.938)	Data 0.000 (0.002)	Loss 0.1905 (0.1988)	Acc@1 99.609 (99.136)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [158 | 160] LR: 0.001000
Epoch: [158][0/196]	Time 0.955 (0.955)	Data 0.334 (0.334)	Loss 0.1880 (0.1880)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [158][64/196]	Time 0.761 (0.899)	Data 0.000 (0.005)	Loss 0.1985 (0.1963)	Acc@1 98.828 (99.261)	Acc@5 100.000 (100.000)
Epoch: [158][128/196]	Time 0.902 (0.872)	Data 0.000 (0.003)	Loss 0.2006 (0.1973)	Acc@1 99.219 (99.182)	Acc@5 100.000 (100.000)
Epoch: [158][192/196]	Time 0.747 (0.849)	Data 0.000 (0.002)	Loss 0.1923 (0.1972)	Acc@1 99.609 (99.160)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [159 | 160] LR: 0.001000
Epoch: [159][0/196]	Time 0.686 (0.686)	Data 0.291 (0.291)	Loss 0.1940 (0.1940)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [159][64/196]	Time 0.944 (0.869)	Data 0.000 (0.005)	Loss 0.2245 (0.1967)	Acc@1 98.828 (99.165)	Acc@5 100.000 (100.000)
Epoch: [159][128/196]	Time 0.935 (0.904)	Data 0.000 (0.002)	Loss 0.1880 (0.1950)	Acc@1 100.000 (99.264)	Acc@5 100.000 (99.997)
Epoch: [159][192/196]	Time 0.940 (0.916)	Data 0.000 (0.002)	Loss 0.1898 (0.1949)	Acc@1 100.000 (99.259)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [160 | 160] LR: 0.001000
Epoch: [160][0/196]	Time 0.872 (0.872)	Data 0.333 (0.333)	Loss 0.1793 (0.1793)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [160][64/196]	Time 0.932 (0.940)	Data 0.000 (0.005)	Loss 0.1944 (0.1933)	Acc@1 98.438 (99.321)	Acc@5 100.000 (100.000)
Epoch: [160][128/196]	Time 0.943 (0.940)	Data 0.000 (0.003)	Loss 0.1915 (0.1943)	Acc@1 99.219 (99.249)	Acc@5 100.000 (100.000)
Epoch: [160][192/196]	Time 0.868 (0.939)	Data 0.000 (0.002)	Loss 0.2010 (0.1940)	Acc@1 98.828 (99.267)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.62
Max memory: 89.8305024
 184.573s  j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 161
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [161 | 165] LR: 0.001000
Epoch: [161][0/196]	Time 2.274 (2.274)	Data 0.328 (0.328)	Loss 0.1845 (0.1845)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [161][64/196]	Time 0.941 (0.960)	Data 0.000 (0.005)	Loss 0.1880 (0.1908)	Acc@1 99.219 (99.345)	Acc@5 100.000 (100.000)
Epoch: [161][128/196]	Time 0.941 (0.950)	Data 0.000 (0.003)	Loss 0.1784 (0.1927)	Acc@1 100.000 (99.282)	Acc@5 100.000 (99.994)
Epoch: [161][192/196]	Time 0.941 (0.947)	Data 0.000 (0.002)	Loss 0.2037 (0.1924)	Acc@1 98.047 (99.300)	Acc@5 100.000 (99.996)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [162 | 165] LR: 0.001000
Epoch: [162][0/196]	Time 0.723 (0.723)	Data 0.293 (0.293)	Loss 0.1755 (0.1755)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [162][64/196]	Time 0.945 (0.936)	Data 0.000 (0.005)	Loss 0.2005 (0.1924)	Acc@1 99.219 (99.261)	Acc@5 100.000 (99.988)
Epoch: [162][128/196]	Time 0.841 (0.938)	Data 0.000 (0.002)	Loss 0.2093 (0.1917)	Acc@1 98.438 (99.301)	Acc@5 100.000 (99.994)
Epoch: [162][192/196]	Time 0.944 (0.939)	Data 0.000 (0.002)	Loss 0.1918 (0.1918)	Acc@1 99.219 (99.288)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [163 | 165] LR: 0.001000
Epoch: [163][0/196]	Time 0.878 (0.878)	Data 0.321 (0.321)	Loss 0.1989 (0.1989)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [163][64/196]	Time 0.744 (0.857)	Data 0.000 (0.005)	Loss 0.2089 (0.1927)	Acc@1 98.438 (99.165)	Acc@5 100.000 (99.988)
Epoch: [163][128/196]	Time 0.942 (0.881)	Data 0.000 (0.003)	Loss 0.1857 (0.1903)	Acc@1 99.609 (99.285)	Acc@5 100.000 (99.994)
Epoch: [163][192/196]	Time 0.840 (0.881)	Data 0.000 (0.002)	Loss 0.1870 (0.1901)	Acc@1 99.609 (99.320)	Acc@5 100.000 (99.994)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [164 | 165] LR: 0.001000
Epoch: [164][0/196]	Time 0.682 (0.682)	Data 0.292 (0.292)	Loss 0.1919 (0.1919)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [164][64/196]	Time 0.749 (0.823)	Data 0.000 (0.005)	Loss 0.1822 (0.1900)	Acc@1 100.000 (99.279)	Acc@5 100.000 (99.994)
Epoch: [164][128/196]	Time 0.948 (0.860)	Data 0.000 (0.002)	Loss 0.1798 (0.1880)	Acc@1 100.000 (99.355)	Acc@5 100.000 (99.997)
Epoch: [164][192/196]	Time 0.943 (0.886)	Data 0.000 (0.002)	Loss 0.1890 (0.1881)	Acc@1 99.609 (99.371)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [165 | 165] LR: 0.001000
Epoch: [165][0/196]	Time 1.036 (1.036)	Data 0.349 (0.349)	Loss 0.1971 (0.1971)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [165][64/196]	Time 0.940 (0.941)	Data 0.000 (0.006)	Loss 0.1887 (0.1875)	Acc@1 99.219 (99.417)	Acc@5 100.000 (100.000)
Epoch: [165][128/196]	Time 0.937 (0.941)	Data 0.000 (0.003)	Loss 0.2062 (0.1878)	Acc@1 99.219 (99.406)	Acc@5 100.000 (100.000)
Epoch: [165][192/196]	Time 0.936 (0.941)	Data 0.000 (0.002)	Loss 0.1808 (0.1869)	Acc@1 99.219 (99.429)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.76
Max memory: 89.8305024
 184.856s  j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 166
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [166 | 170] LR: 0.001000
Epoch: [166][0/196]	Time 2.092 (2.092)	Data 0.290 (0.290)	Loss 0.2069 (0.2069)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [166][64/196]	Time 0.943 (0.958)	Data 0.000 (0.005)	Loss 0.2102 (0.1864)	Acc@1 98.047 (99.417)	Acc@5 100.000 (99.994)
Epoch: [166][128/196]	Time 0.944 (0.948)	Data 0.000 (0.002)	Loss 0.1865 (0.1865)	Acc@1 99.609 (99.434)	Acc@5 100.000 (99.997)
Epoch: [166][192/196]	Time 0.933 (0.946)	Data 0.000 (0.002)	Loss 0.1791 (0.1862)	Acc@1 100.000 (99.454)	Acc@5 100.000 (99.996)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [167 | 170] LR: 0.001000
Epoch: [167][0/196]	Time 0.957 (0.957)	Data 0.320 (0.320)	Loss 0.1908 (0.1908)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [167][64/196]	Time 0.933 (0.940)	Data 0.000 (0.005)	Loss 0.1769 (0.1862)	Acc@1 100.000 (99.351)	Acc@5 100.000 (100.000)
Epoch: [167][128/196]	Time 0.937 (0.940)	Data 0.000 (0.003)	Loss 0.1969 (0.1855)	Acc@1 98.047 (99.422)	Acc@5 100.000 (100.000)
Epoch: [167][192/196]	Time 0.935 (0.940)	Data 0.000 (0.002)	Loss 0.1733 (0.1851)	Acc@1 100.000 (99.425)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [168 | 170] LR: 0.001000
Epoch: [168][0/196]	Time 0.925 (0.925)	Data 0.316 (0.316)	Loss 0.1930 (0.1930)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [168][64/196]	Time 0.754 (0.853)	Data 0.000 (0.005)	Loss 0.1885 (0.1845)	Acc@1 99.219 (99.429)	Acc@5 100.000 (99.988)
Epoch: [168][128/196]	Time 0.936 (0.882)	Data 0.000 (0.003)	Loss 0.1768 (0.1841)	Acc@1 99.609 (99.464)	Acc@5 100.000 (99.994)
Epoch: [168][192/196]	Time 0.702 (0.900)	Data 0.000 (0.002)	Loss 0.1771 (0.1840)	Acc@1 100.000 (99.468)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [169 | 170] LR: 0.001000
Epoch: [169][0/196]	Time 0.935 (0.935)	Data 0.354 (0.354)	Loss 0.1812 (0.1812)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [169][64/196]	Time 0.722 (0.836)	Data 0.000 (0.006)	Loss 0.1790 (0.1841)	Acc@1 99.609 (99.465)	Acc@5 100.000 (100.000)
Epoch: [169][128/196]	Time 0.746 (0.848)	Data 0.000 (0.003)	Loss 0.1937 (0.1838)	Acc@1 99.219 (99.443)	Acc@5 100.000 (100.000)
Epoch: [169][192/196]	Time 0.939 (0.860)	Data 0.000 (0.002)	Loss 0.1802 (0.1836)	Acc@1 99.609 (99.464)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [170 | 170] LR: 0.001000
Epoch: [170][0/196]	Time 0.958 (0.958)	Data 0.312 (0.312)	Loss 0.1875 (0.1875)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [170][64/196]	Time 0.940 (0.939)	Data 0.000 (0.005)	Loss 0.1812 (0.1818)	Acc@1 99.219 (99.549)	Acc@5 100.000 (100.000)
Epoch: [170][128/196]	Time 0.940 (0.938)	Data 0.000 (0.003)	Loss 0.1747 (0.1822)	Acc@1 100.000 (99.525)	Acc@5 100.000 (99.997)
Epoch: [170][192/196]	Time 0.941 (0.938)	Data 0.000 (0.002)	Loss 0.1708 (0.1825)	Acc@1 100.000 (99.490)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.73
Max memory: 89.8305024
 184.275s  j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 171
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [171 | 175] LR: 0.001000
Epoch: [171][0/196]	Time 1.733 (1.733)	Data 0.308 (0.308)	Loss 0.1803 (0.1803)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [171][64/196]	Time 0.938 (0.861)	Data 0.000 (0.005)	Loss 0.1888 (0.1819)	Acc@1 99.609 (99.477)	Acc@5 100.000 (100.000)
Epoch: [171][128/196]	Time 0.934 (0.899)	Data 0.000 (0.003)	Loss 0.2016 (0.1827)	Acc@1 98.438 (99.452)	Acc@5 100.000 (100.000)
Epoch: [171][192/196]	Time 0.909 (0.912)	Data 0.000 (0.002)	Loss 0.1827 (0.1820)	Acc@1 99.609 (99.490)	Acc@5 100.000 (100.000)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [172 | 175] LR: 0.001000
Epoch: [172][0/196]	Time 0.965 (0.965)	Data 0.374 (0.374)	Loss 0.1737 (0.1737)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][64/196]	Time 0.944 (0.939)	Data 0.000 (0.006)	Loss 0.1819 (0.1812)	Acc@1 99.609 (99.507)	Acc@5 100.000 (100.000)
Epoch: [172][128/196]	Time 0.938 (0.938)	Data 0.000 (0.003)	Loss 0.1802 (0.1802)	Acc@1 99.609 (99.555)	Acc@5 100.000 (100.000)
Epoch: [172][192/196]	Time 0.999 (0.938)	Data 0.000 (0.002)	Loss 0.1895 (0.1801)	Acc@1 99.609 (99.553)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [173 | 175] LR: 0.001000
Epoch: [173][0/196]	Time 0.939 (0.939)	Data 0.306 (0.306)	Loss 0.1759 (0.1759)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][64/196]	Time 0.755 (0.842)	Data 0.000 (0.005)	Loss 0.1835 (0.1807)	Acc@1 99.219 (99.507)	Acc@5 100.000 (100.000)
Epoch: [173][128/196]	Time 0.937 (0.881)	Data 0.000 (0.003)	Loss 0.1775 (0.1803)	Acc@1 100.000 (99.534)	Acc@5 100.000 (99.997)
Epoch: [173][192/196]	Time 0.938 (0.900)	Data 0.000 (0.002)	Loss 0.1856 (0.1800)	Acc@1 99.219 (99.537)	Acc@5 100.000 (99.996)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [174 | 175] LR: 0.001000
Epoch: [174][0/196]	Time 0.964 (0.964)	Data 0.332 (0.332)	Loss 0.1753 (0.1753)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [174][64/196]	Time 0.860 (0.931)	Data 0.000 (0.005)	Loss 0.1689 (0.1784)	Acc@1 100.000 (99.603)	Acc@5 100.000 (100.000)
Epoch: [174][128/196]	Time 1.025 (0.884)	Data 0.000 (0.003)	Loss 0.1939 (0.1791)	Acc@1 98.438 (99.552)	Acc@5 100.000 (99.997)
Epoch: [174][192/196]	Time 0.750 (0.882)	Data 0.000 (0.002)	Loss 0.1751 (0.1785)	Acc@1 99.609 (99.571)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [175 | 175] LR: 0.001000
Epoch: [175][0/196]	Time 0.775 (0.775)	Data 0.317 (0.317)	Loss 0.1858 (0.1858)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [175][64/196]	Time 0.942 (0.902)	Data 0.000 (0.005)	Loss 0.1694 (0.1777)	Acc@1 100.000 (99.579)	Acc@5 100.000 (100.000)
Epoch: [175][128/196]	Time 0.935 (0.920)	Data 0.000 (0.003)	Loss 0.1936 (0.1788)	Acc@1 99.609 (99.528)	Acc@5 100.000 (100.000)
Epoch: [175][192/196]	Time 0.944 (0.926)	Data 0.000 (0.002)	Loss 0.1766 (0.1779)	Acc@1 100.000 (99.569)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.67
Max memory: 89.8305024
 182.035s  j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 176
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [176 | 180] LR: 0.001000
Epoch: [176][0/196]	Time 2.061 (2.061)	Data 0.298 (0.298)	Loss 0.1749 (0.1749)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [176][64/196]	Time 0.900 (0.927)	Data 0.000 (0.005)	Loss 0.1802 (0.1761)	Acc@1 99.219 (99.597)	Acc@5 100.000 (100.000)
Epoch: [176][128/196]	Time 0.938 (0.883)	Data 0.000 (0.002)	Loss 0.1769 (0.1765)	Acc@1 100.000 (99.606)	Acc@5 100.000 (100.000)
Epoch: [176][192/196]	Time 0.928 (0.902)	Data 0.000 (0.002)	Loss 0.1718 (0.1760)	Acc@1 100.000 (99.619)	Acc@5 100.000 (100.000)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [177 | 180] LR: 0.001000
Epoch: [177][0/196]	Time 0.964 (0.964)	Data 0.325 (0.325)	Loss 0.1922 (0.1922)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][64/196]	Time 0.936 (0.939)	Data 0.000 (0.005)	Loss 0.1824 (0.1777)	Acc@1 99.609 (99.573)	Acc@5 100.000 (100.000)
Epoch: [177][128/196]	Time 0.945 (0.940)	Data 0.000 (0.003)	Loss 0.1830 (0.1775)	Acc@1 99.219 (99.531)	Acc@5 100.000 (100.000)
Epoch: [177][192/196]	Time 1.011 (0.939)	Data 0.000 (0.002)	Loss 0.1873 (0.1772)	Acc@1 98.828 (99.555)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [178 | 180] LR: 0.001000
Epoch: [178][0/196]	Time 0.930 (0.930)	Data 0.268 (0.268)	Loss 0.1818 (0.1818)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [178][64/196]	Time 0.750 (0.845)	Data 0.000 (0.004)	Loss 0.1818 (0.1763)	Acc@1 99.219 (99.591)	Acc@5 100.000 (100.000)
Epoch: [178][128/196]	Time 0.945 (0.883)	Data 0.000 (0.002)	Loss 0.1818 (0.1763)	Acc@1 99.609 (99.588)	Acc@5 100.000 (100.000)
Epoch: [178][192/196]	Time 0.942 (0.901)	Data 0.000 (0.002)	Loss 0.1794 (0.1762)	Acc@1 99.219 (99.595)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [179 | 180] LR: 0.001000
Epoch: [179][0/196]	Time 0.950 (0.950)	Data 0.314 (0.314)	Loss 0.1747 (0.1747)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [179][64/196]	Time 0.939 (0.939)	Data 0.000 (0.005)	Loss 0.1691 (0.1745)	Acc@1 100.000 (99.651)	Acc@5 100.000 (100.000)
Epoch: [179][128/196]	Time 0.902 (0.934)	Data 0.000 (0.003)	Loss 0.1805 (0.1746)	Acc@1 99.609 (99.652)	Acc@5 100.000 (100.000)
Epoch: [179][192/196]	Time 0.888 (0.903)	Data 0.000 (0.002)	Loss 0.1728 (0.1745)	Acc@1 100.000 (99.650)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [180 | 180] LR: 0.001000
Epoch: [180][0/196]	Time 0.926 (0.926)	Data 0.314 (0.314)	Loss 0.1641 (0.1641)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][64/196]	Time 0.750 (0.858)	Data 0.000 (0.005)	Loss 0.1649 (0.1722)	Acc@1 100.000 (99.694)	Acc@5 100.000 (100.000)
Epoch: [180][128/196]	Time 0.939 (0.878)	Data 0.000 (0.003)	Loss 0.1895 (0.1732)	Acc@1 98.828 (99.661)	Acc@5 100.000 (100.000)
Epoch: [180][192/196]	Time 0.942 (0.899)	Data 0.000 (0.002)	Loss 0.1741 (0.1740)	Acc@1 99.219 (99.632)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
Model: N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(14, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(13, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(15, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(31, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(30, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(62, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): AdaptiveAvgPool2d(output_size=(1, 1))
    (63): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
[INFO] Storing checkpoint...

  256
  92.53
Max memory: 89.8305024
 176.703s  j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 181
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [181 | 185] LR: 0.001000
Epoch: [181][0/196]	Time 2.051 (2.051)	Data 0.295 (0.295)	Loss 0.1665 (0.1665)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [181][64/196]	Time 0.944 (0.957)	Data 0.000 (0.005)	Loss 0.1689 (0.1726)	Acc@1 100.000 (99.706)	Acc@5 100.000 (99.994)
Epoch: [181][128/196]	Time 0.902 (0.935)	Data 0.000 (0.002)	Loss 0.1720 (0.1727)	Acc@1 99.609 (99.688)	Acc@5 100.000 (99.994)
Epoch: [181][192/196]	Time 0.836 (0.901)	Data 0.000 (0.002)	Loss 0.1737 (0.1735)	Acc@1 99.609 (99.648)	Acc@5 100.000 (99.996)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [182 | 185] LR: 0.001000
Epoch: [182][0/196]	Time 0.965 (0.965)	Data 0.332 (0.332)	Loss 0.1702 (0.1702)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [182][64/196]	Time 0.934 (0.939)	Data 0.000 (0.005)	Loss 0.1719 (0.1717)	Acc@1 100.000 (99.694)	Acc@5 100.000 (100.000)
Epoch: [182][128/196]	Time 0.937 (0.938)	Data 0.000 (0.003)	Loss 0.1674 (0.1721)	Acc@1 100.000 (99.691)	Acc@5 100.000 (100.000)
Epoch: [182][192/196]	Time 1.010 (0.939)	Data 0.000 (0.002)	Loss 0.1646 (0.1723)	Acc@1 100.000 (99.696)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [183 | 185] LR: 0.001000
Epoch: [183][0/196]	Time 0.927 (0.927)	Data 0.292 (0.292)	Loss 0.1667 (0.1667)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [183][64/196]	Time 0.748 (0.842)	Data 0.000 (0.005)	Loss 0.1694 (0.1732)	Acc@1 100.000 (99.609)	Acc@5 100.000 (100.000)
Epoch: [183][128/196]	Time 0.937 (0.882)	Data 0.000 (0.002)	Loss 0.1771 (0.1727)	Acc@1 99.609 (99.631)	Acc@5 100.000 (100.000)
Epoch: [183][192/196]	Time 0.938 (0.901)	Data 0.000 (0.002)	Loss 0.1630 (0.1723)	Acc@1 100.000 (99.646)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [184 | 185] LR: 0.001000
Epoch: [184][0/196]	Time 0.964 (0.964)	Data 0.372 (0.372)	Loss 0.1643 (0.1643)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [184][64/196]	Time 0.929 (0.938)	Data 0.000 (0.006)	Loss 0.1816 (0.1721)	Acc@1 99.219 (99.645)	Acc@5 100.000 (99.994)
Epoch: [184][128/196]	Time 0.937 (0.939)	Data 0.000 (0.003)	Loss 0.1737 (0.1715)	Acc@1 99.609 (99.679)	Acc@5 100.000 (99.997)
Epoch: [184][192/196]	Time 0.905 (0.933)	Data 0.000 (0.002)	Loss 0.1694 (0.1717)	Acc@1 99.609 (99.652)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [185 | 185] LR: 0.001000
Epoch: [185][0/196]	Time 0.780 (0.780)	Data 0.296 (0.296)	Loss 0.1707 (0.1707)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [185][64/196]	Time 0.904 (0.852)	Data 0.000 (0.005)	Loss 0.1673 (0.1709)	Acc@1 100.000 (99.651)	Acc@5 100.000 (100.000)
Epoch: [185][128/196]	Time 0.755 (0.855)	Data 0.000 (0.002)	Loss 0.1715 (0.1710)	Acc@1 99.609 (99.637)	Acc@5 100.000 (100.000)
Epoch: [185][192/196]	Time 0.941 (0.868)	Data 0.000 (0.002)	Loss 0.1641 (0.1711)	Acc@1 100.000 (99.656)	Acc@5 100.000 (99.998)
Max memory in training epoch: 58.251008
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 368082
[INFO] Storing checkpoint...

  256
  92.53
Max memory: 89.8305024
 170.781s  j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 186
Max memory: 0.154624
1
lr: 0.0010000000000000002

Epoch: [186 | 190] LR: 0.001000
Epoch: [186][0/196]	Time 2.057 (2.057)	Data 0.317 (0.317)	Loss 0.1873 (0.1873)	Acc@1 98.828 (98.828)	Acc@5 100.000 (100.000)
Epoch: [186][64/196]	Time 0.937 (0.955)	Data 0.000 (0.005)	Loss 0.1611 (0.1706)	Acc@1 100.000 (99.621)	Acc@5 100.000 (100.000)
Epoch: [186][128/196]	Time 0.935 (0.947)	Data 0.000 (0.003)	Loss 0.1740 (0.1703)	Acc@1 99.609 (99.640)	Acc@5 100.000 (100.000)
Epoch: [186][192/196]	Time 0.965 (0.937)	Data 0.000 (0.002)	Loss 0.1664 (0.1699)	Acc@1 100.000 (99.654)	Acc@5 100.000 (100.000)
Max memory in training epoch: 71.5068928
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [187 | 190] LR: 0.001000
Epoch: [187][0/196]	Time 0.923 (0.923)	Data 0.273 (0.273)	Loss 0.1668 (0.1668)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [187][64/196]	Time 0.934 (0.837)	Data 0.000 (0.004)	Loss 0.1640 (0.1682)	Acc@1 100.000 (99.724)	Acc@5 100.000 (100.000)
Epoch: [187][128/196]	Time 0.939 (0.887)	Data 0.000 (0.002)	Loss 0.1652 (0.1689)	Acc@1 100.000 (99.688)	Acc@5 100.000 (100.000)
Epoch: [187][192/196]	Time 0.971 (0.904)	Data 0.000 (0.002)	Loss 0.1635 (0.1688)	Acc@1 100.000 (99.694)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [188 | 190] LR: 0.001000
Epoch: [188][0/196]	Time 0.928 (0.928)	Data 0.306 (0.306)	Loss 0.1669 (0.1669)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [188][64/196]	Time 0.751 (0.838)	Data 0.000 (0.005)	Loss 0.1724 (0.1687)	Acc@1 100.000 (99.706)	Acc@5 100.000 (100.000)
Epoch: [188][128/196]	Time 0.934 (0.882)	Data 0.000 (0.003)	Loss 0.1722 (0.1691)	Acc@1 99.609 (99.682)	Acc@5 100.000 (100.000)
Epoch: [188][192/196]	Time 0.941 (0.901)	Data 0.000 (0.002)	Loss 0.1687 (0.1688)	Acc@1 99.609 (99.694)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [189 | 190] LR: 0.001000
Epoch: [189][0/196]	Time 0.948 (0.948)	Data 0.325 (0.325)	Loss 0.1661 (0.1661)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [189][64/196]	Time 0.942 (0.939)	Data 0.000 (0.005)	Loss 0.1714 (0.1666)	Acc@1 99.609 (99.796)	Acc@5 100.000 (100.000)
Epoch: [189][128/196]	Time 0.940 (0.938)	Data 0.000 (0.003)	Loss 0.1649 (0.1678)	Acc@1 100.000 (99.737)	Acc@5 100.000 (100.000)
Epoch: [189][192/196]	Time 0.936 (0.938)	Data 0.000 (0.002)	Loss 0.1703 (0.1681)	Acc@1 99.219 (99.700)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
1
lr: 0.0010000000000000002

Epoch: [190 | 190] LR: 0.001000
Epoch: [190][0/196]	Time 0.978 (0.978)	Data 0.294 (0.294)	Loss 0.1712 (0.1712)	Acc@1 99.609 (99.609)	Acc@5 100.000 (100.000)
Epoch: [190][64/196]	Time 0.754 (0.892)	Data 0.000 (0.005)	Loss 0.1637 (0.1673)	Acc@1 100.000 (99.766)	Acc@5 100.000 (100.000)
Epoch: [190][128/196]	Time 0.904 (0.883)	Data 0.000 (0.002)	Loss 0.1737 (0.1679)	Acc@1 99.609 (99.706)	Acc@5 100.000 (100.000)
Epoch: [190][192/196]	Time 0.748 (0.874)	Data 0.000 (0.002)	Loss 0.1665 (0.1677)	Acc@1 100.000 (99.700)	Acc@5 100.000 (100.000)
Max memory in training epoch: 58.251008
count0: 368082
[INFO] Storing checkpoint...

  256
  92.57
Max memory: 89.8305024
 171.213s  Thres 0.001
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
numoFStages: 3
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
1
lr: 0.1

Epoch: [1 | 5] LR: 0.100000
Epoch: [1][0/196]	Time 1.149 (1.149)	Data 0.284 (0.284)	Loss 2.9910 (2.9910)	Acc@1 9.766 (9.766)	Acc@5 56.250 (56.250)
Epoch: [1][64/196]	Time 0.915 (1.001)	Data 0.000 (0.004)	Loss 2.3535 (2.6291)	Acc@1 29.688 (23.552)	Acc@5 85.156 (78.119)
Epoch: [1][128/196]	Time 0.998 (0.999)	Data 0.000 (0.002)	Loss 2.1038 (2.4393)	Acc@1 44.141 (29.642)	Acc@5 91.797 (83.091)
Epoch: [1][192/196]	Time 0.996 (0.999)	Data 0.000 (0.002)	Loss 1.9200 (2.3112)	Acc@1 50.000 (34.302)	Acc@5 94.141 (85.964)
Max memory in training epoch: 81.9808768
count0: 487386
1
lr: 0.1

Epoch: [2 | 5] LR: 0.100000
Epoch: [2][0/196]	Time 1.028 (1.028)	Data 0.312 (0.312)	Loss 1.9292 (1.9292)	Acc@1 48.047 (48.047)	Acc@5 92.578 (92.578)
Epoch: [2][64/196]	Time 0.903 (0.995)	Data 0.000 (0.005)	Loss 1.6579 (1.8620)	Acc@1 58.594 (51.316)	Acc@5 95.312 (93.912)
Epoch: [2][128/196]	Time 0.800 (0.951)	Data 0.000 (0.003)	Loss 1.7354 (1.8073)	Acc@1 54.297 (52.916)	Acc@5 95.312 (94.416)
Epoch: [2][192/196]	Time 0.997 (0.955)	Data 0.000 (0.002)	Loss 1.5920 (1.7452)	Acc@1 59.375 (54.932)	Acc@5 97.266 (94.833)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [3 | 5] LR: 0.100000
Epoch: [3][0/196]	Time 1.018 (1.018)	Data 0.300 (0.300)	Loss 1.4731 (1.4731)	Acc@1 62.500 (62.500)	Acc@5 98.438 (98.438)
Epoch: [3][64/196]	Time 0.664 (0.944)	Data 0.000 (0.005)	Loss 1.4688 (1.5123)	Acc@1 66.016 (62.855)	Acc@5 96.484 (96.514)
Epoch: [3][128/196]	Time 0.999 (0.941)	Data 0.000 (0.002)	Loss 1.5490 (1.4696)	Acc@1 64.844 (64.069)	Acc@5 94.141 (96.863)
Epoch: [3][192/196]	Time 0.996 (0.960)	Data 0.000 (0.002)	Loss 1.2181 (1.4408)	Acc@1 72.656 (64.747)	Acc@5 98.047 (97.021)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [4 | 5] LR: 0.100000
Epoch: [4][0/196]	Time 1.014 (1.014)	Data 0.343 (0.343)	Loss 1.2836 (1.2836)	Acc@1 68.359 (68.359)	Acc@5 96.094 (96.094)
Epoch: [4][64/196]	Time 0.929 (0.998)	Data 0.000 (0.005)	Loss 1.2967 (1.2621)	Acc@1 70.312 (70.349)	Acc@5 96.875 (97.650)
Epoch: [4][128/196]	Time 1.002 (0.999)	Data 0.000 (0.003)	Loss 1.1909 (1.2489)	Acc@1 74.219 (70.767)	Acc@5 98.047 (97.680)
Epoch: [4][192/196]	Time 0.999 (0.999)	Data 0.000 (0.002)	Loss 1.2558 (1.2298)	Acc@1 68.359 (71.193)	Acc@5 97.266 (97.820)
Max memory in training epoch: 66.5419264
count0: 487386
1
lr: 0.1

Epoch: [5 | 5] LR: 0.100000
Epoch: [5][0/196]	Time 1.017 (1.017)	Data 0.330 (0.330)	Loss 1.1767 (1.1767)	Acc@1 71.875 (71.875)	Acc@5 97.656 (97.656)
Epoch: [5][64/196]	Time 1.030 (1.001)	Data 0.000 (0.005)	Loss 1.1056 (1.1231)	Acc@1 75.391 (74.237)	Acc@5 99.609 (98.275)
Epoch: [5][128/196]	Time 0.801 (0.947)	Data 0.000 (0.003)	Loss 1.1383 (1.1005)	Acc@1 73.047 (74.885)	Acc@5 98.047 (98.365)
Epoch: [5][192/196]	Time 0.960 (0.959)	Data 0.000 (0.002)	Loss 0.9826 (1.0900)	Acc@1 75.781 (74.852)	Acc@5 98.828 (98.413)
Max memory in training epoch: 66.5419264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
[INFO] Storing checkpoint...

  256
  63.95
Max memory: 102.6363904
 188.370s  j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 6
Max memory: 0.202496
1
lr: 0.1

Epoch: [6 | 10] LR: 0.100000
Epoch: [6][0/196]	Time 1.161 (1.161)	Data 0.291 (0.291)	Loss 0.9535 (0.9535)	Acc@1 77.734 (77.734)	Acc@5 100.000 (100.000)
Epoch: [6][64/196]	Time 0.999 (1.002)	Data 0.000 (0.005)	Loss 1.0655 (1.0013)	Acc@1 75.000 (77.272)	Acc@5 98.047 (98.828)
Epoch: [6][128/196]	Time 1.005 (1.000)	Data 0.000 (0.002)	Loss 1.0503 (1.0026)	Acc@1 76.953 (77.262)	Acc@5 96.875 (98.698)
Epoch: [6][192/196]	Time 0.997 (1.001)	Data 0.000 (0.002)	Loss 0.9188 (0.9969)	Acc@1 79.688 (77.382)	Acc@5 97.656 (98.707)
Max memory in training epoch: 81.9807744
count0: 487386
1
lr: 0.1

Epoch: [7 | 10] LR: 0.100000
Epoch: [7][0/196]	Time 1.019 (1.019)	Data 0.324 (0.324)	Loss 0.9869 (0.9869)	Acc@1 78.516 (78.516)	Acc@5 98.828 (98.828)
Epoch: [7][64/196]	Time 0.954 (0.997)	Data 0.000 (0.005)	Loss 1.0159 (0.9447)	Acc@1 75.391 (78.864)	Acc@5 98.438 (98.852)
Epoch: [7][128/196]	Time 0.800 (0.953)	Data 0.000 (0.003)	Loss 0.8161 (0.9339)	Acc@1 82.812 (79.009)	Acc@5 100.000 (98.889)
Epoch: [7][192/196]	Time 0.793 (0.940)	Data 0.000 (0.002)	Loss 0.9192 (0.9297)	Acc@1 79.297 (78.999)	Acc@5 98.828 (98.893)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [8 | 10] LR: 0.100000
Epoch: [8][0/196]	Time 0.826 (0.826)	Data 0.290 (0.290)	Loss 0.8815 (0.8815)	Acc@1 78.125 (78.125)	Acc@5 98.438 (98.438)
Epoch: [8][64/196]	Time 0.994 (0.948)	Data 0.000 (0.005)	Loss 0.9296 (0.9017)	Acc@1 80.469 (79.309)	Acc@5 98.047 (98.942)
Epoch: [8][128/196]	Time 0.994 (0.972)	Data 0.000 (0.002)	Loss 0.8350 (0.8938)	Acc@1 82.422 (79.575)	Acc@5 99.219 (98.904)
Epoch: [8][192/196]	Time 0.992 (0.980)	Data 0.000 (0.002)	Loss 0.8930 (0.8853)	Acc@1 78.906 (79.884)	Acc@5 99.609 (98.909)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [9 | 10] LR: 0.100000
Epoch: [9][0/196]	Time 1.017 (1.017)	Data 0.300 (0.300)	Loss 0.7708 (0.7708)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [9][64/196]	Time 0.999 (0.997)	Data 0.000 (0.005)	Loss 0.9520 (0.8436)	Acc@1 76.172 (81.166)	Acc@5 98.047 (98.990)
Epoch: [9][128/196]	Time 0.980 (0.997)	Data 0.000 (0.002)	Loss 0.7908 (0.8418)	Acc@1 85.156 (81.180)	Acc@5 99.219 (99.049)
Epoch: [9][192/196]	Time 0.927 (0.997)	Data 0.000 (0.002)	Loss 0.8604 (0.8437)	Acc@1 79.688 (81.023)	Acc@5 99.609 (99.037)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [10 | 10] LR: 0.100000
Epoch: [10][0/196]	Time 1.037 (1.037)	Data 0.307 (0.307)	Loss 0.8392 (0.8392)	Acc@1 82.422 (82.422)	Acc@5 98.438 (98.438)
Epoch: [10][64/196]	Time 0.963 (0.988)	Data 0.000 (0.005)	Loss 0.7640 (0.8164)	Acc@1 83.984 (81.599)	Acc@5 98.828 (99.105)
Epoch: [10][128/196]	Time 0.998 (0.940)	Data 0.000 (0.003)	Loss 0.7735 (0.8233)	Acc@1 82.812 (81.386)	Acc@5 100.000 (99.086)
Epoch: [10][192/196]	Time 0.955 (0.955)	Data 0.000 (0.002)	Loss 0.8666 (0.8214)	Acc@1 81.250 (81.454)	Acc@5 98.047 (99.077)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
[INFO] Storing checkpoint...

  256
  77.54
Max memory: 102.636288
 187.564s  j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 11
Max memory: 0.202496
1
lr: 0.1

Epoch: [11 | 15] LR: 0.100000
Epoch: [11][0/196]	Time 1.155 (1.155)	Data 0.300 (0.300)	Loss 0.7490 (0.7490)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [11][64/196]	Time 1.001 (1.002)	Data 0.000 (0.005)	Loss 0.8313 (0.7807)	Acc@1 82.422 (82.740)	Acc@5 98.828 (99.171)
Epoch: [11][128/196]	Time 0.996 (1.000)	Data 0.000 (0.002)	Loss 0.9699 (0.7938)	Acc@1 74.219 (82.337)	Acc@5 99.219 (99.146)
Epoch: [11][192/196]	Time 1.004 (1.001)	Data 0.000 (0.002)	Loss 0.7331 (0.7938)	Acc@1 82.812 (82.307)	Acc@5 98.438 (99.122)
Max memory in training epoch: 81.9807744
count0: 487386
1
lr: 0.1

Epoch: [12 | 15] LR: 0.100000
Epoch: [12][0/196]	Time 1.019 (1.019)	Data 0.294 (0.294)	Loss 0.7828 (0.7828)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [12][64/196]	Time 0.964 (0.996)	Data 0.000 (0.005)	Loss 0.7508 (0.7788)	Acc@1 83.984 (82.728)	Acc@5 98.828 (99.189)
Epoch: [12][128/196]	Time 0.798 (0.899)	Data 0.000 (0.002)	Loss 0.7732 (0.7886)	Acc@1 82.422 (82.322)	Acc@5 99.219 (99.152)
Epoch: [12][192/196]	Time 1.001 (0.926)	Data 0.000 (0.002)	Loss 0.7453 (0.7833)	Acc@1 82.031 (82.495)	Acc@5 98.438 (99.132)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [13 | 15] LR: 0.100000
Epoch: [13][0/196]	Time 1.021 (1.021)	Data 0.348 (0.348)	Loss 0.7241 (0.7241)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [13][64/196]	Time 1.001 (1.002)	Data 0.000 (0.005)	Loss 0.6742 (0.7689)	Acc@1 87.500 (83.053)	Acc@5 99.609 (99.261)
Epoch: [13][128/196]	Time 1.000 (1.002)	Data 0.000 (0.003)	Loss 0.7766 (0.7701)	Acc@1 81.250 (83.015)	Acc@5 100.000 (99.225)
Epoch: [13][192/196]	Time 1.001 (1.002)	Data 0.000 (0.002)	Loss 0.7947 (0.7762)	Acc@1 81.250 (82.677)	Acc@5 98.438 (99.194)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [14 | 15] LR: 0.100000
Epoch: [14][0/196]	Time 1.030 (1.030)	Data 0.334 (0.334)	Loss 0.6935 (0.6935)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [14][64/196]	Time 1.001 (1.001)	Data 0.000 (0.005)	Loss 0.8651 (0.7781)	Acc@1 79.297 (82.356)	Acc@5 99.609 (99.123)
Epoch: [14][128/196]	Time 1.002 (1.001)	Data 0.000 (0.003)	Loss 0.9084 (0.7767)	Acc@1 80.469 (82.631)	Acc@5 99.609 (99.143)
Epoch: [14][192/196]	Time 1.000 (1.002)	Data 0.000 (0.002)	Loss 0.7187 (0.7745)	Acc@1 87.109 (82.703)	Acc@5 99.219 (99.182)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [15 | 15] LR: 0.100000
Epoch: [15][0/196]	Time 1.029 (1.029)	Data 0.290 (0.290)	Loss 0.6859 (0.6859)	Acc@1 85.156 (85.156)	Acc@5 99.609 (99.609)
Epoch: [15][64/196]	Time 0.964 (0.984)	Data 0.000 (0.005)	Loss 0.7011 (0.7407)	Acc@1 86.328 (83.786)	Acc@5 98.828 (99.363)
Epoch: [15][128/196]	Time 1.002 (0.946)	Data 0.000 (0.002)	Loss 0.7379 (0.7530)	Acc@1 83.984 (83.385)	Acc@5 98.438 (99.328)
Epoch: [15][192/196]	Time 0.961 (0.959)	Data 0.000 (0.002)	Loss 0.7883 (0.7578)	Acc@1 80.859 (83.250)	Acc@5 100.000 (99.245)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
[INFO] Storing checkpoint...

  256
  76.23
Max memory: 102.636288
 188.237s  j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 16
Max memory: 0.202496
1
lr: 0.1

Epoch: [16 | 20] LR: 0.100000
Epoch: [16][0/196]	Time 1.157 (1.157)	Data 0.313 (0.313)	Loss 0.7247 (0.7247)	Acc@1 84.766 (84.766)	Acc@5 100.000 (100.000)
Epoch: [16][64/196]	Time 0.996 (1.002)	Data 0.000 (0.005)	Loss 0.6869 (0.7366)	Acc@1 85.156 (83.792)	Acc@5 100.000 (99.309)
Epoch: [16][128/196]	Time 0.999 (1.000)	Data 0.000 (0.003)	Loss 0.8001 (0.7443)	Acc@1 83.203 (83.603)	Acc@5 99.219 (99.279)
Epoch: [16][192/196]	Time 0.998 (0.999)	Data 0.000 (0.002)	Loss 0.8850 (0.7523)	Acc@1 79.688 (83.418)	Acc@5 98.047 (99.229)
Max memory in training epoch: 81.9807744
count0: 487386
1
lr: 0.1

Epoch: [17 | 20] LR: 0.100000
Epoch: [17][0/196]	Time 1.028 (1.028)	Data 0.272 (0.272)	Loss 0.7421 (0.7421)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [17][64/196]	Time 0.916 (0.966)	Data 0.000 (0.004)	Loss 0.7255 (0.7527)	Acc@1 83.984 (83.377)	Acc@5 100.000 (99.243)
Epoch: [17][128/196]	Time 0.594 (0.835)	Data 0.000 (0.002)	Loss 0.7397 (0.7410)	Acc@1 84.766 (83.842)	Acc@5 99.219 (99.273)
Epoch: [17][192/196]	Time 0.794 (0.809)	Data 0.000 (0.002)	Loss 0.7480 (0.7485)	Acc@1 83.984 (83.683)	Acc@5 99.609 (99.275)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [18 | 20] LR: 0.100000
Epoch: [18][0/196]	Time 0.823 (0.823)	Data 0.285 (0.285)	Loss 0.6432 (0.6432)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [18][64/196]	Time 0.795 (0.796)	Data 0.000 (0.005)	Loss 0.6994 (0.7529)	Acc@1 83.984 (83.588)	Acc@5 99.609 (99.099)
Epoch: [18][128/196]	Time 0.796 (0.795)	Data 0.000 (0.002)	Loss 0.7220 (0.7505)	Acc@1 86.328 (83.506)	Acc@5 98.828 (99.185)
Epoch: [18][192/196]	Time 0.794 (0.795)	Data 0.000 (0.002)	Loss 0.6878 (0.7445)	Acc@1 83.984 (83.723)	Acc@5 98.438 (99.188)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [19 | 20] LR: 0.100000
Epoch: [19][0/196]	Time 0.828 (0.828)	Data 0.282 (0.282)	Loss 0.8028 (0.8028)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [19][64/196]	Time 0.795 (0.794)	Data 0.000 (0.004)	Loss 0.7809 (0.7272)	Acc@1 82.812 (84.429)	Acc@5 98.438 (99.405)
Epoch: [19][128/196]	Time 0.796 (0.794)	Data 0.000 (0.002)	Loss 0.8015 (0.7354)	Acc@1 82.031 (84.133)	Acc@5 99.219 (99.331)
Epoch: [19][192/196]	Time 0.794 (0.794)	Data 0.000 (0.002)	Loss 0.7563 (0.7312)	Acc@1 82.422 (84.387)	Acc@5 98.438 (99.310)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [20 | 20] LR: 0.100000
Epoch: [20][0/196]	Time 0.817 (0.817)	Data 0.301 (0.301)	Loss 0.7464 (0.7464)	Acc@1 82.422 (82.422)	Acc@5 99.609 (99.609)
Epoch: [20][64/196]	Time 0.593 (0.738)	Data 0.000 (0.005)	Loss 0.6540 (0.7270)	Acc@1 85.547 (84.405)	Acc@5 99.219 (99.321)
Epoch: [20][128/196]	Time 0.794 (0.723)	Data 0.000 (0.002)	Loss 0.7052 (0.7255)	Acc@1 86.328 (84.378)	Acc@5 100.000 (99.328)
Epoch: [20][192/196]	Time 0.756 (0.740)	Data 0.000 (0.002)	Loss 0.6690 (0.7277)	Acc@1 88.672 (84.415)	Acc@5 99.609 (99.320)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
[INFO] Storing checkpoint...

  256
  78.61
Max memory: 102.636288
 145.461s  j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 21
Max memory: 0.202496
1
lr: 0.1

Epoch: [21 | 25] LR: 0.100000
Epoch: [21][0/196]	Time 0.985 (0.985)	Data 0.324 (0.324)	Loss 0.6624 (0.6624)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [21][64/196]	Time 0.788 (0.796)	Data 0.000 (0.005)	Loss 0.6703 (0.6995)	Acc@1 85.547 (85.475)	Acc@5 99.219 (99.399)
Epoch: [21][128/196]	Time 0.796 (0.795)	Data 0.000 (0.003)	Loss 0.7111 (0.7129)	Acc@1 87.891 (85.029)	Acc@5 99.609 (99.364)
Epoch: [21][192/196]	Time 0.793 (0.795)	Data 0.000 (0.002)	Loss 0.6141 (0.7186)	Acc@1 87.109 (84.780)	Acc@5 99.609 (99.336)
Max memory in training epoch: 81.9807744
count0: 487386
1
lr: 0.1

Epoch: [22 | 25] LR: 0.100000
Epoch: [22][0/196]	Time 0.873 (0.873)	Data 0.324 (0.324)	Loss 0.6301 (0.6301)	Acc@1 88.672 (88.672)	Acc@5 99.219 (99.219)
Epoch: [22][64/196]	Time 0.757 (0.786)	Data 0.000 (0.005)	Loss 0.7079 (0.7162)	Acc@1 84.375 (84.892)	Acc@5 99.609 (99.285)
Epoch: [22][128/196]	Time 0.594 (0.724)	Data 0.000 (0.003)	Loss 0.7999 (0.7271)	Acc@1 83.203 (84.605)	Acc@5 99.219 (99.273)
Epoch: [22][192/196]	Time 0.795 (0.743)	Data 0.000 (0.002)	Loss 0.7970 (0.7289)	Acc@1 84.375 (84.484)	Acc@5 98.828 (99.265)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [23 | 25] LR: 0.100000
Epoch: [23][0/196]	Time 0.879 (0.879)	Data 0.313 (0.313)	Loss 0.7315 (0.7315)	Acc@1 83.203 (83.203)	Acc@5 100.000 (100.000)
Epoch: [23][64/196]	Time 0.795 (0.796)	Data 0.000 (0.005)	Loss 0.7757 (0.7217)	Acc@1 84.375 (84.507)	Acc@5 98.828 (99.429)
Epoch: [23][128/196]	Time 0.795 (0.796)	Data 0.000 (0.003)	Loss 0.7428 (0.7211)	Acc@1 84.766 (84.826)	Acc@5 99.609 (99.382)
Epoch: [23][192/196]	Time 0.794 (0.795)	Data 0.000 (0.002)	Loss 0.6286 (0.7252)	Acc@1 87.891 (84.612)	Acc@5 100.000 (99.354)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [24 | 25] LR: 0.100000
Epoch: [24][0/196]	Time 0.873 (0.873)	Data 0.290 (0.290)	Loss 0.7271 (0.7271)	Acc@1 87.891 (87.891)	Acc@5 98.438 (98.438)
Epoch: [24][64/196]	Time 0.795 (0.795)	Data 0.000 (0.005)	Loss 0.7990 (0.7078)	Acc@1 80.078 (85.084)	Acc@5 98.438 (99.411)
Epoch: [24][128/196]	Time 0.795 (0.795)	Data 0.000 (0.002)	Loss 0.7399 (0.7172)	Acc@1 85.156 (84.844)	Acc@5 99.609 (99.328)
Epoch: [24][192/196]	Time 0.794 (0.795)	Data 0.000 (0.002)	Loss 0.7252 (0.7168)	Acc@1 85.547 (84.790)	Acc@5 98.828 (99.338)
Max memory in training epoch: 66.541824
count0: 487386
1
lr: 0.1

Epoch: [25 | 25] LR: 0.100000
Epoch: [25][0/196]	Time 0.881 (0.881)	Data 0.329 (0.329)	Loss 0.7592 (0.7592)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [25][64/196]	Time 0.597 (0.697)	Data 0.000 (0.005)	Loss 0.7780 (0.7125)	Acc@1 81.250 (85.319)	Acc@5 99.219 (99.291)
Epoch: [25][128/196]	Time 0.794 (0.724)	Data 0.000 (0.003)	Loss 0.6599 (0.7104)	Acc@1 87.109 (85.238)	Acc@5 99.609 (99.346)
Epoch: [25][192/196]	Time 0.592 (0.737)	Data 0.000 (0.002)	Loss 0.6579 (0.7157)	Acc@1 85.156 (85.011)	Acc@5 99.609 (99.348)
Max memory in training epoch: 66.541824
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 487386
Count: 477576 ; 487386 ; 0.9798722162721129
[INFO] Storing checkpoint...

  256
  81.28
Max memory: 102.636288
 144.382s  j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 26
Max memory: 0.1986048
1
lr: 0.1

Epoch: [26 | 30] LR: 0.100000
Epoch: [26][0/196]	Time 1.080 (1.080)	Data 0.287 (0.287)	Loss 0.7081 (0.7081)	Acc@1 84.766 (84.766)	Acc@5 99.219 (99.219)
Epoch: [26][64/196]	Time 0.795 (0.799)	Data 0.000 (0.005)	Loss 0.7547 (0.6871)	Acc@1 84.375 (86.070)	Acc@5 99.609 (99.411)
Epoch: [26][128/196]	Time 0.795 (0.797)	Data 0.000 (0.002)	Loss 0.7622 (0.7024)	Acc@1 82.812 (85.383)	Acc@5 99.609 (99.385)
Epoch: [26][192/196]	Time 0.794 (0.796)	Data 0.000 (0.002)	Loss 0.6522 (0.7037)	Acc@1 83.984 (85.318)	Acc@5 100.000 (99.375)
Max memory in training epoch: 80.7040512
count0: 477576
1
lr: 0.1

Epoch: [27 | 30] LR: 0.100000
Epoch: [27][0/196]	Time 0.824 (0.824)	Data 0.288 (0.288)	Loss 0.6465 (0.6465)	Acc@1 87.891 (87.891)	Acc@5 98.047 (98.047)
Epoch: [27][64/196]	Time 0.756 (0.782)	Data 0.000 (0.005)	Loss 0.7216 (0.7114)	Acc@1 84.766 (85.036)	Acc@5 99.219 (99.267)
Epoch: [27][128/196]	Time 0.826 (0.720)	Data 0.000 (0.002)	Loss 0.7210 (0.7008)	Acc@1 85.156 (85.302)	Acc@5 99.219 (99.361)
Epoch: [27][192/196]	Time 0.793 (0.744)	Data 0.000 (0.002)	Loss 0.7293 (0.7085)	Acc@1 84.375 (85.110)	Acc@5 98.828 (99.328)
Max memory in training epoch: 66.3689728
count0: 477576
1
lr: 0.1

Epoch: [28 | 30] LR: 0.100000
Epoch: [28][0/196]	Time 0.815 (0.815)	Data 0.305 (0.305)	Loss 0.6327 (0.6327)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [28][64/196]	Time 0.794 (0.795)	Data 0.000 (0.005)	Loss 0.6256 (0.7039)	Acc@1 89.453 (85.433)	Acc@5 99.609 (99.375)
Epoch: [28][128/196]	Time 0.687 (0.795)	Data 0.000 (0.002)	Loss 0.6215 (0.7075)	Acc@1 89.062 (85.199)	Acc@5 100.000 (99.328)
Epoch: [28][192/196]	Time 0.794 (0.794)	Data 0.000 (0.002)	Loss 0.7844 (0.7094)	Acc@1 81.250 (85.189)	Acc@5 98.438 (99.316)
Max memory in training epoch: 66.3689728
count0: 477576
1
lr: 0.1

Epoch: [29 | 30] LR: 0.100000
Epoch: [29][0/196]	Time 0.824 (0.824)	Data 0.310 (0.310)	Loss 0.6769 (0.6769)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [29][64/196]	Time 0.793 (0.794)	Data 0.000 (0.005)	Loss 0.7177 (0.7047)	Acc@1 84.766 (85.054)	Acc@5 99.609 (99.447)
Epoch: [29][128/196]	Time 0.766 (0.794)	Data 0.000 (0.003)	Loss 0.6768 (0.7084)	Acc@1 85.547 (85.050)	Acc@5 100.000 (99.400)
Epoch: [29][192/196]	Time 0.594 (0.789)	Data 0.000 (0.002)	Loss 0.8002 (0.7035)	Acc@1 80.859 (85.288)	Acc@5 99.609 (99.391)
Max memory in training epoch: 66.3689728
count0: 477576
1
lr: 0.1

Epoch: [30 | 30] LR: 0.100000
Epoch: [30][0/196]	Time 0.611 (0.611)	Data 0.262 (0.262)	Loss 0.6786 (0.6786)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [30][64/196]	Time 0.798 (0.710)	Data 0.000 (0.004)	Loss 0.6779 (0.6967)	Acc@1 84.766 (85.673)	Acc@5 99.609 (99.441)
Epoch: [30][128/196]	Time 0.680 (0.754)	Data 0.000 (0.002)	Loss 0.7936 (0.7082)	Acc@1 81.641 (85.244)	Acc@5 99.609 (99.422)
Epoch: [30][192/196]	Time 0.597 (0.749)	Data 0.000 (0.001)	Loss 0.6781 (0.7073)	Acc@1 84.375 (85.213)	Acc@5 100.000 (99.403)
Max memory in training epoch: 66.3689728
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 477576
Count: 466036 ; 477576 ; 0.9758363066820779
[INFO] Storing checkpoint...

  256
  77.4
Max memory: 102.5312256
 146.735s  j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 31
Max memory: 0.1939968
1
lr: 0.1

Epoch: [31 | 35] LR: 0.100000
Epoch: [31][0/196]	Time 1.075 (1.075)	Data 0.306 (0.306)	Loss 0.7841 (0.7841)	Acc@1 82.812 (82.812)	Acc@5 99.609 (99.609)
Epoch: [31][64/196]	Time 0.796 (0.799)	Data 0.000 (0.005)	Loss 0.6788 (0.6652)	Acc@1 86.328 (86.659)	Acc@5 99.219 (99.561)
Epoch: [31][128/196]	Time 0.789 (0.797)	Data 0.000 (0.003)	Loss 0.6550 (0.6816)	Acc@1 85.938 (86.025)	Acc@5 99.219 (99.506)
Epoch: [31][192/196]	Time 0.794 (0.797)	Data 0.000 (0.002)	Loss 0.6043 (0.6841)	Acc@1 87.109 (85.895)	Acc@5 99.219 (99.445)
Max memory in training epoch: 80.2860544
count0: 466036
1
lr: 0.1

Epoch: [32 | 35] LR: 0.100000
Epoch: [32][0/196]	Time 0.837 (0.837)	Data 0.254 (0.254)	Loss 0.6344 (0.6344)	Acc@1 87.891 (87.891)	Acc@5 99.219 (99.219)
Epoch: [32][64/196]	Time 0.759 (0.780)	Data 0.000 (0.004)	Loss 0.6064 (0.7059)	Acc@1 89.844 (85.595)	Acc@5 99.609 (99.297)
Epoch: [32][128/196]	Time 0.797 (0.721)	Data 0.000 (0.002)	Loss 0.5717 (0.7054)	Acc@1 91.016 (85.377)	Acc@5 98.828 (99.349)
Epoch: [32][192/196]	Time 0.791 (0.745)	Data 0.000 (0.001)	Loss 0.6444 (0.7037)	Acc@1 85.938 (85.340)	Acc@5 100.000 (99.383)
Max memory in training epoch: 66.232576
count0: 466036
1
lr: 0.1

Epoch: [33 | 35] LR: 0.100000
Epoch: [33][0/196]	Time 0.818 (0.818)	Data 0.270 (0.270)	Loss 0.7942 (0.7942)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [33][64/196]	Time 0.797 (0.796)	Data 0.000 (0.004)	Loss 0.7352 (0.6948)	Acc@1 85.156 (85.487)	Acc@5 99.219 (99.327)
Epoch: [33][128/196]	Time 0.796 (0.797)	Data 0.000 (0.002)	Loss 0.7046 (0.6990)	Acc@1 84.766 (85.223)	Acc@5 99.609 (99.364)
Epoch: [33][192/196]	Time 0.797 (0.795)	Data 0.000 (0.002)	Loss 0.6455 (0.6966)	Acc@1 86.328 (85.464)	Acc@5 99.609 (99.421)
Max memory in training epoch: 66.2587904
count0: 466036
1
lr: 0.1

Epoch: [34 | 35] LR: 0.100000
Epoch: [34][0/196]	Time 0.812 (0.812)	Data 0.302 (0.302)	Loss 0.6887 (0.6887)	Acc@1 83.203 (83.203)	Acc@5 99.219 (99.219)
Epoch: [34][64/196]	Time 0.797 (0.798)	Data 0.000 (0.005)	Loss 0.7457 (0.6843)	Acc@1 83.203 (85.499)	Acc@5 99.219 (99.405)
Epoch: [34][128/196]	Time 0.797 (0.797)	Data 0.000 (0.002)	Loss 0.7662 (0.6899)	Acc@1 83.203 (85.632)	Acc@5 98.047 (99.370)
Epoch: [34][192/196]	Time 0.757 (0.785)	Data 0.000 (0.002)	Loss 0.6348 (0.6899)	Acc@1 87.500 (85.658)	Acc@5 99.609 (99.401)
Max memory in training epoch: 66.2587904
count0: 466036
1
lr: 0.1

Epoch: [35 | 35] LR: 0.100000
Epoch: [35][0/196]	Time 0.615 (0.615)	Data 0.297 (0.297)	Loss 0.6674 (0.6674)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [35][64/196]	Time 0.799 (0.691)	Data 0.000 (0.005)	Loss 0.6431 (0.6773)	Acc@1 86.328 (86.250)	Acc@5 99.609 (99.363)
Epoch: [35][128/196]	Time 0.799 (0.744)	Data 0.000 (0.002)	Loss 0.7598 (0.6877)	Acc@1 83.594 (85.807)	Acc@5 98.438 (99.406)
Epoch: [35][192/196]	Time 0.597 (0.737)	Data 0.000 (0.002)	Loss 0.8101 (0.6872)	Acc@1 82.422 (85.917)	Acc@5 98.438 (99.407)
Max memory in training epoch: 66.2587904
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 466036
Count: 444674 ; 466036 ; 0.95416233939009
[INFO] Storing checkpoint...

  256
  76.54
Max memory: 102.4252416
 144.469s  j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 36
Max memory: 0.1856
1
lr: 0.1

Epoch: [36 | 40] LR: 0.100000
Epoch: [36][0/196]	Time 1.367 (1.367)	Data 0.299 (0.299)	Loss 0.6852 (0.6852)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [36][64/196]	Time 0.798 (0.807)	Data 0.000 (0.005)	Loss 0.7599 (0.6632)	Acc@1 83.203 (86.779)	Acc@5 99.609 (99.459)
Epoch: [36][128/196]	Time 0.844 (0.804)	Data 0.000 (0.002)	Loss 0.7124 (0.6711)	Acc@1 86.719 (86.458)	Acc@5 98.438 (99.449)
Epoch: [36][192/196]	Time 0.797 (0.802)	Data 0.000 (0.002)	Loss 0.7175 (0.6849)	Acc@1 83.984 (85.952)	Acc@5 98.828 (99.421)
Max memory in training epoch: 79.2731136
count0: 444674
1
lr: 0.1

Epoch: [37 | 40] LR: 0.100000
Epoch: [37][0/196]	Time 0.835 (0.835)	Data 0.293 (0.293)	Loss 0.6925 (0.6925)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [37][64/196]	Time 0.762 (0.779)	Data 0.000 (0.005)	Loss 0.8597 (0.6881)	Acc@1 80.859 (85.661)	Acc@5 97.656 (99.399)
Epoch: [37][128/196]	Time 0.743 (0.724)	Data 0.000 (0.002)	Loss 0.6819 (0.6862)	Acc@1 87.109 (85.871)	Acc@5 99.609 (99.419)
Epoch: [37][192/196]	Time 0.798 (0.748)	Data 0.000 (0.002)	Loss 0.7257 (0.6879)	Acc@1 82.422 (85.753)	Acc@5 99.609 (99.415)
Max memory in training epoch: 65.16352
count0: 444674
1
lr: 0.1

Epoch: [38 | 40] LR: 0.100000
Epoch: [38][0/196]	Time 0.834 (0.834)	Data 0.269 (0.269)	Loss 0.6543 (0.6543)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [38][64/196]	Time 0.798 (0.800)	Data 0.000 (0.004)	Loss 0.7965 (0.6860)	Acc@1 84.766 (85.944)	Acc@5 99.219 (99.399)
Epoch: [38][128/196]	Time 0.797 (0.799)	Data 0.000 (0.002)	Loss 0.6255 (0.6887)	Acc@1 86.719 (85.732)	Acc@5 99.609 (99.416)
Epoch: [38][192/196]	Time 0.798 (0.798)	Data 0.000 (0.002)	Loss 0.6633 (0.6865)	Acc@1 87.891 (85.814)	Acc@5 100.000 (99.435)
Max memory in training epoch: 65.16352
count0: 444674
1
lr: 0.1

Epoch: [39 | 40] LR: 0.100000
Epoch: [39][0/196]	Time 0.829 (0.829)	Data 0.260 (0.260)	Loss 0.6979 (0.6979)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [39][64/196]	Time 0.799 (0.799)	Data 0.000 (0.004)	Loss 0.6468 (0.6829)	Acc@1 86.719 (86.028)	Acc@5 99.219 (99.405)
Epoch: [39][128/196]	Time 0.798 (0.798)	Data 0.000 (0.002)	Loss 0.6782 (0.6739)	Acc@1 86.328 (86.413)	Acc@5 100.000 (99.437)
Epoch: [39][192/196]	Time 0.757 (0.787)	Data 0.000 (0.001)	Loss 0.6486 (0.6741)	Acc@1 86.328 (86.288)	Acc@5 99.219 (99.441)
Max memory in training epoch: 65.16352
count0: 444674
1
lr: 0.1

Epoch: [40 | 40] LR: 0.100000
Epoch: [40][0/196]	Time 0.610 (0.610)	Data 0.277 (0.277)	Loss 0.6321 (0.6321)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [40][64/196]	Time 0.798 (0.691)	Data 0.000 (0.004)	Loss 0.6788 (0.6818)	Acc@1 86.328 (86.208)	Acc@5 99.609 (99.447)
Epoch: [40][128/196]	Time 0.761 (0.744)	Data 0.000 (0.002)	Loss 0.7730 (0.6787)	Acc@1 81.641 (86.195)	Acc@5 99.609 (99.467)
Epoch: [40][192/196]	Time 0.597 (0.727)	Data 0.000 (0.002)	Loss 0.7381 (0.6811)	Acc@1 84.766 (86.116)	Acc@5 99.219 (99.456)
Max memory in training epoch: 65.16352
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 444674
Count: 431102 ; 444674 ; 0.9694787642182813
[INFO] Storing checkpoint...

  256
  75.1
Max memory: 100.8751104
 142.352s  j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 41
Max memory: 0.1801728
1
lr: 0.1

Epoch: [41 | 45] LR: 0.100000
Epoch: [41][0/196]	Time 1.363 (1.363)	Data 0.295 (0.295)	Loss 0.6910 (0.6910)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [41][64/196]	Time 0.799 (0.806)	Data 0.000 (0.005)	Loss 0.6311 (0.6539)	Acc@1 88.672 (86.893)	Acc@5 99.609 (99.441)
Epoch: [41][128/196]	Time 0.800 (0.803)	Data 0.000 (0.002)	Loss 0.6504 (0.6538)	Acc@1 85.938 (86.885)	Acc@5 100.000 (99.470)
Epoch: [41][192/196]	Time 0.798 (0.801)	Data 0.000 (0.002)	Loss 0.6549 (0.6692)	Acc@1 86.719 (86.460)	Acc@5 100.000 (99.419)
Max memory in training epoch: 78.5020416
count0: 431102
1
lr: 0.1

Epoch: [42 | 45] LR: 0.100000
Epoch: [42][0/196]	Time 0.831 (0.831)	Data 0.301 (0.301)	Loss 0.6206 (0.6206)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [42][64/196]	Time 0.762 (0.776)	Data 0.000 (0.005)	Loss 0.7029 (0.6728)	Acc@1 85.547 (86.262)	Acc@5 98.438 (99.429)
Epoch: [42][128/196]	Time 0.797 (0.724)	Data 0.000 (0.002)	Loss 0.7438 (0.6797)	Acc@1 84.375 (85.977)	Acc@5 99.609 (99.446)
Epoch: [42][192/196]	Time 0.797 (0.748)	Data 0.000 (0.002)	Loss 0.7587 (0.6744)	Acc@1 85.156 (86.229)	Acc@5 98.828 (99.441)
Max memory in training epoch: 64.2505216
count0: 431102
1
lr: 0.1

Epoch: [43 | 45] LR: 0.100000
Epoch: [43][0/196]	Time 0.832 (0.832)	Data 0.254 (0.254)	Loss 0.6439 (0.6439)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [43][64/196]	Time 0.798 (0.798)	Data 0.000 (0.004)	Loss 0.6846 (0.6754)	Acc@1 86.719 (86.328)	Acc@5 98.828 (99.429)
Epoch: [43][128/196]	Time 0.797 (0.797)	Data 0.000 (0.002)	Loss 0.6979 (0.6746)	Acc@1 86.719 (86.298)	Acc@5 99.219 (99.440)
Epoch: [43][192/196]	Time 0.797 (0.797)	Data 0.000 (0.001)	Loss 0.6975 (0.6725)	Acc@1 84.766 (86.261)	Acc@5 99.609 (99.449)
Max memory in training epoch: 64.2505216
count0: 431102
1
lr: 0.1

Epoch: [44 | 45] LR: 0.100000
Epoch: [44][0/196]	Time 0.824 (0.824)	Data 0.290 (0.290)	Loss 0.5987 (0.5987)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [44][64/196]	Time 0.797 (0.799)	Data 0.000 (0.005)	Loss 0.6456 (0.6623)	Acc@1 88.281 (86.550)	Acc@5 99.609 (99.459)
Epoch: [44][128/196]	Time 0.798 (0.797)	Data 0.000 (0.002)	Loss 0.7190 (0.6776)	Acc@1 83.984 (86.125)	Acc@5 98.828 (99.397)
Epoch: [44][192/196]	Time 0.757 (0.787)	Data 0.000 (0.002)	Loss 0.6559 (0.6778)	Acc@1 87.500 (86.041)	Acc@5 100.000 (99.411)
Max memory in training epoch: 64.2505216
count0: 431102
1
lr: 0.1

Epoch: [45 | 45] LR: 0.100000
Epoch: [45][0/196]	Time 0.623 (0.623)	Data 0.305 (0.305)	Loss 0.6811 (0.6811)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [45][64/196]	Time 0.798 (0.686)	Data 0.000 (0.005)	Loss 0.5880 (0.6728)	Acc@1 87.891 (86.064)	Acc@5 99.219 (99.405)
Epoch: [45][128/196]	Time 0.761 (0.736)	Data 0.000 (0.002)	Loss 0.6346 (0.6798)	Acc@1 86.719 (85.850)	Acc@5 99.219 (99.425)
Epoch: [45][192/196]	Time 0.595 (0.713)	Data 0.000 (0.002)	Loss 0.7949 (0.6758)	Acc@1 83.594 (86.059)	Acc@5 98.438 (99.423)
Max memory in training epoch: 64.2505216
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 431102
Count: 415800 ; 431102 ; 0.9645049199493392
[INFO] Storing checkpoint...

  256
  77.31
Max memory: 99.3252864
 139.948s  j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 46
Max memory: 0.1741312
1
lr: 0.1

Epoch: [46 | 50] LR: 0.100000
Epoch: [46][0/196]	Time 1.393 (1.393)	Data 0.285 (0.285)	Loss 0.6026 (0.6026)	Acc@1 90.234 (90.234)	Acc@5 100.000 (100.000)
Epoch: [46][64/196]	Time 0.794 (0.803)	Data 0.000 (0.005)	Loss 0.6393 (0.6431)	Acc@1 89.062 (87.266)	Acc@5 99.609 (99.465)
Epoch: [46][128/196]	Time 0.796 (0.800)	Data 0.000 (0.002)	Loss 0.6675 (0.6571)	Acc@1 86.328 (86.831)	Acc@5 100.000 (99.425)
Epoch: [46][192/196]	Time 0.787 (0.798)	Data 0.000 (0.002)	Loss 0.6607 (0.6616)	Acc@1 87.500 (86.650)	Acc@5 99.609 (99.423)
Max memory in training epoch: 77.1259904
count0: 415800
1
lr: 0.1

Epoch: [47 | 50] LR: 0.100000
Epoch: [47][0/196]	Time 0.820 (0.820)	Data 0.293 (0.293)	Loss 0.6004 (0.6004)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [47][64/196]	Time 0.596 (0.761)	Data 0.000 (0.005)	Loss 0.6714 (0.6659)	Acc@1 87.109 (86.556)	Acc@5 98.828 (99.417)
Epoch: [47][128/196]	Time 0.792 (0.721)	Data 0.000 (0.002)	Loss 0.7235 (0.6688)	Acc@1 83.594 (86.371)	Acc@5 99.609 (99.455)
Epoch: [47][192/196]	Time 0.797 (0.746)	Data 0.000 (0.002)	Loss 0.6547 (0.6699)	Acc@1 85.938 (86.363)	Acc@5 99.609 (99.474)
Max memory in training epoch: 63.1515648
count0: 415800
1
lr: 0.1

Epoch: [48 | 50] LR: 0.100000
Epoch: [48][0/196]	Time 0.806 (0.806)	Data 0.291 (0.291)	Loss 0.7722 (0.7722)	Acc@1 83.984 (83.984)	Acc@5 98.047 (98.047)
Epoch: [48][64/196]	Time 0.796 (0.796)	Data 0.000 (0.005)	Loss 0.5668 (0.6659)	Acc@1 89.453 (86.406)	Acc@5 100.000 (99.417)
Epoch: [48][128/196]	Time 0.797 (0.796)	Data 0.000 (0.002)	Loss 0.7147 (0.6670)	Acc@1 86.719 (86.410)	Acc@5 99.219 (99.440)
Epoch: [48][192/196]	Time 0.797 (0.796)	Data 0.000 (0.002)	Loss 0.7598 (0.6648)	Acc@1 79.688 (86.431)	Acc@5 99.219 (99.460)
Max memory in training epoch: 63.1777792
count0: 415800
1
lr: 0.1

Epoch: [49 | 50] LR: 0.100000
Epoch: [49][0/196]	Time 0.830 (0.830)	Data 0.255 (0.255)	Loss 0.7094 (0.7094)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [49][64/196]	Time 0.795 (0.797)	Data 0.000 (0.004)	Loss 0.6831 (0.6642)	Acc@1 85.156 (86.370)	Acc@5 99.219 (99.507)
Epoch: [49][128/196]	Time 0.797 (0.796)	Data 0.000 (0.002)	Loss 0.6168 (0.6597)	Acc@1 87.891 (86.507)	Acc@5 99.609 (99.506)
Epoch: [49][192/196]	Time 0.755 (0.787)	Data 0.000 (0.001)	Loss 0.6632 (0.6630)	Acc@1 88.672 (86.446)	Acc@5 98.438 (99.488)
Max memory in training epoch: 63.1777792
count0: 415800
1
lr: 0.1

Epoch: [50 | 50] LR: 0.100000
Epoch: [50][0/196]	Time 0.620 (0.620)	Data 0.272 (0.272)	Loss 0.6265 (0.6265)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [50][64/196]	Time 0.797 (0.675)	Data 0.000 (0.004)	Loss 0.6210 (0.6463)	Acc@1 87.500 (87.266)	Acc@5 100.000 (99.483)
Epoch: [50][128/196]	Time 0.764 (0.729)	Data 0.000 (0.002)	Loss 0.6094 (0.6551)	Acc@1 88.281 (86.988)	Acc@5 99.609 (99.494)
Epoch: [50][192/196]	Time 0.840 (0.706)	Data 0.000 (0.002)	Loss 0.6909 (0.6570)	Acc@1 83.594 (86.891)	Acc@5 99.609 (99.460)
Max memory in training epoch: 63.1777792
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 415800
Count: 406266 ; 415800 ; 0.9770707070707071
[INFO] Storing checkpoint...

  256
  75.51
Max memory: 97.799424
 139.039s  j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 51
Max memory: 0.1703424
1
lr: 0.1

Epoch: [51 | 55] LR: 0.100000
Epoch: [51][0/196]	Time 1.475 (1.475)	Data 0.286 (0.286)	Loss 0.7155 (0.7155)	Acc@1 84.375 (84.375)	Acc@5 98.828 (98.828)
Epoch: [51][64/196]	Time 0.794 (0.802)	Data 0.000 (0.005)	Loss 0.6739 (0.6374)	Acc@1 85.156 (87.133)	Acc@5 100.000 (99.543)
Epoch: [51][128/196]	Time 0.798 (0.799)	Data 0.000 (0.002)	Loss 0.7346 (0.6529)	Acc@1 82.812 (86.658)	Acc@5 99.609 (99.525)
Epoch: [51][192/196]	Time 0.795 (0.797)	Data 0.000 (0.002)	Loss 0.7026 (0.6586)	Acc@1 85.547 (86.537)	Acc@5 99.609 (99.494)
Max memory in training epoch: 76.345088
count0: 406266
1
lr: 0.1

Epoch: [52 | 55] LR: 0.100000
Epoch: [52][0/196]	Time 0.823 (0.823)	Data 0.278 (0.278)	Loss 0.7843 (0.7843)	Acc@1 82.422 (82.422)	Acc@5 98.828 (98.828)
Epoch: [52][64/196]	Time 0.594 (0.749)	Data 0.000 (0.004)	Loss 0.6487 (0.6600)	Acc@1 85.547 (86.605)	Acc@5 99.219 (99.465)
Epoch: [52][128/196]	Time 0.795 (0.720)	Data 0.000 (0.002)	Loss 0.5637 (0.6621)	Acc@1 89.453 (86.449)	Acc@5 100.000 (99.488)
Epoch: [52][192/196]	Time 0.793 (0.744)	Data 0.000 (0.002)	Loss 0.6564 (0.6605)	Acc@1 86.719 (86.504)	Acc@5 99.609 (99.468)
Max memory in training epoch: 62.8218368
count0: 406266
1
lr: 0.1

Epoch: [53 | 55] LR: 0.100000
Epoch: [53][0/196]	Time 0.826 (0.826)	Data 0.279 (0.279)	Loss 0.7609 (0.7609)	Acc@1 82.031 (82.031)	Acc@5 99.609 (99.609)
Epoch: [53][64/196]	Time 0.794 (0.795)	Data 0.000 (0.004)	Loss 0.7056 (0.6541)	Acc@1 85.156 (86.508)	Acc@5 98.828 (99.465)
Epoch: [53][128/196]	Time 0.793 (0.794)	Data 0.000 (0.002)	Loss 0.6757 (0.6587)	Acc@1 87.109 (86.437)	Acc@5 98.828 (99.449)
Epoch: [53][192/196]	Time 0.793 (0.794)	Data 0.000 (0.002)	Loss 0.6004 (0.6622)	Acc@1 89.453 (86.322)	Acc@5 99.609 (99.472)
Max memory in training epoch: 62.8218368
count0: 406266
1
lr: 0.1

Epoch: [54 | 55] LR: 0.100000
Epoch: [54][0/196]	Time 0.815 (0.815)	Data 0.287 (0.287)	Loss 0.6834 (0.6834)	Acc@1 87.109 (87.109)	Acc@5 99.219 (99.219)
Epoch: [54][64/196]	Time 0.795 (0.794)	Data 0.000 (0.005)	Loss 0.6728 (0.6618)	Acc@1 85.938 (86.466)	Acc@5 99.609 (99.411)
Epoch: [54][128/196]	Time 0.794 (0.793)	Data 0.000 (0.002)	Loss 0.6492 (0.6670)	Acc@1 85.938 (86.313)	Acc@5 98.828 (99.428)
Epoch: [54][192/196]	Time 0.754 (0.785)	Data 0.000 (0.002)	Loss 0.7840 (0.6645)	Acc@1 84.766 (86.433)	Acc@5 98.828 (99.437)
Max memory in training epoch: 62.8218368
count0: 406266
1
lr: 0.1

Epoch: [55 | 55] LR: 0.100000
Epoch: [55][0/196]	Time 0.786 (0.786)	Data 0.258 (0.258)	Loss 0.6982 (0.6982)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [55][64/196]	Time 0.795 (0.663)	Data 0.000 (0.004)	Loss 0.5704 (0.6649)	Acc@1 90.234 (86.508)	Acc@5 100.000 (99.381)
Epoch: [55][128/196]	Time 0.759 (0.721)	Data 0.000 (0.002)	Loss 0.5491 (0.6622)	Acc@1 89.062 (86.661)	Acc@5 99.609 (99.400)
Epoch: [55][192/196]	Time 0.918 (0.701)	Data 0.000 (0.001)	Loss 0.6394 (0.6665)	Acc@1 87.891 (86.526)	Acc@5 99.219 (99.441)
Max memory in training epoch: 62.8218368
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 406266
Count: 400492 ; 406266 ; 0.9857876366715403
[INFO] Storing checkpoint...

  256
  80.13
Max memory: 96.6989312
 137.929s  j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 56
Max memory: 0.1680896
1
lr: 0.1

Epoch: [56 | 60] LR: 0.100000
Epoch: [56][0/196]	Time 1.545 (1.545)	Data 0.295 (0.295)	Loss 0.7658 (0.7658)	Acc@1 80.859 (80.859)	Acc@5 99.219 (99.219)
Epoch: [56][64/196]	Time 0.796 (0.806)	Data 0.000 (0.005)	Loss 0.7671 (0.6284)	Acc@1 82.031 (87.482)	Acc@5 98.828 (99.597)
Epoch: [56][128/196]	Time 0.795 (0.801)	Data 0.000 (0.002)	Loss 0.6637 (0.6378)	Acc@1 84.375 (87.137)	Acc@5 98.828 (99.558)
Epoch: [56][192/196]	Time 0.795 (0.799)	Data 0.000 (0.002)	Loss 0.6238 (0.6489)	Acc@1 86.328 (86.828)	Acc@5 99.609 (99.508)
Max memory in training epoch: 76.1701888
count0: 400492
1
lr: 0.1

Epoch: [57 | 60] LR: 0.100000
Epoch: [57][0/196]	Time 0.825 (0.825)	Data 0.289 (0.289)	Loss 0.6217 (0.6217)	Acc@1 88.281 (88.281)	Acc@5 99.609 (99.609)
Epoch: [57][64/196]	Time 0.596 (0.747)	Data 0.000 (0.005)	Loss 0.7139 (0.6583)	Acc@1 84.375 (86.749)	Acc@5 98.828 (99.483)
Epoch: [57][128/196]	Time 0.795 (0.722)	Data 0.000 (0.002)	Loss 0.6624 (0.6617)	Acc@1 85.547 (86.525)	Acc@5 100.000 (99.473)
Epoch: [57][192/196]	Time 0.795 (0.746)	Data 0.000 (0.002)	Loss 0.7068 (0.6620)	Acc@1 85.938 (86.492)	Acc@5 99.609 (99.452)
Max memory in training epoch: 62.4589312
count0: 400492
1
lr: 0.1

Epoch: [58 | 60] LR: 0.100000
Epoch: [58][0/196]	Time 0.824 (0.824)	Data 0.304 (0.304)	Loss 0.7087 (0.7087)	Acc@1 85.938 (85.938)	Acc@5 98.828 (98.828)
Epoch: [58][64/196]	Time 0.795 (0.796)	Data 0.000 (0.005)	Loss 0.7206 (0.6429)	Acc@1 86.719 (87.284)	Acc@5 99.609 (99.441)
Epoch: [58][128/196]	Time 0.795 (0.794)	Data 0.000 (0.002)	Loss 0.6720 (0.6522)	Acc@1 88.281 (87.034)	Acc@5 99.609 (99.482)
Epoch: [58][192/196]	Time 0.794 (0.794)	Data 0.000 (0.002)	Loss 0.6440 (0.6575)	Acc@1 88.672 (86.794)	Acc@5 98.828 (99.476)
Max memory in training epoch: 62.4589312
count0: 400492
1
lr: 0.1

Epoch: [59 | 60] LR: 0.100000
Epoch: [59][0/196]	Time 0.825 (0.825)	Data 0.254 (0.254)	Loss 0.6836 (0.6836)	Acc@1 84.766 (84.766)	Acc@5 99.609 (99.609)
Epoch: [59][64/196]	Time 0.795 (0.796)	Data 0.000 (0.004)	Loss 0.6389 (0.6479)	Acc@1 86.328 (86.761)	Acc@5 98.828 (99.507)
Epoch: [59][128/196]	Time 0.801 (0.796)	Data 0.000 (0.002)	Loss 0.6342 (0.6488)	Acc@1 87.891 (86.940)	Acc@5 98.828 (99.497)
Epoch: [59][192/196]	Time 0.760 (0.791)	Data 0.000 (0.001)	Loss 0.5937 (0.6560)	Acc@1 89.844 (86.660)	Acc@5 99.609 (99.472)
Max memory in training epoch: 62.4589312
count0: 400492
1
lr: 0.1

Epoch: [60 | 60] LR: 0.100000
Epoch: [60][0/196]	Time 0.785 (0.785)	Data 0.292 (0.292)	Loss 0.6852 (0.6852)	Acc@1 86.328 (86.328)	Acc@5 98.828 (98.828)
Epoch: [60][64/196]	Time 0.804 (0.670)	Data 0.000 (0.005)	Loss 0.6611 (0.6544)	Acc@1 86.719 (87.037)	Acc@5 99.609 (99.543)
Epoch: [60][128/196]	Time 0.766 (0.728)	Data 0.000 (0.002)	Loss 0.6384 (0.6561)	Acc@1 88.672 (86.785)	Acc@5 99.609 (99.503)
Epoch: [60][192/196]	Time 0.803 (0.708)	Data 0.000 (0.002)	Loss 0.6214 (0.6534)	Acc@1 87.891 (86.860)	Acc@5 99.219 (99.522)
Max memory in training epoch: 62.4589312
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 400492
Count: 395582 ; 400492 ; 0.9877400797019665
[INFO] Storing checkpoint...

  256
  81.53
Max memory: 96.0855552
 139.371s  j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 61
Max memory: 0.166144
1
lr: 0.1

Epoch: [61 | 65] LR: 0.100000
Epoch: [61][0/196]	Time 1.560 (1.560)	Data 0.299 (0.299)	Loss 0.6185 (0.6185)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [61][64/196]	Time 0.801 (0.812)	Data 0.000 (0.005)	Loss 0.7066 (0.6270)	Acc@1 85.547 (87.668)	Acc@5 98.828 (99.579)
Epoch: [61][128/196]	Time 0.802 (0.807)	Data 0.000 (0.002)	Loss 0.6903 (0.6401)	Acc@1 85.547 (87.091)	Acc@5 99.219 (99.558)
Epoch: [61][192/196]	Time 0.801 (0.805)	Data 0.000 (0.002)	Loss 0.6178 (0.6481)	Acc@1 87.109 (86.802)	Acc@5 100.000 (99.532)
Max memory in training epoch: 75.6534784
count0: 395582
1
lr: 0.1

Epoch: [62 | 65] LR: 0.100000
Epoch: [62][0/196]	Time 0.819 (0.819)	Data 0.311 (0.311)	Loss 0.6696 (0.6696)	Acc@1 84.375 (84.375)	Acc@5 99.609 (99.609)
Epoch: [62][64/196]	Time 0.599 (0.749)	Data 0.000 (0.005)	Loss 0.6081 (0.6427)	Acc@1 87.109 (86.947)	Acc@5 100.000 (99.489)
Epoch: [62][128/196]	Time 0.802 (0.726)	Data 0.000 (0.003)	Loss 0.6898 (0.6573)	Acc@1 84.375 (86.507)	Acc@5 100.000 (99.503)
Epoch: [62][192/196]	Time 0.800 (0.751)	Data 0.000 (0.002)	Loss 0.7307 (0.6581)	Acc@1 83.984 (86.563)	Acc@5 99.219 (99.496)
Max memory in training epoch: 62.3066112
count0: 395582
1
lr: 0.1

Epoch: [63 | 65] LR: 0.100000
Epoch: [63][0/196]	Time 0.830 (0.830)	Data 0.304 (0.304)	Loss 0.6285 (0.6285)	Acc@1 89.062 (89.062)	Acc@5 99.609 (99.609)
Epoch: [63][64/196]	Time 0.802 (0.803)	Data 0.000 (0.005)	Loss 0.6423 (0.6478)	Acc@1 86.719 (86.833)	Acc@5 100.000 (99.459)
Epoch: [63][128/196]	Time 0.802 (0.801)	Data 0.000 (0.002)	Loss 0.6935 (0.6592)	Acc@1 85.156 (86.498)	Acc@5 100.000 (99.488)
Epoch: [63][192/196]	Time 0.800 (0.801)	Data 0.000 (0.002)	Loss 0.7869 (0.6569)	Acc@1 82.031 (86.573)	Acc@5 98.828 (99.486)
Max memory in training epoch: 62.3066112
count0: 395582
1
lr: 0.1

Epoch: [64 | 65] LR: 0.100000
Epoch: [64][0/196]	Time 0.826 (0.826)	Data 0.289 (0.289)	Loss 0.6792 (0.6792)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [64][64/196]	Time 0.801 (0.801)	Data 0.000 (0.005)	Loss 0.6264 (0.6449)	Acc@1 87.109 (87.001)	Acc@5 99.609 (99.513)
Epoch: [64][128/196]	Time 0.802 (0.799)	Data 0.000 (0.002)	Loss 0.6447 (0.6504)	Acc@1 88.281 (86.797)	Acc@5 99.219 (99.500)
Epoch: [64][192/196]	Time 0.758 (0.794)	Data 0.000 (0.002)	Loss 0.6281 (0.6521)	Acc@1 87.891 (86.824)	Acc@5 99.609 (99.478)
Max memory in training epoch: 62.3066112
count0: 395582
1
lr: 0.1

Epoch: [65 | 65] LR: 0.100000
Epoch: [65][0/196]	Time 0.777 (0.777)	Data 0.303 (0.303)	Loss 0.6205 (0.6205)	Acc@1 88.672 (88.672)	Acc@5 98.828 (98.828)
Epoch: [65][64/196]	Time 0.799 (0.667)	Data 0.000 (0.005)	Loss 0.6255 (0.6403)	Acc@1 87.500 (87.350)	Acc@5 99.609 (99.621)
Epoch: [65][128/196]	Time 0.761 (0.722)	Data 0.000 (0.002)	Loss 0.6004 (0.6425)	Acc@1 87.891 (86.955)	Acc@5 100.000 (99.585)
Epoch: [65][192/196]	Time 0.796 (0.702)	Data 0.000 (0.002)	Loss 0.6793 (0.6473)	Acc@1 84.375 (86.814)	Acc@5 99.219 (99.541)
Max memory in training epoch: 62.3066112
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 395582
Count: 392696 ; 395582 ; 0.9927044203224615
[INFO] Storing checkpoint...

  256
  73.07
Max memory: 95.3221632
 138.293s  j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 66
Max memory: 0.1650176
1
lr: 0.1

Epoch: [66 | 70] LR: 0.100000
Epoch: [66][0/196]	Time 1.559 (1.559)	Data 0.293 (0.293)	Loss 0.7319 (0.7319)	Acc@1 85.547 (85.547)	Acc@5 98.438 (98.438)
Epoch: [66][64/196]	Time 0.798 (0.808)	Data 0.000 (0.005)	Loss 0.5625 (0.6398)	Acc@1 90.625 (87.169)	Acc@5 100.000 (99.507)
Epoch: [66][128/196]	Time 0.798 (0.803)	Data 0.000 (0.002)	Loss 0.7510 (0.6438)	Acc@1 83.984 (87.091)	Acc@5 99.609 (99.522)
Epoch: [66][192/196]	Time 0.798 (0.802)	Data 0.000 (0.002)	Loss 0.6655 (0.6542)	Acc@1 87.109 (86.779)	Acc@5 99.609 (99.482)
Max memory in training epoch: 75.4939392
count0: 392696
1
lr: 0.1

Epoch: [67 | 70] LR: 0.100000
Epoch: [67][0/196]	Time 0.819 (0.819)	Data 0.281 (0.281)	Loss 0.5577 (0.5577)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [67][64/196]	Time 0.598 (0.747)	Data 0.000 (0.004)	Loss 0.6162 (0.6274)	Acc@1 89.844 (87.440)	Acc@5 99.609 (99.591)
Epoch: [67][128/196]	Time 0.798 (0.723)	Data 0.000 (0.002)	Loss 0.6924 (0.6423)	Acc@1 85.938 (87.103)	Acc@5 99.609 (99.516)
Epoch: [67][192/196]	Time 0.799 (0.748)	Data 0.000 (0.002)	Loss 0.6990 (0.6439)	Acc@1 85.938 (87.041)	Acc@5 99.609 (99.498)
Max memory in training epoch: 61.5488
count0: 392696
1
lr: 0.1

Epoch: [68 | 70] LR: 0.100000
Epoch: [68][0/196]	Time 0.837 (0.837)	Data 0.263 (0.263)	Loss 0.5631 (0.5631)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [68][64/196]	Time 0.799 (0.800)	Data 0.000 (0.004)	Loss 0.7093 (0.6600)	Acc@1 85.547 (86.364)	Acc@5 99.219 (99.405)
Epoch: [68][128/196]	Time 0.798 (0.798)	Data 0.000 (0.002)	Loss 0.6050 (0.6524)	Acc@1 89.844 (86.643)	Acc@5 100.000 (99.431)
Epoch: [68][192/196]	Time 0.798 (0.798)	Data 0.000 (0.001)	Loss 0.5628 (0.6563)	Acc@1 89.453 (86.680)	Acc@5 99.609 (99.458)
Max memory in training epoch: 61.5488
count0: 392696
1
lr: 0.1

Epoch: [69 | 70] LR: 0.100000
Epoch: [69][0/196]	Time 0.828 (0.828)	Data 0.288 (0.288)	Loss 0.6173 (0.6173)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [69][64/196]	Time 0.797 (0.798)	Data 0.000 (0.005)	Loss 0.6888 (0.6506)	Acc@1 83.203 (86.809)	Acc@5 99.219 (99.543)
Epoch: [69][128/196]	Time 0.799 (0.797)	Data 0.000 (0.002)	Loss 0.7286 (0.6526)	Acc@1 86.328 (86.822)	Acc@5 99.219 (99.497)
Epoch: [69][192/196]	Time 0.759 (0.794)	Data 0.000 (0.002)	Loss 0.6682 (0.6494)	Acc@1 83.594 (86.879)	Acc@5 99.609 (99.504)
Max memory in training epoch: 61.5488
count0: 392696
1
lr: 0.1

Epoch: [70 | 70] LR: 0.100000
Epoch: [70][0/196]	Time 0.794 (0.794)	Data 0.252 (0.252)	Loss 0.6500 (0.6500)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [70][64/196]	Time 0.798 (0.662)	Data 0.000 (0.004)	Loss 0.6648 (0.6557)	Acc@1 86.719 (86.653)	Acc@5 98.828 (99.423)
Epoch: [70][128/196]	Time 0.762 (0.721)	Data 0.000 (0.002)	Loss 0.5939 (0.6468)	Acc@1 89.844 (87.052)	Acc@5 99.609 (99.482)
Epoch: [70][192/196]	Time 0.797 (0.703)	Data 0.000 (0.001)	Loss 0.6027 (0.6483)	Acc@1 86.719 (87.043)	Acc@5 100.000 (99.476)
Max memory in training epoch: 61.5488
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 392696
Count: 390382 ; 392696 ; 0.994107401144906
[INFO] Storing checkpoint...

  256
  81.96
Max memory: 95.270656
 138.358s  j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 71
Max memory: 0.1641984
1
lr: 0.1

Epoch: [71 | 75] LR: 0.100000
Epoch: [71][0/196]	Time 1.548 (1.548)	Data 0.281 (0.281)	Loss 0.6204 (0.6204)	Acc@1 85.547 (85.547)	Acc@5 100.000 (100.000)
Epoch: [71][64/196]	Time 0.797 (0.808)	Data 0.000 (0.004)	Loss 0.6531 (0.6122)	Acc@1 87.891 (88.053)	Acc@5 100.000 (99.591)
Epoch: [71][128/196]	Time 0.795 (0.803)	Data 0.000 (0.002)	Loss 0.5950 (0.6379)	Acc@1 88.672 (87.161)	Acc@5 99.609 (99.506)
Epoch: [71][192/196]	Time 0.797 (0.801)	Data 0.000 (0.002)	Loss 0.6249 (0.6415)	Acc@1 89.453 (87.041)	Acc@5 99.609 (99.496)
Max memory in training epoch: 74.8631552
count0: 390382
1
lr: 0.1

Epoch: [72 | 75] LR: 0.100000
Epoch: [72][0/196]	Time 0.829 (0.829)	Data 0.251 (0.251)	Loss 0.6189 (0.6189)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [72][64/196]	Time 0.595 (0.741)	Data 0.000 (0.004)	Loss 0.6041 (0.6465)	Acc@1 89.062 (86.803)	Acc@5 100.000 (99.501)
Epoch: [72][128/196]	Time 0.797 (0.721)	Data 0.000 (0.002)	Loss 0.6991 (0.6463)	Acc@1 86.328 (86.655)	Acc@5 98.828 (99.522)
Epoch: [72][192/196]	Time 0.797 (0.746)	Data 0.000 (0.001)	Loss 0.8022 (0.6462)	Acc@1 78.125 (86.779)	Acc@5 98.828 (99.508)
Max memory in training epoch: 60.9688064
count0: 390382
1
lr: 0.1

Epoch: [73 | 75] LR: 0.100000
Epoch: [73][0/196]	Time 0.831 (0.831)	Data 0.249 (0.249)	Loss 0.6566 (0.6566)	Acc@1 85.938 (85.938)	Acc@5 99.609 (99.609)
Epoch: [73][64/196]	Time 0.797 (0.799)	Data 0.000 (0.004)	Loss 0.6340 (0.6318)	Acc@1 89.453 (87.656)	Acc@5 99.609 (99.495)
Epoch: [73][128/196]	Time 0.799 (0.797)	Data 0.000 (0.002)	Loss 0.5730 (0.6406)	Acc@1 89.062 (87.088)	Acc@5 100.000 (99.540)
Epoch: [73][192/196]	Time 0.797 (0.797)	Data 0.000 (0.001)	Loss 0.6757 (0.6478)	Acc@1 85.547 (86.808)	Acc@5 99.609 (99.530)
Max memory in training epoch: 60.9688064
count0: 390382
1
lr: 0.1

Epoch: [74 | 75] LR: 0.100000
Epoch: [74][0/196]	Time 0.822 (0.822)	Data 0.284 (0.284)	Loss 0.6032 (0.6032)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [74][64/196]	Time 0.798 (0.798)	Data 0.000 (0.004)	Loss 0.6187 (0.6391)	Acc@1 89.062 (87.025)	Acc@5 100.000 (99.573)
Epoch: [74][128/196]	Time 0.798 (0.796)	Data 0.000 (0.002)	Loss 0.5841 (0.6421)	Acc@1 88.672 (87.043)	Acc@5 99.219 (99.564)
Epoch: [74][192/196]	Time 0.758 (0.794)	Data 0.000 (0.002)	Loss 0.6413 (0.6453)	Acc@1 87.500 (86.915)	Acc@5 99.609 (99.524)
Max memory in training epoch: 60.9688064
count0: 390382
1
lr: 0.1

Epoch: [75 | 75] LR: 0.100000
Epoch: [75][0/196]	Time 0.779 (0.779)	Data 0.284 (0.284)	Loss 0.6250 (0.6250)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [75][64/196]	Time 0.620 (0.663)	Data 0.000 (0.005)	Loss 0.5474 (0.6374)	Acc@1 91.016 (87.368)	Acc@5 99.219 (99.561)
Epoch: [75][128/196]	Time 0.761 (0.717)	Data 0.000 (0.002)	Loss 0.5950 (0.6453)	Acc@1 87.891 (86.970)	Acc@5 99.609 (99.543)
Epoch: [75][192/196]	Time 0.797 (0.700)	Data 0.000 (0.002)	Loss 0.6191 (0.6495)	Acc@1 87.891 (86.881)	Acc@5 99.609 (99.504)
Max memory in training epoch: 60.9688064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 390382
Count: 387780 ; 390382 ; 0.9933347336711221
[INFO] Storing checkpoint...

  256
  79.25
Max memory: 94.2288384
 137.934s  j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 76
Max memory: 0.1631744
1
lr: 0.1

Epoch: [76 | 80] LR: 0.100000
Epoch: [76][0/196]	Time 1.766 (1.766)	Data 0.291 (0.291)	Loss 0.6031 (0.6031)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [76][64/196]	Time 0.799 (0.813)	Data 0.000 (0.005)	Loss 0.6144 (0.6121)	Acc@1 87.109 (87.933)	Acc@5 99.609 (99.657)
Epoch: [76][128/196]	Time 0.798 (0.806)	Data 0.000 (0.002)	Loss 0.6755 (0.6250)	Acc@1 86.719 (87.455)	Acc@5 99.219 (99.585)
Epoch: [76][192/196]	Time 0.798 (0.803)	Data 0.000 (0.002)	Loss 0.5666 (0.6378)	Acc@1 90.625 (87.124)	Acc@5 99.609 (99.530)
Max memory in training epoch: 74.1385728
count0: 387780
1
lr: 0.1

Epoch: [77 | 80] LR: 0.100000
Epoch: [77][0/196]	Time 0.834 (0.834)	Data 0.294 (0.294)	Loss 0.5908 (0.5908)	Acc@1 89.453 (89.453)	Acc@5 99.609 (99.609)
Epoch: [77][64/196]	Time 0.599 (0.739)	Data 0.000 (0.005)	Loss 0.6253 (0.6258)	Acc@1 86.719 (87.650)	Acc@5 99.609 (99.507)
Epoch: [77][128/196]	Time 0.799 (0.724)	Data 0.000 (0.002)	Loss 0.6574 (0.6392)	Acc@1 84.375 (87.188)	Acc@5 99.609 (99.506)
Epoch: [77][192/196]	Time 0.797 (0.749)	Data 0.000 (0.002)	Loss 0.5912 (0.6419)	Acc@1 88.672 (87.073)	Acc@5 99.219 (99.488)
Max memory in training epoch: 60.5387264
count0: 387780
1
lr: 0.1

Epoch: [78 | 80] LR: 0.100000
Epoch: [78][0/196]	Time 0.824 (0.824)	Data 0.258 (0.258)	Loss 0.5791 (0.5791)	Acc@1 88.672 (88.672)	Acc@5 100.000 (100.000)
Epoch: [78][64/196]	Time 0.800 (0.800)	Data 0.000 (0.004)	Loss 0.5706 (0.6535)	Acc@1 90.234 (86.761)	Acc@5 100.000 (99.435)
Epoch: [78][128/196]	Time 0.799 (0.798)	Data 0.000 (0.002)	Loss 0.6657 (0.6449)	Acc@1 85.547 (87.073)	Acc@5 99.609 (99.525)
Epoch: [78][192/196]	Time 0.798 (0.798)	Data 0.000 (0.001)	Loss 0.7278 (0.6461)	Acc@1 83.984 (86.952)	Acc@5 98.438 (99.522)
Max memory in training epoch: 60.5387264
count0: 387780
1
lr: 0.1

Epoch: [79 | 80] LR: 0.100000
Epoch: [79][0/196]	Time 0.832 (0.832)	Data 0.289 (0.289)	Loss 0.7823 (0.7823)	Acc@1 80.078 (80.078)	Acc@5 99.219 (99.219)
Epoch: [79][64/196]	Time 0.799 (0.799)	Data 0.000 (0.005)	Loss 0.7038 (0.6483)	Acc@1 85.156 (86.809)	Acc@5 99.219 (99.495)
Epoch: [79][128/196]	Time 0.800 (0.797)	Data 0.000 (0.002)	Loss 0.6250 (0.6433)	Acc@1 85.938 (86.840)	Acc@5 99.609 (99.485)
Epoch: [79][192/196]	Time 0.759 (0.796)	Data 0.000 (0.002)	Loss 0.6781 (0.6425)	Acc@1 85.938 (86.943)	Acc@5 99.219 (99.488)
Max memory in training epoch: 60.5387264
count0: 387780
1
lr: 0.1

Epoch: [80 | 80] LR: 0.100000
Epoch: [80][0/196]	Time 0.786 (0.786)	Data 0.300 (0.300)	Loss 0.6692 (0.6692)	Acc@1 86.328 (86.328)	Acc@5 99.609 (99.609)
Epoch: [80][64/196]	Time 0.593 (0.665)	Data 0.000 (0.005)	Loss 0.6356 (0.6413)	Acc@1 87.891 (87.091)	Acc@5 99.219 (99.495)
Epoch: [80][128/196]	Time 0.761 (0.716)	Data 0.000 (0.002)	Loss 0.5712 (0.6436)	Acc@1 88.672 (87.094)	Acc@5 98.828 (99.464)
Epoch: [80][192/196]	Time 0.798 (0.699)	Data 0.000 (0.002)	Loss 0.6710 (0.6431)	Acc@1 85.156 (87.117)	Acc@5 100.000 (99.504)
Max memory in training epoch: 60.5387264
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 387780
Count: 384026 ; 387780 ; 0.9903192531847955
[INFO] Storing checkpoint...

  256
  82.43
Max memory: 93.5407104
 137.701s  j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 81
Max memory: 0.1616384
1
lr: 0.1

Epoch: [81 | 85] LR: 0.100000
Epoch: [81][0/196]	Time 1.816 (1.816)	Data 0.296 (0.296)	Loss 0.6369 (0.6369)	Acc@1 87.891 (87.891)	Acc@5 99.609 (99.609)
Epoch: [81][64/196]	Time 0.796 (0.809)	Data 0.000 (0.005)	Loss 0.6030 (0.6090)	Acc@1 88.281 (88.185)	Acc@5 100.000 (99.627)
Epoch: [81][128/196]	Time 0.811 (0.803)	Data 0.000 (0.002)	Loss 0.7203 (0.6248)	Acc@1 84.375 (87.551)	Acc@5 100.000 (99.597)
Epoch: [81][192/196]	Time 0.797 (0.801)	Data 0.000 (0.002)	Loss 0.6598 (0.6296)	Acc@1 86.328 (87.445)	Acc@5 98.828 (99.532)
Max memory in training epoch: 73.8446848
count0: 384026
1
lr: 0.1

Epoch: [82 | 85] LR: 0.100000
Epoch: [82][0/196]	Time 0.821 (0.821)	Data 0.286 (0.286)	Loss 0.5686 (0.5686)	Acc@1 90.234 (90.234)	Acc@5 99.609 (99.609)
Epoch: [82][64/196]	Time 0.595 (0.733)	Data 0.000 (0.005)	Loss 0.6616 (0.6404)	Acc@1 86.328 (86.983)	Acc@5 100.000 (99.573)
Epoch: [82][128/196]	Time 0.797 (0.722)	Data 0.000 (0.002)	Loss 0.6238 (0.6402)	Acc@1 86.719 (86.952)	Acc@5 99.609 (99.570)
Epoch: [82][192/196]	Time 0.795 (0.746)	Data 0.000 (0.002)	Loss 0.6054 (0.6455)	Acc@1 87.500 (86.709)	Acc@5 100.000 (99.516)
Max memory in training epoch: 60.375296
count0: 384026
1
lr: 0.1

Epoch: [83 | 85] LR: 0.100000
Epoch: [83][0/196]	Time 0.841 (0.841)	Data 0.280 (0.280)	Loss 0.5801 (0.5801)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [83][64/196]	Time 0.796 (0.798)	Data 0.000 (0.004)	Loss 0.6787 (0.6242)	Acc@1 85.938 (87.662)	Acc@5 98.828 (99.525)
Epoch: [83][128/196]	Time 0.796 (0.796)	Data 0.000 (0.002)	Loss 0.5973 (0.6260)	Acc@1 87.891 (87.548)	Acc@5 100.000 (99.555)
Epoch: [83][192/196]	Time 0.796 (0.796)	Data 0.000 (0.002)	Loss 0.6431 (0.6322)	Acc@1 87.891 (87.399)	Acc@5 100.000 (99.539)
Max memory in training epoch: 60.375296
count0: 384026
1
lr: 0.1

Epoch: [84 | 85] LR: 0.100000
Epoch: [84][0/196]	Time 0.827 (0.827)	Data 0.302 (0.302)	Loss 0.6093 (0.6093)	Acc@1 86.719 (86.719)	Acc@5 99.609 (99.609)
Epoch: [84][64/196]	Time 0.796 (0.797)	Data 0.000 (0.005)	Loss 0.6639 (0.6476)	Acc@1 84.766 (86.953)	Acc@5 98.828 (99.513)
Epoch: [84][128/196]	Time 0.796 (0.795)	Data 0.000 (0.002)	Loss 0.5676 (0.6480)	Acc@1 90.625 (86.910)	Acc@5 99.609 (99.519)
Epoch: [84][192/196]	Time 0.757 (0.794)	Data 0.000 (0.002)	Loss 0.5747 (0.6482)	Acc@1 88.672 (86.826)	Acc@5 99.609 (99.522)
Max memory in training epoch: 60.375296
count0: 384026
1
lr: 0.1

Epoch: [85 | 85] LR: 0.100000
Epoch: [85][0/196]	Time 0.769 (0.769)	Data 0.304 (0.304)	Loss 0.5085 (0.5085)	Acc@1 91.797 (91.797)	Acc@5 100.000 (100.000)
Epoch: [85][64/196]	Time 0.595 (0.672)	Data 0.000 (0.005)	Loss 0.5986 (0.6261)	Acc@1 87.891 (87.740)	Acc@5 99.609 (99.549)
Epoch: [85][128/196]	Time 0.759 (0.714)	Data 0.000 (0.002)	Loss 0.6876 (0.6379)	Acc@1 85.938 (87.346)	Acc@5 99.609 (99.494)
Epoch: [85][192/196]	Time 0.796 (0.697)	Data 0.000 (0.002)	Loss 0.5653 (0.6420)	Acc@1 92.188 (87.144)	Acc@5 99.609 (99.482)
Max memory in training epoch: 60.375296
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...

 RM:  module.conv21.weight

 RM:  module.conv22.weight
numoFStages: 3
count0: 384026
Count: 382228 ; 384026 ; 0.9953180253420342
[INFO] Storing checkpoint...

  256
  79.13
Max memory: 92.6984704
 137.377s  j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 86
Max memory: 0.1603072
1
lr: 0.1

Epoch: [86 | 90] LR: 0.100000
Epoch: [86][0/196]	Time 1.723 (1.723)	Data 0.260 (0.260)	Loss 0.6265 (0.6265)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [86][64/196]	Time 0.755 (0.766)	Data 0.000 (0.004)	Loss 0.7184 (0.6205)	Acc@1 83.594 (87.909)	Acc@5 99.219 (99.609)
Epoch: [86][128/196]	Time 0.747 (0.759)	Data 0.000 (0.002)	Loss 0.6871 (0.6355)	Acc@1 83.984 (87.294)	Acc@5 100.000 (99.594)
Epoch: [86][192/196]	Time 0.756 (0.757)	Data 0.000 (0.001)	Loss 0.6385 (0.6371)	Acc@1 86.328 (87.146)	Acc@5 99.219 (99.567)
Max memory in training epoch: 72.0073216
count0: 382228
1
lr: 0.1

Epoch: [87 | 90] LR: 0.100000
Epoch: [87][0/196]	Time 0.651 (0.651)	Data 0.265 (0.265)	Loss 0.6109 (0.6109)	Acc@1 87.891 (87.891)	Acc@5 100.000 (100.000)
Epoch: [87][64/196]	Time 0.713 (0.728)	Data 0.000 (0.004)	Loss 0.6024 (0.6410)	Acc@1 90.625 (87.025)	Acc@5 99.609 (99.441)
Epoch: [87][128/196]	Time 0.751 (0.676)	Data 0.000 (0.002)	Loss 0.6991 (0.6328)	Acc@1 86.328 (87.315)	Acc@5 99.609 (99.528)
Epoch: [87][192/196]	Time 0.753 (0.701)	Data 0.000 (0.001)	Loss 0.7077 (0.6382)	Acc@1 84.766 (87.134)	Acc@5 100.000 (99.490)
Max memory in training epoch: 58.5752064
count0: 382228
1
lr: 0.1

Epoch: [88 | 90] LR: 0.100000
Epoch: [88][0/196]	Time 0.785 (0.785)	Data 0.284 (0.284)	Loss 0.5202 (0.5202)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [88][64/196]	Time 0.757 (0.752)	Data 0.000 (0.004)	Loss 0.6877 (0.6336)	Acc@1 83.984 (87.386)	Acc@5 100.000 (99.579)
Epoch: [88][128/196]	Time 0.747 (0.751)	Data 0.000 (0.002)	Loss 0.7305 (0.6423)	Acc@1 83.203 (87.019)	Acc@5 99.609 (99.519)
Epoch: [88][192/196]	Time 0.758 (0.751)	Data 0.000 (0.002)	Loss 0.6634 (0.6413)	Acc@1 86.719 (86.943)	Acc@5 99.609 (99.496)
Max memory in training epoch: 58.5752064
count0: 382228
1
lr: 0.1

Epoch: [89 | 90] LR: 0.100000
Epoch: [89][0/196]	Time 0.770 (0.770)	Data 0.299 (0.299)	Loss 0.5756 (0.5756)	Acc@1 91.406 (91.406)	Acc@5 99.609 (99.609)
Epoch: [89][64/196]	Time 0.745 (0.751)	Data 0.000 (0.005)	Loss 0.5707 (0.6271)	Acc@1 89.844 (87.674)	Acc@5 99.609 (99.555)
Epoch: [89][128/196]	Time 0.753 (0.752)	Data 0.000 (0.002)	Loss 0.6368 (0.6413)	Acc@1 85.547 (87.106)	Acc@5 100.000 (99.503)
Epoch: [89][192/196]	Time 0.749 (0.750)	Data 0.000 (0.002)	Loss 0.6783 (0.6418)	Acc@1 87.500 (87.047)	Acc@5 99.609 (99.518)
Max memory in training epoch: 58.5752064
count0: 382228
1
lr: 0.1

Epoch: [90 | 90] LR: 0.100000
Epoch: [90][0/196]	Time 0.778 (0.778)	Data 0.265 (0.265)	Loss 0.6379 (0.6379)	Acc@1 87.109 (87.109)	Acc@5 100.000 (100.000)
Epoch: [90][64/196]	Time 0.713 (0.739)	Data 0.000 (0.004)	Loss 0.6114 (0.6226)	Acc@1 87.500 (87.752)	Acc@5 100.000 (99.633)
Epoch: [90][128/196]	Time 0.609 (0.676)	Data 0.000 (0.002)	Loss 0.6315 (0.6311)	Acc@1 89.062 (87.467)	Acc@5 98.828 (99.546)
Epoch: [90][192/196]	Time 0.717 (0.694)	Data 0.000 (0.001)	Loss 0.6575 (0.6359)	Acc@1 88.281 (87.239)	Acc@5 99.609 (99.504)
Max memory in training epoch: 58.5752064
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 382228
Count: 380784 ; 382228 ; 0.9962221501302887
[INFO] Storing checkpoint...

  256
  76.73
Max memory: 90.1164544
 136.335s  j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 91
Max memory: 0.1597952
1
lr: 0.1

Epoch: [91 | 95] LR: 0.100000
Epoch: [91][0/196]	Time 1.721 (1.721)	Data 0.332 (0.332)	Loss 0.6903 (0.6903)	Acc@1 86.328 (86.328)	Acc@5 99.219 (99.219)
Epoch: [91][64/196]	Time 0.758 (0.767)	Data 0.000 (0.005)	Loss 0.6064 (0.6106)	Acc@1 88.672 (88.023)	Acc@5 100.000 (99.639)
Epoch: [91][128/196]	Time 0.757 (0.759)	Data 0.000 (0.003)	Loss 0.6262 (0.6215)	Acc@1 89.453 (87.706)	Acc@5 100.000 (99.576)
Epoch: [91][192/196]	Time 0.748 (0.756)	Data 0.000 (0.002)	Loss 0.6155 (0.6302)	Acc@1 87.500 (87.265)	Acc@5 100.000 (99.553)
Max memory in training epoch: 71.6990976
count0: 380784
1
lr: 0.1

Epoch: [92 | 95] LR: 0.100000
Epoch: [92][0/196]	Time 0.775 (0.775)	Data 0.294 (0.294)	Loss 0.5790 (0.5790)	Acc@1 87.500 (87.500)	Acc@5 99.609 (99.609)
Epoch: [92][64/196]	Time 0.743 (0.751)	Data 0.000 (0.005)	Loss 0.5644 (0.6374)	Acc@1 91.797 (87.266)	Acc@5 99.609 (99.519)
Epoch: [92][128/196]	Time 0.562 (0.735)	Data 0.000 (0.002)	Loss 0.5884 (0.6373)	Acc@1 89.062 (87.125)	Acc@5 100.000 (99.528)
Epoch: [92][192/196]	Time 0.742 (0.700)	Data 0.000 (0.002)	Loss 0.6390 (0.6408)	Acc@1 87.500 (86.994)	Acc@5 99.609 (99.522)
Max memory in training epoch: 58.2585856
count0: 380784
1
lr: 0.010000000000000002

Epoch: [93 | 95] LR: 0.010000
Epoch: [93][0/196]	Time 0.770 (0.770)	Data 0.292 (0.292)	Loss 0.7031 (0.7031)	Acc@1 87.109 (87.109)	Acc@5 99.609 (99.609)
Epoch: [93][64/196]	Time 0.752 (0.752)	Data 0.000 (0.005)	Loss 0.4412 (0.5526)	Acc@1 93.750 (90.379)	Acc@5 100.000 (99.688)
Epoch: [93][128/196]	Time 0.746 (0.751)	Data 0.000 (0.002)	Loss 0.4794 (0.5288)	Acc@1 93.359 (91.209)	Acc@5 100.000 (99.758)
Epoch: [93][192/196]	Time 0.757 (0.751)	Data 0.000 (0.002)	Loss 0.4884 (0.5111)	Acc@1 94.141 (91.694)	Acc@5 100.000 (99.785)
Max memory in training epoch: 58.2585856
count0: 380784
1
lr: 0.010000000000000002

Epoch: [94 | 95] LR: 0.010000
Epoch: [94][0/196]	Time 0.776 (0.776)	Data 0.292 (0.292)	Loss 0.4348 (0.4348)	Acc@1 94.141 (94.141)	Acc@5 99.609 (99.609)
Epoch: [94][64/196]	Time 0.758 (0.752)	Data 0.000 (0.005)	Loss 0.4311 (0.4651)	Acc@1 94.922 (93.107)	Acc@5 100.000 (99.856)
Epoch: [94][128/196]	Time 0.755 (0.752)	Data 0.000 (0.002)	Loss 0.4066 (0.4588)	Acc@1 96.094 (93.253)	Acc@5 100.000 (99.836)
Epoch: [94][192/196]	Time 0.746 (0.752)	Data 0.000 (0.002)	Loss 0.4548 (0.4569)	Acc@1 92.969 (93.284)	Acc@5 100.000 (99.838)
Max memory in training epoch: 58.2585856
count0: 380784
1
lr: 0.010000000000000002

Epoch: [95 | 95] LR: 0.010000
Epoch: [95][0/196]	Time 0.820 (0.820)	Data 0.302 (0.302)	Loss 0.4101 (0.4101)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [95][64/196]	Time 0.755 (0.753)	Data 0.000 (0.005)	Loss 0.4424 (0.4306)	Acc@1 94.141 (94.231)	Acc@5 100.000 (99.868)
Epoch: [95][128/196]	Time 0.712 (0.744)	Data 0.000 (0.002)	Loss 0.4622 (0.4319)	Acc@1 94.141 (94.189)	Acc@5 99.219 (99.864)
Epoch: [95][192/196]	Time 0.751 (0.701)	Data 0.000 (0.002)	Loss 0.4557 (0.4326)	Acc@1 91.797 (94.048)	Acc@5 100.000 (99.866)
Max memory in training epoch: 58.2585856
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 380784
Count: 380206 ; 380784 ; 0.9984820790789529
[INFO] Storing checkpoint...

  256
  91.47
Max memory: 89.7339904
 137.944s  j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 96
Max memory: 0.1595904
1
lr: 0.010000000000000002

Epoch: [96 | 100] LR: 0.010000
Epoch: [96][0/196]	Time 1.358 (1.358)	Data 0.305 (0.305)	Loss 0.3930 (0.3930)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [96][64/196]	Time 0.748 (0.737)	Data 0.000 (0.005)	Loss 0.4097 (0.4091)	Acc@1 94.922 (94.669)	Acc@5 100.000 (99.910)
Epoch: [96][128/196]	Time 0.758 (0.744)	Data 0.000 (0.002)	Loss 0.4441 (0.4149)	Acc@1 92.969 (94.401)	Acc@5 99.609 (99.879)
Epoch: [96][192/196]	Time 0.754 (0.746)	Data 0.000 (0.002)	Loss 0.4037 (0.4159)	Acc@1 93.750 (94.357)	Acc@5 99.609 (99.889)
Max memory in training epoch: 71.6724736
count0: 380206
1
lr: 0.010000000000000002

Epoch: [97 | 100] LR: 0.010000
Epoch: [97][0/196]	Time 0.778 (0.778)	Data 0.290 (0.290)	Loss 0.3681 (0.3681)	Acc@1 95.703 (95.703)	Acc@5 100.000 (100.000)
Epoch: [97][64/196]	Time 0.758 (0.752)	Data 0.000 (0.005)	Loss 0.3966 (0.3958)	Acc@1 94.531 (95.024)	Acc@5 100.000 (99.892)
Epoch: [97][128/196]	Time 0.714 (0.750)	Data 0.000 (0.002)	Loss 0.4144 (0.3965)	Acc@1 93.359 (94.889)	Acc@5 100.000 (99.909)
Epoch: [97][192/196]	Time 0.565 (0.718)	Data 0.000 (0.002)	Loss 0.3649 (0.3981)	Acc@1 95.703 (94.798)	Acc@5 100.000 (99.905)
Max memory in training epoch: 58.3233024
count0: 380206
1
lr: 0.010000000000000002

Epoch: [98 | 100] LR: 0.010000
Epoch: [98][0/196]	Time 0.600 (0.600)	Data 0.296 (0.296)	Loss 0.3691 (0.3691)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [98][64/196]	Time 0.746 (0.723)	Data 0.000 (0.005)	Loss 0.4045 (0.3854)	Acc@1 93.750 (95.228)	Acc@5 100.000 (99.892)
Epoch: [98][128/196]	Time 0.751 (0.737)	Data 0.000 (0.002)	Loss 0.3585 (0.3877)	Acc@1 96.484 (95.104)	Acc@5 100.000 (99.894)
Epoch: [98][192/196]	Time 0.741 (0.741)	Data 0.000 (0.002)	Loss 0.3902 (0.3872)	Acc@1 95.703 (95.051)	Acc@5 100.000 (99.901)
Max memory in training epoch: 58.3233024
count0: 380206
1
lr: 0.010000000000000002

Epoch: [99 | 100] LR: 0.010000
Epoch: [99][0/196]	Time 0.770 (0.770)	Data 0.313 (0.313)	Loss 0.3593 (0.3593)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [99][64/196]	Time 0.742 (0.750)	Data 0.000 (0.005)	Loss 0.3167 (0.3794)	Acc@1 97.656 (95.000)	Acc@5 100.000 (99.916)
Epoch: [99][128/196]	Time 0.618 (0.693)	Data 0.000 (0.003)	Loss 0.3545 (0.3767)	Acc@1 94.922 (95.173)	Acc@5 100.000 (99.906)
Epoch: [99][192/196]	Time 0.378 (0.603)	Data 0.000 (0.002)	Loss 0.3366 (0.3759)	Acc@1 96.875 (95.175)	Acc@5 100.000 (99.915)
Max memory in training epoch: 58.3233024
count0: 380206
1
lr: 0.010000000000000002

Epoch: [100 | 100] LR: 0.010000
Epoch: [100][0/196]	Time 0.314 (0.314)	Data 0.268 (0.268)	Loss 0.3538 (0.3538)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [100][64/196]	Time 1.150 (0.734)	Data 0.000 (0.004)	Loss 0.3143 (0.3670)	Acc@1 97.656 (95.373)	Acc@5 100.000 (99.940)
Epoch: [100][128/196]	Time 1.144 (0.938)	Data 0.000 (0.002)	Loss 0.3641 (0.3655)	Acc@1 95.312 (95.440)	Acc@5 100.000 (99.942)
Epoch: [100][192/196]	Time 1.141 (1.006)	Data 0.000 (0.002)	Loss 0.3872 (0.3671)	Acc@1 94.922 (95.389)	Acc@5 100.000 (99.931)
Max memory in training epoch: 58.3233024
[INFO] Force the sparse filters to zero...
[INFO] Squeezing the sparse model to dense one...
numoFStages: 3
count0: 380206
Count: 379772 ; 380206 ; 0.9988585135426584
[INFO] Storing checkpoint...

  256
  91.54
Max memory: 89.840896
 197.879s  j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 493, in forward
    x = self.module_list[j](_x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 19.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
==> Resuming from checkpoint..
Startepoche: 101
Max memory: 0.1594368
1
lr: 0.010000000000000002

Epoch: [101 | 105] LR: 0.010000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 555, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 472.29 MiB already allocated; 17.94 MiB free; 480.00 MiB reserved in total by PyTorch)
Thres 0.0001
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
numoFStages: 3
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
1
lr: 0.1

Epoch: [1 | 5] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 529, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 349, in forward
    return self._conv_forward(input, self.weight)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 346, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 453.95 MiB already allocated; 19.94 MiB free; 478.00 MiB reserved in total by PyTorch)
j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres41_13/model.nn'
Thres 0.00001
j: 0 bis 5
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
numoFStages: 3
N2N(
  (module_list): ModuleList(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (13): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (15): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (17): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (19): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (23): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (24): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (27): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (28): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (34): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (35): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (37): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (38): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (39): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (40): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (41): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (43): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (44): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (45): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (46): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (47): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (48): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (49): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (50): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (51): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (54): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (55): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (56): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (57): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (58): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (59): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (60): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (61): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (62): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (63): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (64): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (65): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (66): AdaptiveAvgPool2d(output_size=(1, 1))
    (67): Linear(in_features=64, out_features=10, bias=True)
  )
  (relu): ReLU(inplace=True)
)
device count: 1
Startepoche: 1
Max memory: 0.202496
1
lr: 0.1

Epoch: [1 | 5] LR: 0.100000
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 420, in main
    optimizer, epoch, use_cuda)
  File "main.py", line 595, in train
    outputs = model.forward(inputs)
  File "/home/jessica.buehler/MA_Source/src/n2n.py", line 537, in forward
    x = self.module_list[j](x)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 601.96 MiB already allocated; 13.94 MiB free; 606.00 MiB reserved in total by PyTorch)
j: 6 bis 10
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 11 bis 15
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 16 bis 20
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 21 bis 25
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 26 bis 30
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 31 bis 35
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 36 bis 40
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 41 bis 45
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 46 bis 50
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 51 bis 55
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 56 bis 60
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 61 bis 65
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 66 bis 70
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 71 bis 75
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 76 bis 80
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 81 bis 85
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 86 bis 90
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 91 bis 95
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 96 bis 100
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 101 bis 105
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 106 bis 110
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 111 bis 115
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 116 bis 120
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 121 bis 125
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 126 bis 130
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 131 bis 135
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 136 bis 140
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 141 bis 145
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 146 bis 150
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 151 bis 155
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 156 bis 160
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 161 bis 165
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 166 bis 170
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 171 bis 175
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
j: 176 bis 180
no display found. Using non-interactive Agg backend
[5, 5, 5]
Files already downloaded and verified
Traceback (most recent call last):
  File "main.py", line 882, in <module>
    main()
  File "main.py", line 313, in main
    model = torch.load(args.pathToModell)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 584, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 234, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/jessica.buehler/venv/lib/python3.6/site-packages/torch/serialization.py", line 215, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './output/experimente2/prune_thres00001_13/model.nn'
