digraph {
	graph [size="60.3,60.3"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	139900011010256 [label=AddmmBackward fillcolor=darkolivegreen1]
	139900011009528 -> 139900011010256
	139900011009528 [label="module_list.59.bias
 (10)" fillcolor=lightblue]
	139900011010816 -> 139900011010256
	139900011010816 [label=ViewBackward]
	139900011009584 -> 139900011010816
	139900011009584 [label=ViewBackward]
	139900011009248 -> 139900011009584
	139900011009248 [label=MeanBackward1]
	139900011008576 -> 139900011009248
	139900011008576 [label=ViewBackward]
	139900011010480 -> 139900011008576
	139900011010480 [label=ReluBackward1]
	139900011011320 -> 139900011010480
	139900011011320 [label=AddBackward0]
	139900011010592 -> 139900011011320
	139900011010592 [label=ReluBackward1]
	139900011011376 -> 139900011010592
	139900011011376 [label=AddBackward0]
	139900011011488 -> 139900011011376
	139900011011488 [label=ReluBackward1]
	139900011011656 -> 139900011011488
	139900011011656 [label=AddBackward0]
	139900011011768 -> 139900011011656
	139900011011768 [label=ReluBackward1]
	139900011011936 -> 139900011011768
	139900011011936 [label=AddBackward0]
	139900011012048 -> 139900011011936
	139900011012048 [label=ReluBackward1]
	139898685087928 -> 139900011012048
	139898685087928 [label=CudnnBatchNormBackward]
	139898685088040 -> 139898685087928
	139898685088040 [label=CudnnConvolutionBackward]
	139898685088264 -> 139898685088040
	139898685088264 [label=ReluBackward1]
	139898685088432 -> 139898685088264
	139898685088432 [label=CudnnBatchNormBackward]
	139898685088544 -> 139898685088432
	139898685088544 [label=CudnnConvolutionBackward]
	139898685088768 -> 139898685088544
	139898685088768 [label=ReluBackward1]
	139898685088936 -> 139898685088768
	139898685088936 [label=AddBackward0]
	139898685089048 -> 139898685088936
	139898685089048 [label=ReluBackward1]
	139898685089216 -> 139898685089048
	139898685089216 [label=AddBackward0]
	139898685089328 -> 139898685089216
	139898685089328 [label=ReluBackward1]
	139898685089496 -> 139898685089328
	139898685089496 [label=AddBackward0]
	139898685089608 -> 139898685089496
	139898685089608 [label=ReluBackward1]
	139898685089776 -> 139898685089608
	139898685089776 [label=AddBackward0]
	139898685089888 -> 139898685089776
	139898685089888 [label=ReluBackward1]
	139898685090056 -> 139898685089888
	139898685090056 [label=CudnnBatchNormBackward]
	139898685090168 -> 139898685090056
	139898685090168 [label=CudnnConvolutionBackward]
	139898685090392 -> 139898685090168
	139898685090392 [label=ReluBackward1]
	139898685090560 -> 139898685090392
	139898685090560 [label=CudnnBatchNormBackward]
	139898685090672 -> 139898685090560
	139898685090672 [label=CudnnConvolutionBackward]
	139898685090896 -> 139898685090672
	139898685090896 [label=ReluBackward1]
	139898685091064 -> 139898685090896
	139898685091064 [label=AddBackward0]
	139898685091176 -> 139898685091064
	139898685091176 [label=ReluBackward1]
	139898685091344 -> 139898685091176
	139898685091344 [label=AddBackward0]
	139898685091456 -> 139898685091344
	139898685091456 [label=ReluBackward1]
	139898685091624 -> 139898685091456
	139898685091624 [label=AddBackward0]
	139898685091736 -> 139898685091624
	139898685091736 [label=ReluBackward1]
	139898685096064 -> 139898685091736
	139898685096064 [label=AddBackward0]
	139898685096176 -> 139898685096064
	139898685096176 [label=ReluBackward1]
	139898685096344 -> 139898685096176
	139898685096344 [label=AddBackward0]
	139898685096456 -> 139898685096344
	139898685096456 [label=ReluBackward1]
	139898685096624 -> 139898685096456
	139898685096624 [label=CudnnBatchNormBackward]
	139898685096736 -> 139898685096624
	139898685096736 [label=CudnnConvolutionBackward]
	139898685096960 -> 139898685096736
	139898685096960 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	139898685096792 -> 139898685096624
	139898685096792 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	139898685096848 -> 139898685096624
	139898685096848 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	139898685096512 -> 139898685096344
	139898685096512 [label=CudnnBatchNormBackward]
	139898685096680 -> 139898685096512
	139898685096680 [label=CudnnConvolutionBackward]
	139898685097072 -> 139898685096680
	139898685097072 [label=ReluBackward1]
	139898685097296 -> 139898685097072
	139898685097296 [label=CudnnBatchNormBackward]
	139898685097408 -> 139898685097296
	139898685097408 [label=CudnnConvolutionBackward]
	139898685096456 -> 139898685097408
	139898685097632 -> 139898685097408
	139898685097632 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139898685097464 -> 139898685097296
	139898685097464 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	139898685097520 -> 139898685097296
	139898685097520 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	139898685097184 -> 139898685096680
	139898685097184 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139898685096904 -> 139898685096512
	139898685096904 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	139898685097016 -> 139898685096512
	139898685097016 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	139898685096232 -> 139898685096064
	139898685096232 [label=CudnnBatchNormBackward]
	139898685096400 -> 139898685096232
	139898685096400 [label=CudnnConvolutionBackward]
	139898685097576 -> 139898685096400
	139898685097576 [label=ReluBackward1]
	139898685097800 -> 139898685097576
	139898685097800 [label=CudnnBatchNormBackward]
	139898685097744 -> 139898685097800
	139898685097744 [label=CudnnConvolutionBackward]
	139898685096176 -> 139898685097744
	139898685098080 -> 139898685097744
	139898685098080 [label="module_list.6.weight
 (15, 16, 3, 3)" fillcolor=lightblue]
	139898685097912 -> 139898685097800
	139898685097912 [label="module_list.7.weight
 (15)" fillcolor=lightblue]
	139898685097968 -> 139898685097800
	139898685097968 [label="module_list.7.bias
 (15)" fillcolor=lightblue]
	139898685097688 -> 139898685096400
	139898685097688 [label="module_list.8.weight
 (16, 15, 3, 3)" fillcolor=lightblue]
	139898685096568 -> 139898685096232
	139898685096568 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	139898685097128 -> 139898685096232
	139898685097128 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	139898685091792 -> 139898685091624
	139898685091792 [label=CudnnBatchNormBackward]
	139898685096120 -> 139898685091792
	139898685096120 [label=CudnnConvolutionBackward]
	139898685098024 -> 139898685096120
	139898685098024 [label=ReluBackward1]
	139898685098248 -> 139898685098024
	139898685098248 [label=CudnnBatchNormBackward]
	139898685098192 -> 139898685098248
	139898685098192 [label=CudnnConvolutionBackward]
	139898685091736 -> 139898685098192
	139898685098528 -> 139898685098192
	139898685098528 [label="module_list.10.weight
 (11, 16, 3, 3)" fillcolor=lightblue]
	139898685098360 -> 139898685098248
	139898685098360 [label="module_list.11.weight
 (11)" fillcolor=lightblue]
	139898685098416 -> 139898685098248
	139898685098416 [label="module_list.11.bias
 (11)" fillcolor=lightblue]
	139898685098136 -> 139898685096120
	139898685098136 [label="module_list.12.weight
 (16, 11, 3, 3)" fillcolor=lightblue]
	139898685096288 -> 139898685091792
	139898685096288 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	139898685097240 -> 139898685091792
	139898685097240 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	139898685091512 -> 139898685091344
	139898685091512 [label=CudnnBatchNormBackward]
	139898685091680 -> 139898685091512
	139898685091680 [label=CudnnConvolutionBackward]
	139898685098472 -> 139898685091680
	139898685098472 [label=ReluBackward1]
	139898685098696 -> 139898685098472
	139898685098696 [label=CudnnBatchNormBackward]
	139898685098640 -> 139898685098696
	139898685098640 [label=CudnnConvolutionBackward]
	139898685091456 -> 139898685098640
	139898685098976 -> 139898685098640
	139898685098976 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139898685098808 -> 139898685098696
	139898685098808 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	139898685098864 -> 139898685098696
	139898685098864 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	139898685098584 -> 139898685091680
	139898685098584 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139898685096008 -> 139898685091512
	139898685096008 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	139898685097352 -> 139898685091512
	139898685097352 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	139898685091232 -> 139898685091064
	139898685091232 [label=CudnnBatchNormBackward]
	139898685091400 -> 139898685091232
	139898685091400 [label=CudnnConvolutionBackward]
	139898685098920 -> 139898685091400
	139898685098920 [label=ReluBackward1]
	139898685099144 -> 139898685098920
	139898685099144 [label=CudnnBatchNormBackward]
	139898685099088 -> 139898685099144
	139898685099088 [label=CudnnConvolutionBackward]
	139898685091176 -> 139898685099088
	139898685099424 -> 139898685099088
	139898685099424 [label="module_list.18.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	139898685099256 -> 139898685099144
	139898685099256 [label="module_list.19.weight
 (14)" fillcolor=lightblue]
	139898685099312 -> 139898685099144
	139898685099312 [label="module_list.19.bias
 (14)" fillcolor=lightblue]
	139898685099032 -> 139898685091400
	139898685099032 [label="module_list.20.weight
 (16, 14, 3, 3)" fillcolor=lightblue]
	139898685091568 -> 139898685091232
	139898685091568 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	139898685097856 -> 139898685091232
	139898685097856 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	139898685090952 -> 139898685090672
	139898685090952 [label="module_list.22.weight
 (30, 16, 3, 3)" fillcolor=lightblue]
	139898685090728 -> 139898685090560
	139898685090728 [label="module_list.23.weight
 (30)" fillcolor=lightblue]
	139898685090784 -> 139898685090560
	139898685090784 [label="module_list.23.bias
 (30)" fillcolor=lightblue]
	139898685090448 -> 139898685090168
	139898685090448 [label="module_list.24.weight
 (32, 30, 3, 3)" fillcolor=lightblue]
	139898685090224 -> 139898685090056
	139898685090224 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	139898685090280 -> 139898685090056
	139898685090280 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	139898685089944 -> 139898685089776
	139898685089944 [label=CudnnBatchNormBackward]
	139898685090112 -> 139898685089944
	139898685090112 [label=CudnnConvolutionBackward]
	139898685090896 -> 139898685090112
	139898685091008 -> 139898685090112
	139898685091008 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	139898685090336 -> 139898685089944
	139898685090336 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	139898685090504 -> 139898685089944
	139898685090504 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	139898685089664 -> 139898685089496
	139898685089664 [label=CudnnBatchNormBackward]
	139898685089832 -> 139898685089664
	139898685089832 [label=CudnnConvolutionBackward]
	139898685091120 -> 139898685089832
	139898685091120 [label=ReluBackward1]
	139898685098752 -> 139898685091120
	139898685098752 [label=CudnnBatchNormBackward]
	139898685099480 -> 139898685098752
	139898685099480 [label=CudnnConvolutionBackward]
	139898685089608 -> 139898685099480
	139898685099536 -> 139898685099480
	139898685099536 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139898685099200 -> 139898685098752
	139898685099200 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	139898685099592 -> 139898685098752
	139898685099592 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	139898685091288 -> 139898685089832
	139898685091288 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139898685090000 -> 139898685089664
	139898685090000 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	139898685090840 -> 139898685089664
	139898685090840 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	139898685089384 -> 139898685089216
	139898685089384 [label=CudnnBatchNormBackward]
	139898685089552 -> 139898685089384
	139898685089552 [label=CudnnConvolutionBackward]
	139898685099648 -> 139898685089552
	139898685099648 [label=ReluBackward1]
	139898685099816 -> 139898685099648
	139898685099816 [label=CudnnBatchNormBackward]
	139898685099760 -> 139898685099816
	139898685099760 [label=CudnnConvolutionBackward]
	139898685089328 -> 139898685099760
	139898685128832 -> 139898685099760
	139898685128832 [label="module_list.32.weight
 (26, 32, 3, 3)" fillcolor=lightblue]
	139898685099928 -> 139898685099816
	139898685099928 [label="module_list.33.weight
 (26)" fillcolor=lightblue]
	139898685099984 -> 139898685099816
	139898685099984 [label="module_list.33.bias
 (26)" fillcolor=lightblue]
	139898685099704 -> 139898685089552
	139898685099704 [label="module_list.34.weight
 (32, 26, 3, 3)" fillcolor=lightblue]
	139898685089720 -> 139898685089384
	139898685089720 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	139898685090616 -> 139898685089384
	139898685090616 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	139898685089104 -> 139898685088936
	139898685089104 [label=CudnnBatchNormBackward]
	139898685089272 -> 139898685089104
	139898685089272 [label=CudnnConvolutionBackward]
	139898685099872 -> 139898685089272
	139898685099872 [label=ReluBackward1]
	139898685129000 -> 139898685099872
	139898685129000 [label=CudnnBatchNormBackward]
	139898685128944 -> 139898685129000
	139898685128944 [label=CudnnConvolutionBackward]
	139898685089048 -> 139898685128944
	139898685129280 -> 139898685128944
	139898685129280 [label="module_list.36.weight
 (5, 32, 3, 3)" fillcolor=lightblue]
	139898685129112 -> 139898685129000
	139898685129112 [label="module_list.37.weight
 (5)" fillcolor=lightblue]
	139898685129168 -> 139898685129000
	139898685129168 [label="module_list.37.bias
 (5)" fillcolor=lightblue]
	139898685128776 -> 139898685089272
	139898685128776 [label="module_list.38.weight
 (32, 5, 3, 3)" fillcolor=lightblue]
	139898685089440 -> 139898685089104
	139898685089440 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	139898685098304 -> 139898685089104
	139898685098304 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	139898685088824 -> 139898685088544
	139898685088824 [label="module_list.40.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139898685088600 -> 139898685088432
	139898685088600 [label="module_list.41.weight
 (64)" fillcolor=lightblue]
	139898685088656 -> 139898685088432
	139898685088656 [label="module_list.41.bias
 (64)" fillcolor=lightblue]
	139898685088320 -> 139898685088040
	139898685088320 [label="module_list.42.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139898685088096 -> 139898685087928
	139898685088096 [label="module_list.43.weight
 (64)" fillcolor=lightblue]
	139898685088152 -> 139898685087928
	139898685088152 [label="module_list.43.bias
 (64)" fillcolor=lightblue]
	139898685087816 -> 139900011011936
	139898685087816 [label=CudnnBatchNormBackward]
	139898685099368 -> 139898685087816
	139898685099368 [label=CudnnConvolutionBackward]
	139898685088768 -> 139898685099368
	139898685088488 -> 139898685099368
	139898685088488 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139898685087984 -> 139898685087816
	139898685087984 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	139898685088208 -> 139898685087816
	139898685088208 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	139900011011824 -> 139900011011656
	139900011011824 [label=CudnnBatchNormBackward]
	139900011011992 -> 139900011011824
	139900011011992 [label=CudnnConvolutionBackward]
	139898685089160 -> 139900011011992
	139898685089160 [label=ReluBackward1]
	139898685128888 -> 139898685089160
	139898685128888 [label=CudnnBatchNormBackward]
	139898685129056 -> 139898685128888
	139898685129056 [label=CudnnConvolutionBackward]
	139900011011768 -> 139898685129056
	139898685129504 -> 139898685129056
	139898685129504 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139898685129336 -> 139898685128888
	139898685129336 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	139898685129448 -> 139898685128888
	139898685129448 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	139898685088992 -> 139900011011992
	139898685088992 [label="module_list.48.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139898685087872 -> 139900011011824
	139898685087872 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	139898685088376 -> 139900011011824
	139898685088376 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	139900011011544 -> 139900011011376
	139900011011544 [label=CudnnBatchNormBackward]
	139900011011712 -> 139900011011544
	139900011011712 [label=CudnnConvolutionBackward]
	139898685129392 -> 139900011011712
	139898685129392 [label=ReluBackward1]
	139898685129672 -> 139898685129392
	139898685129672 [label=CudnnBatchNormBackward]
	139898685129616 -> 139898685129672
	139898685129616 [label=CudnnConvolutionBackward]
	139900011011488 -> 139898685129616
	139898685129952 -> 139898685129616
	139898685129952 [label="module_list.50.weight
 (53, 64, 3, 3)" fillcolor=lightblue]
	139898685129784 -> 139898685129672
	139898685129784 [label="module_list.51.weight
 (53)" fillcolor=lightblue]
	139898685129840 -> 139898685129672
	139898685129840 [label="module_list.51.bias
 (53)" fillcolor=lightblue]
	139898685129560 -> 139900011011712
	139898685129560 [label="module_list.52.weight
 (64, 53, 3, 3)" fillcolor=lightblue]
	139900011011880 -> 139900011011544
	139900011011880 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	139898685088712 -> 139900011011544
	139898685088712 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	139900011011264 -> 139900011011320
	139900011011264 [label=CudnnBatchNormBackward]
	139900011011432 -> 139900011011264
	139900011011432 [label=CudnnConvolutionBackward]
	139898685129896 -> 139900011011432
	139898685129896 [label=ReluBackward1]
	139898685130120 -> 139898685129896
	139898685130120 [label=CudnnBatchNormBackward]
	139898685130064 -> 139898685130120
	139898685130064 [label=CudnnConvolutionBackward]
	139900011010592 -> 139898685130064
	139898685130400 -> 139898685130064
	139898685130400 [label="module_list.54.weight
 (52, 64, 3, 3)" fillcolor=lightblue]
	139898685130232 -> 139898685130120
	139898685130232 [label="module_list.55.weight
 (52)" fillcolor=lightblue]
	139898685130288 -> 139898685130120
	139898685130288 [label="module_list.55.bias
 (52)" fillcolor=lightblue]
	139898685130008 -> 139900011011432
	139898685130008 [label="module_list.56.weight
 (64, 52, 3, 3)" fillcolor=lightblue]
	139900011011600 -> 139900011011264
	139900011011600 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	139898685088880 -> 139900011011264
	139898685088880 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	139900011010032 -> 139900011010256
	139900011010032 [label=TBackward]
	139900011009360 -> 139900011010032
	139900011009360 [label="module_list.59.weight
 (10, 64)" fillcolor=lightblue]
}
