digraph {
	graph [size="64.35,64.35"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140490098843432 [label=AddmmBackward fillcolor=darkolivegreen1]
	140490219011376 -> 140490098843432
	140490219011376 [label="module_list.63.bias
 (10)" fillcolor=lightblue]
	140490098897920 -> 140490098843432
	140490098897920 [label=ViewBackward]
	140490098898200 -> 140490098897920
	140490098898200 [label=ViewBackward]
	140490098897024 -> 140490098898200
	140490098897024 [label=MeanBackward1]
	140490098900888 -> 140490098897024
	140490098900888 [label=ViewBackward]
	140490098897360 -> 140490098900888
	140490098897360 [label=ReluBackward1]
	140490098899824 -> 140490098897360
	140490098899824 [label=AddBackward0]
	140490098899992 -> 140490098899824
	140490098899992 [label=ReluBackward1]
	140490098897976 -> 140490098899992
	140490098897976 [label=AddBackward0]
	140490098898816 -> 140490098897976
	140490098898816 [label=ReluBackward1]
	140490098898648 -> 140490098898816
	140490098898648 [label=AddBackward0]
	140490098899880 -> 140490098898648
	140490098899880 [label=ReluBackward1]
	140490098899768 -> 140490098899880
	140490098899768 [label=AddBackward0]
	140490098898088 -> 140490098899768
	140490098898088 [label=ReluBackward1]
	140490099013056 -> 140490098898088
	140490099013056 [label=AddBackward0]
	140490099013392 -> 140490099013056
	140490099013392 [label=ReluBackward1]
	140490099012160 -> 140490099013392
	140490099012160 [label=CudnnBatchNormBackward]
	140490099011880 -> 140490099012160
	140490099011880 [label=CudnnConvolutionBackward]
	140490099012664 -> 140490099011880
	140490099012664 [label=ReluBackward1]
	140490099014792 -> 140490099012664
	140490099014792 [label=CudnnBatchNormBackward]
	140490099015520 -> 140490099014792
	140490099015520 [label=CudnnConvolutionBackward]
	140490099015408 -> 140490099015520
	140490099015408 [label=ReluBackward1]
	140490099015128 -> 140490099015408
	140490099015128 [label=AddBackward0]
	140490099013672 -> 140490099015128
	140490099013672 [label=ReluBackward1]
	140490099012384 -> 140490099013672
	140490099012384 [label=AddBackward0]
	140490099013616 -> 140490099012384
	140490099013616 [label=ReluBackward1]
	140490099014736 -> 140490099013616
	140490099014736 [label=AddBackward0]
	140490099014624 -> 140490099014736
	140490099014624 [label=ReluBackward1]
	140490099014512 -> 140490099014624
	140490099014512 [label=AddBackward0]
	140490099011768 -> 140490099014512
	140490099011768 [label=ReluBackward1]
	140490099011656 -> 140490099011768
	140490099011656 [label=CudnnBatchNormBackward]
	140490099015072 -> 140490099011656
	140490099015072 [label=CudnnConvolutionBackward]
	140490099012104 -> 140490099015072
	140490099012104 [label=ReluBackward1]
	140486486491208 -> 140490099012104
	140486486491208 [label=CudnnBatchNormBackward]
	140486486491432 -> 140486486491208
	140486486491432 [label=CudnnConvolutionBackward]
	140486486491656 -> 140486486491432
	140486486491656 [label=ReluBackward1]
	140486486491824 -> 140486486491656
	140486486491824 [label=AddBackward0]
	140486486491936 -> 140486486491824
	140486486491936 [label=ReluBackward1]
	140486486492104 -> 140486486491936
	140486486492104 [label=AddBackward0]
	140486486492216 -> 140486486492104
	140486486492216 [label=ReluBackward1]
	140486486492384 -> 140486486492216
	140486486492384 [label=AddBackward0]
	140486486492496 -> 140486486492384
	140486486492496 [label=ReluBackward1]
	140486486492664 -> 140486486492496
	140486486492664 [label=AddBackward0]
	140486486492776 -> 140486486492664
	140486486492776 [label=ReluBackward1]
	140486486492944 -> 140486486492776
	140486486492944 [label=AddBackward0]
	140486486493056 -> 140486486492944
	140486486493056 [label=ReluBackward1]
	140486486493224 -> 140486486493056
	140486486493224 [label=CudnnBatchNormBackward]
	140486486493336 -> 140486486493224
	140486486493336 [label=CudnnConvolutionBackward]
	140486486493560 -> 140486486493336
	140486486493560 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140486486493392 -> 140486486493224
	140486486493392 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140486486493448 -> 140486486493224
	140486486493448 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140486486493112 -> 140486486492944
	140486486493112 [label=CudnnBatchNormBackward]
	140486486493280 -> 140486486493112
	140486486493280 [label=CudnnConvolutionBackward]
	140486486493672 -> 140486486493280
	140486486493672 [label=ReluBackward1]
	140486486493896 -> 140486486493672
	140486486493896 [label=CudnnBatchNormBackward]
	140486486494008 -> 140486486493896
	140486486494008 [label=CudnnConvolutionBackward]
	140486486493056 -> 140486486494008
	140486486494232 -> 140486486494008
	140486486494232 [label="module_list.2.weight
 (8, 16, 3, 3)" fillcolor=lightblue]
	140486486494064 -> 140486486493896
	140486486494064 [label="module_list.3.weight
 (8)" fillcolor=lightblue]
	140486486494120 -> 140486486493896
	140486486494120 [label="module_list.3.bias
 (8)" fillcolor=lightblue]
	140486486493784 -> 140486486493280
	140486486493784 [label="module_list.4.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	140486486493504 -> 140486486493112
	140486486493504 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140486486493616 -> 140486486493112
	140486486493616 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140486486492832 -> 140486486492664
	140486486492832 [label=CudnnBatchNormBackward]
	140486486493000 -> 140486486492832
	140486486493000 [label=CudnnConvolutionBackward]
	140486486494176 -> 140486486493000
	140486486494176 [label=ReluBackward1]
	140486486494400 -> 140486486494176
	140486486494400 [label=CudnnBatchNormBackward]
	140486486494456 -> 140486486494400
	140486486494456 [label=CudnnConvolutionBackward]
	140486486492776 -> 140486486494456
	140486486494680 -> 140486486494456
	140486486494680 [label="module_list.6.weight
 (12, 16, 3, 3)" fillcolor=lightblue]
	140486486494512 -> 140486486494400
	140486486494512 [label="module_list.7.weight
 (12)" fillcolor=lightblue]
	140486486494568 -> 140486486494400
	140486486494568 [label="module_list.7.bias
 (12)" fillcolor=lightblue]
	140486486493952 -> 140486486493000
	140486486493952 [label="module_list.8.weight
 (16, 12, 3, 3)" fillcolor=lightblue]
	140486486493168 -> 140486486492832
	140486486493168 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140486486493728 -> 140486486492832
	140486486493728 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140486486492552 -> 140486486492384
	140486486492552 [label=CudnnBatchNormBackward]
	140486486492720 -> 140486486492552
	140486486492720 [label=CudnnConvolutionBackward]
	140486486494624 -> 140486486492720
	140486486494624 [label=ReluBackward1]
	140486486494848 -> 140486486494624
	140486486494848 [label=CudnnBatchNormBackward]
	140486486494792 -> 140486486494848
	140486486494792 [label=CudnnConvolutionBackward]
	140486486492496 -> 140486486494792
	140486486495128 -> 140486486494792
	140486486495128 [label="module_list.10.weight
 (9, 16, 3, 3)" fillcolor=lightblue]
	140486486494960 -> 140486486494848
	140486486494960 [label="module_list.11.weight
 (9)" fillcolor=lightblue]
	140486486495016 -> 140486486494848
	140486486495016 [label="module_list.11.bias
 (9)" fillcolor=lightblue]
	140486486494736 -> 140486486492720
	140486486494736 [label="module_list.12.weight
 (16, 9, 3, 3)" fillcolor=lightblue]
	140486486492888 -> 140486486492552
	140486486492888 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140486486493840 -> 140486486492552
	140486486493840 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140486486492272 -> 140486486492104
	140486486492272 [label=CudnnBatchNormBackward]
	140486486492440 -> 140486486492272
	140486486492440 [label=CudnnConvolutionBackward]
	140486486495072 -> 140486486492440
	140486486495072 [label=ReluBackward1]
	140488888225920 -> 140486486495072
	140488888225920 [label=CudnnBatchNormBackward]
	140488888225976 -> 140488888225920
	140488888225976 [label=CudnnConvolutionBackward]
	140486486492216 -> 140488888225976
	140488888226200 -> 140488888225976
	140488888226200 [label="module_list.14.weight
 (8, 16, 3, 3)" fillcolor=lightblue]
	140488888226032 -> 140488888225920
	140488888226032 [label="module_list.15.weight
 (8)" fillcolor=lightblue]
	140488888226088 -> 140488888225920
	140488888226088 [label="module_list.15.bias
 (8)" fillcolor=lightblue]
	140486486494904 -> 140486486492440
	140486486494904 [label="module_list.16.weight
 (16, 8, 3, 3)" fillcolor=lightblue]
	140486486492608 -> 140486486492272
	140486486492608 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140486486494288 -> 140486486492272
	140486486494288 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140486486491992 -> 140486486491824
	140486486491992 [label=CudnnBatchNormBackward]
	140486486492160 -> 140486486491992
	140486486492160 [label=CudnnConvolutionBackward]
	140488888226144 -> 140486486492160
	140488888226144 [label=ReluBackward1]
	140488888226368 -> 140488888226144
	140488888226368 [label=CudnnBatchNormBackward]
	140488888226424 -> 140488888226368
	140488888226424 [label=CudnnConvolutionBackward]
	140486486491936 -> 140488888226424
	140488888226648 -> 140488888226424
	140488888226648 [label="module_list.18.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	140488888226480 -> 140488888226368
	140488888226480 [label="module_list.19.weight
 (14)" fillcolor=lightblue]
	140488888226536 -> 140488888226368
	140488888226536 [label="module_list.19.bias
 (14)" fillcolor=lightblue]
	140488888225864 -> 140486486492160
	140488888225864 [label="module_list.20.weight
 (16, 14, 3, 3)" fillcolor=lightblue]
	140486486492328 -> 140486486491992
	140486486492328 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140486486494344 -> 140486486491992
	140486486494344 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140486486491712 -> 140486486491432
	140486486491712 [label="module_list.22.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	140486486491600 -> 140486486491208
	140486486491600 [label="module_list.23.weight
 (14)" fillcolor=lightblue]
	140486486491264 -> 140486486491208
	140486486491264 [label="module_list.23.bias
 (14)" fillcolor=lightblue]
	140490099014680 -> 140490099015072
	140490099014680 [label="module_list.24.weight
 (32, 14, 3, 3)" fillcolor=lightblue]
	140490099012552 -> 140490099011656
	140490099012552 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140490099014344 -> 140490099011656
	140490099014344 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140490099015632 -> 140490099014512
	140490099015632 [label=CudnnBatchNormBackward]
	140490099012776 -> 140490099015632
	140490099012776 [label=CudnnConvolutionBackward]
	140486486491656 -> 140490099012776
	140486486491768 -> 140490099012776
	140486486491768 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140490099013896 -> 140490099015632
	140490099013896 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140486486491320 -> 140490099015632
	140486486491320 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140490099014176 -> 140490099014736
	140490099014176 [label=CudnnBatchNormBackward]
	140490099012328 -> 140490099014176
	140490099012328 [label=CudnnConvolutionBackward]
	140486486495184 -> 140490099012328
	140486486495184 [label=ReluBackward1]
	140488888226256 -> 140486486495184
	140488888226256 [label=CudnnBatchNormBackward]
	140488888226704 -> 140488888226256
	140488888226704 [label=CudnnConvolutionBackward]
	140490099014624 -> 140488888226704
	140488888226760 -> 140488888226704
	140488888226760 [label="module_list.28.weight
 (28, 32, 3, 3)" fillcolor=lightblue]
	140488888226312 -> 140488888226256
	140488888226312 [label="module_list.29.weight
 (28)" fillcolor=lightblue]
	140488888226816 -> 140488888226256
	140488888226816 [label="module_list.29.bias
 (28)" fillcolor=lightblue]
	140486486491880 -> 140490099012328
	140486486491880 [label="module_list.30.weight
 (32, 28, 3, 3)" fillcolor=lightblue]
	140490099014120 -> 140490099014176
	140490099014120 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140486486491544 -> 140490099014176
	140486486491544 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140490099012608 -> 140490099012384
	140490099012608 [label=CudnnBatchNormBackward]
	140490099014456 -> 140490099012608
	140490099014456 [label=CudnnConvolutionBackward]
	140488888226872 -> 140490099014456
	140488888226872 [label=ReluBackward1]
	140488888227040 -> 140488888226872
	140488888227040 [label=CudnnBatchNormBackward]
	140488888226984 -> 140488888227040
	140488888226984 [label=CudnnConvolutionBackward]
	140490099013616 -> 140488888226984
	140488888227320 -> 140488888226984
	140488888227320 [label="module_list.32.weight
 (13, 32, 3, 3)" fillcolor=lightblue]
	140488888227152 -> 140488888227040
	140488888227152 [label="module_list.33.weight
 (13)" fillcolor=lightblue]
	140488888227208 -> 140488888227040
	140488888227208 [label="module_list.33.bias
 (13)" fillcolor=lightblue]
	140488888226928 -> 140490099014456
	140488888226928 [label="module_list.34.weight
 (32, 13, 3, 3)" fillcolor=lightblue]
	140490099013560 -> 140490099012608
	140490099013560 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140486486491488 -> 140490099012608
	140486486491488 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140490099012944 -> 140490099015128
	140490099012944 [label=CudnnBatchNormBackward]
	140490099015464 -> 140490099012944
	140490099015464 [label=CudnnConvolutionBackward]
	140488888227264 -> 140490099015464
	140488888227264 [label=ReluBackward1]
	140488888227488 -> 140488888227264
	140488888227488 [label=CudnnBatchNormBackward]
	140488888227432 -> 140488888227488
	140488888227432 [label=CudnnConvolutionBackward]
	140490099013672 -> 140488888227432
	140488888227768 -> 140488888227432
	140488888227768 [label="module_list.36.weight
 (15, 32, 3, 3)" fillcolor=lightblue]
	140488888227600 -> 140488888227488
	140488888227600 [label="module_list.37.weight
 (15)" fillcolor=lightblue]
	140488888227656 -> 140488888227488
	140488888227656 [label="module_list.37.bias
 (15)" fillcolor=lightblue]
	140488888227376 -> 140490099015464
	140488888227376 [label="module_list.38.weight
 (32, 15, 3, 3)" fillcolor=lightblue]
	140490099011712 -> 140490099012944
	140490099011712 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140486486492048 -> 140490099012944
	140486486492048 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140490099014064 -> 140490099015520
	140490099014064 [label="module_list.40.weight
 (63, 32, 3, 3)" fillcolor=lightblue]
	140490099013336 -> 140490099014792
	140490099013336 [label="module_list.41.weight
 (63)" fillcolor=lightblue]
	140490099014400 -> 140490099014792
	140490099014400 [label="module_list.41.bias
 (63)" fillcolor=lightblue]
	140490099014904 -> 140490099011880
	140490099014904 [label="module_list.42.weight
 (64, 63, 3, 3)" fillcolor=lightblue]
	140490099013112 -> 140490099012160
	140490099013112 [label="module_list.43.weight
 (64)" fillcolor=lightblue]
	140490099013448 -> 140490099012160
	140490099013448 [label="module_list.43.bias
 (64)" fillcolor=lightblue]
	140490099013784 -> 140490099013056
	140490099013784 [label=CudnnBatchNormBackward]
	140490099015576 -> 140490099013784
	140490099015576 [label=CudnnConvolutionBackward]
	140490099015408 -> 140490099015576
	140490099012440 -> 140490099015576
	140490099012440 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140490099013168 -> 140490099013784
	140490099013168 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140490099012496 -> 140490099013784
	140490099012496 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140490098898256 -> 140490098899768
	140490098898256 [label=CudnnBatchNormBackward]
	140490099014568 -> 140490098898256
	140490099014568 [label=CudnnConvolutionBackward]
	140490099011936 -> 140490099014568
	140490099011936 [label=ReluBackward1]
	140488888227096 -> 140490099011936
	140488888227096 [label=CudnnBatchNormBackward]
	140488888227824 -> 140488888227096
	140488888227824 [label=CudnnConvolutionBackward]
	140490098898088 -> 140488888227824
	140488888227880 -> 140488888227824
	140488888227880 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140488888227544 -> 140488888227096
	140488888227544 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140488888227936 -> 140488888227096
	140488888227936 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140490099014960 -> 140490099014568
	140490099014960 [label="module_list.48.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140490099015184 -> 140490098898256
	140490099015184 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140490099012720 -> 140490098898256
	140490099012720 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140490098897808 -> 140490098898648
	140490098897808 [label=CudnnBatchNormBackward]
	140490098896968 -> 140490098897808
	140490098896968 [label=CudnnConvolutionBackward]
	140488888227992 -> 140490098896968
	140488888227992 [label=ReluBackward1]
	140488888228160 -> 140488888227992
	140488888228160 [label=CudnnBatchNormBackward]
	140488888228104 -> 140488888228160
	140488888228104 [label=CudnnConvolutionBackward]
	140490098899880 -> 140488888228104
	140488888228440 -> 140488888228104
	140488888228440 [label="module_list.50.weight
 (49, 64, 3, 3)" fillcolor=lightblue]
	140488888228272 -> 140488888228160
	140488888228272 [label="module_list.51.weight
 (49)" fillcolor=lightblue]
	140488888228328 -> 140488888228160
	140488888228328 [label="module_list.51.bias
 (49)" fillcolor=lightblue]
	140488888228048 -> 140490098896968
	140488888228048 [label="module_list.52.weight
 (64, 49, 3, 3)" fillcolor=lightblue]
	140490099012888 -> 140490098897808
	140490099012888 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140490099013504 -> 140490098897808
	140490099013504 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140490098899488 -> 140490098897976
	140490098899488 [label=CudnnBatchNormBackward]
	140490098897080 -> 140490098899488
	140490098897080 [label=CudnnConvolutionBackward]
	140488888228384 -> 140490098897080
	140488888228384 [label=ReluBackward1]
	140488888228608 -> 140488888228384
	140488888228608 [label=CudnnBatchNormBackward]
	140488888228552 -> 140488888228608
	140488888228552 [label=CudnnConvolutionBackward]
	140490098898816 -> 140488888228552
	140488888228888 -> 140488888228552
	140488888228888 [label="module_list.54.weight
 (50, 64, 3, 3)" fillcolor=lightblue]
	140488888228720 -> 140488888228608
	140488888228720 [label="module_list.55.weight
 (50)" fillcolor=lightblue]
	140488888228776 -> 140488888228608
	140488888228776 [label="module_list.55.bias
 (50)" fillcolor=lightblue]
	140488888228496 -> 140490098897080
	140488888228496 [label="module_list.56.weight
 (64, 50, 3, 3)" fillcolor=lightblue]
	140490098899376 -> 140490098899488
	140490098899376 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140488888226592 -> 140490098899488
	140488888226592 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140490098897640 -> 140490098899824
	140490098897640 [label=CudnnBatchNormBackward]
	140490098897864 -> 140490098897640
	140490098897864 [label=CudnnConvolutionBackward]
	140488888228832 -> 140490098897864
	140488888228832 [label=ReluBackward1]
	140488888229056 -> 140488888228832
	140488888229056 [label=CudnnBatchNormBackward]
	140488888229000 -> 140488888229056
	140488888229000 [label=CudnnConvolutionBackward]
	140490098899992 -> 140488888229000
	140488888229336 -> 140488888229000
	140488888229336 [label="module_list.58.weight
 (5, 64, 3, 3)" fillcolor=lightblue]
	140488888229168 -> 140488888229056
	140488888229168 [label="module_list.59.weight
 (5)" fillcolor=lightblue]
	140488888229224 -> 140488888229056
	140488888229224 [label="module_list.59.bias
 (5)" fillcolor=lightblue]
	140488888228944 -> 140490098897864
	140488888228944 [label="module_list.60.weight
 (64, 5, 3, 3)" fillcolor=lightblue]
	140490098897192 -> 140490098897640
	140490098897192 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140488888227712 -> 140490098897640
	140488888227712 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140490098899712 -> 140490098843432
	140490098899712 [label=TBackward]
	140490098900272 -> 140490098899712
	140490098900272 [label="module_list.63.weight
 (10, 64)" fillcolor=lightblue]
}
