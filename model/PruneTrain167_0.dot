digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140296456845632 [label=AddmmBackward fillcolor=darkolivegreen1]
	140296691209048 -> 140296456845632
	140296691209048 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140296456845128 -> 140296456845632
	140296456845128 [label=ViewBackward]
	140296456844904 -> 140296456845128
	140296456844904 [label=ViewBackward]
	140296456846080 -> 140296456844904
	140296456846080 [label=MeanBackward1]
	140296456846192 -> 140296456846080
	140296456846192 [label=ViewBackward]
	140296456846304 -> 140296456846192
	140296456846304 [label=ReluBackward1]
	140296456846416 -> 140296456846304
	140296456846416 [label=AddBackward0]
	140296456846528 -> 140296456846416
	140296456846528 [label=ReluBackward1]
	140296456846696 -> 140296456846528
	140296456846696 [label=AddBackward0]
	140296456846808 -> 140296456846696
	140296456846808 [label=ReluBackward1]
	140296456846976 -> 140296456846808
	140296456846976 [label=AddBackward0]
	140296456847088 -> 140296456846976
	140296456847088 [label=ReluBackward1]
	140296456847256 -> 140296456847088
	140296456847256 [label=AddBackward0]
	140296456953928 -> 140296456847256
	140296456953928 [label=ReluBackward1]
	140296456954096 -> 140296456953928
	140296456954096 [label=AddBackward0]
	140296456954208 -> 140296456954096
	140296456954208 [label=ReluBackward1]
	140296456954376 -> 140296456954208
	140296456954376 [label=CudnnBatchNormBackward]
	140296456954488 -> 140296456954376
	140296456954488 [label=CudnnConvolutionBackward]
	140296456954600 -> 140296456954488
	140296456954600 [label=ReluBackward1]
	140296456954712 -> 140296456954600
	140296456954712 [label=CudnnBatchNormBackward]
	140296456954824 -> 140296456954712
	140296456954824 [label=CudnnConvolutionBackward]
	140296456954936 -> 140296456954824
	140296456954936 [label=ReluBackward1]
	140296456955048 -> 140296456954936
	140296456955048 [label=AddBackward0]
	140296456955160 -> 140296456955048
	140296456955160 [label=ReluBackward1]
	140296456955328 -> 140296456955160
	140296456955328 [label=AddBackward0]
	140296456955440 -> 140296456955328
	140296456955440 [label=ReluBackward1]
	140296456955608 -> 140296456955440
	140296456955608 [label=AddBackward0]
	140296456955720 -> 140296456955608
	140296456955720 [label=ReluBackward1]
	140296456955888 -> 140296456955720
	140296456955888 [label=AddBackward0]
	140296456956000 -> 140296456955888
	140296456956000 [label=ReluBackward1]
	140296456956168 -> 140296456956000
	140296456956168 [label=AddBackward0]
	140296456956280 -> 140296456956168
	140296456956280 [label=ReluBackward1]
	140296456956448 -> 140296456956280
	140296456956448 [label=CudnnBatchNormBackward]
	140296456956560 -> 140296456956448
	140296456956560 [label=CudnnConvolutionBackward]
	140296456956672 -> 140296456956560
	140296456956672 [label=ReluBackward1]
	140296456956784 -> 140296456956672
	140296456956784 [label=CudnnBatchNormBackward]
	140296456956896 -> 140296456956784
	140296456956896 [label=CudnnConvolutionBackward]
	140296456957008 -> 140296456956896
	140296456957008 [label=ReluBackward1]
	140296456957120 -> 140296456957008
	140296456957120 [label=AddBackward0]
	140296456957232 -> 140296456957120
	140296456957232 [label=ReluBackward1]
	140296456957400 -> 140296456957232
	140296456957400 [label=AddBackward0]
	140296456957512 -> 140296456957400
	140296456957512 [label=ReluBackward1]
	140296456957680 -> 140296456957512
	140296456957680 [label=AddBackward0]
	140296456957792 -> 140296456957680
	140296456957792 [label=ReluBackward1]
	140296550109256 -> 140296456957792
	140296550109256 [label=AddBackward0]
	140296550109368 -> 140296550109256
	140296550109368 [label=ReluBackward1]
	140296550109536 -> 140296550109368
	140296550109536 [label=AddBackward0]
	140296550109648 -> 140296550109536
	140296550109648 [label=ReluBackward1]
	140296550109816 -> 140296550109648
	140296550109816 [label=CudnnBatchNormBackward]
	140296550109928 -> 140296550109816
	140296550109928 [label=CudnnConvolutionBackward]
	140296456797936 -> 140296550109928
	140296456797936 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140296456797768 -> 140296550109816
	140296456797768 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140296456797824 -> 140296550109816
	140296456797824 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140296550109704 -> 140296550109536
	140296550109704 [label=CudnnBatchNormBackward]
	140296550109872 -> 140296550109704
	140296550109872 [label=CudnnConvolutionBackward]
	140296550110040 -> 140296550109872
	140296550110040 [label=ReluBackward1]
	140296550110096 -> 140296550110040
	140296550110096 [label=CudnnBatchNormBackward]
	140296550110264 -> 140296550110096
	140296550110264 [label=CudnnConvolutionBackward]
	140296550109648 -> 140296550110264
	140296456806864 -> 140296550110264
	140296456806864 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456806696 -> 140296550110096
	140296456806696 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140296456806752 -> 140296550110096
	140296456806752 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140296456798160 -> 140296550109872
	140296456798160 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456797880 -> 140296550109704
	140296456797880 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140296456797992 -> 140296550109704
	140296456797992 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140296550109424 -> 140296550109256
	140296550109424 [label=CudnnBatchNormBackward]
	140296550109592 -> 140296550109424
	140296550109592 [label=CudnnConvolutionBackward]
	140296550109984 -> 140296550109592
	140296550109984 [label=ReluBackward1]
	140296550110320 -> 140296550109984
	140296550110320 [label=CudnnBatchNormBackward]
	140296550110208 -> 140296550110320
	140296550110208 [label=CudnnConvolutionBackward]
	140296550109368 -> 140296550110208
	140296456807312 -> 140296550110208
	140296456807312 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456807144 -> 140296550110320
	140296456807144 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140296456807200 -> 140296550110320
	140296456807200 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140296456806920 -> 140296550109592
	140296456806920 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456797544 -> 140296550109424
	140296456797544 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140296456798104 -> 140296550109424
	140296456798104 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140296456957848 -> 140296456957680
	140296456957848 [label=CudnnBatchNormBackward]
	140296550109312 -> 140296456957848
	140296550109312 [label=CudnnConvolutionBackward]
	140296550109760 -> 140296550109312
	140296550109760 [label=ReluBackward1]
	140296550110488 -> 140296550109760
	140296550110488 [label=CudnnBatchNormBackward]
	140296550110376 -> 140296550110488
	140296550110376 [label=CudnnConvolutionBackward]
	140296456957792 -> 140296550110376
	140296456807760 -> 140296550110376
	140296456807760 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456807592 -> 140296550110488
	140296456807592 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140296456807648 -> 140296550110488
	140296456807648 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140296456807368 -> 140296550109312
	140296456807368 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456797264 -> 140296456957848
	140296456797264 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140296456806472 -> 140296456957848
	140296456806472 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140296456957568 -> 140296456957400
	140296456957568 [label=CudnnBatchNormBackward]
	140296456957736 -> 140296456957568
	140296456957736 [label=CudnnConvolutionBackward]
	140296550109480 -> 140296456957736
	140296550109480 [label=ReluBackward1]
	140296550110600 -> 140296550109480
	140296550110600 [label=CudnnBatchNormBackward]
	140296550110544 -> 140296550110600
	140296550110544 [label=CudnnConvolutionBackward]
	140296456957512 -> 140296550110544
	140296456808208 -> 140296550110544
	140296456808208 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456808040 -> 140296550110600
	140296456808040 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140296456808096 -> 140296550110600
	140296456808096 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140296456807816 -> 140296456957736
	140296456807816 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456796984 -> 140296456957568
	140296456796984 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140296456806584 -> 140296456957568
	140296456806584 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140296456957288 -> 140296456957120
	140296456957288 [label=CudnnBatchNormBackward]
	140296456957456 -> 140296456957288
	140296456957456 [label=CudnnConvolutionBackward]
	140296456957904 -> 140296456957456
	140296456957904 [label=ReluBackward1]
	140296550110712 -> 140296456957904
	140296550110712 [label=CudnnBatchNormBackward]
	140296550110656 -> 140296550110712
	140296550110656 [label=CudnnConvolutionBackward]
	140296456957232 -> 140296550110656
	140296456808656 -> 140296550110656
	140296456808656 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456808488 -> 140296550110712
	140296456808488 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140296456808544 -> 140296550110712
	140296456808544 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140296456808264 -> 140296456957456
	140296456808264 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456796704 -> 140296456957288
	140296456796704 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140296456807088 -> 140296456957288
	140296456807088 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140296456796088 -> 140296456956896
	140296456796088 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140296456795864 -> 140296456956784
	140296456795864 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140296456795920 -> 140296456956784
	140296456795920 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140296456795584 -> 140296456956560
	140296456795584 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456795360 -> 140296456956448
	140296456795360 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140296456795416 -> 140296456956448
	140296456795416 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140296456956336 -> 140296456956168
	140296456956336 [label=CudnnBatchNormBackward]
	140296456956504 -> 140296456956336
	140296456956504 [label=CudnnConvolutionBackward]
	140296456957008 -> 140296456956504
	140296456796144 -> 140296456956504
	140296456796144 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140296456795472 -> 140296456956336
	140296456795472 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140296456795640 -> 140296456956336
	140296456795640 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140296456956056 -> 140296456955888
	140296456956056 [label=CudnnBatchNormBackward]
	140296456956224 -> 140296456956056
	140296456956224 [label=CudnnConvolutionBackward]
	140296456956616 -> 140296456956224
	140296456956616 [label=ReluBackward1]
	140296456957064 -> 140296456956616
	140296456957064 [label=CudnnBatchNormBackward]
	140296456956952 -> 140296456957064
	140296456956952 [label=CudnnConvolutionBackward]
	140296456956000 -> 140296456956952
	140296456808768 -> 140296456956952
	140296456808768 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456808432 -> 140296456957064
	140296456808432 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140296456808824 -> 140296456957064
	140296456808824 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140296456796424 -> 140296456956224
	140296456796424 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456795136 -> 140296456956056
	140296456795136 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140296456795976 -> 140296456956056
	140296456795976 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140296456955776 -> 140296456955608
	140296456955776 [label=CudnnBatchNormBackward]
	140296456955944 -> 140296456955776
	140296456955944 [label=CudnnConvolutionBackward]
	140296456956392 -> 140296456955944
	140296456956392 [label=ReluBackward1]
	140296456957344 -> 140296456956392
	140296456957344 [label=CudnnBatchNormBackward]
	140296456956840 -> 140296456957344
	140296456956840 [label=CudnnConvolutionBackward]
	140296456955720 -> 140296456956840
	140296456809328 -> 140296456956840
	140296456809328 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456809160 -> 140296456957344
	140296456809160 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140296456809216 -> 140296456957344
	140296456809216 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140296456808936 -> 140296456955944
	140296456808936 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456794856 -> 140296456955776
	140296456794856 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140296456795752 -> 140296456955776
	140296456795752 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140296456955496 -> 140296456955328
	140296456955496 [label=CudnnBatchNormBackward]
	140296456955664 -> 140296456955496
	140296456955664 [label=CudnnConvolutionBackward]
	140296456956112 -> 140296456955664
	140296456956112 [label=ReluBackward1]
	140296456957176 -> 140296456956112
	140296456957176 [label=CudnnBatchNormBackward]
	140296550110152 -> 140296456957176
	140296550110152 [label=CudnnConvolutionBackward]
	140296456955440 -> 140296550110152
	140296456809776 -> 140296550110152
	140296456809776 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456809608 -> 140296456957176
	140296456809608 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140296456809664 -> 140296456957176
	140296456809664 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140296456809384 -> 140296456955664
	140296456809384 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456794576 -> 140296456955496
	140296456794576 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140296456807536 -> 140296456955496
	140296456807536 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140296456955216 -> 140296456955048
	140296456955216 [label=CudnnBatchNormBackward]
	140296456955384 -> 140296456955216
	140296456955384 [label=CudnnConvolutionBackward]
	140296456955832 -> 140296456955384
	140296456955832 [label=ReluBackward1]
	140296456957624 -> 140296456955832
	140296456957624 [label=CudnnBatchNormBackward]
	140296550110768 -> 140296456957624
	140296550110768 [label=CudnnConvolutionBackward]
	140296456955160 -> 140296550110768
	140296456810224 -> 140296550110768
	140296456810224 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456810056 -> 140296456957624
	140296456810056 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140296456810112 -> 140296456957624
	140296456810112 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140296456809832 -> 140296456955384
	140296456809832 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456794296 -> 140296456955216
	140296456794296 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140296456808600 -> 140296456955216
	140296456808600 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140296568331792 -> 140296456954824
	140296568331792 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140296568331568 -> 140296456954712
	140296568331568 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140296568331624 -> 140296456954712
	140296568331624 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140296568331288 -> 140296456954488
	140296568331288 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568331064 -> 140296456954376
	140296568331064 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140296568331120 -> 140296456954376
	140296568331120 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140296456954264 -> 140296456954096
	140296456954264 [label=CudnnBatchNormBackward]
	140296456954432 -> 140296456954264
	140296456954432 [label=CudnnConvolutionBackward]
	140296456954936 -> 140296456954432
	140296568331848 -> 140296456954432
	140296568331848 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140296568331176 -> 140296456954264
	140296568331176 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140296568331344 -> 140296456954264
	140296568331344 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140296456953984 -> 140296456847256
	140296456953984 [label=CudnnBatchNormBackward]
	140296456954152 -> 140296456953984
	140296456954152 [label=CudnnConvolutionBackward]
	140296456954544 -> 140296456954152
	140296456954544 [label=ReluBackward1]
	140296456954992 -> 140296456954544
	140296456954992 [label=CudnnBatchNormBackward]
	140296456954880 -> 140296456954992
	140296456954880 [label=CudnnConvolutionBackward]
	140296456953928 -> 140296456954880
	140296456810336 -> 140296456954880
	140296456810336 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456810000 -> 140296456954992
	140296456810000 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140296456810392 -> 140296456954992
	140296456810392 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140296568332128 -> 140296456954152
	140296568332128 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330840 -> 140296456953984
	140296568330840 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140296568331680 -> 140296456953984
	140296568331680 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140296456847144 -> 140296456846976
	140296456847144 [label=CudnnBatchNormBackward]
	140296456847312 -> 140296456847144
	140296456847312 [label=CudnnConvolutionBackward]
	140296456954320 -> 140296456847312
	140296456954320 [label=ReluBackward1]
	140296456955272 -> 140296456954320
	140296456955272 [label=CudnnBatchNormBackward]
	140296456954768 -> 140296456955272
	140296456954768 [label=CudnnConvolutionBackward]
	140296456847088 -> 140296456954768
	140296456843728 -> 140296456954768
	140296456843728 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456843560 -> 140296456955272
	140296456843560 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140296456843616 -> 140296456955272
	140296456843616 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140296456810168 -> 140296456847312
	140296456810168 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330560 -> 140296456847144
	140296568330560 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140296568331456 -> 140296456847144
	140296568331456 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140296456846864 -> 140296456846696
	140296456846864 [label=CudnnBatchNormBackward]
	140296456847032 -> 140296456846864
	140296456847032 [label=CudnnConvolutionBackward]
	140296456954040 -> 140296456847032
	140296456954040 [label=ReluBackward1]
	140296456956728 -> 140296456954040
	140296456956728 [label=CudnnBatchNormBackward]
	140296456955552 -> 140296456956728
	140296456955552 [label=CudnnConvolutionBackward]
	140296456846808 -> 140296456955552
	140296456844176 -> 140296456955552
	140296456844176 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456844008 -> 140296456956728
	140296456844008 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140296456844064 -> 140296456956728
	140296456844064 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140296456843784 -> 140296456847032
	140296456843784 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330280 -> 140296456846864
	140296568330280 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140296456809104 -> 140296456846864
	140296456809104 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140296456846584 -> 140296456846416
	140296456846584 [label=CudnnBatchNormBackward]
	140296456846752 -> 140296456846584
	140296456846752 [label=CudnnConvolutionBackward]
	140296456847200 -> 140296456846752
	140296456847200 [label=ReluBackward1]
	140296456955104 -> 140296456847200
	140296456955104 [label=CudnnBatchNormBackward]
	140296550110880 -> 140296456955104
	140296550110880 [label=CudnnConvolutionBackward]
	140296456846528 -> 140296550110880
	140296456844624 -> 140296550110880
	140296456844624 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456844456 -> 140296456955104
	140296456844456 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140296456844512 -> 140296456955104
	140296456844512 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140296456844232 -> 140296456846752
	140296456844232 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330000 -> 140296456846584
	140296568330000 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140296456843336 -> 140296456846584
	140296456843336 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140296456845408 -> 140296456845632
	140296456845408 [label=TBackward]
	140296568328992 -> 140296456845408
	140296568328992 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
