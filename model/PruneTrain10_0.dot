digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	139817612777680 [label=AddmmBackward fillcolor=darkolivegreen1]
	139817612778800 -> 139817612777680
	139817612778800 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	139817612666304 -> 139817612777680
	139817612666304 [label=ViewBackward]
	139817612776952 -> 139817612666304
	139817612776952 [label=ViewBackward]
	139817612667480 -> 139817612776952
	139817612667480 [label=MeanBackward1]
	139817732676464 -> 139817612667480
	139817732676464 [label=ViewBackward]
	139817732674784 -> 139817732676464
	139817732674784 [label=ReluBackward1]
	139817732676296 -> 139817732674784
	139817732676296 [label=AddBackward0]
	139817732673832 -> 139817732676296
	139817732673832 [label=ReluBackward1]
	139817732674728 -> 139817732673832
	139817732674728 [label=AddBackward0]
	139817612911448 -> 139817732674728
	139817612911448 [label=ReluBackward1]
	139817612911896 -> 139817612911448
	139817612911896 [label=AddBackward0]
	139817612911784 -> 139817612911896
	139817612911784 [label=ReluBackward1]
	139817612912568 -> 139817612911784
	139817612912568 [label=AddBackward0]
	139817612910664 -> 139817612912568
	139817612910664 [label=ReluBackward1]
	139817612912624 -> 139817612910664
	139817612912624 [label=AddBackward0]
	139817612912120 -> 139817612912624
	139817612912120 [label=ReluBackward1]
	139817612912792 -> 139817612912120
	139817612912792 [label=CudnnBatchNormBackward]
	139817612912904 -> 139817612912792
	139817612912904 [label=CudnnConvolutionBackward]
	139817612913128 -> 139817612912904
	139817612913128 [label=ReluBackward1]
	139817612913296 -> 139817612913128
	139817612913296 [label=CudnnBatchNormBackward]
	139817612913408 -> 139817612913296
	139817612913408 [label=CudnnConvolutionBackward]
	139817612913632 -> 139817612913408
	139817612913632 [label=ReluBackward1]
	139817612913800 -> 139817612913632
	139817612913800 [label=AddBackward0]
	139817612913912 -> 139817612913800
	139817612913912 [label=ReluBackward1]
	139817612914080 -> 139817612913912
	139817612914080 [label=AddBackward0]
	139817612914192 -> 139817612914080
	139817612914192 [label=ReluBackward1]
	139817612914360 -> 139817612914192
	139817612914360 [label=AddBackward0]
	139817612914472 -> 139817612914360
	139817612914472 [label=ReluBackward1]
	139817612914640 -> 139817612914472
	139817612914640 [label=AddBackward0]
	139816568639616 -> 139817612914640
	139816568639616 [label=ReluBackward1]
	139816568639784 -> 139816568639616
	139816568639784 [label=AddBackward0]
	139816568639896 -> 139816568639784
	139816568639896 [label=ReluBackward1]
	139816568640064 -> 139816568639896
	139816568640064 [label=CudnnBatchNormBackward]
	139816568640176 -> 139816568640064
	139816568640176 [label=CudnnConvolutionBackward]
	139816568640400 -> 139816568640176
	139816568640400 [label=ReluBackward1]
	139816568640568 -> 139816568640400
	139816568640568 [label=CudnnBatchNormBackward]
	139816568640680 -> 139816568640568
	139816568640680 [label=CudnnConvolutionBackward]
	139816568640904 -> 139816568640680
	139816568640904 [label=ReluBackward1]
	139816568641072 -> 139816568640904
	139816568641072 [label=AddBackward0]
	139816568641184 -> 139816568641072
	139816568641184 [label=ReluBackward1]
	139816568641352 -> 139816568641184
	139816568641352 [label=AddBackward0]
	139816568641464 -> 139816568641352
	139816568641464 [label=ReluBackward1]
	139816568641632 -> 139816568641464
	139816568641632 [label=AddBackward0]
	139816568641744 -> 139816568641632
	139816568641744 [label=ReluBackward1]
	139816568641912 -> 139816568641744
	139816568641912 [label=AddBackward0]
	139816568642024 -> 139816568641912
	139816568642024 [label=ReluBackward1]
	139816568642192 -> 139816568642024
	139816568642192 [label=AddBackward0]
	139816568642304 -> 139816568642192
	139816568642304 [label=ReluBackward1]
	139816568642472 -> 139816568642304
	139816568642472 [label=CudnnBatchNormBackward]
	139816568642584 -> 139816568642472
	139816568642584 [label=CudnnConvolutionBackward]
	139816568642808 -> 139816568642584
	139816568642808 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	139816568642640 -> 139816568642472
	139816568642640 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	139816568642696 -> 139816568642472
	139816568642696 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	139816568642360 -> 139816568642192
	139816568642360 [label=CudnnBatchNormBackward]
	139816568642528 -> 139816568642360
	139816568642528 [label=CudnnConvolutionBackward]
	139816568642920 -> 139816568642528
	139816568642920 [label=ReluBackward1]
	139816568643144 -> 139816568642920
	139816568643144 [label=CudnnBatchNormBackward]
	139816568643256 -> 139816568643144
	139816568643256 [label=CudnnConvolutionBackward]
	139816568642304 -> 139816568643256
	139816568643480 -> 139816568643256
	139816568643480 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568643312 -> 139816568643144
	139816568643312 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	139816568643368 -> 139816568643144
	139816568643368 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	139816568643032 -> 139816568642528
	139816568643032 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568642752 -> 139816568642360
	139816568642752 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	139816568642864 -> 139816568642360
	139816568642864 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	139816568642080 -> 139816568641912
	139816568642080 [label=CudnnBatchNormBackward]
	139816568642248 -> 139816568642080
	139816568642248 [label=CudnnConvolutionBackward]
	139816568643424 -> 139816568642248
	139816568643424 [label=ReluBackward1]
	139816568651848 -> 139816568643424
	139816568651848 [label=CudnnBatchNormBackward]
	139816568651960 -> 139816568651848
	139816568651960 [label=CudnnConvolutionBackward]
	139816568642024 -> 139816568651960
	139816568652184 -> 139816568651960
	139816568652184 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568652016 -> 139816568651848
	139816568652016 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	139816568652072 -> 139816568651848
	139816568652072 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	139816568643536 -> 139816568642248
	139816568643536 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568642416 -> 139816568642080
	139816568642416 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	139816568642976 -> 139816568642080
	139816568642976 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	139816568641800 -> 139816568641632
	139816568641800 [label=CudnnBatchNormBackward]
	139816568641968 -> 139816568641800
	139816568641968 [label=CudnnConvolutionBackward]
	139816568652128 -> 139816568641968
	139816568652128 [label=ReluBackward1]
	139816568652352 -> 139816568652128
	139816568652352 [label=CudnnBatchNormBackward]
	139816568652296 -> 139816568652352
	139816568652296 [label=CudnnConvolutionBackward]
	139816568641744 -> 139816568652296
	139816568652632 -> 139816568652296
	139816568652632 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568652464 -> 139816568652352
	139816568652464 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	139816568652520 -> 139816568652352
	139816568652520 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	139816568652240 -> 139816568641968
	139816568652240 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568642136 -> 139816568641800
	139816568642136 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	139816568643088 -> 139816568641800
	139816568643088 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	139816568641520 -> 139816568641352
	139816568641520 [label=CudnnBatchNormBackward]
	139816568641688 -> 139816568641520
	139816568641688 [label=CudnnConvolutionBackward]
	139816568652576 -> 139816568641688
	139816568652576 [label=ReluBackward1]
	139816568652800 -> 139816568652576
	139816568652800 [label=CudnnBatchNormBackward]
	139816568652744 -> 139816568652800
	139816568652744 [label=CudnnConvolutionBackward]
	139816568641464 -> 139816568652744
	139816568653080 -> 139816568652744
	139816568653080 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568652912 -> 139816568652800
	139816568652912 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	139816568652968 -> 139816568652800
	139816568652968 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	139816568652688 -> 139816568641688
	139816568652688 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568641856 -> 139816568641520
	139816568641856 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	139816568643200 -> 139816568641520
	139816568643200 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	139816568641240 -> 139816568641072
	139816568641240 [label=CudnnBatchNormBackward]
	139816568641408 -> 139816568641240
	139816568641408 [label=CudnnConvolutionBackward]
	139816568653024 -> 139816568641408
	139816568653024 [label=ReluBackward1]
	139816568653248 -> 139816568653024
	139816568653248 [label=CudnnBatchNormBackward]
	139816568653192 -> 139816568653248
	139816568653192 [label=CudnnConvolutionBackward]
	139816568641184 -> 139816568653192
	139816568653528 -> 139816568653192
	139816568653528 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568653360 -> 139816568653248
	139816568653360 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	139816568653416 -> 139816568653248
	139816568653416 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	139816568653136 -> 139816568641408
	139816568653136 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139816568641576 -> 139816568641240
	139816568641576 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	139816568651904 -> 139816568641240
	139816568651904 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	139816568640960 -> 139816568640680
	139816568640960 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	139816568640736 -> 139816568640568
	139816568640736 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	139816568640792 -> 139816568640568
	139816568640792 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	139816568640456 -> 139816568640176
	139816568640456 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568640232 -> 139816568640064
	139816568640232 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	139816568640288 -> 139816568640064
	139816568640288 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	139816568639952 -> 139816568639784
	139816568639952 [label=CudnnBatchNormBackward]
	139816568640120 -> 139816568639952
	139816568640120 [label=CudnnConvolutionBackward]
	139816568640904 -> 139816568640120
	139816568641016 -> 139816568640120
	139816568641016 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	139816568640344 -> 139816568639952
	139816568640344 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	139816568640512 -> 139816568639952
	139816568640512 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	139816568639672 -> 139817612914640
	139816568639672 [label=CudnnBatchNormBackward]
	139816568639840 -> 139816568639672
	139816568639840 [label=CudnnConvolutionBackward]
	139816568641128 -> 139816568639840
	139816568641128 [label=ReluBackward1]
	139816568652856 -> 139816568641128
	139816568652856 [label=CudnnBatchNormBackward]
	139816568653584 -> 139816568652856
	139816568653584 [label=CudnnConvolutionBackward]
	139816568639616 -> 139816568653584
	139816568653640 -> 139816568653584
	139816568653640 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568653304 -> 139816568652856
	139816568653304 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	139816568653696 -> 139816568652856
	139816568653696 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	139816568641296 -> 139816568639840
	139816568641296 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568640008 -> 139816568639672
	139816568640008 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	139816568640848 -> 139816568639672
	139816568640848 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	139817612914528 -> 139817612914360
	139817612914528 [label=CudnnBatchNormBackward]
	139816568639560 -> 139817612914528
	139816568639560 [label=CudnnConvolutionBackward]
	139816568653752 -> 139816568639560
	139816568653752 [label=ReluBackward1]
	139816568653920 -> 139816568653752
	139816568653920 [label=CudnnBatchNormBackward]
	139816568653864 -> 139816568653920
	139816568653864 [label=CudnnConvolutionBackward]
	139817612914472 -> 139816568653864
	139816568654200 -> 139816568653864
	139816568654200 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568654032 -> 139816568653920
	139816568654032 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	139816568654088 -> 139816568653920
	139816568654088 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	139816568653808 -> 139816568639560
	139816568653808 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568639728 -> 139817612914528
	139816568639728 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	139816568640624 -> 139817612914528
	139816568640624 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	139817612914248 -> 139817612914080
	139817612914248 [label=CudnnBatchNormBackward]
	139817612914416 -> 139817612914248
	139817612914416 [label=CudnnConvolutionBackward]
	139816568654144 -> 139817612914416
	139816568654144 [label=ReluBackward1]
	139816568654368 -> 139816568654144
	139816568654368 [label=CudnnBatchNormBackward]
	139816568654312 -> 139816568654368
	139816568654312 [label=CudnnConvolutionBackward]
	139817612914192 -> 139816568654312
	139816568654648 -> 139816568654312
	139816568654648 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568654480 -> 139816568654368
	139816568654480 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	139816568654536 -> 139816568654368
	139816568654536 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	139816568654256 -> 139817612914416
	139816568654256 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139817612914584 -> 139817612914248
	139817612914584 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	139816568652408 -> 139817612914248
	139816568652408 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	139817612913968 -> 139817612913800
	139817612913968 [label=CudnnBatchNormBackward]
	139817612914136 -> 139817612913968
	139817612914136 [label=CudnnConvolutionBackward]
	139816568654592 -> 139817612914136
	139816568654592 [label=ReluBackward1]
	139816568654816 -> 139816568654592
	139816568654816 [label=CudnnBatchNormBackward]
	139816568654760 -> 139816568654816
	139816568654760 [label=CudnnConvolutionBackward]
	139817612913912 -> 139816568654760
	139816568655096 -> 139816568654760
	139816568655096 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139816568654928 -> 139816568654816
	139816568654928 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	139816568654984 -> 139816568654816
	139816568654984 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	139816568654704 -> 139817612914136
	139816568654704 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139817612914304 -> 139817612913968
	139817612914304 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	139816568653472 -> 139817612913968
	139816568653472 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	139817612913688 -> 139817612913408
	139817612913688 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139817612913464 -> 139817612913296
	139817612913464 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	139817612913520 -> 139817612913296
	139817612913520 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	139817612913184 -> 139817612912904
	139817612913184 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139817612912960 -> 139817612912792
	139817612912960 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	139817612913016 -> 139817612912792
	139817612913016 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	139817612910832 -> 139817612912624
	139817612910832 [label=CudnnBatchNormBackward]
	139817612912848 -> 139817612910832
	139817612912848 [label=CudnnConvolutionBackward]
	139817612913632 -> 139817612912848
	139817612913744 -> 139817612912848
	139817612913744 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139817612913072 -> 139817612910832
	139817612913072 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	139817612913240 -> 139817612910832
	139817612913240 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	139817612911952 -> 139817612912568
	139817612911952 [label=CudnnBatchNormBackward]
	139817612911672 -> 139817612911952
	139817612911672 [label=CudnnConvolutionBackward]
	139817612913856 -> 139817612911672
	139817612913856 [label=ReluBackward1]
	139816568654424 -> 139817612913856
	139816568654424 [label=CudnnBatchNormBackward]
	139816568655152 -> 139816568654424
	139816568655152 [label=CudnnConvolutionBackward]
	139817612910664 -> 139816568655152
	139816568655208 -> 139816568655152
	139816568655208 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139816568654872 -> 139816568654424
	139816568654872 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	139816568655264 -> 139816568654424
	139816568655264 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	139817612914024 -> 139817612911672
	139817612914024 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139817612912736 -> 139817612911952
	139817612912736 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	139817612913576 -> 139817612911952
	139817612913576 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	139817612912680 -> 139817612911896
	139817612912680 [label=CudnnBatchNormBackward]
	139817612911336 -> 139817612912680
	139817612911336 [label=CudnnConvolutionBackward]
	139816568655320 -> 139817612911336
	139816568655320 [label=ReluBackward1]
	139816568655488 -> 139816568655320
	139816568655488 [label=CudnnBatchNormBackward]
	139816568655432 -> 139816568655488
	139816568655432 [label=CudnnConvolutionBackward]
	139817612911784 -> 139816568655432
	139816568655768 -> 139816568655432
	139816568655768 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139816568655600 -> 139816568655488
	139816568655600 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	139816568655656 -> 139816568655488
	139816568655656 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	139816568655376 -> 139817612911336
	139816568655376 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139817612912008 -> 139817612912680
	139817612912008 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	139817612913352 -> 139817612912680
	139817612913352 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	139817612911392 -> 139817732674728
	139817612911392 [label=CudnnBatchNormBackward]
	139817612911560 -> 139817612911392
	139817612911560 [label=CudnnConvolutionBackward]
	139816568655712 -> 139817612911560
	139816568655712 [label=ReluBackward1]
	139816568684616 -> 139816568655712
	139816568684616 [label=CudnnBatchNormBackward]
	139816568684728 -> 139816568684616
	139816568684728 [label=CudnnConvolutionBackward]
	139817612911448 -> 139816568684728
	139816568684952 -> 139816568684728
	139816568684952 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139816568684784 -> 139816568684616
	139816568684784 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	139816568684840 -> 139816568684616
	139816568684840 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	139816568655824 -> 139817612911560
	139816568655824 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139817612911616 -> 139817612911392
	139817612911616 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	139816568653976 -> 139817612911392
	139816568653976 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	139817732674896 -> 139817732676296
	139817732674896 [label=CudnnBatchNormBackward]
	139817612911728 -> 139817732674896
	139817612911728 [label=CudnnConvolutionBackward]
	139816568684896 -> 139817612911728
	139816568684896 [label=ReluBackward1]
	139816568685120 -> 139816568684896
	139816568685120 [label=CudnnBatchNormBackward]
	139816568685064 -> 139816568685120
	139816568685064 [label=CudnnConvolutionBackward]
	139817732673832 -> 139816568685064
	139816568685400 -> 139816568685064
	139816568685400 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139816568685232 -> 139816568685120
	139816568685232 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	139816568685288 -> 139816568685120
	139816568685288 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	139816568685008 -> 139817612911728
	139816568685008 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139817612911840 -> 139817732674896
	139817612911840 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	139816568655040 -> 139817732674896
	139816568655040 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	139817612668264 -> 139817612777680
	139817612668264 [label=TBackward]
	139817612666528 -> 139817612668264
	139817612666528 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
