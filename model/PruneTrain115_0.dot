digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140517403462400 [label=AddmmBackward fillcolor=darkolivegreen1]
	140517523634552 -> 140517403462400
	140517523634552 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140517403461448 -> 140517403462400
	140517403461448 [label=ViewBackward]
	140517374790176 -> 140517403461448
	140517374790176 [label=ViewBackward]
	140517374790064 -> 140517374790176
	140517374790064 [label=MeanBackward1]
	140517374791184 -> 140517374790064
	140517374791184 [label=ViewBackward]
	140517374789168 -> 140517374791184
	140517374789168 [label=ReluBackward1]
	140517374791072 -> 140517374789168
	140517374791072 [label=AddBackward0]
	140517374788944 -> 140517374791072
	140517374788944 [label=ReluBackward1]
	140517374791520 -> 140517374788944
	140517374791520 [label=AddBackward0]
	140517374789728 -> 140517374791520
	140517374789728 [label=ReluBackward1]
	140517374791296 -> 140517374789728
	140517374791296 [label=AddBackward0]
	140517374790848 -> 140517374791296
	140517374790848 [label=ReluBackward1]
	140517374789504 -> 140517374790848
	140517374789504 [label=AddBackward0]
	140517374788160 -> 140517374789504
	140517374788160 [label=ReluBackward1]
	140517374789560 -> 140517374788160
	140517374789560 [label=AddBackward0]
	140517374789896 -> 140517374789560
	140517374789896 [label=ReluBackward1]
	140517374791632 -> 140517374789896
	140517374791632 [label=CudnnBatchNormBackward]
	140517374790904 -> 140517374791632
	140517374790904 [label=CudnnConvolutionBackward]
	140517374788888 -> 140517374790904
	140517374788888 [label=ReluBackward1]
	140517374789672 -> 140517374788888
	140517374789672 [label=CudnnBatchNormBackward]
	140517374790008 -> 140517374789672
	140517374790008 [label=CudnnConvolutionBackward]
	140517374791240 -> 140517374790008
	140517374791240 [label=ReluBackward1]
	140517374791016 -> 140517374791240
	140517374791016 [label=AddBackward0]
	140517374657928 -> 140517374791016
	140517374657928 [label=ReluBackward1]
	140517374657200 -> 140517374657928
	140517374657200 [label=AddBackward0]
	140517374657704 -> 140517374657200
	140517374657704 [label=ReluBackward1]
	140517374657368 -> 140517374657704
	140517374657368 [label=AddBackward0]
	140517374657592 -> 140517374657368
	140517374657592 [label=ReluBackward1]
	140517374658264 -> 140517374657592
	140517374658264 [label=AddBackward0]
	140517374659888 -> 140517374658264
	140517374659888 [label=ReluBackward1]
	140516806086840 -> 140517374659888
	140516806086840 [label=AddBackward0]
	140516806087176 -> 140516806086840
	140516806087176 [label=ReluBackward1]
	140516806087288 -> 140516806087176
	140516806087288 [label=CudnnBatchNormBackward]
	140516806087400 -> 140516806087288
	140516806087400 [label=CudnnConvolutionBackward]
	140516806087512 -> 140516806087400
	140516806087512 [label=ReluBackward1]
	140516806087624 -> 140516806087512
	140516806087624 [label=CudnnBatchNormBackward]
	140516806087736 -> 140516806087624
	140516806087736 [label=CudnnConvolutionBackward]
	140516806087848 -> 140516806087736
	140516806087848 [label=ReluBackward1]
	140516806087960 -> 140516806087848
	140516806087960 [label=AddBackward0]
	140516806088072 -> 140516806087960
	140516806088072 [label=ReluBackward1]
	140516806088240 -> 140516806088072
	140516806088240 [label=AddBackward0]
	140516806088352 -> 140516806088240
	140516806088352 [label=ReluBackward1]
	140516806088520 -> 140516806088352
	140516806088520 [label=AddBackward0]
	140516806088632 -> 140516806088520
	140516806088632 [label=ReluBackward1]
	140516806088800 -> 140516806088632
	140516806088800 [label=AddBackward0]
	140516806088912 -> 140516806088800
	140516806088912 [label=ReluBackward1]
	140516806089080 -> 140516806088912
	140516806089080 [label=AddBackward0]
	140516805881808 -> 140516806089080
	140516805881808 [label=ReluBackward1]
	140516805881640 -> 140516805881808
	140516805881640 [label=CudnnBatchNormBackward]
	140516805881528 -> 140516805881640
	140516805881528 [label=CudnnConvolutionBackward]
	140516805881304 -> 140516805881528
	140516805881304 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140516805881472 -> 140516805881640
	140516805881472 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140516805881416 -> 140516805881640
	140516805881416 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140516805881752 -> 140516806089080
	140516805881752 [label=CudnnBatchNormBackward]
	140516805881584 -> 140516805881752
	140516805881584 [label=CudnnConvolutionBackward]
	140516805881192 -> 140516805881584
	140516805881192 [label=ReluBackward1]
	140516805880968 -> 140516805881192
	140516805880968 [label=CudnnBatchNormBackward]
	140516805880856 -> 140516805880968
	140516805880856 [label=CudnnConvolutionBackward]
	140516805881808 -> 140516805880856
	140516805880632 -> 140516805880856
	140516805880632 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805880800 -> 140516805880968
	140516805880800 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140516805880744 -> 140516805880968
	140516805880744 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140516805881080 -> 140516805881584
	140516805881080 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805881360 -> 140516805881752
	140516805881360 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140516805881248 -> 140516805881752
	140516805881248 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140516806088968 -> 140516806088800
	140516806088968 [label=CudnnBatchNormBackward]
	140516805881696 -> 140516806088968
	140516805881696 [label=CudnnConvolutionBackward]
	140516805880576 -> 140516805881696
	140516805880576 [label=ReluBackward1]
	140516805880408 -> 140516805880576
	140516805880408 [label=CudnnBatchNormBackward]
	140516805880352 -> 140516805880408
	140516805880352 [label=CudnnConvolutionBackward]
	140516806088912 -> 140516805880352
	140516805880128 -> 140516805880352
	140516805880128 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805880296 -> 140516805880408
	140516805880296 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140516805880240 -> 140516805880408
	140516805880240 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140516805880912 -> 140516805881696
	140516805880912 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805881136 -> 140516806088968
	140516805881136 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140516805881024 -> 140516806088968
	140516805881024 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140516806088688 -> 140516806088520
	140516806088688 [label=CudnnBatchNormBackward]
	140516805880688 -> 140516806088688
	140516805880688 [label=CudnnConvolutionBackward]
	140516805880520 -> 140516805880688
	140516805880520 [label=ReluBackward1]
	140516805880016 -> 140516805880520
	140516805880016 [label=CudnnBatchNormBackward]
	140516805879792 -> 140516805880016
	140516805879792 [label=CudnnConvolutionBackward]
	140516806088632 -> 140516805879792
	140516805879568 -> 140516805879792
	140516805879568 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805879736 -> 140516805880016
	140516805879736 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140516805879680 -> 140516805880016
	140516805879680 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140516805879960 -> 140516805880688
	140516805879960 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805880464 -> 140516806088688
	140516805880464 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140516805880184 -> 140516806088688
	140516805880184 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140516806088408 -> 140516806088240
	140516806088408 [label=CudnnBatchNormBackward]
	140516805880072 -> 140516806088408
	140516805880072 [label=CudnnConvolutionBackward]
	140516805879848 -> 140516805880072
	140516805879848 [label=ReluBackward1]
	140516805879456 -> 140516805879848
	140516805879456 [label=CudnnBatchNormBackward]
	140516805879232 -> 140516805879456
	140516805879232 [label=CudnnConvolutionBackward]
	140516806088352 -> 140516805879232
	140516805878952 -> 140516805879232
	140516805878952 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805879120 -> 140516805879456
	140516805879120 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140516805879064 -> 140516805879456
	140516805879064 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140516805879400 -> 140516805880072
	140516805879400 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805879904 -> 140516806088408
	140516805879904 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140516805879624 -> 140516806088408
	140516805879624 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140516806088128 -> 140516806087960
	140516806088128 [label=CudnnBatchNormBackward]
	140516805879512 -> 140516806088128
	140516805879512 [label=CudnnConvolutionBackward]
	140516805879288 -> 140516805879512
	140516805879288 [label=ReluBackward1]
	140516805878840 -> 140516805879288
	140516805878840 [label=CudnnBatchNormBackward]
	140516805878616 -> 140516805878840
	140516805878616 [label=CudnnConvolutionBackward]
	140516806088072 -> 140516805878616
	140516805878392 -> 140516805878616
	140516805878392 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805878560 -> 140516805878840
	140516805878560 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140516805878504 -> 140516805878840
	140516805878504 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140516805878784 -> 140516805879512
	140516805878784 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516805879344 -> 140516806088128
	140516805879344 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140516805879008 -> 140516806088128
	140516805879008 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140517375268680 -> 140516806087736
	140517375268680 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140517375268456 -> 140516806087624
	140517375268456 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140517375268512 -> 140516806087624
	140517375268512 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140517375268176 -> 140516806087400
	140517375268176 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140517375267952 -> 140516806087288
	140517375267952 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140517375268008 -> 140516806087288
	140517375268008 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140516806087232 -> 140516806086840
	140516806087232 [label=CudnnBatchNormBackward]
	140516805878448 -> 140516806087232
	140516805878448 [label=CudnnConvolutionBackward]
	140516806087848 -> 140516805878448
	140516805878672 -> 140516805878448
	140516805878672 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140516805878896 -> 140516806087232
	140516805878896 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140516805878728 -> 140516806087232
	140516805878728 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140516806087064 -> 140517374658264
	140516806087064 [label=CudnnBatchNormBackward]
	140516805878336 -> 140516806087064
	140516805878336 [label=CudnnConvolutionBackward]
	140516805878168 -> 140516805878336
	140516805878168 [label=ReluBackward1]
	140516805877944 -> 140516805878168
	140516805877944 [label=CudnnBatchNormBackward]
	140516805877832 -> 140516805877944
	140516805877832 [label=CudnnConvolutionBackward]
	140517374659888 -> 140516805877832
	140516806279008 -> 140516805877832
	140516806279008 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516806276600 -> 140516805877944
	140516806276600 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140516806276544 -> 140516805877944
	140516806276544 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140516805878056 -> 140516805878336
	140516805878056 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516805878224 -> 140516806087064
	140516805878224 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140516805878280 -> 140516806087064
	140516805878280 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140517374658040 -> 140517374657368
	140517374658040 [label=CudnnBatchNormBackward]
	140516805878112 -> 140517374658040
	140516805878112 [label=CudnnConvolutionBackward]
	140516806278896 -> 140516805878112
	140516806278896 [label=ReluBackward1]
	140516806278840 -> 140516806278896
	140516806278840 [label=CudnnBatchNormBackward]
	140516806278616 -> 140516806278840
	140516806278616 [label=CudnnConvolutionBackward]
	140517374657592 -> 140516806278616
	140516806278392 -> 140516806278616
	140516806278392 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516806278560 -> 140516806278840
	140516806278560 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140516806278504 -> 140516806278840
	140516806278504 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140516806278784 -> 140516805878112
	140516806278784 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516805878000 -> 140517374658040
	140516805878000 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140516805877888 -> 140517374658040
	140516805877888 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140517374658432 -> 140517374657200
	140517374658432 [label=CudnnBatchNormBackward]
	140516806279120 -> 140517374658432
	140516806279120 [label=CudnnConvolutionBackward]
	140516806278672 -> 140516806279120
	140516806278672 [label=ReluBackward1]
	140516806278280 -> 140516806278672
	140516806278280 [label=CudnnBatchNormBackward]
	140516806278056 -> 140516806278280
	140516806278056 [label=CudnnConvolutionBackward]
	140517374657704 -> 140516806278056
	140516806277832 -> 140516806278056
	140516806277832 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516806278000 -> 140516806278280
	140516806278000 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140516806277944 -> 140516806278280
	140516806277944 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140516806278224 -> 140516806279120
	140516806278224 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516806278728 -> 140517374658432
	140516806278728 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140516806278448 -> 140517374658432
	140516806278448 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140517374657424 -> 140517374791016
	140517374657424 [label=CudnnBatchNormBackward]
	140516806278336 -> 140517374657424
	140516806278336 [label=CudnnConvolutionBackward]
	140516806278112 -> 140516806278336
	140516806278112 [label=ReluBackward1]
	140516806277664 -> 140516806278112
	140516806277664 [label=CudnnBatchNormBackward]
	140516806277384 -> 140516806277664
	140516806277384 [label=CudnnConvolutionBackward]
	140517374657928 -> 140516806277384
	140516806276936 -> 140516806277384
	140516806276936 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516806277272 -> 140516806277664
	140516806277272 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140516806277160 -> 140516806277664
	140516806277160 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140516806277608 -> 140516806278336
	140516806277608 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516806278168 -> 140517374657424
	140516806278168 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140516806277888 -> 140517374657424
	140516806277888 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140517400747424 -> 140517374790008
	140517400747424 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140517400747200 -> 140517374789672
	140517400747200 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140517400747256 -> 140517374789672
	140517400747256 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140517400746920 -> 140517374790904
	140517400746920 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517400746696 -> 140517374791632
	140517400746696 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140517400746752 -> 140517374791632
	140517400746752 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140517374790232 -> 140517374789560
	140517374790232 [label=CudnnBatchNormBackward]
	140516806277048 -> 140517374790232
	140516806277048 [label=CudnnConvolutionBackward]
	140517374791240 -> 140516806277048
	140516806277440 -> 140516806277048
	140516806277440 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140516806277720 -> 140517374790232
	140516806277720 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140516806277552 -> 140517374790232
	140516806277552 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140517374787656 -> 140517374789504
	140517374787656 [label=CudnnBatchNormBackward]
	140516806276824 -> 140517374787656
	140516806276824 [label=CudnnConvolutionBackward]
	140516806276432 -> 140516806276824
	140516806276432 [label=ReluBackward1]
	140517374574376 -> 140516806276432
	140517374574376 [label=CudnnBatchNormBackward]
	140517374574264 -> 140517374574376
	140517374574264 [label=CudnnConvolutionBackward]
	140517374788160 -> 140517374574264
	140517374574040 -> 140517374574264
	140517374574040 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374574208 -> 140517374574376
	140517374574208 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140517374574152 -> 140517374574376
	140517374574152 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140517374574488 -> 140516806276824
	140517374574488 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516806276656 -> 140517374787656
	140516806276656 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140516806276712 -> 140517374787656
	140516806276712 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140517374789616 -> 140517374791296
	140517374789616 [label=CudnnBatchNormBackward]
	140516806279064 -> 140517374789616
	140516806279064 [label=CudnnConvolutionBackward]
	140517374574320 -> 140516806279064
	140517374574320 [label=ReluBackward1]
	140517374573928 -> 140517374574320
	140517374573928 [label=CudnnBatchNormBackward]
	140517374573704 -> 140517374573928
	140517374573704 [label=CudnnConvolutionBackward]
	140517374790848 -> 140517374573704
	140517374573480 -> 140517374573704
	140517374573480 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374573648 -> 140517374573928
	140517374573648 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140517374573592 -> 140517374573928
	140517374573592 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140517374573872 -> 140516806279064
	140517374573872 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374574432 -> 140517374789616
	140517374574432 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140517374574096 -> 140517374789616
	140517374574096 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140517374789448 -> 140517374791520
	140517374789448 [label=CudnnBatchNormBackward]
	140517374573984 -> 140517374789448
	140517374573984 [label=CudnnConvolutionBackward]
	140517374573760 -> 140517374573984
	140517374573760 [label=ReluBackward1]
	140517374573368 -> 140517374573760
	140517374573368 [label=CudnnBatchNormBackward]
	140517374573144 -> 140517374573368
	140517374573144 [label=CudnnConvolutionBackward]
	140517374789728 -> 140517374573144
	140517374572920 -> 140517374573144
	140517374572920 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374573088 -> 140517374573368
	140517374573088 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140517374573032 -> 140517374573368
	140517374573032 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140517374573312 -> 140517374573984
	140517374573312 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374573816 -> 140517374789448
	140517374573816 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140517374573536 -> 140517374789448
	140517374573536 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140517374790288 -> 140517374791072
	140517374790288 [label=CudnnBatchNormBackward]
	140517374573424 -> 140517374790288
	140517374573424 [label=CudnnConvolutionBackward]
	140517374573200 -> 140517374573424
	140517374573200 [label=ReluBackward1]
	140517374572808 -> 140517374573200
	140517374572808 [label=CudnnBatchNormBackward]
	140517374572584 -> 140517374572808
	140517374572584 [label=CudnnConvolutionBackward]
	140517374788944 -> 140517374572584
	140517374572304 -> 140517374572584
	140517374572304 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374572528 -> 140517374572808
	140517374572528 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140517374572472 -> 140517374572808
	140517374572472 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140517374572752 -> 140517374573424
	140517374572752 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140517374573256 -> 140517374790288
	140517374573256 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140517374572976 -> 140517374790288
	140517374572976 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140517374789392 -> 140517403462400
	140517374789392 [label=TBackward]
	140517374572864 -> 140517374789392
	140517374572864 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
