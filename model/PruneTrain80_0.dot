digraph {
	graph [size="60.3,60.3"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140248751689856 [label=AddmmBackward fillcolor=darkolivegreen1]
	140248750347376 -> 140248751689856
	140248750347376 [label="module_list.59.bias
 (10)" fillcolor=lightblue]
	140248750348720 -> 140248751689856
	140248750348720 [label=ViewBackward]
	140248750348944 -> 140248750348720
	140248750348944 [label=ViewBackward]
	140248750347152 -> 140248750348944
	140248750347152 [label=MeanBackward1]
	140248750347544 -> 140248750347152
	140248750347544 [label=ViewBackward]
	140248750348888 -> 140248750347544
	140248750348888 [label=ReluBackward1]
	140248750348664 -> 140248750348888
	140248750348664 [label=AddBackward0]
	140248750349504 -> 140248750348664
	140248750349504 [label=ReluBackward1]
	140248750349672 -> 140248750349504
	140248750349672 [label=AddBackward0]
	140248750349784 -> 140248750349672
	140248750349784 [label=ReluBackward1]
	140248750349952 -> 140248750349784
	140248750349952 [label=AddBackward0]
	140248750350064 -> 140248750349952
	140248750350064 [label=ReluBackward1]
	140248750350232 -> 140248750350064
	140248750350232 [label=AddBackward0]
	140246628102216 -> 140248750350232
	140246628102216 [label=ReluBackward1]
	140246628102384 -> 140246628102216
	140246628102384 [label=CudnnBatchNormBackward]
	140246628102496 -> 140246628102384
	140246628102496 [label=CudnnConvolutionBackward]
	140246628102720 -> 140246628102496
	140246628102720 [label=ReluBackward1]
	140246628102888 -> 140246628102720
	140246628102888 [label=CudnnBatchNormBackward]
	140246628103000 -> 140246628102888
	140246628103000 [label=CudnnConvolutionBackward]
	140246628103224 -> 140246628103000
	140246628103224 [label=ReluBackward1]
	140246628103392 -> 140246628103224
	140246628103392 [label=AddBackward0]
	140246628103504 -> 140246628103392
	140246628103504 [label=ReluBackward1]
	140246628103672 -> 140246628103504
	140246628103672 [label=AddBackward0]
	140246628103784 -> 140246628103672
	140246628103784 [label=ReluBackward1]
	140246628103952 -> 140246628103784
	140246628103952 [label=AddBackward0]
	140246628104064 -> 140246628103952
	140246628104064 [label=ReluBackward1]
	140246628104232 -> 140246628104064
	140246628104232 [label=AddBackward0]
	140246628104344 -> 140246628104232
	140246628104344 [label=ReluBackward1]
	140246628104512 -> 140246628104344
	140246628104512 [label=CudnnBatchNormBackward]
	140246628104624 -> 140246628104512
	140246628104624 [label=CudnnConvolutionBackward]
	140246628104848 -> 140246628104624
	140246628104848 [label=ReluBackward1]
	140246628105016 -> 140246628104848
	140246628105016 [label=CudnnBatchNormBackward]
	140246628105128 -> 140246628105016
	140246628105128 [label=CudnnConvolutionBackward]
	140246628105352 -> 140246628105128
	140246628105352 [label=ReluBackward1]
	140246628105520 -> 140246628105352
	140246628105520 [label=AddBackward0]
	140246628105632 -> 140246628105520
	140246628105632 [label=ReluBackward1]
	140246628105800 -> 140246628105632
	140246628105800 [label=AddBackward0]
	140246628105912 -> 140246628105800
	140246628105912 [label=ReluBackward1]
	140246628106080 -> 140246628105912
	140246628106080 [label=AddBackward0]
	140246628106192 -> 140246628106080
	140246628106192 [label=ReluBackward1]
	140246628110520 -> 140246628106192
	140246628110520 [label=AddBackward0]
	140246628110632 -> 140246628110520
	140246628110632 [label=ReluBackward1]
	140246628110800 -> 140246628110632
	140246628110800 [label=AddBackward0]
	140246628110912 -> 140246628110800
	140246628110912 [label=ReluBackward1]
	140246628111080 -> 140246628110912
	140246628111080 [label=CudnnBatchNormBackward]
	140246628111192 -> 140246628111080
	140246628111192 [label=CudnnConvolutionBackward]
	140246628111416 -> 140246628111192
	140246628111416 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140246628111248 -> 140246628111080
	140246628111248 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140246628111304 -> 140246628111080
	140246628111304 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140246628110968 -> 140246628110800
	140246628110968 [label=CudnnBatchNormBackward]
	140246628111136 -> 140246628110968
	140246628111136 [label=CudnnConvolutionBackward]
	140246628111528 -> 140246628111136
	140246628111528 [label=ReluBackward1]
	140246628111752 -> 140246628111528
	140246628111752 [label=CudnnBatchNormBackward]
	140246628111864 -> 140246628111752
	140246628111864 [label=CudnnConvolutionBackward]
	140246628110912 -> 140246628111864
	140246628112088 -> 140246628111864
	140246628112088 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140246628111920 -> 140246628111752
	140246628111920 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140246628111976 -> 140246628111752
	140246628111976 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140246628111640 -> 140246628111136
	140246628111640 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140246628111360 -> 140246628110968
	140246628111360 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140246628111472 -> 140246628110968
	140246628111472 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140246628110688 -> 140246628110520
	140246628110688 [label=CudnnBatchNormBackward]
	140246628110856 -> 140246628110688
	140246628110856 [label=CudnnConvolutionBackward]
	140246628112032 -> 140246628110856
	140246628112032 [label=ReluBackward1]
	140246628112256 -> 140246628112032
	140246628112256 [label=CudnnBatchNormBackward]
	140246628112200 -> 140246628112256
	140246628112200 [label=CudnnConvolutionBackward]
	140246628110632 -> 140246628112200
	140246628112536 -> 140246628112200
	140246628112536 [label="module_list.6.weight
 (15, 16, 3, 3)" fillcolor=lightblue]
	140246628112368 -> 140246628112256
	140246628112368 [label="module_list.7.weight
 (15)" fillcolor=lightblue]
	140246628112424 -> 140246628112256
	140246628112424 [label="module_list.7.bias
 (15)" fillcolor=lightblue]
	140246628112144 -> 140246628110856
	140246628112144 [label="module_list.8.weight
 (16, 15, 3, 3)" fillcolor=lightblue]
	140246628111024 -> 140246628110688
	140246628111024 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140246628111584 -> 140246628110688
	140246628111584 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140246628110408 -> 140246628106080
	140246628110408 [label=CudnnBatchNormBackward]
	140246628110576 -> 140246628110408
	140246628110576 [label=CudnnConvolutionBackward]
	140246628112480 -> 140246628110576
	140246628112480 [label=ReluBackward1]
	140246628112704 -> 140246628112480
	140246628112704 [label=CudnnBatchNormBackward]
	140246628112648 -> 140246628112704
	140246628112648 [label=CudnnConvolutionBackward]
	140246628106192 -> 140246628112648
	140246628112984 -> 140246628112648
	140246628112984 [label="module_list.10.weight
 (11, 16, 3, 3)" fillcolor=lightblue]
	140246628112816 -> 140246628112704
	140246628112816 [label="module_list.11.weight
 (11)" fillcolor=lightblue]
	140246628112872 -> 140246628112704
	140246628112872 [label="module_list.11.bias
 (11)" fillcolor=lightblue]
	140246628112592 -> 140246628110576
	140246628112592 [label="module_list.12.weight
 (16, 11, 3, 3)" fillcolor=lightblue]
	140246628110744 -> 140246628110408
	140246628110744 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140246628111696 -> 140246628110408
	140246628111696 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140246628105968 -> 140246628105800
	140246628105968 [label=CudnnBatchNormBackward]
	140246628106136 -> 140246628105968
	140246628106136 [label=CudnnConvolutionBackward]
	140246628112928 -> 140246628106136
	140246628112928 [label=ReluBackward1]
	140246628113152 -> 140246628112928
	140246628113152 [label=CudnnBatchNormBackward]
	140246628113096 -> 140246628113152
	140246628113096 [label=CudnnConvolutionBackward]
	140246628105912 -> 140246628113096
	140246628113432 -> 140246628113096
	140246628113432 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140246628113264 -> 140246628113152
	140246628113264 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140246628113320 -> 140246628113152
	140246628113320 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140246628113040 -> 140246628106136
	140246628113040 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140246628110464 -> 140246628105968
	140246628110464 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140246628111808 -> 140246628105968
	140246628111808 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140246628105688 -> 140246628105520
	140246628105688 [label=CudnnBatchNormBackward]
	140246628105856 -> 140246628105688
	140246628105856 [label=CudnnConvolutionBackward]
	140246628113376 -> 140246628105856
	140246628113376 [label=ReluBackward1]
	140246628113600 -> 140246628113376
	140246628113600 [label=CudnnBatchNormBackward]
	140246628113544 -> 140246628113600
	140246628113544 [label=CudnnConvolutionBackward]
	140246628105632 -> 140246628113544
	140246628113880 -> 140246628113544
	140246628113880 [label="module_list.18.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	140246628113712 -> 140246628113600
	140246628113712 [label="module_list.19.weight
 (14)" fillcolor=lightblue]
	140246628113768 -> 140246628113600
	140246628113768 [label="module_list.19.bias
 (14)" fillcolor=lightblue]
	140246628113488 -> 140246628105856
	140246628113488 [label="module_list.20.weight
 (16, 14, 3, 3)" fillcolor=lightblue]
	140246628106024 -> 140246628105688
	140246628106024 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140246628112312 -> 140246628105688
	140246628112312 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140246628105408 -> 140246628105128
	140246628105408 [label="module_list.22.weight
 (30, 16, 3, 3)" fillcolor=lightblue]
	140246628105184 -> 140246628105016
	140246628105184 [label="module_list.23.weight
 (30)" fillcolor=lightblue]
	140246628105240 -> 140246628105016
	140246628105240 [label="module_list.23.bias
 (30)" fillcolor=lightblue]
	140246628104904 -> 140246628104624
	140246628104904 [label="module_list.24.weight
 (32, 30, 3, 3)" fillcolor=lightblue]
	140246628104680 -> 140246628104512
	140246628104680 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140246628104736 -> 140246628104512
	140246628104736 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140246628104400 -> 140246628104232
	140246628104400 [label=CudnnBatchNormBackward]
	140246628104568 -> 140246628104400
	140246628104568 [label=CudnnConvolutionBackward]
	140246628105352 -> 140246628104568
	140246628105464 -> 140246628104568
	140246628105464 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140246628104792 -> 140246628104400
	140246628104792 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140246628104960 -> 140246628104400
	140246628104960 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140246628104120 -> 140246628103952
	140246628104120 [label=CudnnBatchNormBackward]
	140246628104288 -> 140246628104120
	140246628104288 [label=CudnnConvolutionBackward]
	140246628105576 -> 140246628104288
	140246628105576 [label=ReluBackward1]
	140246628113208 -> 140246628105576
	140246628113208 [label=CudnnBatchNormBackward]
	140246628113936 -> 140246628113208
	140246628113936 [label=CudnnConvolutionBackward]
	140246628104064 -> 140246628113936
	140246628113992 -> 140246628113936
	140246628113992 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140246628113656 -> 140246628113208
	140246628113656 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140246628114048 -> 140246628113208
	140246628114048 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140246628105744 -> 140246628104288
	140246628105744 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140246628104456 -> 140246628104120
	140246628104456 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140246628105296 -> 140246628104120
	140246628105296 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140246628103840 -> 140246628103672
	140246628103840 [label=CudnnBatchNormBackward]
	140246628104008 -> 140246628103840
	140246628104008 [label=CudnnConvolutionBackward]
	140246628114104 -> 140246628104008
	140246628114104 [label=ReluBackward1]
	140246628114272 -> 140246628114104
	140246628114272 [label=CudnnBatchNormBackward]
	140246628114216 -> 140246628114272
	140246628114216 [label=CudnnConvolutionBackward]
	140246628103784 -> 140246628114216
	140246628143288 -> 140246628114216
	140246628143288 [label="module_list.32.weight
 (26, 32, 3, 3)" fillcolor=lightblue]
	140246628114384 -> 140246628114272
	140246628114384 [label="module_list.33.weight
 (26)" fillcolor=lightblue]
	140246628143176 -> 140246628114272
	140246628143176 [label="module_list.33.bias
 (26)" fillcolor=lightblue]
	140246628114160 -> 140246628104008
	140246628114160 [label="module_list.34.weight
 (32, 26, 3, 3)" fillcolor=lightblue]
	140246628104176 -> 140246628103840
	140246628104176 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140246628105072 -> 140246628103840
	140246628105072 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140246628103560 -> 140246628103392
	140246628103560 [label=CudnnBatchNormBackward]
	140246628103728 -> 140246628103560
	140246628103728 [label=CudnnConvolutionBackward]
	140246628114328 -> 140246628103728
	140246628114328 [label=ReluBackward1]
	140246628143456 -> 140246628114328
	140246628143456 [label=CudnnBatchNormBackward]
	140246628143400 -> 140246628143456
	140246628143400 [label=CudnnConvolutionBackward]
	140246628103504 -> 140246628143400
	140246628143736 -> 140246628143400
	140246628143736 [label="module_list.36.weight
 (5, 32, 3, 3)" fillcolor=lightblue]
	140246628143568 -> 140246628143456
	140246628143568 [label="module_list.37.weight
 (5)" fillcolor=lightblue]
	140246628143624 -> 140246628143456
	140246628143624 [label="module_list.37.bias
 (5)" fillcolor=lightblue]
	140246628143232 -> 140246628103728
	140246628143232 [label="module_list.38.weight
 (32, 5, 3, 3)" fillcolor=lightblue]
	140246628103896 -> 140246628103560
	140246628103896 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140246628112760 -> 140246628103560
	140246628112760 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140246628103280 -> 140246628103000
	140246628103280 [label="module_list.40.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140246628103056 -> 140246628102888
	140246628103056 [label="module_list.41.weight
 (64)" fillcolor=lightblue]
	140246628103112 -> 140246628102888
	140246628103112 [label="module_list.41.bias
 (64)" fillcolor=lightblue]
	140246628102776 -> 140246628102496
	140246628102776 [label="module_list.42.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140246628102552 -> 140246628102384
	140246628102552 [label="module_list.43.weight
 (64)" fillcolor=lightblue]
	140246628102608 -> 140246628102384
	140246628102608 [label="module_list.43.bias
 (64)" fillcolor=lightblue]
	140246628102272 -> 140248750350232
	140246628102272 [label=CudnnBatchNormBackward]
	140246628113824 -> 140246628102272
	140246628113824 [label=CudnnConvolutionBackward]
	140246628103224 -> 140246628113824
	140246628102944 -> 140246628113824
	140246628102944 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140246628102440 -> 140246628102272
	140246628102440 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140246628102664 -> 140246628102272
	140246628102664 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140248750350120 -> 140248750349952
	140248750350120 [label=CudnnBatchNormBackward]
	140248750350288 -> 140248750350120
	140248750350288 [label=CudnnConvolutionBackward]
	140246628103616 -> 140248750350288
	140246628103616 [label=ReluBackward1]
	140246628143344 -> 140246628103616
	140246628143344 [label=CudnnBatchNormBackward]
	140246628143512 -> 140246628143344
	140246628143512 [label=CudnnConvolutionBackward]
	140248750350064 -> 140246628143512
	140246628143960 -> 140246628143512
	140246628143960 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140246628143792 -> 140246628143344
	140246628143792 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140246628143904 -> 140246628143344
	140246628143904 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140246628103448 -> 140248750350288
	140246628103448 [label="module_list.48.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140246628102328 -> 140248750350120
	140246628102328 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140246628102832 -> 140248750350120
	140246628102832 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140248750349840 -> 140248750349672
	140248750349840 [label=CudnnBatchNormBackward]
	140248750350008 -> 140248750349840
	140248750350008 [label=CudnnConvolutionBackward]
	140246628143848 -> 140248750350008
	140246628143848 [label=ReluBackward1]
	140246628144128 -> 140246628143848
	140246628144128 [label=CudnnBatchNormBackward]
	140246628144072 -> 140246628144128
	140246628144072 [label=CudnnConvolutionBackward]
	140248750349784 -> 140246628144072
	140246628144408 -> 140246628144072
	140246628144408 [label="module_list.50.weight
 (53, 64, 3, 3)" fillcolor=lightblue]
	140246628144240 -> 140246628144128
	140246628144240 [label="module_list.51.weight
 (53)" fillcolor=lightblue]
	140246628144296 -> 140246628144128
	140246628144296 [label="module_list.51.bias
 (53)" fillcolor=lightblue]
	140246628144016 -> 140248750350008
	140246628144016 [label="module_list.52.weight
 (64, 53, 3, 3)" fillcolor=lightblue]
	140248750350176 -> 140248750349840
	140248750350176 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140246628103168 -> 140248750349840
	140246628103168 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140248750349560 -> 140248750348664
	140248750349560 [label=CudnnBatchNormBackward]
	140248750349728 -> 140248750349560
	140248750349728 [label=CudnnConvolutionBackward]
	140246628144352 -> 140248750349728
	140246628144352 [label=ReluBackward1]
	140246628144576 -> 140246628144352
	140246628144576 [label=CudnnBatchNormBackward]
	140246628144520 -> 140246628144576
	140246628144520 [label=CudnnConvolutionBackward]
	140248750349504 -> 140246628144520
	140246628144856 -> 140246628144520
	140246628144856 [label="module_list.54.weight
 (52, 64, 3, 3)" fillcolor=lightblue]
	140246628144688 -> 140246628144576
	140246628144688 [label="module_list.55.weight
 (52)" fillcolor=lightblue]
	140246628144744 -> 140246628144576
	140246628144744 [label="module_list.55.bias
 (52)" fillcolor=lightblue]
	140246628144464 -> 140248750349728
	140246628144464 [label="module_list.56.weight
 (64, 52, 3, 3)" fillcolor=lightblue]
	140248750349896 -> 140248750349560
	140248750349896 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140246628103336 -> 140248750349560
	140246628103336 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140248750348272 -> 140248751689856
	140248750348272 [label=TBackward]
	140248750348776 -> 140248750348272
	140248750348776 [label="module_list.59.weight
 (10, 64)" fillcolor=lightblue]
}
