digraph {
	graph [size="64.35,64.35"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140596270393832 [label=AddmmBackward fillcolor=darkolivegreen1]
	140596270393552 -> 140596270393832
	140596270393552 [label="module_list.63.bias
 (10)" fillcolor=lightblue]
	140596270393048 -> 140596270393832
	140596270393048 [label=ViewBackward]
	140596270440968 -> 140596270393048
	140596270440968 [label=ViewBackward]
	140596270440800 -> 140596270440968
	140596270440800 [label=MeanBackward1]
	140596270443432 -> 140596270440800
	140596270443432 [label=ViewBackward]
	140596270443488 -> 140596270443432
	140596270443488 [label=ReluBackward1]
	140596270441024 -> 140596270443488
	140596270441024 [label=AddBackward0]
	140596270440688 -> 140596270441024
	140596270440688 [label=ReluBackward1]
	140596270444104 -> 140596270440688
	140596270444104 [label=AddBackward0]
	140596098105920 -> 140596270444104
	140596098105920 [label=ReluBackward1]
	140596098105472 -> 140596098105920
	140596098105472 [label=AddBackward0]
	140596098106032 -> 140596098105472
	140596098106032 [label=ReluBackward1]
	140596098106200 -> 140596098106032
	140596098106200 [label=AddBackward0]
	140596098106312 -> 140596098106200
	140596098106312 [label=ReluBackward1]
	140596098106480 -> 140596098106312
	140596098106480 [label=CudnnBatchNormBackward]
	140596098106592 -> 140596098106480
	140596098106592 [label=CudnnConvolutionBackward]
	140596098106816 -> 140596098106592
	140596098106816 [label=ReluBackward1]
	140596098106984 -> 140596098106816
	140596098106984 [label=CudnnBatchNormBackward]
	140596098107096 -> 140596098106984
	140596098107096 [label=CudnnConvolutionBackward]
	140596098107320 -> 140596098107096
	140596098107320 [label=ReluBackward1]
	140596098107488 -> 140596098107320
	140596098107488 [label=AddBackward0]
	140596098107600 -> 140596098107488
	140596098107600 [label=ReluBackward1]
	140596098107768 -> 140596098107600
	140596098107768 [label=AddBackward0]
	140596098107880 -> 140596098107768
	140596098107880 [label=ReluBackward1]
	140596098108048 -> 140596098107880
	140596098108048 [label=AddBackward0]
	140596098108160 -> 140596098108048
	140596098108160 [label=ReluBackward1]
	140596098108328 -> 140596098108160
	140596098108328 [label=AddBackward0]
	140596098108440 -> 140596098108328
	140596098108440 [label=ReluBackward1]
	140596098108608 -> 140596098108440
	140596098108608 [label=AddBackward0]
	140596098108720 -> 140596098108608
	140596098108720 [label=ReluBackward1]
	140596098108888 -> 140596098108720
	140596098108888 [label=CudnnBatchNormBackward]
	140596098109000 -> 140596098108888
	140596098109000 [label=CudnnConvolutionBackward]
	140596098109224 -> 140596098109000
	140596098109224 [label=ReluBackward1]
	140596098109392 -> 140596098109224
	140596098109392 [label=CudnnBatchNormBackward]
	140594116952192 -> 140596098109392
	140594116952192 [label=CudnnConvolutionBackward]
	140594116952416 -> 140594116952192
	140594116952416 [label=ReluBackward1]
	140594116952584 -> 140594116952416
	140594116952584 [label=AddBackward0]
	140594116952696 -> 140594116952584
	140594116952696 [label=ReluBackward1]
	140594116952864 -> 140594116952696
	140594116952864 [label=AddBackward0]
	140594116952976 -> 140594116952864
	140594116952976 [label=ReluBackward1]
	140594116953144 -> 140594116952976
	140594116953144 [label=AddBackward0]
	140594116953256 -> 140594116953144
	140594116953256 [label=ReluBackward1]
	140594116953424 -> 140594116953256
	140594116953424 [label=AddBackward0]
	140594116953536 -> 140594116953424
	140594116953536 [label=ReluBackward1]
	140594116953704 -> 140594116953536
	140594116953704 [label=AddBackward0]
	140594116953816 -> 140594116953704
	140594116953816 [label=ReluBackward1]
	140594116953984 -> 140594116953816
	140594116953984 [label=CudnnBatchNormBackward]
	140594116954096 -> 140594116953984
	140594116954096 [label=CudnnConvolutionBackward]
	140594116954320 -> 140594116954096
	140594116954320 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140594116954152 -> 140594116953984
	140594116954152 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140594116954208 -> 140594116953984
	140594116954208 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140594116953872 -> 140594116953704
	140594116953872 [label=CudnnBatchNormBackward]
	140594116954040 -> 140594116953872
	140594116954040 [label=CudnnConvolutionBackward]
	140594116954432 -> 140594116954040
	140594116954432 [label=ReluBackward1]
	140594116954656 -> 140594116954432
	140594116954656 [label=CudnnBatchNormBackward]
	140594116954768 -> 140594116954656
	140594116954768 [label=CudnnConvolutionBackward]
	140594116953816 -> 140594116954768
	140594116954992 -> 140594116954768
	140594116954992 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140594116954824 -> 140594116954656
	140594116954824 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140594116954880 -> 140594116954656
	140594116954880 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140594116954544 -> 140594116954040
	140594116954544 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140594116954264 -> 140594116953872
	140594116954264 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140594116954376 -> 140594116953872
	140594116954376 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140594116953592 -> 140594116953424
	140594116953592 [label=CudnnBatchNormBackward]
	140594116953760 -> 140594116953592
	140594116953760 [label=CudnnConvolutionBackward]
	140594116954936 -> 140594116953760
	140594116954936 [label=ReluBackward1]
	140594116955160 -> 140594116954936
	140594116955160 [label=CudnnBatchNormBackward]
	140594116955104 -> 140594116955160
	140594116955104 [label=CudnnConvolutionBackward]
	140594116953536 -> 140594116955104
	140594116955440 -> 140594116955104
	140594116955440 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140594116955272 -> 140594116955160
	140594116955272 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140594116955328 -> 140594116955160
	140594116955328 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140594116955048 -> 140594116953760
	140594116955048 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140594116953928 -> 140594116953592
	140594116953928 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140594116954488 -> 140594116953592
	140594116954488 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140594116953312 -> 140594116953144
	140594116953312 [label=CudnnBatchNormBackward]
	140594116953480 -> 140594116953312
	140594116953480 [label=CudnnConvolutionBackward]
	140594116955384 -> 140594116953480
	140594116955384 [label=ReluBackward1]
	140594116955608 -> 140594116955384
	140594116955608 [label=CudnnBatchNormBackward]
	140594116955552 -> 140594116955608
	140594116955552 [label=CudnnConvolutionBackward]
	140594116953256 -> 140594116955552
	140594116955888 -> 140594116955552
	140594116955888 [label="module_list.10.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	140594116955720 -> 140594116955608
	140594116955720 [label="module_list.11.weight
 (14)" fillcolor=lightblue]
	140594116955776 -> 140594116955608
	140594116955776 [label="module_list.11.bias
 (14)" fillcolor=lightblue]
	140594116955496 -> 140594116953480
	140594116955496 [label="module_list.12.weight
 (16, 14, 3, 3)" fillcolor=lightblue]
	140594116953648 -> 140594116953312
	140594116953648 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140594116954600 -> 140594116953312
	140594116954600 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140594116953032 -> 140594116952864
	140594116953032 [label=CudnnBatchNormBackward]
	140594116953200 -> 140594116953032
	140594116953200 [label=CudnnConvolutionBackward]
	140594116955832 -> 140594116953200
	140594116955832 [label=ReluBackward1]
	140594116956056 -> 140594116955832
	140594116956056 [label=CudnnBatchNormBackward]
	140594116956000 -> 140594116956056
	140594116956000 [label=CudnnConvolutionBackward]
	140594116952976 -> 140594116956000
	140594116972784 -> 140594116956000
	140594116972784 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140594116972616 -> 140594116956056
	140594116972616 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140594116972672 -> 140594116956056
	140594116972672 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140594116955944 -> 140594116953200
	140594116955944 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140594116953368 -> 140594116953032
	140594116953368 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140594116954712 -> 140594116953032
	140594116954712 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140594116952752 -> 140594116952584
	140594116952752 [label=CudnnBatchNormBackward]
	140594116952920 -> 140594116952752
	140594116952920 [label=CudnnConvolutionBackward]
	140594116956112 -> 140594116952920
	140594116956112 [label=ReluBackward1]
	140594116972952 -> 140594116956112
	140594116972952 [label=CudnnBatchNormBackward]
	140594116972896 -> 140594116972952
	140594116972896 [label=CudnnConvolutionBackward]
	140594116952696 -> 140594116972896
	140594116973232 -> 140594116972896
	140594116973232 [label="module_list.18.weight
 (15, 16, 3, 3)" fillcolor=lightblue]
	140594116973064 -> 140594116972952
	140594116973064 [label="module_list.19.weight
 (15)" fillcolor=lightblue]
	140594116973120 -> 140594116972952
	140594116973120 [label="module_list.19.bias
 (15)" fillcolor=lightblue]
	140594116972728 -> 140594116952920
	140594116972728 [label="module_list.20.weight
 (16, 15, 3, 3)" fillcolor=lightblue]
	140594116953088 -> 140594116952752
	140594116953088 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140594116955216 -> 140594116952752
	140594116955216 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140594116952472 -> 140594116952192
	140594116952472 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140594116952248 -> 140596098109392
	140594116952248 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140594116952304 -> 140596098109392
	140594116952304 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140596098109280 -> 140596098109000
	140596098109280 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140596098109056 -> 140596098108888
	140596098109056 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140596098109112 -> 140596098108888
	140596098109112 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140596098108776 -> 140596098108608
	140596098108776 [label=CudnnBatchNormBackward]
	140596098108944 -> 140596098108776
	140596098108944 [label=CudnnConvolutionBackward]
	140594116952416 -> 140596098108944
	140594116952528 -> 140596098108944
	140594116952528 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140596098109168 -> 140596098108776
	140596098109168 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140596098109336 -> 140596098108776
	140596098109336 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140596098108496 -> 140596098108328
	140596098108496 [label=CudnnBatchNormBackward]
	140596098108664 -> 140596098108496
	140596098108664 [label=CudnnConvolutionBackward]
	140594116955664 -> 140596098108664
	140594116955664 [label=ReluBackward1]
	140594116972840 -> 140594116955664
	140594116972840 [label=CudnnBatchNormBackward]
	140594116973288 -> 140594116972840
	140594116973288 [label=CudnnConvolutionBackward]
	140596098108440 -> 140594116973288
	140594116973344 -> 140594116973288
	140594116973344 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140594116973008 -> 140594116972840
	140594116973008 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140594116973400 -> 140594116972840
	140594116973400 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140594116952640 -> 140596098108664
	140594116952640 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140596098108832 -> 140596098108496
	140596098108832 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140594116952360 -> 140596098108496
	140594116952360 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140596098108216 -> 140596098108048
	140596098108216 [label=CudnnBatchNormBackward]
	140596098108384 -> 140596098108216
	140596098108384 [label=CudnnConvolutionBackward]
	140594116973456 -> 140596098108384
	140594116973456 [label=ReluBackward1]
	140594116973624 -> 140594116973456
	140594116973624 [label=CudnnBatchNormBackward]
	140594116973568 -> 140594116973624
	140594116973568 [label=CudnnConvolutionBackward]
	140596098108160 -> 140594116973568
	140594116973904 -> 140594116973568
	140594116973904 [label="module_list.32.weight
 (30, 32, 3, 3)" fillcolor=lightblue]
	140594116973736 -> 140594116973624
	140594116973736 [label="module_list.33.weight
 (30)" fillcolor=lightblue]
	140594116973792 -> 140594116973624
	140594116973792 [label="module_list.33.bias
 (30)" fillcolor=lightblue]
	140594116973512 -> 140596098108384
	140594116973512 [label="module_list.34.weight
 (32, 30, 3, 3)" fillcolor=lightblue]
	140596098108552 -> 140596098108216
	140596098108552 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140594116952136 -> 140596098108216
	140594116952136 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140596098107936 -> 140596098107768
	140596098107936 [label=CudnnBatchNormBackward]
	140596098108104 -> 140596098107936
	140596098108104 [label=CudnnConvolutionBackward]
	140594116973848 -> 140596098108104
	140594116973848 [label=ReluBackward1]
	140594116974072 -> 140594116973848
	140594116974072 [label=CudnnBatchNormBackward]
	140594116974016 -> 140594116974072
	140594116974016 [label=CudnnConvolutionBackward]
	140596098107880 -> 140594116974016
	140594116974352 -> 140594116974016
	140594116974352 [label="module_list.36.weight
 (17, 32, 3, 3)" fillcolor=lightblue]
	140594116974184 -> 140594116974072
	140594116974184 [label="module_list.37.weight
 (17)" fillcolor=lightblue]
	140594116974240 -> 140594116974072
	140594116974240 [label="module_list.37.bias
 (17)" fillcolor=lightblue]
	140594116973960 -> 140596098108104
	140594116973960 [label="module_list.38.weight
 (32, 17, 3, 3)" fillcolor=lightblue]
	140596098108272 -> 140596098107936
	140596098108272 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140594116952808 -> 140596098107936
	140594116952808 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140596098107656 -> 140596098107488
	140596098107656 [label=CudnnBatchNormBackward]
	140596098107824 -> 140596098107656
	140596098107824 [label=CudnnConvolutionBackward]
	140594116973176 -> 140596098107824
	140594116973176 [label=ReluBackward1]
	140594116974296 -> 140594116973176
	140594116974296 [label=CudnnBatchNormBackward]
	140594116974520 -> 140594116974296
	140594116974520 [label=CudnnConvolutionBackward]
	140596098107600 -> 140594116974520
	140594116974688 -> 140594116974520
	140594116974688 [label="module_list.40.weight
 (8, 32, 3, 3)" fillcolor=lightblue]
	140594116974576 -> 140594116974296
	140594116974576 [label="module_list.41.weight
 (8)" fillcolor=lightblue]
	140594116974464 -> 140594116974296
	140594116974464 [label="module_list.41.bias
 (8)" fillcolor=lightblue]
	140594116973680 -> 140596098107824
	140594116973680 [label="module_list.42.weight
 (32, 8, 3, 3)" fillcolor=lightblue]
	140596098107992 -> 140596098107656
	140596098107992 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140596270337944 -> 140596098107656
	140596270337944 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140596098107376 -> 140596098107096
	140596098107376 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140596098107152 -> 140596098106984
	140596098107152 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140596098107208 -> 140596098106984
	140596098107208 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140596098106872 -> 140596098106592
	140596098106872 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140596098106648 -> 140596098106480
	140596098106648 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140596098106704 -> 140596098106480
	140596098106704 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140596098106368 -> 140596098106200
	140596098106368 [label=CudnnBatchNormBackward]
	140596270335704 -> 140596098106368
	140596270335704 [label=CudnnConvolutionBackward]
	140596098107320 -> 140596270335704
	140596098107040 -> 140596270335704
	140596098107040 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140596098106536 -> 140596098106368
	140596098106536 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140596098106760 -> 140596098106368
	140596098106760 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140596098105584 -> 140596098105472
	140596098105584 [label=CudnnBatchNormBackward]
	140596098106256 -> 140596098105584
	140596098106256 [label=CudnnConvolutionBackward]
	140596098107712 -> 140596098106256
	140596098107712 [label=ReluBackward1]
	140594116974128 -> 140596098107712
	140594116974128 [label=CudnnBatchNormBackward]
	140594116974408 -> 140594116974128
	140594116974408 [label=CudnnConvolutionBackward]
	140596098106032 -> 140594116974408
	140594116974912 -> 140594116974408
	140594116974912 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140594116974744 -> 140594116974128
	140594116974744 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140594116974856 -> 140594116974128
	140594116974856 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140596098107544 -> 140596098106256
	140596098107544 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140596098106424 -> 140596098105584
	140596098106424 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140596098106928 -> 140596098105584
	140596098106928 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140596098105528 -> 140596270444104
	140596098105528 [label=CudnnBatchNormBackward]
	140596098105976 -> 140596098105528
	140596098105976 [label=CudnnConvolutionBackward]
	140594116974800 -> 140596098105976
	140594116974800 [label=ReluBackward1]
	140594116975080 -> 140594116974800
	140594116975080 [label=CudnnBatchNormBackward]
	140594116975024 -> 140594116975080
	140594116975024 [label=CudnnConvolutionBackward]
	140596098105920 -> 140594116975024
	140594116975360 -> 140594116975024
	140594116975360 [label="module_list.54.weight
 (59, 64, 3, 3)" fillcolor=lightblue]
	140594116975192 -> 140594116975080
	140594116975192 [label="module_list.55.weight
 (59)" fillcolor=lightblue]
	140594116975248 -> 140594116975080
	140594116975248 [label="module_list.55.bias
 (59)" fillcolor=lightblue]
	140594116974968 -> 140596098105976
	140594116974968 [label="module_list.56.weight
 (64, 59, 3, 3)" fillcolor=lightblue]
	140596098106144 -> 140596098105528
	140596098106144 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140596098107264 -> 140596098105528
	140596098107264 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140596270440632 -> 140596270441024
	140596270440632 [label=CudnnBatchNormBackward]
	140596098106088 -> 140596270440632
	140596098106088 [label=CudnnConvolutionBackward]
	140594116975304 -> 140596098106088
	140594116975304 [label=ReluBackward1]
	140594116975528 -> 140594116975304
	140594116975528 [label=CudnnBatchNormBackward]
	140594116975472 -> 140594116975528
	140594116975472 [label=CudnnConvolutionBackward]
	140596270440688 -> 140594116975472
	140594116975808 -> 140594116975472
	140594116975808 [label="module_list.58.weight
 (55, 64, 3, 3)" fillcolor=lightblue]
	140594116975640 -> 140594116975528
	140594116975640 [label="module_list.59.weight
 (55)" fillcolor=lightblue]
	140594116975696 -> 140594116975528
	140594116975696 [label="module_list.59.bias
 (55)" fillcolor=lightblue]
	140594116975416 -> 140596098106088
	140594116975416 [label="module_list.60.weight
 (64, 55, 3, 3)" fillcolor=lightblue]
	140596098105416 -> 140596270440632
	140596098105416 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140596098107432 -> 140596270440632
	140596098107432 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140596270395344 -> 140596270393832
	140596270395344 [label=TBackward]
	140596270441528 -> 140596270395344
	140596270441528 [label="module_list.63.weight
 (10, 64)" fillcolor=lightblue]
}
