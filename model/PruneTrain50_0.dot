digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140116475401552 [label=AddmmBackward fillcolor=darkolivegreen1]
	140116641211336 -> 140116475401552
	140116641211336 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140116475401440 -> 140116475401552
	140116475401440 [label=ViewBackward]
	140116520152704 -> 140116475401440
	140116520152704 [label=ViewBackward]
	140116520152032 -> 140116520152704
	140116520152032 [label=MeanBackward1]
	140116520151864 -> 140116520152032
	140116520151864 [label=ViewBackward]
	140116464967808 -> 140116520151864
	140116464967808 [label=ReluBackward1]
	140116464967920 -> 140116464967808
	140116464967920 [label=AddBackward0]
	140116464968032 -> 140116464967920
	140116464968032 [label=ReluBackward1]
	140116464968200 -> 140116464968032
	140116464968200 [label=AddBackward0]
	140116464968312 -> 140116464968200
	140116464968312 [label=ReluBackward1]
	140116464968480 -> 140116464968312
	140116464968480 [label=AddBackward0]
	140116464968592 -> 140116464968480
	140116464968592 [label=ReluBackward1]
	140116464968760 -> 140116464968592
	140116464968760 [label=AddBackward0]
	140116464968872 -> 140116464968760
	140116464968872 [label=ReluBackward1]
	140116464969040 -> 140116464968872
	140116464969040 [label=AddBackward0]
	140116464969152 -> 140116464969040
	140116464969152 [label=ReluBackward1]
	140116464969320 -> 140116464969152
	140116464969320 [label=CudnnBatchNormBackward]
	140116464969432 -> 140116464969320
	140116464969432 [label=CudnnConvolutionBackward]
	140116464969544 -> 140116464969432
	140116464969544 [label=ReluBackward1]
	140116464969656 -> 140116464969544
	140116464969656 [label=CudnnBatchNormBackward]
	140116464969768 -> 140116464969656
	140116464969768 [label=CudnnConvolutionBackward]
	140116464969880 -> 140116464969768
	140116464969880 [label=ReluBackward1]
	140116464969992 -> 140116464969880
	140116464969992 [label=AddBackward0]
	140116464970104 -> 140116464969992
	140116464970104 [label=ReluBackward1]
	140116464970272 -> 140116464970104
	140116464970272 [label=AddBackward0]
	140116464970384 -> 140116464970272
	140116464970384 [label=ReluBackward1]
	140116464970552 -> 140116464970384
	140116464970552 [label=AddBackward0]
	140116464970664 -> 140116464970552
	140116464970664 [label=ReluBackward1]
	140116464970832 -> 140116464970664
	140116464970832 [label=AddBackward0]
	140116464970944 -> 140116464970832
	140116464970944 [label=ReluBackward1]
	140116464971112 -> 140116464970944
	140116464971112 [label=AddBackward0]
	140116464971224 -> 140116464971112
	140116464971224 [label=ReluBackward1]
	140116464971392 -> 140116464971224
	140116464971392 [label=CudnnBatchNormBackward]
	140116464971504 -> 140116464971392
	140116464971504 [label=CudnnConvolutionBackward]
	140116464971616 -> 140116464971504
	140116464971616 [label=ReluBackward1]
	140116464971728 -> 140116464971616
	140116464971728 [label=CudnnBatchNormBackward]
	140116465016960 -> 140116464971728
	140116465016960 [label=CudnnConvolutionBackward]
	140116465017072 -> 140116465016960
	140116465017072 [label=ReluBackward1]
	140116465017184 -> 140116465017072
	140116465017184 [label=AddBackward0]
	140116465017296 -> 140116465017184
	140116465017296 [label=ReluBackward1]
	140116465017464 -> 140116465017296
	140116465017464 [label=AddBackward0]
	140116465017576 -> 140116465017464
	140116465017576 [label=ReluBackward1]
	140116465017744 -> 140116465017576
	140116465017744 [label=AddBackward0]
	140116465017856 -> 140116465017744
	140116465017856 [label=ReluBackward1]
	140116465018024 -> 140116465017856
	140116465018024 [label=AddBackward0]
	140116465018136 -> 140116465018024
	140116465018136 [label=ReluBackward1]
	140116465018304 -> 140116465018136
	140116465018304 [label=AddBackward0]
	140116520207024 -> 140116465018304
	140116520207024 [label=ReluBackward1]
	140116475903840 -> 140116520207024
	140116475903840 [label=CudnnBatchNormBackward]
	140116475903728 -> 140116475903840
	140116475903728 [label=CudnnConvolutionBackward]
	140116475903504 -> 140116475903728
	140116475903504 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140116475903672 -> 140116475903840
	140116475903672 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140116475903616 -> 140116475903840
	140116475903616 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140116520210216 -> 140116465018304
	140116520210216 [label=CudnnBatchNormBackward]
	140116475903784 -> 140116520210216
	140116475903784 [label=CudnnConvolutionBackward]
	140116475903336 -> 140116475903784
	140116475903336 [label=ReluBackward1]
	140116475903112 -> 140116475903336
	140116475903112 [label=CudnnBatchNormBackward]
	140116475903000 -> 140116475903112
	140116475903000 [label=CudnnConvolutionBackward]
	140116520207024 -> 140116475903000
	140116475902776 -> 140116475903000
	140116475902776 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475902944 -> 140116475903112
	140116475902944 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140116475902888 -> 140116475903112
	140116475902888 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140116475903224 -> 140116475903784
	140116475903224 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475903560 -> 140116520210216
	140116475903560 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140116475903392 -> 140116520210216
	140116475903392 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140116465018192 -> 140116465018024
	140116465018192 [label=CudnnBatchNormBackward]
	140116475903896 -> 140116465018192
	140116475903896 [label=CudnnConvolutionBackward]
	140116475902720 -> 140116475903896
	140116475902720 [label=ReluBackward1]
	140116475902552 -> 140116475902720
	140116475902552 [label=CudnnBatchNormBackward]
	140116475902496 -> 140116475902552
	140116475902496 [label=CudnnConvolutionBackward]
	140116465018136 -> 140116475902496
	140116475902272 -> 140116475902496
	140116475902272 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475902440 -> 140116475902552
	140116475902440 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140116475902384 -> 140116475902552
	140116475902384 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140116475903056 -> 140116475903896
	140116475903056 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475903280 -> 140116465018192
	140116475903280 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140116475903168 -> 140116465018192
	140116475903168 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140116465017912 -> 140116465017744
	140116465017912 [label=CudnnBatchNormBackward]
	140116475902832 -> 140116465017912
	140116475902832 [label=CudnnConvolutionBackward]
	140116475902664 -> 140116475902832
	140116475902664 [label=ReluBackward1]
	140116475902160 -> 140116475902664
	140116475902160 [label=CudnnBatchNormBackward]
	140116475901936 -> 140116475902160
	140116475901936 [label=CudnnConvolutionBackward]
	140116465017856 -> 140116475901936
	140116475901712 -> 140116475901936
	140116475901712 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475901880 -> 140116475902160
	140116475901880 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140116475901824 -> 140116475902160
	140116475901824 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140116475902104 -> 140116475902832
	140116475902104 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475902608 -> 140116465017912
	140116475902608 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140116475902328 -> 140116465017912
	140116475902328 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140116465017632 -> 140116465017464
	140116465017632 [label=CudnnBatchNormBackward]
	140116475902216 -> 140116465017632
	140116475902216 [label=CudnnConvolutionBackward]
	140116475901992 -> 140116475902216
	140116475901992 [label=ReluBackward1]
	140116475901600 -> 140116475901992
	140116475901600 [label=CudnnBatchNormBackward]
	140116475901320 -> 140116475901600
	140116475901320 [label=CudnnConvolutionBackward]
	140116465017576 -> 140116475901320
	140116475901096 -> 140116475901320
	140116475901096 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475901264 -> 140116475901600
	140116475901264 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140116475901208 -> 140116475901600
	140116475901208 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140116475901544 -> 140116475902216
	140116475901544 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475902048 -> 140116465017632
	140116475902048 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140116475901768 -> 140116465017632
	140116475901768 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140116465017352 -> 140116465017184
	140116465017352 [label=CudnnBatchNormBackward]
	140116475901656 -> 140116465017352
	140116475901656 [label=CudnnConvolutionBackward]
	140116475901376 -> 140116475901656
	140116475901376 [label=ReluBackward1]
	140116475900984 -> 140116475901376
	140116475900984 [label=CudnnBatchNormBackward]
	140116475900760 -> 140116475900984
	140116475900760 [label=CudnnConvolutionBackward]
	140116465017296 -> 140116475900760
	140116475900536 -> 140116475900760
	140116475900536 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475900704 -> 140116475900984
	140116475900704 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140116475900648 -> 140116475900984
	140116475900648 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140116475900928 -> 140116475901656
	140116475900928 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116475901432 -> 140116465017352
	140116475901432 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140116475901152 -> 140116465017352
	140116475901152 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140116465845920 -> 140116465016960
	140116465845920 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140116465845696 -> 140116464971728
	140116465845696 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140116465845752 -> 140116464971728
	140116465845752 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140116465845416 -> 140116464971504
	140116465845416 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465845192 -> 140116464971392
	140116465845192 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140116465845248 -> 140116464971392
	140116465845248 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140116464971280 -> 140116464971112
	140116464971280 [label=CudnnBatchNormBackward]
	140116464971448 -> 140116464971280
	140116464971448 [label=CudnnConvolutionBackward]
	140116465017072 -> 140116464971448
	140116475901040 -> 140116464971448
	140116475901040 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140116464971560 -> 140116464971280
	140116464971560 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140116464971672 -> 140116464971280
	140116464971672 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140116464971000 -> 140116464970832
	140116464971000 [label=CudnnBatchNormBackward]
	140116464971168 -> 140116464971000
	140116464971168 [label=CudnnConvolutionBackward]
	140116475900816 -> 140116464971168
	140116475900816 [label=ReluBackward1]
	140116475900312 -> 140116475900816
	140116475900312 [label=CudnnBatchNormBackward]
	140116475900256 -> 140116475900312
	140116475900256 [label=CudnnConvolutionBackward]
	140116464970944 -> 140116475900256
	140116475900032 -> 140116475900256
	140116475900032 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116475900200 -> 140116475900312
	140116475900200 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140116475900144 -> 140116475900312
	140116475900144 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140116475900368 -> 140116464971168
	140116475900368 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116464971336 -> 140116464971000
	140116464971336 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140116475900592 -> 140116464971000
	140116475900592 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140116464970720 -> 140116464970552
	140116464970720 [label=CudnnBatchNormBackward]
	140116464970888 -> 140116464970720
	140116464970888 [label=CudnnConvolutionBackward]
	140116475900088 -> 140116464970888
	140116475900088 [label=ReluBackward1]
	140116474934552 -> 140116475900088
	140116474934552 [label=CudnnBatchNormBackward]
	140116474934496 -> 140116474934552
	140116474934496 [label=CudnnConvolutionBackward]
	140116464970664 -> 140116474934496
	140116474937072 -> 140116474934496
	140116474937072 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116474937240 -> 140116474934552
	140116474937240 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140116474937184 -> 140116474934552
	140116474937184 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140116475899976 -> 140116464970888
	140116475899976 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116464971056 -> 140116464970720
	140116464971056 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140116475900872 -> 140116464970720
	140116475900872 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140116464970440 -> 140116464970272
	140116464970440 [label=CudnnBatchNormBackward]
	140116464970608 -> 140116464970440
	140116464970608 [label=CudnnConvolutionBackward]
	140116474937128 -> 140116464970608
	140116474937128 [label=ReluBackward1]
	140116474936848 -> 140116474937128
	140116474936848 [label=CudnnBatchNormBackward]
	140116474936904 -> 140116474936848
	140116474936904 [label=CudnnConvolutionBackward]
	140116464970384 -> 140116474936904
	140116474936568 -> 140116474936904
	140116474936568 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116474936736 -> 140116474936848
	140116474936736 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140116474936680 -> 140116474936848
	140116474936680 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140116474937016 -> 140116464970608
	140116474937016 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116464970776 -> 140116464970440
	140116464970776 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140116475900480 -> 140116464970440
	140116475900480 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140116464970160 -> 140116464969992
	140116464970160 [label=CudnnBatchNormBackward]
	140116464970328 -> 140116464970160
	140116464970328 [label=CudnnConvolutionBackward]
	140116474936624 -> 140116464970328
	140116474936624 [label=ReluBackward1]
	140116474936400 -> 140116474936624
	140116474936400 [label=CudnnBatchNormBackward]
	140116474936456 -> 140116474936400
	140116474936456 [label=CudnnConvolutionBackward]
	140116464970104 -> 140116474936456
	140116474936120 -> 140116474936456
	140116474936120 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116474936288 -> 140116474936400
	140116474936288 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140116474936232 -> 140116474936400
	140116474936232 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140116474936512 -> 140116464970328
	140116474936512 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116464970496 -> 140116464970160
	140116464970496 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140116475900424 -> 140116464970160
	140116475900424 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140116521217272 -> 140116464969768
	140116521217272 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140116521217048 -> 140116464969656
	140116521217048 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140116521217104 -> 140116464969656
	140116521217104 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140116521216768 -> 140116464969432
	140116521216768 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116521216544 -> 140116464969320
	140116521216544 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140116521216600 -> 140116464969320
	140116521216600 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140116464969208 -> 140116464969040
	140116464969208 [label=CudnnBatchNormBackward]
	140116464969376 -> 140116464969208
	140116464969376 [label=CudnnConvolutionBackward]
	140116464969880 -> 140116464969376
	140116464969936 -> 140116464969376
	140116464969936 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140116464969488 -> 140116464969208
	140116464969488 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140116464969600 -> 140116464969208
	140116464969600 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140116464968928 -> 140116464968760
	140116464968928 [label=CudnnBatchNormBackward]
	140116464969096 -> 140116464968928
	140116464969096 [label=CudnnConvolutionBackward]
	140116464970048 -> 140116464969096
	140116464970048 [label=ReluBackward1]
	140116474936792 -> 140116464970048
	140116474936792 [label=CudnnBatchNormBackward]
	140116474936064 -> 140116474936792
	140116474936064 [label=CudnnConvolutionBackward]
	140116464968872 -> 140116474936064
	140116474936008 -> 140116474936064
	140116474936008 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116474936344 -> 140116474936792
	140116474936344 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140116474935952 -> 140116474936792
	140116474935952 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140116464970216 -> 140116464969096
	140116464970216 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116464969264 -> 140116464968928
	140116464969264 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140116464969824 -> 140116464968928
	140116464969824 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140116464968648 -> 140116464968480
	140116464968648 [label=CudnnBatchNormBackward]
	140116464968816 -> 140116464968648
	140116464968816 [label=CudnnConvolutionBackward]
	140116474935896 -> 140116464968816
	140116474935896 [label=ReluBackward1]
	140116474935672 -> 140116474935896
	140116474935672 [label=CudnnBatchNormBackward]
	140116474935728 -> 140116474935672
	140116474935728 [label=CudnnConvolutionBackward]
	140116464968592 -> 140116474935728
	140116474935280 -> 140116474935728
	140116474935280 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116474935560 -> 140116474935672
	140116474935560 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140116474935448 -> 140116474935672
	140116474935448 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140116474935840 -> 140116464968816
	140116474935840 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116464968984 -> 140116464968648
	140116464968984 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140116464969712 -> 140116464968648
	140116464969712 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140116464968368 -> 140116464968200
	140116464968368 [label=CudnnBatchNormBackward]
	140116464968536 -> 140116464968368
	140116464968536 [label=CudnnConvolutionBackward]
	140116474935392 -> 140116464968536
	140116474935392 [label=ReluBackward1]
	140116474934944 -> 140116474935392
	140116474934944 [label=CudnnBatchNormBackward]
	140116474935056 -> 140116474934944
	140116474935056 [label=CudnnConvolutionBackward]
	140116464968312 -> 140116474935056
	140116475404128 -> 140116474935056
	140116475404128 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116474934440 -> 140116474934944
	140116474934440 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140116474934160 -> 140116474934944
	140116474934160 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140116474935168 -> 140116464968536
	140116474935168 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116464968704 -> 140116464968368
	140116464968704 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140116474937296 -> 140116464968368
	140116474937296 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140116464968088 -> 140116464967920
	140116464968088 [label=CudnnBatchNormBackward]
	140116464968256 -> 140116464968088
	140116464968256 [label=CudnnConvolutionBackward]
	140116474934888 -> 140116464968256
	140116474934888 [label=ReluBackward1]
	140116475403960 -> 140116474934888
	140116475403960 [label=CudnnBatchNormBackward]
	140116475404016 -> 140116475403960
	140116475404016 [label=CudnnConvolutionBackward]
	140116464968032 -> 140116475404016
	140116475403680 -> 140116475404016
	140116475403680 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116475403848 -> 140116475403960
	140116475403848 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140116475403792 -> 140116475403960
	140116475403792 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140116475404240 -> 140116464968256
	140116475404240 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116464968424 -> 140116464968088
	140116464968424 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140116474936176 -> 140116464968088
	140116474936176 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140116520149736 -> 140116475401552
	140116520149736 [label=TBackward]
	140116520150520 -> 140116520149736
	140116520150520 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
