digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140482767379424 [label=AddmmBackward fillcolor=darkolivegreen1]
	140483034358896 -> 140482767379424
	140483034358896 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140482767380264 -> 140482767379424
	140482767380264 [label=ViewBackward]
	140482767380096 -> 140482767380264
	140482767380096 [label=ViewBackward]
	140482767380040 -> 140482767380096
	140482767380040 [label=MeanBackward1]
	140482767380432 -> 140482767380040
	140482767380432 [label=ViewBackward]
	140482768130176 -> 140482767380432
	140482768130176 [label=ReluBackward1]
	140482768130288 -> 140482768130176
	140482768130288 [label=AddBackward0]
	140482768130400 -> 140482768130288
	140482768130400 [label=ReluBackward1]
	140482768130568 -> 140482768130400
	140482768130568 [label=AddBackward0]
	140482768130680 -> 140482768130568
	140482768130680 [label=ReluBackward1]
	140482768130848 -> 140482768130680
	140482768130848 [label=AddBackward0]
	140482768130960 -> 140482768130848
	140482768130960 [label=ReluBackward1]
	140482768131128 -> 140482768130960
	140482768131128 [label=AddBackward0]
	140482768131240 -> 140482768131128
	140482768131240 [label=ReluBackward1]
	140482768131408 -> 140482768131240
	140482768131408 [label=AddBackward0]
	140482768131520 -> 140482768131408
	140482768131520 [label=ReluBackward1]
	140482768131688 -> 140482768131520
	140482768131688 [label=CudnnBatchNormBackward]
	140482768131800 -> 140482768131688
	140482768131800 [label=CudnnConvolutionBackward]
	140482768131912 -> 140482768131800
	140482768131912 [label=ReluBackward1]
	140482768132024 -> 140482768131912
	140482768132024 [label=CudnnBatchNormBackward]
	140482768132136 -> 140482768132024
	140482768132136 [label=CudnnConvolutionBackward]
	140482768132248 -> 140482768132136
	140482768132248 [label=ReluBackward1]
	140482768132360 -> 140482768132248
	140482768132360 [label=AddBackward0]
	140482768132472 -> 140482768132360
	140482768132472 [label=ReluBackward1]
	140482768132640 -> 140482768132472
	140482768132640 [label=AddBackward0]
	140482768132752 -> 140482768132640
	140482768132752 [label=ReluBackward1]
	140482768132920 -> 140482768132752
	140482768132920 [label=AddBackward0]
	140482768133032 -> 140482768132920
	140482768133032 [label=ReluBackward1]
	140482768133200 -> 140482768133032
	140482768133200 [label=AddBackward0]
	140482768133312 -> 140482768133200
	140482768133312 [label=ReluBackward1]
	140482768133480 -> 140482768133312
	140482768133480 [label=AddBackward0]
	140482768133592 -> 140482768133480
	140482768133592 [label=ReluBackward1]
	140482768133760 -> 140482768133592
	140482768133760 [label=CudnnBatchNormBackward]
	140482768133872 -> 140482768133760
	140482768133872 [label=CudnnConvolutionBackward]
	140482768133984 -> 140482768133872
	140482768133984 [label=ReluBackward1]
	140482768134096 -> 140482768133984
	140482768134096 [label=CudnnBatchNormBackward]
	140482768138368 -> 140482768134096
	140482768138368 [label=CudnnConvolutionBackward]
	140482768138480 -> 140482768138368
	140482768138480 [label=ReluBackward1]
	140482768138592 -> 140482768138480
	140482768138592 [label=AddBackward0]
	140482768138704 -> 140482768138592
	140482768138704 [label=ReluBackward1]
	140482768138872 -> 140482768138704
	140482768138872 [label=AddBackward0]
	140482768138984 -> 140482768138872
	140482768138984 [label=ReluBackward1]
	140482768139152 -> 140482768138984
	140482768139152 [label=AddBackward0]
	140482768139264 -> 140482768139152
	140482768139264 [label=ReluBackward1]
	140482768139432 -> 140482768139264
	140482768139432 [label=AddBackward0]
	140482768139544 -> 140482768139432
	140482768139544 [label=ReluBackward1]
	140482768139712 -> 140482768139544
	140482768139712 [label=AddBackward0]
	140482768139824 -> 140482768139712
	140482768139824 [label=ReluBackward1]
	140482768139992 -> 140482768139824
	140482768139992 [label=CudnnBatchNormBackward]
	140482768140104 -> 140482768139992
	140482768140104 [label=CudnnConvolutionBackward]
	140482749414984 -> 140482768140104
	140482749414984 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140482749414816 -> 140482768139992
	140482749414816 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140482749414872 -> 140482768139992
	140482749414872 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140482768139880 -> 140482768139712
	140482768139880 [label=CudnnBatchNormBackward]
	140482768140048 -> 140482768139880
	140482768140048 [label=CudnnConvolutionBackward]
	140482768140216 -> 140482768140048
	140482768140216 [label=ReluBackward1]
	140482768140272 -> 140482768140216
	140482768140272 [label=CudnnBatchNormBackward]
	140482768140440 -> 140482768140272
	140482768140440 [label=CudnnConvolutionBackward]
	140482768139824 -> 140482768140440
	140482749428008 -> 140482768140440
	140482749428008 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749427840 -> 140482768140272
	140482749427840 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140482749427896 -> 140482768140272
	140482749427896 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140482749415208 -> 140482768140048
	140482749415208 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749414928 -> 140482768139880
	140482749414928 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140482749415040 -> 140482768139880
	140482749415040 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140482768139600 -> 140482768139432
	140482768139600 [label=CudnnBatchNormBackward]
	140482768139768 -> 140482768139600
	140482768139768 [label=CudnnConvolutionBackward]
	140482768140160 -> 140482768139768
	140482768140160 [label=ReluBackward1]
	140482768140496 -> 140482768140160
	140482768140496 [label=CudnnBatchNormBackward]
	140482768140384 -> 140482768140496
	140482768140384 [label=CudnnConvolutionBackward]
	140482768139544 -> 140482768140384
	140482749428456 -> 140482768140384
	140482749428456 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749428288 -> 140482768140496
	140482749428288 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140482749428344 -> 140482768140496
	140482749428344 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140482749427952 -> 140482768139768
	140482749427952 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749414592 -> 140482768139600
	140482749414592 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140482749415152 -> 140482768139600
	140482749415152 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140482768139320 -> 140482768139152
	140482768139320 [label=CudnnBatchNormBackward]
	140482768139488 -> 140482768139320
	140482768139488 [label=CudnnConvolutionBackward]
	140482768139936 -> 140482768139488
	140482768139936 [label=ReluBackward1]
	140482768140664 -> 140482768139936
	140482768140664 [label=CudnnBatchNormBackward]
	140482768140552 -> 140482768140664
	140482768140552 [label=CudnnConvolutionBackward]
	140482768139264 -> 140482768140552
	140482749428904 -> 140482768140552
	140482749428904 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749428736 -> 140482768140664
	140482749428736 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140482749428792 -> 140482768140664
	140482749428792 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140482749428512 -> 140482768139488
	140482749428512 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749414312 -> 140482768139320
	140482749414312 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140482749415264 -> 140482768139320
	140482749415264 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140482768139040 -> 140482768138872
	140482768139040 [label=CudnnBatchNormBackward]
	140482768139208 -> 140482768139040
	140482768139208 [label=CudnnConvolutionBackward]
	140482768139656 -> 140482768139208
	140482768139656 [label=ReluBackward1]
	140482768140776 -> 140482768139656
	140482768140776 [label=CudnnBatchNormBackward]
	140482768140720 -> 140482768140776
	140482768140720 [label=CudnnConvolutionBackward]
	140482768138984 -> 140482768140720
	140482749429352 -> 140482768140720
	140482749429352 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749429184 -> 140482768140776
	140482749429184 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140482749429240 -> 140482768140776
	140482749429240 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140482749428960 -> 140482768139208
	140482749428960 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749414032 -> 140482768139040
	140482749414032 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140482749428064 -> 140482768139040
	140482749428064 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140482768138760 -> 140482768138592
	140482768138760 [label=CudnnBatchNormBackward]
	140482768138928 -> 140482768138760
	140482768138928 [label=CudnnConvolutionBackward]
	140482768139376 -> 140482768138928
	140482768139376 [label=ReluBackward1]
	140482768140888 -> 140482768139376
	140482768140888 [label=CudnnBatchNormBackward]
	140482768140832 -> 140482768140888
	140482768140832 [label=CudnnConvolutionBackward]
	140482768138704 -> 140482768140832
	140482749429800 -> 140482768140832
	140482749429800 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749429632 -> 140482768140888
	140482749429632 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140482749429688 -> 140482768140888
	140482749429688 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140482749429408 -> 140482768138928
	140482749429408 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140482749413752 -> 140482768138760
	140482749413752 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140482749428232 -> 140482768138760
	140482749428232 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140482749413136 -> 140482768138368
	140482749413136 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140482749412912 -> 140482768134096
	140482749412912 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140482749412968 -> 140482768134096
	140482749412968 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140482749412632 -> 140482768133872
	140482749412632 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749412408 -> 140482768133760
	140482749412408 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140482749412464 -> 140482768133760
	140482749412464 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140482768133648 -> 140482768133480
	140482768133648 [label=CudnnBatchNormBackward]
	140482768133816 -> 140482768133648
	140482768133816 [label=CudnnConvolutionBackward]
	140482768138480 -> 140482768133816
	140482749413192 -> 140482768133816
	140482749413192 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140482749412520 -> 140482768133648
	140482749412520 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140482749412688 -> 140482768133648
	140482749412688 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140482768133368 -> 140482768133200
	140482768133368 [label=CudnnBatchNormBackward]
	140482768133536 -> 140482768133368
	140482768133536 [label=CudnnConvolutionBackward]
	140482768133928 -> 140482768133536
	140482768133928 [label=ReluBackward1]
	140482768138536 -> 140482768133928
	140482768138536 [label=CudnnBatchNormBackward]
	140482768138424 -> 140482768138536
	140482768138424 [label=CudnnConvolutionBackward]
	140482768133312 -> 140482768138424
	140482749429912 -> 140482768138424
	140482749429912 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749429576 -> 140482768138536
	140482749429576 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140482749429968 -> 140482768138536
	140482749429968 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140482749413472 -> 140482768133536
	140482749413472 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749412184 -> 140482768133368
	140482749412184 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140482749413024 -> 140482768133368
	140482749413024 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140482768133088 -> 140482768132920
	140482768133088 [label=CudnnBatchNormBackward]
	140482768133256 -> 140482768133088
	140482768133256 [label=CudnnConvolutionBackward]
	140482768133704 -> 140482768133256
	140482768133704 [label=ReluBackward1]
	140482768138816 -> 140482768133704
	140482768138816 [label=CudnnBatchNormBackward]
	140482768138312 -> 140482768138816
	140482768138312 [label=CudnnConvolutionBackward]
	140482768133032 -> 140482768138312
	140482749430472 -> 140482768138312
	140482749430472 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749430304 -> 140482768138816
	140482749430304 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140482749430360 -> 140482768138816
	140482749430360 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140482749430080 -> 140482768133256
	140482749430080 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749411904 -> 140482768133088
	140482749411904 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140482749412800 -> 140482768133088
	140482749412800 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140482768132808 -> 140482768132640
	140482768132808 [label=CudnnBatchNormBackward]
	140482768132976 -> 140482768132808
	140482768132976 [label=CudnnConvolutionBackward]
	140482768133424 -> 140482768132976
	140482768133424 [label=ReluBackward1]
	140482768140328 -> 140482768133424
	140482768140328 [label=CudnnBatchNormBackward]
	140482768139096 -> 140482768140328
	140482768139096 [label=CudnnConvolutionBackward]
	140482768132752 -> 140482768139096
	140482749430920 -> 140482768139096
	140482749430920 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749430752 -> 140482768140328
	140482749430752 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140482749430808 -> 140482768140328
	140482749430808 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140482749430528 -> 140482768132976
	140482749430528 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749411624 -> 140482768132808
	140482749411624 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140482749428680 -> 140482768132808
	140482749428680 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140482768132528 -> 140482768132360
	140482768132528 [label=CudnnBatchNormBackward]
	140482768132696 -> 140482768132528
	140482768132696 [label=CudnnConvolutionBackward]
	140482768133144 -> 140482768132696
	140482768133144 [label=ReluBackward1]
	140482768141056 -> 140482768133144
	140482768141056 [label=CudnnBatchNormBackward]
	140482768141000 -> 140482768141056
	140482768141000 [label=CudnnConvolutionBackward]
	140482768132472 -> 140482768141000
	140482749431368 -> 140482768141000
	140482749431368 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482749431200 -> 140482768141056
	140482749431200 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140482749431256 -> 140482768141056
	140482749431256 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140482749430976 -> 140482768132696
	140482749430976 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140482911518672 -> 140482768132528
	140482911518672 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140482749429744 -> 140482768132528
	140482749429744 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140482911518056 -> 140482768132136
	140482911518056 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140482911517832 -> 140482768132024
	140482911517832 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140482911517888 -> 140482768132024
	140482911517888 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140482911517552 -> 140482768131800
	140482911517552 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482911517328 -> 140482768131688
	140482911517328 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140482911517384 -> 140482768131688
	140482911517384 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140482768131576 -> 140482768131408
	140482768131576 [label=CudnnBatchNormBackward]
	140482768131744 -> 140482768131576
	140482768131744 [label=CudnnConvolutionBackward]
	140482768132248 -> 140482768131744
	140482911518112 -> 140482768131744
	140482911518112 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140482911517440 -> 140482768131576
	140482911517440 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140482911517608 -> 140482768131576
	140482911517608 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140482768131296 -> 140482768131128
	140482768131296 [label=CudnnBatchNormBackward]
	140482768131464 -> 140482768131296
	140482768131464 [label=CudnnConvolutionBackward]
	140482768131856 -> 140482768131464
	140482768131856 [label=ReluBackward1]
	140482768132304 -> 140482768131856
	140482768132304 [label=CudnnBatchNormBackward]
	140482768132192 -> 140482768132304
	140482768132192 [label=CudnnConvolutionBackward]
	140482768131240 -> 140482768132192
	140482749431480 -> 140482768132192
	140482749431480 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482749431144 -> 140482768132304
	140482749431144 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140482749431536 -> 140482768132304
	140482749431536 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140482911518392 -> 140482768131464
	140482911518392 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482911517104 -> 140482768131296
	140482911517104 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140482911517944 -> 140482768131296
	140482911517944 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140482768131016 -> 140482768130848
	140482768131016 [label=CudnnBatchNormBackward]
	140482768131184 -> 140482768131016
	140482768131184 [label=CudnnConvolutionBackward]
	140482768131632 -> 140482768131184
	140482768131632 [label=ReluBackward1]
	140482768132584 -> 140482768131632
	140482768132584 [label=CudnnBatchNormBackward]
	140482768132080 -> 140482768132584
	140482768132080 [label=CudnnConvolutionBackward]
	140482768130960 -> 140482768132080
	140482749460776 -> 140482768132080
	140482749460776 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482749460608 -> 140482768132584
	140482749460608 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140482749460664 -> 140482768132584
	140482749460664 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140482749431648 -> 140482768131184
	140482749431648 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482911516824 -> 140482768131016
	140482911516824 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140482911517720 -> 140482768131016
	140482911517720 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140482768130736 -> 140482768130568
	140482768130736 [label=CudnnBatchNormBackward]
	140482768130904 -> 140482768130736
	140482768130904 [label=CudnnConvolutionBackward]
	140482768131352 -> 140482768130904
	140482768131352 [label=ReluBackward1]
	140482768134040 -> 140482768131352
	140482768134040 [label=CudnnBatchNormBackward]
	140482768132864 -> 140482768134040
	140482768132864 [label=CudnnConvolutionBackward]
	140482768130680 -> 140482768132864
	140482749461224 -> 140482768132864
	140482749461224 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482749461056 -> 140482768134040
	140482749461056 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140482749461112 -> 140482768134040
	140482749461112 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140482749460720 -> 140482768130904
	140482749460720 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482911516544 -> 140482768130736
	140482911516544 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140482749430248 -> 140482768130736
	140482749430248 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140482768130456 -> 140482768130288
	140482768130456 [label=CudnnBatchNormBackward]
	140482768130624 -> 140482768130456
	140482768130624 [label=CudnnConvolutionBackward]
	140482768131072 -> 140482768130624
	140482768131072 [label=ReluBackward1]
	140482768132416 -> 140482768131072
	140482768132416 [label=CudnnBatchNormBackward]
	140482768140944 -> 140482768132416
	140482768140944 [label=CudnnConvolutionBackward]
	140482768130400 -> 140482768140944
	140482749461672 -> 140482768140944
	140482749461672 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482749461504 -> 140482768132416
	140482749461504 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140482749461560 -> 140482768132416
	140482749461560 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140482749461280 -> 140482768130624
	140482749461280 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140482911516264 -> 140482768130456
	140482911516264 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140482749431312 -> 140482768130456
	140482749431312 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140482767379928 -> 140482767379424
	140482767379928 [label=TBackward]
	140482911514808 -> 140482767379928
	140482911514808 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
