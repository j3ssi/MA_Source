digraph {
	graph [size="64.35,64.35"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	139961521551344 [label=AddmmBackward fillcolor=darkolivegreen1]
	139961641601456 -> 139961521551344
	139961641601456 [label="module_list.63.bias
 (10)" fillcolor=lightblue]
	139961521658736 -> 139961521551344
	139961521658736 [label=ViewBackward]
	139961521656272 -> 139961521658736
	139961521656272 [label=ViewBackward]
	139961521655992 -> 139961521656272
	139961521655992 [label=MeanBackward1]
	139961521657280 -> 139961521655992
	139961521657280 [label=ViewBackward]
	139961521658960 -> 139961521657280
	139961521658960 [label=ReluBackward1]
	139961521656328 -> 139961521658960
	139961521656328 [label=AddBackward0]
	139961521657728 -> 139961521656328
	139961521657728 [label=ReluBackward1]
	139961521659296 -> 139961521657728
	139961521659296 [label=AddBackward0]
	139961509105736 -> 139961521659296
	139961509105736 [label=ReluBackward1]
	139961509105904 -> 139961509105736
	139961509105904 [label=AddBackward0]
	139961509106016 -> 139961509105904
	139961509106016 [label=ReluBackward1]
	139961509106184 -> 139961509106016
	139961509106184 [label=AddBackward0]
	139961509106296 -> 139961509106184
	139961509106296 [label=ReluBackward1]
	139961509106464 -> 139961509106296
	139961509106464 [label=AddBackward0]
	139961509106576 -> 139961509106464
	139961509106576 [label=ReluBackward1]
	139961509106744 -> 139961509106576
	139961509106744 [label=CudnnBatchNormBackward]
	139961509106856 -> 139961509106744
	139961509106856 [label=CudnnConvolutionBackward]
	139961509107080 -> 139961509106856
	139961509107080 [label=ReluBackward1]
	139961509107248 -> 139961509107080
	139961509107248 [label=CudnnBatchNormBackward]
	139961509107360 -> 139961509107248
	139961509107360 [label=CudnnConvolutionBackward]
	139961509107584 -> 139961509107360
	139961509107584 [label=ReluBackward1]
	139961509107752 -> 139961509107584
	139961509107752 [label=AddBackward0]
	139961509107864 -> 139961509107752
	139961509107864 [label=ReluBackward1]
	139961509108032 -> 139961509107864
	139961509108032 [label=AddBackward0]
	139961509108144 -> 139961509108032
	139961509108144 [label=ReluBackward1]
	139961509108312 -> 139961509108144
	139961509108312 [label=AddBackward0]
	139961509108424 -> 139961509108312
	139961509108424 [label=ReluBackward1]
	139961509108592 -> 139961509108424
	139961509108592 [label=AddBackward0]
	139961509108704 -> 139961509108592
	139961509108704 [label=ReluBackward1]
	139961509108872 -> 139961509108704
	139961509108872 [label=CudnnBatchNormBackward]
	139961509108984 -> 139961509108872
	139961509108984 [label=CudnnConvolutionBackward]
	139961509109208 -> 139961509108984
	139961509109208 [label=ReluBackward1]
	139961509109376 -> 139961509109208
	139961509109376 [label=CudnnBatchNormBackward]
	139961509109488 -> 139961509109376
	139961509109488 [label=CudnnConvolutionBackward]
	139961509109712 -> 139961509109488
	139961509109712 [label=ReluBackward1]
	139961509064888 -> 139961509109712
	139961509064888 [label=AddBackward0]
	139961509065000 -> 139961509064888
	139961509065000 [label=ReluBackward1]
	139961509065168 -> 139961509065000
	139961509065168 [label=AddBackward0]
	139961509065280 -> 139961509065168
	139961509065280 [label=ReluBackward1]
	139961509065448 -> 139961509065280
	139961509065448 [label=AddBackward0]
	139961509065560 -> 139961509065448
	139961509065560 [label=ReluBackward1]
	139961509065728 -> 139961509065560
	139961509065728 [label=AddBackward0]
	139961509065840 -> 139961509065728
	139961509065840 [label=ReluBackward1]
	139961509066008 -> 139961509065840
	139961509066008 [label=AddBackward0]
	139961509066120 -> 139961509066008
	139961509066120 [label=ReluBackward1]
	139961509066288 -> 139961509066120
	139961509066288 [label=CudnnBatchNormBackward]
	139961509066400 -> 139961509066288
	139961509066400 [label=CudnnConvolutionBackward]
	139961509066624 -> 139961509066400
	139961509066624 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	139961509066456 -> 139961509066288
	139961509066456 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	139961509066512 -> 139961509066288
	139961509066512 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	139961509066176 -> 139961509066008
	139961509066176 [label=CudnnBatchNormBackward]
	139961509066344 -> 139961509066176
	139961509066344 [label=CudnnConvolutionBackward]
	139961509066736 -> 139961509066344
	139961509066736 [label=ReluBackward1]
	139961509066960 -> 139961509066736
	139961509066960 [label=CudnnBatchNormBackward]
	139961509067072 -> 139961509066960
	139961509067072 [label=CudnnConvolutionBackward]
	139961509066120 -> 139961509067072
	139961509067296 -> 139961509067072
	139961509067296 [label="module_list.2.weight
 (9, 16, 3, 3)" fillcolor=lightblue]
	139961509067128 -> 139961509066960
	139961509067128 [label="module_list.3.weight
 (9)" fillcolor=lightblue]
	139961509067184 -> 139961509066960
	139961509067184 [label="module_list.3.bias
 (9)" fillcolor=lightblue]
	139961509066848 -> 139961509066344
	139961509066848 [label="module_list.4.weight
 (16, 9, 3, 3)" fillcolor=lightblue]
	139961509066568 -> 139961509066176
	139961509066568 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	139961509066680 -> 139961509066176
	139961509066680 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	139961509065896 -> 139961509065728
	139961509065896 [label=CudnnBatchNormBackward]
	139961509066064 -> 139961509065896
	139961509066064 [label=CudnnConvolutionBackward]
	139961509067240 -> 139961509066064
	139961509067240 [label=ReluBackward1]
	139961509067464 -> 139961509067240
	139961509067464 [label=CudnnBatchNormBackward]
	139961509067520 -> 139961509067464
	139961509067520 [label=CudnnConvolutionBackward]
	139961509065840 -> 139961509067520
	139961509067744 -> 139961509067520
	139961509067744 [label="module_list.6.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	139961509067576 -> 139961509067464
	139961509067576 [label="module_list.7.weight
 (14)" fillcolor=lightblue]
	139961509067632 -> 139961509067464
	139961509067632 [label="module_list.7.bias
 (14)" fillcolor=lightblue]
	139961509067016 -> 139961509066064
	139961509067016 [label="module_list.8.weight
 (16, 14, 3, 3)" fillcolor=lightblue]
	139961509066232 -> 139961509065896
	139961509066232 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	139961509066792 -> 139961509065896
	139961509066792 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	139961509065616 -> 139961509065448
	139961509065616 [label=CudnnBatchNormBackward]
	139961509065784 -> 139961509065616
	139961509065784 [label=CudnnConvolutionBackward]
	139961509067688 -> 139961509065784
	139961509067688 [label=ReluBackward1]
	139961509067912 -> 139961509067688
	139961509067912 [label=CudnnBatchNormBackward]
	139961509067856 -> 139961509067912
	139961509067856 [label=CudnnConvolutionBackward]
	139961509065560 -> 139961509067856
	139961509068192 -> 139961509067856
	139961509068192 [label="module_list.10.weight
 (11, 16, 3, 3)" fillcolor=lightblue]
	139961509068024 -> 139961509067912
	139961509068024 [label="module_list.11.weight
 (11)" fillcolor=lightblue]
	139961509068080 -> 139961509067912
	139961509068080 [label="module_list.11.bias
 (11)" fillcolor=lightblue]
	139961509067800 -> 139961509065784
	139961509067800 [label="module_list.12.weight
 (16, 11, 3, 3)" fillcolor=lightblue]
	139961509065952 -> 139961509065616
	139961509065952 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	139961509066904 -> 139961509065616
	139961509066904 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	139961509065336 -> 139961509065168
	139961509065336 [label=CudnnBatchNormBackward]
	139961509065504 -> 139961509065336
	139961509065504 [label=CudnnConvolutionBackward]
	139961509068136 -> 139961509065504
	139961509068136 [label=ReluBackward1]
	139961509068360 -> 139961509068136
	139961509068360 [label=CudnnBatchNormBackward]
	139961509068304 -> 139961509068360
	139961509068304 [label=CudnnConvolutionBackward]
	139961509065280 -> 139961509068304
	139961509068640 -> 139961509068304
	139961509068640 [label="module_list.14.weight
 (9, 16, 3, 3)" fillcolor=lightblue]
	139961509068472 -> 139961509068360
	139961509068472 [label="module_list.15.weight
 (9)" fillcolor=lightblue]
	139961509068528 -> 139961509068360
	139961509068528 [label="module_list.15.bias
 (9)" fillcolor=lightblue]
	139961509068248 -> 139961509065504
	139961509068248 [label="module_list.16.weight
 (16, 9, 3, 3)" fillcolor=lightblue]
	139961509065672 -> 139961509065336
	139961509065672 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	139961509067352 -> 139961509065336
	139961509067352 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	139961509065056 -> 139961509064888
	139961509065056 [label=CudnnBatchNormBackward]
	139961509065224 -> 139961509065056
	139961509065224 [label=CudnnConvolutionBackward]
	139961509068584 -> 139961509065224
	139961509068584 [label=ReluBackward1]
	139961509068752 -> 139961509068584
	139961509068752 [label=CudnnBatchNormBackward]
	139961508966528 -> 139961509068752
	139961508966528 [label=CudnnConvolutionBackward]
	139961509065000 -> 139961508966528
	139961508966752 -> 139961508966528
	139961508966752 [label="module_list.18.weight
 (14, 16, 3, 3)" fillcolor=lightblue]
	139961508966584 -> 139961509068752
	139961508966584 [label="module_list.19.weight
 (14)" fillcolor=lightblue]
	139961508966640 -> 139961509068752
	139961508966640 [label="module_list.19.bias
 (14)" fillcolor=lightblue]
	139961509068416 -> 139961509065224
	139961509068416 [label="module_list.20.weight
 (16, 14, 3, 3)" fillcolor=lightblue]
	139961509065392 -> 139961509065056
	139961509065392 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	139961509067408 -> 139961509065056
	139961509067408 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	139961509064776 -> 139961509109488
	139961509064776 [label="module_list.22.weight
 (21, 16, 3, 3)" fillcolor=lightblue]
	139961509109544 -> 139961509109376
	139961509109544 [label="module_list.23.weight
 (21)" fillcolor=lightblue]
	139961509109600 -> 139961509109376
	139961509109600 [label="module_list.23.bias
 (21)" fillcolor=lightblue]
	139961509109264 -> 139961509108984
	139961509109264 [label="module_list.24.weight
 (32, 21, 3, 3)" fillcolor=lightblue]
	139961509109040 -> 139961509108872
	139961509109040 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	139961509109096 -> 139961509108872
	139961509109096 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	139961509108760 -> 139961509108592
	139961509108760 [label=CudnnBatchNormBackward]
	139961509108928 -> 139961509108760
	139961509108928 [label=CudnnConvolutionBackward]
	139961509109712 -> 139961509108928
	139961509109432 -> 139961509108928
	139961509109432 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	139961509109152 -> 139961509108760
	139961509109152 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	139961509109320 -> 139961509108760
	139961509109320 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	139961509108480 -> 139961509108312
	139961509108480 [label=CudnnBatchNormBackward]
	139961509108648 -> 139961509108480
	139961509108648 [label=CudnnConvolutionBackward]
	139961509067968 -> 139961509108648
	139961509067968 [label=ReluBackward1]
	139961509068696 -> 139961509067968
	139961509068696 [label=CudnnBatchNormBackward]
	139961508966808 -> 139961509068696
	139961508966808 [label=CudnnConvolutionBackward]
	139961509108424 -> 139961508966808
	139961508966864 -> 139961508966808
	139961508966864 [label="module_list.28.weight
 (29, 32, 3, 3)" fillcolor=lightblue]
	139961508966472 -> 139961509068696
	139961508966472 [label="module_list.29.weight
 (29)" fillcolor=lightblue]
	139961508966920 -> 139961509068696
	139961508966920 [label="module_list.29.bias
 (29)" fillcolor=lightblue]
	139961509064944 -> 139961509108648
	139961509064944 [label="module_list.30.weight
 (32, 29, 3, 3)" fillcolor=lightblue]
	139961509108816 -> 139961509108480
	139961509108816 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	139961509109656 -> 139961509108480
	139961509109656 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	139961509108200 -> 139961509108032
	139961509108200 [label=CudnnBatchNormBackward]
	139961509108368 -> 139961509108200
	139961509108368 [label=CudnnConvolutionBackward]
	139961508966976 -> 139961509108368
	139961508966976 [label=ReluBackward1]
	139961508967144 -> 139961508966976
	139961508967144 [label=CudnnBatchNormBackward]
	139961508967088 -> 139961508967144
	139961508967088 [label=CudnnConvolutionBackward]
	139961509108144 -> 139961508967088
	139961508967424 -> 139961508967088
	139961508967424 [label="module_list.32.weight
 (21, 32, 3, 3)" fillcolor=lightblue]
	139961508967256 -> 139961508967144
	139961508967256 [label="module_list.33.weight
 (21)" fillcolor=lightblue]
	139961508967312 -> 139961508967144
	139961508967312 [label="module_list.33.bias
 (21)" fillcolor=lightblue]
	139961508967032 -> 139961509108368
	139961508967032 [label="module_list.34.weight
 (32, 21, 3, 3)" fillcolor=lightblue]
	139961509108536 -> 139961509108200
	139961509108536 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	139961509064832 -> 139961509108200
	139961509064832 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	139961509107920 -> 139961509107752
	139961509107920 [label=CudnnBatchNormBackward]
	139961509108088 -> 139961509107920
	139961509108088 [label=CudnnConvolutionBackward]
	139961521606440 -> 139961509108088
	139961521606440 [label=ReluBackward1]
	139961508967368 -> 139961521606440
	139961508967368 [label=CudnnBatchNormBackward]
	139961508967592 -> 139961508967368
	139961508967592 [label=CudnnConvolutionBackward]
	139961509107864 -> 139961508967592
	139961508967760 -> 139961508967592
	139961508967760 [label="module_list.36.weight
 (21, 32, 3, 3)" fillcolor=lightblue]
	139961508967648 -> 139961508967368
	139961508967648 [label="module_list.37.weight
 (21)" fillcolor=lightblue]
	139961508967536 -> 139961508967368
	139961508967536 [label="module_list.37.bias
 (21)" fillcolor=lightblue]
	139961508966696 -> 139961509108088
	139961508966696 [label="module_list.38.weight
 (32, 21, 3, 3)" fillcolor=lightblue]
	139961509108256 -> 139961509107920
	139961509108256 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	139961509065112 -> 139961509107920
	139961509065112 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	139961509107640 -> 139961509107360
	139961509107640 [label="module_list.40.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139961509107416 -> 139961509107248
	139961509107416 [label="module_list.41.weight
 (64)" fillcolor=lightblue]
	139961509107472 -> 139961509107248
	139961509107472 [label="module_list.41.bias
 (64)" fillcolor=lightblue]
	139961509107136 -> 139961509106856
	139961509107136 [label="module_list.42.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139961509106912 -> 139961509106744
	139961509106912 [label="module_list.43.weight
 (64)" fillcolor=lightblue]
	139961509106968 -> 139961509106744
	139961509106968 [label="module_list.43.bias
 (64)" fillcolor=lightblue]
	139961509106632 -> 139961509106464
	139961509106632 [label=CudnnBatchNormBackward]
	139961521552632 -> 139961509106632
	139961521552632 [label=CudnnConvolutionBackward]
	139961509107584 -> 139961521552632
	139961509107304 -> 139961521552632
	139961509107304 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139961509106800 -> 139961509106632
	139961509106800 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	139961509107024 -> 139961509106632
	139961509107024 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	139961509106352 -> 139961509106184
	139961509106352 [label=CudnnBatchNormBackward]
	139961509106520 -> 139961509106352
	139961509106520 [label=CudnnConvolutionBackward]
	139961509107976 -> 139961509106520
	139961509107976 [label=ReluBackward1]
	139961508967200 -> 139961509107976
	139961508967200 [label=CudnnBatchNormBackward]
	139961508967816 -> 139961508967200
	139961508967816 [label=CudnnConvolutionBackward]
	139961509106296 -> 139961508967816
	139961508967872 -> 139961508967816
	139961508967872 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139961508967480 -> 139961508967200
	139961508967480 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	139961508967928 -> 139961508967200
	139961508967928 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	139961509107808 -> 139961509106520
	139961509107808 [label="module_list.48.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139961509106688 -> 139961509106352
	139961509106688 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	139961509107192 -> 139961509106352
	139961509107192 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	139961509106072 -> 139961509105904
	139961509106072 [label=CudnnBatchNormBackward]
	139961509106240 -> 139961509106072
	139961509106240 [label=CudnnConvolutionBackward]
	139961508967984 -> 139961509106240
	139961508967984 [label=ReluBackward1]
	139961508968152 -> 139961508967984
	139961508968152 [label=CudnnBatchNormBackward]
	139961508968096 -> 139961508968152
	139961508968096 [label=CudnnConvolutionBackward]
	139961509106016 -> 139961508968096
	139961508968432 -> 139961508968096
	139961508968432 [label="module_list.50.weight
 (55, 64, 3, 3)" fillcolor=lightblue]
	139961508968264 -> 139961508968152
	139961508968264 [label="module_list.51.weight
 (55)" fillcolor=lightblue]
	139961508968320 -> 139961508968152
	139961508968320 [label="module_list.51.bias
 (55)" fillcolor=lightblue]
	139961508968040 -> 139961509106240
	139961508968040 [label="module_list.52.weight
 (64, 55, 3, 3)" fillcolor=lightblue]
	139961509106408 -> 139961509106072
	139961509106408 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	139961509107528 -> 139961509106072
	139961509107528 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	139961509105792 -> 139961521659296
	139961509105792 [label=CudnnBatchNormBackward]
	139961509105960 -> 139961509105792
	139961509105960 [label=CudnnConvolutionBackward]
	139961508968376 -> 139961509105960
	139961508968376 [label=ReluBackward1]
	139961508968600 -> 139961508968376
	139961508968600 [label=CudnnBatchNormBackward]
	139961508968544 -> 139961508968600
	139961508968544 [label=CudnnConvolutionBackward]
	139961509105736 -> 139961508968544
	139961508968880 -> 139961508968544
	139961508968880 [label="module_list.54.weight
 (53, 64, 3, 3)" fillcolor=lightblue]
	139961508968712 -> 139961508968600
	139961508968712 [label="module_list.55.weight
 (53)" fillcolor=lightblue]
	139961508968768 -> 139961508968600
	139961508968768 [label="module_list.55.bias
 (53)" fillcolor=lightblue]
	139961508968488 -> 139961509105960
	139961508968488 [label="module_list.56.weight
 (64, 53, 3, 3)" fillcolor=lightblue]
	139961509106128 -> 139961509105792
	139961509106128 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	139961509107696 -> 139961509105792
	139961509107696 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	139961521657616 -> 139961521656328
	139961521657616 [label=CudnnBatchNormBackward]
	139961521658624 -> 139961521657616
	139961521658624 [label=CudnnConvolutionBackward]
	139961508968824 -> 139961521658624
	139961508968824 [label=ReluBackward1]
	139961508969048 -> 139961508968824
	139961508969048 [label=CudnnBatchNormBackward]
	139961508968992 -> 139961508969048
	139961508968992 [label=CudnnConvolutionBackward]
	139961521657728 -> 139961508968992
	139961508969328 -> 139961508968992
	139961508969328 [label="module_list.58.weight
 (7, 64, 3, 3)" fillcolor=lightblue]
	139961508969160 -> 139961508969048
	139961508969160 [label="module_list.59.weight
 (7)" fillcolor=lightblue]
	139961508969216 -> 139961508969048
	139961508969216 [label="module_list.59.bias
 (7)" fillcolor=lightblue]
	139961508968936 -> 139961521658624
	139961508968936 [label="module_list.60.weight
 (64, 7, 3, 3)" fillcolor=lightblue]
	139961509105848 -> 139961521657616
	139961509105848 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	139961508967704 -> 139961521657616
	139961508967704 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	139961521657168 -> 139961521551344
	139961521657168 [label=TBackward]
	139961521656720 -> 139961521657168
	139961521656720 [label="module_list.63.weight
 (10, 64)" fillcolor=lightblue]
}
