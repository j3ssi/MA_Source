digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	139902792942144 [label=AddmmBackward fillcolor=darkolivegreen1]
	139902792941976 -> 139902792942144
	139902792941976 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	139902792944664 -> 139902792942144
	139902792944664 [label=ViewBackward]
	139902795505224 -> 139902792944664
	139902795505224 [label=ViewBackward]
	139902795505336 -> 139902795505224
	139902795505336 [label=MeanBackward1]
	139902795505448 -> 139902795505336
	139902795505448 [label=ViewBackward]
	139902795505560 -> 139902795505448
	139902795505560 [label=ReluBackward1]
	139902792573000 -> 139902795505560
	139902792573000 [label=AddBackward0]
	139902792573112 -> 139902792573000
	139902792573112 [label=ReluBackward1]
	139902792573280 -> 139902792573112
	139902792573280 [label=AddBackward0]
	139902792573392 -> 139902792573280
	139902792573392 [label=ReluBackward1]
	139902792573560 -> 139902792573392
	139902792573560 [label=AddBackward0]
	139902792573672 -> 139902792573560
	139902792573672 [label=ReluBackward1]
	139902792573840 -> 139902792573672
	139902792573840 [label=AddBackward0]
	139902792573952 -> 139902792573840
	139902792573952 [label=ReluBackward1]
	139902792574120 -> 139902792573952
	139902792574120 [label=AddBackward0]
	139902792574232 -> 139902792574120
	139902792574232 [label=ReluBackward1]
	139902792574400 -> 139902792574232
	139902792574400 [label=CudnnBatchNormBackward]
	139902792574512 -> 139902792574400
	139902792574512 [label=CudnnConvolutionBackward]
	139902792574624 -> 139902792574512
	139902792574624 [label=ReluBackward1]
	139902792574736 -> 139902792574624
	139902792574736 [label=CudnnBatchNormBackward]
	139902792574848 -> 139902792574736
	139902792574848 [label=CudnnConvolutionBackward]
	139902792574960 -> 139902792574848
	139902792574960 [label=ReluBackward1]
	139902792575072 -> 139902792574960
	139902792575072 [label=AddBackward0]
	139902792575184 -> 139902792575072
	139902792575184 [label=ReluBackward1]
	139902792575352 -> 139902792575184
	139902792575352 [label=AddBackward0]
	139902792575464 -> 139902792575352
	139902792575464 [label=ReluBackward1]
	139902792575632 -> 139902792575464
	139902792575632 [label=AddBackward0]
	139902792575744 -> 139902792575632
	139902792575744 [label=ReluBackward1]
	139902792575912 -> 139902792575744
	139902792575912 [label=AddBackward0]
	139902792576024 -> 139902792575912
	139902792576024 [label=ReluBackward1]
	139902792576192 -> 139902792576024
	139902792576192 [label=AddBackward0]
	139902792576304 -> 139902792576192
	139902792576304 [label=ReluBackward1]
	139902792576472 -> 139902792576304
	139902792576472 [label=CudnnBatchNormBackward]
	139902792576584 -> 139902792576472
	139902792576584 [label=CudnnConvolutionBackward]
	139902792576696 -> 139902792576584
	139902792576696 [label=ReluBackward1]
	139902792576808 -> 139902792576696
	139902792576808 [label=CudnnBatchNormBackward]
	139902792576920 -> 139902792576808
	139902792576920 [label=CudnnConvolutionBackward]
	139902792577096 -> 139902792576920
	139902792577096 [label=ReluBackward1]
	139902792577208 -> 139902792577096
	139902792577208 [label=AddBackward0]
	139902792577320 -> 139902792577208
	139902792577320 [label=ReluBackward1]
	139902792577488 -> 139902792577320
	139902792577488 [label=AddBackward0]
	139902792577600 -> 139902792577488
	139902792577600 [label=ReluBackward1]
	139902792577768 -> 139902792577600
	139902792577768 [label=AddBackward0]
	139902792577880 -> 139902792577768
	139902792577880 [label=ReluBackward1]
	139902792578048 -> 139902792577880
	139902792578048 [label=AddBackward0]
	139902792578160 -> 139902792578048
	139902792578160 [label=ReluBackward1]
	139902792578328 -> 139902792578160
	139902792578328 [label=AddBackward0]
	139902792578440 -> 139902792578328
	139902792578440 [label=ReluBackward1]
	139902792578608 -> 139902792578440
	139902792578608 [label=CudnnBatchNormBackward]
	139902792578720 -> 139902792578608
	139902792578720 [label=CudnnConvolutionBackward]
	139902792973672 -> 139902792578720
	139902792973672 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	139902792973504 -> 139902792578608
	139902792973504 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	139902792973560 -> 139902792578608
	139902792973560 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	139902792578496 -> 139902792578328
	139902792578496 [label=CudnnBatchNormBackward]
	139902792578664 -> 139902792578496
	139902792578664 [label=CudnnConvolutionBackward]
	139902792578832 -> 139902792578664
	139902792578832 [label=ReluBackward1]
	139902792578888 -> 139902792578832
	139902792578888 [label=CudnnBatchNormBackward]
	139902792579056 -> 139902792578888
	139902792579056 [label=CudnnConvolutionBackward]
	139902792578440 -> 139902792579056
	139902794690632 -> 139902792579056
	139902794690632 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902792974176 -> 139902792578888
	139902792974176 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	139902792974232 -> 139902792578888
	139902792974232 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	139902792973896 -> 139902792578664
	139902792973896 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902792973616 -> 139902792578496
	139902792973616 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	139902792973728 -> 139902792578496
	139902792973728 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	139902792578216 -> 139902792578048
	139902792578216 [label=CudnnBatchNormBackward]
	139902792578384 -> 139902792578216
	139902792578384 [label=CudnnConvolutionBackward]
	139902792578776 -> 139902792578384
	139902792578776 [label=ReluBackward1]
	139902792579112 -> 139902792578776
	139902792579112 [label=CudnnBatchNormBackward]
	139902792579000 -> 139902792579112
	139902792579000 [label=CudnnConvolutionBackward]
	139902792578160 -> 139902792579000
	139902794691080 -> 139902792579000
	139902794691080 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902794690912 -> 139902792579112
	139902794690912 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	139902794690968 -> 139902792579112
	139902794690968 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	139902792974064 -> 139902792578384
	139902792974064 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902792973280 -> 139902792578216
	139902792973280 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	139902792973840 -> 139902792578216
	139902792973840 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	139902792577936 -> 139902792577768
	139902792577936 [label=CudnnBatchNormBackward]
	139902792578104 -> 139902792577936
	139902792578104 [label=CudnnConvolutionBackward]
	139902792578552 -> 139902792578104
	139902792578552 [label=ReluBackward1]
	139902792579280 -> 139902792578552
	139902792579280 [label=CudnnBatchNormBackward]
	139902792579168 -> 139902792579280
	139902792579168 [label=CudnnConvolutionBackward]
	139902792577880 -> 139902792579168
	139902794691528 -> 139902792579168
	139902794691528 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902794691360 -> 139902792579280
	139902794691360 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	139902794691416 -> 139902792579280
	139902794691416 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	139902794691136 -> 139902792578104
	139902794691136 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902792972776 -> 139902792577936
	139902792972776 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	139902792973952 -> 139902792577936
	139902792973952 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	139902792577656 -> 139902792577488
	139902792577656 [label=CudnnBatchNormBackward]
	139902792577824 -> 139902792577656
	139902792577824 [label=CudnnConvolutionBackward]
	139902792578272 -> 139902792577824
	139902792578272 [label=ReluBackward1]
	139902792579392 -> 139902792578272
	139902792579392 [label=CudnnBatchNormBackward]
	139902792579336 -> 139902792579392
	139902792579336 [label=CudnnConvolutionBackward]
	139902792577600 -> 139902792579336
	139902794691976 -> 139902792579336
	139902794691976 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902794691808 -> 139902792579392
	139902794691808 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	139902794691864 -> 139902792579392
	139902794691864 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	139902794691584 -> 139902792577824
	139902794691584 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902792972888 -> 139902792577656
	139902792972888 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	139902794690688 -> 139902792577656
	139902794690688 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	139902792577376 -> 139902792577208
	139902792577376 [label=CudnnBatchNormBackward]
	139902792577544 -> 139902792577376
	139902792577544 [label=CudnnConvolutionBackward]
	139902792577992 -> 139902792577544
	139902792577992 [label=ReluBackward1]
	139902792579504 -> 139902792577992
	139902792579504 [label=CudnnBatchNormBackward]
	139902792579448 -> 139902792579504
	139902792579448 [label=CudnnConvolutionBackward]
	139902792577320 -> 139902792579448
	139902794692424 -> 139902792579448
	139902794692424 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902794692256 -> 139902792579504
	139902794692256 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	139902794692312 -> 139902792579504
	139902794692312 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	139902794692032 -> 139902792577544
	139902794692032 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	139902792970480 -> 139902792577376
	139902792970480 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	139902794690856 -> 139902792577376
	139902794690856 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	139902792971096 -> 139902792576920
	139902792971096 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	139902792971320 -> 139902792576808
	139902792971320 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	139902792971264 -> 139902792576808
	139902792971264 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	139902792971656 -> 139902792576584
	139902792971656 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902792971880 -> 139902792576472
	139902792971880 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	139902792971824 -> 139902792576472
	139902792971824 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	139902792576360 -> 139902792576192
	139902792576360 [label=CudnnBatchNormBackward]
	139902792576528 -> 139902792576360
	139902792576528 [label=CudnnConvolutionBackward]
	139902792577096 -> 139902792576528
	139902792971040 -> 139902792576528
	139902792971040 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	139902792971768 -> 139902792576360
	139902792971768 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	139902792971600 -> 139902792576360
	139902792971600 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	139902792576080 -> 139902792575912
	139902792576080 [label=CudnnBatchNormBackward]
	139902792576248 -> 139902792576080
	139902792576248 [label=CudnnConvolutionBackward]
	139902792576640 -> 139902792576248
	139902792576640 [label=ReluBackward1]
	139902792576864 -> 139902792576640
	139902792576864 [label=CudnnBatchNormBackward]
	139902792577152 -> 139902792576864
	139902792577152 [label=CudnnConvolutionBackward]
	139902792576024 -> 139902792577152
	139902794692536 -> 139902792577152
	139902794692536 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902794692200 -> 139902792576864
	139902794692200 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	139902794692592 -> 139902792576864
	139902794692592 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	139902792970760 -> 139902792576248
	139902792970760 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902792972160 -> 139902792576080
	139902792972160 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	139902792971208 -> 139902792576080
	139902792971208 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	139902792575800 -> 139902792575632
	139902792575800 [label=CudnnBatchNormBackward]
	139902792575968 -> 139902792575800
	139902792575968 [label=CudnnConvolutionBackward]
	139902792576416 -> 139902792575968
	139902792576416 [label=ReluBackward1]
	139902792576976 -> 139902792576416
	139902792576976 [label=CudnnBatchNormBackward]
	139902792577712 -> 139902792576976
	139902792577712 [label=CudnnConvolutionBackward]
	139902792575744 -> 139902792577712
	139902794693096 -> 139902792577712
	139902794693096 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902794692928 -> 139902792576976
	139902794692928 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	139902794692984 -> 139902792576976
	139902794692984 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	139902794692704 -> 139902792575968
	139902794692704 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902792972496 -> 139902792575800
	139902792972496 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	139902792971432 -> 139902792575800
	139902792971432 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	139902792575520 -> 139902792575352
	139902792575520 [label=CudnnBatchNormBackward]
	139902792575688 -> 139902792575520
	139902792575688 [label=CudnnConvolutionBackward]
	139902792576136 -> 139902792575688
	139902792576136 [label=ReluBackward1]
	139902792578944 -> 139902792576136
	139902792578944 [label=CudnnBatchNormBackward]
	139902792577432 -> 139902792578944
	139902792577432 [label=CudnnConvolutionBackward]
	139902792575464 -> 139902792577432
	139902794693544 -> 139902792577432
	139902794693544 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902794693376 -> 139902792578944
	139902794693376 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	139902794693432 -> 139902792578944
	139902794693432 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	139902794693152 -> 139902792575688
	139902794693152 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902793786816 -> 139902792575520
	139902793786816 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	139902794691304 -> 139902792575520
	139902794691304 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	139902792575240 -> 139902792575072
	139902792575240 [label=CudnnBatchNormBackward]
	139902792575408 -> 139902792575240
	139902792575408 [label=CudnnConvolutionBackward]
	139902792575856 -> 139902792575408
	139902792575856 [label=ReluBackward1]
	139902792579672 -> 139902792575856
	139902792579672 [label=CudnnBatchNormBackward]
	139902792579616 -> 139902792579672
	139902792579616 [label=CudnnConvolutionBackward]
	139902792575184 -> 139902792579616
	139902794693992 -> 139902792579616
	139902794693992 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902794693824 -> 139902792579672
	139902794693824 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	139902794693880 -> 139902792579672
	139902794693880 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	139902794693600 -> 139902792575408
	139902794693600 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	139902793785976 -> 139902792575240
	139902793785976 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	139902794692368 -> 139902792575240
	139902794692368 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	139902793787040 -> 139902792574848
	139902793787040 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139902793787264 -> 139902792574736
	139902793787264 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	139902793787208 -> 139902792574736
	139902793787208 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	139902793787600 -> 139902792574512
	139902793787600 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902793787880 -> 139902792574400
	139902793787880 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	139902793787824 -> 139902792574400
	139902793787824 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	139902792574288 -> 139902792574120
	139902792574288 [label=CudnnBatchNormBackward]
	139902792574456 -> 139902792574288
	139902792574456 [label=CudnnConvolutionBackward]
	139902792574960 -> 139902792574456
	139902793786928 -> 139902792574456
	139902793786928 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	139902793787768 -> 139902792574288
	139902793787768 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	139902793787544 -> 139902792574288
	139902793787544 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	139902792574008 -> 139902792573840
	139902792574008 [label=CudnnBatchNormBackward]
	139902792574176 -> 139902792574008
	139902792574176 [label=CudnnConvolutionBackward]
	139902792574568 -> 139902792574176
	139902792574568 [label=ReluBackward1]
	139902792575016 -> 139902792574568
	139902792575016 [label=CudnnBatchNormBackward]
	139902792574904 -> 139902792575016
	139902792574904 [label=CudnnConvolutionBackward]
	139902792573952 -> 139902792574904
	139902794694104 -> 139902792574904
	139902794694104 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902794693768 -> 139902792575016
	139902794693768 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	139902794694160 -> 139902792575016
	139902794694160 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	139902793786424 -> 139902792574176
	139902793786424 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902793788160 -> 139902792574008
	139902793788160 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	139902793787152 -> 139902792574008
	139902793787152 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	139902792573728 -> 139902792573560
	139902792573728 [label=CudnnBatchNormBackward]
	139902792573896 -> 139902792573728
	139902792573896 [label=CudnnConvolutionBackward]
	139902792574344 -> 139902792573896
	139902792574344 [label=ReluBackward1]
	139902792575296 -> 139902792574344
	139902792575296 [label=CudnnBatchNormBackward]
	139902792574792 -> 139902792575296
	139902792574792 [label=CudnnConvolutionBackward]
	139902792573672 -> 139902792574792
	139902794727496 -> 139902792574792
	139902794727496 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902794694496 -> 139902792575296
	139902794694496 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	139902794694552 -> 139902792575296
	139902794694552 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	139902794694272 -> 139902792573896
	139902794694272 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902793788496 -> 139902792573728
	139902793788496 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	139902793787432 -> 139902792573728
	139902793787432 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	139902792573448 -> 139902792573280
	139902792573448 [label=CudnnBatchNormBackward]
	139902792573616 -> 139902792573448
	139902792573616 [label=CudnnConvolutionBackward]
	139902792574064 -> 139902792573616
	139902792574064 [label=ReluBackward1]
	139902792576752 -> 139902792574064
	139902792576752 [label=CudnnBatchNormBackward]
	139902792575576 -> 139902792576752
	139902792575576 [label=CudnnConvolutionBackward]
	139902792573392 -> 139902792575576
	139902794727944 -> 139902792575576
	139902794727944 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902794727776 -> 139902792576752
	139902794727776 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	139902794727832 -> 139902792576752
	139902794727832 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	139902794694440 -> 139902792573616
	139902794694440 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902793788776 -> 139902792573448
	139902793788776 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	139902794692872 -> 139902792573448
	139902794692872 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	139902792573168 -> 139902792573000
	139902792573168 [label=CudnnBatchNormBackward]
	139902792573336 -> 139902792573168
	139902792573336 [label=CudnnConvolutionBackward]
	139902792573784 -> 139902792573336
	139902792573784 [label=ReluBackward1]
	139902792575128 -> 139902792573784
	139902792575128 [label=CudnnBatchNormBackward]
	139902792579560 -> 139902792575128
	139902792579560 [label=CudnnConvolutionBackward]
	139902792573112 -> 139902792579560
	139902794728392 -> 139902792579560
	139902794728392 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902794728224 -> 139902792575128
	139902794728224 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	139902794728280 -> 139902792575128
	139902794728280 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	139902794728000 -> 139902792573336
	139902794728000 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	139902793789112 -> 139902792573168
	139902793789112 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	139902794693936 -> 139902792573168
	139902794693936 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	139902795505280 -> 139902792942144
	139902795505280 [label=TBackward]
	139902792942256 -> 139902795505280
	139902792942256 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
