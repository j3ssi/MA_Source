digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140296550886928 [label=AddmmBackward fillcolor=darkolivegreen1]
	140296691209048 -> 140296550886928
	140296691209048 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140296550886760 -> 140296550886928
	140296550886760 [label=ViewBackward]
	140296550886984 -> 140296550886760
	140296550886984 [label=ViewBackward]
	140296550887096 -> 140296550886984
	140296550887096 [label=MeanBackward1]
	140296550887208 -> 140296550887096
	140296550887208 [label=ViewBackward]
	140296550887320 -> 140296550887208
	140296550887320 [label=ReluBackward1]
	140296551116872 -> 140296550887320
	140296551116872 [label=AddBackward0]
	140296551116984 -> 140296551116872
	140296551116984 [label=ReluBackward1]
	140296551117152 -> 140296551116984
	140296551117152 [label=AddBackward0]
	140296551117264 -> 140296551117152
	140296551117264 [label=ReluBackward1]
	140296551117432 -> 140296551117264
	140296551117432 [label=AddBackward0]
	140296551117544 -> 140296551117432
	140296551117544 [label=ReluBackward1]
	140296551117712 -> 140296551117544
	140296551117712 [label=AddBackward0]
	140296551117824 -> 140296551117712
	140296551117824 [label=ReluBackward1]
	140296551117992 -> 140296551117824
	140296551117992 [label=AddBackward0]
	140296551118104 -> 140296551117992
	140296551118104 [label=ReluBackward1]
	140296551118272 -> 140296551118104
	140296551118272 [label=CudnnBatchNormBackward]
	140296551118384 -> 140296551118272
	140296551118384 [label=CudnnConvolutionBackward]
	140296551118496 -> 140296551118384
	140296551118496 [label=ReluBackward1]
	140296551118608 -> 140296551118496
	140296551118608 [label=CudnnBatchNormBackward]
	140296551118720 -> 140296551118608
	140296551118720 [label=CudnnConvolutionBackward]
	140296551118832 -> 140296551118720
	140296551118832 [label=ReluBackward1]
	140296551118944 -> 140296551118832
	140296551118944 [label=AddBackward0]
	140296551119056 -> 140296551118944
	140296551119056 [label=ReluBackward1]
	140296551119224 -> 140296551119056
	140296551119224 [label=AddBackward0]
	140296551119336 -> 140296551119224
	140296551119336 [label=ReluBackward1]
	140296551119504 -> 140296551119336
	140296551119504 [label=AddBackward0]
	140296551119616 -> 140296551119504
	140296551119616 [label=ReluBackward1]
	140296551119784 -> 140296551119616
	140296551119784 [label=AddBackward0]
	140296551119896 -> 140296551119784
	140296551119896 [label=ReluBackward1]
	140296551120064 -> 140296551119896
	140296551120064 [label=AddBackward0]
	140296551120176 -> 140296551120064
	140296551120176 [label=ReluBackward1]
	140296551120344 -> 140296551120176
	140296551120344 [label=CudnnBatchNormBackward]
	140296551120456 -> 140296551120344
	140296551120456 [label=CudnnConvolutionBackward]
	140296551120568 -> 140296551120456
	140296551120568 [label=ReluBackward1]
	140296551120680 -> 140296551120568
	140296551120680 [label=CudnnBatchNormBackward]
	140296551120792 -> 140296551120680
	140296551120792 [label=CudnnConvolutionBackward]
	140296551125064 -> 140296551120792
	140296551125064 [label=ReluBackward1]
	140296551125176 -> 140296551125064
	140296551125176 [label=AddBackward0]
	140296551125288 -> 140296551125176
	140296551125288 [label=ReluBackward1]
	140296551125456 -> 140296551125288
	140296551125456 [label=AddBackward0]
	140296551125568 -> 140296551125456
	140296551125568 [label=ReluBackward1]
	140296551125736 -> 140296551125568
	140296551125736 [label=AddBackward0]
	140296551125848 -> 140296551125736
	140296551125848 [label=ReluBackward1]
	140296551126016 -> 140296551125848
	140296551126016 [label=AddBackward0]
	140296551126128 -> 140296551126016
	140296551126128 [label=ReluBackward1]
	140296551126296 -> 140296551126128
	140296551126296 [label=AddBackward0]
	140296551126408 -> 140296551126296
	140296551126408 [label=ReluBackward1]
	140296551126576 -> 140296551126408
	140296551126576 [label=CudnnBatchNormBackward]
	140296551126688 -> 140296551126576
	140296551126688 [label=CudnnConvolutionBackward]
	140296456797936 -> 140296551126688
	140296456797936 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140296456797768 -> 140296551126576
	140296456797768 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140296456797824 -> 140296551126576
	140296456797824 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140296551126464 -> 140296551126296
	140296551126464 [label=CudnnBatchNormBackward]
	140296551126632 -> 140296551126464
	140296551126632 [label=CudnnConvolutionBackward]
	140296551126800 -> 140296551126632
	140296551126800 [label=ReluBackward1]
	140296551126856 -> 140296551126800
	140296551126856 [label=CudnnBatchNormBackward]
	140296551127024 -> 140296551126856
	140296551127024 [label=CudnnConvolutionBackward]
	140296551126408 -> 140296551127024
	140296456806864 -> 140296551127024
	140296456806864 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456806696 -> 140296551126856
	140296456806696 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140296456806752 -> 140296551126856
	140296456806752 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140296456798160 -> 140296551126632
	140296456798160 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456797880 -> 140296551126464
	140296456797880 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140296456797992 -> 140296551126464
	140296456797992 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140296551126184 -> 140296551126016
	140296551126184 [label=CudnnBatchNormBackward]
	140296551126352 -> 140296551126184
	140296551126352 [label=CudnnConvolutionBackward]
	140296551126744 -> 140296551126352
	140296551126744 [label=ReluBackward1]
	140296551127080 -> 140296551126744
	140296551127080 [label=CudnnBatchNormBackward]
	140296551126968 -> 140296551127080
	140296551126968 [label=CudnnConvolutionBackward]
	140296551126128 -> 140296551126968
	140296456807312 -> 140296551126968
	140296456807312 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456807144 -> 140296551127080
	140296456807144 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140296456807200 -> 140296551127080
	140296456807200 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140296456806920 -> 140296551126352
	140296456806920 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456797544 -> 140296551126184
	140296456797544 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140296456798104 -> 140296551126184
	140296456798104 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140296551125904 -> 140296551125736
	140296551125904 [label=CudnnBatchNormBackward]
	140296551126072 -> 140296551125904
	140296551126072 [label=CudnnConvolutionBackward]
	140296551126520 -> 140296551126072
	140296551126520 [label=ReluBackward1]
	140296551127248 -> 140296551126520
	140296551127248 [label=CudnnBatchNormBackward]
	140296551127136 -> 140296551127248
	140296551127136 [label=CudnnConvolutionBackward]
	140296551125848 -> 140296551127136
	140296456807760 -> 140296551127136
	140296456807760 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456807592 -> 140296551127248
	140296456807592 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140296456807648 -> 140296551127248
	140296456807648 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140296456807368 -> 140296551126072
	140296456807368 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456797264 -> 140296551125904
	140296456797264 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140296456806472 -> 140296551125904
	140296456806472 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140296551125624 -> 140296551125456
	140296551125624 [label=CudnnBatchNormBackward]
	140296551125792 -> 140296551125624
	140296551125792 [label=CudnnConvolutionBackward]
	140296551126240 -> 140296551125792
	140296551126240 [label=ReluBackward1]
	140296551127360 -> 140296551126240
	140296551127360 [label=CudnnBatchNormBackward]
	140296551127304 -> 140296551127360
	140296551127304 [label=CudnnConvolutionBackward]
	140296551125568 -> 140296551127304
	140296456808208 -> 140296551127304
	140296456808208 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456808040 -> 140296551127360
	140296456808040 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140296456808096 -> 140296551127360
	140296456808096 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140296456807816 -> 140296551125792
	140296456807816 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456796984 -> 140296551125624
	140296456796984 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140296456806584 -> 140296551125624
	140296456806584 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140296551125344 -> 140296551125176
	140296551125344 [label=CudnnBatchNormBackward]
	140296551125512 -> 140296551125344
	140296551125512 [label=CudnnConvolutionBackward]
	140296551125960 -> 140296551125512
	140296551125960 [label=ReluBackward1]
	140296551127472 -> 140296551125960
	140296551127472 [label=CudnnBatchNormBackward]
	140296551127416 -> 140296551127472
	140296551127416 [label=CudnnConvolutionBackward]
	140296551125288 -> 140296551127416
	140296456808656 -> 140296551127416
	140296456808656 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456808488 -> 140296551127472
	140296456808488 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140296456808544 -> 140296551127472
	140296456808544 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140296456808264 -> 140296551125512
	140296456808264 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140296456796704 -> 140296551125344
	140296456796704 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140296456807088 -> 140296551125344
	140296456807088 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140296456796088 -> 140296551120792
	140296456796088 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140296456795864 -> 140296551120680
	140296456795864 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140296456795920 -> 140296551120680
	140296456795920 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140296456795584 -> 140296551120456
	140296456795584 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456795360 -> 140296551120344
	140296456795360 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140296456795416 -> 140296551120344
	140296456795416 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140296551120232 -> 140296551120064
	140296551120232 [label=CudnnBatchNormBackward]
	140296551120400 -> 140296551120232
	140296551120400 [label=CudnnConvolutionBackward]
	140296551125064 -> 140296551120400
	140296456796144 -> 140296551120400
	140296456796144 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140296456795472 -> 140296551120232
	140296456795472 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140296456795640 -> 140296551120232
	140296456795640 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140296551119952 -> 140296551119784
	140296551119952 [label=CudnnBatchNormBackward]
	140296551120120 -> 140296551119952
	140296551120120 [label=CudnnConvolutionBackward]
	140296551120512 -> 140296551120120
	140296551120512 [label=ReluBackward1]
	140296551120736 -> 140296551120512
	140296551120736 [label=CudnnBatchNormBackward]
	140296551125120 -> 140296551120736
	140296551125120 [label=CudnnConvolutionBackward]
	140296551119896 -> 140296551125120
	140296456808768 -> 140296551125120
	140296456808768 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456808432 -> 140296551120736
	140296456808432 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140296456808824 -> 140296551120736
	140296456808824 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140296456796424 -> 140296551120120
	140296456796424 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456795136 -> 140296551119952
	140296456795136 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140296456795976 -> 140296551119952
	140296456795976 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140296551119672 -> 140296551119504
	140296551119672 [label=CudnnBatchNormBackward]
	140296551119840 -> 140296551119672
	140296551119840 [label=CudnnConvolutionBackward]
	140296551120288 -> 140296551119840
	140296551120288 [label=ReluBackward1]
	140296551120848 -> 140296551120288
	140296551120848 [label=CudnnBatchNormBackward]
	140296551125680 -> 140296551120848
	140296551125680 [label=CudnnConvolutionBackward]
	140296551119616 -> 140296551125680
	140296456809328 -> 140296551125680
	140296456809328 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456809160 -> 140296551120848
	140296456809160 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140296456809216 -> 140296551120848
	140296456809216 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140296456808936 -> 140296551119840
	140296456808936 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456794856 -> 140296551119672
	140296456794856 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140296456795752 -> 140296551119672
	140296456795752 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140296551119392 -> 140296551119224
	140296551119392 [label=CudnnBatchNormBackward]
	140296551119560 -> 140296551119392
	140296551119560 [label=CudnnConvolutionBackward]
	140296551120008 -> 140296551119560
	140296551120008 [label=ReluBackward1]
	140296551126912 -> 140296551120008
	140296551126912 [label=CudnnBatchNormBackward]
	140296551125400 -> 140296551126912
	140296551125400 [label=CudnnConvolutionBackward]
	140296551119336 -> 140296551125400
	140296456809776 -> 140296551125400
	140296456809776 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456809608 -> 140296551126912
	140296456809608 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140296456809664 -> 140296551126912
	140296456809664 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140296456809384 -> 140296551119560
	140296456809384 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456794576 -> 140296551119392
	140296456794576 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140296456807536 -> 140296551119392
	140296456807536 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140296551119112 -> 140296551118944
	140296551119112 [label=CudnnBatchNormBackward]
	140296551119280 -> 140296551119112
	140296551119280 [label=CudnnConvolutionBackward]
	140296551119728 -> 140296551119280
	140296551119728 [label=ReluBackward1]
	140296551127640 -> 140296551119728
	140296551127640 [label=CudnnBatchNormBackward]
	140296551127584 -> 140296551127640
	140296551127584 [label=CudnnConvolutionBackward]
	140296551119056 -> 140296551127584
	140296456810224 -> 140296551127584
	140296456810224 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456810056 -> 140296551127640
	140296456810056 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140296456810112 -> 140296551127640
	140296456810112 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140296456809832 -> 140296551119280
	140296456809832 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140296456794296 -> 140296551119112
	140296456794296 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140296456808600 -> 140296551119112
	140296456808600 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140296568331792 -> 140296551118720
	140296568331792 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140296568331568 -> 140296551118608
	140296568331568 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140296568331624 -> 140296551118608
	140296568331624 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140296568331288 -> 140296551118384
	140296568331288 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568331064 -> 140296551118272
	140296568331064 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140296568331120 -> 140296551118272
	140296568331120 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140296551118160 -> 140296551117992
	140296551118160 [label=CudnnBatchNormBackward]
	140296551118328 -> 140296551118160
	140296551118328 [label=CudnnConvolutionBackward]
	140296551118832 -> 140296551118328
	140296568331848 -> 140296551118328
	140296568331848 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140296568331176 -> 140296551118160
	140296568331176 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140296568331344 -> 140296551118160
	140296568331344 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140296551117880 -> 140296551117712
	140296551117880 [label=CudnnBatchNormBackward]
	140296551118048 -> 140296551117880
	140296551118048 [label=CudnnConvolutionBackward]
	140296551118440 -> 140296551118048
	140296551118440 [label=ReluBackward1]
	140296551118888 -> 140296551118440
	140296551118888 [label=CudnnBatchNormBackward]
	140296551118776 -> 140296551118888
	140296551118776 [label=CudnnConvolutionBackward]
	140296551117824 -> 140296551118776
	140296456810336 -> 140296551118776
	140296456810336 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456810000 -> 140296551118888
	140296456810000 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140296456810392 -> 140296551118888
	140296456810392 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140296568332128 -> 140296551118048
	140296568332128 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330840 -> 140296551117880
	140296568330840 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140296568331680 -> 140296551117880
	140296568331680 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140296551117600 -> 140296551117432
	140296551117600 [label=CudnnBatchNormBackward]
	140296551117768 -> 140296551117600
	140296551117768 [label=CudnnConvolutionBackward]
	140296551118216 -> 140296551117768
	140296551118216 [label=ReluBackward1]
	140296551119168 -> 140296551118216
	140296551119168 [label=CudnnBatchNormBackward]
	140296551118664 -> 140296551119168
	140296551118664 [label=CudnnConvolutionBackward]
	140296551117544 -> 140296551118664
	140296456843728 -> 140296551118664
	140296456843728 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456843560 -> 140296551119168
	140296456843560 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140296456843616 -> 140296551119168
	140296456843616 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140296456810168 -> 140296551117768
	140296456810168 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330560 -> 140296551117600
	140296568330560 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140296568331456 -> 140296551117600
	140296568331456 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140296551117320 -> 140296551117152
	140296551117320 [label=CudnnBatchNormBackward]
	140296551117488 -> 140296551117320
	140296551117488 [label=CudnnConvolutionBackward]
	140296551117936 -> 140296551117488
	140296551117936 [label=ReluBackward1]
	140296551120624 -> 140296551117936
	140296551120624 [label=CudnnBatchNormBackward]
	140296551119448 -> 140296551120624
	140296551119448 [label=CudnnConvolutionBackward]
	140296551117264 -> 140296551119448
	140296456844176 -> 140296551119448
	140296456844176 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456844008 -> 140296551120624
	140296456844008 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140296456844064 -> 140296551120624
	140296456844064 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140296456843784 -> 140296551117488
	140296456843784 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330280 -> 140296551117320
	140296568330280 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140296456809104 -> 140296551117320
	140296456809104 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140296551117040 -> 140296551116872
	140296551117040 [label=CudnnBatchNormBackward]
	140296551117208 -> 140296551117040
	140296551117208 [label=CudnnConvolutionBackward]
	140296551117656 -> 140296551117208
	140296551117656 [label=ReluBackward1]
	140296551119000 -> 140296551117656
	140296551119000 [label=CudnnBatchNormBackward]
	140296551127528 -> 140296551119000
	140296551127528 [label=CudnnConvolutionBackward]
	140296551116984 -> 140296551127528
	140296456844624 -> 140296551127528
	140296456844624 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296456844456 -> 140296551119000
	140296456844456 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140296456844512 -> 140296551119000
	140296456844512 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140296456844232 -> 140296551117208
	140296456844232 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140296568330000 -> 140296551117040
	140296568330000 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140296456843336 -> 140296551117040
	140296456843336 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140296550886816 -> 140296550886928
	140296550886816 [label=TBackward]
	140296568328992 -> 140296550886816
	140296568328992 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
