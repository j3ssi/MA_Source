digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140110898166192 [label=AddmmBackward fillcolor=darkolivegreen1]
	140111048807424 -> 140110898166192
	140111048807424 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140110898165520 -> 140110898166192
	140110898165520 [label=ViewBackward]
	140110898166416 -> 140110898165520
	140110898166416 [label=ViewBackward]
	140110898165856 -> 140110898166416
	140110898165856 [label=MeanBackward1]
	140110898166528 -> 140110898165856
	140110898166528 [label=ViewBackward]
	140110898166640 -> 140110898166528
	140110898166640 [label=ReluBackward1]
	140110898166752 -> 140110898166640
	140110898166752 [label=AddBackward0]
	140110898166864 -> 140110898166752
	140110898166864 [label=ReluBackward1]
	140110898167032 -> 140110898166864
	140110898167032 [label=AddBackward0]
	140110898167144 -> 140110898167032
	140110898167144 [label=ReluBackward1]
	140110898167312 -> 140110898167144
	140110898167312 [label=AddBackward0]
	140110898167424 -> 140110898167312
	140110898167424 [label=ReluBackward1]
	140110898167592 -> 140110898167424
	140110898167592 [label=AddBackward0]
	140110898167704 -> 140110898167592
	140110898167704 [label=ReluBackward1]
	140110899269760 -> 140110898167704
	140110899269760 [label=AddBackward0]
	140110899269872 -> 140110899269760
	140110899269872 [label=ReluBackward1]
	140110899270040 -> 140110899269872
	140110899270040 [label=CudnnBatchNormBackward]
	140110899270152 -> 140110899270040
	140110899270152 [label=CudnnConvolutionBackward]
	140110899270264 -> 140110899270152
	140110899270264 [label=ReluBackward1]
	140110899270376 -> 140110899270264
	140110899270376 [label=CudnnBatchNormBackward]
	140110899270488 -> 140110899270376
	140110899270488 [label=CudnnConvolutionBackward]
	140110899270600 -> 140110899270488
	140110899270600 [label=ReluBackward1]
	140110899270712 -> 140110899270600
	140110899270712 [label=AddBackward0]
	140110899270824 -> 140110899270712
	140110899270824 [label=ReluBackward1]
	140110899270992 -> 140110899270824
	140110899270992 [label=AddBackward0]
	140110899271104 -> 140110899270992
	140110899271104 [label=ReluBackward1]
	140110899271272 -> 140110899271104
	140110899271272 [label=AddBackward0]
	140110899271384 -> 140110899271272
	140110899271384 [label=ReluBackward1]
	140110899271552 -> 140110899271384
	140110899271552 [label=AddBackward0]
	140110899271664 -> 140110899271552
	140110899271664 [label=ReluBackward1]
	140110899271832 -> 140110899271664
	140110899271832 [label=AddBackward0]
	140110899271944 -> 140110899271832
	140110899271944 [label=ReluBackward1]
	140110899272112 -> 140110899271944
	140110899272112 [label=CudnnBatchNormBackward]
	140110899272224 -> 140110899272112
	140110899272224 [label=CudnnConvolutionBackward]
	140110899272336 -> 140110899272224
	140110899272336 [label=ReluBackward1]
	140110899272448 -> 140110899272336
	140110899272448 [label=CudnnBatchNormBackward]
	140110899272560 -> 140110899272448
	140110899272560 [label=CudnnConvolutionBackward]
	140110899272672 -> 140110899272560
	140110899272672 [label=ReluBackward1]
	140110899272784 -> 140110899272672
	140110899272784 [label=AddBackward0]
	140110899272896 -> 140110899272784
	140110899272896 [label=ReluBackward1]
	140110899273064 -> 140110899272896
	140110899273064 [label=AddBackward0]
	140110899273176 -> 140110899273064
	140110899273176 [label=ReluBackward1]
	140110899273344 -> 140110899273176
	140110899273344 [label=AddBackward0]
	140110899273456 -> 140110899273344
	140110899273456 [label=ReluBackward1]
	140110899273624 -> 140110899273456
	140110899273624 [label=AddBackward0]
	140110899286088 -> 140110899273624
	140110899286088 [label=ReluBackward1]
	140110899286256 -> 140110899286088
	140110899286256 [label=AddBackward0]
	140110899286368 -> 140110899286256
	140110899286368 [label=ReluBackward1]
	140110899286536 -> 140110899286368
	140110899286536 [label=CudnnBatchNormBackward]
	140110899286648 -> 140110899286536
	140110899286648 [label=CudnnConvolutionBackward]
	140110898118216 -> 140110899286648
	140110898118216 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140110898118048 -> 140110899286536
	140110898118048 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140110898118104 -> 140110899286536
	140110898118104 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140110899286424 -> 140110899286256
	140110899286424 [label=CudnnBatchNormBackward]
	140110899286592 -> 140110899286424
	140110899286592 [label=CudnnConvolutionBackward]
	140110899286760 -> 140110899286592
	140110899286760 [label=ReluBackward1]
	140110899286816 -> 140110899286760
	140110899286816 [label=CudnnBatchNormBackward]
	140110899286984 -> 140110899286816
	140110899286984 [label=CudnnConvolutionBackward]
	140110899286368 -> 140110899286984
	140110898131240 -> 140110899286984
	140110898131240 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898131072 -> 140110899286816
	140110898131072 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140110898131128 -> 140110899286816
	140110898131128 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140110898118440 -> 140110899286592
	140110898118440 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898118160 -> 140110899286424
	140110898118160 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140110898118272 -> 140110899286424
	140110898118272 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140110899286144 -> 140110899273624
	140110899286144 [label=CudnnBatchNormBackward]
	140110899286312 -> 140110899286144
	140110899286312 [label=CudnnConvolutionBackward]
	140110899286704 -> 140110899286312
	140110899286704 [label=ReluBackward1]
	140110899287040 -> 140110899286704
	140110899287040 [label=CudnnBatchNormBackward]
	140110899286928 -> 140110899287040
	140110899286928 [label=CudnnConvolutionBackward]
	140110899286088 -> 140110899286928
	140110898131688 -> 140110899286928
	140110898131688 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898131520 -> 140110899287040
	140110898131520 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140110898131576 -> 140110899287040
	140110898131576 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140110898131184 -> 140110899286312
	140110898131184 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898117824 -> 140110899286144
	140110898117824 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140110898118384 -> 140110899286144
	140110898118384 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140110899273512 -> 140110899273344
	140110899273512 [label=CudnnBatchNormBackward]
	140110899273680 -> 140110899273512
	140110899273680 [label=CudnnConvolutionBackward]
	140110899286480 -> 140110899273680
	140110899286480 [label=ReluBackward1]
	140110899287208 -> 140110899286480
	140110899287208 [label=CudnnBatchNormBackward]
	140110899287096 -> 140110899287208
	140110899287096 [label=CudnnConvolutionBackward]
	140110899273456 -> 140110899287096
	140110898132136 -> 140110899287096
	140110898132136 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898131968 -> 140110899287208
	140110898131968 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140110898132024 -> 140110899287208
	140110898132024 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140110898131744 -> 140110899273680
	140110898131744 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898117544 -> 140110899273512
	140110898117544 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140110898118496 -> 140110899273512
	140110898118496 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140110899273232 -> 140110899273064
	140110899273232 [label=CudnnBatchNormBackward]
	140110899273400 -> 140110899273232
	140110899273400 [label=CudnnConvolutionBackward]
	140110899286200 -> 140110899273400
	140110899286200 [label=ReluBackward1]
	140110899287320 -> 140110899286200
	140110899287320 [label=CudnnBatchNormBackward]
	140110899287264 -> 140110899287320
	140110899287264 [label=CudnnConvolutionBackward]
	140110899273176 -> 140110899287264
	140110898132584 -> 140110899287264
	140110898132584 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898132416 -> 140110899287320
	140110898132416 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140110898132472 -> 140110899287320
	140110898132472 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140110898132192 -> 140110899273400
	140110898132192 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898117264 -> 140110899273232
	140110898117264 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140110898131296 -> 140110899273232
	140110898131296 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140110899272952 -> 140110899272784
	140110899272952 [label=CudnnBatchNormBackward]
	140110899273120 -> 140110899272952
	140110899273120 [label=CudnnConvolutionBackward]
	140110899273568 -> 140110899273120
	140110899273568 [label=ReluBackward1]
	140110899287432 -> 140110899273568
	140110899287432 [label=CudnnBatchNormBackward]
	140110899287376 -> 140110899287432
	140110899287376 [label=CudnnConvolutionBackward]
	140110899272896 -> 140110899287376
	140110898133032 -> 140110899287376
	140110898133032 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898132864 -> 140110899287432
	140110898132864 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140110898132920 -> 140110899287432
	140110898132920 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140110898132640 -> 140110899273120
	140110898132640 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140110898116984 -> 140110899272952
	140110898116984 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140110898131464 -> 140110899272952
	140110898131464 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140110898116368 -> 140110899272560
	140110898116368 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140110898116144 -> 140110899272448
	140110898116144 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140110898116200 -> 140110899272448
	140110898116200 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140110898115864 -> 140110899272224
	140110898115864 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898115640 -> 140110899272112
	140110898115640 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140110898115696 -> 140110899272112
	140110898115696 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140110899272000 -> 140110899271832
	140110899272000 [label=CudnnBatchNormBackward]
	140110899272168 -> 140110899272000
	140110899272168 [label=CudnnConvolutionBackward]
	140110899272672 -> 140110899272168
	140110898116424 -> 140110899272168
	140110898116424 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140110898115752 -> 140110899272000
	140110898115752 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140110898115920 -> 140110899272000
	140110898115920 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140110899271720 -> 140110899271552
	140110899271720 [label=CudnnBatchNormBackward]
	140110899271888 -> 140110899271720
	140110899271888 [label=CudnnConvolutionBackward]
	140110899272280 -> 140110899271888
	140110899272280 [label=ReluBackward1]
	140110899272728 -> 140110899272280
	140110899272728 [label=CudnnBatchNormBackward]
	140110899272616 -> 140110899272728
	140110899272616 [label=CudnnConvolutionBackward]
	140110899271664 -> 140110899272616
	140110898133144 -> 140110899272616
	140110898133144 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898132808 -> 140110899272728
	140110898132808 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140110898133200 -> 140110899272728
	140110898133200 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140110898116704 -> 140110899271888
	140110898116704 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898115416 -> 140110899271720
	140110898115416 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140110898116256 -> 140110899271720
	140110898116256 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140110899271440 -> 140110899271272
	140110899271440 [label=CudnnBatchNormBackward]
	140110899271608 -> 140110899271440
	140110899271608 [label=CudnnConvolutionBackward]
	140110899272056 -> 140110899271608
	140110899272056 [label=ReluBackward1]
	140110899273008 -> 140110899272056
	140110899273008 [label=CudnnBatchNormBackward]
	140110899272504 -> 140110899273008
	140110899272504 [label=CudnnConvolutionBackward]
	140110899271384 -> 140110899272504
	140110898133704 -> 140110899272504
	140110898133704 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898133536 -> 140110899273008
	140110898133536 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140110898133592 -> 140110899273008
	140110898133592 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140110898133312 -> 140110899271608
	140110898133312 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898115136 -> 140110899271440
	140110898115136 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140110898116032 -> 140110899271440
	140110898116032 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140110899271160 -> 140110899270992
	140110899271160 [label=CudnnBatchNormBackward]
	140110899271328 -> 140110899271160
	140110899271328 [label=CudnnConvolutionBackward]
	140110899271776 -> 140110899271328
	140110899271776 [label=ReluBackward1]
	140110899272840 -> 140110899271776
	140110899272840 [label=CudnnBatchNormBackward]
	140110899286872 -> 140110899272840
	140110899286872 [label=CudnnConvolutionBackward]
	140110899271104 -> 140110899286872
	140110898134152 -> 140110899286872
	140110898134152 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898133984 -> 140110899272840
	140110898133984 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140110898134040 -> 140110899272840
	140110898134040 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140110898133760 -> 140110899271328
	140110898133760 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898114856 -> 140110899271160
	140110898114856 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140110898131912 -> 140110899271160
	140110898131912 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140110899270880 -> 140110899270712
	140110899270880 [label=CudnnBatchNormBackward]
	140110899271048 -> 140110899270880
	140110899271048 [label=CudnnConvolutionBackward]
	140110899271496 -> 140110899271048
	140110899271496 [label=ReluBackward1]
	140110899273288 -> 140110899271496
	140110899273288 [label=CudnnBatchNormBackward]
	140110899287488 -> 140110899273288
	140110899287488 [label=CudnnConvolutionBackward]
	140110899270824 -> 140110899287488
	140110898134600 -> 140110899287488
	140110898134600 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110898134432 -> 140110899273288
	140110898134432 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140110898134488 -> 140110899273288
	140110898134488 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140110898134208 -> 140110899271048
	140110898134208 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140110925922256 -> 140110899270880
	140110925922256 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140110898132976 -> 140110899270880
	140110898132976 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140110925921640 -> 140110899270488
	140110925921640 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140110925921416 -> 140110899270376
	140110925921416 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140110925921472 -> 140110899270376
	140110925921472 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140110925921136 -> 140110899270152
	140110925921136 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110925920912 -> 140110899270040
	140110925920912 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140110925920968 -> 140110899270040
	140110925920968 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140110899269928 -> 140110899269760
	140110899269928 [label=CudnnBatchNormBackward]
	140110899270096 -> 140110899269928
	140110899270096 [label=CudnnConvolutionBackward]
	140110899270600 -> 140110899270096
	140110925921696 -> 140110899270096
	140110925921696 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140110925921024 -> 140110899269928
	140110925921024 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140110925921192 -> 140110899269928
	140110925921192 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140110898167760 -> 140110898167592
	140110898167760 [label=CudnnBatchNormBackward]
	140110899269816 -> 140110898167760
	140110899269816 [label=CudnnConvolutionBackward]
	140110899270208 -> 140110899269816
	140110899270208 [label=ReluBackward1]
	140110899270656 -> 140110899270208
	140110899270656 [label=CudnnBatchNormBackward]
	140110899270544 -> 140110899270656
	140110899270544 [label=CudnnConvolutionBackward]
	140110898167704 -> 140110899270544
	140110898134712 -> 140110899270544
	140110898134712 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110898134376 -> 140110899270656
	140110898134376 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140110898134768 -> 140110899270656
	140110898134768 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140110925921976 -> 140110899269816
	140110925921976 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110925920688 -> 140110898167760
	140110925920688 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140110925921528 -> 140110898167760
	140110925921528 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140110898167480 -> 140110898167312
	140110898167480 [label=CudnnBatchNormBackward]
	140110898167648 -> 140110898167480
	140110898167648 [label=CudnnConvolutionBackward]
	140110899269984 -> 140110898167648
	140110899269984 [label=ReluBackward1]
	140110899270936 -> 140110899269984
	140110899270936 [label=CudnnBatchNormBackward]
	140110899270432 -> 140110899270936
	140110899270432 [label=CudnnConvolutionBackward]
	140110898167424 -> 140110899270432
	140110898164008 -> 140110899270432
	140110898164008 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110898163840 -> 140110899270936
	140110898163840 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140110898163896 -> 140110899270936
	140110898163896 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140110898134880 -> 140110898167648
	140110898134880 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110925920408 -> 140110898167480
	140110925920408 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140110925921304 -> 140110898167480
	140110925921304 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140110898167200 -> 140110898167032
	140110898167200 [label=CudnnBatchNormBackward]
	140110898167368 -> 140110898167200
	140110898167368 [label=CudnnConvolutionBackward]
	140110899269704 -> 140110898167368
	140110899269704 [label=ReluBackward1]
	140110899272392 -> 140110899269704
	140110899272392 [label=CudnnBatchNormBackward]
	140110899271216 -> 140110899272392
	140110899271216 [label=CudnnConvolutionBackward]
	140110898167144 -> 140110899271216
	140110898164456 -> 140110899271216
	140110898164456 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110898164288 -> 140110899272392
	140110898164288 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140110898164344 -> 140110899272392
	140110898164344 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140110898163952 -> 140110898167368
	140110898163952 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110925920128 -> 140110898167200
	140110925920128 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140110898133480 -> 140110898167200
	140110898133480 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140110898166920 -> 140110898166752
	140110898166920 [label=CudnnBatchNormBackward]
	140110898167088 -> 140110898166920
	140110898167088 [label=CudnnConvolutionBackward]
	140110898167536 -> 140110898167088
	140110898167536 [label=ReluBackward1]
	140110899270768 -> 140110898167536
	140110899270768 [label=CudnnBatchNormBackward]
	140110899287600 -> 140110899270768
	140110899287600 [label=CudnnConvolutionBackward]
	140110898166864 -> 140110899287600
	140110898164904 -> 140110899287600
	140110898164904 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110898164736 -> 140110899270768
	140110898164736 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140110898164792 -> 140110899270768
	140110898164792 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140110898164512 -> 140110898167088
	140110898164512 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140110925919848 -> 140110898166920
	140110925919848 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140110898134544 -> 140110898166920
	140110898134544 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140110898166360 -> 140110898166192
	140110898166360 [label=TBackward]
	140110925918728 -> 140110898166360
	140110925918728 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
