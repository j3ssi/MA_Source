digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140169644417880 [label=AddmmBackward fillcolor=darkolivegreen1]
	140169764638848 -> 140169644417880
	140169764638848 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140169644417824 -> 140169644417880
	140169644417824 [label=ViewBackward]
	140169644468992 -> 140169644417824
	140169644468992 [label=ViewBackward]
	140169644468768 -> 140169644468992
	140169644468768 [label=MeanBackward1]
	140169644469832 -> 140169644468768
	140169644469832 [label=ViewBackward]
	140169644467984 -> 140169644469832
	140169644467984 [label=ReluBackward1]
	140169644470112 -> 140169644467984
	140169644470112 [label=AddBackward0]
	140169644466920 -> 140169644470112
	140169644466920 [label=ReluBackward1]
	140169644467256 -> 140169644466920
	140169644467256 [label=AddBackward0]
	140169615761648 -> 140169644467256
	140169615761648 [label=ReluBackward1]
	140169615763384 -> 140169615761648
	140169615763384 [label=AddBackward0]
	140169615763552 -> 140169615763384
	140169615763552 [label=ReluBackward1]
	140169615761816 -> 140169615763552
	140169615761816 [label=AddBackward0]
	140169615765176 -> 140169615761816
	140169615765176 [label=ReluBackward1]
	140169615762600 -> 140169615765176
	140169615762600 [label=AddBackward0]
	140169615763776 -> 140169615762600
	140169615763776 [label=ReluBackward1]
	140169615763328 -> 140169615763776
	140169615763328 [label=CudnnBatchNormBackward]
	140169615762936 -> 140169615763328
	140169615762936 [label=CudnnConvolutionBackward]
	140169615765288 -> 140169615762936
	140169615765288 [label=ReluBackward1]
	140169615763216 -> 140169615765288
	140169615763216 [label=CudnnBatchNormBackward]
	140169615764336 -> 140169615763216
	140169615764336 [label=CudnnConvolutionBackward]
	140169615763608 -> 140169615764336
	140169615763608 [label=ReluBackward1]
	140169615764280 -> 140169615763608
	140169615764280 [label=AddBackward0]
	140169615762712 -> 140169615764280
	140169615762712 [label=ReluBackward1]
	140169615763272 -> 140169615762712
	140169615763272 [label=AddBackward0]
	140169615764784 -> 140169615763272
	140169615764784 [label=ReluBackward1]
	140169615763888 -> 140169615764784
	140169615763888 [label=AddBackward0]
	140169615765008 -> 140169615763888
	140169615765008 [label=ReluBackward1]
	140169615763664 -> 140169615765008
	140169615763664 [label=AddBackward0]
	140169615765456 -> 140169615763664
	140169615765456 [label=ReluBackward1]
	140169614003000 -> 140169615765456
	140169614003000 [label=AddBackward0]
	140169614002104 -> 140169614003000
	140169614002104 [label=ReluBackward1]
	140169614001488 -> 140169614002104
	140169614001488 [label=CudnnBatchNormBackward]
	140169614001264 -> 140169614001488
	140169614001264 [label=CudnnConvolutionBackward]
	140169614001880 -> 140169614001264
	140169614001880 [label=ReluBackward1]
	140169614000536 -> 140169614001880
	140169614000536 [label=CudnnBatchNormBackward]
	140169614000592 -> 140169614000536
	140169614000592 [label=CudnnConvolutionBackward]
	140169614001768 -> 140169614000592
	140169614001768 [label=ReluBackward1]
	140169614000256 -> 140169614001768
	140169614000256 [label=AddBackward0]
	140169614000816 -> 140169614000256
	140169614000816 [label=ReluBackward1]
	140169614000480 -> 140169614000816
	140169614000480 [label=AddBackward0]
	140169614000760 -> 140169614000480
	140169614000760 [label=ReluBackward1]
	140169614001656 -> 140169614000760
	140169614001656 [label=AddBackward0]
	140169614001152 -> 140169614001656
	140169614001152 [label=ReluBackward1]
	140169614001824 -> 140169614001152
	140169614001824 [label=AddBackward0]
	140169614000928 -> 140169614001824
	140169614000928 [label=ReluBackward1]
	140169614004176 -> 140169614000928
	140169614004176 [label=AddBackward0]
	140169615524304 -> 140169614004176
	140169615524304 [label=ReluBackward1]
	140169615525032 -> 140169615524304
	140169615525032 [label=CudnnBatchNormBackward]
	140169615524976 -> 140169615525032
	140169615524976 [label=CudnnConvolutionBackward]
	140169616244184 -> 140169615524976
	140169616244184 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140169616244016 -> 140169615525032
	140169616244016 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140169616244072 -> 140169615525032
	140169616244072 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140169615524696 -> 140169614004176
	140169615524696 [label=CudnnBatchNormBackward]
	140169615524920 -> 140169615524696
	140169615524920 [label=CudnnConvolutionBackward]
	140169615525144 -> 140169615524920
	140169615525144 [label=ReluBackward1]
	140169615525200 -> 140169615525144
	140169615525200 [label=CudnnBatchNormBackward]
	140169615525368 -> 140169615525200
	140169615525368 [label=CudnnConvolutionBackward]
	140169615524304 -> 140169615525368
	140169616253112 -> 140169615525368
	140169616253112 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616244688 -> 140169615525200
	140169616244688 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140169616253000 -> 140169615525200
	140169616253000 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140169616244408 -> 140169615524920
	140169616244408 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616244128 -> 140169615524696
	140169616244128 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140169616244240 -> 140169615524696
	140169616244240 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140169614001208 -> 140169614001824
	140169614001208 [label=CudnnBatchNormBackward]
	140169615524864 -> 140169614001208
	140169615524864 [label=CudnnConvolutionBackward]
	140169615525088 -> 140169615524864
	140169615525088 [label=ReluBackward1]
	140169615525424 -> 140169615525088
	140169615525424 [label=CudnnBatchNormBackward]
	140169615525312 -> 140169615525424
	140169615525312 [label=CudnnConvolutionBackward]
	140169614000928 -> 140169615525312
	140169616253560 -> 140169615525312
	140169616253560 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616253392 -> 140169615525424
	140169616253392 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140169616253448 -> 140169615525424
	140169616253448 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140169616253056 -> 140169615524864
	140169616253056 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616243792 -> 140169614001208
	140169616243792 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140169616244352 -> 140169614001208
	140169616244352 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140169614002440 -> 140169614001656
	140169614002440 [label=CudnnBatchNormBackward]
	140169614001992 -> 140169614002440
	140169614001992 [label=CudnnConvolutionBackward]
	140169615524808 -> 140169614001992
	140169615524808 [label=ReluBackward1]
	140169615525592 -> 140169615524808
	140169615525592 [label=CudnnBatchNormBackward]
	140169615525480 -> 140169615525592
	140169615525480 [label=CudnnConvolutionBackward]
	140169614001152 -> 140169615525480
	140169616254008 -> 140169615525480
	140169616254008 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616253840 -> 140169615525592
	140169616253840 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140169616253896 -> 140169615525592
	140169616253896 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140169616253616 -> 140169614001992
	140169616253616 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616243512 -> 140169614002440
	140169616243512 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140169616244464 -> 140169614002440
	140169616244464 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140169614000872 -> 140169614000480
	140169614000872 [label=CudnnBatchNormBackward]
	140169614001320 -> 140169614000872
	140169614001320 [label=CudnnConvolutionBackward]
	140169614002552 -> 140169614001320
	140169614002552 [label=ReluBackward1]
	140169615525704 -> 140169614002552
	140169615525704 [label=CudnnBatchNormBackward]
	140169615525648 -> 140169615525704
	140169615525648 [label=CudnnConvolutionBackward]
	140169614000760 -> 140169615525648
	140169616254456 -> 140169615525648
	140169616254456 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616254288 -> 140169615525704
	140169616254288 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140169616254344 -> 140169615525704
	140169616254344 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140169616254064 -> 140169614001320
	140169616254064 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616243232 -> 140169614000872
	140169616243232 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140169616253168 -> 140169614000872
	140169616253168 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140169614001432 -> 140169614000256
	140169614001432 [label=CudnnBatchNormBackward]
	140169614001712 -> 140169614001432
	140169614001712 [label=CudnnConvolutionBackward]
	140169614002216 -> 140169614001712
	140169614002216 [label=ReluBackward1]
	140169615525816 -> 140169614002216
	140169615525816 [label=CudnnBatchNormBackward]
	140169615525760 -> 140169615525816
	140169615525760 [label=CudnnConvolutionBackward]
	140169614000816 -> 140169615525760
	140169616254904 -> 140169615525760
	140169616254904 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616254736 -> 140169615525816
	140169616254736 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140169616254792 -> 140169615525816
	140169616254792 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140169616254512 -> 140169614001712
	140169616254512 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140169616242952 -> 140169614001432
	140169616242952 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140169616253336 -> 140169614001432
	140169616253336 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140169616242336 -> 140169614000592
	140169616242336 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140169616242112 -> 140169614000536
	140169616242112 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140169616242168 -> 140169614000536
	140169616242168 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140169616241832 -> 140169614001264
	140169616241832 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616241608 -> 140169614001488
	140169616241608 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140169616241664 -> 140169614001488
	140169616241664 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140169614001096 -> 140169614003000
	140169614001096 [label=CudnnBatchNormBackward]
	140169614000984 -> 140169614001096
	140169614000984 [label=CudnnConvolutionBackward]
	140169614001768 -> 140169614000984
	140169616242392 -> 140169614000984
	140169616242392 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140169616241720 -> 140169614001096
	140169616241720 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140169616241888 -> 140169614001096
	140169616241888 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140169615763104 -> 140169615763664
	140169615763104 [label=CudnnBatchNormBackward]
	140169614000648 -> 140169615763104
	140169614000648 [label=CudnnConvolutionBackward]
	140169614000704 -> 140169614000648
	140169614000704 [label=ReluBackward1]
	140169614000312 -> 140169614000704
	140169614000312 [label=CudnnBatchNormBackward]
	140169614000424 -> 140169614000312
	140169614000424 [label=CudnnConvolutionBackward]
	140169615765456 -> 140169614000424
	140169616255016 -> 140169614000424
	140169616255016 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616254680 -> 140169614000312
	140169616254680 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140169616255072 -> 140169614000312
	140169616255072 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140169616242672 -> 140169614000648
	140169616242672 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616241384 -> 140169615763104
	140169616241384 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140169616242224 -> 140169615763104
	140169616242224 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140169615763832 -> 140169615763888
	140169615763832 [label=CudnnBatchNormBackward]
	140169615763944 -> 140169615763832
	140169615763944 [label=CudnnConvolutionBackward]
	140169614000200 -> 140169615763944
	140169614000200 [label=ReluBackward1]
	140169614001040 -> 140169614000200
	140169614001040 [label=CudnnBatchNormBackward]
	140169614002328 -> 140169614001040
	140169614002328 [label=CudnnConvolutionBackward]
	140169615765008 -> 140169614002328
	140169616255576 -> 140169614002328
	140169616255576 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616255408 -> 140169614001040
	140169616255408 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140169616255464 -> 140169614001040
	140169616255464 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140169616255184 -> 140169615763944
	140169616255184 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616241104 -> 140169615763832
	140169616241104 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140169616242000 -> 140169615763832
	140169616242000 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140169615763440 -> 140169615763272
	140169615763440 [label=CudnnBatchNormBackward]
	140169615764112 -> 140169615763440
	140169615764112 [label=CudnnConvolutionBackward]
	140169615765064 -> 140169615764112
	140169615765064 [label=ReluBackward1]
	140169614000368 -> 140169615765064
	140169614000368 [label=CudnnBatchNormBackward]
	140169615525256 -> 140169614000368
	140169615525256 [label=CudnnConvolutionBackward]
	140169615764784 -> 140169615525256
	140169616256024 -> 140169615525256
	140169616256024 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616255856 -> 140169614000368
	140169616255856 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140169616255912 -> 140169614000368
	140169616255912 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140169616255632 -> 140169615764112
	140169616255632 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616240824 -> 140169615763440
	140169616240824 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140169616253784 -> 140169615763440
	140169616253784 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140169615764448 -> 140169615764280
	140169615764448 [label=CudnnBatchNormBackward]
	140169615765400 -> 140169615764448
	140169615765400 [label=CudnnConvolutionBackward]
	140169615765344 -> 140169615765400
	140169615765344 [label=ReluBackward1]
	140169614001376 -> 140169615765344
	140169614001376 [label=CudnnBatchNormBackward]
	140169615525872 -> 140169614001376
	140169615525872 [label=CudnnConvolutionBackward]
	140169615762712 -> 140169615525872
	140169616256472 -> 140169615525872
	140169616256472 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169616256304 -> 140169614001376
	140169616256304 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140169616256360 -> 140169614001376
	140169616256360 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140169616256080 -> 140169615765400
	140169616256080 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140169641754464 -> 140169615764448
	140169641754464 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140169616254848 -> 140169615764448
	140169616254848 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140169641753848 -> 140169615764336
	140169641753848 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140169641753624 -> 140169615763216
	140169641753624 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140169641753680 -> 140169615763216
	140169641753680 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140169641753344 -> 140169615762936
	140169641753344 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169641753120 -> 140169615763328
	140169641753120 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140169641753176 -> 140169615763328
	140169641753176 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140169615763720 -> 140169615762600
	140169615763720 [label=CudnnBatchNormBackward]
	140169615763048 -> 140169615763720
	140169615763048 [label=CudnnConvolutionBackward]
	140169615763608 -> 140169615763048
	140169641753904 -> 140169615763048
	140169641753904 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140169641753232 -> 140169615763720
	140169641753232 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140169641753400 -> 140169615763720
	140169641753400 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140169615762992 -> 140169615761816
	140169615762992 [label=CudnnBatchNormBackward]
	140169615764952 -> 140169615762992
	140169615764952 [label=CudnnConvolutionBackward]
	140169615764840 -> 140169615764952
	140169615764840 [label=ReluBackward1]
	140169615764728 -> 140169615764840
	140169615764728 [label=CudnnBatchNormBackward]
	140169615764504 -> 140169615764728
	140169615764504 [label=CudnnConvolutionBackward]
	140169615765176 -> 140169615764504
	140169616256584 -> 140169615764504
	140169616256584 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169616256248 -> 140169615764728
	140169616256248 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140169616256640 -> 140169615764728
	140169616256640 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140169641754184 -> 140169615764952
	140169641754184 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169641752896 -> 140169615762992
	140169641752896 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140169641753736 -> 140169615762992
	140169641753736 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140169615762544 -> 140169615763384
	140169615762544 [label=CudnnBatchNormBackward]
	140169614002720 -> 140169615762544
	140169614002720 [label=CudnnConvolutionBackward]
	140169615762824 -> 140169614002720
	140169615762824 [label=ReluBackward1]
	140169615764168 -> 140169615762824
	140169615764168 [label=CudnnBatchNormBackward]
	140169615762264 -> 140169615764168
	140169615762264 [label=CudnnConvolutionBackward]
	140169615763552 -> 140169615762264
	140169615761592 -> 140169615762264
	140169615761592 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169616256976 -> 140169615764168
	140169616256976 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140169615761480 -> 140169615764168
	140169615761480 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140169616256752 -> 140169614002720
	140169616256752 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169641752616 -> 140169615762544
	140169641752616 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140169641753512 -> 140169615762544
	140169641753512 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140169615762768 -> 140169644467256
	140169615762768 [label=CudnnBatchNormBackward]
	140169615762880 -> 140169615762768
	140169615762880 [label=CudnnConvolutionBackward]
	140169615765232 -> 140169615762880
	140169615765232 [label=ReluBackward1]
	140169615764896 -> 140169615765232
	140169615764896 [label=CudnnBatchNormBackward]
	140169615764056 -> 140169615764896
	140169615764056 [label=CudnnConvolutionBackward]
	140169615761648 -> 140169615764056
	140169615762040 -> 140169615764056
	140169615762040 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169615761872 -> 140169615764896
	140169615761872 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140169615761928 -> 140169615764896
	140169615761928 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140169615761536 -> 140169615762880
	140169615761536 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169641752336 -> 140169615762768
	140169641752336 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140169616255352 -> 140169615762768
	140169616255352 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140169644469048 -> 140169644470112
	140169644469048 [label=CudnnBatchNormBackward]
	140169615764000 -> 140169644469048
	140169615764000 [label=CudnnConvolutionBackward]
	140169615763496 -> 140169615764000
	140169615763496 [label=ReluBackward1]
	140169615764560 -> 140169615763496
	140169615764560 [label=CudnnBatchNormBackward]
	140169615525984 -> 140169615764560
	140169615525984 [label=CudnnConvolutionBackward]
	140169644466920 -> 140169615525984
	140169615762488 -> 140169615525984
	140169615762488 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169615762320 -> 140169615764560
	140169615762320 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140169615762376 -> 140169615764560
	140169615762376 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140169615762096 -> 140169615764000
	140169615762096 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140169641752056 -> 140169644469048
	140169641752056 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140169616256416 -> 140169644469048
	140169616256416 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140169644466248 -> 140169644417880
	140169644466248 [label=TBackward]
	140169641751216 -> 140169644466248
	140169641751216 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
