digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140116520210216 [label=AddmmBackward fillcolor=darkolivegreen1]
	140116641211336 -> 140116520210216
	140116641211336 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140116521215200 -> 140116520210216
	140116521215200 [label=ViewBackward]
	140116475400936 -> 140116521215200
	140116475400936 [label=ViewBackward]
	140116475400712 -> 140116475400936
	140116475400712 [label=MeanBackward1]
	140116475401272 -> 140116475400712
	140116475401272 [label=ViewBackward]
	140116475401496 -> 140116475401272
	140116475401496 [label=ReluBackward1]
	140116475401608 -> 140116475401496
	140116475401608 [label=AddBackward0]
	140116475401720 -> 140116475401608
	140116475401720 [label=ReluBackward1]
	140116475401888 -> 140116475401720
	140116475401888 [label=AddBackward0]
	140116475402000 -> 140116475401888
	140116475402000 [label=ReluBackward1]
	140116475402168 -> 140116475402000
	140116475402168 [label=AddBackward0]
	140116475402280 -> 140116475402168
	140116475402280 [label=ReluBackward1]
	140116475402448 -> 140116475402280
	140116475402448 [label=AddBackward0]
	140116475402560 -> 140116475402448
	140116475402560 [label=ReluBackward1]
	140116475402728 -> 140116475402560
	140116475402728 [label=AddBackward0]
	140116475402840 -> 140116475402728
	140116475402840 [label=ReluBackward1]
	140116475403008 -> 140116475402840
	140116475403008 [label=CudnnBatchNormBackward]
	140116475403120 -> 140116475403008
	140116475403120 [label=CudnnConvolutionBackward]
	140116475403232 -> 140116475403120
	140116475403232 [label=ReluBackward1]
	140116475403344 -> 140116475403232
	140116475403344 [label=CudnnBatchNormBackward]
	140116475403456 -> 140116475403344
	140116475403456 [label=CudnnConvolutionBackward]
	140116475403568 -> 140116475403456
	140116475403568 [label=ReluBackward1]
	140116475403680 -> 140116475403568
	140116475403680 [label=AddBackward0]
	140116475403792 -> 140116475403680
	140116475403792 [label=ReluBackward1]
	140116475403960 -> 140116475403792
	140116475403960 [label=AddBackward0]
	140116475404072 -> 140116475403960
	140116475404072 [label=ReluBackward1]
	140116475404240 -> 140116475404072
	140116475404240 [label=AddBackward0]
	140116475900032 -> 140116475404240
	140116475900032 [label=ReluBackward1]
	140116475900200 -> 140116475900032
	140116475900200 [label=AddBackward0]
	140116475900312 -> 140116475900200
	140116475900312 [label=ReluBackward1]
	140116475900480 -> 140116475900312
	140116475900480 [label=AddBackward0]
	140116475900592 -> 140116475900480
	140116475900592 [label=ReluBackward1]
	140116475900760 -> 140116475900592
	140116475900760 [label=CudnnBatchNormBackward]
	140116475900872 -> 140116475900760
	140116475900872 [label=CudnnConvolutionBackward]
	140116475900984 -> 140116475900872
	140116475900984 [label=ReluBackward1]
	140116475901096 -> 140116475900984
	140116475901096 [label=CudnnBatchNormBackward]
	140116475901208 -> 140116475901096
	140116475901208 [label=CudnnConvolutionBackward]
	140116475901320 -> 140116475901208
	140116475901320 [label=ReluBackward1]
	140116475901432 -> 140116475901320
	140116475901432 [label=AddBackward0]
	140116475901544 -> 140116475901432
	140116475901544 [label=ReluBackward1]
	140116475901712 -> 140116475901544
	140116475901712 [label=AddBackward0]
	140116475901824 -> 140116475901712
	140116475901824 [label=ReluBackward1]
	140116475901992 -> 140116475901824
	140116475901992 [label=AddBackward0]
	140116475902104 -> 140116475901992
	140116475902104 [label=ReluBackward1]
	140116475902272 -> 140116475902104
	140116475902272 [label=AddBackward0]
	140116475902384 -> 140116475902272
	140116475902384 [label=ReluBackward1]
	140116475902552 -> 140116475902384
	140116475902552 [label=AddBackward0]
	140116475902664 -> 140116475902552
	140116475902664 [label=ReluBackward1]
	140116475902832 -> 140116475902664
	140116475902832 [label=CudnnBatchNormBackward]
	140116475902944 -> 140116475902832
	140116475902944 [label=CudnnConvolutionBackward]
	140116465847768 -> 140116475902944
	140116465847768 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140116465847600 -> 140116475902832
	140116465847600 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140116465847656 -> 140116475902832
	140116465847656 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140116475902720 -> 140116475902552
	140116475902720 [label=CudnnBatchNormBackward]
	140116475902888 -> 140116475902720
	140116475902888 [label=CudnnConvolutionBackward]
	140116475903056 -> 140116475902888
	140116475903056 [label=ReluBackward1]
	140116475903112 -> 140116475903056
	140116475903112 [label=CudnnBatchNormBackward]
	140116475903280 -> 140116475903112
	140116475903280 [label=CudnnConvolutionBackward]
	140116475902664 -> 140116475903280
	140116465336504 -> 140116475903280
	140116465336504 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465848272 -> 140116475903112
	140116465848272 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140116465336392 -> 140116475903112
	140116465336392 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140116465847992 -> 140116475902888
	140116465847992 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465847712 -> 140116475902720
	140116465847712 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140116465847824 -> 140116475902720
	140116465847824 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140116475902440 -> 140116475902272
	140116475902440 [label=CudnnBatchNormBackward]
	140116475902608 -> 140116475902440
	140116475902608 [label=CudnnConvolutionBackward]
	140116475903000 -> 140116475902608
	140116475903000 [label=ReluBackward1]
	140116475903336 -> 140116475903000
	140116475903336 [label=CudnnBatchNormBackward]
	140116475903224 -> 140116475903336
	140116475903224 [label=CudnnConvolutionBackward]
	140116475902384 -> 140116475903224
	140116465336952 -> 140116475903224
	140116465336952 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465336784 -> 140116475903336
	140116465336784 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140116465336840 -> 140116475903336
	140116465336840 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140116465336448 -> 140116475902608
	140116465336448 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465847376 -> 140116475902440
	140116465847376 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140116465847936 -> 140116475902440
	140116465847936 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140116475902160 -> 140116475901992
	140116475902160 [label=CudnnBatchNormBackward]
	140116475902328 -> 140116475902160
	140116475902328 [label=CudnnConvolutionBackward]
	140116475902776 -> 140116475902328
	140116475902776 [label=ReluBackward1]
	140116475903504 -> 140116475902776
	140116475903504 [label=CudnnBatchNormBackward]
	140116475903392 -> 140116475903504
	140116475903392 [label=CudnnConvolutionBackward]
	140116475902104 -> 140116475903392
	140116465337400 -> 140116475903392
	140116465337400 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465337232 -> 140116475903504
	140116465337232 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140116465337288 -> 140116475903504
	140116465337288 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140116465337008 -> 140116475902328
	140116465337008 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465847096 -> 140116475902160
	140116465847096 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140116465848048 -> 140116475902160
	140116465848048 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140116475901880 -> 140116475901712
	140116475901880 [label=CudnnBatchNormBackward]
	140116475902048 -> 140116475901880
	140116475902048 [label=CudnnConvolutionBackward]
	140116475902496 -> 140116475902048
	140116475902496 [label=ReluBackward1]
	140116475903616 -> 140116475902496
	140116475903616 [label=CudnnBatchNormBackward]
	140116475903560 -> 140116475903616
	140116475903560 [label=CudnnConvolutionBackward]
	140116475901824 -> 140116475903560
	140116465337848 -> 140116475903560
	140116465337848 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465337680 -> 140116475903616
	140116465337680 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140116465337736 -> 140116475903616
	140116465337736 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140116465337456 -> 140116475902048
	140116465337456 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465846816 -> 140116475901880
	140116465846816 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140116465336560 -> 140116475901880
	140116465336560 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140116475901600 -> 140116475901432
	140116475901600 [label=CudnnBatchNormBackward]
	140116475901768 -> 140116475901600
	140116475901768 [label=CudnnConvolutionBackward]
	140116475902216 -> 140116475901768
	140116475902216 [label=ReluBackward1]
	140116475903728 -> 140116475902216
	140116475903728 [label=CudnnBatchNormBackward]
	140116475903672 -> 140116475903728
	140116475903672 [label=CudnnConvolutionBackward]
	140116475901544 -> 140116475903672
	140116465338296 -> 140116475903672
	140116465338296 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465338128 -> 140116475903728
	140116465338128 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140116465338184 -> 140116475903728
	140116465338184 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140116465337904 -> 140116475901768
	140116465337904 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140116465846536 -> 140116475901600
	140116465846536 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140116465336728 -> 140116475901600
	140116465336728 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140116465845920 -> 140116475901208
	140116465845920 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140116465845696 -> 140116475901096
	140116465845696 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140116465845752 -> 140116475901096
	140116465845752 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140116465845416 -> 140116475900872
	140116465845416 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465845192 -> 140116475900760
	140116465845192 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140116465845248 -> 140116475900760
	140116465845248 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140116475900648 -> 140116475900480
	140116475900648 [label=CudnnBatchNormBackward]
	140116475900816 -> 140116475900648
	140116475900816 [label=CudnnConvolutionBackward]
	140116475901320 -> 140116475900816
	140116465845976 -> 140116475900816
	140116465845976 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140116465845304 -> 140116475900648
	140116465845304 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140116465845472 -> 140116475900648
	140116465845472 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140116475900368 -> 140116475900200
	140116475900368 [label=CudnnBatchNormBackward]
	140116475900536 -> 140116475900368
	140116475900536 [label=CudnnConvolutionBackward]
	140116475900928 -> 140116475900536
	140116475900928 [label=ReluBackward1]
	140116475901376 -> 140116475900928
	140116475901376 [label=CudnnBatchNormBackward]
	140116475901264 -> 140116475901376
	140116475901264 [label=CudnnConvolutionBackward]
	140116475900312 -> 140116475901264
	140116465338408 -> 140116475901264
	140116465338408 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465338072 -> 140116475901376
	140116465338072 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140116465338464 -> 140116475901376
	140116465338464 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140116465846256 -> 140116475900536
	140116465846256 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465844968 -> 140116475900368
	140116465844968 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140116465845808 -> 140116475900368
	140116465845808 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140116475900088 -> 140116475404240
	140116475900088 [label=CudnnBatchNormBackward]
	140116475900256 -> 140116475900088
	140116475900256 [label=CudnnConvolutionBackward]
	140116475900704 -> 140116475900256
	140116475900704 [label=ReluBackward1]
	140116475901656 -> 140116475900704
	140116475901656 [label=CudnnBatchNormBackward]
	140116475901152 -> 140116475901656
	140116475901152 [label=CudnnConvolutionBackward]
	140116475900032 -> 140116475901152
	140116465338968 -> 140116475901152
	140116465338968 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465338800 -> 140116475901656
	140116465338800 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140116465338856 -> 140116475901656
	140116465338856 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140116465338576 -> 140116475900256
	140116465338576 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465844688 -> 140116475900088
	140116465844688 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140116465845584 -> 140116475900088
	140116465845584 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140116475404128 -> 140116475403960
	140116475404128 [label=CudnnBatchNormBackward]
	140116475899976 -> 140116475404128
	140116475899976 [label=CudnnConvolutionBackward]
	140116475900424 -> 140116475899976
	140116475900424 [label=ReluBackward1]
	140116475903168 -> 140116475900424
	140116475903168 [label=CudnnBatchNormBackward]
	140116475901936 -> 140116475903168
	140116475901936 [label=CudnnConvolutionBackward]
	140116475404072 -> 140116475901936
	140116465339416 -> 140116475901936
	140116465339416 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465339248 -> 140116475903168
	140116465339248 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140116465339304 -> 140116475903168
	140116465339304 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140116465339024 -> 140116475899976
	140116465339024 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465844408 -> 140116475404128
	140116465844408 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140116465337176 -> 140116475404128
	140116465337176 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140116475403848 -> 140116475403680
	140116475403848 [label=CudnnBatchNormBackward]
	140116475404016 -> 140116475403848
	140116475404016 [label=CudnnConvolutionBackward]
	140116475900144 -> 140116475404016
	140116475900144 [label=ReluBackward1]
	140116475903896 -> 140116475900144
	140116475903896 [label=CudnnBatchNormBackward]
	140116475903840 -> 140116475903896
	140116475903840 [label=CudnnConvolutionBackward]
	140116475403792 -> 140116475903840
	140116465339864 -> 140116475903840
	140116465339864 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116465339696 -> 140116475903896
	140116465339696 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140116465339752 -> 140116475903896
	140116465339752 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140116465339472 -> 140116475404016
	140116465339472 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140116521217888 -> 140116475403848
	140116521217888 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140116465338240 -> 140116475403848
	140116465338240 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140116521217272 -> 140116475403456
	140116521217272 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140116521217048 -> 140116475403344
	140116521217048 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140116521217104 -> 140116475403344
	140116521217104 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140116521216768 -> 140116475403120
	140116521216768 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116521216544 -> 140116475403008
	140116521216544 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140116521216600 -> 140116475403008
	140116521216600 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140116475402896 -> 140116475402728
	140116475402896 [label=CudnnBatchNormBackward]
	140116475403064 -> 140116475402896
	140116475403064 [label=CudnnConvolutionBackward]
	140116475403568 -> 140116475403064
	140116521217328 -> 140116475403064
	140116521217328 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140116521216656 -> 140116475402896
	140116521216656 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140116521216824 -> 140116475402896
	140116521216824 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140116475402616 -> 140116475402448
	140116475402616 [label=CudnnBatchNormBackward]
	140116475402784 -> 140116475402616
	140116475402784 [label=CudnnConvolutionBackward]
	140116475403176 -> 140116475402784
	140116475403176 [label=ReluBackward1]
	140116475403624 -> 140116475403176
	140116475403624 [label=CudnnBatchNormBackward]
	140116475403512 -> 140116475403624
	140116475403512 [label=CudnnConvolutionBackward]
	140116475402560 -> 140116475403512
	140116465339976 -> 140116475403512
	140116465339976 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116465339640 -> 140116475403624
	140116465339640 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140116465340032 -> 140116475403624
	140116465340032 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140116521217608 -> 140116475402784
	140116521217608 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116521216320 -> 140116475402616
	140116521216320 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140116521217160 -> 140116475402616
	140116521217160 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140116475402336 -> 140116475402168
	140116475402336 [label=CudnnBatchNormBackward]
	140116475402504 -> 140116475402336
	140116475402504 [label=CudnnConvolutionBackward]
	140116475402952 -> 140116475402504
	140116475402952 [label=ReluBackward1]
	140116475403904 -> 140116475402952
	140116475403904 [label=CudnnBatchNormBackward]
	140116475403400 -> 140116475403904
	140116475403400 [label=CudnnConvolutionBackward]
	140116475402280 -> 140116475403400
	140116465369272 -> 140116475403400
	140116465369272 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116465340368 -> 140116475403904
	140116465340368 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140116465369160 -> 140116475403904
	140116465369160 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140116465340144 -> 140116475402504
	140116465340144 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116521216040 -> 140116475402336
	140116521216040 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140116521216936 -> 140116475402336
	140116521216936 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140116475402056 -> 140116475401888
	140116475402056 [label=CudnnBatchNormBackward]
	140116475402224 -> 140116475402056
	140116475402224 [label=CudnnConvolutionBackward]
	140116475402672 -> 140116475402224
	140116475402672 [label=ReluBackward1]
	140116475403736 -> 140116475402672
	140116475403736 [label=CudnnBatchNormBackward]
	140116475901040 -> 140116475403736
	140116475901040 [label=CudnnConvolutionBackward]
	140116475402000 -> 140116475901040
	140116465369720 -> 140116475901040
	140116465369720 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116465369552 -> 140116475403736
	140116465369552 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140116465369608 -> 140116475403736
	140116465369608 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140116465369216 -> 140116475402224
	140116465369216 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116521215760 -> 140116475402056
	140116521215760 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140116465338744 -> 140116475402056
	140116465338744 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140116475401776 -> 140116475401608
	140116475401776 [label=CudnnBatchNormBackward]
	140116475401944 -> 140116475401776
	140116475401944 [label=CudnnConvolutionBackward]
	140116475402392 -> 140116475401944
	140116475402392 [label=ReluBackward1]
	140116475404184 -> 140116475402392
	140116475404184 [label=CudnnBatchNormBackward]
	140116475903784 -> 140116475404184
	140116475903784 [label=CudnnConvolutionBackward]
	140116475401720 -> 140116475903784
	140116465370168 -> 140116475903784
	140116465370168 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116465370000 -> 140116475404184
	140116465370000 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140116465370056 -> 140116475404184
	140116465370056 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140116465369776 -> 140116475401944
	140116465369776 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140116521215480 -> 140116475401776
	140116521215480 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140116465339808 -> 140116475401776
	140116465339808 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140116521214808 -> 140116520210216
	140116521214808 [label=TBackward]
	140116521214696 -> 140116521214808
	140116521214696 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
