digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140586980406048 [label=AddmmBackward fillcolor=darkolivegreen1]
	140586857517912 -> 140586980406048
	140586857517912 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140586857517800 -> 140586980406048
	140586857517800 [label=ViewBackward]
	140586857518080 -> 140586857517800
	140586857518080 [label=ViewBackward]
	140586857518248 -> 140586857518080
	140586857518248 [label=MeanBackward1]
	140586857518136 -> 140586857518248
	140586857518136 [label=ViewBackward]
	140586857518360 -> 140586857518136
	140586857518360 [label=ReluBackward1]
	140586857518472 -> 140586857518360
	140586857518472 [label=AddBackward0]
	140586857518584 -> 140586857518472
	140586857518584 [label=ReluBackward1]
	140586857518752 -> 140586857518584
	140586857518752 [label=AddBackward0]
	140586857518864 -> 140586857518752
	140586857518864 [label=ReluBackward1]
	140586857519032 -> 140586857518864
	140586857519032 [label=AddBackward0]
	140586857519144 -> 140586857519032
	140586857519144 [label=ReluBackward1]
	140586857519312 -> 140586857519144
	140586857519312 [label=AddBackward0]
	140586857519424 -> 140586857519312
	140586857519424 [label=ReluBackward1]
	140586857519592 -> 140586857519424
	140586857519592 [label=AddBackward0]
	140586857519704 -> 140586857519592
	140586857519704 [label=ReluBackward1]
	140586857519872 -> 140586857519704
	140586857519872 [label=CudnnBatchNormBackward]
	140586857519984 -> 140586857519872
	140586857519984 [label=CudnnConvolutionBackward]
	140586857520208 -> 140586857519984
	140586857520208 [label=ReluBackward1]
	140586857520376 -> 140586857520208
	140586857520376 [label=CudnnBatchNormBackward]
	140586857520488 -> 140586857520376
	140586857520488 [label=CudnnConvolutionBackward]
	140586857520712 -> 140586857520488
	140586857520712 [label=ReluBackward1]
	140586857520880 -> 140586857520712
	140586857520880 [label=AddBackward0]
	140586857520992 -> 140586857520880
	140586857520992 [label=ReluBackward1]
	140586830192712 -> 140586857520992
	140586830192712 [label=AddBackward0]
	140586830192824 -> 140586830192712
	140586830192824 [label=ReluBackward1]
	140586830192992 -> 140586830192824
	140586830192992 [label=AddBackward0]
	140586830193104 -> 140586830192992
	140586830193104 [label=ReluBackward1]
	140586830193272 -> 140586830193104
	140586830193272 [label=AddBackward0]
	140586830193384 -> 140586830193272
	140586830193384 [label=ReluBackward1]
	140586830193552 -> 140586830193384
	140586830193552 [label=AddBackward0]
	140586830193664 -> 140586830193552
	140586830193664 [label=ReluBackward1]
	140586830193832 -> 140586830193664
	140586830193832 [label=CudnnBatchNormBackward]
	140586830193944 -> 140586830193832
	140586830193944 [label=CudnnConvolutionBackward]
	140586830194168 -> 140586830193944
	140586830194168 [label=ReluBackward1]
	140586830194336 -> 140586830194168
	140586830194336 [label=CudnnBatchNormBackward]
	140586830194448 -> 140586830194336
	140586830194448 [label=CudnnConvolutionBackward]
	140586830194672 -> 140586830194448
	140586830194672 [label=ReluBackward1]
	140586830194840 -> 140586830194672
	140586830194840 [label=AddBackward0]
	140586830194952 -> 140586830194840
	140586830194952 [label=ReluBackward1]
	140586830195120 -> 140586830194952
	140586830195120 [label=AddBackward0]
	140586830195232 -> 140586830195120
	140586830195232 [label=ReluBackward1]
	140586830195400 -> 140586830195232
	140586830195400 [label=AddBackward0]
	140586830195512 -> 140586830195400
	140586830195512 [label=ReluBackward1]
	140586830195680 -> 140586830195512
	140586830195680 [label=AddBackward0]
	140586830195792 -> 140586830195680
	140586830195792 [label=ReluBackward1]
	140586830195960 -> 140586830195792
	140586830195960 [label=AddBackward0]
	140586830196072 -> 140586830195960
	140586830196072 [label=ReluBackward1]
	140586830196240 -> 140586830196072
	140586830196240 [label=CudnnBatchNormBackward]
	140586830196352 -> 140586830196240
	140586830196352 [label=CudnnConvolutionBackward]
	140586830196576 -> 140586830196352
	140586830196576 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140586830196408 -> 140586830196240
	140586830196408 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140586830196464 -> 140586830196240
	140586830196464 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140586830196128 -> 140586830195960
	140586830196128 [label=CudnnBatchNormBackward]
	140586830196296 -> 140586830196128
	140586830196296 [label=CudnnConvolutionBackward]
	140586830205000 -> 140586830196296
	140586830205000 [label=ReluBackward1]
	140586830205168 -> 140586830205000
	140586830205168 [label=CudnnBatchNormBackward]
	140586830205280 -> 140586830205168
	140586830205280 [label=CudnnConvolutionBackward]
	140586830196072 -> 140586830205280
	140586830205504 -> 140586830205280
	140586830205504 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830205336 -> 140586830205168
	140586830205336 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140586830205392 -> 140586830205168
	140586830205392 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140586830205056 -> 140586830196296
	140586830205056 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830196520 -> 140586830196128
	140586830196520 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140586830196632 -> 140586830196128
	140586830196632 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140586830195848 -> 140586830195680
	140586830195848 [label=CudnnBatchNormBackward]
	140586830196016 -> 140586830195848
	140586830196016 [label=CudnnConvolutionBackward]
	140586830205448 -> 140586830196016
	140586830205448 [label=ReluBackward1]
	140586830205672 -> 140586830205448
	140586830205672 [label=CudnnBatchNormBackward]
	140586830205616 -> 140586830205672
	140586830205616 [label=CudnnConvolutionBackward]
	140586830195792 -> 140586830205616
	140586830205952 -> 140586830205616
	140586830205952 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830205784 -> 140586830205672
	140586830205784 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140586830205840 -> 140586830205672
	140586830205840 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140586830205560 -> 140586830196016
	140586830205560 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830196184 -> 140586830195848
	140586830196184 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140586830196688 -> 140586830195848
	140586830196688 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140586830195568 -> 140586830195400
	140586830195568 [label=CudnnBatchNormBackward]
	140586830195736 -> 140586830195568
	140586830195736 [label=CudnnConvolutionBackward]
	140586830205896 -> 140586830195736
	140586830205896 [label=ReluBackward1]
	140586830206120 -> 140586830205896
	140586830206120 [label=CudnnBatchNormBackward]
	140586830206064 -> 140586830206120
	140586830206064 [label=CudnnConvolutionBackward]
	140586830195512 -> 140586830206064
	140586830206400 -> 140586830206064
	140586830206400 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830206232 -> 140586830206120
	140586830206232 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140586830206288 -> 140586830206120
	140586830206288 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140586830206008 -> 140586830195736
	140586830206008 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830195904 -> 140586830195568
	140586830195904 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140586830205112 -> 140586830195568
	140586830205112 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140586830195288 -> 140586830195120
	140586830195288 [label=CudnnBatchNormBackward]
	140586830195456 -> 140586830195288
	140586830195456 [label=CudnnConvolutionBackward]
	140586830206344 -> 140586830195456
	140586830206344 [label=ReluBackward1]
	140586830206568 -> 140586830206344
	140586830206568 [label=CudnnBatchNormBackward]
	140586830206512 -> 140586830206568
	140586830206512 [label=CudnnConvolutionBackward]
	140586830195232 -> 140586830206512
	140586830206848 -> 140586830206512
	140586830206848 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830206680 -> 140586830206568
	140586830206680 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140586830206736 -> 140586830206568
	140586830206736 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140586830206456 -> 140586830195456
	140586830206456 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830195624 -> 140586830195288
	140586830195624 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140586830205224 -> 140586830195288
	140586830205224 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140586830195008 -> 140586830194840
	140586830195008 [label=CudnnBatchNormBackward]
	140586830195176 -> 140586830195008
	140586830195176 [label=CudnnConvolutionBackward]
	140586830206792 -> 140586830195176
	140586830206792 [label=ReluBackward1]
	140586830207016 -> 140586830206792
	140586830207016 [label=CudnnBatchNormBackward]
	140586830206960 -> 140586830207016
	140586830206960 [label=CudnnConvolutionBackward]
	140586830194952 -> 140586830206960
	140586830207296 -> 140586830206960
	140586830207296 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830207128 -> 140586830207016
	140586830207128 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140586830207184 -> 140586830207016
	140586830207184 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140586830206904 -> 140586830195176
	140586830206904 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140586830195344 -> 140586830195008
	140586830195344 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140586830205728 -> 140586830195008
	140586830205728 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140586830194728 -> 140586830194448
	140586830194728 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140586830194504 -> 140586830194336
	140586830194504 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140586830194560 -> 140586830194336
	140586830194560 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140586830194224 -> 140586830193944
	140586830194224 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830194000 -> 140586830193832
	140586830194000 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140586830194056 -> 140586830193832
	140586830194056 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140586830193720 -> 140586830193552
	140586830193720 [label=CudnnBatchNormBackward]
	140586830193888 -> 140586830193720
	140586830193888 [label=CudnnConvolutionBackward]
	140586830194672 -> 140586830193888
	140586830194784 -> 140586830193888
	140586830194784 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140586830194112 -> 140586830193720
	140586830194112 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140586830194280 -> 140586830193720
	140586830194280 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140586830193440 -> 140586830193272
	140586830193440 [label=CudnnBatchNormBackward]
	140586830193608 -> 140586830193440
	140586830193608 [label=CudnnConvolutionBackward]
	140586830194896 -> 140586830193608
	140586830194896 [label=ReluBackward1]
	140586830206624 -> 140586830194896
	140586830206624 [label=CudnnBatchNormBackward]
	140586830207352 -> 140586830206624
	140586830207352 [label=CudnnConvolutionBackward]
	140586830193384 -> 140586830207352
	140586830207408 -> 140586830207352
	140586830207408 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830207072 -> 140586830206624
	140586830207072 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140586830207464 -> 140586830206624
	140586830207464 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140586830195064 -> 140586830193608
	140586830195064 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830193776 -> 140586830193440
	140586830193776 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140586830194616 -> 140586830193440
	140586830194616 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140586830193160 -> 140586830192992
	140586830193160 [label=CudnnBatchNormBackward]
	140586830193328 -> 140586830193160
	140586830193328 [label=CudnnConvolutionBackward]
	140586830207520 -> 140586830193328
	140586830207520 [label=ReluBackward1]
	140586830207688 -> 140586830207520
	140586830207688 [label=CudnnBatchNormBackward]
	140586830207632 -> 140586830207688
	140586830207632 [label=CudnnConvolutionBackward]
	140586830193104 -> 140586830207632
	140586830207968 -> 140586830207632
	140586830207968 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830207800 -> 140586830207688
	140586830207800 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140586830207856 -> 140586830207688
	140586830207856 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140586830207576 -> 140586830193328
	140586830207576 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830193496 -> 140586830193160
	140586830193496 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140586830194392 -> 140586830193160
	140586830194392 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140586830192880 -> 140586830192712
	140586830192880 [label=CudnnBatchNormBackward]
	140586830193048 -> 140586830192880
	140586830193048 [label=CudnnConvolutionBackward]
	140586830207912 -> 140586830193048
	140586830207912 [label=ReluBackward1]
	140586830208136 -> 140586830207912
	140586830208136 [label=CudnnBatchNormBackward]
	140586830208080 -> 140586830208136
	140586830208080 [label=CudnnConvolutionBackward]
	140586830192824 -> 140586830208080
	140586830208416 -> 140586830208080
	140586830208416 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830208248 -> 140586830208136
	140586830208248 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140586830208304 -> 140586830208136
	140586830208304 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140586830208024 -> 140586830193048
	140586830208024 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830193216 -> 140586830192880
	140586830193216 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140586830206176 -> 140586830192880
	140586830206176 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140586857521048 -> 140586857520880
	140586857521048 [label=CudnnBatchNormBackward]
	140586830192768 -> 140586857521048
	140586830192768 [label=CudnnConvolutionBackward]
	140586830208360 -> 140586830192768
	140586830208360 [label=ReluBackward1]
	140586830208584 -> 140586830208360
	140586830208584 [label=CudnnBatchNormBackward]
	140586830208528 -> 140586830208584
	140586830208528 [label=CudnnConvolutionBackward]
	140586857520992 -> 140586830208528
	140586830208864 -> 140586830208528
	140586830208864 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830208696 -> 140586830208584
	140586830208696 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140586830208752 -> 140586830208584
	140586830208752 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140586830208472 -> 140586830192768
	140586830208472 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140586830192936 -> 140586857521048
	140586830192936 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140586830207240 -> 140586857521048
	140586830207240 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140586857520768 -> 140586857520488
	140586857520768 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140586857520544 -> 140586857520376
	140586857520544 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140586857520600 -> 140586857520376
	140586857520600 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140586857520264 -> 140586857519984
	140586857520264 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586857520040 -> 140586857519872
	140586857520040 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140586857520096 -> 140586857519872
	140586857520096 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140586857519760 -> 140586857519592
	140586857519760 [label=CudnnBatchNormBackward]
	140586857519928 -> 140586857519760
	140586857519928 [label=CudnnConvolutionBackward]
	140586857520712 -> 140586857519928
	140586857520824 -> 140586857519928
	140586857520824 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140586857520152 -> 140586857519760
	140586857520152 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140586857520320 -> 140586857519760
	140586857520320 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140586857519480 -> 140586857519312
	140586857519480 [label=CudnnBatchNormBackward]
	140586857519648 -> 140586857519480
	140586857519648 [label=CudnnConvolutionBackward]
	140586857520936 -> 140586857519648
	140586857520936 [label=ReluBackward1]
	140586830208192 -> 140586857520936
	140586830208192 [label=CudnnBatchNormBackward]
	140586830208920 -> 140586830208192
	140586830208920 [label=CudnnConvolutionBackward]
	140586857519424 -> 140586830208920
	140586829713536 -> 140586830208920
	140586829713536 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586830208640 -> 140586830208192
	140586830208640 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140586830208976 -> 140586830208192
	140586830208976 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140586857521104 -> 140586857519648
	140586857521104 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586857519816 -> 140586857519480
	140586857519816 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140586857520656 -> 140586857519480
	140586857520656 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140586857519200 -> 140586857519032
	140586857519200 [label=CudnnBatchNormBackward]
	140586857519368 -> 140586857519200
	140586857519368 [label=CudnnConvolutionBackward]
	140586830208808 -> 140586857519368
	140586830208808 [label=ReluBackward1]
	140586829713704 -> 140586830208808
	140586829713704 [label=CudnnBatchNormBackward]
	140586829713648 -> 140586829713704
	140586829713648 [label=CudnnConvolutionBackward]
	140586857519144 -> 140586829713648
	140586829713984 -> 140586829713648
	140586829713984 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586829713816 -> 140586829713704
	140586829713816 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140586829713872 -> 140586829713704
	140586829713872 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140586829713480 -> 140586857519368
	140586829713480 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586857519536 -> 140586857519200
	140586857519536 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140586857520432 -> 140586857519200
	140586857520432 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140586857518920 -> 140586857518752
	140586857518920 [label=CudnnBatchNormBackward]
	140586857519088 -> 140586857518920
	140586857519088 [label=CudnnConvolutionBackward]
	140586829713928 -> 140586857519088
	140586829713928 [label=ReluBackward1]
	140586829714152 -> 140586829713928
	140586829714152 [label=CudnnBatchNormBackward]
	140586829714096 -> 140586829714152
	140586829714096 [label=CudnnConvolutionBackward]
	140586857518864 -> 140586829714096
	140586829714432 -> 140586829714096
	140586829714432 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586829714264 -> 140586829714152
	140586829714264 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140586829714320 -> 140586829714152
	140586829714320 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140586829714040 -> 140586857519088
	140586829714040 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586857519256 -> 140586857518920
	140586857519256 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140586830207744 -> 140586857518920
	140586830207744 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140586857518640 -> 140586857518472
	140586857518640 [label=CudnnBatchNormBackward]
	140586857518808 -> 140586857518640
	140586857518808 [label=CudnnConvolutionBackward]
	140586829714376 -> 140586857518808
	140586829714376 [label=ReluBackward1]
	140586829714600 -> 140586829714376
	140586829714600 [label=CudnnBatchNormBackward]
	140586829714544 -> 140586829714600
	140586829714544 [label=CudnnConvolutionBackward]
	140586857518584 -> 140586829714544
	140586829714880 -> 140586829714544
	140586829714880 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586829714712 -> 140586829714600
	140586829714712 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140586829714768 -> 140586829714600
	140586829714768 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140586829714488 -> 140586857518808
	140586829714488 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140586857518976 -> 140586857518640
	140586857518976 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140586829713592 -> 140586857518640
	140586829713592 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140586857517968 -> 140586980406048
	140586857517968 [label=TBackward]
	140586857518024 -> 140586857517968
	140586857518024 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
