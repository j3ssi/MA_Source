digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140517628305192 [label=AddmmBackward fillcolor=darkolivegreen1]
	140517628303960 -> 140517628305192
	140517628303960 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140517628304352 -> 140517628305192
	140517628304352 [label=ViewBackward]
	140516412694600 -> 140517628304352
	140516412694600 [label=ViewBackward]
	140516412694824 -> 140516412694600
	140516412694824 [label=MeanBackward1]
	140516412694656 -> 140516412694824
	140516412694656 [label=ViewBackward]
	140516412694936 -> 140516412694656
	140516412694936 [label=ReluBackward1]
	140516412695048 -> 140516412694936
	140516412695048 [label=AddBackward0]
	140516412695160 -> 140516412695048
	140516412695160 [label=ReluBackward1]
	140516412695328 -> 140516412695160
	140516412695328 [label=AddBackward0]
	140516412695440 -> 140516412695328
	140516412695440 [label=ReluBackward1]
	140516412695608 -> 140516412695440
	140516412695608 [label=AddBackward0]
	140516412695720 -> 140516412695608
	140516412695720 [label=ReluBackward1]
	140516412695888 -> 140516412695720
	140516412695888 [label=AddBackward0]
	140516412696000 -> 140516412695888
	140516412696000 [label=ReluBackward1]
	140516412696168 -> 140516412696000
	140516412696168 [label=AddBackward0]
	140516412696280 -> 140516412696168
	140516412696280 [label=ReluBackward1]
	140516412696448 -> 140516412696280
	140516412696448 [label=CudnnBatchNormBackward]
	140516412696560 -> 140516412696448
	140516412696560 [label=CudnnConvolutionBackward]
	140516412696784 -> 140516412696560
	140516412696784 [label=ReluBackward1]
	140516412696952 -> 140516412696784
	140516412696952 [label=CudnnBatchNormBackward]
	140516412697064 -> 140516412696952
	140516412697064 [label=CudnnConvolutionBackward]
	140516412697288 -> 140516412697064
	140516412697288 [label=ReluBackward1]
	140516412697456 -> 140516412697288
	140516412697456 [label=AddBackward0]
	140516412697568 -> 140516412697456
	140516412697568 [label=ReluBackward1]
	140516412697736 -> 140516412697568
	140516412697736 [label=AddBackward0]
	140516412697848 -> 140516412697736
	140516412697848 [label=ReluBackward1]
	140516412698016 -> 140516412697848
	140516412698016 [label=AddBackward0]
	140516412698128 -> 140516412698016
	140516412698128 [label=ReluBackward1]
	140516412698296 -> 140516412698128
	140516412698296 [label=AddBackward0]
	140516412698408 -> 140516412698296
	140516412698408 [label=ReluBackward1]
	140516412698576 -> 140516412698408
	140516412698576 [label=AddBackward0]
	140516412743808 -> 140516412698576
	140516412743808 [label=ReluBackward1]
	140516412743976 -> 140516412743808
	140516412743976 [label=CudnnBatchNormBackward]
	140516412744088 -> 140516412743976
	140516412744088 [label=CudnnConvolutionBackward]
	140516412744312 -> 140516412744088
	140516412744312 [label=ReluBackward1]
	140516412744480 -> 140516412744312
	140516412744480 [label=CudnnBatchNormBackward]
	140516412744592 -> 140516412744480
	140516412744592 [label=CudnnConvolutionBackward]
	140516412744816 -> 140516412744592
	140516412744816 [label=ReluBackward1]
	140516412744984 -> 140516412744816
	140516412744984 [label=AddBackward0]
	140516412745096 -> 140516412744984
	140516412745096 [label=ReluBackward1]
	140516412745264 -> 140516412745096
	140516412745264 [label=AddBackward0]
	140516412745376 -> 140516412745264
	140516412745376 [label=ReluBackward1]
	140516412745544 -> 140516412745376
	140516412745544 [label=AddBackward0]
	140516412745656 -> 140516412745544
	140516412745656 [label=ReluBackward1]
	140516412745824 -> 140516412745656
	140516412745824 [label=AddBackward0]
	140516412745936 -> 140516412745824
	140516412745936 [label=ReluBackward1]
	140516412746104 -> 140516412745936
	140516412746104 [label=AddBackward0]
	140516412746216 -> 140516412746104
	140516412746216 [label=ReluBackward1]
	140516412746384 -> 140516412746216
	140516412746384 [label=CudnnBatchNormBackward]
	140516412746496 -> 140516412746384
	140516412746496 [label=CudnnConvolutionBackward]
	140516412746720 -> 140516412746496
	140516412746720 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140516412746552 -> 140516412746384
	140516412746552 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140516412746608 -> 140516412746384
	140516412746608 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140516412746272 -> 140516412746104
	140516412746272 [label=CudnnBatchNormBackward]
	140516412746440 -> 140516412746272
	140516412746440 [label=CudnnConvolutionBackward]
	140516412746832 -> 140516412746440
	140516412746832 [label=ReluBackward1]
	140516412747056 -> 140516412746832
	140516412747056 [label=CudnnBatchNormBackward]
	140516412747168 -> 140516412747056
	140516412747168 [label=CudnnConvolutionBackward]
	140516412746216 -> 140516412747168
	140516412747392 -> 140516412747168
	140516412747392 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412747224 -> 140516412747056
	140516412747224 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140516412747280 -> 140516412747056
	140516412747280 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140516412746944 -> 140516412746440
	140516412746944 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412746664 -> 140516412746272
	140516412746664 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140516412746776 -> 140516412746272
	140516412746776 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140516412745992 -> 140516412745824
	140516412745992 [label=CudnnBatchNormBackward]
	140516412746160 -> 140516412745992
	140516412746160 [label=CudnnConvolutionBackward]
	140516412747336 -> 140516412746160
	140516412747336 [label=ReluBackward1]
	140516412747560 -> 140516412747336
	140516412747560 [label=CudnnBatchNormBackward]
	140516412747504 -> 140516412747560
	140516412747504 [label=CudnnConvolutionBackward]
	140516412745936 -> 140516412747504
	140516412895360 -> 140516412747504
	140516412895360 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412747672 -> 140516412747560
	140516412747672 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140516412747728 -> 140516412747560
	140516412747728 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140516412747448 -> 140516412746160
	140516412747448 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412746328 -> 140516412745992
	140516412746328 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140516412746888 -> 140516412745992
	140516412746888 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140516412745712 -> 140516412745544
	140516412745712 [label=CudnnBatchNormBackward]
	140516412745880 -> 140516412745712
	140516412745880 [label=CudnnConvolutionBackward]
	140516412747616 -> 140516412745880
	140516412747616 [label=ReluBackward1]
	140516412895528 -> 140516412747616
	140516412895528 [label=CudnnBatchNormBackward]
	140516412895472 -> 140516412895528
	140516412895472 [label=CudnnConvolutionBackward]
	140516412745656 -> 140516412895472
	140516412895808 -> 140516412895472
	140516412895808 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412895640 -> 140516412895528
	140516412895640 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140516412895696 -> 140516412895528
	140516412895696 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140516412895304 -> 140516412745880
	140516412895304 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412746048 -> 140516412745712
	140516412746048 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140516412747000 -> 140516412745712
	140516412747000 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140516412745432 -> 140516412745264
	140516412745432 [label=CudnnBatchNormBackward]
	140516412745600 -> 140516412745432
	140516412745600 [label=CudnnConvolutionBackward]
	140516412895752 -> 140516412745600
	140516412895752 [label=ReluBackward1]
	140516412895976 -> 140516412895752
	140516412895976 [label=CudnnBatchNormBackward]
	140516412895920 -> 140516412895976
	140516412895920 [label=CudnnConvolutionBackward]
	140516412745376 -> 140516412895920
	140516412896256 -> 140516412895920
	140516412896256 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412896088 -> 140516412895976
	140516412896088 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140516412896144 -> 140516412895976
	140516412896144 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140516412895864 -> 140516412745600
	140516412895864 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412745768 -> 140516412745432
	140516412745768 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140516412747112 -> 140516412745432
	140516412747112 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140516412745152 -> 140516412744984
	140516412745152 [label=CudnnBatchNormBackward]
	140516412745320 -> 140516412745152
	140516412745320 [label=CudnnConvolutionBackward]
	140516412896200 -> 140516412745320
	140516412896200 [label=ReluBackward1]
	140516412896424 -> 140516412896200
	140516412896424 [label=CudnnBatchNormBackward]
	140516412896368 -> 140516412896424
	140516412896368 [label=CudnnConvolutionBackward]
	140516412745096 -> 140516412896368
	140516412896704 -> 140516412896368
	140516412896704 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412896536 -> 140516412896424
	140516412896536 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140516412896592 -> 140516412896424
	140516412896592 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140516412896312 -> 140516412745320
	140516412896312 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140516412745488 -> 140516412745152
	140516412745488 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140516412895416 -> 140516412745152
	140516412895416 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140516412744872 -> 140516412744592
	140516412744872 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140516412744648 -> 140516412744480
	140516412744648 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140516412744704 -> 140516412744480
	140516412744704 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140516412744368 -> 140516412744088
	140516412744368 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412744144 -> 140516412743976
	140516412744144 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140516412744200 -> 140516412743976
	140516412744200 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140516412743864 -> 140516412698576
	140516412743864 [label=CudnnBatchNormBackward]
	140516412744032 -> 140516412743864
	140516412744032 [label=CudnnConvolutionBackward]
	140516412744816 -> 140516412744032
	140516412744928 -> 140516412744032
	140516412744928 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140516412744256 -> 140516412743864
	140516412744256 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140516412744424 -> 140516412743864
	140516412744424 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140516412698464 -> 140516412698296
	140516412698464 [label=CudnnBatchNormBackward]
	140516412743752 -> 140516412698464
	140516412743752 [label=CudnnConvolutionBackward]
	140516412745040 -> 140516412743752
	140516412745040 [label=ReluBackward1]
	140516412896032 -> 140516412745040
	140516412896032 [label=CudnnBatchNormBackward]
	140516412896760 -> 140516412896032
	140516412896760 [label=CudnnConvolutionBackward]
	140516412698408 -> 140516412896760
	140516412896816 -> 140516412896760
	140516412896816 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412896480 -> 140516412896032
	140516412896480 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140516412896872 -> 140516412896032
	140516412896872 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140516412745208 -> 140516412743752
	140516412745208 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412743920 -> 140516412698464
	140516412743920 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140516412744760 -> 140516412698464
	140516412744760 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140516412698184 -> 140516412698016
	140516412698184 [label=CudnnBatchNormBackward]
	140516412698352 -> 140516412698184
	140516412698352 [label=CudnnConvolutionBackward]
	140516412896928 -> 140516412698352
	140516412896928 [label=ReluBackward1]
	140516412897096 -> 140516412896928
	140516412897096 [label=CudnnBatchNormBackward]
	140516412897040 -> 140516412897096
	140516412897040 [label=CudnnConvolutionBackward]
	140516412698128 -> 140516412897040
	140516412897376 -> 140516412897040
	140516412897376 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412897208 -> 140516412897096
	140516412897208 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140516412897264 -> 140516412897096
	140516412897264 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140516412896984 -> 140516412698352
	140516412896984 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412698520 -> 140516412698184
	140516412698520 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140516412744536 -> 140516412698184
	140516412744536 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140516412697904 -> 140516412697736
	140516412697904 [label=CudnnBatchNormBackward]
	140516412698072 -> 140516412697904
	140516412698072 [label=CudnnConvolutionBackward]
	140516412897320 -> 140516412698072
	140516412897320 [label=ReluBackward1]
	140516412897544 -> 140516412897320
	140516412897544 [label=CudnnBatchNormBackward]
	140516412897488 -> 140516412897544
	140516412897488 [label=CudnnConvolutionBackward]
	140516412697848 -> 140516412897488
	140516412897824 -> 140516412897488
	140516412897824 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412897656 -> 140516412897544
	140516412897656 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140516412897712 -> 140516412897544
	140516412897712 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140516412897432 -> 140516412698072
	140516412897432 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412698240 -> 140516412697904
	140516412698240 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140516412895584 -> 140516412697904
	140516412895584 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140516412697624 -> 140516412697456
	140516412697624 [label=CudnnBatchNormBackward]
	140516412697792 -> 140516412697624
	140516412697792 [label=CudnnConvolutionBackward]
	140516412897768 -> 140516412697792
	140516412897768 [label=ReluBackward1]
	140516412897992 -> 140516412897768
	140516412897992 [label=CudnnBatchNormBackward]
	140516412897936 -> 140516412897992
	140516412897936 [label=CudnnConvolutionBackward]
	140516412697568 -> 140516412897936
	140516412898272 -> 140516412897936
	140516412898272 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412898104 -> 140516412897992
	140516412898104 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140516412898160 -> 140516412897992
	140516412898160 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140516412897880 -> 140516412697792
	140516412897880 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140516412697960 -> 140516412697624
	140516412697960 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140516412896648 -> 140516412697624
	140516412896648 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140516412697344 -> 140516412697064
	140516412697344 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140516412697120 -> 140516412696952
	140516412697120 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140516412697176 -> 140516412696952
	140516412697176 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140516412696840 -> 140516412696560
	140516412696840 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412696616 -> 140516412696448
	140516412696616 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140516412696672 -> 140516412696448
	140516412696672 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140516412696336 -> 140516412696168
	140516412696336 [label=CudnnBatchNormBackward]
	140516412696504 -> 140516412696336
	140516412696504 [label=CudnnConvolutionBackward]
	140516412697288 -> 140516412696504
	140516412697400 -> 140516412696504
	140516412697400 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140516412696728 -> 140516412696336
	140516412696728 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140516412696896 -> 140516412696336
	140516412696896 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140516412696056 -> 140516412695888
	140516412696056 [label=CudnnBatchNormBackward]
	140516412696224 -> 140516412696056
	140516412696224 [label=CudnnConvolutionBackward]
	140516412697512 -> 140516412696224
	140516412697512 [label=ReluBackward1]
	140516412897600 -> 140516412697512
	140516412897600 [label=CudnnBatchNormBackward]
	140516412898328 -> 140516412897600
	140516412898328 [label=CudnnConvolutionBackward]
	140516412696000 -> 140516412898328
	140516412898384 -> 140516412898328
	140516412898384 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412898048 -> 140516412897600
	140516412898048 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140516412898440 -> 140516412897600
	140516412898440 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140516412697680 -> 140516412696224
	140516412697680 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412696392 -> 140516412696056
	140516412696392 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140516412697232 -> 140516412696056
	140516412697232 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140516412695776 -> 140516412695608
	140516412695776 [label=CudnnBatchNormBackward]
	140516412695944 -> 140516412695776
	140516412695944 [label=CudnnConvolutionBackward]
	140516412898496 -> 140516412695944
	140516412898496 [label=ReluBackward1]
	140516412898664 -> 140516412898496
	140516412898664 [label=CudnnBatchNormBackward]
	140516412898608 -> 140516412898664
	140516412898608 [label=CudnnConvolutionBackward]
	140516412695720 -> 140516412898608
	140516412898944 -> 140516412898608
	140516412898944 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412898776 -> 140516412898664
	140516412898776 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140516412898832 -> 140516412898664
	140516412898832 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140516412898552 -> 140516412695944
	140516412898552 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412696112 -> 140516412695776
	140516412696112 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140516412697008 -> 140516412695776
	140516412697008 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140516412695496 -> 140516412695328
	140516412695496 [label=CudnnBatchNormBackward]
	140516412695664 -> 140516412695496
	140516412695664 [label=CudnnConvolutionBackward]
	140516412898888 -> 140516412695664
	140516412898888 [label=ReluBackward1]
	140516412899112 -> 140516412898888
	140516412899112 [label=CudnnBatchNormBackward]
	140516412899056 -> 140516412899112
	140516412899056 [label=CudnnConvolutionBackward]
	140516412695440 -> 140516412899056
	140516412768384 -> 140516412899056
	140516412768384 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412899224 -> 140516412899112
	140516412899224 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140516412899280 -> 140516412899112
	140516412899280 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140516412899000 -> 140516412695664
	140516412899000 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412695832 -> 140516412695496
	140516412695832 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140516412897152 -> 140516412695496
	140516412897152 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140516412695216 -> 140516412695048
	140516412695216 [label=CudnnBatchNormBackward]
	140516412695384 -> 140516412695216
	140516412695384 [label=CudnnConvolutionBackward]
	140516412899168 -> 140516412695384
	140516412899168 [label=ReluBackward1]
	140516412768552 -> 140516412899168
	140516412768552 [label=CudnnBatchNormBackward]
	140516412768496 -> 140516412768552
	140516412768496 [label=CudnnConvolutionBackward]
	140516412695160 -> 140516412768496
	140516412768832 -> 140516412768496
	140516412768832 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412768664 -> 140516412768552
	140516412768664 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140516412768720 -> 140516412768552
	140516412768720 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140516412768328 -> 140516412695384
	140516412768328 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140516412695552 -> 140516412695216
	140516412695552 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140516412898216 -> 140516412695216
	140516412898216 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140517628204256 -> 140517628305192
	140517628204256 [label=TBackward]
	140516412694712 -> 140517628204256
	140516412694712 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
