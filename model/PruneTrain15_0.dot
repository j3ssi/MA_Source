digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140448638938416 [label=AddmmBackward fillcolor=darkolivegreen1]
	140448638938696 -> 140448638938416
	140448638938696 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140448638938136 -> 140448638938416
	140448638938136 [label=ViewBackward]
	140448638937408 -> 140448638938136
	140448638937408 [label=ViewBackward]
	140448638938640 -> 140448638937408
	140448638938640 [label=MeanBackward1]
	140448638938248 -> 140448638938640
	140448638938248 [label=ViewBackward]
	140448638936008 -> 140448638938248
	140448638936008 [label=ReluBackward1]
	140448638936960 -> 140448638936008
	140448638936960 [label=AddBackward0]
	140448638937744 -> 140448638936960
	140448638937744 [label=ReluBackward1]
	140448638936064 -> 140448638937744
	140448638936064 [label=AddBackward0]
	140448638937912 -> 140448638936064
	140448638937912 [label=ReluBackward1]
	140448638937240 -> 140448638937912
	140448638937240 [label=AddBackward0]
	140448638938304 -> 140448638937240
	140448638938304 [label=ReluBackward1]
	140448596623488 -> 140448638938304
	140448596623488 [label=AddBackward0]
	140448596623600 -> 140448596623488
	140448596623600 [label=ReluBackward1]
	140448596623768 -> 140448596623600
	140448596623768 [label=AddBackward0]
	140448596623880 -> 140448596623768
	140448596623880 [label=ReluBackward1]
	140448596624048 -> 140448596623880
	140448596624048 [label=CudnnBatchNormBackward]
	140448596624160 -> 140448596624048
	140448596624160 [label=CudnnConvolutionBackward]
	140448596624384 -> 140448596624160
	140448596624384 [label=ReluBackward1]
	140448596624552 -> 140448596624384
	140448596624552 [label=CudnnBatchNormBackward]
	140448596624664 -> 140448596624552
	140448596624664 [label=CudnnConvolutionBackward]
	140448596624888 -> 140448596624664
	140448596624888 [label=ReluBackward1]
	140448596625056 -> 140448596624888
	140448596625056 [label=AddBackward0]
	140448596625168 -> 140448596625056
	140448596625168 [label=ReluBackward1]
	140448596625336 -> 140448596625168
	140448596625336 [label=AddBackward0]
	140448596625448 -> 140448596625336
	140448596625448 [label=ReluBackward1]
	140448596625616 -> 140448596625448
	140448596625616 [label=AddBackward0]
	140448596625728 -> 140448596625616
	140448596625728 [label=ReluBackward1]
	140448596625896 -> 140448596625728
	140448596625896 [label=AddBackward0]
	140448596626008 -> 140448596625896
	140448596626008 [label=ReluBackward1]
	140448596626176 -> 140448596626008
	140448596626176 [label=AddBackward0]
	140448596626288 -> 140448596626176
	140448596626288 [label=ReluBackward1]
	140448596626456 -> 140448596626288
	140448596626456 [label=CudnnBatchNormBackward]
	140448596626568 -> 140448596626456
	140448596626568 [label=CudnnConvolutionBackward]
	140448596626792 -> 140448596626568
	140448596626792 [label=ReluBackward1]
	140448596626960 -> 140448596626792
	140448596626960 [label=CudnnBatchNormBackward]
	140448596627072 -> 140448596626960
	140448596627072 [label=CudnnConvolutionBackward]
	140448596627296 -> 140448596627072
	140448596627296 [label=ReluBackward1]
	140448596619336 -> 140448596627296
	140448596619336 [label=AddBackward0]
	140448596619448 -> 140448596619336
	140448596619448 [label=ReluBackward1]
	140448596619616 -> 140448596619448
	140448596619616 [label=AddBackward0]
	140448596619728 -> 140448596619616
	140448596619728 [label=ReluBackward1]
	140448596619896 -> 140448596619728
	140448596619896 [label=AddBackward0]
	140448596620008 -> 140448596619896
	140448596620008 [label=ReluBackward1]
	140448596620176 -> 140448596620008
	140448596620176 [label=AddBackward0]
	140448596620288 -> 140448596620176
	140448596620288 [label=ReluBackward1]
	140448596620456 -> 140448596620288
	140448596620456 [label=AddBackward0]
	140448596620568 -> 140448596620456
	140448596620568 [label=ReluBackward1]
	140448596620736 -> 140448596620568
	140448596620736 [label=CudnnBatchNormBackward]
	140448596620848 -> 140448596620736
	140448596620848 [label=CudnnConvolutionBackward]
	140448596621072 -> 140448596620848
	140448596621072 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140448596620904 -> 140448596620736
	140448596620904 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140448596620960 -> 140448596620736
	140448596620960 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140448596620624 -> 140448596620456
	140448596620624 [label=CudnnBatchNormBackward]
	140448596620792 -> 140448596620624
	140448596620792 [label=CudnnConvolutionBackward]
	140448596621184 -> 140448596620792
	140448596621184 [label=ReluBackward1]
	140448596621408 -> 140448596621184
	140448596621408 [label=CudnnBatchNormBackward]
	140448596621520 -> 140448596621408
	140448596621520 [label=CudnnConvolutionBackward]
	140448596620568 -> 140448596621520
	140448596621744 -> 140448596621520
	140448596621744 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596621576 -> 140448596621408
	140448596621576 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140448596621632 -> 140448596621408
	140448596621632 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140448596621296 -> 140448596620792
	140448596621296 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596621016 -> 140448596620624
	140448596621016 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140448596621128 -> 140448596620624
	140448596621128 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140448596620344 -> 140448596620176
	140448596620344 [label=CudnnBatchNormBackward]
	140448596620512 -> 140448596620344
	140448596620512 [label=CudnnConvolutionBackward]
	140448596621688 -> 140448596620512
	140448596621688 [label=ReluBackward1]
	140448596621912 -> 140448596621688
	140448596621912 [label=CudnnBatchNormBackward]
	140448596621856 -> 140448596621912
	140448596621856 [label=CudnnConvolutionBackward]
	140448596620288 -> 140448596621856
	140448596622192 -> 140448596621856
	140448596622192 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596622024 -> 140448596621912
	140448596622024 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140448596622080 -> 140448596621912
	140448596622080 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140448596621800 -> 140448596620512
	140448596621800 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596620680 -> 140448596620344
	140448596620680 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140448596621240 -> 140448596620344
	140448596621240 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140448596620064 -> 140448596619896
	140448596620064 [label=CudnnBatchNormBackward]
	140448596620232 -> 140448596620064
	140448596620232 [label=CudnnConvolutionBackward]
	140448596622136 -> 140448596620232
	140448596622136 [label=ReluBackward1]
	140448596622360 -> 140448596622136
	140448596622360 [label=CudnnBatchNormBackward]
	140448596622304 -> 140448596622360
	140448596622304 [label=CudnnConvolutionBackward]
	140448596620008 -> 140448596622304
	140448596622640 -> 140448596622304
	140448596622640 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596622472 -> 140448596622360
	140448596622472 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140448596622528 -> 140448596622360
	140448596622528 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140448596622248 -> 140448596620232
	140448596622248 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596620400 -> 140448596620064
	140448596620400 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140448596621352 -> 140448596620064
	140448596621352 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140448596619784 -> 140448596619616
	140448596619784 [label=CudnnBatchNormBackward]
	140448596619952 -> 140448596619784
	140448596619952 [label=CudnnConvolutionBackward]
	140448596622584 -> 140448596619952
	140448596622584 [label=ReluBackward1]
	140448596622808 -> 140448596622584
	140448596622808 [label=CudnnBatchNormBackward]
	140448596622752 -> 140448596622808
	140448596622752 [label=CudnnConvolutionBackward]
	140448596619728 -> 140448596622752
	140448596623088 -> 140448596622752
	140448596623088 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596622920 -> 140448596622808
	140448596622920 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140448596622976 -> 140448596622808
	140448596622976 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140448596622696 -> 140448596619952
	140448596622696 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596620120 -> 140448596619784
	140448596620120 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140448596621464 -> 140448596619784
	140448596621464 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140448596619504 -> 140448596619336
	140448596619504 [label=CudnnBatchNormBackward]
	140448596619672 -> 140448596619504
	140448596619672 [label=CudnnConvolutionBackward]
	140448596623032 -> 140448596619672
	140448596623032 [label=ReluBackward1]
	140448596623256 -> 140448596623032
	140448596623256 [label=CudnnBatchNormBackward]
	140448596623200 -> 140448596623256
	140448596623200 [label=CudnnConvolutionBackward]
	140448596619448 -> 140448596623200
	140448596627696 -> 140448596623200
	140448596627696 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596627528 -> 140448596623256
	140448596627528 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140448596627584 -> 140448596623256
	140448596627584 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140448596623144 -> 140448596619672
	140448596623144 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140448596619840 -> 140448596619504
	140448596619840 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140448596621968 -> 140448596619504
	140448596621968 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140448596627352 -> 140448596627072
	140448596627352 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140448596627128 -> 140448596626960
	140448596627128 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140448596627184 -> 140448596626960
	140448596627184 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140448596626848 -> 140448596626568
	140448596626848 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596626624 -> 140448596626456
	140448596626624 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140448596626680 -> 140448596626456
	140448596626680 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140448596626344 -> 140448596626176
	140448596626344 [label=CudnnBatchNormBackward]
	140448596626512 -> 140448596626344
	140448596626512 [label=CudnnConvolutionBackward]
	140448596627296 -> 140448596626512
	140448596627408 -> 140448596626512
	140448596627408 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140448596626736 -> 140448596626344
	140448596626736 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140448596626904 -> 140448596626344
	140448596626904 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140448596626064 -> 140448596625896
	140448596626064 [label=CudnnBatchNormBackward]
	140448596626232 -> 140448596626064
	140448596626232 [label=CudnnConvolutionBackward]
	140448596622416 -> 140448596626232
	140448596622416 [label=ReluBackward1]
	140448596622864 -> 140448596622416
	140448596622864 [label=CudnnBatchNormBackward]
	140448596627640 -> 140448596622864
	140448596627640 [label=CudnnConvolutionBackward]
	140448596626008 -> 140448596627640
	140448596627808 -> 140448596627640
	140448596627808 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596627752 -> 140448596622864
	140448596627752 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140448596627864 -> 140448596622864
	140448596627864 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140448596619392 -> 140448596626232
	140448596619392 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596626400 -> 140448596626064
	140448596626400 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140448596627240 -> 140448596626064
	140448596627240 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140448596625784 -> 140448596625616
	140448596625784 [label=CudnnBatchNormBackward]
	140448596625952 -> 140448596625784
	140448596625952 [label=CudnnConvolutionBackward]
	140448596623312 -> 140448596625952
	140448596623312 [label=ReluBackward1]
	140448596628088 -> 140448596623312
	140448596628088 [label=CudnnBatchNormBackward]
	140448596628032 -> 140448596628088
	140448596628032 [label=CudnnConvolutionBackward]
	140448596625728 -> 140448596628032
	140448596628368 -> 140448596628032
	140448596628368 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596628200 -> 140448596628088
	140448596628200 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140448596628256 -> 140448596628088
	140448596628256 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140448596627920 -> 140448596625952
	140448596627920 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596626120 -> 140448596625784
	140448596626120 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140448596627016 -> 140448596625784
	140448596627016 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140448596625504 -> 140448596625336
	140448596625504 [label=CudnnBatchNormBackward]
	140448596625672 -> 140448596625504
	140448596625672 [label=CudnnConvolutionBackward]
	140448596628312 -> 140448596625672
	140448596628312 [label=ReluBackward1]
	140448596628536 -> 140448596628312
	140448596628536 [label=CudnnBatchNormBackward]
	140448596628480 -> 140448596628536
	140448596628480 [label=CudnnConvolutionBackward]
	140448596625448 -> 140448596628480
	140448596628816 -> 140448596628480
	140448596628816 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596628648 -> 140448596628536
	140448596628648 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140448596628704 -> 140448596628536
	140448596628704 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140448596628424 -> 140448596625672
	140448596628424 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596625840 -> 140448596625504
	140448596625840 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140448596619560 -> 140448596625504
	140448596619560 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140448596625224 -> 140448596625056
	140448596625224 [label=CudnnBatchNormBackward]
	140448596625392 -> 140448596625224
	140448596625392 [label=CudnnConvolutionBackward]
	140448596628760 -> 140448596625392
	140448596628760 [label=ReluBackward1]
	140448596628984 -> 140448596628760
	140448596628984 [label=CudnnBatchNormBackward]
	140448596628928 -> 140448596628984
	140448596628928 [label=CudnnConvolutionBackward]
	140448596625168 -> 140448596628928
	140448596629264 -> 140448596628928
	140448596629264 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596629096 -> 140448596628984
	140448596629096 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140448596629152 -> 140448596628984
	140448596629152 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140448596628872 -> 140448596625392
	140448596628872 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140448596625560 -> 140448596625224
	140448596625560 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140448596627976 -> 140448596625224
	140448596627976 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140448596624944 -> 140448596624664
	140448596624944 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140448596624720 -> 140448596624552
	140448596624720 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140448596624776 -> 140448596624552
	140448596624776 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140448596624440 -> 140448596624160
	140448596624440 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596624216 -> 140448596624048
	140448596624216 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140448596624272 -> 140448596624048
	140448596624272 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140448596623936 -> 140448596623768
	140448596623936 [label=CudnnBatchNormBackward]
	140448596624104 -> 140448596623936
	140448596624104 [label=CudnnConvolutionBackward]
	140448596624888 -> 140448596624104
	140448596625000 -> 140448596624104
	140448596625000 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140448596624328 -> 140448596623936
	140448596624328 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140448596624496 -> 140448596623936
	140448596624496 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140448596623656 -> 140448596623488
	140448596623656 [label=CudnnBatchNormBackward]
	140448596623824 -> 140448596623656
	140448596623824 [label=CudnnConvolutionBackward]
	140448596625112 -> 140448596623824
	140448596625112 [label=ReluBackward1]
	140448596628592 -> 140448596625112
	140448596628592 [label=CudnnBatchNormBackward]
	140448596629320 -> 140448596628592
	140448596629320 [label=CudnnConvolutionBackward]
	140448596623600 -> 140448596629320
	140448596629376 -> 140448596629320
	140448596629376 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596629040 -> 140448596628592
	140448596629040 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140448596629432 -> 140448596628592
	140448596629432 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140448596625280 -> 140448596623824
	140448596625280 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596623992 -> 140448596623656
	140448596623992 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140448596624832 -> 140448596623656
	140448596624832 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140448638937968 -> 140448638937240
	140448638937968 [label=CudnnBatchNormBackward]
	140448596623544 -> 140448638937968
	140448596623544 [label=CudnnConvolutionBackward]
	140448596629488 -> 140448596623544
	140448596629488 [label=ReluBackward1]
	140448596629656 -> 140448596629488
	140448596629656 [label=CudnnBatchNormBackward]
	140448596629600 -> 140448596629656
	140448596629600 [label=CudnnConvolutionBackward]
	140448638938304 -> 140448596629600
	140448596629936 -> 140448596629600
	140448596629936 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596629768 -> 140448596629656
	140448596629768 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140448596629824 -> 140448596629656
	140448596629824 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140448596629544 -> 140448596623544
	140448596629544 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596623712 -> 140448638937968
	140448596623712 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140448596624608 -> 140448638937968
	140448596624608 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140448638937072 -> 140448638936064
	140448638937072 [label=CudnnBatchNormBackward]
	140448638937688 -> 140448638937072
	140448638937688 [label=CudnnConvolutionBackward]
	140448596629880 -> 140448638937688
	140448596629880 [label=ReluBackward1]
	140448596630104 -> 140448596629880
	140448596630104 [label=CudnnBatchNormBackward]
	140448596630048 -> 140448596630104
	140448596630048 [label=CudnnConvolutionBackward]
	140448638937912 -> 140448596630048
	140448596630384 -> 140448596630048
	140448596630384 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596630216 -> 140448596630104
	140448596630216 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140448596630272 -> 140448596630104
	140448596630272 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140448596629992 -> 140448638937688
	140448596629992 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596623432 -> 140448638937072
	140448596623432 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140448596628144 -> 140448638937072
	140448596628144 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140448638936904 -> 140448638936960
	140448638936904 [label=CudnnBatchNormBackward]
	140448638935224 -> 140448638936904
	140448638935224 [label=CudnnConvolutionBackward]
	140448596630328 -> 140448638935224
	140448596630328 [label=ReluBackward1]
	140448596630552 -> 140448596630328
	140448596630552 [label=CudnnBatchNormBackward]
	140448596630496 -> 140448596630552
	140448596630496 [label=CudnnConvolutionBackward]
	140448638937744 -> 140448596630496
	140448596630832 -> 140448596630496
	140448596630832 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448596630664 -> 140448596630552
	140448596630664 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140448596630720 -> 140448596630552
	140448596630720 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140448596630440 -> 140448638935224
	140448596630440 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140448638937184 -> 140448638936904
	140448638937184 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140448596629208 -> 140448638936904
	140448596629208 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140448638938024 -> 140448638938416
	140448638938024 [label=TBackward]
	140448638938192 -> 140448638938024
	140448638938192 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
