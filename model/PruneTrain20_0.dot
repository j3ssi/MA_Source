digraph {
	graph [size="68.39999999999999,68.39999999999999"]
	node [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]
	140498878345792 [label=AddmmBackward fillcolor=darkolivegreen1]
	140498878283000 -> 140498878345792
	140498878283000 [label="module_list.67.bias
 (10)" fillcolor=lightblue]
	140498878279808 -> 140498878345792
	140498878279808 [label=ViewBackward]
	140498878281824 -> 140498878279808
	140498878281824 [label=ViewBackward]
	140498878281992 -> 140498878281824
	140498878281992 [label=MeanBackward1]
	140498878280984 -> 140498878281992
	140498878280984 [label=ViewBackward]
	140498878280032 -> 140498878280984
	140498878280032 [label=ReluBackward1]
	140498998392144 -> 140498878280032
	140498998392144 [label=AddBackward0]
	140498998392200 -> 140498998392144
	140498998392200 [label=ReluBackward1]
	140498998391920 -> 140498998392200
	140498998391920 [label=AddBackward0]
	140498998390912 -> 140498998391920
	140498998390912 [label=ReluBackward1]
	140498875511304 -> 140498998390912
	140498875511304 [label=AddBackward0]
	140498875511248 -> 140498875511304
	140498875511248 [label=ReluBackward1]
	140498875512480 -> 140498875511248
	140498875512480 [label=AddBackward0]
	140498875511472 -> 140498875512480
	140498875511472 [label=ReluBackward1]
	140498875512368 -> 140498875511472
	140498875512368 [label=AddBackward0]
	140498875511584 -> 140498875512368
	140498875511584 [label=ReluBackward1]
	140498875512648 -> 140498875511584
	140498875512648 [label=CudnnBatchNormBackward]
	140498875512760 -> 140498875512648
	140498875512760 [label=CudnnConvolutionBackward]
	140498875512984 -> 140498875512760
	140498875512984 [label=ReluBackward1]
	140498875513152 -> 140498875512984
	140498875513152 [label=CudnnBatchNormBackward]
	140498875513264 -> 140498875513152
	140498875513264 [label=CudnnConvolutionBackward]
	140498875513488 -> 140498875513264
	140498875513488 [label=ReluBackward1]
	140498875513656 -> 140498875513488
	140498875513656 [label=AddBackward0]
	140498875513768 -> 140498875513656
	140498875513768 [label=ReluBackward1]
	140498875513936 -> 140498875513768
	140498875513936 [label=AddBackward0]
	140498875514048 -> 140498875513936
	140498875514048 [label=ReluBackward1]
	140498875514216 -> 140498875514048
	140498875514216 [label=AddBackward0]
	140498875514328 -> 140498875514216
	140498875514328 [label=ReluBackward1]
	140498875514496 -> 140498875514328
	140498875514496 [label=AddBackward0]
	140498875514608 -> 140498875514496
	140498875514608 [label=ReluBackward1]
	140498875514776 -> 140498875514608
	140498875514776 [label=AddBackward0]
	140496655450184 -> 140498875514776
	140496655450184 [label=ReluBackward1]
	140496655450352 -> 140496655450184
	140496655450352 [label=CudnnBatchNormBackward]
	140496655450464 -> 140496655450352
	140496655450464 [label=CudnnConvolutionBackward]
	140496655450688 -> 140496655450464
	140496655450688 [label=ReluBackward1]
	140496655450856 -> 140496655450688
	140496655450856 [label=CudnnBatchNormBackward]
	140496655450968 -> 140496655450856
	140496655450968 [label=CudnnConvolutionBackward]
	140496655451192 -> 140496655450968
	140496655451192 [label=ReluBackward1]
	140496655451360 -> 140496655451192
	140496655451360 [label=AddBackward0]
	140496655451472 -> 140496655451360
	140496655451472 [label=ReluBackward1]
	140496655451640 -> 140496655451472
	140496655451640 [label=AddBackward0]
	140496655451752 -> 140496655451640
	140496655451752 [label=ReluBackward1]
	140496655451920 -> 140496655451752
	140496655451920 [label=AddBackward0]
	140496655452032 -> 140496655451920
	140496655452032 [label=ReluBackward1]
	140496655452200 -> 140496655452032
	140496655452200 [label=AddBackward0]
	140496655452312 -> 140496655452200
	140496655452312 [label=ReluBackward1]
	140496655452480 -> 140496655452312
	140496655452480 [label=AddBackward0]
	140496655452592 -> 140496655452480
	140496655452592 [label=ReluBackward1]
	140496655452760 -> 140496655452592
	140496655452760 [label=CudnnBatchNormBackward]
	140496655452872 -> 140496655452760
	140496655452872 [label=CudnnConvolutionBackward]
	140496655453096 -> 140496655452872
	140496655453096 [label="module_list.0.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140496655452928 -> 140496655452760
	140496655452928 [label="module_list.1.weight
 (16)" fillcolor=lightblue]
	140496655452984 -> 140496655452760
	140496655452984 [label="module_list.1.bias
 (16)" fillcolor=lightblue]
	140496655452648 -> 140496655452480
	140496655452648 [label=CudnnBatchNormBackward]
	140496655452816 -> 140496655452648
	140496655452816 [label=CudnnConvolutionBackward]
	140496655453208 -> 140496655452816
	140496655453208 [label=ReluBackward1]
	140496655453432 -> 140496655453208
	140496655453432 [label=CudnnBatchNormBackward]
	140496655453544 -> 140496655453432
	140496655453544 [label=CudnnConvolutionBackward]
	140496655452592 -> 140496655453544
	140496655453768 -> 140496655453544
	140496655453768 [label="module_list.2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655453600 -> 140496655453432
	140496655453600 [label="module_list.3.weight
 (16)" fillcolor=lightblue]
	140496655453656 -> 140496655453432
	140496655453656 [label="module_list.3.bias
 (16)" fillcolor=lightblue]
	140496655453320 -> 140496655452816
	140496655453320 [label="module_list.4.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655453040 -> 140496655452648
	140496655453040 [label="module_list.5.weight
 (16)" fillcolor=lightblue]
	140496655453152 -> 140496655452648
	140496655453152 [label="module_list.5.bias
 (16)" fillcolor=lightblue]
	140496655452368 -> 140496655452200
	140496655452368 [label=CudnnBatchNormBackward]
	140496655452536 -> 140496655452368
	140496655452536 [label=CudnnConvolutionBackward]
	140496655453712 -> 140496655452536
	140496655453712 [label=ReluBackward1]
	140496655453936 -> 140496655453712
	140496655453936 [label=CudnnBatchNormBackward]
	140496655453880 -> 140496655453936
	140496655453880 [label=CudnnConvolutionBackward]
	140496655452312 -> 140496655453880
	140496655458376 -> 140496655453880
	140496655458376 [label="module_list.6.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655454048 -> 140496655453936
	140496655454048 [label="module_list.7.weight
 (16)" fillcolor=lightblue]
	140496655454104 -> 140496655453936
	140496655454104 [label="module_list.7.bias
 (16)" fillcolor=lightblue]
	140496655453824 -> 140496655452536
	140496655453824 [label="module_list.8.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655452704 -> 140496655452368
	140496655452704 [label="module_list.9.weight
 (16)" fillcolor=lightblue]
	140496655453264 -> 140496655452368
	140496655453264 [label="module_list.9.bias
 (16)" fillcolor=lightblue]
	140496655452088 -> 140496655451920
	140496655452088 [label=CudnnBatchNormBackward]
	140496655452256 -> 140496655452088
	140496655452256 [label=CudnnConvolutionBackward]
	140496655454160 -> 140496655452256
	140496655454160 [label=ReluBackward1]
	140496655458544 -> 140496655454160
	140496655458544 [label=CudnnBatchNormBackward]
	140496655458488 -> 140496655458544
	140496655458488 [label=CudnnConvolutionBackward]
	140496655452032 -> 140496655458488
	140496655458824 -> 140496655458488
	140496655458824 [label="module_list.10.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655458656 -> 140496655458544
	140496655458656 [label="module_list.11.weight
 (16)" fillcolor=lightblue]
	140496655458712 -> 140496655458544
	140496655458712 [label="module_list.11.bias
 (16)" fillcolor=lightblue]
	140496655453992 -> 140496655452256
	140496655453992 [label="module_list.12.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655452424 -> 140496655452088
	140496655452424 [label="module_list.13.weight
 (16)" fillcolor=lightblue]
	140496655453376 -> 140496655452088
	140496655453376 [label="module_list.13.bias
 (16)" fillcolor=lightblue]
	140496655451808 -> 140496655451640
	140496655451808 [label=CudnnBatchNormBackward]
	140496655451976 -> 140496655451808
	140496655451976 [label=CudnnConvolutionBackward]
	140496655458768 -> 140496655451976
	140496655458768 [label=ReluBackward1]
	140496655458992 -> 140496655458768
	140496655458992 [label=CudnnBatchNormBackward]
	140496655458936 -> 140496655458992
	140496655458936 [label=CudnnConvolutionBackward]
	140496655451752 -> 140496655458936
	140496655459272 -> 140496655458936
	140496655459272 [label="module_list.14.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655459104 -> 140496655458992
	140496655459104 [label="module_list.15.weight
 (16)" fillcolor=lightblue]
	140496655459160 -> 140496655458992
	140496655459160 [label="module_list.15.bias
 (16)" fillcolor=lightblue]
	140496655458880 -> 140496655451976
	140496655458880 [label="module_list.16.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655452144 -> 140496655451808
	140496655452144 [label="module_list.17.weight
 (16)" fillcolor=lightblue]
	140496655453488 -> 140496655451808
	140496655453488 [label="module_list.17.bias
 (16)" fillcolor=lightblue]
	140496655451528 -> 140496655451360
	140496655451528 [label=CudnnBatchNormBackward]
	140496655451696 -> 140496655451528
	140496655451696 [label=CudnnConvolutionBackward]
	140496655459216 -> 140496655451696
	140496655459216 [label=ReluBackward1]
	140496655459440 -> 140496655459216
	140496655459440 [label=CudnnBatchNormBackward]
	140496655459384 -> 140496655459440
	140496655459384 [label=CudnnConvolutionBackward]
	140496655451472 -> 140496655459384
	140496655459720 -> 140496655459384
	140496655459720 [label="module_list.18.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655459552 -> 140496655459440
	140496655459552 [label="module_list.19.weight
 (16)" fillcolor=lightblue]
	140496655459608 -> 140496655459440
	140496655459608 [label="module_list.19.bias
 (16)" fillcolor=lightblue]
	140496655459328 -> 140496655451696
	140496655459328 [label="module_list.20.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140496655451864 -> 140496655451528
	140496655451864 [label="module_list.21.weight
 (16)" fillcolor=lightblue]
	140496655458432 -> 140496655451528
	140496655458432 [label="module_list.21.bias
 (16)" fillcolor=lightblue]
	140496655451248 -> 140496655450968
	140496655451248 [label="module_list.22.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140496655451024 -> 140496655450856
	140496655451024 [label="module_list.23.weight
 (32)" fillcolor=lightblue]
	140496655451080 -> 140496655450856
	140496655451080 [label="module_list.23.bias
 (32)" fillcolor=lightblue]
	140496655450744 -> 140496655450464
	140496655450744 [label="module_list.24.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140496655450520 -> 140496655450352
	140496655450520 [label="module_list.25.weight
 (32)" fillcolor=lightblue]
	140496655450576 -> 140496655450352
	140496655450576 [label="module_list.25.bias
 (32)" fillcolor=lightblue]
	140496655450240 -> 140498875514776
	140496655450240 [label=CudnnBatchNormBackward]
	140496655450408 -> 140496655450240
	140496655450408 [label=CudnnConvolutionBackward]
	140496655451192 -> 140496655450408
	140496655451304 -> 140496655450408
	140496655451304 [label="module_list.26.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140496655450632 -> 140496655450240
	140496655450632 [label="module_list.27.weight
 (32)" fillcolor=lightblue]
	140496655450800 -> 140496655450240
	140496655450800 [label="module_list.27.bias
 (32)" fillcolor=lightblue]
	140498875514664 -> 140498875514496
	140498875514664 [label=CudnnBatchNormBackward]
	140498875514832 -> 140498875514664
	140498875514832 [label=CudnnConvolutionBackward]
	140496655451416 -> 140498875514832
	140496655451416 [label=ReluBackward1]
	140496655459048 -> 140496655451416
	140496655459048 [label=CudnnBatchNormBackward]
	140496655459776 -> 140496655459048
	140496655459776 [label=CudnnConvolutionBackward]
	140498875514608 -> 140496655459776
	140496655459832 -> 140496655459776
	140496655459832 [label="module_list.28.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140496655459496 -> 140496655459048
	140496655459496 [label="module_list.29.weight
 (32)" fillcolor=lightblue]
	140496655459888 -> 140496655459048
	140496655459888 [label="module_list.29.bias
 (32)" fillcolor=lightblue]
	140496655451584 -> 140498875514832
	140496655451584 [label="module_list.30.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140496655450296 -> 140498875514664
	140496655450296 [label="module_list.31.weight
 (32)" fillcolor=lightblue]
	140496655451136 -> 140498875514664
	140496655451136 [label="module_list.31.bias
 (32)" fillcolor=lightblue]
	140498875514384 -> 140498875514216
	140498875514384 [label=CudnnBatchNormBackward]
	140498875514552 -> 140498875514384
	140498875514552 [label=CudnnConvolutionBackward]
	140496655459944 -> 140498875514552
	140496655459944 [label=ReluBackward1]
	140496655460112 -> 140496655459944
	140496655460112 [label=CudnnBatchNormBackward]
	140496655460056 -> 140496655460112
	140496655460056 [label=CudnnConvolutionBackward]
	140498875514328 -> 140496655460056
	140496655460392 -> 140496655460056
	140496655460392 [label="module_list.32.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140496655460224 -> 140496655460112
	140496655460224 [label="module_list.33.weight
 (32)" fillcolor=lightblue]
	140496655460280 -> 140496655460112
	140496655460280 [label="module_list.33.bias
 (32)" fillcolor=lightblue]
	140496655460000 -> 140498875514552
	140496655460000 [label="module_list.34.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140498875514720 -> 140498875514384
	140498875514720 [label="module_list.35.weight
 (32)" fillcolor=lightblue]
	140496655450912 -> 140498875514384
	140496655450912 [label="module_list.35.bias
 (32)" fillcolor=lightblue]
	140498875514104 -> 140498875513936
	140498875514104 [label=CudnnBatchNormBackward]
	140498875514272 -> 140498875514104
	140498875514272 [label=CudnnConvolutionBackward]
	140496655460336 -> 140498875514272
	140496655460336 [label=ReluBackward1]
	140496655460560 -> 140496655460336
	140496655460560 [label=CudnnBatchNormBackward]
	140496655460504 -> 140496655460560
	140496655460504 [label=CudnnConvolutionBackward]
	140498875514048 -> 140496655460504
	140496655460840 -> 140496655460504
	140496655460840 [label="module_list.36.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140496655460672 -> 140496655460560
	140496655460672 [label="module_list.37.weight
 (32)" fillcolor=lightblue]
	140496655460728 -> 140496655460560
	140496655460728 [label="module_list.37.bias
 (32)" fillcolor=lightblue]
	140496655460448 -> 140498875514272
	140496655460448 [label="module_list.38.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140498875514440 -> 140498875514104
	140498875514440 [label="module_list.39.weight
 (32)" fillcolor=lightblue]
	140496655458600 -> 140498875514104
	140496655458600 [label="module_list.39.bias
 (32)" fillcolor=lightblue]
	140498875513824 -> 140498875513656
	140498875513824 [label=CudnnBatchNormBackward]
	140498875513992 -> 140498875513824
	140498875513992 [label=CudnnConvolutionBackward]
	140496655460784 -> 140498875513992
	140496655460784 [label=ReluBackward1]
	140496655461008 -> 140496655460784
	140496655461008 [label=CudnnBatchNormBackward]
	140496655460952 -> 140496655461008
	140496655460952 [label=CudnnConvolutionBackward]
	140498875513768 -> 140496655460952
	140496655461288 -> 140496655460952
	140496655461288 [label="module_list.40.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140496655461120 -> 140496655461008
	140496655461120 [label="module_list.41.weight
 (32)" fillcolor=lightblue]
	140496655461176 -> 140496655461008
	140496655461176 [label="module_list.41.bias
 (32)" fillcolor=lightblue]
	140496655460896 -> 140498875513992
	140496655460896 [label="module_list.42.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140498875514160 -> 140498875513824
	140498875514160 [label="module_list.43.weight
 (32)" fillcolor=lightblue]
	140496655459664 -> 140498875513824
	140496655459664 [label="module_list.43.bias
 (32)" fillcolor=lightblue]
	140498875513544 -> 140498875513264
	140498875513544 [label="module_list.44.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140498875513320 -> 140498875513152
	140498875513320 [label="module_list.45.weight
 (64)" fillcolor=lightblue]
	140498875513376 -> 140498875513152
	140498875513376 [label="module_list.45.bias
 (64)" fillcolor=lightblue]
	140498875513040 -> 140498875512760
	140498875513040 [label="module_list.46.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140498875512816 -> 140498875512648
	140498875512816 [label="module_list.47.weight
 (64)" fillcolor=lightblue]
	140498875512872 -> 140498875512648
	140498875512872 [label="module_list.47.bias
 (64)" fillcolor=lightblue]
	140498875512536 -> 140498875512368
	140498875512536 [label=CudnnBatchNormBackward]
	140498875512704 -> 140498875512536
	140498875512704 [label=CudnnConvolutionBackward]
	140498875513488 -> 140498875512704
	140498875513600 -> 140498875512704
	140498875513600 [label="module_list.48.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140498875512928 -> 140498875512536
	140498875512928 [label="module_list.49.weight
 (64)" fillcolor=lightblue]
	140498875513096 -> 140498875512536
	140498875513096 [label="module_list.49.bias
 (64)" fillcolor=lightblue]
	140498875511808 -> 140498875512480
	140498875511808 [label=CudnnBatchNormBackward]
	140498875511640 -> 140498875511808
	140498875511640 [label=CudnnConvolutionBackward]
	140498875513712 -> 140498875511640
	140498875513712 [label=ReluBackward1]
	140496655460616 -> 140498875513712
	140496655460616 [label=CudnnBatchNormBackward]
	140496655461344 -> 140496655460616
	140496655461344 [label=CudnnConvolutionBackward]
	140498875511472 -> 140496655461344
	140496655461400 -> 140496655461344
	140496655461400 [label="module_list.50.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140496655461064 -> 140496655460616
	140496655461064 [label="module_list.51.weight
 (64)" fillcolor=lightblue]
	140496655461456 -> 140496655460616
	140496655461456 [label="module_list.51.bias
 (64)" fillcolor=lightblue]
	140498875513880 -> 140498875511640
	140498875513880 [label="module_list.52.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140498875512592 -> 140498875511808
	140498875512592 [label="module_list.53.weight
 (64)" fillcolor=lightblue]
	140498875513432 -> 140498875511808
	140498875513432 [label="module_list.53.bias
 (64)" fillcolor=lightblue]
	140498875511752 -> 140498875511304
	140498875511752 [label=CudnnBatchNormBackward]
	140498875511192 -> 140498875511752
	140498875511192 [label=CudnnConvolutionBackward]
	140496655461512 -> 140498875511192
	140496655461512 [label=ReluBackward1]
	140496655461680 -> 140496655461512
	140496655461680 [label=CudnnBatchNormBackward]
	140496655461624 -> 140496655461680
	140496655461624 [label=CudnnConvolutionBackward]
	140498875511248 -> 140496655461624
	140496655461960 -> 140496655461624
	140496655461960 [label="module_list.54.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140496655461792 -> 140496655461680
	140496655461792 [label="module_list.55.weight
 (64)" fillcolor=lightblue]
	140496655461848 -> 140496655461680
	140496655461848 [label="module_list.55.bias
 (64)" fillcolor=lightblue]
	140496655461568 -> 140498875511192
	140496655461568 [label="module_list.56.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140498875512424 -> 140498875511752
	140498875512424 [label="module_list.57.weight
 (64)" fillcolor=lightblue]
	140498875513208 -> 140498875511752
	140498875513208 [label="module_list.57.bias
 (64)" fillcolor=lightblue]
	140498998391024 -> 140498998391920
	140498998391024 [label=CudnnBatchNormBackward]
	140498875511528 -> 140498998391024
	140498875511528 [label=CudnnConvolutionBackward]
	140496655461904 -> 140498875511528
	140496655461904 [label=ReluBackward1]
	140496655462128 -> 140496655461904
	140496655462128 [label=CudnnBatchNormBackward]
	140496655462072 -> 140496655462128
	140496655462072 [label=CudnnConvolutionBackward]
	140498998390912 -> 140496655462072
	140496655495240 -> 140496655462072
	140496655495240 [label="module_list.58.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140496655462240 -> 140496655462128
	140496655462240 [label="module_list.59.weight
 (64)" fillcolor=lightblue]
	140496655462296 -> 140496655462128
	140496655462296 [label="module_list.59.bias
 (64)" fillcolor=lightblue]
	140496655462016 -> 140498875511528
	140496655462016 [label="module_list.60.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140498875511416 -> 140498998391024
	140498875511416 [label="module_list.61.weight
 (64)" fillcolor=lightblue]
	140496655460168 -> 140498998391024
	140496655460168 [label="module_list.61.bias
 (64)" fillcolor=lightblue]
	140498998392424 -> 140498998392144
	140498998392424 [label=CudnnBatchNormBackward]
	140498998391808 -> 140498998392424
	140498998391808 [label=CudnnConvolutionBackward]
	140496655462352 -> 140498998391808
	140496655462352 [label=ReluBackward1]
	140496655495408 -> 140496655462352
	140496655495408 [label=CudnnBatchNormBackward]
	140496655495352 -> 140496655495408
	140496655495352 [label=CudnnConvolutionBackward]
	140498998392200 -> 140496655495352
	140496655495688 -> 140496655495352
	140496655495688 [label="module_list.62.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140496655495520 -> 140496655495408
	140496655495520 [label="module_list.63.weight
 (64)" fillcolor=lightblue]
	140496655495576 -> 140496655495408
	140496655495576 [label="module_list.63.bias
 (64)" fillcolor=lightblue]
	140496655462184 -> 140498998391808
	140496655462184 [label="module_list.64.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140498875511696 -> 140498998392424
	140498875511696 [label="module_list.65.weight
 (64)" fillcolor=lightblue]
	140496655461232 -> 140498998392424
	140496655461232 [label="module_list.65.bias
 (64)" fillcolor=lightblue]
	140498878283280 -> 140498878345792
	140498878283280 [label=TBackward]
	140498878283672 -> 140498878283280
	140498878283672 [label="module_list.67.weight
 (10, 64)" fillcolor=lightblue]
}
